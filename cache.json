{
  "sources": [
    {
      "title": "ML in Production",
      "feedUrl": "https://mlinproduction.com/feed",
      "siteUrl": "https://mlinproduction.com",
      "articles": []
    },
    {
      "title": "Blog",
      "feedUrl": "http://machinelearningmastery.com/blog/feed",
      "siteUrl": "https://machinelearningmastery.com/blog/",
      "articles": [
        {
          "id": "https://machinelearningmastery.com/?p=14330",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "The gradient descent algorithm is one of the most popular techniques for training deep neural networks. It has many applications in fields such as computer vision, speech recognition, and natural language processing. While the idea of gradient descent has been around for decades, it’s only recently that it’s been applied to applications related to deep […]\nThe post Implementing Gradient Descent in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/implementing-gradient-descent-in-pytorch/",
          "publishedOn": "2022-11-26T20:28:14.000Z",
          "wordCount": 7592,
          "title": "Implementing Gradient Descent in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/michael-behrens-DA-iYgv8kjE-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14318",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Linear regression is a simple yet powerful technique for predicting the values of variables based on other variables. It is often used for modeling relationships between two or more continuous variables, such as the relationship between income and age, or the relationship between weight and height. Likewise, linear regression can be used to predict continuous […]\nThe post Training a Linear Regression Model in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/training-a-linear-regression-model-in-pytorch/",
          "publishedOn": "2022-11-24T17:24:24.000Z",
          "wordCount": 7119,
          "title": "Training a Linear Regression Model in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/ryan-tasto-chbXE4o0ryU-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14311",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Linear regression is a statistical technique for estimating the relationship between two variables. A simple example of linear regression is to predict the height of someone based on the square root of the person’s weight (that’s what BMI is based on). To do this, we need to find the slope and intercept of the line. […]\nThe post Making Linear Predictions in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/making-linear-predictions-in-pytorch/",
          "publishedOn": "2022-11-24T04:11:30.000Z",
          "wordCount": 6417,
          "title": "Making Linear Predictions in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/daryan-shamkhali-pMCbPPPBSkA-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14301",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Structuring the data pipeline in a way that it can be effortlessly linked to your deep learning model is an important aspect of any deep learning-based system. PyTorch packs everything to do just that. While in the previous tutorial, we used simple datasets, we’ll need to work with larger datasets in real world scenarios in […]\nThe post Loading and Providing Datasets in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/loading-and-providing-datasets-in-pytorch/",
          "publishedOn": "2022-11-19T01:57:22.000Z",
          "wordCount": 5933,
          "title": "Loading and Providing Datasets in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/uriel-sc-11KDtiUWRq4-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14298",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "In machine learning and deep learning problems, a lot of effort goes into preparing the data. Data is usually messy and needs to be preprocessed before it can be used for training a model. If the data is not prepared correctly, the model won’t be able to generalize well. Some of the common steps required […]\nThe post Using Dataset Classes in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/using-dataset-classes-in-pytorch/",
          "publishedOn": "2022-11-17T01:55:54.000Z",
          "wordCount": 6445,
          "title": "Using Dataset Classes in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/nasa-1lfI7wkGWZ4-unsplash.jpg"
        },
        {
          "id": "https://35.82.237.216/?p=13195",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Derivatives are one of the most fundamental concepts in calculus. They describe how changes in the variable inputs affect the function outputs. The objective of this article is to provide a high-level introduction to calculating derivatives in PyTorch for those who are new to the framework. PyTorch offers a convenient way to calculate derivatives for […]\nThe post Calculating Derivatives in PyTorch appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/calculating-derivatives-in-pytorch/",
          "publishedOn": "2022-11-11T21:30:18.000Z",
          "wordCount": 6011,
          "title": "Calculating Derivatives in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/01/jossuha-theophile-H-CZjCQfsFw-unsplash.jpg"
        },
        {
          "id": "https://35.82.237.216/?p=13183",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Two-dimensional tensors are analogous to two-dimensional metrics. Like a two-dimensional metric, a two-dimensional tensor also has $n$ number of rows and columns. Let’s take a gray-scale image as an example, which is a two-dimensional matrix of numeric values, commonly known as pixels. Ranging from ‘0’ to ‘255’, each number represents a pixel intensity value. Here, […]\nThe post Two-Dimensional Tensors in Pytorch appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/two-dimensional-tensors-in-pytorch/",
          "publishedOn": "2022-11-09T21:30:51.000Z",
          "wordCount": 6286,
          "title": "Two-Dimensional Tensors in Pytorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/01/dylan-nolte-NIrgENd0sAY-unsplash-scaled.jpg"
        },
        {
          "id": "https://35.82.237.216/?p=13157",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "PyTorch is an open-source deep learning framework based on Python language. It allows you to build, train, and deploy deep learning models, offering a lot of versatility and efficiency. PyTorch is primarily focused on tensor operations while a tensor can be a number, matrix, or a multi-dimensional array. In this tutorial, we will perform some […]\nThe post One-Dimensional Tensors in Pytorch appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/one-dimensional-tensors-in-pytorch/",
          "publishedOn": "2022-11-07T21:30:13.000Z",
          "wordCount": 6633,
          "title": "One-Dimensional Tensors in Pytorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2021/12/jo-szczepanska-9OKGEVJiTKk-unsplash.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14064",
          "author": "MLM Team",
          "description": "Sponsored Post   The unlimited access initiative presents a risk-free way to break into data science.     The online educational platform 365 Data Science launches the #21DaysFREE campaign and provides 100% free unlimited access to all content for three weeks. From November 1 to 21, you can take courses from renowned instructors and earn […]\nThe post 365 Data Science courses free until November 21 appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/365-data-science-courses-free-until-november-21/",
          "publishedOn": "2022-11-02T15:50:51.000Z",
          "wordCount": 4628,
          "title": "365 Data Science courses free until November 21",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/mlm-365ds-20221102-1.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14006",
          "author": "MLM Team",
          "description": "Sponsored Post      Attend the Data Science Symposium 2022 on November 8 The Center for Business Analytics at the University of Cincinnati will present its annual Data Science Symposium 2022 on November 8. This all day in-person event will have three featured speakers and two tech talk tracks with four concurrent presentations in each track. The […]\nThe post Attend the Data Science Symposium 2022, November 8 in Cincinnati appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/uccsb-data-science-symposium-2022-cincinnati/",
          "publishedOn": "2022-11-01T15:16:00.000Z",
          "wordCount": 3115,
          "title": "Attend the Data Science Symposium 2022, November 8 in Cincinnati",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/10/mlm-uccsb-221018.png"
        }
      ]
    },
    {
      "title": "Machine Learning Archives - Uber Engineering Blog",
      "feedUrl": "https://eng.uber.com/tag/machine-learning/feed",
      "siteUrl": null,
      "articles": []
    },
    {
      "title": "AWS Machine Learning Blog",
      "feedUrl": "https://aws.amazon.com/blogs/machine-learning/feed",
      "siteUrl": "https://aws.amazon.com/blogs/machine-learning/",
      "articles": [
        {
          "id": "c31ba9f6161236cada276eab650a8e20bd5e322b",
          "author": "Fabian Benitez-Quiroz",
          "description": "Creative advertising has the potential to be revolutionized by generative AI (GenAI). You can now create a wide variation of novel images, such as product shots, by retraining a GenAI model and providing a few inputs into the model, such as textual prompts (sentences describing the scene and objects to be produced by the model). […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/generate-creative-advertising-using-generative-ai-deployed-on-amazon-sagemaker/",
          "publishedOn": "2023-08-09T15:51:52.000Z",
          "wordCount": 2604,
          "title": "Generate creative advertising using generative AI deployed on Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/23/ml14623-pic5.png"
        },
        {
          "id": "fe4b7176ee2cb00d55731c82d55cffc5048de587",
          "author": "Giuseppe Angelo Porcelli",
          "description": "Amazon SageMaker offers several ways to run distributed data processing jobs with Apache Spark, a popular distributed computing framework for big data processing. You can run Spark applications interactively from Amazon SageMaker Studio by connecting SageMaker Studio notebooks and AWS Glue Interactive Sessions to run Spark jobs with a serverless cluster. With interactive sessions, you […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/host-the-spark-ui-on-amazon-sagemaker-studio/",
          "publishedOn": "2023-08-08T14:56:37.000Z",
          "wordCount": 2022,
          "title": "Host the Spark UI on Amazon SageMaker Studio",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/08/host-spark-ui-sagemaker-1260x627.jpg"
        },
        {
          "id": "0d891430918fc0e8d35e838165355924f5d50203",
          "author": "Saurabh Trikande",
          "description": "Artificial intelligence (AI) adoption is accelerating across industries and use cases. Recent scientific breakthroughs in deep learning (DL), large language models (LLMs), and generative AI is allowing customers to use advanced state-of-the-art solutions with almost human-like performance. These complex models often require hardware acceleration because it enables not only faster training but also faster inference […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/deploy-thousands-of-model-ensembles-with-amazon-sagemaker-multi-model-endpoints-on-gpu-to-minimize-your-hosting-costs/",
          "publishedOn": "2023-08-08T14:50:24.000Z",
          "wordCount": 4014,
          "title": "Deploy thousands of model ensembles with Amazon SageMaker multi-model endpoints on GPU to minimize your hosting costs",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/08/deploy-thousands-of-models-1248x630.jpg"
        },
        {
          "id": "77a17a11d0aead706432a73843e10ef5fcb04866",
          "author": "James Poquiz",
          "description": "The video gaming industry has an estimated user base of over 3 billion worldwide1. It consists of massive amounts of players virtually interacting with each other every single day. Unfortunately, as in the real world, not all players communicate appropriately and respectfully. In an effort to create and maintain a socially responsible gaming environment, AWS […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/aws-performs-fine-tuning-on-a-large-language-model-llm-to-classify-toxic-speech-for-a-large-gaming-company/",
          "publishedOn": "2023-08-07T16:19:32.000Z",
          "wordCount": 3834,
          "title": "AWS performs fine-tuning on a Large Language Model (LLM) to classify toxic speech for a large gaming company",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/07/fine-tuning-llm-toxic-speech.jpg"
        },
        {
          "id": "d1805ab7deb9bfb3391ea7c0a40f3de550fb774f",
          "author": "Munish Dabra",
          "description": "Data preparation is a critical step in any data-driven project, and having the right tools can greatly enhance operational efficiency. Amazon SageMaker Data Wrangler reduces the time it takes to aggregate and prepare tabular and image data for machine learning (ML) from weeks to minutes. With SageMaker Data Wrangler, you can simplify the process of […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/optimize-data-preparation-with-new-features-in-aws-sagemaker-data-wrangler/",
          "publishedOn": "2023-08-04T15:25:07.000Z",
          "wordCount": 3113,
          "title": "Optimize data preparation with new features in AWS SageMaker Data Wrangler",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/04/optimize-data-prepration.jpg"
        },
        {
          "id": "a2b1bc4198e78d6b2212663d4bbfe35684d07cf1",
          "author": "Arun Anand",
          "description": "Amazon Kendra is a highly accurate and simple-to-use intelligent search service powered by machine learning (ML). Amazon Kendra offers a suite of data source connectors to simplify the process of ingesting and indexing your content, wherever it resides. Valuable data in organizations is stored in both structured and unstructured repositories. An enterprise search solution should […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/index-your-alfresco-content-using-the-new-amazon-kendra-alfresco-connector/",
          "publishedOn": "2023-08-04T15:22:23.000Z",
          "wordCount": 3832,
          "title": "Index your Alfresco content using the new Amazon Kendra Alfresco connector",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/04/index-alfresco-kendra.jpg"
        },
        {
          "id": "916f79e9bd6042fdeef0f4597c4d9c4d2b84b1cb",
          "author": "Daryl Martis",
          "description": "This post is co-authored by Daryl Martis, Director of Product, Salesforce Einstein AI. This is the second post in a series discussing the integration of Salesforce Data Cloud and Amazon SageMaker. In Part 1, we show how the Salesforce Data Cloud and Einstein Studio integration with SageMaker allows businesses to access their Salesforce data securely […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/use-the-amazon-sagemaker-and-salesforce-data-cloud-integration-to-power-your-salesforce-apps-with-ai-ml/",
          "publishedOn": "2023-08-04T13:28:06.000Z",
          "wordCount": 4017,
          "title": "Use the Amazon SageMaker and Salesforce Data Cloud integration to power your Salesforce apps with AI/ML",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/04/featured-images-ML-14831-1120x630.jpg"
        },
        {
          "id": "6dfe21fba320ad0766e221ed41ad1fa0f05ca2a5",
          "author": "Daryl Martis",
          "description": "This post is co-authored by Daryl Martis, Director of Product, Salesforce Einstein AI. We’re excited to announce Amazon SageMaker and Salesforce Data Cloud integration. With this capability, businesses can access their Salesforce data securely with a zero-copy approach using SageMaker and use SageMaker tools to build, train, and deploy AI models. The inference endpoints are […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/bring-your-own-ai-using-amazon-sagemaker-with-salesforce-data-cloud/",
          "publishedOn": "2023-08-04T13:27:49.000Z",
          "wordCount": 1966,
          "title": "Bring your own AI using Amazon SageMaker with Salesforce Data Cloud",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/04/featured-images-ML-14150-1120x630.jpg"
        },
        {
          "id": "484db3a32281ed52711245b1b2a28e1a0738395f",
          "author": "Sonali Sahu",
          "description": "Data classification, extraction, and analysis can be challenging for organizations that deal with volumes of documents. Traditional document processing solutions are manual, expensive, error prone, and difficult to scale. AWS intelligent document processing (IDP), with AI services such as Amazon Textract, allows you to take advantage of industry-leading machine learning (ML) technology to quickly and […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/enhancing-aws-intelligent-document-processing-with-generative-ai/",
          "publishedOn": "2023-08-03T21:03:51.000Z",
          "wordCount": 2972,
          "title": "Enhancing AWS intelligent document processing with generative AI",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/26/How-to-get-started.png"
        },
        {
          "id": "d67642ddc18badec3079714f22048736b1af685b",
          "author": "Davide Gallitelli",
          "description": "Training and serving thousands of models requires a robust and scalable infrastructure, which is where Amazon SageMaker can help. SageMaker is a fully managed platform that enables developers and data scientists to build, train, and deploy ML models quickly, while also offering the cost-saving benefits of using the AWS Cloud infrastructure. In this post, we explore how you can use SageMaker features, including Amazon SageMaker Processing, SageMaker training jobs, and SageMaker multi-model endpoints (MMEs), to train and serve thousands of models in a cost-effective way. To get started with the described solution, you can refer to the accompanying notebook on GitHub.",
          "link": "https://aws.amazon.com/blogs/machine-learning/scale-training-and-inference-of-thousands-of-ml-models-with-amazon-sagemaker/",
          "publishedOn": "2023-08-03T15:05:18.000Z",
          "wordCount": 2296,
          "title": "Scale training and inference of thousands of ML models with Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/21/ML_14247_001-982x630.jpg"
        },
        {
          "id": "2f187b6559dc9961698a191709d895142a1af1c2",
          "author": "Peter Chung",
          "description": "Amazon SageMaker Canvas is a visual interface that enables business analysts to generate accurate machine learning (ML) predictions on their own, without requiring any ML experience or having to write a single line of code. SageMaker Canvas’s intuitive user interface lets business analysts browse and access disparate data sources in the cloud or on premises, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/accelerate-business-outcomes-with-70-performance-improvements-to-data-processing-training-and-inference-with-amazon-sagemaker-canvas/",
          "publishedOn": "2023-08-03T15:03:13.000Z",
          "wordCount": 1537,
          "title": "Accelerate business outcomes with 70% performance improvements to data processing, training, and inference with Amazon SageMaker Canvas",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/03/accelerate-business-outcomes.jpg"
        },
        {
          "id": "08cbe64d98b902ecbbf3bdfff6eb742b50522061",
          "author": "Michael Wallner",
          "description": "Computer vision (CV) is one of the most common applications of machine learning (ML) and deep learning. Use cases range from self-driving cars, content moderation on social media platforms, cancer detection, and automated defect detection. Amazon Rekognition is a fully managed service that can perform CV tasks like object detection, video segment detection, content moderation, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-and-train-computer-vision-models-to-detect-car-positions-in-images-using-amazon-sagemaker-and-amazon-rekognition/",
          "publishedOn": "2023-08-03T14:53:06.000Z",
          "wordCount": 3321,
          "title": "Build and train computer vision models to detect car positions in images using Amazon SageMaker and Amazon Rekognition",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/03/ML-5922-demo-v2-1253x630.jpg"
        },
        {
          "id": "a961dec7677d8fc197198ecf9f9fbd3ab483418e",
          "author": "James Wu",
          "description": "Generative AI has become a common tool for enhancing and accelerating the creative process across various industries, including entertainment, advertising, and graphic design. It enables more personalized experiences for audiences and improves the overall quality of the final products. One significant benefit of generative AI is creating unique and personalized experiences for users. For example, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-a-personalized-avatar-with-generative-ai-using-amazon-sagemaker/",
          "publishedOn": "2023-08-02T18:34:51.000Z",
          "wordCount": 4077,
          "title": "Build a personalized avatar with generative AI using Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/02/avatar-generator.jpg"
        },
        {
          "id": "bf1992cff067be622b2fbc0b0528128dcb94e007",
          "author": "Durga Sury",
          "description": "SageMaker Distribution is a pre-built Docker image containing many popular packages for machine learning (ML), data science, and data visualization. This includes deep learning frameworks like PyTorch, TensorFlow, and Keras; popular Python packages like NumPy, scikit-learn, and pandas; and IDEs like JupyterLab. In addition to this, SageMaker Distribution supports conda, micromamba, and pip as Python […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/sagemaker-distribution-is-now-available-on-amazon-sagemaker-studio/",
          "publishedOn": "2023-08-02T16:43:38.000Z",
          "wordCount": 1659,
          "title": "SageMaker Distribution is now available on Amazon SageMaker Studio",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/27/featured-images-ML-14803.jpg"
        },
        {
          "id": "9e5578025e96d9ac193588c84fd557b4a05bb9ce",
          "author": "Bharathi Srinivasan",
          "description": "Amazon Kendra is an intelligent search service powered by machine learning (ML). Amazon Kendra reimagines search for your websites and applications so your employees and customers can easily find the content they are looking for, even when it’s scattered across multiple locations and content repositories within your organization. Amazon Kendra supports a variety of document […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/automate-caption-creation-and-search-for-images-at-enterprise-scale-using-generative-ai-and-amazon-kendra/",
          "publishedOn": "2023-08-02T16:41:11.000Z",
          "wordCount": 3865,
          "title": "Automate caption creation and search for images at enterprise scale using generative AI and Amazon Kendra",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/12/ML-14376-dog.png"
        },
        {
          "id": "4dcd970c366917e179e4ccb0ae4b3226624ac4a5",
          "author": "Cody Collins",
          "description": "In today’s rapidly evolving healthcare landscape, doctors are faced with vast amounts of clinical data from various sources, such as caregiver notes, electronic health records, and imaging reports. This wealth of information, while essential for patient care, can also be overwhelming and time-consuming for medical professionals to sift through and analyze. Efficiently summarizing and extracting […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/exploring-summarization-options-for-healthcare-with-amazon-sagemaker/",
          "publishedOn": "2023-08-01T16:18:11.000Z",
          "wordCount": 3980,
          "title": "Exploring summarization options for Healthcare with Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/01/exploring-summarization.jpg"
        },
        {
          "id": "029fa01aab00ba059bb2c4dea65ccb92a529fe52",
          "author": "Sovik Nath",
          "description": "Advertising agencies can use generative AI and text-to-image foundation models to create innovative ad creatives and content. In this post, we demonstrate how you can generate new images from existing base images using Amazon SageMaker, a fully managed service to build, train, and deploy ML models for at scale. With this solution, businesses large and […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/unlocking-creativity-how-generative-ai-and-amazon-sagemaker-help-businesses-produce-ad-creatives-for-marketing-campaigns-with-aws/",
          "publishedOn": "2023-08-01T16:07:55.000Z",
          "wordCount": 2361,
          "title": "Unlocking creativity: How generative AI and Amazon SageMaker help businesses produce ad creatives for marketing campaigns with AWS",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/01/unlocking-creativity.jpg"
        },
        {
          "id": "6e0df33339b9d69180135f44d0365aab07316895",
          "author": "Michael Hsieh",
          "description": "Drug development is a complex and long process that involves screening thousands of drug candidates and using computational or experimental methods to evaluate leads. According to McKinsey, a single drug can take 10 years and cost an average of $2.6 billion to go through disease target identification, drug screening, drug-target validation, and eventual commercial launch. […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-protein-folding-workflows-to-accelerate-drug-discovery-on-amazon-sagemaker/",
          "publishedOn": "2023-07-31T18:49:40.000Z",
          "wordCount": 4648,
          "title": "Build protein folding workflows to accelerate drug discovery on Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/24/ML-13966_image_1-1247x630.png"
        },
        {
          "id": "9e80cb060b91fc116b0d34de8ee6d79177b5440c",
          "author": "Marcos Boaglio",
          "description": "If you are a business analyst, understanding customer behavior is probably one of the most important things you care about. Understanding the reasons and mechanisms behind customer purchase decisions can facilitate revenue growth. However, the loss of customers (commonly referred to as customer churn) always poses a risk. Gaining insights into why customers leave can […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/is-your-model-good-a-deep-dive-into-amazon-sagemaker-canvas-advanced-metrics/",
          "publishedOn": "2023-07-31T18:45:03.000Z",
          "wordCount": 4149,
          "title": "Is your model good? A deep dive into Amazon SageMaker Canvas advanced metrics",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/23/canvas-adv-metric-blog-image033-1260x580.png"
        },
        {
          "id": "ea51ece96c1f0e5780bdeb5ac665bbda0afa5913",
          "author": "June Won",
          "description": "Today we are excited to announce that Stable Diffusion XL 1.0 (SDXL 1.0) is available for customers through Amazon SageMaker JumpStart. SDXL 1.0 is the latest image generation model from Stability AI. SDXL 1.0 enhancements include native 1024-pixel image generation at a variety of aspect ratios. It’s designed for professional use, and calibrated for high-resolution […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/use-stable-diffusion-xl-with-amazon-sagemaker-jumpstart-in-amazon-sagemaker-studio/",
          "publishedOn": "2023-07-26T21:09:59.000Z",
          "wordCount": 3450,
          "title": "Use Stable Diffusion XL with Amazon SageMaker JumpStart in Amazon SageMaker Studio",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/26/ml-15160-image018-share.jpg"
        },
        {
          "id": "45df9e13aa8d2c9e4346f4b49aebb96cdcdfa796",
          "author": "Lana Zhang",
          "description": "The increase in online social activities such as social networking or online gaming is often riddled with hostile or aggressive behavior that can lead to unsolicited manifestations of hate speech, cyberbullying, or harassment. For example, many online gaming communities offer voice chat functionality to facilitate communication among their users. Although voice chat often supports friendly […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/flag-harmful-language-in-spoken-conversations-with-amazon-transcribe-toxicity-detection/",
          "publishedOn": "2023-07-26T18:48:17.000Z",
          "wordCount": 2340,
          "title": "Flag harmful language in spoken conversations with Amazon Transcribe Toxicity Detection",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/26/harmful-language-transcribe-1260x630.jpg"
        },
        {
          "id": "24f6299643a27c604568ebe4a5d18c25792dfae7",
          "author": "Vivek Gangasani",
          "description": "Generative AI models have been experiencing rapid growth in recent months due to its impressive capabilities in creating realistic text, images, code, and audio. Among these models, Stable Diffusion models stand out for their unique strength in creating high-quality images based on text prompts. Stable Diffusion can generate a wide variety of high-quality images, including […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/maximize-stable-diffusion-performance-and-lower-inference-costs-with-aws-inferentia2/",
          "publishedOn": "2023-07-26T16:37:10.000Z",
          "wordCount": 3516,
          "title": "Maximize Stable Diffusion performance and lower inference costs with AWS Inferentia2",
          "enclosure": {
            "length": "8479584",
            "type": "video/mp4",
            "url": "https://d2908q01vomqb2.cloudfront.net/artifacts/DBSBlogs/ML-14708/ML-14708_demo.mp4"
          },
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/26/maximize-stable-diffusion-performance-1260x628.jpg"
        },
        {
          "id": "de48f99409df65a899600721f40313e6f5072b2a",
          "author": "Caleb Wilkinson",
          "description": "Breakthroughs in artificial intelligence (AI) and machine learning (ML) have been in the headlines for months—and for good reason. The emerging and evolving capabilities of this technology promises new business opportunities for customer across all sectors and industries. But the speed of this revolution has made it harder for organizations and consumers to assess what […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/aws-offers-new-artificial-intelligence-machine-learning-and-generative-ai-guides-to-plan-your-ai-strategy/",
          "publishedOn": "2023-07-26T16:30:40.000Z",
          "wordCount": 1874,
          "title": "AWS offers new artificial intelligence, machine learning, and generative AI guides to plan your AI strategy",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/25/generative-ai-guides-1260x630.jpg"
        },
        {
          "id": "fc28b7f09affe471cd04291b543db1974f4b6fb4",
          "author": "Emily Webber",
          "description": "Generative AI Foundations on AWS is a new technical deep dive course that gives you the conceptual fundamentals, practical advice, and hands-on guidance to pre-train, fine-tune, and deploy state-of-the-art foundation models on AWS and beyond. Developed by AWS generative AI worldwide foundations lead Emily Webber, this free hands-on course and the supporting GitHub source code […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/new-technical-deep-dive-course-generative-ai-foundations-on-aws/",
          "publishedOn": "2023-07-26T12:20:13.000Z",
          "wordCount": 1812,
          "title": "New technical deep dive course: Generative AI Foundations on AWS",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/25/Gen-AI-Foundations-Course-resized-1260x630.png"
        },
        {
          "id": "f68d0d6b4fc134ccc9ec193efb8173f70bf616d6",
          "author": "Peter Hallinan",
          "description": "As a pioneer in artificial intelligence and machine learning, AWS is committed to developing and deploying generative AI responsibly As one of the most transformational innovations of our time, generative AI continues to capture the world’s imagination, and we remain as committed as ever to harnessing it responsibly. With a team of dedicated responsible AI […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/aws-reaffirms-its-commitment-to-responsible-generative-ai/",
          "publishedOn": "2023-07-26T04:00:36.000Z",
          "wordCount": 1385,
          "title": "AWS Reaffirms its Commitment to Responsible Generative AI",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/26/aws-commitment-to-responsible-generative-ai-1260x628.jpg"
        },
        {
          "id": "e6cf42cd370b365438792942d951302067509d3f",
          "author": "Vikesh Pandey",
          "description": "With recent advancements in generative AI, there are lot of discussions happening on how to use generative AI across different industries to solve specific business problems. Generative AI is a type of AI that can create new content and ideas, including conversations, stories, images, videos, and music. It is all backed by very large models […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/use-generative-ai-foundation-models-in-vpc-mode-with-no-internet-connectivity-using-amazon-sagemaker-jumpstart/",
          "publishedOn": "2023-07-25T16:29:41.000Z",
          "wordCount": 2614,
          "title": "Use generative AI foundation models in VPC mode with no internet connectivity using Amazon SageMaker JumpStart",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/06/22/14480-sol-arch-1080x630.jpg"
        },
        {
          "id": "5acad1559c5977ab664629f8f12ddd6316f830a0",
          "author": "Hao Huang",
          "description": "This blog post was co-authored, and includes an introduction, by Zilong Bai, senior natural language processing engineer at Patsnap. You’re likely familiar with the autocomplete suggestion feature when you search for something on Google or Amazon. Although the search terms in these scenarios are pretty common keywords or expressions that we use in daily life, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/how-patsnap-used-gpt-2-inference-on-amazon-sagemaker-with-low-latency-and-cost/",
          "publishedOn": "2023-07-24T21:23:16.000Z",
          "wordCount": 2682,
          "title": "How Patsnap used GPT-2 inference on Amazon SageMaker with low latency and cost",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/24/patsnap-gpt-2.jpg"
        },
        {
          "id": "1258cb4db60d1f090fe8dc73bde2cf5c7e131899",
          "author": "Ankur Srivastava",
          "description": "When deploying Deep Learning models at scale, it is crucial to effectively utilize the underlying hardware to maximize performance and cost benefits. For production workloads requiring high throughput and low latency, the selection of the Amazon Elastic Compute Cloud (EC2) instance, model serving stack, and deployment architecture is very important. Inefficient architecture can lead to […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/optimize-aws-inferentia-utilization-with-fastapi-and-pytorch-models-on-amazon-ec2-inf1-inf2-instances/",
          "publishedOn": "2023-07-24T20:55:07.000Z",
          "wordCount": 4483,
          "title": "Optimize AWS Inferentia utilization with FastAPI and PyTorch models on Amazon EC2 Inf1 & Inf2 instances",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/24/optimize-inferentia-utilization.jpg"
        },
        {
          "id": "91f805ef65823ffa7025c4aae175da7beb6fd212",
          "author": "Bunny Kaushik",
          "description": "Rodents such as rats and mice are associated with a number of health risks and are known to spread more than 35 diseases. Identifying regions of high rodent activity can help local authorities and pest control organizations plan for interventions effectively and exterminate the rodents. In this post, we show how to monitor and visualize […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/analyze-rodent-infestation-using-amazon-sagemaker-geospatial-capabilities/",
          "publishedOn": "2023-07-21T18:29:22.000Z",
          "wordCount": 2143,
          "title": "Analyze rodent infestation using Amazon SageMaker geospatial capabilities",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/13/ML-13593-image001-1103x630.png"
        },
        {
          "id": "61cc7a608e5ac9fe8dcf9aaf73b46566906295fe",
          "author": "Mario Namtao Shianti Larcher",
          "description": "This is a guest post by Mario Namtao Shianti Larcher, Head of Computer Vision at Enel. Enel, which started as Italy’s national entity for electricity, is today a multinational company present in 32 countries and the first private network operator in the world with 74 million users. It is also recognized as the first renewables […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/enel-automates-large-scale-power-grid-asset-management-and-anomaly-detection-using-amazon-sagemaker/",
          "publishedOn": "2023-07-20T17:59:24.000Z",
          "wordCount": 2479,
          "title": "Enel automates large-scale power grid asset management and anomaly detection using Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/20/enel-power-grid-management-sagemaker.jpg"
        },
        {
          "id": "a3fd48657b2b543b3d4f647d1c41dd9cc848e460",
          "author": "Melanie Li",
          "description": "Artificial intelligence (AI) has become an important and popular topic in the technology community. As AI has evolved, we have seen different types of machine learning (ML) models emerge. One approach, known as ensemble modeling, has been rapidly gaining traction among data scientists and practitioners. In this post, we discuss what ensemble models are and […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/efficiently-train-tune-and-deploy-custom-ensembles-using-amazon-sagemaker/",
          "publishedOn": "2023-07-20T16:12:14.000Z",
          "wordCount": 3465,
          "title": "Efficiently train, tune, and deploy custom ensembles using Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/20/train-tune-deploy-custom-ensembles-sagemaker.png"
        },
        {
          "id": "40f4f6b6c98faf3948905a3ac98c06c5c51fd01f",
          "author": "Randy DeFauw",
          "description": "Large language models (LLMs) can be used to analyze complex documents and provide summaries and answers to questions. The post Domain-adaptation Fine-tuning of Foundation Models in Amazon SageMaker JumpStart on Financial data describes how to fine-tune an LLM using your own dataset. Once you have a solid LLM, you’ll want to expose that LLM to […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/use-a-generative-ai-foundation-model-for-summarization-and-question-answering-using-your-own-data/",
          "publishedOn": "2023-07-19T16:27:34.000Z",
          "wordCount": 2141,
          "title": "Use a generative AI foundation model for summarization and question answering using your own data",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/19/use-generative-ai-foundation-model-summarization-1260x630.jpg"
        },
        {
          "id": "2397694c770e4cadd95ac6afad7d6f07fd5b53ed",
          "author": "Ram Vittal",
          "description": "Amazon SageMaker Model Cards enable you to standardize how models are documented, thereby achieving visibility into the lifecycle of a model, from designing, building, training, and evaluation. Model cards are intended to be a single source of truth for business and technical metadata about the model that can reliably be used for auditing and documentation […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/integrate-amazon-sagemaker-model-cards-with-the-model-registry/",
          "publishedOn": "2023-07-19T16:19:54.000Z",
          "wordCount": 2242,
          "title": "Integrate Amazon SageMaker Model Cards with the model registry",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/12/ML-14808-image001.png"
        },
        {
          "id": "9668f5be1fea4a8e94dec7ba7df6c1398fedc088",
          "author": "Max Henkel-Wallace",
          "description": "Amazon Lex is a service that allows you to quickly and easily build conversational bots (“chatbots”), virtual agents, and interactive voice response (IVR) systems for applications such as Amazon Connect. Artificial intelligence (AI) and machine learning (ML) have been a focus for Amazon for over 20 years, and many of the capabilities that customers use […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/enhance-amazon-lex-with-conversational-faq-features-using-llms/",
          "publishedOn": "2023-07-18T22:48:24.000Z",
          "wordCount": 2982,
          "title": "Enhance Amazon Lex with conversational FAQ features using LLMs",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/18/enhance-lex-conversational-faq-llm.jpg"
        },
        {
          "id": "1243f804dd0606d34a2c5295d389c54ded000d99",
          "author": "Max Henkel-Wallace",
          "description": "In today’s digital world, most consumers would rather find answers to their customer service questions on their own rather than taking the time to reach out to businesses and/or service providers. This blog post explores an innovative solution to build a question and answer chatbot in Amazon Lex that uses existing FAQs from your website. […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/enhance-amazon-lex-with-llms-and-improve-the-faq-experience-using-url-ingestion/",
          "publishedOn": "2023-07-18T22:48:15.000Z",
          "wordCount": 2600,
          "title": "Enhance Amazon Lex with LLMs and improve the FAQ experience using URL ingestion",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/18/enhance-lex-llms-url-ingestion.jpg"
        },
        {
          "id": "dfcb0f9020db2ad682fe75f2a663402cf9b10c2d",
          "author": "Dhiraj Thakur",
          "description": "Spam emails, also known as junk mail, are sent to a large number of users at once and often contain scams, phishing content, or cryptic messages. Spam emails are sometimes sent manually by a human, but most often they are sent using a bot. Examples of spam emails include fake ads, chain emails, and impersonation […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-an-email-spam-detector-using-amazon-sagemaker/",
          "publishedOn": "2023-07-18T16:45:26.000Z",
          "wordCount": 1703,
          "title": "Build an email spam detector using Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/18/build-an-amazon-sagemaker-email-spam-detector.jpg"
        },
        {
          "id": "17b85f3b3e8e5ddfe1c795e50b416b392a28f188",
          "author": "June Won",
          "description": "Today, we are excited to announce that Llama 2 foundation models developed by Meta are available for customers through Amazon SageMaker JumpStart. The Llama 2 family of large language models (LLMs) is a collection of pre-trained and fine-tuned generative text models ranging in scale from 7 billion to 70 billion parameters. Fine-tuned LLMs, called Llama-2-chat, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/llama-2-foundation-models-from-meta-are-now-available-in-amazon-sagemaker-jumpstart/",
          "publishedOn": "2023-07-18T16:01:34.000Z",
          "wordCount": 4173,
          "title": "Llama 2 foundation models from Meta are now available in Amazon SageMaker JumpStart",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/18/llama-2-foundation-models-sagemaker-jumpstart.jpg"
        },
        {
          "id": "7a9ba44e3a06219c8fb5e7af7a8e9248abce1d5f",
          "author": "Supriya Puragundla",
          "description": "With cloud computing, as compute power and data became more available, machine learning (ML) is now making an impact across every industry and is a core part of every business and industry. Amazon SageMaker Studio is the first fully integrated ML development environment (IDE) with a web-based visual interface. You can perform all ML development […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/configure-cross-account-access-of-amazon-redshift-clusters-in-amazon-sagemaker-studio-using-vpc-peering/",
          "publishedOn": "2023-07-17T19:54:11.000Z",
          "wordCount": 3095,
          "title": "Configure cross-account access of Amazon Redshift clusters in Amazon SageMaker Studio using VPC peering",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/07/MLBlog10198_1_image1-1053x630.jpg"
        },
        {
          "id": "16fdfeba6a2409d487b2ce43115d50e2cec95a71",
          "author": "Uri Rosenberg",
          "description": "Recent years have shown amazing growth in deep learning neural networks (DNNs). This growth can be seen in more accurate models and even opening new possibilities with generative AI: large language models (LLMs) that synthesize natural language, text-to-image generators, and more. These increased capabilities of DNNs come with the cost of having massive models that […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/effectively-solve-distributed-training-convergence-issues-with-amazon-sagemaker-hyperband-automatic-model-tuning/",
          "publishedOn": "2023-07-13T16:03:48.000Z",
          "wordCount": 3162,
          "title": "Effectively solve distributed training convergence issues with Amazon SageMaker Hyperband Automatic Model Tuning",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/13/effectively-solve-distributed-training.jpg"
        },
        {
          "id": "cdc3226b1bb7b354bc2e0c7d0dd28b1d37f7e77f",
          "author": "Vikesh Pandey",
          "description": "As more and more customers are looking to put machine learning (ML) workloads in production, there is a large push in organizations to shorten the development lifecycle of ML code. Many organizations prefer writing their ML code in a production-ready style in the form of Python methods and classes as opposed to an exploratory style […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/access-private-repos-using-the-remote-decorator-for-amazon-sagemaker-training-workloads/",
          "publishedOn": "2023-07-11T16:25:23.000Z",
          "wordCount": 2347,
          "title": "Access private repos using the @remote decorator for Amazon SageMaker training workloads",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/07/11/acces-private-repos-remote-decorator.jpg"
        }
      ]
    },
    {
      "title": "cs.LG updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/cs.LG",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2212.03188",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Bond_R/0/1/0/all/0/1\">R. Bailey Bond</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ren_P/0/1/0/all/0/1\">Pu Ren</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Hajjar_J/0/1/0/all/0/1\">Jerome F. Hajjar</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sun_H/0/1/0/all/0/1\">Hao Sun</a>",
          "description": "Clustering analysis of sequence data continues to address many applications\nin engineering design, aided with the rapid growth of machine learning in\napplied science. This paper presents an unsupervised machine learning algorithm\nto extract defining characteristics of earthquake ground-motion spectra, also\ncalled latent features, to aid in ground-motion selection (GMS). In this\ncontext, a latent feature is a low-dimensional machine-discovered spectral\ncharacteristic learned through nonlinear relationships of a neural network\nautoencoder. Machine discovered latent features can be combined with\ntraditionally defined intensity measures and clustering can be performed to\nselect a representative subgroup from a large ground-motion suite. The\nobjective of efficient GMS is to choose characteristic records representative\nof what the structure will probabilistically experience in its lifetime. Three\nexamples are presented to validate this approach, including the use of\nsynthetic and field recorded ground-motion datasets. The presented deep\nembedding clustering of ground-motion spectra has three main advantages: 1.\ndefining characteristics the represent the sparse spectral content of\nground-motions are discovered efficiently through training of the autoencoder,\n2. domain knowledge is incorporated into the machine learning framework with\nconditional variables in the deep embedding scheme, and 3. method exhibits\nexcellent performance when compared to a benchmark seismic hazard analysis.",
          "link": "http://arxiv.org/abs/2212.03188",
          "publishedOn": "2023-08-05T00:48:27.439Z",
          "wordCount": 738,
          "title": "An Unsupervised Machine Learning Approach for Ground-Motion Spectra Clustering and Selection. (arXiv:2212.03188v2 [physics.geo-ph] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01674",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mayfrank_D/0/1/0/all/0/1\">Daniel Mayfrank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitsos_A/0/1/0/all/0/1\">Alexander Mitsos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dahmen_M/0/1/0/all/0/1\">Manuel Dahmen</a>",
          "description": "(Economic) nonlinear model predictive control ((e)NMPC) requires dynamic\nsystem models that are sufficiently accurate in all relevant state-space\nregions. These models must also be computationally cheap enough to ensure\nreal-time tractability. Data-driven surrogate models for mechanistic models can\nbe used to reduce the computational burden of (e)NMPC; however, such models are\ntypically trained by system identification for maximum average prediction\naccuracy on simulation samples and perform suboptimally as part of actual\n(e)NMPC. We present a method for end-to-end reinforcement learning of dynamic\nsurrogate models for optimal performance in (e)NMPC applications, resulting in\npredictive controllers that strike a favorable balance between control\nperformance and computational demand. We validate our method on two\napplications derived from an established nonlinear continuous stirred-tank\nreactor model. We compare the controller performance to that of MPCs utilizing\nmodels trained by the prevailing maximum prediction accuracy paradigm, and\nmodel-free neural network controllers trained using reinforcement learning. We\nshow that our method matches the performance of the model-free neural network\ncontrollers while consistently outperforming models derived from system\nidentification. Additionally, we show that the MPC policies can react to\nchanges in the control setting without retraining.",
          "link": "http://arxiv.org/abs/2308.01674",
          "publishedOn": "2023-08-05T00:48:27.433Z",
          "wordCount": 716,
          "title": "End-to-End Reinforcement Learning of Koopman Models for Economic Nonlinear MPC. (arXiv:2308.01674v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2112.15402",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Quanziang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Renzhen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuexiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1\">Dong Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1\">Kai Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yefeng Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_D/0/1/0/all/0/1\">Deyu Meng</a>",
          "description": "Continual learning is a promising machine learning paradigm to learn new\ntasks while retaining previously learned knowledge over streaming training\ndata. Till now, rehearsal-based methods, keeping a small part of data from old\ntasks as a memory buffer, have shown good performance in mitigating\ncatastrophic forgetting for previously learned knowledge. However, most of\nthese methods typically treat each new task equally, which may not adequately\nconsider the relationship or similarity between old and new tasks. Furthermore,\nthese methods commonly neglect sample importance in the continual training\nprocess and result in sub-optimal performance on certain tasks. To address this\nchallenging problem, we propose Relational Experience Replay (RER), a bi-level\nlearning framework, to adaptively tune task-wise relationships and sample\nimportance within each task to achieve a better `stability' and `plasticity'\ntrade-off. As such, the proposed method is capable of accumulating new\nknowledge while consolidating previously learned old knowledge during continual\nlearning. Extensive experiments conducted on three publicly available datasets\n(i.e., CIFAR-10, CIFAR-100, and Tiny ImageNet) show that the proposed method\ncan consistently improve the performance of all baselines and surpass current\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2112.15402",
          "publishedOn": "2023-08-05T00:48:27.426Z",
          "wordCount": 744,
          "title": "Relational Experience Replay: Continual Learning by Adaptively Tuning Task-wise Relationship. (arXiv:2112.15402v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01606",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Peng_L/0/1/0/all/0/1\">Liang Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaofeng Zhu</a>",
          "description": "Unsupervised multiplex graph learning (UMGL) has been shown to achieve\nsignificant effectiveness for different downstream tasks by exploring both\ncomplementary information and consistent information among multiple graphs.\nHowever, previous methods usually overlook the issues in practical\napplications, i.e., the out-of-sample issue and the noise issue. To address the\nabove issues, in this paper, we propose an effective and efficient UMGL method\nto explore both complementary and consistent information. To do this, our\nmethod employs multiple MLP encoders rather than graph convolutional network\n(GCN) to conduct representation learning with two constraints, i.e., preserving\nthe local graph structure among nodes to handle the out-of-sample issue, and\nmaximizing the correlation of multiple node representations to handle the noise\nissue. Comprehensive experiments demonstrate that our proposed method achieves\nsuperior effectiveness and efficiency over the comparison methods and\neffectively tackles those two issues. Code is available at\nhttps://github.com/LarryUESTC/CoCoMG.",
          "link": "http://arxiv.org/abs/2308.01606",
          "publishedOn": "2023-08-05T00:48:27.404Z",
          "wordCount": 664,
          "title": "Unsupervised Multiplex Graph Learning with Complementary and Consistent Information. (arXiv:2308.01606v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01390",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Awadalla_A/0/1/0/all/0/1\">Anas Awadalla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_I/0/1/0/all/0/1\">Irena Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gardner_J/0/1/0/all/0/1\">Josh Gardner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hessel_J/0/1/0/all/0/1\">Jack Hessel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanafy_Y/0/1/0/all/0/1\">Yusuf Hanafy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wanrong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marathe_K/0/1/0/all/0/1\">Kalyani Marathe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bitton_Y/0/1/0/all/0/1\">Yonatan Bitton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gadre_S/0/1/0/all/0/1\">Samir Gadre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagawa_S/0/1/0/all/0/1\">Shiori Sagawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jitsev_J/0/1/0/all/0/1\">Jenia Jitsev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kornblith_S/0/1/0/all/0/1\">Simon Kornblith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koh_P/0/1/0/all/0/1\">Pang Wei Koh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilharco_G/0/1/0/all/0/1\">Gabriel Ilharco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wortsman_M/0/1/0/all/0/1\">Mitchell Wortsman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1\">Ludwig Schmidt</a>",
          "description": "We introduce OpenFlamingo, a family of autoregressive vision-language models\nranging from 3B to 9B parameters. OpenFlamingo is an ongoing effort to produce\nan open-source replication of DeepMind's Flamingo models. On seven\nvision-language datasets, OpenFlamingo models average between 80 - 89% of\ncorresponding Flamingo performance. This technical report describes our models,\ntraining data, hyperparameters, and evaluation suite. We share our models and\ncode at https://github.com/mlfoundations/open_flamingo.",
          "link": "http://arxiv.org/abs/2308.01390",
          "publishedOn": "2023-08-05T00:48:27.396Z",
          "wordCount": 690,
          "title": "OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models. (arXiv:2308.01390v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2208.07898",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kawamata_Y/0/1/0/all/0/1\">Yuji Kawamata</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Motai_R/0/1/0/all/0/1\">Ryoki Motai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Okada_Y/0/1/0/all/0/1\">Yukihiko Okada</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Imakura_A/0/1/0/all/0/1\">Akira Imakura</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sakurai_T/0/1/0/all/0/1\">Tetsuya Sakurai</a>",
          "description": "The development of technologies for causal inference with the privacy\npreservation of distributed data has attracted considerable attention in recent\nyears. To address this issue, we propose a data collaboration quasi-experiment\n(DC-QE) that enables causal inference from distributed data with privacy\npreservation. In our method, first, local parties construct\ndimensionality-reduced intermediate representations from the private data.\nSecond, they share intermediate representations, instead of private data for\nprivacy preservation. Third, propensity scores were estimated from the shared\nintermediate representations. Finally, the treatment effects were estimated\nfrom propensity scores. Our method can reduce both random errors and biases,\nwhereas existing methods can only reduce random errors in the estimation of\ntreatment effects. Through numerical experiments on both artificial and\nreal-world data, we confirmed that our method can lead to better estimation\nresults than individual analyses. Dimensionality-reduction loses some of the\ninformation in the private data and causes performance degradation. However, we\nobserved that in the experiments, sharing intermediate representations with\nmany parties to resolve the lack of subjects and covariates, our method\nimproved performance enough to overcome the degradation caused by\ndimensionality-reduction. With the spread of our method, intermediate\nrepresentations can be published as open data to help researchers find\ncausalities and accumulated as a knowledge base.",
          "link": "http://arxiv.org/abs/2208.07898",
          "publishedOn": "2023-08-05T00:48:27.389Z",
          "wordCount": 718,
          "title": "Collaborative causal inference on distributed data. (arXiv:2208.07898v2 [stat.ME] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2111.12146",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Upadhyay_R/0/1/0/all/0/1\">Richa Upadhyay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phlypo_R/0/1/0/all/0/1\">Ronald Phlypo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saini_R/0/1/0/all/0/1\">Rajkumar Saini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liwicki_M/0/1/0/all/0/1\">Marcus Liwicki</a>",
          "description": "Integrating knowledge across different domains is an essential feature of\nhuman learning. Learning paradigms such as transfer learning, meta learning,\nand multi-task learning reflect the human learning process by exploiting the\nprior knowledge for new tasks, encouraging faster learning and good\ngeneralization for new tasks. This article gives a detailed view of these\nlearning paradigms and their comparative analysis. The weakness of one learning\nalgorithm turns out to be a strength of another, and thus merging them is a\nprevalent trait in the literature. There are numerous research papers that\nfocus on each of these learning paradigms separately and provide a\ncomprehensive overview of them. However, this article provides a review of\nresearch studies that combine (two of) these learning algorithms. This survey\ndescribes how these techniques are combined to solve problems in many different\nfields of study, including computer vision, natural language processing,\nhyperspectral imaging, and many more, in supervised setting only. As a result,\nthe global generic learning network an amalgamation of meta learning, transfer\nlearning, and multi-task learning is introduced here, along with some open\nresearch questions and future research directions in the multi-task setting.",
          "link": "http://arxiv.org/abs/2111.12146",
          "publishedOn": "2023-08-05T00:48:27.382Z",
          "wordCount": 803,
          "title": "Sharing to learn and learning to share -- Fitting together Meta-Learning, Multi-Task Learning, and Transfer Learning: A meta review. (arXiv:2111.12146v6 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.06267",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhiqiu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Samuel Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuang_Z/0/1/0/all/0/1\">Zhiyi Kuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1\">Deepak Pathak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanan_D/0/1/0/all/0/1\">Deva Ramanan</a>",
          "description": "The ability to quickly learn a new task with minimal instruction - known as\nfew-shot learning - is a central aspect of intelligent agents. Classical\nfew-shot benchmarks make use of few-shot samples from a single modality, but\nsuch samples may not be sufficient to characterize an entire concept class. In\ncontrast, humans use cross-modal information to learn new concepts efficiently.\nIn this work, we demonstrate that one can indeed build a better ${\\bf visual}$\ndog classifier by ${\\bf read}$ing about dogs and ${\\bf listen}$ing to them\nbark. To do so, we exploit the fact that recent multimodal foundation models\nsuch as CLIP are inherently cross-modal, mapping different modalities to the\nsame representation space. Specifically, we propose a simple cross-modal\nadaptation approach that learns from few-shot examples spanning different\nmodalities. By repurposing class names as additional one-shot training samples,\nwe achieve SOTA results with an embarrassingly simple linear classifier for\nvision-language adaptation. Furthermore, we show that our approach can benefit\nexisting methods such as prefix tuning, adapters, and classifier ensembling.\nFinally, to explore other modalities beyond vision and language, we construct\nthe first (to our knowledge) audiovisual few-shot benchmark and use cross-modal\ntraining to improve the performance of both image and audio classification.",
          "link": "http://arxiv.org/abs/2301.06267",
          "publishedOn": "2023-08-05T00:48:27.361Z",
          "wordCount": 770,
          "title": "Multimodality Helps Unimodality: Cross-Modal Few-Shot Learning with Multimodal Models. (arXiv:2301.06267v4 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.16149",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1\">Xun Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alromih_A/0/1/0/all/0/1\">Arwa Alromih</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gope_P/0/1/0/all/0/1\">Prosanta Gope</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sikdar_B/0/1/0/all/0/1\">Biplab Sikdar</a>",
          "description": "Energy theft detection (ETD) and energy consumption forecasting (ECF) are two\ninterconnected challenges in smart grid systems. Addressing these issues\ncollectively is crucial for ensuring system security. This paper addresses the\ninterconnected challenges of ETD and ECF in smart grid systems. The proposed\nsolution combines long short-term memory (LSTM) and a denoising diffusion\nprobabilistic model (DDPM) to generate input reconstruction and forecasting. By\nleveraging the reconstruction and forecasting errors, the system identifies\ninstances of energy theft, with the methods based on reconstruction error and\nforecasting error complementing each other in detecting different types of\nattacks. Through extensive experiments on real-world and synthetic datasets,\nthe proposed scheme outperforms baseline methods in ETD and ECF problems. The\nensemble method significantly enhances ETD performance, accurately detecting\nenergy theft attacks that baseline methods fail to detect. The research offers\na comprehensive and effective solution for addressing ETD and ECF challenges,\ndemonstrating promising results and improved security in smart grid systems.",
          "link": "http://arxiv.org/abs/2307.16149",
          "publishedOn": "2023-08-05T00:48:27.355Z",
          "wordCount": 723,
          "title": "An Effective LSTM-DDPM Scheme for Energy Theft Detection and Forecasting in Smart Grid. (arXiv:2307.16149v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01759",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nachkov_A/0/1/0/all/0/1\">Asen Nachkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Luchen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luise_G/0/1/0/all/0/1\">Giulia Luise</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valdettaro_F/0/1/0/all/0/1\">Filippo Valdettaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faisal_A/0/1/0/all/0/1\">Aldo Faisal</a>",
          "description": "Efficient exploration in complex environments remains a major challenge for\nreinforcement learning (RL). Compared to previous Thompson sampling-inspired\nmechanisms that enable temporally extended exploration, i.e., deep exploration,\nwe focus on deep exploration in distributional RL. We develop here a general\npurpose approach, Bag of Policies (BoP), that can be built on top of any return\ndistribution estimator by maintaining a population of its copies. BoP consists\nof an ensemble of multiple heads that are updated independently. During\ntraining, each episode is controlled by only one of the heads and the collected\nstate-action pairs are used to update all heads off-policy, leading to distinct\nlearning signals for each head which diversify learning and behaviour. To test\nwhether optimistic ensemble method can improve on distributional RL as did on\nscalar RL, by e.g. Bootstrapped DQN, we implement the BoP approach with a\npopulation of distributional actor-critics using Bayesian Distributional Policy\nGradients (BDPG). The population thus approximates a posterior distribution of\nreturn distributions along with a posterior distribution of policies. Another\nbenefit of building upon BDPG is that it allows to analyze global posterior\nuncertainty along with local curiosity bonus simultaneously for exploration. As\nBDPG is already an optimistic method, this pairing helps to investigate if\noptimism is accumulatable in distributional RL. Overall BoP results in greater\nrobustness and speed during learning as demonstrated by our experimental\nresults on ALE Atari games.",
          "link": "http://arxiv.org/abs/2308.01759",
          "publishedOn": "2023-08-05T00:48:27.298Z",
          "wordCount": 744,
          "title": "Bag of Policies for Distributional Deep Exploration. (arXiv:2308.01759v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01578",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meng_Q/0/1/0/all/0/1\">Qianwen Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_H/0/1/0/all/0/1\">Hangwei Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yonghui Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zhiqi Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Lizhen Cui</a>",
          "description": "Unsupervised representation learning approaches aim to learn discriminative\nfeature representations from unlabeled data, without the requirement of\nannotating every sample. Enabling unsupervised representation learning is\nextremely crucial for time series data, due to its unique annotation bottleneck\ncaused by its complex characteristics and lack of visual cues compared with\nother data modalities. In recent years, unsupervised representation learning\ntechniques have advanced rapidly in various domains. However, there is a lack\nof systematic analysis of unsupervised representation learning approaches for\ntime series. To fill the gap, we conduct a comprehensive literature review of\nexisting rapidly evolving unsupervised representation learning approaches for\ntime series. Moreover, we also develop a unified and standardized library,\nnamed ULTS (i.e., Unsupervised Learning for Time Series), to facilitate fast\nimplementations and unified evaluations on various models. With ULTS, we\nempirically evaluate state-of-the-art approaches, especially the rapidly\nevolving contrastive learning methods, on 9 diverse real-world datasets. We\nfurther discuss practical considerations as well as open research challenges on\nunsupervised representation learning for time series to facilitate future\nresearch in this field.",
          "link": "http://arxiv.org/abs/2308.01578",
          "publishedOn": "2023-08-05T00:48:26.926Z",
          "wordCount": null,
          "title": "Unsupervised Representation Learning for Time Series: A Review. (arXiv:2308.01578v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.08757",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Tomasetti_L/0/1/0/all/0/1\">Luca Tomasetti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Engan_K/0/1/0/all/0/1\">Kjersti Engan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hollesli_L/0/1/0/all/0/1\">Liv Jorunn H&#xf8;llesli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kurz_K/0/1/0/all/0/1\">Kathinka D&#xe6;hli Kurz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Khanmohammadi_M/0/1/0/all/0/1\">Mahdieh Khanmohammadi</a>",
          "description": "Precise and fast prediction methods for ischemic areas comprised of dead\ntissue, core, and salvageable tissue, penumbra, in acute ischemic stroke (AIS)\npatients are of significant clinical interest. They play an essential role in\nimproving diagnosis and treatment planning. Computed Tomography (CT) scan is\none of the primary modalities for early assessment in patients with suspected\nAIS. CT Perfusion (CTP) is often used as a primary assessment to determine\nstroke location, severity, and volume of ischemic lesions. Current automatic\nsegmentation methods for CTP mostly use already processed 3D parametric maps\nconventionally used for clinical interpretation by radiologists as input.\nAlternatively, the raw CTP data is used on a slice-by-slice basis as 2D+time\ninput, where the spatial information over the volume is ignored. In addition,\nthese methods are only interested in segmenting core regions, while predicting\npenumbra can be essential for treatment planning. This paper investigates\ndifferent methods to utilize the entire 4D CTP as input to fully exploit the\nspatio-temporal information, leading us to propose a novel 4D convolution\nlayer. Our comprehensive experiments on a local dataset of 152 patients divided\ninto three groups show that our proposed models generate more precise results\nthan other methods explored. Adopting the proposed 4D mJ-Net, a Dice\nCoefficient of 0.53 and 0.23 is achieved for segmenting penumbra and core\nareas, respectively. The code is available on\nhttps://github.com/Biomedical-Data-Analysis-Laboratory/4D-mJ-Net.git.",
          "link": "http://arxiv.org/abs/2303.08757",
          "publishedOn": "2023-08-05T00:48:26.926Z",
          "wordCount": null,
          "title": "CT Perfusion is All We Need: 4D CNN Segmentation of Penumbra and Core in Patient With Suspected Ischemic Stroke. (arXiv:2303.08757v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.08875",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sluijterman_L/0/1/0/all/0/1\">Laurens Sluijterman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cator_E/0/1/0/all/0/1\">Eric Cator</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Heskes_T/0/1/0/all/0/1\">Tom Heskes</a>",
          "description": "This paper focusses on the optimal implementation of a Mean Variance\nEstimation network (MVE network) (Nix and Weigend, 1994). This type of network\nis often used as a building block for uncertainty estimation methods in a\nregression setting, for instance Concrete dropout (Gal et al., 2017) and Deep\nEnsembles (Lakshminarayanan et al., 2017). Specifically, an MVE network assumes\nthat the data is produced from a normal distribution with a mean function and\nvariance function. The MVE network outputs a mean and variance estimate and\noptimizes the network parameters by minimizing the negative loglikelihood. In\nour paper, we present two significant insights. Firstly, the convergence\ndifficulties reported in recent work can be relatively easily prevented by\nfollowing the simple yet often overlooked recommendation from the original\nauthors that a warm-up period should be used. During this period, only the mean\nis optimized with a fixed variance. We demonstrate the effectiveness of this\nstep through experimentation, highlighting that it should be standard practice.\nAs a sidenote, we examine whether, after the warm-up, it is beneficial to fix\nthe mean while optimizing the variance or to optimize both simultaneously.\nHere, we do not observe a substantial difference. Secondly, we introduce a\nnovel improvement of the MVE network: separate regularization of the mean and\nthe variance estimate. We demonstrate, both on toy examples and on a number of\nbenchmark UCI regression data sets, that following the original recommendations\nand the novel separate regularization can lead to significant improvements.",
          "link": "http://arxiv.org/abs/2302.08875",
          "publishedOn": "2023-08-05T00:48:26.917Z",
          "wordCount": null,
          "title": "Optimal Training of Mean Variance Estimation Neural Networks. (arXiv:2302.08875v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01472",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Croitoru_F/0/1/0/all/0/1\">Florinel-Alin Croitoru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hondru_V/0/1/0/all/0/1\">Vlad Hondru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ionescu_R/0/1/0/all/0/1\">Radu Tudor Ionescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Mubarak Shah</a>",
          "description": "Text-to-image diffusion models such as Stable Diffusion have recently\nattracted the interest of many researchers, and inverting the diffusion process\ncan play an important role in better understanding the generative process and\nhow to engineer prompts in order to obtain the desired images. To this end, we\nintroduce the new task of predicting the text prompt given an image generated\nby a generative diffusion model. We combine a series of white-box and black-box\nmodels (with and without access to the weights of the diffusion network) to\ndeal with the proposed task. We propose a novel learning framework comprising\nof a joint prompt regression and multi-label vocabulary classification\nobjective that generates improved prompts. To further improve our method, we\nemploy a curriculum learning procedure that promotes the learning of\nimage-prompt pairs with lower labeling noise (i.e. that are better aligned),\nand an unsupervised domain-adaptive kernel learning method that uses the\nsimilarities between samples in the source and target domains as extra\nfeatures. We conduct experiments on the DiffusionDB data set, predicting text\nprompts from images generated by Stable Diffusion. Our novel learning framework\nproduces excellent results on the aforementioned task, yielding the highest\ngains when applied on the white-box model. In addition, we make an interesting\ndiscovery: training a diffusion model on the prompt generation task can make\nthe model generate images that are much better aligned with the input prompts,\nwhen the model is directly reused for text-to-image generation.",
          "link": "http://arxiv.org/abs/2308.01472",
          "publishedOn": "2023-08-05T00:48:26.916Z",
          "wordCount": null,
          "title": "Reverse Stable Diffusion: What prompt was used to generate this image?. (arXiv:2308.01472v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.13831",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsukada_Y/0/1/0/all/0/1\">Yuki Tsukada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iiduka_H/0/1/0/all/0/1\">Hideaki Iiduka</a>",
          "description": "Stochastic gradient descent (SGD) is the simplest deep learning optimizer\nwith which to train deep neural networks. While SGD can use various learning\nrates, such as constant or diminishing rates, the previous numerical results\nshowed that SGD performs better than other deep learning optimizers using when\nit uses learning rates given by line search methods. In this paper, we perform\na convergence analysis on SGD with a learning rate given by an Armijo line\nsearch for nonconvex optimization. The analysis indicates that the upper bound\nof the expectation of the squared norm of the full gradient becomes small when\nthe number of steps and the batch size are large. Next, we show that, for SGD\nwith the Armijo-line-search learning rate, the number of steps needed for\nnonconvex optimization is a monotone decreasing convex function of the batch\nsize; that is, the number of steps needed for nonconvex optimization decreases\nas the batch size increases. Furthermore, we show that the stochastic\nfirst-order oracle (SFO) complexity, which is the stochastic gradient\ncomputation cost, is a convex function of the batch size; that is, there exists\na critical batch size that minimizes the SFO complexity. Finally, we provide\nnumerical results that support our theoretical results. The numerical results\nindicate that the number of steps needed for training deep neural networks\ndecreases as the batch size increases and that there exist the critical batch\nsizes that can be estimated from the theoretical results.",
          "link": "http://arxiv.org/abs/2307.13831",
          "publishedOn": "2023-08-05T00:48:26.914Z",
          "wordCount": null,
          "title": "Relationship between Batch Size and Number of Steps Needed for Nonconvex Optimization of Stochastic Gradient Descent using Armijo Line Search. (arXiv:2307.13831v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.12344",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xi He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahman_W/0/1/0/all/0/1\">Waheed Ul Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Little_M/0/1/0/all/0/1\">Max A. Little</a>",
          "description": "Algorithms for solving the linear classification problem have a long history,\ndating back at least to 1936 with linear discriminant analysis. For linearly\nseparable data, many algorithms can obtain the exact solution to the\ncorresponding 0-1 loss classification problem efficiently, but for data which\nis not linearly separable, it has been shown that this problem, in full\ngenerality, is NP-hard. Alternative approaches all involve approximations of\nsome kind, including the use of surrogates for the 0-1 loss (for example, the\nhinge or logistic loss) or approximate combinatorial search, none of which can\nbe guaranteed to solve the problem exactly. Finding efficient algorithms to\nobtain an exact i.e. globally optimal solution for the 0-1 loss linear\nclassification problem with fixed dimension, remains an open problem. In\nresearch we report here, we detail the rigorous construction of a new\nalgorithm, incremental cell enumeration (ICE), that can solve the 0-1 loss\nclassification problem exactly in polynomial time. We prove correctness using\nconcepts from the theory of hyperplane arrangements and oriented matroids. We\ndemonstrate the effectiveness of this algorithm on synthetic and real-world\ndatasets, showing optimal accuracy both in and out-of-sample, in practical\ncomputational time. We also empirically demonstrate how the use of approximate\nupper bound leads to polynomial time run-time improvements to the algorithm\nwhilst retaining exactness. To our knowledge, this is the first,\nrigorously-proven polynomial time, practical algorithm for this long-standing\nproblem.",
          "link": "http://arxiv.org/abs/2306.12344",
          "publishedOn": "2023-08-05T00:48:26.848Z",
          "wordCount": null,
          "title": "An efficient, provably exact, practical algorithm for the 0-1 loss linear classification problem. (arXiv:2306.12344v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2012.14563",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hiabu_M/0/1/0/all/0/1\">Munir Hiabu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mammen_E/0/1/0/all/0/1\">Enno Mammen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Meyer_J/0/1/0/all/0/1\">Joseph T. Meyer</a>",
          "description": "We introduce a novel interpretable tree based algorithm for prediction in a\nregression setting. Our motivation is to estimate the unknown regression\nfunction from a functional decomposition perspective in which the functional\ncomponents correspond to lower order interaction terms. The idea is to modify\nthe random forest algorithm by keeping certain leaves after they are split\ninstead of deleting them. This leads to non-binary trees which we refer to as\nplanted trees. An extension to a forest leads to our random planted forest\nalgorithm. Additionally, the maximum number of covariates which can interact\nwithin a leaf can be bounded. If we set this interaction bound to one, the\nresulting estimator is a sum of one-dimensional functions. In the other extreme\ncase, if we do not set a limit, the resulting estimator and corresponding model\nplace no restrictions on the form of the regression function. In a simulation\nstudy we find encouraging prediction and visualisation properties of our random\nplanted forest method. We also develop theory for an idealized version of\nrandom planted forests in cases where the interaction bound is low. We show\nthat if it is smaller than three, the idealized version achieves asymptotically\noptimal convergence rates up to a logarithmic factor. Code is available on\nGitHub https://github.com/PlantedML/randomPlantedForest.",
          "link": "http://arxiv.org/abs/2012.14563",
          "publishedOn": "2023-08-05T00:48:26.842Z",
          "wordCount": null,
          "title": "Random Planted Forest: a directly interpretable tree ensemble. (arXiv:2012.14563v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.13866",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Pengcheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1\">Jinpu Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yulin Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rong_Z/0/1/0/all/0/1\">Ziqi Rong</a>",
          "description": "DNA methylation is a crucial regulator of gene transcription and has been\nlinked to various diseases, including autoimmune diseases and cancers. However,\ndiagnostics based on DNA methylation face challenges due to large feature sets\nand small sample sizes, resulting in overfitting and suboptimal performance. To\naddress these issues, we propose MIRACLE, a novel interpretable neural network\nthat leverages autoencoder-based multi-task learning to integrate multiple\ndatasets and jointly identify common patterns in DNA methylation.\n\nMIRACLE's architecture reflects the relationships between methylation sites,\ngenes, and pathways, ensuring biological interpretability and meaningfulness.\nThe network comprises an encoder and a decoder, with a bottleneck layer\nrepresenting pathway information as the basic unit of heredity. Customized\ndefined MaskedLinear Layer is constrained by site-gene-pathway graph adjacency\nmatrix information, which provides explainability and expresses the\nsite-gene-pathway hierarchical structure explicitly. And from the embedding,\nthere are different multi-task classifiers to predict diseases.\n\nTested on six datasets, including rheumatoid arthritis, systemic lupus\nerythematosus, multiple sclerosis, inflammatory bowel disease, psoriasis, and\ntype 1 diabetes, MIRACLE demonstrates robust performance in identifying common\nfunctions of DNA methylation across different phenotypes, with higher accuracy\nin prediction dieseases than baseline methods. By incorporating biological\nprior knowledge, MIRACLE offers a meaningful and interpretable framework for\nDNA methylation data analysis in the context of autoimmune diseases.",
          "link": "http://arxiv.org/abs/2306.13866",
          "publishedOn": "2023-08-05T00:48:26.838Z",
          "wordCount": null,
          "title": "MIRACLE: Multi-task Learning based Interpretable Regulation of Autoimmune Diseases through Common Latent Epigenetics. (arXiv:2306.13866v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.13773",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pasteris_S/0/1/0/all/0/1\">Stephen Pasteris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hicks_C/0/1/0/all/0/1\">Chris Hicks</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mavroudis_V/0/1/0/all/0/1\">Vasilios Mavroudis</a>",
          "description": "In this paper we adapt the nearest neighbour rule to the contextual bandit\nproblem. Our algorithm handles the fully adversarial setting in which no\nassumptions at all are made about the data-generation process. When combined\nwith a sufficiently fast data-structure for (perhaps approximate) adaptive\nnearest neighbour search, such as a navigating net, our algorithm is extremely\nefficient - having a per trial running time polylogarithmic in both the number\nof trials and actions, and taking only quasi-linear space.",
          "link": "http://arxiv.org/abs/2306.13773",
          "publishedOn": "2023-08-05T00:48:26.837Z",
          "wordCount": null,
          "title": "Nearest Neighbour with Bandit Feedback. (arXiv:2306.13773v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_R/0/1/0/all/0/1\">Ruyi Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_S/0/1/0/all/0/1\">Shijin Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaolin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Y/0/1/0/all/0/1\">Yunsi Fei</a>",
          "description": "Graph neural networks (GNNs) have brought superb performance to various\napplications utilizing graph structural data, such as social analysis and fraud\ndetection. The graph links, e.g., social relationships and transaction history,\nare sensitive and valuable information, which raises privacy concerns when\nusing GNNs. To exploit these vulnerabilities, we propose VertexSerum, a novel\ngraph poisoning attack that increases the effectiveness of graph link stealing\nby amplifying the link connectivity leakage. To infer node adjacency more\naccurately, we propose an attention mechanism that can be embedded into the\nlink detection network. Our experiments demonstrate that VertexSerum\nsignificantly outperforms the SOTA link inference attack, improving the AUC\nscores by an average of $9.8\\%$ across four real-world datasets and three\ndifferent GNN structures. Furthermore, our experiments reveal the effectiveness\nof VertexSerum in both black-box and online learning settings, further\nvalidating its applicability in real-world scenarios.",
          "link": "http://arxiv.org/abs/2308.01469",
          "publishedOn": "2023-08-05T00:48:26.831Z",
          "wordCount": null,
          "title": "VertexSerum: Poisoning Graph Neural Networks for Link Inference. (arXiv:2308.01469v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01323",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Hu_J/0/1/0/all/0/1\">Jianchang Hu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Szymczak_S/0/1/0/all/0/1\">Silke Szymczak</a>",
          "description": "Gene network information is believed to be beneficial for disease module and\npathway identification, but has not been explicitly utilized in the standard\nrandom forest (RF) algorithm for gene expression data analysis. We investigate\nthe performance of a network-guided RF where the network information is\nsummarized into a sampling probability of predictor variables which is further\nused in the construction of the RF. Our results suggest that network-guided RF\ndoes not provide better disease prediction than the standard RF. In terms of\ndisease gene discovery, if disease genes form module(s), network-guided RF\nidentifies them more accurately. In addition, when disease status is\nindependent from genes in the given network, spurious gene selection results\ncan occur when using network information, especially on hub genes. Our\nempirical analysis on two balanced microarray and RNA-Seq breast cancer\ndatasets from The Cancer Genome Atlas (TCGA) for classification of progesterone\nreceptor (PR) status also demonstrates that network-guided RF can identify\ngenes from PGR-related pathways, which leads to a better connected module of\nidentified genes.",
          "link": "http://arxiv.org/abs/2308.01323",
          "publishedOn": "2023-08-05T00:48:26.827Z",
          "wordCount": null,
          "title": "Evaluation of network-guided random forest for disease gene discovery. (arXiv:2308.01323v1 [q-bio.MN])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yibo Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Haobo Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiangtai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jianlong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lefei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouchen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip Torr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1\">Bernard Ghanem</a>",
          "description": "How to enable learnability for new classes while keeping the capability well\non old classes has been a crucial challenge for class incremental learning.\nBeyond the normal case, long-tail class incremental learning and few-shot class\nincremental learning are also proposed to consider the data imbalance and data\nscarcity, respectively, which are common in real-world implementations and\nfurther exacerbate the well-known problem of catastrophic forgetting. Existing\nmethods are specifically proposed for one of the three tasks. In this paper, we\noffer a unified solution to the misalignment dilemma in the three tasks.\nConcretely, we propose neural collapse terminus that is a fixed structure with\nthe maximal equiangular inter-class separation for the whole label space. It\nserves as a consistent target throughout the incremental training to avoid\ndividing the feature space incrementally. For CIL and LTCIL, we further propose\na prototype evolving scheme to drive the backbone features into our neural\ncollapse terminus smoothly. Our method also works for FSCIL with only minor\nadaptations. Theoretical analysis indicates that our method holds the neural\ncollapse optimality in an incremental fashion regardless of data imbalance or\ndata scarcity. We also design a generalized case where we do not know the total\nnumber of classes and whether the data distribution is normal, long-tail, or\nfew-shot for each coming session, to test the generalizability of our method.\nExtensive experiments with multiple datasets are conducted to demonstrate the\neffectiveness of our unified solution to all the three tasks and the\ngeneralized case.",
          "link": "http://arxiv.org/abs/2308.01746",
          "publishedOn": "2023-08-05T00:48:26.823Z",
          "wordCount": null,
          "title": "Neural Collapse Terminus: A Unified Solution for Class Incremental Learning and Its Variants. (arXiv:2308.01746v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01744",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sessa_P/0/1/0/all/0/1\">Pier Giuseppe Sessa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laforgue_P/0/1/0/all/0/1\">Pierre Laforgue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cesa_Bianchi_N/0/1/0/all/0/1\">Nicol&#xf2; Cesa-Bianchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1\">Andreas Krause</a>",
          "description": "Multitask learning is a powerful framework that enables one to simultaneously\nlearn multiple related tasks by sharing information between them. Quantifying\nuncertainty in the estimated tasks is of pivotal importance for many downstream\napplications, such as online or active learning. In this work, we provide novel\nmultitask confidence intervals in the challenging agnostic setting, i.e., when\nneither the similarity between tasks nor the tasks' features are available to\nthe learner. The obtained intervals do not require i.i.d. data and can be\ndirectly applied to bound the regret in online learning. Through a refined\nanalysis of the multitask information gain, we obtain new regret guarantees\nthat, depending on a task similarity parameter, can significantly improve over\ntreating tasks independently. We further propose a novel online learning\nalgorithm that achieves such improved regret without knowing this parameter in\nadvance, i.e., automatically adapting to task similarity. As a second key\napplication of our results, we introduce a novel multitask active learning\nsetup where several tasks must be simultaneously optimized, but only one of\nthem can be queried for feedback by the learner at each round. For this\nproblem, we design a no-regret algorithm that uses our confidence intervals to\ndecide which task should be queried. Finally, we empirically validate our\nbounds and algorithms on synthetic and real-world (drug discovery) data.",
          "link": "http://arxiv.org/abs/2308.01744",
          "publishedOn": "2023-08-05T00:48:26.822Z",
          "wordCount": null,
          "title": "Multitask Learning with No Regret: from Improved Confidence Bounds to Active Learning. (arXiv:2308.01744v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01737",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jianghao Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1\">Yanru Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1\">Wei Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1\">Xinyi Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1\">Ruiming Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weinan Zhang</a>",
          "description": "With the widespread application of personalized online services,\nclick-through rate (CTR) prediction has received more and more attention and\nresearch. The most prominent features of CTR prediction are its multi-field\ncategorical data format, and vast and daily-growing data volume. The large\ncapacity of neural models helps digest such massive amounts of data under the\nsupervised learning paradigm, yet they fail to utilize the substantial data to\nits full potential, since the 1-bit click signal is not sufficient to guide the\nmodel to learn capable representations of features and instances. The\nself-supervised learning paradigm provides a more promising pretrain-finetune\nsolution to better exploit the large amount of user click logs, and learn more\ngeneralized and effective representations. However, self-supervised learning\nfor CTR prediction is still an open question, since current works on this line\nare only preliminary and rudimentary. To this end, we propose a Model-agnostic\npretraining (MAP) framework that applies feature corruption and recovery on\nmulti-field categorical data, and more specifically, we derive two practical\nalgorithms: masked feature prediction (MFP) and replaced feature detection\n(RFD). MFP digs into feature interactions within each instance through masking\nand predicting a small portion of input features, and introduces noise\ncontrastive estimation (NCE) to handle large feature spaces. RFD further turns\nMFP into a binary classification mode through replacing and detecting changes\nin input features, making it even simpler and more effective for CTR\npretraining. Our extensive experiments on two real-world large-scale datasets\n(i.e., Avazu, Criteo) demonstrate the advantages of these two methods on\nseveral strong backbones (e.g., DCNv2, DeepFM), and achieve new\nstate-of-the-art performance in terms of both effectiveness and efficiency for\nCTR prediction.",
          "link": "http://arxiv.org/abs/2308.01737",
          "publishedOn": "2023-08-05T00:48:26.814Z",
          "wordCount": null,
          "title": "MAP: A Model-agnostic Pretraining Framework for Click-through Rate Prediction. (arXiv:2308.01737v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.11363",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1\">Jiachen Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1\">Peng Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ba_Z/0/1/0/all/0/1\">Zhongjie Ba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_K/0/1/0/all/0/1\">Kui Ren</a>",
          "description": "Diffusion models have emerged as the \\emph{de-facto} technique for image\ngeneration, yet they entail significant computational overhead, hindering the\ntechnique's broader application in the research community. We propose a\nprior-based denoising training framework, the first to incorporate the\npre-train and fine-tune paradigm into the diffusion model training process,\nwhich substantially improves training efficiency and shows potential in\nfacilitating various downstream tasks. Our approach centers on masking a high\nproportion (e.g., up to 90\\%) of the input image and employing masked denoising\nscore matching to denoise the visible areas, thereby guiding the diffusion\nmodel to learn more salient features from training data as prior knowledge. By\nutilizing masked learning in a pre-training stage, we efficiently train the\nViT-based diffusion model on CelebA-HQ $256 \\times 256$ in the pixel space,\nachieving a 4x acceleration and enhancing the quality of generated images\ncompared to denoising diffusion probabilistic model (DDPM). Moreover, our\nmasked pre-training technique can be universally applied to various diffusion\nmodels that directly generate images in the pixel space, aiding in the learning\nof pre-trained models with superior generalizability. For instance, a diffusion\nmodel pre-trained on VGGFace2 attains a 46\\% quality improvement through\nfine-tuning with merely 10\\% data from a different distribution. Moreover, our\nmethod shows the potential to serve as a training paradigm for enhancing the\nprivacy protection capabilities of diffusion models. Our code is available at\n\\url{https://github.com/jiachenlei/maskdm}.",
          "link": "http://arxiv.org/abs/2306.11363",
          "publishedOn": "2023-08-05T00:48:26.813Z",
          "wordCount": null,
          "title": "Masked Diffusion Models Are Fast and Privacy-Aware Learners. (arXiv:2306.11363v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01419",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Pu_X/0/1/0/all/0/1\">Xingyue Pu</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Cucuringu_M/0/1/0/all/0/1\">Mihai Cucuringu</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Dong_X/0/1/0/all/0/1\">Xiaowen Dong</a>",
          "description": "We present a novel methodology for modeling and forecasting multivariate\nrealized volatilities using customized graph neural networks to incorporate\nspillover effects across stocks. The proposed model offers the benefits of\nincorporating spillover effects from multi-hop neighbors, capturing nonlinear\nrelationships, and flexible training with different loss functions. Our\nempirical findings provide compelling evidence that incorporating spillover\neffects from multi-hop neighbors alone does not yield a clear advantage in\nterms of predictive accuracy. However, modeling nonlinear spillover effects\nenhances the forecasting accuracy of realized volatilities, particularly for\nshort-term horizons of up to one week. Moreover, our results consistently\nindicate that training with the Quasi-likelihood loss leads to substantial\nimprovements in model performance compared to the commonly-used mean squared\nerror. A comprehensive series of empirical evaluations in alternative settings\nconfirm the robustness of our results.",
          "link": "http://arxiv.org/abs/2308.01419",
          "publishedOn": "2023-08-05T00:48:26.803Z",
          "wordCount": null,
          "title": "Graph Neural Networks for Forecasting Multivariate Realized Volatility with Spillover Effects. (arXiv:2308.01419v1 [q-fin.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.08736",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Zhou_M/0/1/0/all/0/1\">Mo Zhou</a>, <a href=\"http://arxiv.org/find/math/1/au:+Han_J/0/1/0/all/0/1\">Jiequn Han</a>, <a href=\"http://arxiv.org/find/math/1/au:+Rachh_M/0/1/0/all/0/1\">Manas Rachh</a>, <a href=\"http://arxiv.org/find/math/1/au:+Borges_C/0/1/0/all/0/1\">Carlos Borges</a>",
          "description": "We consider the inverse acoustic obstacle problem for sound-soft star-shaped\nobstacles in two dimensions wherein the boundary of the obstacle is determined\nfrom measurements of the scattered field at a collection of receivers outside\nthe object. One of the standard approaches for solving this problem is to\nreformulate it as an optimization problem: finding the boundary of the domain\nthat minimizes the $L^2$ distance between computed values of the scattered\nfield and the given measurement data. The optimization problem is\ncomputationally challenging since the local set of convexity shrinks with\nincreasing frequency and results in an increasing number of local minima in the\nvicinity of the true solution. In many practical experimental settings, low\nfrequency measurements are unavailable due to limitations of the experimental\nsetup or the sensors used for measurement. Thus, obtaining a good initial guess\nfor the optimization problem plays a vital role in this environment.\n\nWe present a neural network warm-start approach for solving the inverse\nscattering problem, where an initial guess for the optimization problem is\nobtained using a trained neural network. We demonstrate the effectiveness of\nour method with several numerical examples. For high frequency problems, this\napproach outperforms traditional iterative methods such as Gauss-Newton\ninitialized without any prior (i.e., initialized using a unit circle), or\ninitialized using the solution of a direct method such as the linear sampling\nmethod. The algorithm remains robust to noise in the scattered field\nmeasurements and also converges to the true solution for limited aperture data.\nHowever, the number of training samples required to train the neural network\nscales exponentially in frequency and the complexity of the obstacles\nconsidered. We conclude with a discussion of this phenomenon and potential\ndirections for future research.",
          "link": "http://arxiv.org/abs/2212.08736",
          "publishedOn": "2023-08-05T00:48:26.803Z",
          "wordCount": null,
          "title": "A Neural Network Warm-Start Approach for the Inverse Acoustic Obstacle Scattering Problem. (arXiv:2212.08736v3 [math.NA] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01729",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Duval_F/0/1/0/all/0/1\">Francis Duval</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Boucher_J/0/1/0/all/0/1\">Jean-Philippe Boucher</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pigeon_M/0/1/0/all/0/1\">Mathieu Pigeon</a>",
          "description": "We present novel cross-sectional and longitudinal claim count models for\nvehicle insurance built upon the Combined Actuarial Neural Network (CANN)\nframework proposed by Mario W\\\"uthrich and Michael Merz. The CANN approach\ncombines a classical actuarial model, such as a generalized linear model, with\na neural network. This blending of models results in a two-component model\ncomprising a classical regression model and a neural network part. The CANN\nmodel leverages the strengths of both components, providing a solid foundation\nand interpretability from the classical model while harnessing the flexibility\nand capacity to capture intricate relationships and interactions offered by the\nneural network. In our proposed models, we use well-known log-linear claim\ncount regression models for the classical regression part and a multilayer\nperceptron (MLP) for the neural network part. The MLP part is used to process\ntelematics car driving data given as a vector characterizing the driving\nbehavior of each insured driver. In addition to the Poisson and negative\nbinomial distributions for cross-sectional data, we propose a procedure for\ntraining our CANN model with a multivariate negative binomial (MVNB)\nspecification. By doing so, we introduce a longitudinal model that accounts for\nthe dependence between contracts from the same insured. Our results reveal that\nthe CANN models exhibit superior performance compared to log-linear models that\nrely on manually engineered telematics features.",
          "link": "http://arxiv.org/abs/2308.01729",
          "publishedOn": "2023-08-05T00:48:26.802Z",
          "wordCount": null,
          "title": "Telematics Combined Actuarial Neural Networks for Cross-Sectional and Longitudinal Claim Count Data. (arXiv:2308.01729v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.00605",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jureckova_O/0/1/0/all/0/1\">Olha Jure&#x10d;kov&#xe1;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jurecek_M/0/1/0/all/0/1\">Martin Jure&#x10d;ek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stamp_M/0/1/0/all/0/1\">Mark Stamp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Troia_F/0/1/0/all/0/1\">Fabio Di Troia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lorencz_R/0/1/0/all/0/1\">R&#xf3;bert L&#xf3;rencz</a>",
          "description": "A large amount of new malware is constantly being generated, which must not\nonly be distinguished from benign samples, but also classified into malware\nfamilies. For this purpose, investigating how existing malware families are\ndeveloped and examining emerging families need to be explored. This paper\nfocuses on the online processing of incoming malicious samples to assign them\nto existing families or, in the case of samples from new families, to cluster\nthem. We experimented with seven prevalent malware families from the EMBER\ndataset, four in the training set and three additional new families in the test\nset. Based on the classification score of the multilayer perceptron, we\ndetermined which samples would be classified and which would be clustered into\nnew malware families. We classified 97.21% of streaming data with a balanced\naccuracy of 95.33%. Then, we clustered the remaining data using a\nself-organizing map, achieving a purity from 47.61% for four clusters to 77.68%\nfor ten clusters. These results indicate that our approach has the potential to\nbe applied to the classification and clustering of zero-day malware into\nmalware families.",
          "link": "http://arxiv.org/abs/2305.00605",
          "publishedOn": "2023-08-05T00:48:26.801Z",
          "wordCount": null,
          "title": "Classification and Online Clustering of Zero-Day Malware. (arXiv:2305.00605v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01743",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Posch_S/0/1/0/all/0/1\">Stefan Posch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gossnitzer_C/0/1/0/all/0/1\">Clemens G&#xf6;&#xdf;nitzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rohrhofer_F/0/1/0/all/0/1\">Franz Rohrhofer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiger_B/0/1/0/all/0/1\">Bernhard C. Geiger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wimmer_A/0/1/0/all/0/1\">Andreas Wimmer</a>",
          "description": "The turbulent jet ignition concept using prechambers is a promising solution\nto achieve stable combustion at lean conditions in large gas engines, leading\nto high efficiency at low emission levels. Due to the wide range of design and\noperating parameters for large gas engine prechambers, the preferred method for\nevaluating different designs is computational fluid dynamics (CFD), as testing\nin test bed measurement campaigns is time-consuming and expensive. However, the\nsignificant computational time required for detailed CFD simulations due to the\ncomplexity of solving the underlying physics also limits its applicability. In\noptimization settings similar to the present case, i.e., where the evaluation\nof the objective function(s) is computationally costly, Bayesian optimization\nhas largely replaced classical design-of-experiment. Thus, the present study\ndeals with the computationally efficient Bayesian optimization of large gas\nengine prechambers design using CFD simulation. Reynolds-averaged-Navier-Stokes\nsimulations are used to determine the target values as a function of the\nselected prechamber design parameters. The results indicate that the chosen\nstrategy is effective to find a prechamber design that achieves the desired\ntarget values.",
          "link": "http://arxiv.org/abs/2308.01743",
          "publishedOn": "2023-08-05T00:48:26.798Z",
          "wordCount": null,
          "title": "Finding the Optimum Design of Large Gas Engines Prechambers Using CFD and Bayesian Optimization. (arXiv:2308.01743v1 [cs.CE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agro_B/0/1/0/all/0/1\">Ben Agro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sykora_Q/0/1/0/all/0/1\">Quinlan Sykora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casas_S/0/1/0/all/0/1\">Sergio Casas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Urtasun_R/0/1/0/all/0/1\">Raquel Urtasun</a>",
          "description": "A self-driving vehicle (SDV) must be able to perceive its surroundings and\npredict the future behavior of other traffic participants. Existing works\neither perform object detection followed by trajectory forecasting of the\ndetected objects, or predict dense occupancy and flow grids for the whole\nscene. The former poses a safety concern as the number of detections needs to\nbe kept low for efficiency reasons, sacrificing object recall. The latter is\ncomputationally expensive due to the high-dimensionality of the output grid,\nand suffers from the limited receptive field inherent to fully convolutional\nnetworks. Furthermore, both approaches employ many computational resources\npredicting areas or objects that might never be queried by the motion planner.\nThis motivates our unified approach to perception and future prediction that\nimplicitly represents occupancy and flow over time with a single neural\nnetwork. Our method avoids unnecessary computation, as it can be directly\nqueried by the motion planner at continuous spatio-temporal locations.\nMoreover, we design an architecture that overcomes the limited receptive field\nof previous explicit occupancy prediction methods by adding an efficient yet\neffective global attention mechanism. Through extensive experiments in both\nurban and highway settings, we demonstrate that our implicit model outperforms\nthe current state-of-the-art. For more information, visit the project website:\nhttps://waabi.ai/research/implicito.",
          "link": "http://arxiv.org/abs/2308.01471",
          "publishedOn": "2023-08-05T00:48:26.797Z",
          "wordCount": null,
          "title": "Implicit Occupancy Flow Fields for Perception and Prediction in Self-Driving. (arXiv:2308.01471v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.10903",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sluijterman_L/0/1/0/all/0/1\">Laurens Sluijterman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cator_E/0/1/0/all/0/1\">Eric Cator</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Heskes_T/0/1/0/all/0/1\">Tom Heskes</a>",
          "description": "With the rise of the popularity and usage of neural networks, trustworthy\nuncertainty estimation is becoming increasingly essential. One of the most\nprominent uncertainty estimation methods is Deep Ensembles (Lakshminarayanan et\nal., 2017) . A classical parametric model has uncertainty in the parameters due\nto the fact that the data on which the model is build is a random sample. A\nmodern neural network has an additional uncertainty component since the\noptimization of the network is random. Lakshminarayanan et al. (2017) noted\nthat Deep Ensembles do not incorporate the classical uncertainty induced by the\neffect of finite data. In this paper, we present a computationally cheap\nextension of Deep Ensembles for the regression setting, called Bootstrapped\nDeep Ensembles, that explicitly takes this classical effect of finite data into\naccount using a modified version of the parametric bootstrap. We demonstrate\nthrough an experimental study that our method significantly improves upon\nstandard Deep Ensembles",
          "link": "http://arxiv.org/abs/2202.10903",
          "publishedOn": "2023-08-05T00:48:26.793Z",
          "wordCount": null,
          "title": "Confident Neural Network Regression with Bootstrapped Deep Ensembles. (arXiv:2202.10903v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01362",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Laurie_M/0/1/0/all/0/1\">Mark Laurie</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lu_J/0/1/0/all/0/1\">James Lu</a>",
          "description": "While tumor dynamic modeling has been widely applied to support the\ndevelopment of oncology drugs, there remains a need to increase predictivity,\nenable personalized therapy, and improve decision-making. We propose the use of\nTumor Dynamic Neural-ODE (TDNODE) as a pharmacology-informed neural network to\nenable model discovery from longitudinal tumor size data. We show that TDNODE\novercomes a key limitation of existing models in its ability to make unbiased\npredictions from truncated data. The encoder-decoder architecture is designed\nto express an underlying dynamical law which possesses the fundamental property\nof generalized homogeneity with respect to time. Thus, the modeling formalism\nenables the encoder output to be interpreted as kinetic rate metrics, with\ninverse time as the physical unit. We show that the generated metrics can be\nused to predict patients' overall survival (OS) with high accuracy. The\nproposed modeling formalism provides a principled way to integrate multimodal\ndynamical datasets in oncology disease modeling.",
          "link": "http://arxiv.org/abs/2308.01362",
          "publishedOn": "2023-08-05T00:48:26.791Z",
          "wordCount": null,
          "title": "Explainable Deep Learning for Tumor Dynamic Modeling and Overall Survival Prediction using Neural-ODE. (arXiv:2308.01362v1 [q-bio.QM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.07901",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ott_F/0/1/0/all/0/1\">Felix Ott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rugamer_D/0/1/0/all/0/1\">David R&#xfc;gamer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heublein_L/0/1/0/all/0/1\">Lucas Heublein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bischl_B/0/1/0/all/0/1\">Bernd Bischl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mutschler_C/0/1/0/all/0/1\">Christopher Mutschler</a>",
          "description": "Cross-modal representation learning learns a shared embedding between two or\nmore modalities to improve performance in a given task compared to using only\none of the modalities. Cross-modal representation learning from different data\ntypes -- such as images and time-series data (e.g., audio or text data) --\nrequires a deep metric learning loss that minimizes the distance between the\nmodality embeddings. In this paper, we propose to use the contrastive or\ntriplet loss, which uses positive and negative identities to create sample\npairs with different labels, for cross-modal representation learning between\nimage and time-series modalities (CMR-IS). By adapting the triplet loss for\ncross-modal representation learning, higher accuracy in the main (time-series\nclassification) task can be achieved by exploiting additional information of\nthe auxiliary (image classification) task. We present a triplet loss with a\ndynamic margin for single label and sequence-to-sequence classification tasks.\nWe perform extensive evaluations on synthetic image and time-series data, and\non data for offline handwriting recognition (HWR) and on online HWR from\nsensor-enhanced pens for classifying written words. Our experiments show an\nimproved classification accuracy, faster convergence, and better\ngeneralizability due to an improved cross-modal representation. Furthermore,\nthe more suitable generalizability leads to a better adaptability between\nwriters for online HWR.",
          "link": "http://arxiv.org/abs/2202.07901",
          "publishedOn": "2023-08-05T00:48:26.789Z",
          "wordCount": null,
          "title": "Auxiliary Cross-Modal Representation Learning with Triplet Loss Functions for Online Handwriting Recognition. (arXiv:2202.07901v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.10406",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dhuliawala_S/0/1/0/all/0/1\">Shehzaad Dhuliawala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allen_C/0/1/0/all/0/1\">Carl Allen</a>",
          "description": "We present a latent variable generalisation of neural network softmax\nclassification trained with cross-entropy loss, referred to as variational\nclassification (VC). Our approach offers a novel probabilistic perspective on\nthe highly familiar softmax classification model, to which it relates similarly\nto how variational and traditional autoencoders relate. We derive a training\nobjective based on the evidence lower bound (ELBO) that is non-trivial to\noptimize, and therefore propose an adversarial approach to maximise it. We show\nthat VC addresses an inherent inconsistency within softmax classification,\nwhilst also allowing more flexible choices of prior distributions in the latent\nspace in place of implicit assumptions revealed within off-the-shelf softmax\nclassifiers. Empirical evaluation on image and text classification datasets\ndemonstrates that variational classification maintains prediction accuracy\nwhile improving other desirable properties such as calibration and adversarial\nrobustness, particularly under distribution shift and low data settings.",
          "link": "http://arxiv.org/abs/2305.10406",
          "publishedOn": "2023-08-05T00:48:26.786Z",
          "wordCount": null,
          "title": "Variational Classification. (arXiv:2305.10406v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01649",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leluc_R/0/1/0/all/0/1\">R&#xe9;mi Leluc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kadoche_E/0/1/0/all/0/1\">Elie Kadoche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bertoncello_A/0/1/0/all/0/1\">Antoine Bertoncello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gourvenec_S/0/1/0/all/0/1\">S&#xe9;bastien Gourv&#xe9;nec</a>",
          "description": "Maintaining a balance between the supply and demand of products by optimizing\nreplenishment decisions is one of the most important challenges in the supply\nchain industry. This paper presents a novel reinforcement learning framework\ncalled MARLIM, to address the inventory management problem for a single-echelon\nmulti-products supply chain with stochastic demands and lead-times. Within this\ncontext, controllers are developed through single or multiple agents in a\ncooperative setting. Numerical experiments on real data demonstrate the\nbenefits of reinforcement learning methods over traditional baselines.",
          "link": "http://arxiv.org/abs/2308.01649",
          "publishedOn": "2023-08-05T00:48:26.784Z",
          "wordCount": null,
          "title": "MARLIM: Multi-Agent Reinforcement Learning for Inventory Management. (arXiv:2308.01649v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01789",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Turati_G/0/1/0/all/0/1\">Gloria Turati</a> (1), <a href=\"http://arxiv.org/find/quant-ph/1/au:+Dacrema_M/0/1/0/all/0/1\">Maurizio Ferrari Dacrema</a> (1), <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cremonesi_P/0/1/0/all/0/1\">Paolo Cremonesi</a> (1) ((1) Politecnico di Milano)",
          "description": "In recent years, Variational Quantum Algorithms (VQAs) have emerged as a\npromising approach for solving optimization problems on quantum computers in\nthe NISQ era. However, one limitation of VQAs is their reliance on\nfixed-structure circuits, which may not be taylored for specific problems or\nhardware configurations. A leading strategy to address this issue are\nAdaptative VQAs, which dynamically modify the circuit structure by adding and\nremoving gates, and optimize their parameters during the training. Several\nAdaptative VQAs, based on heuristics such as circuit shallowness, entanglement\ncapability and hardware compatibility, have already been proposed in the\nliterature, but there is still lack of a systematic comparison between the\ndifferent methods. In this paper, we aim to fill this gap by analyzing three\nAdaptative VQAs: Evolutionary Variational Quantum Eigensolver (EVQE), Variable\nAnsatz (VAns), already proposed in the literature, and Random Adapt-VQE\n(RA-VQE), a random approach we introduce as a baseline. In order to compare\nthese algorithms to traditional VQAs, we also include the Quantum Approximate\nOptimization Algorithm (QAOA) in our analysis. We apply these algorithms to\nQUBO problems and study their performance by examining the quality of the\nsolutions found and the computational times required. Additionally, we\ninvestigate how the choice of the hyperparameters can impact the overall\nperformance of the algorithms, highlighting the importance of selecting an\nappropriate methodology for hyperparameter tuning. Our analysis sets benchmarks\nfor Adaptative VQAs designed for near-term quantum devices and provides\nvaluable insights to guide future research in this area.",
          "link": "http://arxiv.org/abs/2308.01789",
          "publishedOn": "2023-08-05T00:48:26.784Z",
          "wordCount": null,
          "title": "Benchmarking Adaptative Variational Quantum Algorithms on QUBO Instances. (arXiv:2308.01789v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.13539",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiawei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_C/0/1/0/all/0/1\">Changkun Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_R/0/1/0/all/0/1\">Ruikai Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaihao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barnes_N/0/1/0/all/0/1\">Nick Barnes</a>",
          "description": "For safety-related applications, it is crucial to produce trustworthy deep\nneural networks whose prediction is associated with confidence that can\nrepresent the likelihood of correctness for subsequent decision-making.\nExisting dense binary classification models are prone to being over-confident.\nTo improve model calibration, we propose Adaptive Stochastic Label Perturbation\n(ASLP) which learns a unique label perturbation level for each training image.\nASLP employs our proposed Self-Calibrating Binary Cross Entropy (SC-BCE) loss,\nwhich unifies label perturbation processes including stochastic approaches\n(like DisturbLabel), and label smoothing, to correct calibration while\nmaintaining classification rates. ASLP follows Maximum Entropy Inference of\nclassic statistical mechanics to maximise prediction entropy with respect to\nmissing information. It performs this while: (1) preserving classification\naccuracy on known data as a conservative solution, or (2) specifically improves\nmodel calibration degree by minimising the gap between the prediction accuracy\nand expected confidence of the target training label. Extensive results\ndemonstrate that ASLP can significantly improve calibration degrees of dense\nbinary classification models on both in-distribution and out-of-distribution\ndata. The code is available on https://github.com/Carlisle-Liu/ASLP.",
          "link": "http://arxiv.org/abs/2307.13539",
          "publishedOn": "2023-08-05T00:48:26.783Z",
          "wordCount": null,
          "title": "Model Calibration in Dense Classification with Adaptive Label Perturbation. (arXiv:2307.13539v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.05357",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Nan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yilun Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1\">Antonio Torralba</a>",
          "description": "Text-to-image generative models have enabled high-resolution image synthesis\nacross different domains, but require users to specify the content they wish to\ngenerate. In this paper, we consider the inverse problem -- given a collection\nof different images, can we discover the generative concepts that represent\neach image? We present an unsupervised approach to discover generative concepts\nfrom a collection of images, disentangling different art styles in paintings,\nobjects, and lighting from kitchen scenes, and discovering image classes given\nImageNet images. We show how such generative concepts can accurately represent\nthe content of images, be recombined and composed to generate new artistic and\nhybrid images, and be further used as a representation for downstream\nclassification tasks.",
          "link": "http://arxiv.org/abs/2306.05357",
          "publishedOn": "2023-08-05T00:48:26.781Z",
          "wordCount": null,
          "title": "Unsupervised Compositional Concepts Discovery with Text-to-Image Generative Models. (arXiv:2306.05357v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.16680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_M/0/1/0/all/0/1\">Mingyuan Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Cen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chengyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jun Huang</a>",
          "description": "Diffusion models and large language models have emerged as leading-edge\ngenerative models and have sparked a revolutionary impact on various aspects of\nhuman life. However, the practical implementation of these models has also\nexposed inherent risks, highlighting their dual nature and raising concerns\nregarding their trustworthiness. Despite the abundance of literature on this\nsubject, a comprehensive survey specifically delving into the intersection of\nlarge-scale generative models and their trustworthiness remains largely absent.\nTo bridge this gap, This paper investigates both the long-standing and emerging\nthreats associated with these models across four fundamental dimensions:\nprivacy, security, fairness, and responsibility. In this way, we construct an\nextensive map outlining the trustworthiness of these models, while also\nproviding practical recommendations and identifying future directions. These\nefforts are crucial for promoting the trustworthy deployment of these models,\nultimately benefiting society as a whole.",
          "link": "http://arxiv.org/abs/2307.16680",
          "publishedOn": "2023-08-05T00:48:26.781Z",
          "wordCount": null,
          "title": "On the Trustworthiness Landscape of State-of-the-art Generative Models: A Comprehensive Survey. (arXiv:2307.16680v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.07944",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Cheng_H/0/1/0/all/0/1\">Huqiang Cheng</a>, <a href=\"http://arxiv.org/find/math/1/au:+Liao_X/0/1/0/all/0/1\">Xiaofeng Liao</a>, <a href=\"http://arxiv.org/find/math/1/au:+Li_H/0/1/0/all/0/1\">Huaqing Li</a>",
          "description": "We deal with a general distributed constrained online learning problem with\nprivacy over time-varying networks, where a class of nondecomposable objectives\nare considered. Under this setting, each node only controls a part of the\nglobal decision, and the goal of all nodes is to collaboratively minimize the\nglobal cost over a time horizon $T$ while guarantees the security of the\ntransmitted information. For such problems, we first design a novel generic\nalgorithm framework, named as DPSDA, of differentially private distributed\nonline learning using the Laplace mechanism and the stochastic variants of dual\naveraging method. Note that in the dual updates, all nodes of DPSDA employ the\nnoise-corrupted gradients for more generality. Then, we propose two algorithms,\nnamed as DPSDA-C and DPSDA-PS, under this framework. In DPSDA-C, the nodes\nimplement a circulation-based communication in the primal updates so as to\nalleviate the disagreements over time-varying undirected networks. In addition,\nfor the extension to time-varying directed ones, the nodes implement the\nbroadcast-based push-sum dynamics in DPSDA-PS, which can achieve average\nconsensus over arbitrary directed networks. Theoretical results show that both\nalgorithms attain an expected regret upper bound in $\\mathcal{O}( \\sqrt{T} )$\nwhen the objective function is convex, which matches the best utility\nachievable by cutting-edge algorithms. Finally, numerical experiment results on\nboth synthetic and real-world datasets verify the effectiveness of our\nalgorithms.",
          "link": "http://arxiv.org/abs/2206.07944",
          "publishedOn": "2023-08-05T00:48:26.780Z",
          "wordCount": null,
          "title": "Distributed Online Private Learning of Convex Nondecomposable Objectives. (arXiv:2206.07944v4 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.12130",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Chen_S/0/1/0/all/0/1\">Shengyu Chen</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bao_T/0/1/0/all/0/1\">Tianshu Bao</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Givi_P/0/1/0/all/0/1\">Peyman Givi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zheng_C/0/1/0/all/0/1\">Can Zheng</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Jia_X/0/1/0/all/0/1\">Xiaowei Jia</a>",
          "description": "Simulating turbulence is critical for many societally important applications\nin aerospace engineering, environmental science, the energy industry, and\nbiomedicine. Large eddy simulation (LES) has been widely used as an alternative\nto direct numerical simulation (DNS) for simulating turbulent flows due to its\nreduced computational cost. However, LES is unable to capture all of the scales\nof turbulent transport accurately. Reconstructing DNS from low-resolution LES\nis critical for many scientific and engineering disciplines, but it poses many\nchallenges to existing super-resolution methods due to the spatio-temporal\ncomplexity of turbulent flows. In this work, we propose a new physics-guided\nneural network for reconstructing the sequential DNS from low-resolution LES\ndata. The proposed method leverages the partial differential equation that\nunderlies the flow dynamics in the design of spatio-temporal model\narchitecture. A degradation-based refinement method is also developed to\nenforce physical constraints and further reduce the accumulated reconstruction\nerrors over long periods. The results on two different types of turbulent flow\ndata confirm the superiority of the proposed method in reconstructing the\nhigh-resolution DNS data and preserving the physical characteristics of flow\ntransport.",
          "link": "http://arxiv.org/abs/2304.12130",
          "publishedOn": "2023-08-05T00:48:26.779Z",
          "wordCount": null,
          "title": "Reconstructing Turbulent Flows Using Physics-Aware Spatio-Temporal Dynamics and Test-Time Refinement. (arXiv:2304.12130v2 [physics.flu-dyn] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.12729",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Darya_A/0/1/0/all/0/1\">Abdollah Masoud Darya</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Fernini_I/0/1/0/all/0/1\">Ilias Fernini</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Vellasco_M/0/1/0/all/0/1\">Marley Vellasco</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Hussain_A/0/1/0/all/0/1\">Abir Hussain</a>",
          "description": "The field of radio astronomy is witnessing a boom in the amount of data\nproduced per day due to newly commissioned radio telescopes. One of the most\ncrucial problems in this field is the automatic classification of extragalactic\nradio sources based on their morphologies. Most recent contributions in the\nfield of morphological classification of extragalactic radio sources have\nproposed classifiers based on convolutional neural networks. Alternatively,\nthis work proposes gradient boosting machine learning methods accompanied by\nprincipal component analysis as data-efficient alternatives to convolutional\nneural networks. Recent findings have shown the efficacy of gradient boosting\nmethods in outperforming deep learning methods for classification problems with\ntabular data. The gradient boosting methods considered in this work are based\non the XGBoost, LightGBM, and CatBoost implementations. This work also studies\nthe effect of dataset size on classifier performance. A three-class\nclassification problem is considered in this work based on the three main\nFanaroff-Riley classes: class 0, class I, and class II, using radio sources\nfrom the Best-Heckman sample. All three proposed gradient boosting methods\noutperformed a state-of-the-art convolutional neural networks-based classifier\nusing less than a quarter of the number of images, with CatBoost having the\nhighest accuracy. This was mainly due to the superior accuracy of gradient\nboosting methods in classifying Fanaroff-Riley class II sources, with\n3$\\unicode{x2013}$4% higher recall.",
          "link": "http://arxiv.org/abs/2304.12729",
          "publishedOn": "2023-08-05T00:48:26.778Z",
          "wordCount": null,
          "title": "Morphological Classification of Extragalactic Radio Sources Using Gradient Boosting Methods. (arXiv:2304.12729v2 [astro-ph.IM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01319",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tajidini_F/0/1/0/all/0/1\">Farzaneh Tajidini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kheiri_M/0/1/0/all/0/1\">Mohammad-Javad Kheiri</a>",
          "description": "Computer-aided diagnosis (CAD), a vibrant medical imaging research field, is\nexpanding quickly. Because errors in medical diagnostic systems might lead to\nseriously misleading medical treatments, major efforts have been made in recent\nyears to improve computer-aided diagnostics applications. The use of machine\nlearning in computer-aided diagnosis is crucial. A simple equation may result\nin a false indication of items like organs. Therefore, learning from examples\nis a vital component of pattern recognition. Pattern recognition and machine\nlearning in the biomedical area promise to increase the precision of disease\ndetection and diagnosis. They also support the decision-making process's\nobjectivity. Machine learning provides a practical method for creating elegant\nand autonomous algorithms to analyze high-dimensional and multimodal\nbio-medical data. This review article examines machine-learning algorithms for\ndetecting diseases, including hepatitis, diabetes, liver disease, dengue fever,\nand heart disease. It draws attention to the collection of machine learning\ntechniques and algorithms employed in studying conditions and the ensuing\ndecision-making process.",
          "link": "http://arxiv.org/abs/2308.01319",
          "publishedOn": "2023-08-05T00:48:26.777Z",
          "wordCount": null,
          "title": "Recent advancement in Disease Diagnostic using machine learning: Systematic survey of decades, comparisons, and challenges. (arXiv:2308.01319v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.10112",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chang Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_D/0/1/0/all/0/1\">Di Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chuzhe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenbin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_J/0/1/0/all/0/1\">Jingping Bi</a>",
          "description": "Temporal data, representing chronological observations of complex systems,\nhas always been a typical data structure that can be widely generated by many\ndomains, such as industry, medicine and finance. Analyzing this type of data is\nextremely valuable for various applications. Thus, different temporal data\nanalysis tasks, eg, classification, clustering and prediction, have been\nproposed in the past decades. Among them, causal discovery, learning the causal\nrelations from temporal data, is considered an interesting yet critical task\nand has attracted much research attention. Existing causal discovery works can\nbe divided into two highly correlated categories according to whether the\ntemporal data is calibrated, ie, multivariate time series causal discovery, and\nevent sequence causal discovery. However, most previous surveys are only\nfocused on the time series causal discovery and ignore the second category. In\nthis paper, we specify the correlation between the two categories and provide a\nsystematical overview of existing solutions. Furthermore, we provide public\ndatasets, evaluation metrics and new perspectives for temporal data causal\ndiscovery.",
          "link": "http://arxiv.org/abs/2303.10112",
          "publishedOn": "2023-08-05T00:48:26.777Z",
          "wordCount": null,
          "title": "Causal Discovery from Temporal Data: An Overview and New Perspectives. (arXiv:2303.10112v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01436",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dvorkin_V/0/1/0/all/0/1\">Vladimir Dvorkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fioretto_F/0/1/0/all/0/1\">Ferdinando Fioretto</a>",
          "description": "While deep learning gradually penetrates operational planning, its inherent\nprediction errors may significantly affect electricity prices. This letter\nexamines how prediction errors propagate into electricity prices, revealing\nnotable pricing errors and their spatial disparity in congested power systems.\nTo improve fairness, we propose to embed electricity market-clearing\noptimization as a deep learning layer. Differentiating through this layer\nallows for balancing between prediction and pricing errors, as oppose to\nminimizing prediction errors alone. This layer implicitly optimizes fairness\nand controls the spatial distribution of price errors across the system. We\nshowcase the price-aware deep learning in the nexus of wind power forecasting\nand short-term electricity market clearing.",
          "link": "http://arxiv.org/abs/2308.01436",
          "publishedOn": "2023-08-05T00:48:26.759Z",
          "wordCount": null,
          "title": "Price-Aware Deep Learning for Electricity Markets. (arXiv:2308.01436v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.11233",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoxing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1\">Xiangxiang Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yuda Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhexi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaokang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>",
          "description": "Albeit being a prevalent architecture searching approach, differentiable\narchitecture search (DARTS) is largely hindered by its substantial memory cost\nsince the entire supernet resides in the memory. This is where the single-path\nDARTS comes in, which only chooses a single-path submodel at each step. While\nbeing memory-friendly, it also comes with low computational costs. Nonetheless,\nwe discover a critical issue of single-path DARTS that has not been primarily\nnoticed. Namely, it also suffers from severe performance collapse since too\nmany parameter-free operations like skip connections are derived, just like\nDARTS does. In this paper, we propose a new algorithm called RObustifying\nMemory-Efficient NAS (ROME) to give a cure. First, we disentangle the topology\nsearch from the operation search to make searching and evaluation consistent.\nWe then adopt Gumbel-Top2 reparameterization and gradient accumulation to\nrobustify the unwieldy bi-level optimization. We verify ROME extensively across\n15 benchmarks to demonstrate its effectiveness and robustness.",
          "link": "http://arxiv.org/abs/2011.11233",
          "publishedOn": "2023-08-05T00:48:26.757Z",
          "wordCount": null,
          "title": "ROME: Robustifying Memory-Efficient NAS via Topology Disentanglement and Gradient Accumulation. (arXiv:2011.11233v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2005.09048",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Rolle_A/0/1/0/all/0/1\">Alexander Rolle</a>, <a href=\"http://arxiv.org/find/math/1/au:+Scoccola_L/0/1/0/all/0/1\">Luis Scoccola</a>",
          "description": "We consider the degree-Rips construction from topological data analysis,\nwhich provides a density-sensitive, multiparameter hierarchical clustering\nalgorithm. We analyze its stability to perturbations of the input data using\nthe correspondence-interleaving distance, a metric for hierarchical clusterings\nthat we introduce. Taking certain one-parameter slices of degree-Rips recovers\nwell-known methods for density-based clustering, but we show that these methods\nare unstable. However, we prove that degree-Rips, as a multiparameter object,\nis stable, and we propose an alternative approach for taking slices of\ndegree-Rips, which yields a one-parameter hierarchical clustering algorithm\nwith better stability properties. We prove that this algorithm is consistent,\nusing the correspondence-interleaving distance. We provide an algorithm for\nextracting a single clustering from one-parameter hierarchical clusterings,\nwhich is stable with respect to the correspondence-interleaving distance. And,\nwe integrate these methods into a pipeline for density-based clustering, which\nwe call Persistable. Adapting tools from multiparameter persistent homology, we\npropose visualization tools that guide the selection of all parameters of the\npipeline. We demonstrate Persistable on benchmark datasets, showing that it\nidentifies multi-scale cluster structure in data.",
          "link": "http://arxiv.org/abs/2005.09048",
          "publishedOn": "2023-08-05T00:48:26.750Z",
          "wordCount": null,
          "title": "Stable and consistent density-based clustering via multiparameter persistence. (arXiv:2005.09048v3 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.13619",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hanxiong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yingqiang Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1\">Juntao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shuchang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>",
          "description": "As one of the most pervasive applications of machine learning, recommender\nsystems are playing an important role on assisting human decision making. The\nsatisfaction of users and the interests of platforms are closely related to the\nquality of the generated recommendation results. However, as a highly\ndata-driven system, recommender system could be affected by data or algorithmic\nbias and thus generate unfair results, which could weaken the reliance of the\nsystems. As a result, it is crucial to address the potential unfairness\nproblems in recommendation settings. Recently, there has been growing attention\non fairness considerations in recommender systems with more and more literature\non approaches to promote fairness in recommendation. However, the studies are\nrather fragmented and lack a systematic organization, thus making it difficult\nto penetrate for new researchers to the domain. This motivates us to provide a\nsystematic survey of existing works on fairness in recommendation. This survey\nfocuses on the foundations for fairness in recommendation literature. It first\npresents a brief introduction about fairness in basic machine learning tasks\nsuch as classification and ranking in order to provide a general overview of\nfairness research, as well as introduce the more complex situations and\nchallenges that need to be considered when studying fairness in recommender\nsystems. After that, the survey will introduce fairness in recommendation with\na focus on the taxonomies of current fairness definitions, the typical\ntechniques for improving fairness, as well as the datasets for fairness studies\nin recommendation. The survey also talks about the challenges and opportunities\nin fairness research with the hope of promoting the fair recommendation\nresearch area and beyond.",
          "link": "http://arxiv.org/abs/2205.13619",
          "publishedOn": "2023-08-05T00:48:26.750Z",
          "wordCount": null,
          "title": "Fairness in Recommendation: Foundations, Methods and Applications. (arXiv:2205.13619v6 [cs.IR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.04800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_X/0/1/0/all/0/1\">Xiangxu Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chuhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jianing Chen</a>",
          "description": "Recently, significant advancements have been made in time-series forecasting\nresearch, with an increasing focus on analyzing the nature of time-series data,\ne.g, channel-independence (CI) and channel-dependence (CD), rather than solely\nfocusing on designing sophisticated forecasting models. However, current\nresearch has primarily focused on either CI or CD in isolation, and the\nchallenge of effectively combining these two opposing properties to achieve a\nsynergistic effect remains an unresolved issue. In this paper, we carefully\nexamine the opposing properties of CI and CD, and raise a practical question\nthat has not been effectively answered, e.g.,\"How to effectively mix the CI and\nCD properties of time series to achieve better predictive performance?\" To\nanswer this question, we propose Mlinear (MIX-Linear), a simple yet effective\nmethod based mainly on linear layers. The design philosophy of Mlinear mainly\nincludes two aspects:(1) dynamically tuning the CI and CD properties based on\nthe time semantics of different input time series, and (2) providing deep\nsupervision to adjust the individual performance of the \"CI predictor\" and \"CD\npredictor\". In addition, empirically, we introduce a new loss function that\nsignificantly outperforms the widely used mean squared error (MSE) on multiple\ndatasets. Experiments on time-series datasets covering multiple fields and\nwidely used have demonstrated the superiority of our method over PatchTST which\nis the lateset Transformer-based method in terms of the MSE and MAE metrics on\n7 datasets with identical sequence inputs (336 or 512). Specifically, our\nmethod significantly outperforms PatchTST with a ratio of 21:3 at 336 sequence\nlength input and 29:10 at 512 sequence length input. Additionally, our approach\nhas a 10 $\\times$ efficiency advantage at the unit level, taking into account\nboth training and inference times.",
          "link": "http://arxiv.org/abs/2305.04800",
          "publishedOn": "2023-08-05T00:48:26.747Z",
          "wordCount": null,
          "title": "Mlinear: Rethink the Linear Model for Time-series Forecasting. (arXiv:2305.04800v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01562",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Pervej_M/0/1/0/all/0/1\">Md Ferdous Pervej</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jin_R/0/1/0/all/0/1\">Richeng Jin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dai_H/0/1/0/all/0/1\">Huaiyu Dai</a>",
          "description": "While a practical wireless network has many tiers where end users do not\ndirectly communicate with the central server, the users' devices have limited\ncomputation and battery powers, and the serving base station (BS) has a fixed\nbandwidth. Owing to these practical constraints and system models, this paper\nleverages model pruning and proposes a pruning-enabled hierarchical federated\nlearning (PHFL) in heterogeneous networks (HetNets). We first derive an upper\nbound of the convergence rate that clearly demonstrates the impact of the model\npruning and wireless communications between the clients and the associated BS.\nThen we jointly optimize the model pruning ratio, central processing unit (CPU)\nfrequency and transmission power of the clients in order to minimize the\ncontrollable terms of the convergence bound under strict delay and energy\nconstraints. However, since the original problem is not convex, we perform\nsuccessive convex approximation (SCA) and jointly optimize the parameters for\nthe relaxed convex problem. Through extensive simulation, we validate the\neffectiveness of our proposed PHFL algorithm in terms of test accuracy, wall\nclock time, energy consumption and bandwidth requirement.",
          "link": "http://arxiv.org/abs/2308.01562",
          "publishedOn": "2023-08-05T00:48:26.745Z",
          "wordCount": null,
          "title": "Hierarchical Federated Learning in Wireless Networks: Pruning Tackles Bandwidth Scarcity and System Heterogeneity. (arXiv:2308.01562v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01433",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Romero_N/0/1/0/all/0/1\">Noemi Maritza L. Romero</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vasconcellos_R/0/1/0/all/0/1\">Ricco Vasconcellos</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mendoza_M/0/1/0/all/0/1\">Mariana R. Mendoza</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Comba_J/0/1/0/all/0/1\">Jo&#xe3;o L. D. Comba</a>",
          "description": "The COVID-19 pandemic presented numerous challenges to healthcare systems\nworldwide. Given that lung infections are prevalent among COVID-19 patients,\nchest Computer Tomography (CT) scans have frequently been utilized as an\nalternative method for identifying COVID-19 conditions and various other types\nof pulmonary diseases. Deep learning architectures have emerged to automate the\nidentification of pulmonary disease types by leveraging CT scan slices as\ninputs for classification models. This paper introduces COVID-VR, a novel\napproach for classifying pulmonary diseases based on volume rendering images of\nthe lungs captured from multiple angles, thereby providing a comprehensive view\nof the entire lung in each image. To assess the effectiveness of our proposal,\nwe compared it against competing strategies utilizing both private data\nobtained from partner hospitals and a publicly available dataset. The results\ndemonstrate that our approach effectively identifies pulmonary lesions and\nperforms competitively when compared to slice-based methods.",
          "link": "http://arxiv.org/abs/2308.01433",
          "publishedOn": "2023-08-05T00:48:26.742Z",
          "wordCount": null,
          "title": "COVID-VR: A Deep Learning COVID-19 Classification Model Using Volume-Rendered Computer Tomography. (arXiv:2308.01433v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01906",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gaur_V/0/1/0/all/0/1\">Vedant Gaur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saunshi_N/0/1/0/all/0/1\">Nikunj Saunshi</a>",
          "description": "Large language models (LLMs) have revolutionized NLP by solving downstream\ntasks with little to no labeled data. Despite their versatile abilities, the\nlarger question of their ability to reason remains ill-understood. This paper\naddresses reasoning in math word problems (MWPs) by studying symbolic versions\nof the numeric problems, since a symbolic expression is a \"concise explanation\"\nof the numeric answer. We create and use a symbolic version of the SVAMP\ndataset and find that GPT-3's davinci-002 model also has good zero-shot\naccuracy on symbolic MWPs. To evaluate the faithfulness of the model's\nreasoning, we go beyond accuracy and additionally evaluate the alignment\nbetween the final answer and the outputted reasoning, which correspond to\nnumeric and symbolic answers respectively for MWPs. We explore a self-prompting\napproach to encourage the symbolic reasoning to align with the numeric answer,\nthus equipping the LLM with the ability to provide a concise and verifiable\nreasoning and making it more interpretable. Surprisingly, self-prompting also\nimproves the symbolic accuracy to be higher than both the numeric and symbolic\naccuracies, thus providing an ensembling effect. The SVAMP_Sym dataset will be\nreleased for future research on symbolic math problems.",
          "link": "http://arxiv.org/abs/2308.01906",
          "publishedOn": "2023-08-05T00:48:26.741Z",
          "wordCount": null,
          "title": "Reasoning in Large Language Models Through Symbolic Math Word Problems. (arXiv:2308.01906v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01823",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenhao Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1\">Xiang Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yulong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Run Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1\">Liming Fang</a>",
          "description": "Adversarial training (AT) is widely considered the state-of-the-art technique\nfor improving the robustness of deep neural networks (DNNs) against adversarial\nexamples (AE). Nevertheless, recent studies have revealed that adversarially\ntrained models are prone to unfairness problems, restricting their\napplicability. In this paper, we empirically observe that this limitation may\nbe attributed to serious adversarial confidence overfitting, i.e., certain\nadversarial examples with overconfidence. To alleviate this problem, we propose\nHAM, a straightforward yet effective framework via adaptive Hard Adversarial\nexample Mining.HAM concentrates on mining hard adversarial examples while\ndiscarding the easy ones in an adaptive fashion. Specifically, HAM identifies\nhard AEs in terms of their step sizes needed to cross the decision boundary\nwhen calculating loss value. Besides, an early-dropping mechanism is\nincorporated to discard the easy examples at the initial stages of AE\ngeneration, resulting in efficient AT. Extensive experimental results on\nCIFAR-10, SVHN, and Imagenette demonstrate that HAM achieves significant\nimprovement in robust fairness while reducing computational cost compared to\nseveral state-of-the-art adversarial training methods. The code will be made\npublicly available.",
          "link": "http://arxiv.org/abs/2308.01823",
          "publishedOn": "2023-08-05T00:48:26.740Z",
          "wordCount": null,
          "title": "Hard Adversarial Example Mining for Improving Robust Fairness. (arXiv:2308.01823v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01320",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zhewei Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aminabadi_R/0/1/0/all/0/1\">Reza Yazdani Aminabadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruwase_O/0/1/0/all/0/1\">Olatunji Ruwase</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajbhandari_S/0/1/0/all/0/1\">Samyam Rajbhandari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiaoxia Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awan_A/0/1/0/all/0/1\">Ammar Ahmad Awan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rasley_J/0/1/0/all/0/1\">Jeff Rasley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Minjia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Conglong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holmes_C/0/1/0/all/0/1\">Connor Holmes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhongzhu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wyatt_M/0/1/0/all/0/1\">Michael Wyatt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_M/0/1/0/all/0/1\">Molly Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurilenko_L/0/1/0/all/0/1\">Lev Kurilenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_H/0/1/0/all/0/1\">Heyang Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_M/0/1/0/all/0/1\">Masahiro Tanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Che_S/0/1/0/all/0/1\">Shuai Che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shuaiwen Leon Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuxiong He</a>",
          "description": "ChatGPT-like models have revolutionized various applications in artificial\nintelligence, from summarization and coding to translation, matching or even\nsurpassing human performance. However, the current landscape lacks an\naccessible, efficient, and cost-effective end-to-end RLHF (Reinforcement\nLearning with Human Feedback) training pipeline for these powerful models,\nparticularly when training at the scale of billions of parameters. This paper\nintroduces DeepSpeed-Chat, a novel system that democratizes RLHF training,\nmaking it accessible to the AI community. DeepSpeed-Chat offers three key\ncapabilities: an easy-to-use training and inference experience for ChatGPT-like\nmodels, a DeepSpeed-RLHF pipeline that replicates the training pipeline from\nInstructGPT, and a robust DeepSpeed-RLHF system that combines various\noptimizations for training and inference in a unified way. The system delivers\nunparalleled efficiency and scalability, enabling training of models with\nhundreds of billions of parameters in record time and at a fraction of the\ncost. With this development, DeepSpeed-Chat paves the way for broader access to\nadvanced RLHF training, even for data scientists with limited resources,\nthereby fostering innovation and further development in the field of AI.",
          "link": "http://arxiv.org/abs/2308.01320",
          "publishedOn": "2023-08-05T00:48:26.738Z",
          "wordCount": null,
          "title": "DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales. (arXiv:2308.01320v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01771",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shokrollahi1_Y/0/1/0/all/0/1\">Yasin Shokrollahi1</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong1_P/0/1/0/all/0/1\">Pengfei Dong1</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xianqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_L/0/1/0/all/0/1\">Linxia Gu</a>",
          "description": "This study investigated the potential of end-to-end deep learning tools as a\nmore effective substitute for FEM in predicting stress-strain fields within 2D\ncross sections of arterial wall. We first proposed a U-Net based fully\nconvolutional neural network (CNN) to predict the von Mises stress and strain\ndistribution based on the spatial arrangement of calcification within arterial\nwall cross-sections. Further, we developed a conditional generative adversarial\nnetwork (cGAN) to enhance, particularly from the perceptual perspective, the\nprediction accuracy of stress and strain field maps for arterial walls with\nvarious calcification quantities and spatial configurations. On top of U-Net\nand cGAN, we also proposed their ensemble approaches, respectively, to further\nimprove the prediction accuracy of field maps. Our dataset, consisting of input\nand output images, was generated by implementing boundary conditions and\nextracting stress-strain field maps. The trained U-Net models can accurately\npredict von Mises stress and strain fields, with structural similarity index\nscores (SSIM) of 0.854 and 0.830 and mean squared errors of 0.017 and 0.018 for\nstress and strain, respectively, on a reserved test set. Meanwhile, the cGAN\nmodels in a combination of ensemble and transfer learning techniques\ndemonstrate high accuracy in predicting von Mises stress and strain fields, as\nevidenced by SSIM scores of 0.890 for stress and 0.803 for strain.\nAdditionally, mean squared errors of 0.008 for stress and 0.017 for strain\nfurther support the model's performance on a designated test set. Overall, this\nstudy developed a surrogate model for finite element analysis, which can\naccurately and efficiently predict stress-strain fields of arterial walls\nregardless of complex geometries and boundary conditions.",
          "link": "http://arxiv.org/abs/2308.01771",
          "publishedOn": "2023-08-05T00:48:26.734Z",
          "wordCount": null,
          "title": "Deep Learning-based Prediction of Stress and Strain Maps in Arterial Walls for Improved Cardiovascular Risk Assessment. (arXiv:2308.01771v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.02144",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barcelo_P/0/1/0/all/0/1\">Pablo Barcel&#xf3;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duarte_M/0/1/0/all/0/1\">Mauricio Duarte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rojas_C/0/1/0/all/0/1\">Crist&#xf3;bal Rojas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steifer_T/0/1/0/all/0/1\">Tomasz Steifer</a>",
          "description": "In peer review systems, reviewers are often asked to evaluate various\nfeatures of submissions, such as technical quality or novelty. A score is given\nto each of the predefined features and based on these the reviewer has to\nprovide an overall quantitative recommendation. It may be assumed that each\nreviewer has her own mapping from the set of features to a recommendation, and\nthat different reviewers have different mappings in mind. This introduces an\nelement of arbitrariness known as commensuration bias. In this paper we discuss\na framework, introduced by Noothigattu, Shah and Procaccia, and then applied by\nthe organizers of the AAAI 2022 conference. Noothigattu, Shah and Procaccia\nproposed to aggregate reviewer's mapping by minimizing certain loss functions,\nand studied axiomatic properties of this approach, in the sense of social\nchoice theory. We challenge several of the results and assumptions used in\ntheir work and report a number of negative results. On the one hand, we study a\ntrade-off between some of the axioms proposed and the ability of the method to\nproperly capture agreements of the majority of reviewers. On the other hand, we\nshow that dropping a certain unrealistic assumption has dramatic effects,\nincluding causing the method to be discontinuous.",
          "link": "http://arxiv.org/abs/2211.02144",
          "publishedOn": "2023-08-05T00:48:26.733Z",
          "wordCount": null,
          "title": "No Agreement Without Loss: Learning and Social Choice in Peer Review. (arXiv:2211.02144v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01415",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianning Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Junda Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaofeng Zhang</a>",
          "description": "At the beginning era of large language model, it is quite critical to\ngenerate a high-quality financial dataset to fine-tune a large language model\nfor financial related tasks. Thus, this paper presents a carefully designed\ndata creation pipeline for this purpose. Particularly, we initiate a dialogue\nbetween an AI investor and financial expert using ChatGPT and incorporate the\nfeedback of human financial experts, leading to the refinement of the dataset.\nThis pipeline yielded a robust instruction tuning dataset comprised of 103k\nmulti-turn chats. Extensive experiments have been conducted on this dataset to\nevaluate the model's performance by adopting an external GPT-4 as the judge.\nThe promising experimental results verify that our approach led to significant\nadvancements in generating accurate, relevant, and financial-style responses\nfrom AI models, and thus providing a powerful tool for applications within the\nfinancial sector.",
          "link": "http://arxiv.org/abs/2308.01415",
          "publishedOn": "2023-08-05T00:48:26.732Z",
          "wordCount": null,
          "title": "An Effective Data Creation Pipeline to Generate High-quality Financial Instruction Data for Large Language Model. (arXiv:2308.01415v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_L/0/1/0/all/0/1\">Lu Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xiaoshuang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Heng Tao Shen</a>",
          "description": "The presence of label noise in the training data has a profound impact on the\ngeneralization of deep neural networks (DNNs). In this study, we introduce and\ntheoretically demonstrate a simple feature noise method, which directly adds\nnoise to the features of training data, can enhance the generalization of DNNs\nunder label noise. Specifically, we conduct theoretical analyses to reveal that\nlabel noise leads to weakened DNN generalization by loosening the PAC-Bayes\ngeneralization bound, and feature noise results in better DNN generalization by\nimposing an upper bound on the mutual information between the model weights and\nthe features, which constrains the PAC-Bayes generalization bound. Furthermore,\nto ensure effective generalization of DNNs in the presence of label noise, we\nconduct application analyses to identify the optimal types and levels of\nfeature noise to add for obtaining desirable label noise generalization.\nFinally, extensive experimental results on several popular datasets demonstrate\nthe feature noise method can significantly enhance the label noise\ngeneralization of the state-of-the-art label noise method.",
          "link": "http://arxiv.org/abs/2308.01609",
          "publishedOn": "2023-08-05T00:48:26.731Z",
          "wordCount": null,
          "title": "Feature Noise Boosts DNN Generalization under Label Noise. (arXiv:2308.01609v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01546",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Ke Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yusong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haohe Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nezhurina_M/0/1/0/all/0/1\">Marianna Nezhurina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_Kirkpatrick_T/0/1/0/all/0/1\">Taylor Berg-Kirkpatrick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubnov_S/0/1/0/all/0/1\">Shlomo Dubnov</a>",
          "description": "Diffusion models have shown promising results in cross-modal generation\ntasks, including text-to-image and text-to-audio generation. However,\ngenerating music, as a special type of audio, presents unique challenges due to\nlimited availability of music data and sensitive issues related to copyright\nand plagiarism. In this paper, to tackle these challenges, we first construct a\nstate-of-the-art text-to-music model, MusicLDM, that adapts Stable Diffusion\nand AudioLDM architectures to the music domain. We achieve this by retraining\nthe contrastive language-audio pretraining model (CLAP) and the Hifi-GAN\nvocoder, as components of MusicLDM, on a collection of music data samples.\nThen, to address the limitations of training data and to avoid plagiarism, we\nleverage a beat tracking model and propose two different mixup strategies for\ndata augmentation: beat-synchronous audio mixup and beat-synchronous latent\nmixup, which recombine training audio directly or via a latent embeddings\nspace, respectively. Such mixup strategies encourage the model to interpolate\nbetween musical training samples and generate new music within the convex hull\nof the training data, making the generated music more diverse while still\nstaying faithful to the corresponding style. In addition to popular evaluation\nmetrics, we design several new evaluation metrics based on CLAP score to\ndemonstrate that our proposed MusicLDM and beat-synchronous mixup strategies\nimprove both the quality and novelty of generated music, as well as the\ncorrespondence between input text and generated music.",
          "link": "http://arxiv.org/abs/2308.01546",
          "publishedOn": "2023-08-05T00:48:26.725Z",
          "wordCount": null,
          "title": "MusicLDM: Enhancing Novelty in Text-to-Music Generation Using Beat-Synchronous Mixup Strategies. (arXiv:2308.01546v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Badrinath_C/0/1/0/all/0/1\">Charumathi Badrinath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1\">Weiwei Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1\">Finale Doshi-Velez</a>",
          "description": "A common way to explore text corpora is through low-dimensional projections\nof the documents, where one hopes that thematically similar documents will be\nclustered together in the projected space. However, popular algorithms for\ndimensionality reduction of text corpora, like Latent Dirichlet Allocation\n(LDA), often produce projections that do not capture human notions of document\nsimilarity. We propose a semi-supervised human-in-the-loop LDA-based method for\nlearning topics that preserve semantically meaningful relationships between\ndocuments in low-dimensional projections. On synthetic corpora, our method\nyields more interpretable projections than baseline methods with only a\nfraction of labels provided. On a real corpus, we obtain qualitatively similar\nresults.",
          "link": "http://arxiv.org/abs/2308.01420",
          "publishedOn": "2023-08-05T00:48:26.716Z",
          "wordCount": null,
          "title": "SAP-sLDA: An Interpretable Interface for Exploring Unstructured Text. (arXiv:2308.01420v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01905",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xinglong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponce_J/0/1/0/all/0/1\">Jean Ponce</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Xiong Wang</a>",
          "description": "Depth completion, which aims to generate high-quality dense depth maps from\nsparse depth maps, has attracted increasing attention in recent years. Previous\nwork usually employs RGB images as guidance, and introduces iterative spatial\npropagation to refine estimated coarse depth maps. However, most of the\npropagation refinement methods require several iterations and suffer from a\nfixed receptive field, which may contain irrelevant and useless information\nwith very sparse input. In this paper, we address these two challenges\nsimultaneously by revisiting the idea of deformable convolution. We propose an\neffective architecture that leverages deformable kernel convolution as a\nsingle-pass refinement module, and empirically demonstrate its superiority. To\nbetter understand the function of deformable convolution and exploit it for\ndepth completion, we further systematically investigate a variety of\nrepresentative strategies. Our study reveals that, different from prior work,\ndeformable convolution needs to be applied on an estimated depth map with a\nrelatively high density for better performance. We evaluate our model on the\nlarge-scale KITTI dataset and achieve state-of-the-art level performance in\nboth accuracy and inference speed. Our code is available at\nhttps://github.com/AlexSunNik/ReDC.",
          "link": "http://arxiv.org/abs/2308.01905",
          "publishedOn": "2023-08-05T00:48:26.712Z",
          "wordCount": null,
          "title": "Revisiting Deformable Convolution for Depth Completion. (arXiv:2308.01905v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2207.10276",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_R/0/1/0/all/0/1\">Ruixuan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yiwen Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haobo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1\">Lei Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1\">Runze Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Gang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Junbo Zhao</a>",
          "description": "Learning with Noisy Labels (LNL) has become an appealing topic, as\nimperfectly annotated data are relatively cheaper to obtain. Recent\nstate-of-the-art approaches employ specific selection mechanisms to separate\nclean and noisy samples and then apply Semi-Supervised Learning (SSL)\ntechniques for improved performance. However, the selection step mostly\nprovides a medium-sized and decent-enough clean subset, which overlooks a rich\nset of clean samples. To fulfill this, we propose a novel LNL framework ProMix\nthat attempts to maximize the utility of clean samples for boosted performance.\nKey to our method, we propose a matched high confidence selection technique\nthat selects those examples with high confidence scores and matched predictions\nwith given labels to dynamically expand a base clean sample set. To overcome\nthe potential side effect of excessive clean set selection procedure, we\nfurther devise a novel SSL framework that is able to train balanced and\nunbiased classifiers on the separated clean and noisy samples. Extensive\nexperiments demonstrate that ProMix significantly advances the current\nstate-of-the-art results on multiple benchmarks with different types and levels\nof noise. It achieves an average improvement of 2.48\\% on the CIFAR-N dataset.\nThe code is available at https://github.com/Justherozen/ProMix",
          "link": "http://arxiv.org/abs/2207.10276",
          "publishedOn": "2023-08-05T00:48:26.711Z",
          "wordCount": null,
          "title": "ProMix: Combating Label Noise via Maximizing Clean Sample Utility. (arXiv:2207.10276v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01682",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Borile_C/0/1/0/all/0/1\">Claudio Borile</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perotti_A/0/1/0/all/0/1\">Alan Perotti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panisson_A/0/1/0/all/0/1\">Andr&#xe9; Panisson</a>",
          "description": "Graph Machine Learning (GML) has numerous applications, such as node/graph\nclassification and link prediction, in real-world domains. Providing\nhuman-understandable explanations for GML models is a challenging yet\nfundamental task to foster their adoption, but validating explanations for link\nprediction models has received little attention. In this paper, we provide\nquantitative metrics to assess the quality of link prediction explanations,\nwith or without ground-truth. State-of-the-art explainability methods for Graph\nNeural Networks are evaluated using these metrics. We discuss how underlying\nassumptions and technical details specific to the link prediction task, such as\nthe choice of distance between node embeddings, can influence the quality of\nthe explanations.",
          "link": "http://arxiv.org/abs/2308.01682",
          "publishedOn": "2023-08-05T00:48:26.710Z",
          "wordCount": null,
          "title": "Evaluating Link Prediction Explanations for Graph Neural Networks. (arXiv:2308.01682v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01508",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pham_M/0/1/0/all/0/1\">Minh Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marshall_K/0/1/0/all/0/1\">Kelly O. Marshall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hegde_C/0/1/0/all/0/1\">Chinmay Hegde</a>",
          "description": "Text-to-image generative models can produce photo-realistic images for an\nextremely broad range of concepts, and their usage has proliferated widely\namong the general public. On the flip side, these models have numerous\ndrawbacks, including their potential to generate images featuring sexually\nexplicit content, mirror artistic styles without permission, or even\nhallucinate (or deepfake) the likenesses of celebrities. Consequently, various\nmethods have been proposed in order to \"erase\" sensitive concepts from\ntext-to-image models. In this work, we examine five recently proposed concept\nerasure methods, and show that targeted concepts are not fully excised from any\nof these methods. Specifically, we leverage the existence of special learned\nword embeddings that can retrieve \"erased\" concepts from the sanitized models\nwith no alterations to their weights. Our results highlight the brittleness of\npost hoc concept erasure methods, and call into question their use in the\nalgorithmic toolkit for AI safety.",
          "link": "http://arxiv.org/abs/2308.01508",
          "publishedOn": "2023-08-05T00:48:26.704Z",
          "wordCount": null,
          "title": "Circumventing Concept Erasure Methods For Text-to-Image Generative Models. (arXiv:2308.01508v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sakhi_O/0/1/0/all/0/1\">Otmane Sakhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rohde_D/0/1/0/all/0/1\">David Rohde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chopin_N/0/1/0/all/0/1\">Nicolas Chopin</a>",
          "description": "An increasingly important building block of large scale machine learning\nsystems is based on returning slates; an ordered lists of items given a query.\nApplications of this technology include: search, information retrieval and\nrecommender systems. When the action space is large, decision systems are\nrestricted to a particular structure to complete online queries quickly. This\npaper addresses the optimization of these large scale decision systems given an\narbitrary reward function. We cast this learning problem in a policy\noptimization framework and propose a new class of policies, born from a novel\nrelaxation of decision functions. This results in a simple, yet efficient\nlearning algorithm that scales to massive action spaces. We compare our method\nto the commonly adopted Plackett-Luce policy class and demonstrate the\neffectiveness of our approach on problems with action space sizes in the order\nof millions.",
          "link": "http://arxiv.org/abs/2308.01566",
          "publishedOn": "2023-08-05T00:48:26.703Z",
          "wordCount": null,
          "title": "Fast Slate Policy Optimization: Going Beyond Plackett-Luce. (arXiv:2308.01566v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01327",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wagner_L/0/1/0/all/0/1\">Laurin Wagner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zusag_M/0/1/0/all/0/1\">Mario Zusag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bloder_T/0/1/0/all/0/1\">Theresa Bloder</a>",
          "description": "This paper presents a fully automated approach for identifying speech\nanomalies from voice recordings to aid in the assessment of speech impairments.\nBy combining Connectionist Temporal Classification (CTC) and\nencoder-decoder-based automatic speech recognition models, we generate rich\nacoustic and clean transcripts. We then apply several natural language\nprocessing methods to extract features from these transcripts to produce\nprototypes of healthy speech. Basic distance measures from these prototypes\nserve as input features for standard machine learning classifiers, yielding\nhuman-level accuracy for the distinction between recordings of people with\naphasia and a healthy control group. Furthermore, the most frequently occurring\naphasia types can be distinguished with 90% accuracy. The pipeline is directly\napplicable to other diseases and languages, showing promise for robustly\nextracting diagnostic speech biomarkers.",
          "link": "http://arxiv.org/abs/2308.01327",
          "publishedOn": "2023-08-05T00:48:26.701Z",
          "wordCount": null,
          "title": "Careful Whisper -- leveraging advances in automatic speech recognition for robust and interpretable aphasia subtype classification. (arXiv:2308.01327v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01650",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zou_M/0/1/0/all/0/1\">Minhao Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1\">Zhongxue Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yutong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_D/0/1/0/all/0/1\">Dongyan Sui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1\">Chun Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leng_S/0/1/0/all/0/1\">Siyang Leng</a>",
          "description": "Graph and hypergraph representation learning has attracted increasing\nattention from various research fields. Despite the decent performance and\nfruitful applications of Graph Neural Networks (GNNs), Hypergraph Neural\nNetworks (HGNNs), and their well-designed variants, on some commonly used\nbenchmark graphs and hypergraphs, they are outperformed by even a simple\nMulti-Layer Perceptron. This observation motivates a reexamination of the\ndesign paradigm of the current GNNs and HGNNs and poses challenges of\nextracting graph features effectively. In this work, a universal feature\nencoder for both graph and hypergraph representation learning is designed,\ncalled UniG-Encoder. The architecture starts with a forward transformation of\nthe topological relationships of connected nodes into edge or hyperedge\nfeatures via a normalized projection matrix. The resulting edge/hyperedge\nfeatures, together with the original node features, are fed into a neural\nnetwork. The encoded node embeddings are then derived from the reversed\ntransformation, described by the transpose of the projection matrix, of the\nnetwork's output, which can be further used for tasks such as node\nclassification. The proposed architecture, in contrast to the traditional\nspectral-based and/or message passing approaches, simultaneously and\ncomprehensively exploits the node features and graph/hypergraph topologies in\nan efficient and unified manner, covering both heterophilic and homophilic\ngraphs. The designed projection matrix, encoding the graph features, is\nintuitive and interpretable. Extensive experiments are conducted and\ndemonstrate the superior performance of the proposed framework on twelve\nrepresentative hypergraph datasets and six real-world graph datasets, compared\nto the state-of-the-art methods. Our implementation is available online at\nhttps://github.com/MinhZou/UniG-Encoder.",
          "link": "http://arxiv.org/abs/2308.01650",
          "publishedOn": "2023-08-05T00:48:26.695Z",
          "wordCount": null,
          "title": "UniG-Encoder: A Universal Feature Encoder for Graph and Hypergraph Node Classification. (arXiv:2308.01650v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.11435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yuwei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ochiai_H/0/1/0/all/0/1\">Hideya Ochiai</a>",
          "description": "Visual Question Answering (VQA) based on multi-modal data facilitates\nreal-life applications such as home robots and medical diagnoses. One\nsignificant challenge is to devise a robust decentralized learning framework\nfor various client models where centralized data collection is refrained due to\nconfidentiality concerns. This work aims to tackle privacy-preserving VQA by\ndecoupling a multi-modal model into representation modules and a contrastive\nmodule and leveraging inter-module gradients sharing and inter-client weight\nsharing. To this end, we propose Bidirectional Contrastive Split Learning\n(BiCSL) to train a global multi-modal model on the entire data distribution of\ndecentralized clients. We employ the contrastive loss that enables a more\nefficient self-supervised learning of decentralized modules. Comprehensive\nexperiments are conducted on the VQA-v2 dataset based on five SOTA VQA models,\ndemonstrating the effectiveness of the proposed method. Furthermore, we inspect\nBiCSL's robustness against a dual-key backdoor attack on VQA. Consequently,\nBiCSL shows much better robustness to the multi-modal adversarial attack\ncompared to the centralized learning method, which provides a promising\napproach to decentralized multi-modal learning.",
          "link": "http://arxiv.org/abs/2208.11435",
          "publishedOn": "2023-08-05T00:48:26.687Z",
          "wordCount": null,
          "title": "Bidirectional Contrastive Split Learning for Visual Question Answering. (arXiv:2208.11435v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01543",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhaumik_D/0/1/0/all/0/1\">Debosmita Bhaumik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1\">Julian Togelius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yannakakis_G/0/1/0/all/0/1\">Georgios N. Yannakakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalifa_A/0/1/0/all/0/1\">Ahmed Khalifa</a>",
          "description": "We explore AI-powered upscaling as a design assistance tool in the context of\ncreating 2D game levels. Deep neural networks are used to upscale artificially\ndownscaled patches of levels from the puzzle platformer game Lode Runner. The\ntrained networks are incorporated into a web-based editor, where the user can\ncreate and edit levels at three different levels of resolution: 4x4, 8x8, and\n16x16. An edit at any resolution instantly transfers to the other resolutions.\nAs upscaling requires inventing features that might not be present at lower\nresolutions, we train neural networks to reproduce these features. We introduce\na neural network architecture that is capable of not only learning upscaling\nbut also giving higher priority to less frequent tiles. To investigate the\npotential of this tool and guide further development, we conduct a qualitative\nstudy with 3 designers to understand how they use it. Designers enjoyed\nco-designing with the tool, liked its underlying concept, and provided feedback\nfor further improvement.",
          "link": "http://arxiv.org/abs/2308.01543",
          "publishedOn": "2023-08-05T00:48:26.686Z",
          "wordCount": null,
          "title": "Lode Enhancer: Level Co-creation Through Scaling. (arXiv:2308.01543v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01626",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Motogna_A/0/1/0/all/0/1\">Alexandru Motogna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Groza_A/0/1/0/all/0/1\">Adrian Groza</a>",
          "description": "An attractive book cover is important for the success of a book. In this\npaper, we apply Generative Adversarial Networks (GANs) to the book covers\ndomain, using different methods for training in order to obtain better\ngenerated images. We interleave GANs with knowledge graphs to alter the input\ntitle to obtain multiple possible options for any given title, which are then\nused as an augmented input to the generator. Finally, we use the discriminator\nobtained during the training phase to select the best images generated with new\ntitles. Our method performed better at generating book covers than previous\nattempts, and the knowledge graph gives better options to the book author or\neditor compared to using GANs alone.",
          "link": "http://arxiv.org/abs/2308.01626",
          "publishedOn": "2023-08-05T00:48:26.682Z",
          "wordCount": null,
          "title": "Interleaving GANs with knowledge graphs to support design creativity for book covers. (arXiv:2308.01626v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04577",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yuzhe Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1\">Binghao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wyk_K/0/1/0/all/0/1\">Karl Van Wyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hao Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chao_Y/0/1/0/all/0/1\">Yu-Wei Chao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fox_D/0/1/0/all/0/1\">Dieter Fox</a>",
          "description": "Vision-based teleoperation offers the possibility to endow robots with\nhuman-level intelligence to physically interact with the environment, while\nonly requiring low-cost camera sensors. However, current vision-based\nteleoperation systems are designed and engineered towards a particular robot\nmodel and deploy environment, which scales poorly as the pool of the robot\nmodels expands and the variety of the operating environment increases. In this\npaper, we propose AnyTeleop, a unified and general teleoperation system to\nsupport multiple different arms, hands, realities, and camera configurations\nwithin a single system. Although being designed to provide great flexibility to\nthe choice of simulators and real hardware, our system can still achieve great\nperformance. For real-world experiments, AnyTeleop can outperform a previous\nsystem that was designed for a specific robot hardware with a higher success\nrate, using the same robot. For teleoperation in simulation, AnyTeleop leads to\nbetter imitation learning performance, compared with a previous system that is\nparticularly designed for that simulator. Project page: this http URL",
          "link": "http://arxiv.org/abs/2307.04577",
          "publishedOn": "2023-08-05T00:48:26.680Z",
          "wordCount": null,
          "title": "AnyTeleop: A General Vision-Based Dexterous Robot Arm-Hand Teleoperation System. (arXiv:2307.04577v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01329",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junpeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeh_C/0/1/0/all/0/1\">Chin-Chia Michael Yeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yujie Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huiyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Zhang</a>",
          "description": "Embedding learning transforms discrete data entities into continuous\nnumerical representations, encoding features/properties of the entities.\nDespite the outstanding performance reported from different embedding learning\nalgorithms, few efforts were devoted to structurally interpreting how features\nare encoded in the learned embedding space. This work proposes EmbeddingTree, a\nhierarchical embedding exploration algorithm that relates the semantics of\nentity features with the less-interpretable embedding vectors. An interactive\nvisualization tool is also developed based on EmbeddingTree to explore\nhigh-dimensional embeddings. The tool helps users discover nuance features of\ndata entities, perform feature denoising/injecting in embedding training, and\ngenerate embeddings for unseen entities. We demonstrate the efficacy of\nEmbeddingTree and our visualization tool through embeddings generated for\nindustry-scale merchant data and the public 30Music listening/playlists\ndataset.",
          "link": "http://arxiv.org/abs/2308.01329",
          "publishedOn": "2023-08-05T00:48:26.679Z",
          "wordCount": null,
          "title": "EmbeddingTree: Hierarchical Exploration of Entity Features in Embedding. (arXiv:2308.01329v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01853",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chao_P/0/1/0/all/0/1\">Patrick Chao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dobriban_E/0/1/0/all/0/1\">Edgar Dobriban</a>",
          "description": "Distribution shifts are a serious concern in modern statistical learning as\nthey can systematically change the properties of the data away from the truth.\nWe focus on Wasserstein distribution shifts, where every data point may undergo\na slight perturbation, as opposed to the Huber contamination model where a\nfraction of observations are outliers. We formulate and study shifts beyond\nindependent perturbations, exploring Joint Distribution Shifts, where the\nper-observation perturbations can be coordinated. We analyze several important\nstatistical problems, including location estimation, linear regression, and\nnon-parametric density estimation. Under a squared loss for mean estimation and\nprediction error in linear regression, we find the exact minimax risk, a least\nfavorable perturbation, and show that the sample mean and least squares\nestimators are respectively optimal. This holds for both independent and joint\nshifts, but the least favorable perturbations and minimax risks differ. For\nother problems, we provide nearly optimal estimators and precise finite-sample\nbounds. We also introduce several tools for bounding the minimax risk under\ndistribution shift, such as a smoothing technique for location families, and\ngeneralizations of classical tools including least favorable sequences of\npriors, the modulus of continuity, Le Cam's, Fano's, and Assouad's methods.",
          "link": "http://arxiv.org/abs/2308.01853",
          "publishedOn": "2023-08-05T00:48:26.678Z",
          "wordCount": null,
          "title": "Statistical Estimation Under Distribution Shift: Wasserstein Perturbations and Minimax Theory. (arXiv:2308.01853v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2003.08904",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weber_M/0/1/0/all/0/1\">Maurice Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaojun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karlas_B/0/1/0/all/0/1\">Bojan Karla&#x161;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Ce Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Recent studies have shown that deep neural networks (DNNs) are vulnerable to\nadversarial attacks, including evasion and backdoor (poisoning) attacks. On the\ndefense side, there have been intensive efforts on improving both empirical and\nprovable robustness against evasion attacks; however, the provable robustness\nagainst backdoor attacks still remains largely unexplored. In this paper, we\nfocus on certifying the machine learning model robustness against general\nthreat models, especially backdoor attacks. We first provide a unified\nframework via randomized smoothing techniques and show how it can be\ninstantiated to certify the robustness against both evasion and backdoor\nattacks. We then propose the first robust training process, RAB, to smooth the\ntrained model and certify its robustness against backdoor attacks. We prove the\nrobustness bound for machine learning models trained with RAB and prove that\nour robustness bound is tight. In addition, we theoretically show that it is\npossible to train the robust smoothed models efficiently for simple models such\nas K-nearest neighbor classifiers, and we propose an exact smooth-training\nalgorithm that eliminates the need to sample from a noise distribution for such\nmodels. Empirically, we conduct comprehensive experiments for different machine\nlearning (ML) models such as DNNs, support vector machines, and K-NN models on\nMNIST, CIFAR-10, and ImageNette datasets and provide the first benchmark for\ncertified robustness against backdoor attacks. In addition, we evaluate K-NN\nmodels on a spambase tabular dataset to demonstrate the advantages of the\nproposed exact algorithm. Both the theoretic analysis and the comprehensive\nevaluation on diverse ML models and datasets shed light on further robust\nlearning strategies against general training time attacks.",
          "link": "http://arxiv.org/abs/2003.08904",
          "publishedOn": "2023-08-05T00:48:26.677Z",
          "wordCount": null,
          "title": "RAB: Provable Robustness Against Backdoor Attacks. (arXiv:2003.08904v8 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01621",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_H/0/1/0/all/0/1\">Hang Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_B/0/1/0/all/0/1\">Bing Bai</a>",
          "description": "This paper introduces a new Convolutional Neural Network (ConvNet)\narchitecture inspired by a class of partial differential equations (PDEs)\ncalled quasi-linear hyperbolic systems. With comparable performance on image\nclassification task, it allows for the modification of the weights via a\ncontinuous group of symmetry. This is a significant shift from traditional\nmodels where the architecture and weights are essentially fixed. We wish to\npromote the (internal) symmetry as a new desirable property for a neural\nnetwork, and to draw attention to the PDE perspective in analyzing and\ninterpreting ConvNets in the broader Deep Learning community.",
          "link": "http://arxiv.org/abs/2308.01621",
          "publishedOn": "2023-08-05T00:48:26.672Z",
          "wordCount": null,
          "title": "A Novel Convolutional Neural Network Architecture with a Continuous Symmetry. (arXiv:2308.01621v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.02096",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Cindy Y. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cen_S/0/1/0/all/0/1\">Sarah H. Cen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_D/0/1/0/all/0/1\">Devavrat Shah</a>",
          "description": "In recent years, multiple notions of algorithmic fairness have arisen. One\nsuch notion is individual fairness (IF), which requires that individuals who\nare similar receive similar treatment. In parallel, matrix estimation (ME) has\nemerged as a natural paradigm for handling noisy data with missing values. In\nthis work, we connect the two concepts. We show that pre-processing data using\nME can improve an algorithm's IF without sacrificing performance. Specifically,\nwe show that using a popular ME method known as singular value thresholding\n(SVT) to pre-process the data provides a strong IF guarantee under appropriate\nconditions. We then show that, under analogous conditions, SVT pre-processing\nalso yields estimates that are consistent and approximately minimax optimal. As\nsuch, the ME pre-processing step does not, under the stated conditions,\nincrease the prediction error of the base algorithm, i.e., does not impose a\nfairness-performance trade-off. We verify these results on synthetic and real\ndata.",
          "link": "http://arxiv.org/abs/2302.02096",
          "publishedOn": "2023-08-05T00:48:26.667Z",
          "wordCount": null,
          "title": "Matrix Estimation for Individual Fairness. (arXiv:2302.02096v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jialiang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhiyang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xiaodong Shi</a>",
          "description": "Preprints play an increasingly critical role in academic communities. There\nare many reasons driving researchers to post their manuscripts to preprint\nservers before formal submission to journals or conferences, but the use of\npreprints has also sparked considerable controversy, especially surrounding the\nclaim of priority. In this paper, a case study of computer science preprints\nsubmitted to arXiv from 2008 to 2017 is conducted to quantify how many\npreprints have eventually been printed in peer-reviewed venues. Among those\npublished manuscripts, some are published under different titles and without an\nupdate to their preprints on arXiv. In the case of these manuscripts, the\ntraditional fuzzy matching method is incapable of mapping the preprint to the\nfinal published version. In view of this issue, we introduce a semantics-based\nmapping method with the employment of Bidirectional Encoder Representations\nfrom Transformers (BERT). With this new mapping method and a plurality of data\nsources, we find that 66% of all sampled preprints are published under\nunchanged titles and 11% are published under different titles and with other\nmodifications. A further analysis was then performed to investigate why these\npreprints but not others were accepted for publication. Our comparison reveals\nthat in the field of computer science, published preprints feature adequate\nrevisions, multiple authorship, detailed abstract and introduction, extensive\nand authoritative references and available source code.",
          "link": "http://arxiv.org/abs/2308.01899",
          "publishedOn": "2023-08-05T00:48:26.666Z",
          "wordCount": null,
          "title": "How many preprints have actually been printed and why: a case study of computer science preprints on arXiv. (arXiv:2308.01899v1 [cs.DL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01814",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Greg Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Littwin_E/0/1/0/all/0/1\">Etai Littwin</a>",
          "description": "Going beyond stochastic gradient descent (SGD), what new phenomena emerge in\nwide neural networks trained by adaptive optimizers like Adam? Here we show:\nThe same dichotomy between feature learning and kernel behaviors (as in SGD)\nholds for general optimizers as well, including Adam -- albeit with a nonlinear\nnotion of \"kernel.\" We derive the corresponding \"neural tangent\" and \"maximal\nupdate\" limits for any architecture. Two foundational advances underlie the\nabove results: 1) A new Tensor Program language, NEXORT, that can express how\nadaptive optimizers process gradients into updates. 2) The introduction of\nbra-ket notation to drastically simplify expressions and calculations in Tensor\nPrograms. This work summarizes and generalizes all previous results in the\nTensor Programs series of papers.",
          "link": "http://arxiv.org/abs/2308.01814",
          "publishedOn": "2023-08-05T00:48:26.662Z",
          "wordCount": null,
          "title": "Tensor Programs IVb: Adaptive Optimization in the Infinite-Width Limit. (arXiv:2308.01814v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.03110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Emukpere_D/0/1/0/all/0/1\">David Emukpere</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alameda_Pineda_X/0/1/0/all/0/1\">Xavier Alameda-Pineda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reinke_C/0/1/0/all/0/1\">Chris Reinke</a>",
          "description": "A longstanding goal in reinforcement learning is to build intelligent agents\nthat show fast learning and a flexible transfer of skills akin to humans and\nanimals. This paper investigates the integration of two frameworks for tackling\nthose goals: episodic control and successor features. Episodic control is a\ncognitively inspired approach relying on episodic memory, an instance-based\nmemory model of an agent's experiences. Meanwhile, successor features and\ngeneralized policy improvement (SF&GPI) is a meta and transfer learning\nframework allowing to learn policies for tasks that can be efficiently reused\nfor later tasks which have a different reward function. Individually, these two\ntechniques have shown impressive results in vastly improving sample efficiency\nand the elegant reuse of previously learned policies. Thus, we outline a\ncombination of both approaches in a single reinforcement learning framework and\nempirically illustrate its benefits.",
          "link": "http://arxiv.org/abs/2111.03110",
          "publishedOn": "2023-08-05T00:48:26.661Z",
          "wordCount": null,
          "title": "Successor Feature Neural Episodic Control. (arXiv:2111.03110v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.03606",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Tyralis_H/0/1/0/all/0/1\">Hristos Tyralis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Papacharalampous_G/0/1/0/all/0/1\">Georgia Papacharalampous</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Doulamis_N/0/1/0/all/0/1\">Nikolaos Doulamis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Doulamis_A/0/1/0/all/0/1\">Anastasios Doulamis</a>",
          "description": "Knowing the actual precipitation in space and time is critical in\nhydrological modelling applications, yet the spatial coverage with rain gauge\nstations is limited due to economic constraints. Gridded satellite\nprecipitation datasets offer an alternative option for estimating the actual\nprecipitation by covering uniformly large areas, albeit related estimates are\nnot accurate. To improve precipitation estimates, machine learning is applied\nto merge rain gauge-based measurements and gridded satellite precipitation\nproducts. In this context, observed precipitation plays the role of the\ndependent variable, while satellite data play the role of predictor variables.\nRandom forests is the dominant machine learning algorithm in relevant\napplications. In those spatial predictions settings, point predictions (mostly\nthe mean or the median of the conditional distribution) of the dependent\nvariable are issued. The aim of the manuscript is to solve the problem of\nprobabilistic prediction of precipitation with an emphasis on extreme quantiles\nin spatial interpolation settings. Here we propose, issuing probabilistic\nspatial predictions of precipitation using Light Gradient Boosting Machine\n(LightGBM). LightGBM is a boosting algorithm, highlighted by prize-winning\nentries in prediction and forecasting competitions. To assess LightGBM, we\ncontribute a large-scale application that includes merging daily precipitation\nmeasurements in contiguous US with PERSIANN and GPM-IMERG satellite\nprecipitation data. We focus on extreme quantiles of the probability\ndistribution of the dependent variable, where LightGBM outperforms quantile\nregression forests (QRF, a variant of random forests) in terms of quantile\nscore at extreme quantiles. Our study offers understanding of probabilistic\npredictions in spatial settings using machine learning.",
          "link": "http://arxiv.org/abs/2302.03606",
          "publishedOn": "2023-08-05T00:48:26.660Z",
          "wordCount": null,
          "title": "Merging satellite and gauge-measured precipitation using LightGBM with an emphasis on extreme quantiles. (arXiv:2302.03606v2 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16174",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Battiloro_C/0/1/0/all/0/1\">Claudio Battiloro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spinelli_I/0/1/0/all/0/1\">Indro Spinelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Telyatnikov_L/0/1/0/all/0/1\">Lev Telyatnikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bronstein_M/0/1/0/all/0/1\">Michael Bronstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scardapane_S/0/1/0/all/0/1\">Simone Scardapane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lorenzo_P/0/1/0/all/0/1\">Paolo Di Lorenzo</a>",
          "description": "Latent Graph Inference (LGI) relaxed the reliance of Graph Neural Networks\n(GNNs) on a given graph topology by dynamically learning it. However, most of\nLGI methods assume to have a (noisy, incomplete, improvable, ...) input graph\nto rewire and can solely learn regular graph topologies. In the wake of the\nsuccess of Topological Deep Learning (TDL), we study Latent Topology Inference\n(LTI) for learning higher-order cell complexes (with sparse and not regular\ntopology) describing multi-way interactions between data points. To this aim,\nwe introduce the Differentiable Cell Complex Module (DCM), a novel learnable\nfunction that computes cell probabilities in the complex to improve the\ndownstream task. We show how to integrate DCM with cell complex message passing\nnetworks layers and train it in a end-to-end fashion, thanks to a two-step\ninference procedure that avoids an exhaustive search across all possible cells\nin the input, thus maintaining scalability. Our model is tested on several\nhomophilic and heterophilic graph datasets and it is shown to outperform other\nstate-of-the-art techniques, offering significant improvements especially in\ncases where an input graph is not provided.",
          "link": "http://arxiv.org/abs/2305.16174",
          "publishedOn": "2023-08-05T00:48:26.656Z",
          "wordCount": null,
          "title": "From Latent Graph to Latent Topology Inference: Differentiable Cell Complex Module. (arXiv:2305.16174v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01445",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Torzoni_M/0/1/0/all/0/1\">Matteo Torzoni</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tezzele_M/0/1/0/all/0/1\">Marco Tezzele</a>, <a href=\"http://arxiv.org/find/math/1/au:+Mariani_S/0/1/0/all/0/1\">Stefano Mariani</a>, <a href=\"http://arxiv.org/find/math/1/au:+Manzoni_A/0/1/0/all/0/1\">Andrea Manzoni</a>, <a href=\"http://arxiv.org/find/math/1/au:+Willcox_K/0/1/0/all/0/1\">Karen E. Willcox</a>",
          "description": "The digital twin concept represents an appealing opportunity to advance\ncondition-based and predictive maintenance paradigms for civil engineering\nsystems, thus allowing reduced lifecycle costs, increased system safety, and\nincreased system availability. This work proposes a predictive digital twin\napproach to the health monitoring, maintenance, and management planning of\ncivil engineering structures. The asset-twin coupled dynamical system is\nencoded employing a probabilistic graphical model, which allows all relevant\nsources of uncertainty to be taken into account. In particular, the\ntime-repeating observations-to-decisions flow is modeled using a dynamic\nBayesian network. Real-time structural health diagnostics are provided by\nassimilating sensed data with deep learning models. The digital twin state is\ncontinually updated in a sequential Bayesian inference fashion. This is then\nexploited to inform the optimal planning of maintenance and management actions\nwithin a dynamic decision-making framework. A preliminary offline phase\ninvolves the population of training datasets through a reduced-order numerical\nmodel and the computation of a health-dependent control policy. The strategy is\nassessed on two synthetic case studies, involving a cantilever beam and a\nrailway bridge, demonstrating the dynamic decision-making capabilities of\nhealth-aware digital twins.",
          "link": "http://arxiv.org/abs/2308.01445",
          "publishedOn": "2023-08-05T00:48:26.652Z",
          "wordCount": null,
          "title": "A digital twin framework for civil engineering structures. (arXiv:2308.01445v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01552",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Po-Lin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1\">Cheng-Shang Chang</a>",
          "description": "This research paper delves into the integration of OpenAI's ChatGPT into\nembodied agent systems, evaluating its influence on interactive decision-making\nbenchmark. Drawing a parallel to the concept of people assuming roles according\nto their unique strengths, we introduce InterAct. In this approach, we feed\nChatGPT with varied prompts, assigning it a numerous roles like a checker and a\nsorter, then integrating them with the original language model. Our research\nshows a remarkable success rate of 98% in AlfWorld, which consists of 6\ndifferent tasks in a simulated household environment, emphasizing the\nsignificance of proficient prompt engineering. The results highlight ChatGPT's\ncompetence in comprehending and performing intricate tasks effectively in\nreal-world settings, thus paving the way for further advancements in task\nplanning.",
          "link": "http://arxiv.org/abs/2308.01552",
          "publishedOn": "2023-08-05T00:48:26.641Z",
          "wordCount": null,
          "title": "InterAct: Exploring the Potentials of ChatGPT as a Cooperative Agent. (arXiv:2308.01552v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01834",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Galatzer_Levy_I/0/1/0/all/0/1\">Isaac R. Galatzer-Levy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McDuff_D/0/1/0/all/0/1\">Daniel McDuff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Natarajan_V/0/1/0/all/0/1\">Vivek Natarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karthikesalingam_A/0/1/0/all/0/1\">Alan Karthikesalingam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malgaroli_M/0/1/0/all/0/1\">Matteo Malgaroli</a>",
          "description": "The current work investigates the capability of Large language models (LLMs)\nthat are explicitly trained on large corpuses of medical knowledge (Med-PaLM 2)\nto predict psychiatric functioning from patient interviews and clinical\ndescriptions without being trained to do so. To assess this, n = 145 depression\nand n =115 PTSD assessments and n = 46 clinical case studies across high\nprevalence/high comorbidity disorders (Depressive, Anxiety, Psychotic, trauma\nand stress, Addictive disorders) were analyzed using prompts to extract\nestimated clinical scores and diagnoses. Results demonstrate that Med-PaLM 2 is\ncapable of assessing psychiatric functioning across a range of psychiatric\nconditions with the strongest performance being the prediction of depression\nscores based on standardized assessments (Accuracy range= 0.80 - 0.84) which\nwere statistically indistinguishable from human clinical raters t(1,144) =\n1.20; p = 0.23. Results show the potential for general clinical language models\nto flexibly predict psychiatric risk based on free descriptions of functioning\nfrom both patients and clinicians.",
          "link": "http://arxiv.org/abs/2308.01834",
          "publishedOn": "2023-08-05T00:48:26.641Z",
          "wordCount": null,
          "title": "The Capability of Large Language Models to Measure Psychiatric Functioning. (arXiv:2308.01834v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01602",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Franco_N/0/1/0/all/0/1\">Nicola Rares Franco</a>, <a href=\"http://arxiv.org/find/math/1/au:+Fresca_S/0/1/0/all/0/1\">Stefania Fresca</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tombari_F/0/1/0/all/0/1\">Filippo Tombari</a>, <a href=\"http://arxiv.org/find/math/1/au:+Manzoni_A/0/1/0/all/0/1\">Andrea Manzoni</a>",
          "description": "Mesh-based simulations play a key role when modeling complex physical systems\nthat, in many disciplines across science and engineering, require the solution\nof parametrized time-dependent nonlinear partial differential equations (PDEs).\nIn this context, full order models (FOMs), such as those relying on the finite\nelement method, can reach high levels of accuracy, however often yielding\nintensive simulations to run. For this reason, surrogate models are developed\nto replace computationally expensive solvers with more efficient ones, which\ncan strike favorable trade-offs between accuracy and efficiency. This work\nexplores the potential usage of graph neural networks (GNNs) for the simulation\nof time-dependent PDEs in the presence of geometrical variability. In\nparticular, we propose a systematic strategy to build surrogate models based on\na data-driven time-stepping scheme where a GNN architecture is used to\nefficiently evolve the system. With respect to the majority of surrogate\nmodels, the proposed approach stands out for its ability of tackling problems\nwith parameter dependent spatial domains, while simultaneously generalizing to\ndifferent geometries and mesh resolutions. We assess the effectiveness of the\nproposed approach through a series of numerical experiments, involving both\ntwo- and three-dimensional problems, showing that GNNs can provide a valid\nalternative to traditional surrogate models in terms of computational\nefficiency and generalization to new scenarios. We also assess, from a\nnumerical standpoint, the importance of using GNNs, rather than classical dense\ndeep neural networks, for the proposed framework.",
          "link": "http://arxiv.org/abs/2308.01602",
          "publishedOn": "2023-08-05T00:48:26.622Z",
          "wordCount": null,
          "title": "Deep Learning-based surrogate models for parametrized PDEs: handling geometric variability through graph neural networks. (arXiv:2308.01602v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+geng_Z/0/1/0/all/0/1\">Zhiqiang Kou jing wang yuheng jia xin geng</a>",
          "description": "Label Distribution Learning (LDL) is a novel machine learning paradigm that\nassigns label distribution to each instance. Many LDL methods proposed to\nleverage label correlation in the learning process to solve the\nexponential-sized output space; among these, many exploited the low-rank\nstructure of label distribution to capture label correlation. However, recent\nstudies disclosed that label distribution matrices are typically full-rank,\nposing challenges to those works exploiting low-rank label correlation. Note\nthat multi-label is generally low-rank; low-rank label correlation is widely\nadopted in multi-label learning (MLL) literature. Inspired by that, we\nintroduce an auxiliary MLL process in LDL and capture low-rank label\ncorrelation on that MLL rather than LDL. In such a way, low-rank label\ncorrelation is appropriately exploited in our LDL methods. We conduct\ncomprehensive experiments and demonstrate that our methods are superior to\nexisting LDL methods. Besides, the ablation studies justify the advantages of\nexploiting low-rank label correlation in the auxiliary MLL.",
          "link": "http://arxiv.org/abs/2308.01742",
          "publishedOn": "2023-08-05T00:48:26.617Z",
          "wordCount": null,
          "title": "Exploiting Multi-Label Correlation in Label Distribution Learning. (arXiv:2308.01742v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01481",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Roy_A/0/1/0/all/0/1\">Abhishek Roy</a>, <a href=\"http://arxiv.org/find/math/1/au:+Balasubramanian_K/0/1/0/all/0/1\">Krishnakumar Balasubramanian</a>",
          "description": "We study the online overlapping batch-means covariance estimator for\nStochastic Gradient Descent (SGD) under Markovian sampling. We show that the\nconvergence rates of the covariance estimator are\n$O\\big(\\sqrt{d}\\,n^{-1/8}(\\log n)^{1/4}\\big)$ and\n$O\\big(\\sqrt{d}\\,n^{-1/8}\\big)$ under state-dependent and state-independent\nMarkovian sampling, respectively, with $d$ representing dimensionality and $n$\ndenoting the number of observations or SGD iterations. Remarkably, these rates\nmatch the best-known convergence rate previously established for the\nindependent and identically distributed ($\\iid$) case by \\cite{zhu2021online},\nup to logarithmic factors. Our analysis overcomes significant challenges that\narise due to Markovian sampling, leading to the introduction of additional\nerror terms and complex dependencies between the blocks of the batch-means\ncovariance estimator. Moreover, we establish the convergence rate for the first\nfour moments of the $\\ell_2$ norm of the error of SGD dynamics under\nstate-dependent Markovian data, which holds potential interest as an\nindependent result. To validate our theoretical findings, we provide numerical\nillustrations to derive confidence intervals for SGD when training linear and\nlogistic regression models under Markovian sampling. Additionally, we apply our\napproach to tackle the intriguing problem of strategic classification with\nlogistic regression, where adversaries can adaptively modify features during\nthe training process to increase their chances of being classified in a\nspecific target class.",
          "link": "http://arxiv.org/abs/2308.01481",
          "publishedOn": "2023-08-05T00:48:26.610Z",
          "wordCount": null,
          "title": "Online covariance estimation for stochastic gradient descent under Markovian sampling. (arXiv:2308.01481v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01677",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Garber_D/0/1/0/all/0/1\">Dan Garber</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kaplan_A/0/1/0/all/0/1\">Atara Kaplan</a>",
          "description": "We consider convex relaxations for recovering low-rank tensors based on\nconstrained minimization over a ball induced by the tensor nuclear norm,\nrecently introduced in \\cite{tensor_tSVD}. We build on a recent line of results\nthat considered convex relaxations for the recovery of low-rank matrices and\nestablished that under a strict complementarity condition (SC), both the\nconvergence rate and per-iteration runtime of standard gradient methods may\nimprove dramatically. We develop the appropriate strict complementarity\ncondition for the tensor nuclear norm ball and obtain the following main\nresults under this condition: 1. When the objective to minimize is of the form\n$f(\\mX)=g(\\mA\\mX)+\\langle{\\mC,\\mX}\\rangle$ , where $g$ is strongly convex and\n$\\mA$ is a linear map (e.g., least squares), a quadratic growth bound holds,\nwhich implies linear convergence rates for standard projected gradient methods,\ndespite the fact that $f$ need not be strongly convex. 2. For a smooth\nobjective function, when initialized in certain proximity of an optimal\nsolution which satisfies SC, standard projected gradient methods only require\nSVD computations (for projecting onto the tensor nuclear norm ball) of rank\nthat matches the tubal rank of the optimal solution. In particular, when the\ntubal rank is constant, this implies nearly linear (in the size of the tensor)\nruntime per iteration, as opposed to super linear without further assumptions.\n3. For a nonsmooth objective function which admits a popular smooth\nsaddle-point formulation, we derive similar results to the latter for the well\nknown extragradient method. An additional contribution which may be of\nindependent interest, is the rigorous extension of many basic results regarding\ntensors of arbitrary order, which were previously obtained only for third-order\ntensors.",
          "link": "http://arxiv.org/abs/2308.01677",
          "publishedOn": "2023-08-05T00:48:26.604Z",
          "wordCount": null,
          "title": "Efficiency of First-Order Methods for Low-Rank Tensor Recovery with the Tensor Nuclear Norm Under Strict Complementarity. (arXiv:2308.01677v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01358",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Philippenko_C/0/1/0/all/0/1\">Constantin Philippenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dieuleveut_A/0/1/0/all/0/1\">Aymeric Dieuleveut</a>",
          "description": "In this paper, we investigate the impact of compression on stochastic\ngradient algorithms for machine learning, a technique widely used in\ndistributed and federated learning. We underline differences in terms of\nconvergence rates between several unbiased compression operators, that all\nsatisfy the same condition on their variance, thus going beyond the classical\nworst-case analysis. To do so, we focus on the case of least-squares regression\n(LSR) and analyze a general stochastic approximation algorithm for minimizing\nquadratic functions relying on a random field. We consider weak assumptions on\nthe random field, tailored to the analysis (specifically, expected H\\\"older\nregularity), and on the noise covariance, enabling the analysis of various\nrandomizing mechanisms, including compression. We then extend our results to\nthe case of federated learning.\n\nMore formally, we highlight the impact on the convergence of the covariance\n$\\mathfrak{C}_{\\mathrm{ania}}$ of the additive noise induced by the algorithm.\nWe demonstrate despite the non-regularity of the stochastic field, that the\nlimit variance term scales with $\\mathrm{Tr}(\\mathfrak{C}_{\\mathrm{ania}}\nH^{-1})/K$ (where $H$ is the Hessian of the optimization problem and $K$ the\nnumber of iterations) generalizing the rate for the vanilla LSR case where it\nis $\\sigma^2 \\mathrm{Tr}(H H^{-1}) / K = \\sigma^2 d / K$ (Bach and Moulines,\n2013). Then, we analyze the dependency of $\\mathfrak{C}_{\\mathrm{ania}}$ on the\ncompression strategy and ultimately its impact on convergence, first in the\ncentralized case, then in two heterogeneous FL frameworks.",
          "link": "http://arxiv.org/abs/2308.01358",
          "publishedOn": "2023-08-05T00:48:26.599Z",
          "wordCount": null,
          "title": "Compressed and distributed least-squares regression: convergence rates with applications to Federated Learning. (arXiv:2308.01358v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.14720",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Read_J/0/1/0/all/0/1\">Jesse Read</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zliobaite_I/0/1/0/all/0/1\">Indr&#x117; &#x17d;liobait&#x117;</a>",
          "description": "The literature on machine learning in the context of data streams is vast and\ngrowing. However, many of the defining assumptions regarding data-stream\nlearning tasks are too strong to hold in practice, or are even contradictory\nsuch that they cannot be met in the contexts of supervised learning. Algorithms\nare chosen and designed based on criteria which are often not clearly stated,\nfor problem settings not clearly defined, tested in unrealistic settings,\nand/or in isolation from related approaches in the wider literature. This puts\ninto question the potential for real-world impact of many approaches conceived\nin such contexts, and risks propagating a misguided research focus. We propose\nto tackle these issues by reformulating the fundamental definitions and\nsettings of supervised data-stream learning with regard to contemporary\nconsiderations of concept drift and temporal dependence; and we take a fresh\nlook at what constitutes a supervised data-stream learning task, and a\nreconsideration of algorithms that may be applied to tackle such tasks. Through\nand in reflection of this formulation and overview, helped by an informal\nsurvey of industrial players dealing with real-world data streams, we provide\nrecommendations. Our main emphasis is that learning from data streams does not\nimpose a single-pass or online-learning approach, or any particular learning\nregime; and any constraints on memory and time are not specific to streaming.\nMeanwhile, there exist established techniques for dealing with temporal\ndependence and concept drift, in other areas of the literature. For the data\nstreams community, we thus encourage a shift in research focus, from dealing\nwith often-artificial constraints and assumptions on the learning mode, to\nissues such as robustness, privacy, and interpretability which are increasingly\nrelevant to learning in data streams in academic and industrial settings.",
          "link": "http://arxiv.org/abs/2212.14720",
          "publishedOn": "2023-08-05T00:48:26.592Z",
          "wordCount": null,
          "title": "Learning from Data Streams: An Overview and Update. (arXiv:2212.14720v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01867",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Manohara_M/0/1/0/all/0/1\">Manasa Manohara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dayal_S/0/1/0/all/0/1\">Sankalp Dayal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Afzal_T/0/1/0/all/0/1\">Tarqi Afzal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bakshi_R/0/1/0/all/0/1\">Rahul Bakshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_K/0/1/0/all/0/1\">Kahkuen Fu</a>",
          "description": "Despite the proliferation of diverse hardware accelerators (e.g., NPU, TPU,\nDPU), deploying deep learning models on edge devices with fixed-point hardware\nis still challenging due to complex model quantization and conversion. Existing\nmodel quantization frameworks like Tensorflow QAT [1], TFLite PTQ [2], and\nQualcomm AIMET [3] supports only a limited set of quantization schemes (e.g.,\nonly asymmetric per-tensor quantization in TF1.x QAT [4]). Accordingly, deep\nlearning models cannot be easily quantized for diverse fixed-point hardwares,\nmainly due to slightly different quantization requirements. In this paper, we\nenvision a new type of model quantization approach called MRQ (model\nre-quantization), which takes existing quantized models and quickly transforms\nthe models to meet different quantization requirements (e.g., asymmetric ->\nsymmetric, non-power-of-2 scale -> power-of-2 scale). Re-quantization is much\nsimpler than quantizing from scratch because it avoids costly re-training and\nprovides support for multiple quantization schemes simultaneously. To minimize\nre-quantization error, we developed a new set of re-quantization algorithms\nincluding weight correction and rounding error folding. We have demonstrated\nthat MobileNetV2 QAT model [7] can be quickly re-quantized into two different\nquantization schemes (i.e., symmetric and symmetric+power-of-2 scale) with less\nthan 0.64 units of accuracy loss. We believe our work is the first to leverage\nthis concept of re-quantization for model quantization and models obtained from\nthe re-quantization process have been successfully deployed on NNA in the Echo\nShow devices.",
          "link": "http://arxiv.org/abs/2308.01867",
          "publishedOn": "2023-08-05T00:48:26.580Z",
          "wordCount": null,
          "title": "MRQ:Support Multiple Quantization Schemes through Model Re-Quantization. (arXiv:2308.01867v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01891",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kiser_S/0/1/0/all/0/1\">Shawn L. Kiser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guskov_M/0/1/0/all/0/1\">Mikhail Guskov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rebillat_M/0/1/0/all/0/1\">Marc R&#xe9;billat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranc_N/0/1/0/all/0/1\">Nicolas Ranc</a>",
          "description": "Identification of nonlinear dynamical systems has been popularized by sparse\nidentification of the nonlinear dynamics (SINDy) via the sequentially\nthresholded least squares (STLS) algorithm. Many extensions SINDy have emerged\nin the literature to deal with experimental data which are finite in length and\nnoisy. Recently, the computationally intensive method of ensembling\nbootstrapped SINDy models (E-SINDy) was proposed for model identification,\nhandling finite, highly noisy data. While the extensions of SINDy are numerous,\ntheir sparsity-promoting estimators occasionally provide sparse approximations\nof the dynamics as opposed to exact recovery. Furthermore, these estimators\nsuffer under multicollinearity, e.g. the irrepresentable condition for the\nLasso. In this paper, we demonstrate that the Trimmed Lasso for robust\nidentification of models (TRIM) can provide exact recovery under more severe\nnoise, finite data, and multicollinearity as opposed to E-SINDy. Additionally,\nthe computational cost of TRIM is asymptotically equal to STLS since the\nsparsity parameter of the TRIM can be solved efficiently by convex solvers. We\ncompare these methodologies on challenging nonlinear systems, specifically the\nLorenz 63 system, the Bouc Wen oscillator from the nonlinear dynamics benchmark\nof No\\\"el and Schoukens, 2016, and a time delay system describing tool cutting\ndynamics. This study emphasizes the comparisons between STLS, reweighted\n$\\ell_1$ minimization, and Trimmed Lasso in identification with respect to\nproblems faced by practitioners: the problem of finite and noisy data, the\nperformance of the sparse regression of when the library grows in dimension\n(multicollinearity), and automatic methods for choice of regularization\nparameters.",
          "link": "http://arxiv.org/abs/2308.01891",
          "publishedOn": "2023-08-05T00:48:26.575Z",
          "wordCount": null,
          "title": "Exact identification of nonlinear dynamical systems by Trimmed Lasso. (arXiv:2308.01891v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01868",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Gonzalez_Abad_J/0/1/0/all/0/1\">Jose Gonz&#xe1;lez-Abad</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Hernandez_Garcia_A/0/1/0/all/0/1\">&#xc1;lex Hern&#xe1;ndez-Garc&#xed;a</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Harder_P/0/1/0/all/0/1\">Paula Harder</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Rolnick_D/0/1/0/all/0/1\">David Rolnick</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gutierrez_J/0/1/0/all/0/1\">Jos&#xe9; Manuel Guti&#xe9;rrez</a>",
          "description": "Global Climate Models (GCMs) are the primary tool to simulate climate\nevolution and assess the impacts of climate change. However, they often operate\nat a coarse spatial resolution that limits their accuracy in reproducing\nlocal-scale phenomena. Statistical downscaling methods leveraging deep learning\noffer a solution to this problem by approximating local-scale climate fields\nfrom coarse variables, thus enabling regional GCM projections. Typically,\nclimate fields of different variables of interest are downscaled independently,\nresulting in violations of fundamental physical properties across\ninterconnected variables. This study investigates the scope of this problem\nand, through an application on temperature, lays the foundation for a framework\nintroducing multi-variable hard constraints that guarantees physical\nrelationships between groups of downscaled climate variables.",
          "link": "http://arxiv.org/abs/2308.01868",
          "publishedOn": "2023-08-05T00:48:26.568Z",
          "wordCount": null,
          "title": "Multi-variable Hard Physical Constraints for Climate Model Downscaling. (arXiv:2308.01868v1 [physics.ao-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01404",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+OGara_A/0/1/0/all/0/1\">Aidan O&#x27;Gara</a>",
          "description": "Are current language models capable of deception and lie detection? We study\nthis question by introducing a text-based game called $\\textit{Hoodwinked}$,\ninspired by $\\textit{Mafia}$ and $\\textit{Among Us}$. Players are locked in a\nhouse and must find a key to escape, but one player is tasked with killing the\nothers. Each time a murder is committed, the surviving players have a natural\nlanguage discussion then vote to banish one player from the game. We conduct\nexperiments with agents controlled by GPT-3, GPT-3.5, and GPT-4 and find\nevidence of deception and lie detection capabilities. The killer often denies\ntheir crime and accuses others, leading to measurable effects on voting\noutcomes. More advanced models are more effective killers, outperforming\nsmaller models in 18 of 24 pairwise comparisons. Secondary metrics provide\nevidence that this improvement is not mediated by different actions, but rather\nby stronger deception capabilities during discussions. Overall, we find\nsubstantial evidence that current language models are capable of deception. To\nbetter evaluate the ability of AI agents to deceive humans, we make this game\npublicly available at https://hoodwinked.ai/ .",
          "link": "http://arxiv.org/abs/2308.01404",
          "publishedOn": "2023-08-05T00:48:26.557Z",
          "wordCount": null,
          "title": "Hoodwinked: Deception and Cooperation in a Text-Based Game for Language Models. (arXiv:2308.01404v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01438",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mohammadshirazi_A/0/1/0/all/0/1\">Ahmad Mohammadshirazi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nadafian_A/0/1/0/all/0/1\">Aida Nadafian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monsefi_A/0/1/0/all/0/1\">Amin Karimi Monsefi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rafiei_M/0/1/0/all/0/1\">Mohammad H. Rafiei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramnath_R/0/1/0/all/0/1\">Rajiv Ramnath</a>",
          "description": "Cost-effective sensors are capable of real-time capturing a variety of air\nquality-related modalities from different pollutant concentrations to\nindoor/outdoor humidity and temperature. Machine learning (ML) models are\ncapable of performing air-quality \"ahead-of-time\" approximations. Undoubtedly,\naccurate indoor air quality approximation significantly helps provide a healthy\nindoor environment, optimize associated energy consumption, and offer human\ncomfort. However, it is crucial to design an ML architecture to capture the\ndomain knowledge, so-called problem physics. In this study, we propose six\nnovel physics-based ML models for accurate indoor pollutant concentration\napproximations. The proposed models include an adroit combination of\nstate-space concepts in physics, Gated Recurrent Units, and Decomposition\ntechniques. The proposed models were illustrated using data collected from five\noffices in a commercial building in California. The proposed models are shown\nto be less complex, computationally more efficient, and more accurate than\nsimilar state-of-the-art transformer-based models. The superiority of the\nproposed models is due to their relatively light architecture (computational\nefficiency) and, more importantly, their ability to capture the underlying\nhighly nonlinear patterns embedded in the often contaminated sensor-collected\nindoor air quality temporal data.",
          "link": "http://arxiv.org/abs/2308.01438",
          "publishedOn": "2023-08-05T00:48:26.550Z",
          "wordCount": null,
          "title": "Novel Physics-Based Machine-Learning Models for Indoor Air Quality Approximations. (arXiv:2308.01438v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01573",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ko_M/0/1/0/all/0/1\">Myeongjin Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yong-Hoon Choi</a>",
          "description": "The diffusion model is capable of generating high-quality data through a\nprobabilistic approach. However, it suffers from the drawback of slow\ngeneration speed due to the requirement of a large number of time steps. To\naddress this limitation, recent models such as denoising diffusion implicit\nmodels (DDIM) focus on generating samples without directly modeling the\nprobability distribution, while models like denoising diffusion generative\nadversarial networks (GAN) combine diffusion processes with GANs. In the field\nof speech synthesis, a recent diffusion speech synthesis model called\nDiffGAN-TTS, utilizing the structure of GANs, has been introduced and\ndemonstrates superior performance in both speech quality and generation speed.\nIn this paper, to further enhance the performance of DiffGAN-TTS, we propose a\nspeech synthesis model with two discriminators: a diffusion discriminator for\nlearning the distribution of the reverse process and a spectrogram\ndiscriminator for learning the distribution of the generated data. Objective\nmetrics such as structural similarity index measure (SSIM), mel-cepstral\ndistortion (MCD), F0 root mean squared error (F0 RMSE), short-time objective\nintelligibility (STOI), perceptual evaluation of speech quality (PESQ), as well\nas subjective metrics like mean opinion score (MOS), are used to evaluate the\nperformance of the proposed model. The evaluation results show that the\nproposed model outperforms recent state-of-the-art models such as FastSpeech2\nand DiffGAN-TTS in various metrics. Our implementation and audio samples are\nlocated on GitHub.",
          "link": "http://arxiv.org/abs/2308.01573",
          "publishedOn": "2023-08-05T00:48:26.540Z",
          "wordCount": null,
          "title": "Adversarial Training of Denoising Diffusion Model Using Dual Discriminators for High-Fidelity Multi-Speaker TTS. (arXiv:2308.01573v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.04934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1\">Jinghan Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiancheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ram_P/0/1/0/all/0/1\">Parikshit Ram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuguang Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Gaowen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1\">Pranay Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sijia Liu</a>",
          "description": "In response to recent data regulation requirements, machine unlearning (MU)\nhas emerged as a critical process to remove the influence of specific examples\nfrom a given model. Although exact unlearning can be achieved through complete\nmodel retraining using the remaining dataset, the associated computational\ncosts have driven the development of efficient, approximate unlearning\ntechniques. Moving beyond data-centric MU approaches, our study introduces a\nnovel model-based perspective: model sparsification via weight pruning, which\nis capable of reducing the gap between exact unlearning and approximate\nunlearning. We show in both theory and practice that model sparsity can boost\nthe multi-criteria unlearning performance of an approximate unlearner, closing\nthe approximation gap, while continuing to be efficient. This leads to a new MU\nparadigm, termed prune first, then unlearn, which infuses a sparse model prior\ninto the unlearning process. Building on this insight, we also develop a\nsparsity-aware unlearning method that utilizes sparsity regularization to\nenhance the training process of approximate unlearning. Extensive experiments\nshow that our proposals consistently benefit MU in various unlearning\nscenarios. A notable highlight is the 77% unlearning efficacy gain of\nfine-tuning (one of the simplest unlearning methods) when using sparsity-aware\nunlearning. Furthermore, we demonstrate the practical impact of our proposed MU\nmethods in addressing other machine learning challenges, such as defending\nagainst backdoor attacks and enhancing transfer learning. Codes are available\nat https://github.com/OPTML-Group/Unlearn-Sparse.",
          "link": "http://arxiv.org/abs/2304.04934",
          "publishedOn": "2023-08-05T00:48:26.522Z",
          "wordCount": null,
          "title": "Model Sparsity Can Simplify Machine Unlearning. (arXiv:2304.04934v7 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bonetta_G/0/1/0/all/0/1\">Giovanni Bonetta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zago_D/0/1/0/all/0/1\">Davide Zago</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cancelliere_R/0/1/0/all/0/1\">Rossella Cancelliere</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grosso_A/0/1/0/all/0/1\">Andrea Grosso</a>",
          "description": "Job scheduling is a well-known Combinatorial Optimization problem with\nendless applications. Well planned schedules bring many benefits in the context\nof automated systems: among others, they limit production costs and waste.\nNevertheless, the NP-hardness of this problem makes it essential to use\nheuristics whose design is difficult, requires specialized knowledge and often\nproduces methods tailored to the specific task. This paper presents an original\nend-to-end Deep Reinforcement Learning approach to scheduling that\nautomatically learns dispatching rules. Our technique is inspired by natural\nlanguage encoder-decoder models for sequence processing and has never been\nused, to the best of our knowledge, for scheduling purposes. We applied and\ntested our method in particular to some benchmark instances of Job Shop\nProblem, but this technique is general enough to be potentially used to tackle\nother different optimal job scheduling tasks with minimal intervention. Results\ndemonstrate that we outperform many classical approaches exploiting priority\ndispatching rules and show competitive results on state-of-the-art Deep\nReinforcement Learning ones.",
          "link": "http://arxiv.org/abs/2308.01797",
          "publishedOn": "2023-08-05T00:48:26.507Z",
          "wordCount": null,
          "title": "Job Shop Scheduling via Deep Reinforcement Learning: a Sequence to Sequence approach. (arXiv:2308.01797v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01557",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_J/0/1/0/all/0/1\">Joao Carvalho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_A/0/1/0/all/0/1\">An T. Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baierl_M/0/1/0/all/0/1\">Mark Baierl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koert_D/0/1/0/all/0/1\">Dorothea Koert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1\">Jan Peters</a>",
          "description": "Learning priors on trajectory distributions can help accelerate robot motion\nplanning optimization. Given previously successful plans, learning trajectory\ngenerative models as priors for a new planning problem is highly desirable.\nPrior works propose several ways on utilizing this prior to bootstrapping the\nmotion planning problem. Either sampling the prior for initializations or using\nthe prior distribution in a maximum-a-posterior formulation for trajectory\noptimization. In this work, we propose learning diffusion models as priors. We\nthen can sample directly from the posterior trajectory distribution conditioned\non task goals, by leveraging the inverse denoising process of diffusion models.\nFurthermore, diffusion has been recently shown to effectively encode data\nmultimodality in high-dimensional settings, which is particularly well-suited\nfor large trajectory dataset. To demonstrate our method efficacy, we compare\nour proposed method - Motion Planning Diffusion - against several baselines in\nsimulated planar robot and 7-dof robot arm manipulator environments. To assess\nthe generalization capabilities of our method, we test it in environments with\npreviously unseen obstacles. Our experiments show that diffusion models are\nstrong priors to encode high-dimensional trajectory distributions of robot\nmotions.",
          "link": "http://arxiv.org/abs/2308.01557",
          "publishedOn": "2023-08-05T00:48:26.488Z",
          "wordCount": null,
          "title": "Motion Planning Diffusion: Learning and Planning of Robot Motions with Diffusion Models. (arXiv:2308.01557v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01835",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tamas_A/0/1/0/all/0/1\">Ambrus Tam&#xe1;s</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Csaji_B/0/1/0/all/0/1\">Bal&#xe1;zs Csan&#xe1;d Cs&#xe1;ji</a>",
          "description": "One of the key objects of binary classification is the regression function,\ni.e., the conditional expectation of the class labels given the inputs. With\nthe regression function not only a Bayes optimal classifier can be defined, but\nit also encodes the corresponding misclassification probabilities. The paper\npresents a resampling framework to construct exact, distribution-free and\nnon-asymptotically guaranteed confidence regions for the true regression\nfunction for any user-chosen confidence level. Then, specific algorithms are\nsuggested to demonstrate the framework. It is proved that the constructed\nconfidence regions are strongly consistent, that is, any false model is\nexcluded in the long run with probability one. The exclusion is quantified with\nprobably approximately correct type bounds, as well. Finally, the algorithms\nare validated via numerical experiments, and the methods are compared to\napproximate asymptotic confidence ellipsoids.",
          "link": "http://arxiv.org/abs/2308.01835",
          "publishedOn": "2023-08-05T00:48:26.474Z",
          "wordCount": null,
          "title": "Distribution-Free Inference for the Regression Function of Binary Classification. (arXiv:2308.01835v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01490",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Puning Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_L/0/1/0/all/0/1\">Lifeng Lai</a>",
          "description": "$Q$ learning is a popular model free reinforcement learning method. Most of\nexisting works focus on analyzing $Q$ learning for finite state and action\nspaces. If the state space is continuous, then the original $Q$ learning method\ncan not be directly used. A modification of the original $Q$ learning method\nwas proposed in (Shah and Xie, 2018), which estimates $Q$ values with nearest\nneighbors. Such modification makes $Q$ learning suitable for continuous state\nspace. (Shah and Xie, 2018) shows that the convergence rate of estimated $Q$\nfunction is $\\tilde{O}(T^{-1/(d+3)})$, which is slower than the minimax lower\nbound $\\tilde{\\Omega}(T^{-1/(d+2)})$, indicating that this method is not\nefficient. This paper proposes two new $Q$ learning methods to bridge the gap\nof convergence rates in (Shah and Xie, 2018), with one of them being offline,\nwhile the other is online. Despite that we still use nearest neighbor approach\nto estimate $Q$ function, the algorithms are crucially different from (Shah and\nXie, 2018). In particular, we replace the kernel nearest neighbor in\ndiscretized region with a direct nearest neighbor approach. Consequently, our\napproach significantly improves the convergence rate. Moreover, the time\ncomplexity is also significantly improved in high dimensional state spaces. Our\nanalysis shows that both offline and online methods are minimax rate optimal.",
          "link": "http://arxiv.org/abs/2308.01490",
          "publishedOn": "2023-08-05T00:48:26.460Z",
          "wordCount": null,
          "title": "Minimax Optimal $Q$ Learning with Nearest Neighbors. (arXiv:2308.01490v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01536",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Na_S/0/1/0/all/0/1\">Sanghyeon Na</a>",
          "description": "Face swapping is a task that changes a facial identity of a given image to\nthat of another person. In this work, we propose a novel face-swapping\nframework called Megapixel Facial Identity Manipulation (MFIM). The\nface-swapping model should achieve two goals. First, it should be able to\ngenerate a high-quality image. We argue that a model which is proficient in\ngenerating a megapixel image can achieve this goal. However, generating a\nmegapixel image is generally difficult without careful model design. Therefore,\nour model exploits pretrained StyleGAN in the manner of GAN-inversion to\neffectively generate a megapixel image. Second, it should be able to\neffectively transform the identity of a given image. Specifically, it should be\nable to actively transform ID attributes (e.g., face shape and eyes) of a given\nimage into those of another person, while preserving ID-irrelevant attributes\n(e.g., pose and expression). To achieve this goal, we exploit 3DMM that can\ncapture various facial attributes. Specifically, we explicitly supervise our\nmodel to generate a face-swapped image with the desirable attributes using\n3DMM. We show that our model achieves state-of-the-art performance through\nextensive experiments. Furthermore, we propose a new operation called ID\nmixing, which creates a new identity by semantically mixing the identities of\nseveral people. It allows the user to customize the new identity.",
          "link": "http://arxiv.org/abs/2308.01536",
          "publishedOn": "2023-08-05T00:48:26.454Z",
          "wordCount": null,
          "title": "MFIM: Megapixel Facial Identity Manipulation. (arXiv:2308.01536v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01421",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agliari_E/0/1/0/all/0/1\">Elena Agliari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aquaro_M/0/1/0/all/0/1\">Miriam Aquaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alemanno_F/0/1/0/all/0/1\">Francesco Alemanno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fachechi_A/0/1/0/all/0/1\">Alberto Fachechi</a>",
          "description": "In this work we approach attractor neural networks from a machine learning\nperspective: we look for optimal network parameters by applying a gradient\ndescent over a regularized loss function. Within this framework, the optimal\nneuron-interaction matrices turn out to be a class of matrices which correspond\nto Hebbian kernels revised by iteratively applying some unlearning protocols.\nRemarkably, the number of unlearning steps is proved to be related to the\nregularization hyperparameters of the loss function and to the training time.\nThus, we can design strategies to avoid overfitting that are formulated in\nterms of the algebraic properties of the interaction matrix, or, equivalently,\nin terms of regularization tuning and early-stopping strategies. The\ngeneralization capabilities of these attractor networks are also investigated:\nanalytical results are obtained for random synthetic datasets, next, the\nemerging picture is corroborated by numerical experiments that highlight the\nexistence of several regimes (i.e., overfitting, failure and success) as the\ndataset parameters are varied.",
          "link": "http://arxiv.org/abs/2308.01421",
          "publishedOn": "2023-08-05T00:48:26.249Z",
          "wordCount": null,
          "title": "Regularization, early-stopping and dreaming: a Hopfield-like setup to address generalization and overfitting. (arXiv:2308.01421v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.04370",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yingqiang Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1\">Wenyue Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_K/0/1/0/all/0/1\">Kai Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1\">Jianchao Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1\">Juntao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zelong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>",
          "description": "Human intelligence excels at combining basic skills to solve complex tasks.\nThis capability is vital for Artificial Intelligence (AI) and should be\nembedded in comprehensive intelligent models, enabling them to harness expert\nmodels for complex task-solving towards Artificial General Intelligence (AGI).\nLarge Language Models (LLMs) show promising learning and reasoning abilities,\nand can effectively use external models, tools or APIs to tackle complex\nproblems. In this work, we introduce OpenAGI, an open-source AGI research\nplatform designed for multi-step, real-world tasks. Specifically, OpenAGI uses\na dual strategy, integrating standard benchmark tasks for benchmarking and\nevaluation, and open-ended tasks including more expandable models, tools or\nAPIs for creative problem-solving. Tasks are presented as natural language\nqueries to the LLM, which then selects and executes appropriate models. We also\npropose a Reinforcement Learning from Task Feedback (RLTF) mechanism that uses\ntask results to improve the LLM's ability, which creates a self-improving AI\nfeedback loop. While we acknowledge that AGI is a broad and multifaceted\nresearch challenge with no singularly defined solution path, the integration of\nLLMs with domain-specific expert models, inspired by mirroring the blend of\ngeneral and specialized intelligence in humans, offers a promising approach\ntowards AGI. We are open-sourcing the OpenAGI project's code, dataset,\nbenchmarks, evaluation methods, and demo to foster community involvement in AGI\nadvancement: https://github.com/agiresearch/OpenAGI.",
          "link": "http://arxiv.org/abs/2304.04370",
          "publishedOn": "2023-08-05T00:48:26.047Z",
          "wordCount": 773,
          "title": "OpenAGI: When LLM Meets Domain Experts. (arXiv:2304.04370v5 [cs.AI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01379",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tabellion_E/0/1/0/all/0/1\">Eric Tabellion</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karnad_N/0/1/0/all/0/1\">Nikhil Karnad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glaser_N/0/1/0/all/0/1\">Noa Glaser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weiss_B/0/1/0/all/0/1\">Ben Weiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobs_D/0/1/0/all/0/1\">David E. Jacobs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pritch_Y/0/1/0/all/0/1\">Yael Pritch</a>",
          "description": "Long exposure photography produces stunning imagery, representing moving\nelements in a scene with motion-blur. It is generally employed in two\nmodalities, producing either a foreground or a background blur effect.\nForeground blur images are traditionally captured on a tripod-mounted camera\nand portray blurred moving foreground elements, such as silky water or light\ntrails, over a perfectly sharp background landscape. Background blur images,\nalso called panning photography, are captured while the camera is tracking a\nmoving subject, to produce an image of a sharp subject over a background\nblurred by relative motion. Both techniques are notoriously challenging and\nrequire additional equipment and advanced skills. In this paper, we describe a\ncomputational burst photography system that operates in a hand-held smartphone\ncamera app, and achieves these effects fully automatically, at the tap of the\nshutter button. Our approach first detects and segments the salient subject. We\ntrack the scene motion over multiple frames and align the images in order to\npreserve desired sharpness and to produce aesthetically pleasing motion\nstreaks. We capture an under-exposed burst and select the subset of input\nframes that will produce blur trails of controlled length, regardless of scene\nor camera motion velocity. We predict inter-frame motion and synthesize\nmotion-blur to fill the temporal gaps between the input frames. Finally, we\ncomposite the blurred image with the sharp regular exposure to protect the\nsharpness of faces or areas of the scene that are barely moving, and produce a\nfinal high resolution and high dynamic range (HDR) photograph. Our system\ndemocratizes a capability previously reserved to professionals, and makes this\ncreative style accessible to most casual photographers.\n\nMore information and supplementary material can be found on our project\nwebpage: https://motion-mode.github.io/",
          "link": "http://arxiv.org/abs/2308.01379",
          "publishedOn": "2023-08-05T00:48:25.989Z",
          "wordCount": 815,
          "title": "Computational Long Exposure Mobile Photography. (arXiv:2308.01379v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.10741",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yang Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kargarandehkordi_A/0/1/0/all/0/1\">Ali Kargarandehkordi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mutlu_O/0/1/0/all/0/1\">Onur Cezmi Mutlu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Surabhi_S/0/1/0/all/0/1\">Saimourya Surabhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Honarmand_M/0/1/0/all/0/1\">Mohammadmahdi Honarmand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wall_D/0/1/0/all/0/1\">Dennis Paul Wall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Washington_P/0/1/0/all/0/1\">Peter Washington</a>",
          "description": "Emotions play an essential role in human communication. Developing computer\nvision models for automatic recognition of emotion expression can aid in a\nvariety of domains, including robotics, digital behavioral healthcare, and\nmedia analytics. There are three types of emotional representations which are\ntraditionally modeled in affective computing research: Action Units, Valence\nArousal (VA), and Categorical Emotions. As part of an effort to move beyond\nthese representations towards more fine-grained labels, we describe our\nsubmission to the newly introduced Emotional Reaction Intensity (ERI)\nEstimation challenge in the 5th competition for Affective Behavior Analysis\nin-the-Wild (ABAW). We developed four deep neural networks trained in the\nvisual domain and a multimodal model trained with both visual and audio\nfeatures to predict emotion reaction intensity. Our best performing model on\nthe Hume-Reaction dataset achieved an average Pearson correlation coefficient\nof 0.4080 on the test set using a pre-trained ResNet50 model. This work\nprovides a first step towards the development of production-grade models which\npredict emotion reaction intensities rather than discrete emotion categories.",
          "link": "http://arxiv.org/abs/2303.10741",
          "publishedOn": "2023-08-05T00:48:25.982Z",
          "wordCount": 704,
          "title": "Computer Vision Estimation of Emotion Reaction Intensity in the Wild. (arXiv:2303.10741v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01731",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tothova_K/0/1/0/all/0/1\">Katar&#xed;na T&#xf3;thov&#xe1;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ladicky_L/0/1/0/all/0/1\">&#x13d;ubor Ladick&#xfd;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thul_D/0/1/0/all/0/1\">Daniel Thul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pollefeys_M/0/1/0/all/0/1\">Marc Pollefeys</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konukoglu_E/0/1/0/all/0/1\">Ender Konukoglu</a>",
          "description": "Predictive variability due to data ambiguities has typically been addressed\nvia construction of dedicated models with built-in probabilistic capabilities\nthat are trained to predict uncertainty estimates as variables of interest.\nThese approaches require distinct architectural components and training\nmechanisms, may include restrictive assumptions and exhibit overconfidence,\ni.e., high confidence in imprecise predictions. In this work, we propose a\npost-hoc sampling strategy for estimating predictive uncertainty accounting for\ndata ambiguity. The method can generate different plausible outputs for a given\ninput and does not assume parametric forms of predictive distributions. It is\narchitecture agnostic and can be applied to any feed-forward deterministic\nnetwork without changes to the architecture or training procedure. Experiments\non regression tasks on imaging and non-imaging input data show the method's\nability to generate diverse and multi-modal predictive distributions, and a\ndesirable correlation of the estimated uncertainty with the prediction error.",
          "link": "http://arxiv.org/abs/2308.01731",
          "publishedOn": "2023-08-05T00:48:25.976Z",
          "wordCount": 673,
          "title": "Quantification of Predictive Uncertainty via Inference-Time Sampling. (arXiv:2308.01731v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sa_J/0/1/0/all/0/1\">Jader Martins Camboim de S&#xe1;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanches_M/0/1/0/all/0/1\">Matheus Ferraroni Sanches</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Souza_R/0/1/0/all/0/1\">Rafael Roque de Souza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reis_J/0/1/0/all/0/1\">J&#xfa;lio Cesar dos Reis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Villas_L/0/1/0/all/0/1\">Leandro Aparecido Villas</a>",
          "description": "Fine-tuning language models in a downstream task is the standard approach for\nmany state-of-the-art methodologies in the field of NLP. However, when the\ndistribution between the source task and target task drifts, \\textit{e.g.},\nconversational environments, these gains tend to be diminished. This article\nproposes a sequence of pre-training steps (a curriculum) guided by \"data\nhacking\" and grammar analysis that allows further gradual adaptation between\npre-training distributions. In our experiments, we acquire a considerable\nimprovement from our method compared to other known pre-training approaches for\nthe MultiWoZ task.",
          "link": "http://arxiv.org/abs/2308.01849",
          "publishedOn": "2023-08-05T00:48:25.970Z",
          "wordCount": 599,
          "title": "Curricular Transfer Learning for Sentence Encoded Tasks. (arXiv:2308.01849v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.00788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yihua Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khanduri_P/0/1/0/all/0/1\">Prashant Khanduri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsaknakis_I/0/1/0/all/0/1\">Ioannis Tsaknakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuguang Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1\">Mingyi Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sijia Liu</a>",
          "description": "Recently, bi-level optimization (BLO) has taken center stage in some very\nexciting developments in the area of signal processing (SP) and machine\nlearning (ML). Roughly speaking, BLO is a classical optimization problem that\ninvolves two levels of hierarchy (i.e., upper and lower levels), wherein\nobtaining the solution to the upper-level problem requires solving the\nlower-level one. BLO has become popular largely because it is powerful in\nmodeling problems in SP and ML, among others, that involve optimizing nested\nobjective functions. Prominent applications of BLO range from resource\nallocation for wireless systems to adversarial machine learning. In this work,\nwe focus on a class of tractable BLO problems that often appear in SP and ML\napplications. We provide an overview of some basic concepts of this class of\nBLO problems, such as their optimality conditions, standard algorithms\n(including their optimization principles and practical implementations), as\nwell as how they can be leveraged to obtain state-of-the-art results for a\nnumber of key SP and ML applications. Further, we discuss some recent advances\nin BLO theory, its implications for applications, and point out some\nlimitations of the state-of-the-art that require significant future research\nefforts. Overall, we hope that this article can serve to accelerate the\nadoption of BLO as a generic tool to model, analyze, and innovate on a wide\narray of emerging SP and ML applications.",
          "link": "http://arxiv.org/abs/2308.00788",
          "publishedOn": "2023-08-05T00:48:25.938Z",
          "wordCount": 777,
          "title": "An Introduction to Bi-level Optimization: Foundations and Applications in Signal Processing and Machine Learning. (arXiv:2308.00788v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2208.13495",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xinyao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1\">Shengdong Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianrui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teng_F/0/1/0/all/0/1\">Fei Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yan Yang</a>",
          "description": "With the advent of the big data era, the data quality problem is becoming\nmore critical. Among many factors, data with missing values is one primary\nissue, and thus developing effective imputation models is a key topic in the\nresearch community. Recently, a major research direction is to employ neural\nnetwork models such as self-organizing mappings or automatic encoders for\nfilling missing values. However, these classical methods can hardly discover\ninterrelated features and common features simultaneously among data attributes.\nEspecially, it is a very typical problem for classical autoencoders that they\noften learn invalid constant mappings, which dramatically hurts the filling\nperformance. To solve the above-mentioned problems, we propose a\nmissing-value-filling model based on a feature-fusion-enhanced autoencoder. We\nfirst incorporate into an autoencoder a hidden layer that consists of\nde-tracking neurons and radial basis function neurons, which can enhance the\nability of learning interrelated features and common features. Besides, we\ndevelop a missing value filling strategy based on dynamic clustering that is\nincorporated into an iterative optimization process. This design can enhance\nthe multi-dimensional feature fusion ability and thus improves the dynamic\ncollaborative missing-value-filling performance. The effectiveness of the\nproposed model is validated by extensive experiments compared to a variety of\nbaseline methods on thirteen data sets.",
          "link": "http://arxiv.org/abs/2208.13495",
          "publishedOn": "2023-08-05T00:48:25.931Z",
          "wordCount": 741,
          "title": "A Missing Value Filling Model Based on Feature Fusion Enhanced Autoencoder. (arXiv:2208.13495v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.11883",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Journe_A/0/1/0/all/0/1\">Adrien Journ&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_H/0/1/0/all/0/1\">Hector Garcia Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1\">Qinghai Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moraitis_T/0/1/0/all/0/1\">Timoleon Moraitis</a>",
          "description": "Recent approximations to backpropagation (BP) have mitigated many of BP's\ncomputational inefficiencies and incompatibilities with biology, but important\nlimitations still remain. Moreover, the approximations significantly decrease\naccuracy in benchmarks, suggesting that an entirely different approach may be\nmore fruitful. Here, grounded on recent theory for Hebbian learning in soft\nwinner-take-all networks, we present multilayer SoftHebb, i.e. an algorithm\nthat trains deep neural networks, without any feedback, target, or error\nsignals. As a result, it achieves efficiency by avoiding weight transport,\nnon-local plasticity, time-locking of layer updates, iterative equilibria, and\n(self-) supervisory or other feedback signals -- which were necessary in other\napproaches. Its increased efficiency and biological compatibility do not trade\noff accuracy compared to state-of-the-art bio-plausible learning, but rather\nimprove it. With up to five hidden layers and an added linear classifier,\naccuracies on MNIST, CIFAR-10, STL-10, and ImageNet, respectively reach 99.4%,\n80.3%, 76.2%, and 27.3%. In conclusion, SoftHebb shows with a radically\ndifferent approach from BP that Deep Learning over few layers may be plausible\nin the brain and increases the accuracy of bio-plausible machine learning. Code\nis available at https://github.com/NeuromorphicComputing/SoftHebb.",
          "link": "http://arxiv.org/abs/2209.11883",
          "publishedOn": "2023-08-05T00:48:25.924Z",
          "wordCount": 728,
          "title": "Hebbian Deep Learning Without Feedback. (arXiv:2209.11883v2 [cs.NE] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01483",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mercier_A/0/1/0/all/0/1\">Antoine Mercier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erasmus_R/0/1/0/all/0/1\">Ruan Erasmus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savani_Y/0/1/0/all/0/1\">Yashesh Savani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhingra_M/0/1/0/all/0/1\">Manik Dhingra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Porikli_F/0/1/0/all/0/1\">Fatih Porikli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berger_G/0/1/0/all/0/1\">Guillaume Berger</a>",
          "description": "Real-time rendering for video games has become increasingly challenging due\nto the need for higher resolutions, framerates and photorealism. Supersampling\nhas emerged as an effective solution to address this challenge. Our work\nintroduces a novel neural algorithm for supersampling rendered content that is\n4 times more efficient than existing methods while maintaining the same level\nof accuracy. Additionally, we introduce a new dataset which provides auxiliary\nmodalities such as motion vectors and depth generated using graphics rendering\nfeatures like viewport jittering and mipmap biasing at different resolutions.\nWe believe that this dataset fills a gap in the current dataset landscape and\ncan serve as a valuable resource to help measure progress in the field and\nadvance the state-of-the-art in super-resolution techniques for gaming content.",
          "link": "http://arxiv.org/abs/2308.01483",
          "publishedOn": "2023-08-05T00:48:25.917Z",
          "wordCount": 658,
          "title": "Efficient neural supersampling on a novel gaming dataset. (arXiv:2308.01483v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.11429",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Streeter_M/0/1/0/all/0/1\">Matthew Streeter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dillon_J/0/1/0/all/0/1\">Joshua V. Dillon</a>",
          "description": "We present a new algorithm for automatically bounding the Taylor remainder\nseries. In the special case of a scalar function $f: \\mathbb{R} \\to\n\\mathbb{R}$, our algorithm takes as input a reference point $x_0$, trust region\n$[a, b]$, and integer $k \\ge 1$, and returns an interval $I$ such that $f(x) -\n\\sum_{i=0}^{k-1} \\frac {1} {i!} f^{(i)}(x_0) (x - x_0)^i \\in I (x - x_0)^k$ for\nall $x \\in [a, b]$. As in automatic differentiation, the function $f$ is\nprovided to the algorithm in symbolic form, and must be composed of known\natomic functions.\n\nAt a high level, our algorithm has two steps. First, for a variety of\ncommonly-used elementary functions (e.g., $\\exp$, $\\log$), we use\nrecently-developed theory to derive sharp polynomial upper and lower bounds on\nthe Taylor remainder series. We then recursively combine the bounds for the\nelementary functions using an interval arithmetic variant of Taylor-mode\nautomatic differentiation. Our algorithm can make efficient use of machine\nlearning hardware accelerators, and we provide an open source implementation in\nJAX.\n\nWe then turn our attention to applications. Most notably, in a companion\npaper we use our new machinery to create the first universal\nmajorization-minimization optimization algorithms: algorithms that iteratively\nminimize an arbitrary loss using a majorizer that is derived automatically,\nrather than by hand. We also show that our automatically-derived bounds can be\nused for verified global optimization and numerical integration, and to prove\nsharper versions of Jensen's inequality.",
          "link": "http://arxiv.org/abs/2212.11429",
          "publishedOn": "2023-08-05T00:48:25.889Z",
          "wordCount": 800,
          "title": "Automatically Bounding the Taylor Remainder Series: Tighter Bounds and New Applications. (arXiv:2212.11429v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01614",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gannamaneni_S/0/1/0/all/0/1\">Sujan Sai Gannamaneni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mock_M/0/1/0/all/0/1\">Michael Mock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akila_M/0/1/0/all/0/1\">Maram Akila</a>",
          "description": "With the advancement of DNNs into safety-critical applications, testing\napproaches for such models have gained more attention. A current direction is\nthe search for and identification of systematic weaknesses that put safety\nassumptions based on average performance values at risk. Such weaknesses can\ntake on the form of (semantically coherent) subsets or areas in the input space\nwhere a DNN performs systematically worse than its expected average. However,\nit is non-trivial to attribute the reason for such observed low performances to\nthe specific semantic features that describe the subset. For instance,\ninhomogeneities within the data w.r.t. other (non-considered) attributes might\ndistort results. However, taking into account all (available) attributes and\ntheir interaction is often computationally highly expensive. Inspired by\ncounterfactual explanations, we propose an effective and computationally cheap\nalgorithm to validate the semantic attribution of existing subsets, i.e., to\ncheck whether the identified attribute is likely to have caused the degraded\nperformance. We demonstrate this approach on an example from the autonomous\ndriving domain using highly annotated simulated data, where we show for a\nsemantic segmentation model that (i) performance differences among the\ndifferent pedestrian assets exist, but (ii) only in some cases is the asset\ntype itself the reason for this reduction in the performance.",
          "link": "http://arxiv.org/abs/2308.01614",
          "publishedOn": "2023-08-05T00:48:25.882Z",
          "wordCount": 722,
          "title": "Assessing Systematic Weaknesses of DNNs using Counterfactuals. (arXiv:2308.01614v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01423",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1\">Yeonghun Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jihan Kim</a>",
          "description": "ChatMOF is an autonomous Artificial Intelligence (AI) system that is built to\npredict and generate of metal-organic frameworks (MOFs). By leveraging a\nlarge-scale language model (gpt-3.5-turbo), ChatMOF extracts key details from\ntextual inputs and delivers appropriate responses, thus eliminating the\nnecessity for rigid structured queries. The system is comprised of three core\ncomponents (i.e. an agent, a toolkit, and an evaluator) and it forms a robust\npipeline that manages a variety of tasks, including data retrieval, property\nprediction, and structure generation. The study further explores the merits and\nconstraints of using large language models (LLMs) AI system in material\nsciences using and showcases its transformative potential for future\nadvancements.",
          "link": "http://arxiv.org/abs/2308.01423",
          "publishedOn": "2023-08-05T00:48:25.875Z",
          "wordCount": 625,
          "title": "ChatMOF: An Autonomous AI System for Predicting and Generating Metal-Organic Frameworks. (arXiv:2308.01423v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jessy Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yuqing Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watkins_O/0/1/0/all/0/1\">Olivia Watkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hafner_D/0/1/0/all/0/1\">Danijar Hafner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1\">Anca Dragan</a>",
          "description": "To interact with humans in the world, agents need to understand the diverse\ntypes of language that people use, relate them to the visual world, and act\nbased on them. While current agents learn to execute simple language\ninstructions from task rewards, we aim to build agents that leverage diverse\nlanguage that conveys general knowledge, describes the state of the world,\nprovides interactive feedback, and more. Our key idea is that language helps\nagents predict the future: what will be observed, how the world will behave,\nand which situations will be rewarded. This perspective unifies language\nunderstanding with future prediction as a powerful self-supervised learning\nobjective. We present Dynalang, an agent that learns a multimodal world model\nthat predicts future text and image representations and learns to act from\nimagined model rollouts. Unlike traditional agents that use language only to\npredict actions, Dynalang acquires rich language understanding by using past\nlanguage also to predict future language, video, and rewards. In addition to\nlearning from online interaction in an environment, Dynalang can be pretrained\non datasets of text, video, or both without actions or rewards. From using\nlanguage hints in grid worlds to navigating photorealistic scans of homes,\nDynalang utilizes diverse types of language to improve task performance,\nincluding environment descriptions, game rules, and instructions.",
          "link": "http://arxiv.org/abs/2308.01399",
          "publishedOn": "2023-08-05T00:48:25.869Z",
          "wordCount": 725,
          "title": "Learning to Model the World with Language. (arXiv:2308.01399v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1\">Ping Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Ximeng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sclaroff_S/0/1/0/all/0/1\">Stan Sclaroff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1\">Kate Saenko</a>",
          "description": "Multi-label image recognition in the low-label regime is a task of great\nchallenge and practical significance. Previous works have focused on learning\nthe alignment between textual and visual spaces to compensate for limited image\nlabels, yet may suffer from reduced accuracy due to the scarcity of\nhigh-quality multi-label annotations. In this research, we leverage the\npowerful alignment between textual and visual features pretrained with millions\nof auxiliary image-text pairs. We introduce an efficient and effective\nframework called Evidence-guided Dual Context Optimization (DualCoOp++), which\nserves as a unified approach for addressing partial-label and zero-shot\nmulti-label recognition. In DualCoOp++ we separately encode evidential,\npositive, and negative contexts for target classes as parametric components of\nthe linguistic input (i.e., prompts). The evidential context aims to discover\nall the related visual content for the target class, and serves as guidance to\naggregate positive and negative contexts from the spatial domain of the image,\nenabling better distinguishment between similar categories. Additionally, we\nintroduce a Winner-Take-All module that promotes inter-class interaction during\ntraining, while avoiding the need for extra parameters and costs. As DualCoOp++\nimposes minimal additional learnable overhead on the pretrained vision-language\nframework, it enables rapid adaptation to multi-label recognition tasks with\nlimited annotations and even unseen classes. Experiments on standard\nmulti-label recognition benchmarks across two challenging low-label settings\ndemonstrate the superior performance of our approach compared to\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2308.01890",
          "publishedOn": "2023-08-05T00:48:25.851Z",
          "wordCount": 775,
          "title": "DualCoOp++: Fast and Effective Adaptation to Multi-Label Recognition with Limited Annotations. (arXiv:2308.01890v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01389",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hossain_J/0/1/0/all/0/1\">Jumman Hossain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Momtaz_M/0/1/0/all/0/1\">Maliha Momtaz</a>",
          "description": "Nowadays, autonomous cars are gaining traction due to their numerous\npotential applications on battlefields and in resolving a variety of other\nreal-world challenges. The main goal of our project is to build an autonomous\nsystem using DeepRacer which will follow a specific person (for our project, a\nsoldier) when they will be moving in any direction. Two main components to\naccomplish this project is an optimized Single-Shot Multibox Detection (SSD)\nobject detection model and a Reinforcement Learning (RL) model. We accomplished\nthe task using SSD Lite instead of SSD and at the end, compared the results\namong SSD, SSD with Neural Computing Stick (NCS), and SSD Lite. Experimental\nresults show that SSD Lite gives better performance among these three\ntechniques and exhibits a considerable boost in inference speed (~2-3 times)\nwithout compromising accuracy.",
          "link": "http://arxiv.org/abs/2308.01389",
          "publishedOn": "2023-08-05T00:48:25.846Z",
          "wordCount": 642,
          "title": "Follow the Soldiers with Optimized Single-Shot Multibox Detection and Reinforcement Learning. (arXiv:2308.01389v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01895",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brignac_D/0/1/0/all/0/1\">Daniel Brignac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lobo_N/0/1/0/all/0/1\">Niels Lobo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahalanobis_A/0/1/0/all/0/1\">Abhijit Mahalanobis</a>",
          "description": "Continual learning seeks to enable deep learners to train on a series of\ntasks of unknown length without suffering from the catastrophic forgetting of\nprevious tasks. One effective solution is replay, which involves storing few\nprevious experiences in memory and replaying them when learning the current\ntask. However, there is still room for improvement when it comes to selecting\nthe most informative samples for storage and determining the optimal number of\nsamples to be stored. This study aims to address these issues with a novel\ncomparison of the commonly used reservoir sampling to various alternative\npopulation strategies and providing a novel detailed analysis of how to find\nthe optimal number of stored samples.",
          "link": "http://arxiv.org/abs/2308.01895",
          "publishedOn": "2023-08-05T00:48:25.840Z",
          "wordCount": 632,
          "title": "Improving Replay Sample Selection and Storage for Less Forgetting in Continual Learning. (arXiv:2308.01895v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.19569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ha_J/0/1/0/all/0/1\">Jong Moon Ha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fink_O/0/1/0/all/0/1\">Olga Fink</a>",
          "description": "Extensive research has been conducted on fault diagnosis of planetary\ngearboxes using vibration signals and deep learning (DL) approaches. However,\nDL-based methods are susceptible to the domain shift problem caused by varying\noperating conditions of the gearbox. Although domain adaptation and data\nsynthesis methods have been proposed to overcome such domain shifts, they are\noften not directly applicable in real-world situations where only healthy data\nis available in the target domain. To tackle the challenge of extreme domain\nshift scenarios where only healthy data is available in the target domain, this\npaper proposes two novel domain knowledge-informed data synthesis methods\nutilizing the health data map (HDMap). The two proposed approaches are referred\nto as scaled CutPaste and FaultPaste. The HDMap is used to physically represent\nthe vibration signal of the planetary gearbox as an image-like matrix, allowing\nfor visualization of fault-related features. CutPaste and FaultPaste are then\napplied to generate faulty samples based on the healthy data in the target\ndomain, using domain knowledge and fault signatures extracted from the source\ndomain, respectively. In addition to generating realistic faults, the proposed\nmethods introduce scaling of fault signatures for controlled synthesis of\nfaults with various severity levels. A case study is conducted on a planetary\ngearbox testbed to evaluate the proposed approaches. The results show that the\nproposed methods are capable of accurately diagnosing faults, even in cases of\nextreme domain shift, and can estimate the severity of faults that have not\nbeen previously observed in the target domain.",
          "link": "http://arxiv.org/abs/2305.19569",
          "publishedOn": "2023-08-05T00:48:25.834Z",
          "wordCount": 840,
          "title": "Domain knowledge-informed Synthetic fault sample generation with Health Data Map for cross-domain Planetary Gearbox Fault Diagnosis. (arXiv:2305.19569v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01475",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Allen_G/0/1/0/all/0/1\">Genevera I. Allen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gan_L/0/1/0/all/0/1\">Luqin Gan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zheng_L/0/1/0/all/0/1\">Lili Zheng</a>",
          "description": "New technologies have led to vast troves of large and complex datasets across\nmany scientific domains and industries. People routinely use machine learning\ntechniques to not only process, visualize, and make predictions from this big\ndata, but also to make data-driven discoveries. These discoveries are often\nmade using Interpretable Machine Learning, or machine learning models and\ntechniques that yield human understandable insights. In this paper, we discuss\nand review the field of interpretable machine learning, focusing especially on\nthe techniques as they are often employed to generate new knowledge or make\ndiscoveries from large data sets. We outline the types of discoveries that can\nbe made using Interpretable Machine Learning in both supervised and\nunsupervised settings. Additionally, we focus on the grand challenge of how to\nvalidate these discoveries in a data-driven manner, which promotes trust in\nmachine learning systems and reproducibility in science. We discuss validation\nfrom both a practical perspective, reviewing approaches based on data-splitting\nand stability, as well as from a theoretical perspective, reviewing statistical\nresults on model selection consistency and uncertainty quantification via\nstatistical inference. Finally, we conclude by highlighting open challenges in\nusing interpretable machine learning techniques to make discoveries, including\ngaps between theory and practice for validating data-driven-discoveries.",
          "link": "http://arxiv.org/abs/2308.01475",
          "publishedOn": "2023-08-05T00:48:25.826Z",
          "wordCount": 709,
          "title": "Interpretable Machine Learning for Discovery: Statistical Challenges \\& Opportunities. (arXiv:2308.01475v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eykholt_K/0/1/0/all/0/1\">Kevin Eykholt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1\">Taesung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schales_D/0/1/0/all/0/1\">Douglas Schales</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1\">Jiyong Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molloy_I/0/1/0/all/0/1\">Ian Molloy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zorin_M/0/1/0/all/0/1\">Masha Zorin</a>",
          "description": "Machine learning models are known to be vulnerable to adversarial evasion\nattacks as illustrated by image classification models. Thoroughly understanding\nsuch attacks is critical in order to ensure the safety and robustness of\ncritical AI tasks. However, most evasion attacks are difficult to deploy\nagainst a majority of AI systems because they have focused on image domain with\nonly few constraints. An image is composed of homogeneous, numerical,\ncontinuous, and independent features, unlike many other input types to AI\nsystems used in practice. Furthermore, some input types include additional\nsemantic and functional constraints that must be observed to generate realistic\nadversarial inputs. In this work, we propose a new framework to enable the\ngeneration of adversarial inputs irrespective of the input type and task\ndomain. Given an input and a set of pre-defined input transformations, our\nframework discovers a sequence of transformations that result in a semantically\ncorrect and functional adversarial input. We demonstrate the generality of our\napproach on several diverse machine learning tasks with various input\nrepresentations. We also show the importance of generating adversarial examples\nas they enable the deployment of mitigation techniques.",
          "link": "http://arxiv.org/abs/2308.01840",
          "publishedOn": "2023-08-05T00:48:25.816Z",
          "wordCount": 701,
          "title": "URET: Universal Robustness Evaluation Toolkit (for Evasion). (arXiv:2308.01840v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2106.03395",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sluijterman_L/0/1/0/all/0/1\">Laurens Sluijterman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cator_E/0/1/0/all/0/1\">Eric Cator</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Heskes_T/0/1/0/all/0/1\">Tom Heskes</a>",
          "description": "As neural networks become more popular, the need for accompanying uncertainty\nestimates increases. There are currently two main approaches to test the\nquality of these estimates. Most methods output a density. They can be compared\nby evaluating their loglikelihood on a test set. Other methods output a\nprediction interval directly. These methods are often tested by examining the\nfraction of test points that fall inside the corresponding prediction\nintervals. Intuitively both approaches seem logical. However, we demonstrate\nthrough both theoretical arguments and simulations that both ways of evaluating\nthe quality of uncertainty estimates have serious flaws. Firstly, both\napproaches cannot disentangle the separate components that jointly create the\npredictive uncertainty, making it difficult to evaluate the quality of the\nestimates of these components. Secondly, a better loglikelihood does not\nguarantee better prediction intervals, which is what the methods are often used\nfor in practice. Moreover, the current approach to test prediction intervals\ndirectly has additional flaws. We show why it is fundamentally flawed to test a\nprediction or confidence interval on a single test set. At best, marginal\ncoverage is measured, implicitly averaging out overconfident and underconfident\npredictions. A much more desirable property is pointwise coverage, requiring\nthe correct coverage for each prediction. We demonstrate through practical\nexamples that these effects can result in favoring a method, based on the\npredictive uncertainty, that has undesirable behaviour of the confidence or\nprediction intervals. Finally, we propose a simulation-based testing approach\nthat addresses these problems while still allowing easy comparison between\ndifferent methods.",
          "link": "http://arxiv.org/abs/2106.03395",
          "publishedOn": "2023-08-05T00:48:25.798Z",
          "wordCount": 778,
          "title": "How to Evaluate Uncertainty Estimates in Machine Learning for Regression?. (arXiv:2106.03395v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.02060",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Stone_I/0/1/0/all/0/1\">Iris R. Stone</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sagiv_Y/0/1/0/all/0/1\">Yotam Sagiv</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Park_I/0/1/0/all/0/1\">Il Memming Park</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pillow_J/0/1/0/all/0/1\">Jonathan W. Pillow</a>",
          "description": "Latent linear dynamical systems with Bernoulli observations provide a\npowerful modeling framework for identifying the temporal dynamics underlying\nbinary time series data, which arise in a variety of contexts such as binary\ndecision-making and discrete stochastic processes (e.g., binned neural spike\ntrains). Here we develop a spectral learning method for fast, efficient fitting\nof probit-Bernoulli latent linear dynamical system (LDS) models. Our approach\nextends traditional subspace identification methods to the Bernoulli setting\nvia a transformation of the first and second sample moments. This results in a\nrobust, fixed-cost estimator that avoids the hazards of local optima and the\nlong computation time of iterative fitting procedures like the\nexpectation-maximization (EM) algorithm. In regimes where data is limited or\nassumptions about the statistical structure of the data are not met, we\ndemonstrate that the spectral estimate provides a good initialization for\nLaplace-EM fitting. Finally, we show that the estimator provides substantial\nbenefits to real world settings by analyzing data from mice performing a\nsensory decision-making task.",
          "link": "http://arxiv.org/abs/2303.02060",
          "publishedOn": "2023-07-29T00:48:57.654Z",
          "wordCount": null,
          "title": "Spectral learning of Bernoulli linear dynamical systems models. (arXiv:2303.02060v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.13381",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yingtian Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_V/0/1/0/all/0/1\">Vikas Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_S/0/1/0/all/0/1\">Sarthak Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_W/0/1/0/all/0/1\">Wai Hoh Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1\">Hieu Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kannala_J/0/1/0/all/0/1\">Juho Kannala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solin_A/0/1/0/all/0/1\">Arno Solin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>",
          "description": "Mixup is a popular data augmentation technique for training deep neural\nnetworks where additional samples are generated by linearly interpolating pairs\nof inputs and their labels. This technique is known to improve the\ngeneralization performance in many learning paradigms and applications. In this\nwork, we first analyze Mixup and show that it implicitly regularizes infinitely\nmany directional derivatives of all orders. Based on this new insight, we\npropose an improved version of Mixup, theoretically justified to deliver better\ngeneralization performance than the vanilla Mixup. To demonstrate the\neffectiveness of the proposed method, we conduct experiments across various\ndomains such as images, tabular data, speech, and graphs. Our results show that\nthe proposed method improves Mixup across multiple datasets using a variety of\narchitectures, for instance, exhibiting an improvement over Mixup by 0.8% in\nImageNet top-1 accuracy.",
          "link": "http://arxiv.org/abs/2212.13381",
          "publishedOn": "2023-07-29T00:48:57.653Z",
          "wordCount": null,
          "title": "MixupE: Understanding and Improving Mixup from Directional Derivative Perspective. (arXiv:2212.13381v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.13849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venkataramanan_A/0/1/0/all/0/1\">Aishwarya Venkataramanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benbihi_A/0/1/0/all/0/1\">Assia Benbihi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laviale_M/0/1/0/all/0/1\">Martin Laviale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pradalier_C/0/1/0/all/0/1\">Cedric Pradalier</a>",
          "description": "Recent works show that the data distribution in a network's latent space is\nuseful for estimating classification uncertainty and detecting\nOut-of-distribution (OOD) samples. To obtain a well-regularized latent space\nthat is conducive for uncertainty estimation, existing methods bring in\nsignificant changes to model architectures and training procedures. In this\npaper, we present a lightweight, fast, and high-performance regularization\nmethod for Mahalanobis distance-based uncertainty prediction, and that requires\nminimal changes to the network's architecture. To derive Gaussian latent\nrepresentation favourable for Mahalanobis Distance calculation, we introduce a\nself-supervised representation learning method that separates in-class\nrepresentations into multiple Gaussians. Classes with non-Gaussian\nrepresentations are automatically identified and dynamically clustered into\nmultiple new classes that are approximately Gaussian. Evaluation on standard\nOOD benchmarks shows that our method achieves state-of-the-art results on OOD\ndetection with minimal inference time, and is very competitive on predictive\nprobability calibration. Finally, we show the applicability of our method to a\nreal-life computer vision use case on microorganism classification.",
          "link": "http://arxiv.org/abs/2305.13849",
          "publishedOn": "2023-07-29T00:48:57.653Z",
          "wordCount": null,
          "title": "Gaussian Latent Representations for Uncertainty Estimation using Mahalanobis Distance in Deep Classifiers. (arXiv:2305.13849v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.10045",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Lin_Y/0/1/0/all/0/1\">Yuchao Lin</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Yan_K/0/1/0/all/0/1\">Keqiang Yan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Luo_Y/0/1/0/all/0/1\">Youzhi Luo</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Liu_Y/0/1/0/all/0/1\">Yi Liu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Qian_X/0/1/0/all/0/1\">Xiaoning Qian</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ji_S/0/1/0/all/0/1\">Shuiwang Ji</a>",
          "description": "We study property prediction for crystal materials. A crystal structure\nconsists of a minimal unit cell that is repeated infinitely in 3D space. How to\naccurately represent such repetitive structures in machine learning models\nremains unresolved. Current methods construct graphs by establishing edges only\nbetween nearby nodes, thereby failing to faithfully capture infinite repeating\npatterns and distant interatomic interactions. In this work, we propose several\ninnovations to overcome these limitations. First, we propose to model\nphysics-principled interatomic potentials directly instead of only using\ndistances as in many existing methods. These potentials include the Coulomb\npotential, London dispersion potential, and Pauli repulsion potential. Second,\nwe model the complete set of potentials among all atoms, instead of only\nbetween nearby atoms as in existing methods. This is enabled by our\napproximations of infinite potential summations with provable error bounds. We\nfurther develop efficient algorithms to compute the approximations. Finally, we\npropose to incorporate our computations of complete interatomic potentials into\nmessage passing neural networks for representation learning. We perform\nexperiments on the JARVIS and Materials Project benchmarks for evaluation.\nResults show that the use of interatomic potentials and complete interatomic\npotentials leads to consistent performance improvements with reasonable\ncomputational costs. Our code is publicly available as part of the AIRS library\n(https://github.com/divelab/AIRS/tree/main/OpenMat/PotNet).",
          "link": "http://arxiv.org/abs/2306.10045",
          "publishedOn": "2023-07-29T00:48:57.653Z",
          "wordCount": null,
          "title": "Efficient Approximations of Complete Interatomic Potentials for Crystal Property Prediction. (arXiv:2306.10045v7 [physics.chem-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09916",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1\">Jianing Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Q/0/1/0/all/0/1\">Qing Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1\">Yilin Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1\">Wei Zeng</a>",
          "description": "Deep learning (DL) approaches are being increasingly used for time-series\nforecasting, with many efforts devoted to designing complex DL models. Recent\nstudies have shown that the DL success is often attributed to effective data\nrepresentations, fostering the fields of feature engineering and representation\nlearning. However, automated approaches for feature learning are typically\nlimited with respect to incorporating prior knowledge, identifying interactions\namong variables, and choosing evaluation metrics to ensure that the models are\nreliable. To improve on these limitations, this paper contributes a novel\nvisual analytics framework, namely TimeTuner, designed to help analysts\nunderstand how model behaviors are associated with localized correlations,\nstationarity, and granularity of time-series representations. The system mainly\nconsists of the following two-stage technique: We first leverage counterfactual\nexplanations to connect the relationships among time-series representations,\nmultivariate features and model predictions. Next, we design multiple\ncoordinated views including a partition-based correlation matrix and juxtaposed\nbivariate stripes, and provide a set of interactions that allow users to step\ninto the transformation selection process, navigate through the feature space,\nand reason the model performance. We instantiate TimeTuner with two\ntransformation methods of smoothing and sampling, and demonstrate its\napplicability on real-world time-series forecasting of univariate sunspots and\nmultivariate air pollutants. Feedback from domain experts indicates that our\nsystem can help characterize time-series representations and guide the feature\nengineering processes.",
          "link": "http://arxiv.org/abs/2307.09916",
          "publishedOn": "2023-07-29T00:48:57.652Z",
          "wordCount": null,
          "title": "TimeTuner: Diagnosing Time Representations for Time-Series Forecasting with Counterfactual Explanations. (arXiv:2307.09916v3 [cs.HC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.13494",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaixin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongzhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yabin Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Ziqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_C/0/1/0/all/0/1\">Chang Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yu Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Donghua Yang</a>",
          "description": "Learned cardinality estimation methods have achieved high precision compared\nto traditional methods. Among learned methods, query-driven approaches face the\ndata and workload drift problem for a long time. Although both query-driven and\nhybrid methods are proposed to avoid this problem, even the state-of-art of\nthem suffer from high training and estimation costs, limited scalability,\ninstability, and long-tailed distribution problem on high cardinality and high\ndimensional tables, which seriously affects the practical application of\nlearned cardinality estimators. In this paper, we prove that most of these\nproblems are directly caused by the widely used progressive sampling. We solve\nthis problem by introducing predicates into the autoregressive model and\npropose Duet, a stable, efficient, and scalable hybrid method to estimate\ncardinality directly without sampling or any non-differentiable process, which\ncan not only reduces the inference complexity from $O(n)$ to $O(1)$ compared to\nNaru and UAE but also achieve higher accuracy on high cardinality and high\ndimensional tables. Experimental results show that Duet can achieve all the\ndesign goals above and be much more practical and even has a lower inference\ncost on CPU than that of most learned methods on GPU.",
          "link": "http://arxiv.org/abs/2307.13494",
          "publishedOn": "2023-07-29T00:48:57.652Z",
          "wordCount": null,
          "title": "Duet: efficient and scalable hybriD neUral rElation undersTanding. (arXiv:2307.13494v3 [cs.DB] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.19472",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brahman_F/0/1/0/all/0/1\">Faeze Brahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhagavatula_C/0/1/0/all/0/1\">Chandra Bhagavatula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pyatkin_V/0/1/0/all/0/1\">Valentina Pyatkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1\">Jena D. Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Lorraine Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arai_H/0/1/0/all/0/1\">Hirona J. Arai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanyal_S/0/1/0/all/0/1\">Soumya Sanyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakaguchi_K/0/1/0/all/0/1\">Keisuke Sakaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>",
          "description": "Procedural planning, which entails decomposing a high-level goal into a\nsequence of temporally ordered steps, is an important yet intricate task for\nmachines. It involves integrating common-sense knowledge to reason about\ncomplex contextualized situations that are often counterfactual, e.g.\n\"scheduling a doctor's appointment without a phone\". While current approaches\nshow encouraging results using large language models (LLMs), they are hindered\nby drawbacks such as costly API calls and reproducibility issues. In this\npaper, we advocate planning using smaller language models. We present PlaSma, a\nnovel two-pronged approach to endow small language models with procedural\nknowledge and (counterfactual) planning capabilities. More concretely, we\ndevelop symbolic procedural knowledge distillation to enhance the implicit\nknowledge in small language models and an inference-time algorithm to\nfacilitate more structured and accurate reasoning. In addition, we introduce a\nnovel task, Counterfactual Planning, that requires a revision of a plan to cope\nwith a counterfactual situation. In both the original and counterfactual\nsetting, we show that orders-of-magnitude smaller models (770M-11B parameters)\ncan compete and often surpass their larger teacher models' capabilities.",
          "link": "http://arxiv.org/abs/2305.19472",
          "publishedOn": "2023-07-29T00:48:57.651Z",
          "wordCount": null,
          "title": "PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning. (arXiv:2305.19472v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.13423",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Close_G/0/1/0/all/0/1\">George Close</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hain_T/0/1/0/all/0/1\">Thomas Hain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goetze_S/0/1/0/all/0/1\">Stefan Goetze</a>",
          "description": "Self-supervised speech representations (SSSRs) have been successfully applied\nto a number of speech-processing tasks, e.g. as feature extractor for speech\nquality (SQ) prediction, which is, in turn, relevant for assessment and\ntraining speech enhancement systems for users with normal or impaired hearing.\nHowever, exact knowledge of why and how quality-related information is encoded\nwell in such representations remains poorly understood. In this work,\ntechniques for non-intrusive prediction of SQ ratings are extended to the\nprediction of intelligibility for hearing-impaired users. It is found that\nself-supervised representations are useful as input features to non-intrusive\nprediction models, achieving competitive performance to more complex systems. A\ndetailed analysis of the performance depending on Clarity Prediction Challenge\n1 listeners and enhancement systems indicates that more data might be needed to\nallow generalisation to unknown systems and (hearing-impaired) individuals",
          "link": "http://arxiv.org/abs/2307.13423",
          "publishedOn": "2023-07-29T00:48:57.651Z",
          "wordCount": null,
          "title": "Non Intrusive Intelligibility Predictor for Hearing Impaired Individuals using Self Supervised Speech Representations. (arXiv:2307.13423v2 [cs.SD] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.02377",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frick_R/0/1/0/all/0/1\">Raphael Frick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogel_I/0/1/0/all/0/1\">Inna Vogel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jeong-Eun Choi</a>",
          "description": "This paper describes the second-placed approach developed by the Fraunhofer\nSIT team in the CLEF-2023 CheckThat! lab Task 1B for English. Given a text\nsnippet from a political debate, the aim of this task is to determine whether\nit should be assessed for check-worthiness. Detecting check-worthy statements\naims to facilitate manual fact-checking efforts by prioritizing the claims that\nfact-checkers should consider first. It can also be considered as primary step\nof a fact-checking system. Our best-performing method took advantage of an\nensemble classification scheme centered on Model Souping. When applied to the\nEnglish data set, our submitted model achieved an overall F1 score of 0.878 and\nwas ranked as the second-best model in the competition.",
          "link": "http://arxiv.org/abs/2307.02377",
          "publishedOn": "2023-07-29T00:48:57.582Z",
          "wordCount": null,
          "title": "Fraunhofer SIT at CheckThat! 2023: Tackling Classification Uncertainty Using Model Souping on the Example of Check-Worthiness Classification. (arXiv:2307.02377v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.01226",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Anpei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zexiang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xinyue Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Siyu Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hao Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiger_A/0/1/0/all/0/1\">Andreas Geiger</a>",
          "description": "We present Factor Fields, a novel framework for modeling and representing\nsignals. Factor Fields decomposes a signal into a product of factors, each\nrepresented by a classical or neural field representation which operates on\ntransformed input coordinates. This decomposition results in a unified\nframework that accommodates several recent signal representations including\nNeRF, Plenoxels, EG3D, Instant-NGP, and TensoRF. Additionally, our framework\nallows for the creation of powerful new signal representations, such as the\n\"Dictionary Field\" (DiF) which is a second contribution of this paper. Our\nexperiments show that DiF leads to improvements in approximation quality,\ncompactness, and training time when compared to previous fast reconstruction\nmethods. Experimentally, our representation achieves better image approximation\nquality on 2D image regression tasks, higher geometric quality when\nreconstructing 3D signed distance fields, and higher compactness for radiance\nfield reconstruction tasks. Furthermore, DiF enables generalization to unseen\nimages/3D scenes by sharing bases across signals during training which greatly\nbenefits use cases such as image regression from sparse observations and\nfew-shot radiance field reconstruction.",
          "link": "http://arxiv.org/abs/2302.01226",
          "publishedOn": "2023-07-29T00:48:57.581Z",
          "wordCount": null,
          "title": "Factor Fields: A Unified Framework for Neural Fields and Beyond. (arXiv:2302.01226v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.00610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frick_R/0/1/0/all/0/1\">Raphael Frick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogel_I/0/1/0/all/0/1\">Inna Vogel</a>",
          "description": "The option of sharing images, videos and audio files on social media opens up\nnew possibilities for distinguishing between false information and fake news on\nthe Internet. Due to the vast amount of data shared every second on social\nmedia, not all data can be verified by a computer or a human expert. Here, a\ncheck-worthiness analysis can be used as a first step in the fact-checking\npipeline and as a filtering mechanism to improve efficiency. This paper\nproposes a novel way of detecting the check-worthiness in multi-modal tweets.\nIt takes advantage of two classifiers, each trained on a single modality. For\nimage data, extracting the embedded text with an OCR analysis has shown to\nperform best. By combining the two classifiers, the proposed solution was able\nto place first in the CheckThat! 2023 Task 1A with an F1 score of 0.7297\nachieved on the private test set.",
          "link": "http://arxiv.org/abs/2307.00610",
          "publishedOn": "2023-07-29T00:48:57.581Z",
          "wordCount": null,
          "title": "Fraunhofer SIT at CheckThat! 2023: Mixing Single-Modal Classifiers to Estimate the Check-Worthiness of Multi-Modal Tweets. (arXiv:2307.00610v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.03811",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Sharma_V/0/1/0/all/0/1\">Vidushi Sharma</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Giammona_M/0/1/0/all/0/1\">Maxwell Giammona</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Zubarev_D/0/1/0/all/0/1\">Dmitry Zubarev</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Tek_A/0/1/0/all/0/1\">Andy Tek</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Nugyuen_K/0/1/0/all/0/1\">Khanh Nugyuen</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Sundberg_L/0/1/0/all/0/1\">Linda Sundberg</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Congiu_D/0/1/0/all/0/1\">Daniele Congiu</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+La_Y/0/1/0/all/0/1\">Young-Hye La</a>",
          "description": "Advanced computational methods are being actively sought for addressing the\nchallenges associated with discovery and development of new combinatorial\nmaterial such as formulations. A widely adopted approach involves domain\ninformed high-throughput screening of individual components that can be\ncombined into a formulation. This manages to accelerate the discovery of new\ncompounds for a target application but still leave the process of identifying\nthe right 'formulation' from the shortlisted chemical space largely a\nlaboratory experiment-driven process. We report a deep learning model,\nFormulation Graph Convolution Network (F-GCN), that can map\nstructure-composition relationship of the individual components to the property\nof liquid formulation as whole. Multiple GCNs are assembled in parallel that\nfeaturize formulation constituents domain-intuitively on the fly. The resulting\nmolecular descriptors are scaled based on respective constituent's molar\npercentage in the formulation, followed by formalizing into a combined\ndescriptor that represents a complete formulation to an external learning\narchitecture. The use case of proposed formulation learning model is\ndemonstrated for battery electrolytes by training and testing it on two\nexemplary datasets representing electrolyte formulations vs battery performance\n-- one dataset is sourced from literature about Li/Cu half-cells, while the\nother is obtained by lab-experiments related to lithium-iodide full-cell\nchemistry. The model is shown to predict the performance metrics like Coulombic\nEfficiency (CE) and specific capacity of new electrolyte formulations with\nlowest reported errors. The best performing F-GCN model uses molecular\ndescriptors derived from molecular graphs that are informed with HOMO-LUMO and\nelectric moment properties of the molecules using a knowledge transfer\ntechnique.",
          "link": "http://arxiv.org/abs/2307.03811",
          "publishedOn": "2023-07-29T00:48:57.581Z",
          "wordCount": null,
          "title": "Formulation Graphs for Mapping Structure-Composition of Battery Electrolytes to Device Performance. (arXiv:2307.03811v2 [cond-mat.mtrl-sci] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.09246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dostal_L/0/1/0/all/0/1\">Leo Dostal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bespalko_A/0/1/0/all/0/1\">Alexej Bespalko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duecker_D/0/1/0/all/0/1\">Daniel A. Duecker</a>",
          "description": "We present computational and experimental results on how artificial\nintelligence (AI) learns to control an Acrobot using reinforcement learning\n(RL). Thereby the experimental setup is designed as an embedded system, which\nis of interest for robotics and energy harvesting applications. Specifically,\nwe study the control of angular velocity of the Acrobot, as well as control of\nits total energy, which is the sum of the kinetic and the potential energy. By\nthis means the RL algorithm is designed to drive the angular velocity or the\nenergy of the first pendulum of the Acrobot towards a desired value. With this,\nlibration or full rotation of the unactuated pendulum of the Acrobot is\nachieved. Moreover, investigations of the Acrobot control are carried out,\nwhich lead to insights about the influence of the state space discretization,\nthe episode length, the action space or the mass of the driven pendulum on the\nRL control. By further numerous simulations and experiments the effects of\nparameter variations are evaluated.",
          "link": "http://arxiv.org/abs/2011.09246",
          "publishedOn": "2023-07-29T00:48:57.580Z",
          "wordCount": null,
          "title": "Experimental Study on Reinforcement Learning-based Control of an Acrobot. (arXiv:2011.09246v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.13709",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fujii_S/0/1/0/all/0/1\">Satoru Fujii</a>",
          "description": "Many properties in the real world, such as desirability or strength in\ncompetitive environment, can't be directly observed, which makes them difficult\nto evaluate. To deal with this challenging problem, prior works have primarily\nfocused on estimating those properties of known items, especially the strength\nof sports players, only of those who appears in paired comparison dataset. In\nthis paper, we introduce Deep Bradley-Terry Rating (DBTR), a novel ML framework\nto evaluate any properties of unknown items, not necessarily present in the\ntraining data. Our method seamlessly integrates traditional Bradley-Terry model\nwith a neural network structure. We also generalizes this architecture further\nfor asymmetric environment with unfairness, which is much more common in real\nworld settings. In our experimental analysis, DBTR successfully learned desired\nquantification of those properties.",
          "link": "http://arxiv.org/abs/2307.13709",
          "publishedOn": "2023-07-29T00:48:57.580Z",
          "wordCount": null,
          "title": "Deep Bradley-Terry Rating: Estimate Properties Without Metric of Unseen Items. (arXiv:2307.13709v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.01462",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Koutny_D/0/1/0/all/0/1\">Dominik Koutn&#xfd;</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gines_L/0/1/0/all/0/1\">Laia Gin&#xe9;s</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Moczala_Dusanowska_M/0/1/0/all/0/1\">Magdalena Mocza&#x142;a-Dusanowska</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Hofling_S/0/1/0/all/0/1\">Sven H&#xf6;fling</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Schneider_C/0/1/0/all/0/1\">Christian Schneider</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Predojevic_A/0/1/0/all/0/1\">Ana Predojevi&#x107;</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Jezek_M/0/1/0/all/0/1\">Miroslav Je&#x17e;ek</a>",
          "description": "The quantification of the entanglement present in a physical system is of\npara\\-mount importance for fundamental research and many cutting-edge\napplications. Currently, achieving this goal requires either a priori knowledge\non the system or very demanding experimental procedures such as full state\ntomography or collective measurements. Here, we demonstrate that by employing\nneural networks we can quantify the degree of entanglement without needing to\nknow the full description of the quantum state. Our method allows for direct\nquantification of the quantum correlations using an incomplete set of local\nmeasurements. Despite using undersampled measurements, we achieve a\nquantification error of up to an order of magnitude lower than the\nstate-of-the-art quantum tomography. Furthermore, we achieve this result\nemploying networks trained using exclusively simulated data. Finally, we derive\na method based on a convolutional network input that can accept data from\nvarious measurement scenarios and perform, to some extent, independently of the\nmeasurement device.",
          "link": "http://arxiv.org/abs/2205.01462",
          "publishedOn": "2023-07-29T00:48:57.580Z",
          "wordCount": null,
          "title": "Deep learning of quantum entanglement from incomplete measurements. (arXiv:2205.01462v6 [quant-ph] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.10291",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Derezinski_M/0/1/0/all/0/1\">Micha&#x142; Derezi&#x144;ski</a>",
          "description": "Algorithmic Gaussianization is a phenomenon that can arise when using\nrandomized sketching or sampling methods to produce smaller representations of\nlarge datasets: For certain tasks, these sketched representations have been\nobserved to exhibit many robust performance characteristics that are known to\noccur when a data sample comes from a sub-gaussian random design, which is a\npowerful statistical model of data distributions. However, this phenomenon has\nonly been studied for specific tasks and metrics, or by relying on\ncomputationally expensive methods. We address this by providing an algorithmic\nframework for gaussianizing data distributions via averaging, proving that it\nis possible to efficiently construct data sketches that are nearly\nindistinguishable (in terms of total variation distance) from sub-gaussian\nrandom designs. In particular, relying on a recently introduced sketching\ntechnique called Leverage Score Sparsified (LESS) embeddings, we show that one\ncan construct an $n\\times d$ sketch of an $N\\times d$ matrix $A$, where $n\\ll\nN$, that is nearly indistinguishable from a sub-gaussian design, in time\n$O(\\text{nnz}(A)\\log N + nd^2)$, where $\\text{nnz}(A)$ is the number of\nnon-zero entries in $A$. As a consequence, strong statistical guarantees and\nprecise asymptotics available for the estimators produced from sub-gaussian\ndesigns (e.g., for least squares and Lasso regression, covariance estimation,\nlow-rank approximation, etc.) can be straightforwardly adapted to our sketching\nframework. We illustrate this with a new approximation guarantee for sketched\nleast squares, among other examples.",
          "link": "http://arxiv.org/abs/2206.10291",
          "publishedOn": "2023-07-29T00:48:57.579Z",
          "wordCount": null,
          "title": "Algorithmic Gaussianization through Sketching: Converting Data into Sub-gaussian Random Designs. (arXiv:2206.10291v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.05697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Helwig_J/0/1/0/all/0/1\">Jacob Helwig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Cong Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurtin_J/0/1/0/all/0/1\">Jerry Kurtin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wojtowytsch_S/0/1/0/all/0/1\">Stephan Wojtowytsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1\">Shuiwang Ji</a>",
          "description": "We consider solving partial differential equations (PDEs) with Fourier neural\noperators (FNOs), which operate in the frequency domain. Since the laws of\nphysics do not depend on the coordinate system used to describe them, it is\ndesirable to encode such symmetries in the neural operator architecture for\nbetter performance and easier learning. While encoding symmetries in the\nphysical domain using group theory has been studied extensively, how to capture\nsymmetries in the frequency domain is under-explored. In this work, we extend\ngroup convolutions to the frequency domain and design Fourier layers that are\nequivariant to rotations, translations, and reflections by leveraging the\nequivariance property of the Fourier transform. The resulting $G$-FNO\narchitecture generalizes well across input resolutions and performs well in\nsettings with varying levels of symmetry. Our code is publicly available as\npart of the AIRS library (https://github.com/divelab/AIRS).",
          "link": "http://arxiv.org/abs/2306.05697",
          "publishedOn": "2023-07-29T00:48:57.579Z",
          "wordCount": null,
          "title": "Group Equivariant Fourier Neural Operators for Partial Differential Equations. (arXiv:2306.05697v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.01669",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shu_Y/0/1/0/all/0/1\">Yangyang Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hengel_A/0/1/0/all/0/1\">Anton van den Hengel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lingqiao Liu</a>",
          "description": "Self-supervised learning (SSL) strategies have demonstrated remarkable\nperformance in various recognition tasks. However, both our preliminary\ninvestigation and recent studies suggest that they may be less effective in\nlearning representations for fine-grained visual recognition (FGVR) since many\nfeatures helpful for optimizing SSL objectives are not suitable for\ncharacterizing the subtle differences in FGVR. To overcome this issue, we\npropose learning an additional screening mechanism to identify discriminative\nclues commonly seen across instances and classes, dubbed as common rationales\nin this paper. Intuitively, common rationales tend to correspond to the\ndiscriminative patterns from the key parts of foreground objects. We show that\na common rationale detector can be learned by simply exploiting the GradCAM\ninduced from the SSL objective without using any pre-trained object parts or\nsaliency detectors, making it seamlessly to be integrated with the existing SSL\nprocess. Specifically, we fit the GradCAM with a branch with limited fitting\ncapacity, which allows the branch to capture the common rationales and discard\nthe less common discriminative patterns. At the test stage, the branch\ngenerates a set of spatial weights to selectively aggregate features\nrepresenting an instance. Extensive experimental results on four visual tasks\ndemonstrate that the proposed method can lead to a significant improvement in\ndifferent evaluation settings.",
          "link": "http://arxiv.org/abs/2303.01669",
          "publishedOn": "2023-07-29T00:48:57.578Z",
          "wordCount": null,
          "title": "Learning Common Rationale to Improve Self-Supervised Representation for Fine-Grained Visual Recognition Problems. (arXiv:2303.01669v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.08944",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ohayon_G/0/1/0/all/0/1\">Guy Ohayon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Adrai_T/0/1/0/all/0/1\">Theo Adrai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Elad_M/0/1/0/all/0/1\">Michael Elad</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Michaeli_T/0/1/0/all/0/1\">Tomer Michaeli</a>",
          "description": "Stochastic restoration algorithms allow to explore the space of solutions\nthat correspond to the degraded input. In this paper we reveal additional\nfundamental advantages of stochastic methods over deterministic ones, which\nfurther motivate their use. First, we prove that any restoration algorithm that\nattains perfect perceptual quality and whose outputs are consistent with the\ninput must be a posterior sampler, and is thus required to be stochastic.\nSecond, we illustrate that while deterministic restoration algorithms may\nattain high perceptual quality, this can be achieved only by filling up the\nspace of all possible source images using an extremely sensitive mapping, which\nmakes them highly vulnerable to adversarial attacks. Indeed, we show that\nenforcing deterministic models to be robust to such attacks profoundly hinders\ntheir perceptual quality, while robustifying stochastic models hardly\ninfluences their perceptual quality, and improves their output variability.\nThese findings provide a motivation to foster progress in stochastic\nrestoration methods, paving the way to better recovery algorithms.",
          "link": "http://arxiv.org/abs/2211.08944",
          "publishedOn": "2023-07-29T00:48:57.577Z",
          "wordCount": null,
          "title": "Reasons for the Superiority of Stochastic Estimators over Deterministic Ones: Robustness, Consistency and Perceptual Quality. (arXiv:2211.08944v3 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05946",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sengupta_A/0/1/0/all/0/1\">Agnimitra Sengupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mondal_S/0/1/0/all/0/1\">Sudeepta Mondal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Adway Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guler_S/0/1/0/all/0/1\">S. Ilgin Guler</a>",
          "description": "Deep-learning models for traffic data prediction can have superior\nperformance in modeling complex functions using a multi-layer architecture.\nHowever, a major drawback of these approaches is that most of these approaches\ndo not offer forecasts with uncertainty estimates, which are essential for\ntraffic operations and control. Without uncertainty estimates, it is difficult\nto place any level of trust to the model predictions, and operational\nstrategies relying on overconfident predictions can lead to worsening traffic\nconditions. In this study, we propose a Bayesian recurrent neural network\nframework for uncertainty quantification in traffic prediction with higher\ngeneralizability by introducing spectral normalization to its hidden layers. In\nour paper, we have shown that normalization alters the training process of deep\nneural networks by controlling the model's complexity and reducing the risk of\noverfitting to the training data. This, in turn, helps improve the\ngeneralization performance of the model on out-of-distribution datasets.\nResults demonstrate that spectral normalization improves uncertainty estimates\nand significantly outperforms both the layer normalization and model without\nnormalization in single-step prediction horizons. This improved performance can\nbe attributed to the ability of spectral normalization to better localize the\nfeature space of the data under perturbations. Our findings are especially\nrelevant to traffic management applications, where predicting traffic\nconditions across multiple locations is the goal, but the availability of\ntraining data from multiple locations is limited. Spectral normalization,\ntherefore, provides a more generalizable approach that can effectively capture\nthe underlying patterns in traffic data without requiring location-specific\nmodels.",
          "link": "http://arxiv.org/abs/2307.05946",
          "publishedOn": "2023-07-29T00:48:57.577Z",
          "wordCount": null,
          "title": "A Bayesian approach to quantifying uncertainties and improving generalizability in traffic prediction models. (arXiv:2307.05946v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2207.00052",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ko_C/0/1/0/all/0/1\">Ching-Yun Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1\">Pulkit Agrawal</a>",
          "description": "One powerful paradigm in visual navigation is to predict actions from\nobservations directly. Training such an end-to-end system allows\nrepresentations useful for downstream tasks to emerge automatically. However,\nthe lack of inductive bias makes this system data inefficient. We hypothesize a\nsufficient representation of the current view and the goal view for a\nnavigation policy can be learned by predicting the location and size of a crop\nof the current view that corresponds to the goal. We further show that training\nsuch random crop prediction in a self-supervised fashion purely on synthetic\nnoise images transfers well to natural home images. The learned representation\ncan then be bootstrapped to learn a navigation policy efficiently with little\ninteraction data. The code is available at https://yanweiw.github.io/noise2ptz",
          "link": "http://arxiv.org/abs/2207.00052",
          "publishedOn": "2023-07-29T00:48:57.576Z",
          "wordCount": null,
          "title": "Visual Pre-training for Navigation: What Can We Learn from Noise?. (arXiv:2207.00052v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14066",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rousseau_J/0/1/0/all/0/1\">J&#xe9;r&#xe9;my Rousseau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alaka_C/0/1/0/all/0/1\">Christian Alaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Covili_E/0/1/0/all/0/1\">Emma Covili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mayard_H/0/1/0/all/0/1\">Hippolyte Mayard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Misrachi_L/0/1/0/all/0/1\">Laura Misrachi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Au_W/0/1/0/all/0/1\">Willy Au</a>",
          "description": "Medical radiography segmentation, and specifically dental radiography, is\nhighly limited by the cost of labeling which requires specific expertise and\nlabor-intensive annotations. In this work, we propose a straightforward\npre-training method for semantic segmentation leveraging Denoising Diffusion\nProbabilistic Models (DDPM), which have shown impressive results for generative\nmodeling. Our straightforward approach achieves remarkable performance in terms\nof label efficiency and does not require architectural modifications between\npre-training and downstream tasks. We propose to first pre-train a Unet by\nexploiting the DDPM training objective, and then fine-tune the resulting model\non a segmentation task. Our experimental results on the segmentation of dental\nradiographs demonstrate that the proposed method is competitive with\nstate-of-the-art pre-training methods.",
          "link": "http://arxiv.org/abs/2307.14066",
          "publishedOn": "2023-07-29T00:48:57.576Z",
          "wordCount": null,
          "title": "Pre-Training with Diffusion models for Dental Radiography segmentation. (arXiv:2307.14066v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2108.13624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiashuo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zheyan Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yue He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xingxuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Renzhe Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Han Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_P/0/1/0/all/0/1\">Peng Cui</a>",
          "description": "Traditional machine learning paradigms are based on the assumption that both\ntraining and test data follow the same statistical pattern, which is\nmathematically referred to as Independent and Identically Distributed\n($i.i.d.$). However, in real-world applications, this $i.i.d.$ assumption often\nfails to hold due to unforeseen distributional shifts, leading to considerable\ndegradation in model performance upon deployment. This observed discrepancy\nindicates the significance of investigating the Out-of-Distribution (OOD)\ngeneralization problem. OOD generalization is an emerging topic of machine\nlearning research that focuses on complex scenarios wherein the distributions\nof the test data differ from those of the training data. This paper represents\nthe first comprehensive, systematic review of OOD generalization, encompassing\na spectrum of aspects from problem definition, methodological development, and\nevaluation procedures, to the implications and future directions of the field.\nOur discussion begins with a precise, formal characterization of the OOD\ngeneralization problem. Following that, we categorize existing methodologies\ninto three segments: unsupervised representation learning, supervised model\nlearning, and optimization, according to their positions within the overarching\nlearning process. We provide an in-depth discussion on representative\nmethodologies for each category, further elucidating the theoretical links\nbetween them. Subsequently, we outline the prevailing benchmark datasets\nemployed in OOD generalization studies. To conclude, we overview the existing\nbody of work in this domain and suggest potential avenues for future research\non OOD generalization. A summary of the OOD generalization methodologies\nsurveyed in this paper can be accessed at\nthis http URL",
          "link": "http://arxiv.org/abs/2108.13624",
          "publishedOn": "2023-07-29T00:48:57.575Z",
          "wordCount": null,
          "title": "Towards Out-Of-Distribution Generalization: A Survey. (arXiv:2108.13624v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.07436",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Malinovskaya_A/0/1/0/all/0/1\">Anna Malinovskaya</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mozharovskyi_P/0/1/0/all/0/1\">Pavlo Mozharovskyi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Otto_P/0/1/0/all/0/1\">Philipp Otto</a>",
          "description": "The rapid advancement of models based on artificial intelligence demands\ninnovative monitoring techniques which can operate in real time with low\ncomputational costs. In machine learning, especially if we consider artificial\nneural networks (ANNs), the models are often trained in a supervised manner.\nConsequently, the learned relationship between the input and the output must\nremain valid during the model's deployment. If this stationarity assumption\nholds, we can conclude that the ANN provides accurate predictions. Otherwise,\nthe retraining or rebuilding of the model is required. We propose considering\nthe latent feature representation of the data (called \"embedding\") generated by\nthe ANN to determine the time when the data stream starts being nonstationary.\nIn particular, we monitor embeddings by applying multivariate control charts\nbased on the data depth calculation and normalized ranks. The performance of\nthe introduced method is compared with benchmark approaches for various ANN\narchitectures and different underlying data formats.",
          "link": "http://arxiv.org/abs/2209.07436",
          "publishedOn": "2023-07-29T00:48:57.571Z",
          "wordCount": null,
          "title": "Statistical process monitoring of artificial neural networks. (arXiv:2209.07436v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.04169",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1\">Mingquan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1\">Junze Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lichen Zhang</a>",
          "description": "Weighted low rank approximation is a fundamental problem in numerical linear\nalgebra, and it has many applications in machine learning. Given a matrix $M\n\\in \\mathbb{R}^{n \\times n}$, a weight matrix $W \\in \\mathbb{R}_{\\geq 0}^{n\n\\times n}$, a parameter $k$, the goal is to output two matrices $U, V \\in\n\\mathbb{R}^{n \\times k}$ such that $\\| W \\circ (M - U V^\\top) \\|_F$ is\nminimized, where $\\circ$ denotes the Hadamard product. Such a problem is known\nto be NP-hard and even hard to approximate assuming Exponential Time Hypothesis\n[GG11, RSW16]. Meanwhile, alternating minimization is a good heuristic solution\nfor approximating weighted low rank approximation. The work [LLR16] shows that,\nunder mild assumptions, alternating minimization does provide provable\nguarantees. In this work, we develop an efficient and robust framework for\nalternating minimization. For weighted low rank approximation, this improves\nthe runtime of [LLR16] from $n^2 k^2$ to $n^2k$. At the heart of our work\nframework is a high-accuracy multiple response regression solver together with\na robust analysis of alternating minimization.",
          "link": "http://arxiv.org/abs/2306.04169",
          "publishedOn": "2023-07-29T00:48:57.571Z",
          "wordCount": null,
          "title": "Efficient Alternating Minimization with Applications to Weighted Low Rank Approximation. (arXiv:2306.04169v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.05965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Erp_B/0/1/0/all/0/1\">Bart van Erp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nuijten_W/0/1/0/all/0/1\">Wouter W. L. Nuijten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laar_T/0/1/0/all/0/1\">Thijs van de Laar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vries_B/0/1/0/all/0/1\">Bert de Vries</a>",
          "description": "Bayesian state and parameter estimation have been automated effectively in a\nvariety of probabilistic programming languages. The process of model comparison\non the other hand, which still requires error-prone and time-consuming manual\nderivations, is often overlooked despite its importance. This paper efficiently\nautomates Bayesian model averaging, selection, and combination by message\npassing on a Forney-style factor graph with a custom mixture node. Parameter\nand state inference, and model comparison can then be executed simultaneously\nusing message passing with scale factors. This approach shortens the model\ndesign cycle and allows for the straightforward extension to hierarchical and\ntemporal model priors to accommodate for modeling complicated time-varying\nprocesses.",
          "link": "http://arxiv.org/abs/2306.05965",
          "publishedOn": "2023-07-29T00:48:57.570Z",
          "wordCount": null,
          "title": "Automating Model Comparison in Factor Graphs. (arXiv:2306.05965v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.13106",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tee_J/0/1/0/all/0/1\">Jia Yu Tee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Candido_O/0/1/0/all/0/1\">Oliver De Candido</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Utschick_W/0/1/0/all/0/1\">Wolfgang Utschick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiger_P/0/1/0/all/0/1\">Philipp Geiger</a>",
          "description": "Towards safe autonomous driving (AD), we consider the problem of learning\nmodels that accurately capture the diversity and tail quantiles of human driver\nbehavior probability distributions, in interaction with an AD vehicle. Such\nmodels, which predict drivers' continuous actions from their states, are\nparticularly relevant for closing the gap between AD agent simulations and\nreality. To this end, we adapt two flexible quantile learning frameworks for\nthis setting that avoid strong distributional assumptions: (1) quantile\nregression (based on the titled absolute loss), and (2) autoregressive quantile\nflows (a version of normalizing flows). Training happens in a behavior\ncloning-fashion. We use the highD dataset consisting of driver trajectories on\nseveral highways. We evaluate our approach in a one-step acceleration\nprediction task, and in multi-step driver simulation rollouts. We report\nquantitative results using the tilted absolute loss as metric, give qualitative\nexamples showing that realistic extremal behavior can be learned, and discuss\nthe main insights.",
          "link": "http://arxiv.org/abs/2305.13106",
          "publishedOn": "2023-07-29T00:48:57.569Z",
          "wordCount": null,
          "title": "On Learning the Tail Quantiles of Driving Behavior Distributions via Quantile Regression and Flows. (arXiv:2305.13106v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.11892",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blum_A/0/1/0/all/0/1\">Avrim Blum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Okoroafor_P/0/1/0/all/0/1\">Princewill Okoroafor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1\">Aadirupa Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stangl_K/0/1/0/all/0/1\">Kevin Stangl</a>",
          "description": "We consider the vulnerability of fairness-constrained learning to small\namounts of malicious noise in the training data. Konstantinov and Lampert\n(2021) initiated the study of this question and presented negative results\nshowing there exist data distributions where for several fairness constraints,\nany proper learner will exhibit high vulnerability when group sizes are\nimbalanced. Here, we present a more optimistic view, showing that if we allow\nrandomized classifiers, then the landscape is much more nuanced. For example,\nfor Demographic Parity we show we can incur only a $\\Theta(\\alpha)$ loss in\naccuracy, where $\\alpha$ is the malicious noise rate, matching the best\npossible even without fairness constraints. For Equal Opportunity, we show we\ncan incur an $O(\\sqrt{\\alpha})$ loss, and give a matching\n$\\Omega(\\sqrt{\\alpha})$lower bound. In contrast, Konstantinov and Lampert\n(2021) showed for proper learners the loss in accuracy for both notions is\n$\\Omega(1)$. The key technical novelty of our work is how randomization can\nbypass simple \"tricks\" an adversary can use to amplify his power. We also\nconsider additional fairness notions including Equalized Odds and Calibration.\nFor these fairness notions, the excess accuracy clusters into three natural\nregimes $O(\\alpha)$,$O(\\sqrt{\\alpha})$ and $O(1)$. These results provide a more\nfine-grained view of the sensitivity of fairness-constrained learning to\nadversarial noise in training data.",
          "link": "http://arxiv.org/abs/2307.11892",
          "publishedOn": "2023-07-29T00:48:57.569Z",
          "wordCount": null,
          "title": "On the Vulnerability of Fairness Constrained Learning to Malicious Noise. (arXiv:2307.11892v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14938",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Jafarpour_S/0/1/0/all/0/1\">Saber Jafarpour</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Harapanahalli_A/0/1/0/all/0/1\">Akash Harapanahalli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Coogan_S/0/1/0/all/0/1\">Samuel Coogan</a>",
          "description": "In this paper, we propose a computationally efficient framework for interval\nreachability of neural network controlled systems. Our approach builds upon\ninclusion functions for the neural network controller and the open-loop system.\nWe observe that many state-of-the-art neural network verifiers can produce\ninclusion functions for neural networks. We introduce and analyze a new class\nof inclusion functions for the open-loop dynamics based on bounds of the\nfunction Jacobian that is particularly suitable for capturing the interactions\nbetween systems and neural network controllers. Next, for any dynamical system,\nwe use inclusion functions to construct an embedding system with twice the\nnumber of states as the original system. We show that a single trajectory of\nthis embedding system provides hyper-rectangular over-approximations of\nreachable sets. We then propose two approaches for constructing a closed-loop\nembedding system for a neural network controlled dynamical system that accounts\nfor the interaction between the system and the controller in different ways.\nThe interconnection-based approach accounts for the worst-case evolution of\neach coordinate separately by substituting the neural network inclusion\nfunction into the open-loop embedding system. The interaction-based approach\nuses the newly introduced class of Jacobian-based inclusion functions to fully\ncapture first-order interactions between the system and the controller.\nFinally, we implement our approach in a Python framework called\n\\texttt{ReachMM} and show that on several existing benchmarks, our methods\noutperform the existing approaches in the literature. We also demonstrate the\nscalability of our method on a vehicle platooning example with up to $200$\nstates.",
          "link": "http://arxiv.org/abs/2307.14938",
          "publishedOn": "2023-07-29T00:48:57.568Z",
          "wordCount": null,
          "title": "Efficient Interaction-Aware Interval Analysis of Neural Network Feedback Loops. (arXiv:2307.14938v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.10825",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Li_J/0/1/0/all/0/1\">Jiajin Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhu_L/0/1/0/all/0/1\">Linglingzhi Zhu</a>, <a href=\"http://arxiv.org/find/math/1/au:+So_A/0/1/0/all/0/1\">Anthony Man-Cho So</a>",
          "description": "Nonconvex-nonconcave minimax optimization has gained widespread interest over\nthe last decade. However, most existing works focus on variants of gradient\ndescent-ascent (GDA) algorithms, which are only applicable to smooth\nnonconvex-concave settings. To address this limitation, we propose a novel\nalgorithm named smoothed proximal linear descent-ascent (smoothed PLDA), which\ncan effectively handle a broad range of structured nonsmooth\nnonconvex-nonconcave minimax problems. Specifically, we consider the setting\nwhere the primal function has a nonsmooth composite structure and the dual\nfunction possesses the Kurdyka-Lojasiewicz (KL) property with exponent $\\theta\n\\in [0,1)$. We introduce a novel convergence analysis framework for smoothed\nPLDA, the key components of which are our newly developed nonsmooth primal\nerror bound and dual error bound. Using this framework, we show that smoothed\nPLDA can find both $\\epsilon$-game-stationary points and\n$\\epsilon$-optimization-stationary points of the problems of interest in\n$\\mathcal{O}(\\epsilon^{-2\\max\\{2\\theta,1\\}})$ iterations. Furthermore, when\n$\\theta \\in [0,\\frac{1}{2}]$, smoothed PLDA achieves the optimal iteration\ncomplexity of $\\mathcal{O}(\\epsilon^{-2})$. To further demonstrate the\neffectiveness and wide applicability of our analysis framework, we show that\ncertain max-structured problem possesses the KL property with exponent\n$\\theta=0$ under mild assumptions. As a by-product, we establish\nalgorithm-independent quantitative relationships among various stationarity\nconcepts, which may be of independent interest.",
          "link": "http://arxiv.org/abs/2209.10825",
          "publishedOn": "2023-07-29T00:48:57.568Z",
          "wordCount": null,
          "title": "Nonsmooth Nonconvex-Nonconcave Minimax Optimization: Primal-Dual Balancing and Iteration Complexity Analysis. (arXiv:2209.10825v3 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.01524",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kakaiya_R/0/1/0/all/0/1\">Ravi Kakaiya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sathish_R/0/1/0/all/0/1\">Rakshith Sathish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sethuraman_R/0/1/0/all/0/1\">Ramanathan Sethuraman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheet_D/0/1/0/all/0/1\">Debdoot Sheet</a>",
          "description": "Autonomous vehicles and Advanced Driving Assistance Systems (ADAS) have the\npotential to radically change the way we travel. Many such vehicles currently\nrely on segmentation and object detection algorithms to detect and track\nobjects around its surrounding. The data collected from the vehicles are often\nsent to cloud servers to facilitate continual/life-long learning of these\nalgorithms. Considering the bandwidth constraints, the data is compressed\nbefore sending it to servers, where it is typically decompressed for training\nand analysis. In this work, we propose the use of a learning-based compression\nCodec to reduce the overhead in latency incurred for the decompression\noperation in the standard pipeline. We demonstrate that the learned compressed\nrepresentation can also be used to perform tasks like semantic segmentation in\naddition to decompression to obtain the images. We experimentally validate the\nproposed pipeline on the Cityscapes dataset, where we achieve a compression\nfactor up to $66 \\times$ while preserving the information required to perform\nsegmentation with a dice coefficient of $0.84$ as compared to $0.88$ achieved\nusing decompressed images while reducing the overall compute by $11\\%$.",
          "link": "http://arxiv.org/abs/2307.01524",
          "publishedOn": "2023-07-29T00:48:57.567Z",
          "wordCount": null,
          "title": "Exploiting Richness of Learned Compressed Representation of Images for Semantic Segmentation. (arXiv:2307.01524v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.03124",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Surasinghe_S/0/1/0/all/0/1\">Sudam Surasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fish_J/0/1/0/all/0/1\">Jeremie Fish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bollt_E/0/1/0/all/0/1\">Erik M. Bollt</a>",
          "description": "Inference of transfer operators from data is often formulated as a classical\nproblem that hinges on the Ulam method. The conventional description, known as\nthe Ulam-Galerkin method, involves projecting onto basis functions represented\nas characteristic functions supported over a fine grid of rectangles. From this\nperspective, the Ulam-Galerkin approach can be interpreted as density\nestimation using the histogram method. In this study, we recast the problem\nwithin the framework of statistical density estimation. This alternative\nperspective allows for an explicit and rigorous analysis of bias and variance,\nthereby facilitating a discussion on the mean square error. Through\ncomprehensive examples utilizing the logistic map and a Markov map, we\ndemonstrate the validity and effectiveness of this approach in estimating the\neigenvectors of the Frobenius-Perron operator. We compare the performance of\nHistogram Density Estimation(HDE) and Kernel Density Estimation(KDE) methods\nand find that KDE generally outperforms HDE in terms of accuracy. However, it\nis important to note that KDE exhibits limitations around boundary points and\njumps. Based on our research findings, we suggest the possibility of\nincorporating other density estimation methods into this field and propose\nfuture investigations into the application of KDE-based estimation for\nhigh-dimensional maps. These findings provide valuable insights for researchers\nand practitioners working on estimating the Frobenius-Perron operator and\nhighlight the potential of density estimation techniques in this area of study.\n\nKeywords: Transfer Operators; Frobenius-Perron operator; probability density\nestimation; Ulam-Galerkin method; Kernel Density Estimation; Histogram Density\nEstimation.",
          "link": "http://arxiv.org/abs/2210.03124",
          "publishedOn": "2023-07-29T00:48:57.563Z",
          "wordCount": null,
          "title": "Learning Transfer Operators by Kernel Density Estimation. (arXiv:2210.03124v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.07959",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Thaler_S/0/1/0/all/0/1\">Stephan Thaler</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Doehner_G/0/1/0/all/0/1\">Gregor Doehner</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zavadlav_J/0/1/0/all/0/1\">Julija Zavadlav</a>",
          "description": "Neural network (NN) potentials promise highly accurate molecular dynamics\n(MD) simulations within the computational complexity of classical MD force\nfields. However, when applied outside their training domain, NN potential\npredictions can be inaccurate, increasing the need for Uncertainty\nQuantification (UQ). Bayesian modeling provides the mathematical framework for\nUQ, but classical Bayesian methods based on Markov chain Monte Carlo (MCMC) are\ncomputationally intractable for NN potentials. By training graph NN potentials\nfor coarse-grained systems of liquid water and alanine dipeptide, we\ndemonstrate here that scalable Bayesian UQ via stochastic gradient MCMC\n(SG-MCMC) yields reliable uncertainty estimates for MD observables. We show\nthat cold posteriors can reduce the required training data size and that for\nreliable UQ, multiple Markov chains are needed. Additionally, we find that\nSG-MCMC and the Deep Ensemble method achieve comparable results, despite\nshorter training and less hyperparameter tuning of the latter. We show that\nboth methods can capture aleatoric and epistemic uncertainty reliably, but not\nsystematic uncertainty, which needs to be minimized by adequate modeling to\nobtain accurate credible intervals for MD observables. Our results represent a\nstep towards accurate UQ that is of vital importance for trustworthy NN\npotential-based MD simulations required for decision-making in practice.",
          "link": "http://arxiv.org/abs/2212.07959",
          "publishedOn": "2023-07-29T00:48:57.557Z",
          "wordCount": null,
          "title": "Scalable Bayesian Uncertainty Quantification for Neural Network Potentials: Promise and Pitfalls. (arXiv:2212.07959v2 [physics.chem-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.13037",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_V/0/1/0/all/0/1\">Van-Duc Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bui_C/0/1/0/all/0/1\">Cuong-Tien Bui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wen-Syan Li</a>",
          "description": "An end-to-end machine learning (ML) lifecycle consists of many iterative\nprocesses, from data preparation and ML model design to model training and then\ndeploying the trained model for inference. When building an end-to-end\nlifecycle for an ML problem, many ML pipelines must be designed and executed\nthat produce a huge number of lifecycle versions. Therefore, this paper\nintroduces VeML, a Version management system dedicated to end-to-end ML\nLifecycle. Our system tackles several crucial problems that other systems have\nnot solved. First, we address the high cost of building an ML lifecycle,\nespecially for large-scale and high-dimensional dataset. We solve this problem\nby proposing to transfer the lifecycle of similar datasets managed in our\nsystem to the new training data. We design an algorithm based on the core set\nto compute similarity for large-scale, high-dimensional data efficiently.\nAnother critical issue is the model accuracy degradation by the difference\nbetween training data and testing data during the ML lifetime, which leads to\nlifecycle rebuild. Our system helps to detect this mismatch without getting\nlabeled data from testing data and rebuild the ML lifecycle for a new data\nversion. To demonstrate our contributions, we conduct experiments on\nreal-world, large-scale datasets of driving images and spatiotemporal sensor\ndata and show promising results.",
          "link": "http://arxiv.org/abs/2304.13037",
          "publishedOn": "2023-07-29T00:48:57.557Z",
          "wordCount": null,
          "title": "VeML: An End-to-End Machine Learning Lifecycle for Large-scale and High-dimensional Data. (arXiv:2304.13037v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.08890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhan_T/0/1/0/all/0/1\">Tianxiang Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuanpeng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yong Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhen Li</a>",
          "description": "Fuzzy time series forecasting (FTSF) is a typical forecasting method with\nwide application. Traditional FTSF is regarded as an expert system which leads\nto loss of the ability to recognize undefined features. The mentioned is the\nmain reason for poor forecasting with FTSF. To solve the problem, the proposed\nmodel Differential Fuzzy Convolutional Neural Network (DFCNN) utilizes a\nconvolution neural network to re-implement FTSF with learnable ability. DFCNN\nis capable of recognizing potential information and improving forecasting\naccuracy. Thanks to the learnable ability of the neural network, the length of\nfuzzy rules established in FTSF is expended to an arbitrary length that the\nexpert is not able to handle by the expert system. At the same time, FTSF\nusually cannot achieve satisfactory performance of non-stationary time series\ndue to the trend of non-stationary time series. The trend of non-stationary\ntime series causes the fuzzy set established by FTSF to be invalid and causes\nthe forecasting to fail. DFCNN utilizes the Difference algorithm to weaken the\nnon-stationary of time series so that DFCNN can forecast the non-stationary\ntime series with a low error that FTSF cannot forecast in satisfactory\nperformance. After the mass of experiments, DFCNN has an excellent prediction\neffect, which is ahead of the existing FTSF and common time series forecasting\nalgorithms. Finally, DFCNN provides further ideas for improving FTSF and holds\ncontinued research value.",
          "link": "http://arxiv.org/abs/2305.08890",
          "publishedOn": "2023-07-29T00:48:57.557Z",
          "wordCount": null,
          "title": "Differential Convolutional Fuzzy Time Series Forecasting. (arXiv:2305.08890v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15010",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Wang_X/0/1/0/all/0/1\">Xiangzun Wang</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Cichos_F/0/1/0/all/0/1\">Frank Cichos</a>",
          "description": "The processing of information is an indispensable property of living systems\nrealized by networks of active processes with enormous complexity. They have\ninspired many variants of modern machine learning one of them being reservoir\ncomputing, in which stimulating a network of nodes with fading memory enables\ncomputations and complex predictions. Reservoirs are implemented on computer\nhardware, but also on unconventional physical substrates such as mechanical\noscillators, spins, or bacteria often summarized as physical reservoir\ncomputing. Here we demonstrate physical reservoir computing with a synthetic\nactive microparticle system that self-organizes from an active and passive\ncomponent into inherently noisy nonlinear dynamical units. The\nself-organization and dynamical response of the unit is the result of a delayed\npropulsion of the microswimmer to a passive target. A reservoir of such units\nwith a self-coupling via the delayed response can perform predictive tasks\ndespite the strong noise resulting from Brownian motion of the microswimmers.\nTo achieve efficient noise suppression, we introduce a special architecture\nthat uses historical reservoir states for output. Our results pave the way for\nthe study of information processing in synthetic self-organized active particle\nsystems.",
          "link": "http://arxiv.org/abs/2307.15010",
          "publishedOn": "2023-07-29T00:48:57.556Z",
          "wordCount": null,
          "title": "Harnessing Synthetic Active Particles for Physical Reservoir Computing. (arXiv:2307.15010v1 [cond-mat.soft])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.00570",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhou_B/0/1/0/all/0/1\">Bo Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xie_H/0/1/0/all/0/1\">Huidong Xie</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Q/0/1/0/all/0/1\">Qiong Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1\">Xiongchao Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Guo_X/0/1/0/all/0/1\">Xueqi Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Feng_Z/0/1/0/all/0/1\">Zhicheng Feng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_S/0/1/0/all/0/1\">S. Kevin Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_B/0/1/0/all/0/1\">Biao Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rominger_A/0/1/0/all/0/1\">Axel Rominger</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_K/0/1/0/all/0/1\">Kuangyu Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Duncan_J/0/1/0/all/0/1\">James S. Duncan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_C/0/1/0/all/0/1\">Chi Liu</a>",
          "description": "Low-count PET is an efficient way to reduce radiation exposure and\nacquisition time, but the reconstructed images often suffer from low\nsignal-to-noise ratio (SNR), thus affecting diagnosis and other downstream\ntasks. Recent advances in deep learning have shown great potential in improving\nlow-count PET image quality, but acquiring a large, centralized, and diverse\ndataset from multiple institutions for training a robust model is difficult due\nto privacy and security concerns of patient data. Moreover, low-count PET data\nat different institutions may have different data distribution, thus requiring\npersonalized models. While previous federated learning (FL) algorithms enable\nmulti-institution collaborative training without the need of aggregating local\ndata, addressing the large domain shift in the application of\nmulti-institutional low-count PET denoising remains a challenge and is still\nhighly under-explored. In this work, we propose FedFTN, a personalized\nfederated learning strategy that addresses these challenges. FedFTN uses a\nlocal deep feature transformation network (FTN) to modulate the feature outputs\nof a globally shared denoising network, enabling personalized low-count PET\ndenoising for each institution. During the federated learning process, only the\ndenoising network's weights are communicated and aggregated, while the FTN\nremains at the local institutions for feature transformation. We evaluated our\nmethod using a large-scale dataset of multi-institutional low-count PET imaging\ndata from three medical centers located across three continents, and showed\nthat FedFTN provides high-quality low-count PET images, outperforming previous\nbaseline FL reconstruction methods across all low-count levels at all three\ninstitutions.",
          "link": "http://arxiv.org/abs/2304.00570",
          "publishedOn": "2023-07-29T00:48:57.556Z",
          "wordCount": null,
          "title": "FedFTN: Personalized Federated Learning with Deep Feature Transformation Network for Multi-institutional Low-count PET Denoising. (arXiv:2304.00570v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.01913",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marty_T/0/1/0/all/0/1\">Tom Marty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Francois_T/0/1/0/all/0/1\">Tristan Fran&#xe7;ois</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tessier_P/0/1/0/all/0/1\">Pierre Tessier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gauthier_L/0/1/0/all/0/1\">Louis Gauthier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rousseau_L/0/1/0/all/0/1\">Louis-Martin Rousseau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cappart_Q/0/1/0/all/0/1\">Quentin Cappart</a>",
          "description": "Constraint programming is known for being an efficient approach for solving\ncombinatorial problems. Important design choices in a solver are the branching\nheuristics, which are designed to lead the search to the best solutions in a\nminimum amount of time. However, developing these heuristics is a\ntime-consuming process that requires problem-specific expertise. This\nobservation has motivated many efforts to use machine learning to automatically\nlearn efficient heuristics without expert intervention. To the best of our\nknowledge, it is still an open research question. Although several generic\nvariable-selection heuristics are available in the literature, the options for\na generic value-selection heuristic are more scarce. In this paper, we propose\nto tackle this issue by introducing a generic learning procedure that can be\nused to obtain a value-selection heuristic inside a constraint programming\nsolver. This has been achieved thanks to the combination of a deep Q-learning\nalgorithm, a tailored reward signal, and a heterogeneous graph neural network\narchitecture. Experiments on graph coloring, maximum independent set, and\nmaximum cut problems show that our framework is able to find better solutions\nclose to optimality without requiring a large amounts of backtracks while being\ngeneric.",
          "link": "http://arxiv.org/abs/2301.01913",
          "publishedOn": "2023-07-29T00:48:57.555Z",
          "wordCount": null,
          "title": "Learning a Generic Value-Selection Heuristic Inside a Constraint Programming Solver. (arXiv:2301.01913v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.01198",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cotta_L/0/1/0/all/0/1\">Leonardo Cotta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bevilacqua_B/0/1/0/all/0/1\">Beatrice Bevilacqua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_N/0/1/0/all/0/1\">Nesreen Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_B/0/1/0/all/0/1\">Bruno Ribeiro</a>",
          "description": "Existing causal models for link prediction assume an underlying set of\ninherent node factors -- an innate characteristic defined at the node's birth\n-- that governs the causal evolution of links in the graph. In some causal\ntasks, however, link formation is path-dependent: The outcome of link\ninterventions depends on existing links. Unfortunately, these existing causal\nmethods are not designed for path-dependent link formation, as the cascading\nfunctional dependencies between links (arising from path dependence) are either\nunidentifiable or require an impractical number of control variables. To\novercome this, we develop the first causal model capable of dealing with path\ndependencies in link prediction. In this work we introduce the concept of\ncausal lifting, an invariance in causal models of independent interest that, on\ngraphs, allows the identification of causal link prediction queries using\nlimited interventional data. Further, we show how structural pairwise\nembeddings exhibit lower bias and correctly represent the task's causal\nstructure, as opposed to existing node embeddings, e.g., graph neural network\nnode embeddings and matrix factorization. Finally, we validate our theoretical\nfindings on three scenarios for causal link prediction tasks: knowledge base\ncompletion, covariance matrix estimation and consumer-product recommendations.",
          "link": "http://arxiv.org/abs/2302.01198",
          "publishedOn": "2023-07-29T00:48:57.555Z",
          "wordCount": null,
          "title": "Causal Lifting and Link Prediction. (arXiv:2302.01198v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.08720",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Annau_N/0/1/0/all/0/1\">Nicolaas J. Annau</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Cannon_A/0/1/0/all/0/1\">Alex J. Cannon</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Monahan_A/0/1/0/all/0/1\">Adam H. Monahan</a>",
          "description": "This paper explores the application of emerging machine learning methods from\nimage super-resolution (SR) to the task of statistical downscaling. We\nspecifically focus on convolutional neural network-based Generative Adversarial\nNetworks (GANs). Our GANs are conditioned on low-resolution (LR) inputs to\ngenerate high-resolution (HR) surface winds emulating Weather Research and\nForecasting (WRF) model simulations over North America. Unlike traditional SR\nmodels, where LR inputs are idealized coarsened versions of the HR images, WRF\nemulation involves using non-idealized LR and HR pairs resulting in\nshared-scale mismatches due to internal variability. Our study builds upon\ncurrent SR-based statistical downscaling by experimenting with a novel\nfrequency-separation (FS) approach from the computer vision field. To assess\nthe skill of SR models, we carefully select evaluation metrics, and focus on\nperformance measures based on spatial power spectra. Our analyses reveal how\nGAN configurations influence spatial structures in the generated fields,\nparticularly biases in spatial variability spectra. Using power spectra to\nevaluate the FS experiments reveals that successful applications of FS in\ncomputer vision do not translate to climate fields. However, the FS experiments\ndemonstrate the sensitivity of power spectra to a commonly used GAN-based SR\nobjective function, which helps interpret and understand its role in\ndetermining spatial structures. This result motivates the development of a\nnovel partial frequency-separation scheme as a promising configuration option.\nWe also quantify the influence on GAN performance of non-idealized LR fields\nresulting from internal variability. Furthermore, we conduct a spectra-based\nfeature-importance experiment allowing us to explore the dependence of the\nspatial structure of generated fields on different physically relevant LR\ncovariates.",
          "link": "http://arxiv.org/abs/2302.08720",
          "publishedOn": "2023-07-29T00:48:57.554Z",
          "wordCount": null,
          "title": "Algorithmic Hallucinations of Near-Surface Winds: Statistical Downscaling with Generative Adversarial Networks to Convection-Permitting Scales. (arXiv:2302.08720v2 [physics.ao-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.12672",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bogdanov_E/0/1/0/all/0/1\">Eli Bogdanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_I/0/1/0/all/0/1\">Izack Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_A/0/1/0/all/0/1\">Avigdor Gal</a>",
          "description": "In this work we propose an algorithm for trace recovery from stochastically\nknown logs, a setting that is becoming more common with the increasing number\nof sensors and predictive models that generate uncertain data. The suggested\napproach calculates the conformance between a process model and a\nstochastically known trace and recovers the best alignment within this\nstochastic trace as the true trace. The paper offers an analysis of the impact\nof various cost models on trace recovery accuracy and makes use of a product\nmulti-graph to compare alternative trace recovery options. The average accuracy\nof our approach, evaluated using two publicly available datasets, is\nimpressive, with an average recovery accuracy score of 90-97%, significantly\nimproving a common heuristic that chooses the most likely value for each\nuncertain activity. We believe that the effectiveness of the proposed algorithm\nin recovering correct traces from stochastically known logs may be a powerful\naid for developing credible decision-making tools in uncertain settings.",
          "link": "http://arxiv.org/abs/2206.12672",
          "publishedOn": "2023-07-29T00:48:57.552Z",
          "wordCount": null,
          "title": "Trace Recovery from Stochastically Known Logs. (arXiv:2206.12672v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16573",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hasegawa_N/0/1/0/all/0/1\">Naoya Hasegawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sato_I/0/1/0/all/0/1\">Issei Sato</a>",
          "description": "Recognition problems in long-tailed data, where the sample size per class is\nheavily skewed, have recently gained importance because the distribution of the\nsample size per class in a dataset is generally exponential unless the sample\nsize is intentionally adjusted. Various approaches have been devised to address\nthese problems. Recently, weight balancing, which combines well-known classical\nregularization techniques with two-stage training, has been proposed. Despite\nits simplicity, it is known for its high performance against existing methods\ndevised in various ways. However, there is a lack of understanding as to why\nthis approach is effective for long-tailed data. In this study, we analyze the\nmethod focusing on neural collapse and cone effect at each training stage and\nfind that it can be decomposed into the increase in Fisher's discriminant ratio\nof the feature extractor caused by weight decay and cross entropy loss and\nimplicit logit adjustment caused by weight decay and class-balanced loss. Our\nanalysis shows that the training method can be further simplified by reducing\nthe number of training stages to one while increasing accuracy.",
          "link": "http://arxiv.org/abs/2305.16573",
          "publishedOn": "2023-07-29T00:48:57.551Z",
          "wordCount": null,
          "title": "Exploring Weight Balancing on Long-Tailed Recognition Problem. (arXiv:2305.16573v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15019",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khormali_A/0/1/0/all/0/1\">Aminollah Khormali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1\">Jiann-Shiun Yuan</a>",
          "description": "Deepfake detection methods have shown promising results in recognizing\nforgeries within a given dataset, where training and testing take place on the\nin-distribution dataset. However, their performance deteriorates significantly\nwhen presented with unseen samples. As a result, a reliable deepfake detection\nsystem must remain impartial to forgery types, appearance, and quality for\nguaranteed generalizable detection performance. Despite various attempts to\nenhance cross-dataset generalization, the problem remains challenging,\nparticularly when testing against common post-processing perturbations, such as\nvideo compression or blur. Hence, this study introduces a deepfake detection\nframework, leveraging a self-supervised pre-training model that delivers\nexceptional generalization ability, withstanding common corruptions and\nenabling feature explainability. The framework comprises three key components:\na feature extractor based on vision Transformer architecture that is\npre-trained via self-supervised contrastive learning methodology, a graph\nconvolution network coupled with a Transformer discriminator, and a graph\nTransformer relevancy map that provides a better understanding of manipulated\nregions and further explains the model's decision. To assess the effectiveness\nof the proposed framework, several challenging experiments are conducted,\nincluding in-data distribution performance, cross-dataset, cross-manipulation\ngeneralization, and robustness against common post-production perturbations.\nThe results achieved demonstrate the remarkable effectiveness of the proposed\ndeepfake detection framework, surpassing the current state-of-the-art\napproaches.",
          "link": "http://arxiv.org/abs/2307.15019",
          "publishedOn": "2023-07-29T00:48:57.547Z",
          "wordCount": null,
          "title": "Self-Supervised Graph Transformer for Deepfake Detection. (arXiv:2307.15019v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15034",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+White_C/0/1/0/all/0/1\">Colin White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_R/0/1/0/all/0/1\">Renbo Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kossaifi_J/0/1/0/all/0/1\">Jean Kossaifi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pekhimenko_G/0/1/0/all/0/1\">Gennady Pekhimenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azizzadenesheli_K/0/1/0/all/0/1\">Kamyar Azizzadenesheli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>",
          "description": "The Fourier neural operator (FNO) is a powerful technique for learning\nsurrogate maps for partial differential equation (PDE) solution operators. For\nmany real-world applications, which often require high-resolution data points,\ntraining time and memory usage are significant bottlenecks. While there are\nmixed-precision training techniques for standard neural networks, those work\nfor real-valued datatypes on finite dimensions and therefore cannot be directly\napplied to FNO, which crucially operates in the (complex-valued) Fourier domain\nand in function spaces. On the other hand, since the Fourier transform is\nalready an approximation (due to discretization error), we do not need to\nperform the operation at full precision. In this work, we (i) profile memory\nand runtime for FNO with full and mixed-precision training, (ii) conduct a\nstudy on the numerical stability of mixed-precision training of FNO, and (iii)\ndevise a training routine which substantially decreases training time and\nmemory usage (up to 34%), with little or no reduction in accuracy, on the\nNavier-Stokes and Darcy flow equations. Combined with the recently proposed\ntensorized FNO (Kossaifi et al., 2023), the resulting model has far better\nperformance while also being significantly faster than the original FNO.",
          "link": "http://arxiv.org/abs/2307.15034",
          "publishedOn": "2023-07-29T00:48:57.547Z",
          "wordCount": null,
          "title": "Speeding up Fourier Neural Operators via Mixed Precision. (arXiv:2307.15034v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.08411",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kandpal_N/0/1/0/all/0/1\">Nikhil Kandpal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_H/0/1/0/all/0/1\">Haikang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_A/0/1/0/all/0/1\">Adam Roberts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_E/0/1/0/all/0/1\">Eric Wallace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>",
          "description": "The Internet contains a wealth of knowledge -- from the birthdays of\nhistorical figures to tutorials on how to code -- all of which may be learned\nby language models. However, while certain pieces of information are ubiquitous\non the web, others appear extremely rarely. In this paper, we study the\nrelationship between the knowledge memorized by large language models and the\ninformation in pre-training datasets scraped from the web. In particular, we\nshow that a language model's ability to answer a fact-based question relates to\nhow many documents associated with that question were seen during pre-training.\nWe identify these relevant documents by entity linking pre-training datasets\nand counting documents that contain the same entities as a given\nquestion-answer pair. Our results demonstrate strong correlational and causal\nrelationships between accuracy and relevant document count for numerous\nquestion answering datasets (e.g., TriviaQA), pre-training corpora (e.g.,\nROOTS), and model sizes (e.g., 176B parameters). Moreover, while larger models\nare better at learning long-tail knowledge, we estimate that today's models\nmust be scaled by many orders of magnitude to reach competitive QA performance\non questions with little support in the pre-training data. Finally, we show\nthat retrieval-augmentation can reduce the dependence on relevant pre-training\ninformation, presenting a promising approach for capturing the long-tail.",
          "link": "http://arxiv.org/abs/2211.08411",
          "publishedOn": "2023-07-29T00:48:57.546Z",
          "wordCount": null,
          "title": "Large Language Models Struggle to Learn Long-Tail Knowledge. (arXiv:2211.08411v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.12481",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khan_Z/0/1/0/all/0/1\">Zulqarnain Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hill_D/0/1/0/all/0/1\">Davin Hill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masoomi_A/0/1/0/all/0/1\">Aria Masoomi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bone_J/0/1/0/all/0/1\">Joshua Bone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dy_J/0/1/0/all/0/1\">Jennifer Dy</a>",
          "description": "Machine learning methods have significantly improved in their predictive\ncapabilities, but at the same time they are becoming more complex and less\ntransparent. As a result, explainers are often relied on to provide\ninterpretability to these black-box prediction models. As crucial diagnostics\ntools, it is important that these explainers themselves are robust. In this\npaper we focus on one particular aspect of robustness, namely that an explainer\nshould give similar explanations for similar data inputs. We formalize this\nnotion by introducing and defining explainer astuteness, analogous to\nastuteness of prediction functions. Our formalism allows us to connect\nexplainer robustness to the predictor's probabilistic Lipschitzness, which\ncaptures the probability of local smoothness of a function. We provide lower\nbound guarantees on the astuteness of a variety of explainers (e.g., SHAP,\nRISE, CXPlain) given the Lipschitzness of the prediction function. These\ntheoretical results imply that locally smooth prediction functions lend\nthemselves to locally robust explanations. We evaluate these results\nempirically on simulated as well as real datasets.",
          "link": "http://arxiv.org/abs/2206.12481",
          "publishedOn": "2023-07-29T00:48:57.545Z",
          "wordCount": null,
          "title": "Analyzing Explainer Robustness via Lipschitzness of Prediction Functions. (arXiv:2206.12481v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.09924",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hecking_T/0/1/0/all/0/1\">Tobias Hecking</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muthukrishnan_S/0/1/0/all/0/1\">Swathy Muthukrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weinert_A/0/1/0/all/0/1\">Alexander Weinert</a>",
          "description": "Solving parity games is a major building block for numerous applications in\nreactive program verification and synthesis. While they can be solved\nefficiently in practice, no known approach has a polynomial worst-case runtime\ncomplexity. We present a incomplete polynomial-time approach to determining the\nwinning regions of parity games via graph neural networks.\n\nOur evaluation on 900 randomly generated parity games shows that this\napproach is effective and efficient in practice. It correctly determines the\nwinning regions of $\\sim$60\\% of the games in our data set and only incurs\nminor errors in the remaining ones. We believe that this approach can be\nextended to efficiently solve parity games as well.",
          "link": "http://arxiv.org/abs/2210.09924",
          "publishedOn": "2023-07-29T00:48:57.545Z",
          "wordCount": null,
          "title": "Predicting Winning Regions in Parity Games via Graph Neural Networks (Extended Abstract). (arXiv:2210.09924v2 [cs.GT] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.03328",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+So_J/0/1/0/all/0/1\">Jinhyun So</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_R/0/1/0/all/0/1\">Ramy E. Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guler_B/0/1/0/all/0/1\">Basak Guler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1\">Jiantao Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avestimehr_S/0/1/0/all/0/1\">Salman Avestimehr</a>",
          "description": "Secure aggregation is a critical component in federated learning (FL), which\nenables the server to learn the aggregate model of the users without observing\ntheir local models. Conventionally, secure aggregation algorithms focus only on\nensuring the privacy of individual users in a single training round. We contend\nthat such designs can lead to significant privacy leakages over multiple\ntraining rounds, due to partial user selection/participation at each round of\nFL. In fact, we show that the conventional random user selection strategies in\nFL lead to leaking users' individual models within number of rounds that is\nlinear in the number of users. To address this challenge, we introduce a secure\naggregation framework, Multi-RoundSecAgg, with multi-round privacy guarantees.\nIn particular, we introduce a new metric to quantify the privacy guarantees of\nFL over multiple training rounds, and develop a structured user selection\nstrategy that guarantees the long-term privacy of each user (over any number of\ntraining rounds). Our framework also carefully accounts for the fairness and\nthe average number of participating users at each round. Our experiments on\nMNIST and CIFAR-10 datasets in the IID and the non-IID settings demonstrate the\nperformance improvement over the baselines, both in terms of privacy protection\nand test accuracy.",
          "link": "http://arxiv.org/abs/2106.03328",
          "publishedOn": "2023-07-29T00:48:57.544Z",
          "wordCount": null,
          "title": "Securing Secure Aggregation: Mitigating Multi-Round Privacy Leakage in Federated Learning. (arXiv:2106.03328v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.14704",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaozhuan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1\">Luo Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>",
          "description": "Prompt learning approaches have made waves in natural language processing by\ninducing better few-shot performance while they still follow a parametric-based\nlearning paradigm; the oblivion and rote memorization problems in learning may\nencounter unstable generalization issues. Specifically, vanilla prompt learning\nmay struggle to utilize atypical instances by rote during fully-supervised\ntraining or overfit shallow patterns with low-shot data. To alleviate such\nlimitations, we develop RetroPrompt with the motivation of decoupling knowledge\nfrom memorization to help the model strike a balance between generalization and\nmemorization. In contrast with vanilla prompt learning, RetroPrompt constructs\nan open-book knowledge-store from training instances and implements a retrieval\nmechanism during the process of input, training and inference, thus equipping\nthe model with the ability to retrieve related contexts from the training\ncorpus as cues for enhancement. Extensive experiments demonstrate that\nRetroPrompt can obtain better performance in both few-shot and zero-shot\nsettings. Besides, we further illustrate that our proposed RetroPrompt can\nyield better generalization abilities with new datasets. Detailed analysis of\nmemorization indeed reveals RetroPrompt can reduce the reliance of language\nmodels on memorization; thus, improving generalization for downstream tasks.\nCode is available in\nhttps://github.com/zjunlp/PromptKG/tree/main/research/RetroPrompt.",
          "link": "http://arxiv.org/abs/2205.14704",
          "publishedOn": "2023-07-29T00:48:57.544Z",
          "wordCount": null,
          "title": "Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning. (arXiv:2205.14704v4 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.01555",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eldele_E/0/1/0/all/0/1\">Emadeldeen Eldele</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ragab_M/0/1/0/all/0/1\">Mohamed Ragab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhenghua Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1\">Min Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwoh_C/0/1/0/all/0/1\">Chee-Keong Kwoh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoli Li</a>",
          "description": "Unsupervised Domain Adaptation (UDA) has emerged as a powerful solution for\nthe domain shift problem via transferring the knowledge from a labeled source\ndomain to a shifted unlabeled target domain. Despite the prevalence of UDA for\nvisual applications, it remains relatively less explored for time-series\napplications. In this work, we propose a novel lightweight contrastive domain\nadaptation framework called CoTMix for time-series data. Unlike existing\napproaches that either use statistical distances or adversarial techniques, we\nleverage contrastive learning solely to mitigate the distribution shift across\nthe different domains. Specifically, we propose a novel temporal mixup strategy\nto generate two intermediate augmented views for the source and target domains.\nSubsequently, we leverage contrastive learning to maximize the similarity\nbetween each domain and its corresponding augmented view. The generated views\nconsider the temporal dynamics of time-series data during the adaptation\nprocess while inheriting the semantics among the two domains. Hence, we\ngradually push both domains towards a common intermediate space, mitigating the\ndistribution shift across them. Extensive experiments conducted on five\nreal-world time-series datasets show that our approach can significantly\noutperform all state-of-the-art UDA methods. The implementation code of CoTMix\nis available at\n\\href{https://github.com/emadeldeen24/CoTMix}{github.com/emadeldeen24/CoTMix}.",
          "link": "http://arxiv.org/abs/2212.01555",
          "publishedOn": "2023-07-29T00:48:57.544Z",
          "wordCount": null,
          "title": "Contrastive Domain Adaptation for Time-Series via Temporal Mixup. (arXiv:2212.01555v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dambra_S/0/1/0/all/0/1\">Savino Dambra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yufei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aonzo_S/0/1/0/all/0/1\">Simone Aonzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kotzias_P/0/1/0/all/0/1\">Platon Kotzias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vitale_A/0/1/0/all/0/1\">Antonino Vitale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caballero_J/0/1/0/all/0/1\">Juan Caballero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balzarotti_D/0/1/0/all/0/1\">Davide Balzarotti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilge_L/0/1/0/all/0/1\">Leyla Bilge</a>",
          "description": "Many studies have proposed machine-learning (ML) models for malware detection\nand classification, reporting an almost-perfect performance. However, they\nassemble ground-truth in different ways, use diverse static- and\ndynamic-analysis techniques for feature extraction, and even differ on what\nthey consider a malware family. As a consequence, our community still lacks an\nunderstanding of malware classification results: whether they are tied to the\nnature and distribution of the collected dataset, to what extent the number of\nfamilies and samples in the training dataset influence performance, and how\nwell static and dynamic features complement each other.\n\nThis work sheds light on those open questions. by investigating the key\nfactors influencing ML-based malware detection and classification. For this, we\ncollect the largest balanced malware dataset so far with 67K samples from 670\nfamilies (100 samples each), and train state-of-the-art models for malware\ndetection and family classification using our dataset. Our results reveal that\nstatic features perform better than dynamic features, and that combining both\nonly provides marginal improvement over static features. We discover no\ncorrelation between packing and classification accuracy, and that missing\nbehaviors in dynamically-extracted features highly penalize their performance.\nWe also demonstrate how a larger number of families to classify make the\nclassification harder, while a higher number of samples per family increases\naccuracy. Finally, we find that models trained on a uniform distribution of\nsamples per family better generalize on unseen data.",
          "link": "http://arxiv.org/abs/2307.14657",
          "publishedOn": "2023-07-29T00:48:57.543Z",
          "wordCount": null,
          "title": "Decoding the Secrets of Machine Learning in Malware Classification: A Deep Dive into Datasets, Feature Extraction, and Model Performance. (arXiv:2307.14657v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14970",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Sturm_D/0/1/0/all/0/1\">Dominik Sturm</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Maddu_S/0/1/0/all/0/1\">Suryanarayana Maddu</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Sbalzarini_I/0/1/0/all/0/1\">Ivo F. Sbalzarini</a>",
          "description": "We use a combination of unsupervised clustering and sparsity-promoting\ninference algorithms to learn locally dominant force balances that explain\nmacroscopic pattern formation in self-organized active particle systems. The\nself-organized emergence of macroscopic patterns from microscopic interactions\nbetween self-propelled particles can be widely observed nature. Although\nhydrodynamic theories help us better understand the physical basis of this\nphenomenon, identifying a sufficient set of local interactions that shape,\nregulate, and sustain self-organized structures in active particle systems\nremains challenging. We investigate a classic hydrodynamic model of\nself-propelled particles that produces a wide variety of patterns, like asters\nand moving density bands. Our data-driven analysis shows that propagating bands\nare formed by local alignment interactions driven by density gradients, while\nsteady-state asters are shaped by a mechanism of splay-induced negative\ncompressibility arising from strong particle interactions. Our method also\nreveals analogous physical principles of pattern formation in a system where\nthe speed of the particle is influenced by local density. This demonstrates the\nability of our method to reveal physical commonalities across models. The\nphysical mechanisms inferred from the data are in excellent agreement with\nanalytical scaling arguments and experimental observations.",
          "link": "http://arxiv.org/abs/2307.14970",
          "publishedOn": "2023-07-29T00:48:57.543Z",
          "wordCount": null,
          "title": "Learning locally dominant force balances in active particle systems. (arXiv:2307.14970v1 [cond-mat.soft])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2005.00695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Sen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyang R. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valiant_G/0/1/0/all/0/1\">Gregory Valiant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Re_C/0/1/0/all/0/1\">Christopher R&#xe9;</a>",
          "description": "Data augmentation is a powerful technique to improve performance in\napplications such as image and text classification tasks. Yet, there is little\nrigorous understanding of why and how various augmentations work. In this work,\nwe consider a family of linear transformations and study their effects on the\nridge estimator in an over-parametrized linear regression setting. First, we\nshow that transformations that preserve the labels of the data can improve\nestimation by enlarging the span of the training data. Second, we show that\ntransformations that mix data can improve estimation by playing a\nregularization effect. Finally, we validate our theoretical insights on MNIST.\nBased on the insights, we propose an augmentation scheme that searches over the\nspace of transformations by how uncertain the model is about the transformed\ndata. We validate our proposed scheme on image and text datasets. For example,\nour method outperforms random sampling methods by 1.24% on CIFAR-100 using\nWide-ResNet-28-10. Furthermore, we achieve comparable accuracy to the SoTA\nAdversarial AutoAugment on CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.",
          "link": "http://arxiv.org/abs/2005.00695",
          "publishedOn": "2023-07-29T00:48:57.543Z",
          "wordCount": null,
          "title": "On the Generalization Effects of Linear Transformations in Data Augmentation. (arXiv:2005.00695v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15053",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeunen_O/0/1/0/all/0/1\">Olivier Jeunen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potapov_I/0/1/0/all/0/1\">Ivan Potapov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ustimenko_A/0/1/0/all/0/1\">Aleksei Ustimenko</a>",
          "description": "Approaches to recommendation are typically evaluated in one of two ways: (1)\nvia a (simulated) online experiment, often seen as the gold standard, or (2)\nvia some offline evaluation procedure, where the goal is to approximate the\noutcome of an online experiment. Several offline evaluation metrics have been\nadopted in the literature, inspired by ranking metrics prevalent in the field\nof Information Retrieval. (Normalised) Discounted Cumulative Gain (nDCG) is one\nsuch metric that has seen widespread adoption in empirical studies, and higher\n(n)DCG values have been used to present new methods as the state-of-the-art in\ntop-$n$ recommendation for many years.\n\nOur work takes a critical look at this approach, and investigates when we can\nexpect such metrics to approximate the gold standard outcome of an online\nexperiment. We formally present the assumptions that are necessary to consider\nDCG an unbiased estimator of online reward and provide a derivation for this\nmetric from first principles, highlighting where we deviate from its\ntraditional uses in IR. Importantly, we show that normalising the metric\nrenders it inconsistent, in that even when DCG is unbiased, ranking competing\nmethods by their normalised DCG can invert their relative order. Through a\ncorrelation analysis between off- and on-line experiments conducted on a\nlarge-scale recommendation platform, we show that our unbiased DCG estimates\nstrongly correlate with online reward, even when some of the metric's inherent\nassumptions are violated. This statement no longer holds for its normalised\nvariant, suggesting that nDCG's practical utility may be limited.",
          "link": "http://arxiv.org/abs/2307.15053",
          "publishedOn": "2023-07-29T00:48:57.542Z",
          "wordCount": null,
          "title": "On (Normalised) Discounted Cumulative Gain as an Offline Evaluation Metric for Top-$n$ Recommendation. (arXiv:2307.15053v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.02626",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Bena_G/0/1/0/all/0/1\">Gabriel B&#xe9;na</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Goodman_D/0/1/0/all/0/1\">Dan F. M. Goodman</a>",
          "description": "It has long been believed that the brain is highly modular both in terms of\nstructure and function, although recent evidence has led some to question the\nextent of both types of modularity. We used artificial neural networks to test\nthe hypothesis that structural modularity is sufficient to guarantee functional\nspecialization, and find that in general, this doesn't necessarily hold except\nat extreme levels. We then systematically tested which features of the\nenvironment and network do lead to the emergence of specialization. We used a\nsimple toy environment, task and network, allowing us precise control, and show\nthat in this setup, several distinct measures of specialization give\nqualitatively similar results. We further find that (1) specialization can only\nemerge in environments where features of that environment are meaningfully\nseparable, (2) specialization preferentially emerges when the network is\nstrongly resource-constrained, and (3) these findings are qualitatively similar\nacross different network architectures, but the quantitative relationships\ndepends on the architecture type. Finally, we show that functional\nspecialization varies dynamically across time, and demonstrate that these\ndynamics depend on both the timing and bandwidth of information flow in the\nnetwork. We conclude that a static notion of specialization, based on\nstructural modularity, is likely too simple a framework for understanding\nintelligent systems in situations of real-world complexity. We propose that\nthoroughly stress testing candidate definitions of functional modularity in\nsimplified scenarios before extending to more complex data, network models and\nelectrophysiological recordings is likely to be a fruitful approach.",
          "link": "http://arxiv.org/abs/2106.02626",
          "publishedOn": "2023-07-29T00:48:57.542Z",
          "wordCount": null,
          "title": "Dynamics of specialization in neural modules under resource constraints. (arXiv:2106.02626v2 [q-bio.NC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.11838",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abate_A/0/1/0/all/0/1\">Alessandro Abate</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Almulla_Y/0/1/0/all/0/1\">Yousif Almulla</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Fox_J/0/1/0/all/0/1\">James Fox</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Hyland_D/0/1/0/all/0/1\">David Hyland</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Wooldridge_M/0/1/0/all/0/1\">Michael Wooldridge</a> (1) ((1) University of Oxford)",
          "description": "Training reinforcement learning (RL) agents using scalar reward signals is\noften infeasible when an environment has sparse and non-Markovian rewards.\nMoreover, handcrafting these reward functions before training is prone to\nmisspecification, especially when the environment's dynamics are only partially\nknown. This paper proposes a novel pipeline for learning non-Markovian task\nspecifications as succinct finite-state `task automata' from episodes of agent\nexperience within unknown environments. We leverage two key algorithmic\ninsights. First, we learn a product MDP, a model composed of the\nspecification's automaton and the environment's MDP (both initially unknown),\nby treating the product MDP as a partially observable MDP and using the\nwell-known Baum-Welch algorithm for learning hidden Markov models. Second, we\npropose a novel method for distilling the task automaton (assumed to be a\ndeterministic finite automaton) from the learnt product MDP. Our learnt task\nautomaton enables the decomposition of a task into its constituent sub-tasks,\nwhich improves the rate at which an RL agent can later synthesise an optimal\npolicy. It also provides an interpretable encoding of high-level environmental\nand task features, so a human can readily verify that the agent has learnt\ncoherent tasks with no misspecifications. In addition, we take steps towards\nensuring that the learnt automaton is environment-agnostic, making it\nwell-suited for use in transfer learning. Finally, we provide experimental\nresults compared with two baselines to illustrate our algorithm's performance\nin different environments and tasks.",
          "link": "http://arxiv.org/abs/2208.11838",
          "publishedOn": "2023-07-29T00:48:57.542Z",
          "wordCount": null,
          "title": "Learning Task Automata for Reinforcement Learning using Hidden Markov Models. (arXiv:2208.11838v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14343",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+R_A/0/1/0/all/0/1\">Amarnath R</a>, <a href=\"http://arxiv.org/find/cs/1/au:+V_V/0/1/0/all/0/1\">Vinay Kumar V</a>",
          "description": "Recognizing handwritten digits is a challenging task primarily due to the\ndiversity of writing styles and the presence of noisy images. The widely used\nMNIST dataset, which is commonly employed as a benchmark for this task,\nincludes distorted digits with irregular shapes, incomplete strokes, and\nvarying skew in both the training and testing datasets. Consequently, these\nfactors contribute to reduced accuracy in digit recognition. To overcome this\nchallenge, we propose a two-stage deep learning approach. In the first stage,\nwe create a simple neural network to identify distorted digits within the\ntraining set. This model serves to detect and filter out such distorted and\nambiguous images. In the second stage, we exclude these identified images from\nthe training dataset and proceed to retrain the model using the filtered\ndataset. This process aims to improve the classification accuracy and\nconfidence levels while mitigating issues of underfitting and overfitting. Our\nexperimental results demonstrate the effectiveness of the proposed approach,\nachieving an accuracy rate of over 99.5% on the testing dataset. This\nsignificant improvement showcases the potential of our method in enhancing\ndigit classification accuracy. In our future work, we intend to explore the\nscalability of this approach and investigate techniques to further enhance\naccuracy by reducing the size of the training data.",
          "link": "http://arxiv.org/abs/2307.14343",
          "publishedOn": "2023-07-29T00:48:57.541Z",
          "wordCount": null,
          "title": "Pruning Distorted Images in MNIST Handwritten Digits. (arXiv:2307.14343v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14758",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cobb_O/0/1/0/all/0/1\">Oliver Cobb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Looveren_A/0/1/0/all/0/1\">Arnaud Van Looveren</a>",
          "description": "There is a growing awareness of the harmful effects of distribution shift on\nthe performance of deployed machine learning models. Consequently, there is a\ngrowing interest in detecting these shifts before associated costs have time to\naccumulate. However, desiderata of crucial importance to the practicable\ndeployment of sequential shift detectors are typically overlooked by existing\nworks, precluding their widespread adoption. We identify three such desiderata,\nhighlight existing works relevant to their satisfaction, and recommend\nimpactful directions for future research.",
          "link": "http://arxiv.org/abs/2307.14758",
          "publishedOn": "2023-07-29T00:48:57.541Z",
          "wordCount": null,
          "title": "Towards Practicable Sequential Shift Detectors. (arXiv:2307.14758v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14565",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yeye He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_C/0/1/0/all/0/1\">Cong Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chauduri_S/0/1/0/all/0/1\">Surajit Chauduri</a>",
          "description": "Relational tables, where each row corresponds to an entity and each column\ncorresponds to an attribute, have been the standard for tables in relational\ndatabases. However, such a standard cannot be taken for granted when dealing\nwith tables \"in the wild\". Our survey of real spreadsheet-tables and web-tables\nshows that over 30% of such tables do not conform to the relational standard,\nfor which complex table-restructuring transformations are needed before these\ntables can be queried easily using SQL-based analytics tools. Unfortunately,\nthe required transformations are non-trivial to program, which has become a\nsubstantial pain point for technical and non-technical users alike, as\nevidenced by large numbers of forum questions in places like StackOverflow and\nExcel/Tableau forums.\n\nWe develop an Auto-Tables system that can automatically synthesize pipelines\nwith multi-step transformations (in Python or other languages), to transform\nnon-relational tables into standard relational forms for downstream analytics,\nobviating the need for users to manually program transformations. We compile an\nextensive benchmark for this new task, by collecting 194 real test cases from\nuser spreadsheets and online forums. Our evaluation suggests that Auto-Tables\ncan successfully synthesize transformations for over 70% of test cases at\ninteractive speeds, without requiring any input from users, making this an\neffective tool for both technical and non-technical users to prepare data for\nanalytics.",
          "link": "http://arxiv.org/abs/2307.14565",
          "publishedOn": "2023-07-29T00:48:57.540Z",
          "wordCount": null,
          "title": "Auto-Tables: Synthesizing Multi-Step Transformations to Relationalize Tables without Using Examples. (arXiv:2307.14565v1 [cs.DB])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14653",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Seroussi_I/0/1/0/all/0/1\">Inbar Seroussi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Alemi_A/0/1/0/all/0/1\">Alexander A. Alemi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Helias_M/0/1/0/all/0/1\">Moritz Helias</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ringel_Z/0/1/0/all/0/1\">Zohar Ringel</a>",
          "description": "State-of-the-art neural networks require extreme computational power to\ntrain. It is therefore natural to wonder whether they are optimally trained.\nHere we apply a recent advancement in stochastic thermodynamics which allows\nbounding the speed at which one can go from the initial weight distribution to\nthe final distribution of the fully trained network, based on the ratio of\ntheir Wasserstein-2 distance and the entropy production rate of the dynamical\nprocess connecting them. Considering both gradient-flow and Langevin training\ndynamics, we provide analytical expressions for these speed limits for linear\nand linearizable neural networks e.g. Neural Tangent Kernel (NTK). Remarkably,\ngiven some plausible scaling assumptions on the NTK spectra and spectral\ndecomposition of the labels -- learning is optimal in a scaling sense. Our\nresults are consistent with small-scale experiments with Convolutional Neural\nNetworks (CNNs) and Fully Connected Neural networks (FCNs) on CIFAR-10, showing\na short highly non-optimal regime followed by a longer optimal regime.",
          "link": "http://arxiv.org/abs/2307.14653",
          "publishedOn": "2023-07-29T00:48:57.500Z",
          "wordCount": null,
          "title": "Speed Limits for Deep Learning. (arXiv:2307.14653v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14754",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oesterling_A/0/1/0/all/0/1\">Alex Oesterling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jiaqi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calmon_F/0/1/0/all/0/1\">Flavio P. Calmon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1\">Hima Lakkaraju</a>",
          "description": "As public consciousness regarding the collection and use of personal\ninformation by corporations grows, it is of increasing importance that\nconsumers be active participants in the curation of corporate datasets. In\nlight of this, data governance frameworks such as the General Data Protection\nRegulation (GDPR) have outlined the right to be forgotten as a key principle\nallowing individuals to request that their personal data be deleted from the\ndatabases and models used by organizations. To achieve forgetting in practice,\nseveral machine unlearning methods have been proposed to address the\ncomputational inefficiencies of retraining a model from scratch with each\nunlearning request. While efficient online alternatives to retraining, it is\nunclear how these methods impact other properties critical to real-world\napplications, such as fairness. In this work, we propose the first fair machine\nunlearning method that can provably and efficiently unlearn data instances\nwhile preserving group fairness. We derive theoretical results which\ndemonstrate that our method can provably unlearn data instances while\nmaintaining fairness objectives. Extensive experimentation with real-world\ndatasets highlight the efficacy of our method at unlearning data instances\nwhile preserving fairness.",
          "link": "http://arxiv.org/abs/2307.14754",
          "publishedOn": "2023-07-29T00:48:57.500Z",
          "wordCount": null,
          "title": "Fair Machine Unlearning: Data Removal while Mitigating Disparities. (arXiv:2307.14754v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15045",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Momeni_S/0/1/0/all/0/1\">Saleh Momeni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+BabaAli_B/0/1/0/all/0/1\">Bagher BabaAli</a>",
          "description": "Handwriting recognition is a challenging and critical problem in the fields\nof pattern recognition and machine learning, with applications spanning a wide\nrange of domains. In this paper, we focus on the specific issue of recognizing\noffline Arabic handwritten text. Existing approaches typically utilize a\ncombination of convolutional neural networks for image feature extraction and\nrecurrent neural networks for temporal modeling, with connectionist temporal\nclassification used for text generation. However, these methods suffer from a\nlack of parallelization due to the sequential nature of recurrent neural\nnetworks. Furthermore, these models cannot account for linguistic rules,\nnecessitating the use of an external language model in the post-processing\nstage to boost accuracy. To overcome these issues, we introduce two alternative\narchitectures, namely the Transformer Transducer and the standard\nsequence-to-sequence Transformer, and compare their performance in terms of\naccuracy and speed. Our approach can model language dependencies and relies\nonly on the attention mechanism, thereby making it more parallelizable and less\ncomplex. We employ pre-trained Transformers for both image understanding and\nlanguage modeling. Our evaluation on the Arabic KHATT dataset demonstrates that\nour proposed method outperforms the current state-of-the-art approaches for\nrecognizing offline Arabic handwritten text.",
          "link": "http://arxiv.org/abs/2307.15045",
          "publishedOn": "2023-07-29T00:48:57.500Z",
          "wordCount": null,
          "title": "A Transformer-based Approach for Arabic Offline Handwritten Text Recognition. (arXiv:2307.15045v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1\">Nancy Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kosma_C/0/1/0/all/0/1\">Chrysoula Kosma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vazirgiannis_M/0/1/0/all/0/1\">Michalis Vazirgiannis</a>",
          "description": "Time series forecasting lies at the core of important real-world applications\nin many fields of science and engineering. The abundance of large time series\ndatasets that consist of complex patterns and long-term dependencies has led to\nthe development of various neural network architectures. Graph neural network\napproaches, which jointly learn a graph structure based on the correlation of\nraw values of multivariate time series while forecasting, have recently seen\ngreat success. However, such solutions are often costly to train and difficult\nto scale. In this paper, we propose TimeGNN, a method that learns dynamic\ntemporal graph representations that can capture the evolution of inter-series\npatterns along with the correlations of multiple series. TimeGNN achieves\ninference times 4 to 80 times faster than other state-of-the-art graph-based\nmethods while achieving comparable forecasting performance",
          "link": "http://arxiv.org/abs/2307.14680",
          "publishedOn": "2023-07-29T00:48:57.499Z",
          "wordCount": null,
          "title": "TimeGNN: Temporal Dynamic Graph Learning for Time Series Forecasting. (arXiv:2307.14680v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14783",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sulun_S/0/1/0/all/0/1\">Serkan Sulun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Oliveira_P/0/1/0/all/0/1\">Pedro Oliveira</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Viana_P/0/1/0/all/0/1\">Paula Viana</a>",
          "description": "We present a new large-scale emotion-labeled symbolic music dataset\nconsisting of 12k MIDI songs. To create this dataset, we first trained emotion\nclassification models on the GoEmotions dataset, achieving state-of-the-art\nresults with a model half the size of the baseline. We then applied these\nmodels to lyrics from two large-scale MIDI datasets. Our dataset covers a wide\nrange of fine-grained emotions, providing a valuable resource to explore the\nconnection between music and emotions and, especially, to develop models that\ncan generate music based on specific emotions. Our code for inference, trained\nmodels, and datasets are available online.",
          "link": "http://arxiv.org/abs/2307.14783",
          "publishedOn": "2023-07-29T00:48:57.499Z",
          "wordCount": null,
          "title": "Emotion4MIDI: a Lyrics-based Emotion-Labeled Symbolic Music Dataset. (arXiv:2307.14783v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.11264",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Feihu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Li</a>",
          "description": "In the paper, we propose an effective and efficient Compositional Federated\nLearning (ComFedL) algorithm for solving a new compositional Federated Learning\n(FL) framework, which frequently appears in many data mining and machine\nlearning problems with a hierarchical structure such as distributionally robust\nFL and model-agnostic meta learning (MAML). Moreover, we study the convergence\nanalysis of our ComFedL algorithm under some mild conditions, and prove that it\nachieves a convergence rate of $O(\\frac{1}{\\sqrt{T}})$, where $T$ denotes the\nnumber of iteration. To the best of our knowledge, our new Compositional FL\nframework is the first work to bridge federated learning with composition\nstochastic optimization. In particular, we first transform the distributionally\nrobust FL (i.e., a minimax optimization problem) into a simple composition\noptimization problem by using KL divergence regularization. At the same time,\nwe also first transform the distribution-agnostic MAML problem (i.e., a minimax\noptimization problem) into a simple yet effective composition optimization\nproblem. Finally, we apply two popular machine learning tasks, i.e.,\ndistributionally robust FL and MAML to demonstrate the effectiveness of our\nalgorithm.",
          "link": "http://arxiv.org/abs/2106.11264",
          "publishedOn": "2023-07-29T00:48:57.499Z",
          "wordCount": null,
          "title": "Compositional federated learning: Applications in distributionally robust averaging and meta learning. (arXiv:2106.11264v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14778",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1\">Jing Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_T/0/1/0/all/0/1\">Tianqi Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dongbo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>",
          "description": "Non-intrusive load monitoring (NILM) identifies the status and power\nconsumption of various household appliances by disaggregating the total power\nusage signal of an entire house. Efficient and accurate load monitoring\nfacilitates user profile establishment, intelligent household energy\nmanagement, and peak load shifting. This is beneficial for both the end-users\nand utilities by improving the overall efficiency of a power distribution\nnetwork. Existing approaches mainly focus on developing an individual model for\neach appliance. Those approaches typically rely on a large amount of\nhousehold-labeled data which is hard to collect. In this paper, we propose a\nmulti-appliance-task framework with a training-efficient sample augmentation\n(SA) scheme that boosts the disaggregation performance with limited labeled\ndata. For each appliance, we develop a shared-hierarchical split structure for\nits regression and classification tasks. In addition, we also propose a\ntwo-dimensional attention mechanism in order to capture spatio-temporal\ncorrelations among all appliances. With only one-day training data and limited\nappliance operation profiles, the proposed SA algorithm can achieve comparable\ntest performance to the case of training with the full dataset. Finally,\nsimulation results show that our proposed approach features a significantly\nimproved performance over many baseline models. The relative errors can be\nreduced by more than 50\\% on average. The codes of this work are available at\nhttps://github.com/jxiong22/MATNilm",
          "link": "http://arxiv.org/abs/2307.14778",
          "publishedOn": "2023-07-29T00:48:57.498Z",
          "wordCount": null,
          "title": "MATNilm: Multi-appliance-task Non-intrusive Load Monitoring with Limited Labeled Data. (arXiv:2307.14778v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14906",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wilm_T/0/1/0/all/0/1\">Timo Wilm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Normann_P/0/1/0/all/0/1\">Philipp Normann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baumeister_S/0/1/0/all/0/1\">Sophie Baumeister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kobow_P/0/1/0/all/0/1\">Paul-Vincent Kobow</a>",
          "description": "This work introduces TRON, a scalable session-based Transformer Recommender\nusing Optimized Negative-sampling. Motivated by the scalability and performance\nlimitations of prevailing models such as SASRec and GRU4Rec+, TRON integrates\ntop-k negative sampling and listwise loss functions to enhance its\nrecommendation accuracy. Evaluations on relevant large-scale e-commerce\ndatasets show that TRON improves upon the recommendation quality of current\nmethods while maintaining training speeds similar to SASRec. A live A/B test\nyielded an 18.14% increase in click-through rate over SASRec, highlighting the\npotential of TRON in practical settings. For further research, we provide\naccess to our source code at https://github.com/otto-de/TRON and an anonymized\ndataset at https://github.com/otto-de/recsys-dataset.",
          "link": "http://arxiv.org/abs/2307.14906",
          "publishedOn": "2023-07-29T00:48:57.498Z",
          "wordCount": null,
          "title": "Scaling Session-Based Transformer Recommendations using Optimized Negative Sampling and Loss Functions. (arXiv:2307.14906v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.06848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cannizzaro_R/0/1/0/all/0/1\">Ricardo Cannizzaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kunze_L/0/1/0/all/0/1\">Lars Kunze</a>",
          "description": "Robots operating in real-world environments must reason about possible\noutcomes of stochastic actions and make decisions based on partial observations\nof the true world state. A major challenge for making accurate and robust\naction predictions is the problem of confounding, which if left untreated can\nlead to prediction errors. The partially observable Markov decision process\n(POMDP) is a widely-used framework to model these stochastic and\npartially-observable decision-making problems. However, due to a lack of\nexplicit causal semantics, POMDP planning methods are prone to confounding bias\nand thus in the presence of unobserved confounders may produce underperforming\npolicies. This paper presents a novel causally-informed extension of \"anytime\nregularized determinized sparse partially observable tree\" (AR-DESPOT), a\nmodern anytime online POMDP planner, using causal modelling and inference to\neliminate errors caused by unmeasured confounder variables. We further propose\na method to learn offline the partial parameterisation of the causal model for\nplanning, from ground truth model data. We evaluate our methods on a toy\nproblem with an unobserved confounder and show that the learned causal model is\nhighly accurate, while our planning method is more robust to confounding and\nproduces overall higher performing policies than AR-DESPOT.",
          "link": "http://arxiv.org/abs/2304.06848",
          "publishedOn": "2023-07-29T00:48:57.497Z",
          "wordCount": null,
          "title": "CAR-DESPOT: Causally-Informed Online POMDP Planning for Robots in Confounded Environments. (arXiv:2304.06848v3 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14971",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xumin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1\">Yongming Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiwen Lu</a>",
          "description": "With the overwhelming trend of mask image modeling led by MAE, generative\npre-training has shown a remarkable potential to boost the performance of\nfundamental models in 2D vision. However, in 3D vision, the over-reliance on\nTransformer-based backbones and the unordered nature of point clouds have\nrestricted the further development of generative pre-training. In this paper,\nwe propose a novel 3D-to-2D generative pre-training method that is adaptable to\nany point cloud model. We propose to generate view images from different\ninstructed poses via the cross-attention mechanism as the pre-training scheme.\nGenerating view images has more precise supervision than its point cloud\ncounterpart, thus assisting 3D backbones to have a finer comprehension of the\ngeometrical structure and stereoscopic relations of the point cloud.\nExperimental results have proved the superiority of our proposed 3D-to-2D\ngenerative pre-training over previous pre-training methods. Our method is also\neffective in boosting the performance of architecture-oriented approaches,\nachieving state-of-the-art performance when fine-tuning on ScanObjectNN\nclassification and ShapeNetPart segmentation tasks. Code is available at\nhttps://github.com/wangzy22/TAP.",
          "link": "http://arxiv.org/abs/2307.14971",
          "publishedOn": "2023-07-29T00:48:57.486Z",
          "wordCount": null,
          "title": "Take-A-Photo: 3D-to-2D Generative Pre-training of Point Cloud Models. (arXiv:2307.14971v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14940",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Coelho_C/0/1/0/all/0/1\">C. Coelho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_M/0/1/0/all/0/1\">M. Fernanda P. Costa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferras_L/0/1/0/all/0/1\">L. L. Ferr&#xe1;s</a>",
          "description": "The continuous dynamics of natural systems has been effectively modelled\nusing Neural Ordinary Differential Equations (Neural ODEs). However, for\naccurate and meaningful predictions, it is crucial that the models follow the\nunderlying rules or laws that govern these systems. In this work, we propose a\nself-adaptive penalty algorithm for Neural ODEs to enable modelling of\nconstrained natural systems. The proposed self-adaptive penalty function can\ndynamically adjust the penalty parameters. The explicit introduction of prior\nknowledge helps to increase the interpretability of Neural ODE -based models.\nWe validate the proposed approach by modelling three natural systems with prior\nknowledge constraints: population growth, chemical reaction evolution, and\ndamped harmonic oscillator motion. The numerical experiments and a comparison\nwith other penalty Neural ODE approaches and \\emph{vanilla} Neural ODE,\ndemonstrate the effectiveness of the proposed self-adaptive penalty algorithm\nfor Neural ODEs in modelling constrained natural systems. Moreover, the\nself-adaptive penalty approach provides more accurate and robust models with\nreliable and meaningful predictions.",
          "link": "http://arxiv.org/abs/2307.14940",
          "publishedOn": "2023-07-29T00:48:57.485Z",
          "wordCount": null,
          "title": "A Self-Adaptive Penalty Method for Integrating Prior Knowledge Constraints into Neural ODEs. (arXiv:2307.14940v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14953",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Montesuma_E/0/1/0/all/0/1\">Eduardo Fernandes Montesuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mboula_F/0/1/0/all/0/1\">Fred Ngol&#xe8; Mboula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Souloumiac_A/0/1/0/all/0/1\">Antoine Souloumiac</a>",
          "description": "This paper seeks to solve Multi-Source Domain Adaptation (MSDA), which aims\nto mitigate data distribution shifts when transferring knowledge from multiple\nlabeled source domains to an unlabeled target domain. We propose a novel MSDA\nframework based on dictionary learning and optimal transport. We interpret each\ndomain in MSDA as an empirical distribution. As such, we express each domain as\na Wasserstein barycenter of dictionary atoms, which are empirical\ndistributions. We propose a novel algorithm, DaDiL, for learning via\nmini-batches: (i) atom distributions; (ii) a matrix of barycentric coordinates.\nBased on our dictionary, we propose two novel methods for MSDA: DaDil-R, based\non the reconstruction of labeled samples in the target domain, and DaDiL-E,\nbased on the ensembling of classifiers learned on atom distributions. We\nevaluate our methods in 3 benchmarks: Caltech-Office, Office 31, and CRWU,\nwhere we improved previous state-of-the-art by 3.15%, 2.29%, and 7.71% in\nclassification performance. Finally, we show that interpolations in the\nWasserstein hull of learned atoms provide data that can generalize to the\ntarget domain.",
          "link": "http://arxiv.org/abs/2307.14953",
          "publishedOn": "2023-07-29T00:48:57.485Z",
          "wordCount": null,
          "title": "Multi-Source Domain Adaptation through Dataset Dictionary Learning in Wasserstein Space. (arXiv:2307.14953v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14823",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dubinin_I/0/1/0/all/0/1\">Igor Dubinin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Effenberger_F/0/1/0/all/0/1\">Felix Effenberger</a>",
          "description": "Residual connections have been proposed as architecture-based inductive bias\nto mitigate the problem of exploding and vanishing gradients and increase task\nperformance in both feed-forward and recurrent networks (RNNs) when trained\nwith the backpropagation algorithm. Yet, little is known about how residual\nconnections in RNNs influence their dynamics and fading memory properties.\nHere, we introduce weakly coupled residual recurrent networks (WCRNNs) in which\nresidual connections result in well-defined Lyapunov exponents and allow for\nstudying properties of fading memory. We investigate how the residual\nconnections of WCRNNs influence their performance, network dynamics, and memory\nproperties on a set of benchmark tasks. We show that several distinct forms of\nresidual connections yield effective inductive biases that result in increased\nnetwork expressivity. In particular, residual connections that (i) result in\nnetwork dynamics at the proximity of the edge of chaos, (ii) allow networks to\ncapitalize on characteristic spectral properties of the data, and (iii) result\nin heterogeneous memory properties are shown to increase practical\nexpressivity. In addition, we demonstrate how our results can be extended to\nnon-linear residuals and introduce a weakly coupled residual initialization\nscheme that can be used for Elman RNNs",
          "link": "http://arxiv.org/abs/2307.14823",
          "publishedOn": "2023-07-29T00:48:57.484Z",
          "wordCount": null,
          "title": "Fading memory as inductive bias in residual recurrent networks. (arXiv:2307.14823v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14936",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_B/0/1/0/all/0/1\">Bo Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiaxin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Taihong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zan_D/0/1/0/all/0/1\">Daoguang Zan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_B/0/1/0/all/0/1\">Bing Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_A/0/1/0/all/0/1\">An Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Muhan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_A/0/1/0/all/0/1\">Ailun Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1\">Jichuan Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jingyang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yuenan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qianxiang Wang</a>",
          "description": "Large Language Models for Code (Code LLM) are flourishing. New and powerful\nmodels are released on a weekly basis, demonstrating remarkable performance on\nthe code generation task. Various approaches have been proposed to boost the\ncode generation performance of pre-trained Code LLMs, such as supervised\nfine-tuning, instruction tuning, reinforcement learning, etc. In this paper, we\npropose a novel RRTF (Rank Responses to align Test&Teacher Feedback) framework,\nwhich can effectively and efficiently boost pre-trained large language models\nfor code generation. Under this framework, we present PanGu-Coder2, which\nachieves 62.20% pass@1 on the OpenAI HumanEval benchmark. Furthermore, through\nan extensive evaluation on CoderEval and LeetCode benchmarks, we show that\nPanGu-Coder2 consistently outperforms all previous Code LLMs.",
          "link": "http://arxiv.org/abs/2307.14936",
          "publishedOn": "2023-07-29T00:48:57.483Z",
          "wordCount": null,
          "title": "PanGu-Coder2: Boosting Large Language Models for Code with Ranking Feedback. (arXiv:2307.14936v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14902",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yuejun Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bettaieb_S/0/1/0/all/0/1\">Seifeddine Bettaieb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Q/0/1/0/all/0/1\">Qiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Traon_Y/0/1/0/all/0/1\">Yves Le Traon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Q/0/1/0/all/0/1\">Qiang Tang</a>",
          "description": "Representing source code in a generic input format is crucial to automate\nsoftware engineering tasks, e.g., applying machine learning algorithms to\nextract information. Visualizing code representations can further enable human\nexperts to gain an intuitive insight into the code. Unfortunately, as of today,\nthere is no universal tool that can simultaneously visualise different types of\ncode representations. In this paper, we introduce a tool, CodeLens, which\nprovides a visual interaction environment that supports various representation\nmethods and helps developers understand and explore them. CodeLens is designed\nto support multiple programming languages, such as Java, Python, and\nJavaScript, and four types of code representations, including sequence of\ntokens, abstract syntax tree (AST), data flow graph (DFG), and control flow\ngraph (CFG). By using CodeLens, developers can quickly visualize the specific\ncode representation and also obtain the represented inputs for models of code.\nThe Web-based interface of CodeLens is available at this http URL\nThe demonstration video can be found at this http URL",
          "link": "http://arxiv.org/abs/2307.14902",
          "publishedOn": "2023-07-29T00:48:57.482Z",
          "wordCount": null,
          "title": "CodeLens: An Interactive Tool for Visualizing Code Representations. (arXiv:2307.14902v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15007",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhalla_U/0/1/0/all/0/1\">Usha Bhalla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivas_S/0/1/0/all/0/1\">Suraj Srinivas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1\">Himabindu Lakkaraju</a>",
          "description": "With the increased deployment of machine learning models in various\nreal-world applications, researchers and practitioners alike have emphasized\nthe need for explanations of model behaviour. To this end, two broad strategies\nhave been outlined in prior literature to explain models. Post hoc explanation\nmethods explain the behaviour of complex black-box models by highlighting\nfeatures that are critical to model predictions; however, prior work has shown\nthat these explanations may not be faithful, and even more concerning is our\ninability to verify them. Specifically, it is nontrivial to evaluate if a given\nattribution is correct with respect to the underlying model. Inherently\ninterpretable models, on the other hand, circumvent these issues by explicitly\nencoding explanations into model architecture, meaning their explanations are\nnaturally faithful and verifiable, but they often exhibit poor predictive\nperformance due to their limited expressive power. In this work, we aim to\nbridge the gap between the aforementioned strategies by proposing Verifiability\nTuning (VerT), a method that transforms black-box models into models that\nnaturally yield faithful and verifiable feature attributions. We begin by\nintroducing a formal theoretical framework to understand verifiability and show\nthat attributions produced by standard models cannot be verified. We then\nleverage this framework to propose a method to build verifiable models and\nfeature attributions out of fully trained black-box models. Finally, we perform\nextensive experiments on semi-synthetic and real-world datasets, and show that\nVerT produces models that (1) yield explanations that are correct and\nverifiable and (2) are faithful to the original black-box models they are meant\nto explain.",
          "link": "http://arxiv.org/abs/2307.15007",
          "publishedOn": "2023-07-29T00:48:57.482Z",
          "wordCount": null,
          "title": "Verifiable Feature Attributions: A Bridge between Post Hoc Explainability and Inherent Interpretability. (arXiv:2307.15007v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.13813",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Busbridge_D/0/1/0/all/0/1\">Dan Busbridge</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramapuram_J/0/1/0/all/0/1\">Jason Ramapuram</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ablin_P/0/1/0/all/0/1\">Pierre Ablin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Likhomanenko_T/0/1/0/all/0/1\">Tatiana Likhomanenko</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dhekane_E/0/1/0/all/0/1\">Eeshan Gunesh Dhekane</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Suau_X/0/1/0/all/0/1\">Xavier Suau</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Webb_R/0/1/0/all/0/1\">Russ Webb</a>",
          "description": "Preserving training dynamics across batch sizes is an important tool for\npractical machine learning as it enables the trade-off between batch size and\nwall-clock time. This trade-off is typically enabled by a scaling rule, for\nexample, in stochastic gradient descent, one should scale the learning rate\nlinearly with the batch size. Another important tool for practical machine\nlearning is the model Exponential Moving Average (EMA), which is a model copy\nthat does not receive gradient information, but instead follows its target\nmodel with some momentum. This model EMA can improve the robustness and\ngeneralization properties of supervised learning, stabilize pseudo-labeling,\nand provide a learning signal for Self-Supervised Learning (SSL). Prior works\nhave treated the model EMA separately from optimization, leading to different\ntraining dynamics across batch sizes and lower model performance. In this work,\nwe provide a scaling rule for optimization in the presence of model EMAs and\ndemonstrate its validity across a range of architectures, optimizers, and data\nmodalities. We also show the rule's validity where the model EMA contributes to\nthe optimization of the target model, enabling us to train EMA-based\npseudo-labeling and SSL methods at small and large batch sizes. For SSL, we\nenable training of BYOL up to batch size 24,576 without sacrificing\nperformance, optimally a 6$\\times$ wall-clock time reduction.",
          "link": "http://arxiv.org/abs/2307.13813",
          "publishedOn": "2023-07-29T00:48:57.481Z",
          "wordCount": null,
          "title": "How to Scale Your EMA. (arXiv:2307.13813v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15017",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Talwar_K/0/1/0/all/0/1\">Kunal Talwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McMillan_A/0/1/0/all/0/1\">Audra McMillan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jina_V/0/1/0/all/0/1\">Vojta Jina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feldman_V/0/1/0/all/0/1\">Vitaly Feldman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basile_B/0/1/0/all/0/1\">Bailey Basile</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cahill_A/0/1/0/all/0/1\">Aine Cahill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_Y/0/1/0/all/0/1\">Yi Sheng Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatzidakis_M/0/1/0/all/0/1\">Mike Chatzidakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junye Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chick_O/0/1/0/all/0/1\">Oliver Chick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chitnis_M/0/1/0/all/0/1\">Mona Chitnis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganta_S/0/1/0/all/0/1\">Suman Ganta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goren_Y/0/1/0/all/0/1\">Yusuf Goren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Granqvist_F/0/1/0/all/0/1\">Filip Granqvist</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_K/0/1/0/all/0/1\">Kristine Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobs_F/0/1/0/all/0/1\">Frederic Jacobs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Javidbakht_O/0/1/0/all/0/1\">Omid Javidbakht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Albert Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Low_R/0/1/0/all/0/1\">Richard Low</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mascenik_D/0/1/0/all/0/1\">Dan Mascenik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Myers_S/0/1/0/all/0/1\">Steve Myers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1\">David Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_W/0/1/0/all/0/1\">Wonhee Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parsa_G/0/1/0/all/0/1\">Gianni Parsa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pauly_T/0/1/0/all/0/1\">Tommy Pauly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Priebe_C/0/1/0/all/0/1\">Christian Priebe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rishi_R/0/1/0/all/0/1\">Rehan Rishi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rothblum_G/0/1/0/all/0/1\">Guy Rothblum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scaria_M/0/1/0/all/0/1\">Michael Scaria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Linmao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1\">Congzheng Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tarbe_K/0/1/0/all/0/1\">Karl Tarbe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogt_S/0/1/0/all/0/1\">Sebastian Vogt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winstrom_L/0/1/0/all/0/1\">Luke Winstrom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Shundong Zhou</a>",
          "description": "We revisit the problem of designing scalable protocols for private statistics\nand private federated learning when each device holds its private data. Our\nfirst contribution is to propose a simple primitive that allows for efficient\nimplementation of several commonly used algorithms, and allows for privacy\naccounting that is close to that in the central setting without requiring the\nstrong trust assumptions it entails. Second, we propose a system architecture\nthat implements this primitive and perform a security analysis of the proposed\nsystem.",
          "link": "http://arxiv.org/abs/2307.15017",
          "publishedOn": "2023-07-29T00:48:57.468Z",
          "wordCount": null,
          "title": "Samplable Anonymous Aggregation for Private Federated Data Analysis. (arXiv:2307.15017v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14588",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Xu_L/0/1/0/all/0/1\">Liang Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_M/0/1/0/all/0/1\">Mingxiao Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_Y/0/1/0/all/0/1\">Yi Cheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shao_P/0/1/0/all/0/1\">Pengfei Shao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shen_S/0/1/0/all/0/1\">Shuwei Shen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yao_P/0/1/0/all/0/1\">Peng Yao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_R/0/1/0/all/0/1\">Ronald X.Xu</a>",
          "description": "The UNet architecture, based on Convolutional Neural Networks (CNN), has\ndemonstrated its remarkable performance in medical image analysis. However, it\nfaces challenges in capturing long-range dependencies due to the limited\nreceptive fields and inherent bias of convolutional operations. Recently,\nnumerous transformer-based techniques have been incorporated into the UNet\narchitecture to overcome this limitation by effectively capturing global\nfeature correlations. However, the integration of the Transformer modules may\nresult in the loss of local contextual information during the global feature\nfusion process. To overcome these challenges, we propose a 2D medical image\nsegmentation model called Multi-scale Cross Perceptron Attention Network\n(MCPA). The MCPA consists of three main components: an encoder, a decoder, and\na Cross Perceptron. The Cross Perceptron first captures the local correlations\nusing multiple Multi-scale Cross Perceptron modules, facilitating the fusion of\nfeatures across scales. The resulting multi-scale feature vectors are then\nspatially unfolded, concatenated, and fed through a Global Perceptron module to\nmodel global dependencies. Furthermore, we introduce a Progressive Dual-branch\nStructure to address the semantic segmentation of the image involving finer\ntissue structures. This structure gradually shifts the segmentation focus of\nMCPA network training from large-scale structural features to more\nsophisticated pixel-level features. We evaluate our proposed MCPA model on\nseveral publicly available medical image datasets from different tasks and\ndevices, including the open large-scale dataset of CT (Synapse), MRI (ACDC),\nfundus camera (DRIVE, CHASE_DB1, HRF), and OCTA (ROSE). The experimental\nresults show that our MCPA model achieves state-of-the-art performance. The\ncode is available at\nhttps://github.com/simonustc/MCPA-for-2D-Medical-Image-Segmentation.",
          "link": "http://arxiv.org/abs/2307.14588",
          "publishedOn": "2023-07-29T00:48:57.467Z",
          "wordCount": null,
          "title": "MCPA: Multi-scale Cross Perceptron Attention Network for 2D Medical Image Segmentation. (arXiv:2307.14588v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14613",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yixian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_K/0/1/0/all/0/1\">Kun Zhan</a>",
          "description": "Augmentation techniques and sampling strategies are crucial in contrastive\nlearning, but in most existing works, augmentation techniques require careful\ndesign, and their sampling strategies can only capture a small amount of\nintrinsic supervision information. Additionally, the existing methods require\ncomplex designs to obtain two different representations of the data. To\novercome these limitations, we propose a novel framework called the\nSelf-Contrastive Graph Diffusion Network (SCGDN). Our framework consists of two\nmain components: the Attentional Module (AttM) and the Diffusion Module (DiFM).\nAttM aggregates higher-order structure and feature information to get an\nexcellent embedding, while DiFM balances the state of each node in the graph\nthrough Laplacian diffusion learning and allows the cooperative evolution of\nadjacency and feature information in the graph. Unlike existing methodologies,\nSCGDN is an augmentation-free approach that avoids \"sampling bias\" and semantic\ndrift, without the need for pre-training. We conduct a high-quality sampling of\nsamples based on structure and feature information. If two nodes are neighbors,\nthey are considered positive samples of each other. If two disconnected nodes\nare also unrelated on $k$NN graph, they are considered negative samples for\neach other. The contrastive objective reasonably uses our proposed sampling\nstrategies, and the redundancy reduction term minimizes redundant information\nin the embedding and can well retain more discriminative information. In this\nnovel framework, the graph self-contrastive learning paradigm gives expression\nto a powerful force. SCGDN effectively balances between preserving high-order\nstructure information and avoiding overfitting. The results manifest that SCGDN\ncan consistently generate outperformance over both the contrastive methods and\nthe classical methods.",
          "link": "http://arxiv.org/abs/2307.14613",
          "publishedOn": "2023-07-29T00:48:57.467Z",
          "wordCount": null,
          "title": "Self-Contrastive Graph Diffusion Network. (arXiv:2307.14613v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garrigos_G/0/1/0/all/0/1\">Guillaume Garrigos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gower_R/0/1/0/all/0/1\">Robert M. Gower</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaipp_F/0/1/0/all/0/1\">Fabian Schaipp</a>",
          "description": "Here we develop variants of SGD (stochastic gradient descent) with an\nadaptive step size that make use of the sampled loss values. In particular, we\nfocus on solving a finite sum-of-terms problem, also known as empirical risk\nminimization. We first detail an idealized adaptive method called\n$\\texttt{SPS}_+$ that makes use of the sampled loss values and assumes\nknowledge of the sampled loss at optimality. This $\\texttt{SPS}_+$ is a minor\nmodification of the SPS (Stochastic Polyak Stepsize) method, where the step\nsize is enforced to be positive. We then show that $\\texttt{SPS}_+$ achieves\nthe best known rates of convergence for SGD in the Lipschitz non-smooth. We\nthen move onto to develop $\\texttt{FUVAL}$, a variant of $\\texttt{SPS}_+$ where\nthe loss values at optimality are gradually learned, as opposed to being given.\nWe give three viewpoints of $\\texttt{FUVAL}$, as a projection based method, as\na variant of the prox-linear method, and then as a particular online SGD\nmethod. We then present a convergence analysis of $\\texttt{FUVAL}$ and\nexperimental results. The shortcomings of our work is that the convergence\nanalysis of $\\texttt{FUVAL}$ shows no advantage over SGD. Another shortcomming\nis that currently only the full batch version of $\\texttt{FUVAL}$ shows a minor\nadvantages of GD (Gradient Descent) in terms of sensitivity to the step size.\nThe stochastic version shows no clear advantage over SGD. We conjecture that\nlarge mini-batches are required to make $\\texttt{FUVAL}$ competitive.\n\nCurrently the new $\\texttt{FUVAL}$ method studied in this paper does not\noffer any clear theoretical or practical advantage. We have chosen to make this\ndraft available online nonetheless because of some of the analysis techniques\nwe use, such as the non-smooth analysis of $\\texttt{SPS}_+$, and also to show\nan apparently interesting approach that currently does not work.",
          "link": "http://arxiv.org/abs/2307.14528",
          "publishedOn": "2023-07-29T00:48:57.466Z",
          "wordCount": null,
          "title": "Function Value Learning: Adaptive Learning Rates Based on the Polyak Stepsize and Function Splitting in ERM. (arXiv:2307.14528v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15008",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1\">Nicholas Carlini</a>",
          "description": "Large language models (LLMs) are now highly capable at a diverse range of\ntasks. This paper studies whether or not GPT-4, one such LLM, is capable of\nassisting researchers in the field of adversarial machine learning. As a case\nstudy, we evaluate the robustness of AI-Guardian, a recent defense to\nadversarial examples published at IEEE S&P 2023, a top computer security\nconference. We completely break this defense: the proposed scheme does not\nincrease robustness compared to an undefended baseline.\n\nWe write none of the code to attack this model, and instead prompt GPT-4 to\nimplement all attack algorithms following our instructions and guidance. This\nprocess was surprisingly effective and efficient, with the language model at\ntimes producing code from ambiguous instructions faster than the author of this\npaper could have done. We conclude by discussing (1) the warning signs present\nin the evaluation that suggested to us AI-Guardian would be broken, and (2) our\nexperience with designing attacks and performing novel research using the most\nrecent advances in language modeling.",
          "link": "http://arxiv.org/abs/2307.15008",
          "publishedOn": "2023-07-29T00:48:57.465Z",
          "wordCount": null,
          "title": "A LLM Assisted Exploitation of AI-Guardian. (arXiv:2307.15008v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14512",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Morovati_M/0/1/0/all/0/1\">Mohammad Mehdi Morovati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikanjam_A/0/1/0/all/0/1\">Amin Nikanjam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tambon_F/0/1/0/all/0/1\">Florian Tambon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khomh_F/0/1/0/all/0/1\">Foutse Khomh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ming_Z/0/1/0/all/0/1\">Zhen Ming</a> (Jack) <a href=\"http://arxiv.org/find/cs/1/au:+Jiang/0/1/0/all/0/1\">Jiang</a>",
          "description": "Rapid growth of applying Machine Learning (ML) in different domains,\nespecially in safety-critical areas, increases the need for reliable ML\ncomponents, i.e., a software component operating based on ML. Understanding the\nbugs characteristics and maintenance challenges in ML-based systems can help\ndevelopers of these systems to identify where to focus maintenance and testing\nefforts, by giving insights into the most error-prone components, most common\nbugs, etc. In this paper, we investigate the characteristics of bugs in\nML-based software systems and the difference between ML and non-ML bugs from\nthe maintenance viewpoint. We extracted 447,948 GitHub repositories that used\none of the three most popular ML frameworks, i.e., TensorFlow, Keras, and\nPyTorch. After multiple filtering steps, we select the top 300 repositories\nwith the highest number of closed issues. We manually investigate the extracted\nrepositories to exclude non-ML-based systems. Our investigation involved a\nmanual inspection of 386 sampled reported issues in the identified ML-based\nsystems to indicate whether they affect ML components or not. Our analysis\nshows that nearly half of the real issues reported in ML-based systems are ML\nbugs, indicating that ML components are more error-prone than non-ML\ncomponents. Next, we thoroughly examined 109 identified ML bugs to identify\ntheir root causes, symptoms, and calculate their required fixing time. The\nresults also revealed that ML bugs have significantly different characteristics\ncompared to non-ML bugs, in terms of the complexity of bug-fixing (number of\ncommits, changed files, and changed lines of code). Based on our results,\nfixing ML bugs are more costly and ML components are more error-prone, compared\nto non-ML bugs and non-ML components respectively. Hence, paying a significant\nattention to the reliability of the ML components is crucial in ML-based\nsystems.",
          "link": "http://arxiv.org/abs/2307.14512",
          "publishedOn": "2023-07-29T00:48:57.464Z",
          "wordCount": null,
          "title": "Bug Characterization in Machine Learning-based Systems. (arXiv:2307.14512v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14643",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nie_H/0/1/0/all/0/1\">Haitao Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shengbo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_B/0/1/0/all/0/1\">Bin Xie</a>",
          "description": "How to accurately measure the relevance and redundancy of features is an\nage-old challenge in the field of feature selection. However, existing\nfilter-based feature selection methods cannot directly measure redundancy for\ncontinuous data. In addition, most methods rely on manually specifying the\nnumber of features, which may introduce errors in the absence of expert\nknowledge. In this paper, we propose a non-parametric feature selection\nalgorithm based on maximum inter-class variation and minimum redundancy,\nabbreviated as MVMR-FS. We first introduce supervised and unsupervised kernel\ndensity estimation on the features to capture their similarities and\ndifferences in inter-class and overall distributions. Subsequently, we present\nthe criteria for maximum inter-class variation and minimum redundancy (MVMR),\nwherein the inter-class probability distributions are employed to reflect\nfeature relevance and the distances between overall probability distributions\nare used to quantify redundancy. Finally, we employ an AGA to search for the\nfeature subset that minimizes the MVMR. Compared with ten state-of-the-art\nmethods, MVMR-FS achieves the highest average accuracy and improves the\naccuracy by 5% to 11%.",
          "link": "http://arxiv.org/abs/2307.14643",
          "publishedOn": "2023-07-29T00:48:57.464Z",
          "wordCount": null,
          "title": "MVMR-FS : Non-parametric feature selection algorithm based on Maximum inter-class Variation and Minimum Redundancy. (arXiv:2307.14643v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14453",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sengupta_P/0/1/0/all/0/1\">Prajit Sengupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_A/0/1/0/all/0/1\">Anant Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rana_P/0/1/0/all/0/1\">Prashant Singh Rana</a>",
          "description": "Armoured vehicles are specialized and complex pieces of machinery designed to\noperate in high-stress environments, often in combat or tactical situations.\nThis study proposes a predictive maintenance-based ensemble system that aids in\npredicting potential maintenance needs based on sensor data collected from\nthese vehicles. The proposed model's architecture involves various models such\nas Light Gradient Boosting, Random Forest, Decision Tree, Extra Tree Classifier\nand Gradient Boosting to predict the maintenance requirements of the vehicles\naccurately. In addition, K-fold cross validation, along with TOPSIS analysis,\nis employed to evaluate the proposed ensemble model's stability. The results\nindicate that the proposed system achieves an accuracy of 98.93%, precision of\n99.80% and recall of 99.03%. The algorithm can effectively predict maintenance\nneeds, thereby reducing vehicle downtime and improving operational efficiency.\nThrough comparisons between various algorithms and the suggested ensemble, this\nstudy highlights the potential of machine learning-based predictive maintenance\nsolutions.",
          "link": "http://arxiv.org/abs/2307.14453",
          "publishedOn": "2023-07-29T00:48:57.463Z",
          "wordCount": null,
          "title": "Predictive Maintenance of Armoured Vehicles using Machine Learning Approaches. (arXiv:2307.14453v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14527",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Manzini_T/0/1/0/all/0/1\">Thomas Manzini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murphy_R/0/1/0/all/0/1\">Robin Murphy</a>",
          "description": "This paper details the challenges in applying two computer vision systems, an\nEfficientDET supervised learning model and the unsupervised RX spectral\nclassifier, to 98.9 GB of drone imagery from the Wu-Murad wilderness search and\nrescue (WSAR) effort in Japan and identifies 3 directions for future research.\nThere have been at least 19 proposed approaches and 3 datasets aimed at\nlocating missing persons in drone imagery, but only 3 approaches (2\nunsupervised and 1 of an unknown structure) are referenced in the literature as\nhaving been used in an actual WSAR operation. Of these proposed approaches, the\nEfficientDET architecture and the unsupervised spectral RX classifier were\nselected as the most appropriate for this setting. The EfficientDET model was\napplied to the HERIDAL dataset and despite achieving performance that is\nstatistically equivalent to the state-of-the-art, the model fails to translate\nto the real world in terms of false positives (e.g., identifying tree limbs and\nrocks as people), and false negatives (e.g., failing to identify members of the\nsearch team). The poor results in practice for algorithms that showed good\nresults on datasets suggest 3 areas of future research: more realistic datasets\nfor wilderness SAR, computer vision models that are capable of seamlessly\nhandling the variety of imagery that can be collected during actual WSAR\noperations, and better alignment on performance measures.",
          "link": "http://arxiv.org/abs/2307.14527",
          "publishedOn": "2023-07-29T00:48:57.463Z",
          "wordCount": null,
          "title": "Open Problems in Computer Vision for Wilderness SAR and The Search for Patricia Wu-Murad. (arXiv:2307.14527v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abrate_C/0/1/0/all/0/1\">Carlo Abrate</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preti_G/0/1/0/all/0/1\">Giulia Preti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonchi_F/0/1/0/all/0/1\">Francesco Bonchi</a>",
          "description": "Counterfactual examples have emerged as an effective approach to produce\nsimple and understandable post-hoc explanations. In the context of graph\nclassification, previous work has focused on generating counterfactual\nexplanations by manipulating the most elementary units of a graph, i.e.,\nremoving an existing edge, or adding a non-existing one. In this paper, we\nclaim that such language of explanation might be too fine-grained, and turn our\nattention to some of the main characterizing features of real-world complex\nnetworks, such as the tendency to close triangles, the existence of recurring\nmotifs, and the organization into dense modules. We thus define a general\ndensity-based counterfactual search framework to generate instance-level\ncounterfactual explanations for graph classifiers, which can be instantiated\nwith different notions of dense substructures. In particular, we show two\nspecific instantiations of this general framework: a method that searches for\ncounterfactual graphs by opening or closing triangles, and a method driven by\nmaximal cliques. We also discuss how the general method can be instantiated to\nexploit any other notion of dense substructures, including, for instance, a\ngiven taxonomy of nodes. We evaluate the effectiveness of our approaches in 7\nbrain network datasets and compare the counterfactual statements generated\naccording to several widely-used metrics. Results confirm that adopting a\nsemantic-relevant unit of change like density is essential to define versatile\nand interpretable counterfactual explanation methods.",
          "link": "http://arxiv.org/abs/2307.14849",
          "publishedOn": "2023-07-29T00:48:57.462Z",
          "wordCount": null,
          "title": "Counterfactual Explanations for Graph Classification Through the Lenses of Density. (arXiv:2307.14849v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14642",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kim_K/0/1/0/all/0/1\">Kyurae Kim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ma_Y/0/1/0/all/0/1\">Yian Ma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gardner_J/0/1/0/all/0/1\">Jacob R. Gardner</a>",
          "description": "We prove that black-box variational inference (BBVI) with control variates,\nparticularly the sticking-the-landing (STL) estimator, converges at a geometric\n(traditionally called \"linear\") rate under perfect variational family\nspecification. In particular, we prove a quadratic bound on the gradient\nvariance of the STL estimator, one which encompasses misspecified variational\nfamilies. Combined with previous works on the quadratic variance condition,\nthis directly implies convergence of BBVI with the use of projected stochastic\ngradient descent. We also improve existing analysis on the regular closed-form\nentropy gradient estimators, which enables comparison against the STL estimator\nand provides explicit non-asymptotic complexity guarantees for both.",
          "link": "http://arxiv.org/abs/2307.14642",
          "publishedOn": "2023-07-29T00:48:57.461Z",
          "wordCount": null,
          "title": "Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?. (arXiv:2307.14642v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.10473",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhihong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Just_H/0/1/0/all/0/1\">Hoang Anh Just</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1\">Xiangyu Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ruoxi Jia</a>",
          "description": "Data valuation -- quantifying the contribution of individual data sources to\ncertain predictive behaviors of a model -- is of great importance to enhancing\nthe transparency of machine learning and designing incentive systems for data\nsharing. Existing work has focused on evaluating data sources with the shared\nfeature or sample space. How to valuate fragmented data sources of which each\nonly contains partial features and samples remains an open question. We start\nby presenting a method to calculate the counterfactual of removing a fragment\nfrom the aggregated data matrix. Based on the counterfactual calculation, we\nfurther propose 2D-Shapley, a theoretical framework for fragmented data\nvaluation that uniquely satisfies some appealing axioms in the fragmented data\ncontext. 2D-Shapley empowers a range of new use cases, such as selecting useful\ndata fragments, providing interpretation for sample-wise data values, and\nfine-grained data issue diagnosis.",
          "link": "http://arxiv.org/abs/2306.10473",
          "publishedOn": "2023-07-29T00:48:57.461Z",
          "wordCount": null,
          "title": "2D-Shapley: A Framework for Fragmented Data Valuation. (arXiv:2306.10473v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15016",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_H/0/1/0/all/0/1\">Haotong Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_G/0/1/0/all/0/1\">Ge-Peng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1\">Salman Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1\">Deng-Ping Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1\">Fahad Shahbaz Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>",
          "description": "Google's Bard has emerged as a formidable competitor to OpenAI's ChatGPT in\nthe field of conversational AI. Notably, Bard has recently been updated to\nhandle visual inputs alongside text prompts during conversations. Given Bard's\nimpressive track record in handling textual inputs, we explore its capabilities\nin understanding and interpreting visual data (images) conditioned by text\nquestions. This exploration holds the potential to unveil new insights and\nchallenges for Bard and other forthcoming multi-modal Generative models,\nespecially in addressing complex computer vision problems that demand accurate\nvisual and language understanding. Specifically, in this study, we focus on 15\ndiverse task scenarios encompassing regular, camouflaged, medical, under-water\nand remote sensing data to comprehensively evaluate Bard's performance. Our\nprimary finding indicates that Bard still struggles in these vision scenarios,\nhighlighting the significant gap in vision-based understanding that needs to be\nbridged in future developments. We expect that this empirical study will prove\nvaluable in advancing future models, leading to enhanced capabilities in\ncomprehending and interpreting fine-grained visual data. Our project is\nreleased on https://github.com/htqin/GoogleBard-VisUnderstand",
          "link": "http://arxiv.org/abs/2307.15016",
          "publishedOn": "2023-07-29T00:48:57.460Z",
          "wordCount": null,
          "title": "How Good is Google Bard's Visual Understanding? An Empirical Study on Open Challenges. (arXiv:2307.15016v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14732",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yeung_C/0/1/0/all/0/1\">Calvin C. K. Yeung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fujii_K/0/1/0/all/0/1\">Keisuke Fujii</a>",
          "description": "Complex interactions between two opposing agents frequently occur in domains\nof machine learning, game theory, and other application domains. Quantitatively\nanalyzing the strategies involved can provide an objective basis for\ndecision-making. One such critical scenario is shot-taking in football, where\ndecisions, such as whether the attacker should shoot or pass the ball and\nwhether the defender should attempt to block the shot, play a crucial role in\nthe outcome of the game. However, there are currently no effective data-driven\nand/or theory-based approaches to analyzing such situations. To address this\nissue, we proposed a novel framework to analyze such scenarios based on game\ntheory, where we estimate the expected payoff with machine learning (ML)\nmodels, and additional features for ML models were extracted with a\ntheory-based shot block model. Conventionally, successes or failures (1 or 0)\nare used as payoffs, while a success shot (goal) is extremely rare in football.\nTherefore, we proposed the Expected Probability of Shot On Target (xSOT) metric\nto evaluate players' actions even if the shot results in no goal; this allows\nfor effective differentiation and comparison between different shots and even\nenables counterfactual shot situation analysis. In our experiments, we have\nvalidated the framework by comparing it with baseline and ablated models.\nFurthermore, we have observed a high correlation between the xSOT and existing\nmetrics. This alignment of information suggests that xSOT provides valuable\ninsights. Lastly, as an illustration, we studied optimal strategies in the\nWorld Cup 2022 and analyzed a shot situation in EURO 2020.",
          "link": "http://arxiv.org/abs/2307.14732",
          "publishedOn": "2023-07-29T00:48:57.459Z",
          "wordCount": null,
          "title": "A Strategic Framework for Optimal Decisions in Football 1-vs-1 Shot-Taking Situations: An Integrated Approach of Machine Learning, Theory-Based Modeling, and Game Theory. (arXiv:2307.14732v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14857",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Heyder_F/0/1/0/all/0/1\">Florian Heyder</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mellado_J/0/1/0/all/0/1\">Juan Pedro Mellado</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Schumacher_J/0/1/0/all/0/1\">J&#xf6;rg Schumacher</a>",
          "description": "Turbulence parametrizations will remain a necessary building block in\nkilometer-scale Earth system models. In convective boundary layers, where the\nmean vertical gradients of conserved properties such as potential temperature\nand moisture are approximately zero, the standard ansatz which relates\nturbulent fluxes to mean vertical gradients via an eddy diffusivity has to be\nextended by mass flux parametrizations for the typically asymmetric up- and\ndowndrafts in the atmospheric boundary layer. In this work, we present a\nparametrization for a dry convective boundary layer based on a generative\nadversarial network. The model incorporates the physics of self-similar layer\ngrowth following from the classical mixed layer theory by Deardorff. This\nenhances the training data base of the generative machine learning algorithm\nand thus significantly improves the predicted statistics of the synthetically\ngenerated turbulence fields at different heights inside the boundary layer. The\nalgorithm training is based on fully three-dimensional direct numerical\nsimulation data. Differently to stochastic parametrizations, our model is able\nto predict the highly non-Gaussian transient statistics of buoyancy\nfluctuations, vertical velocity, and buoyancy flux at different heights thus\nalso capturing the fastest thermals penetrating into the stabilized top region.\nThe results of our generative algorithm agree with standard two-equation or\nmulti-plume stochastic mass-flux schemes. The present parametrization provides\nadditionally the granule-type horizontal organization of the turbulent\nconvection which cannot be obtained in any of the other model closures. Our\nwork paves the way to efficient data-driven convective parametrizations in\nother natural flows, such as moist convection, upper ocean mixing, or\nconvection in stellar interiors.",
          "link": "http://arxiv.org/abs/2307.14857",
          "publishedOn": "2023-07-29T00:48:57.459Z",
          "wordCount": null,
          "title": "Generative convective parametrization of dry atmospheric boundary layer. (arXiv:2307.14857v1 [physics.flu-dyn])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14993",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chung_S/0/1/0/all/0/1\">Stephen Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anokhin_I/0/1/0/all/0/1\">Ivan Anokhin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krueger_D/0/1/0/all/0/1\">David Krueger</a>",
          "description": "We propose the Thinker algorithm, a novel approach that enables reinforcement\nlearning agents to autonomously interact with and utilize a learned world\nmodel. The Thinker algorithm wraps the environment with a world model and\nintroduces new actions designed for interacting with the world model. These\nmodel-interaction actions enable agents to perform planning by proposing\nalternative plans to the world model before selecting a final action to execute\nin the environment. This approach eliminates the need for hand-crafted planning\nalgorithms by enabling the agent to learn how to plan autonomously and allows\nfor easy interpretation of the agent's plan with visualization. We demonstrate\nthe algorithm's effectiveness through experimental results in the game of\nSokoban and the Atari 2600 benchmark, where the Thinker algorithm achieves\nstate-of-the-art performance and competitive results, respectively.\nVisualizations of agents trained with the Thinker algorithm demonstrate that\nthey have learned to plan effectively with the world model to select better\nactions. The algorithm's generality opens a new research direction on how a\nworld model can be used in reinforcement learning and how planning can be\nseamlessly integrated into an agent's decision-making process.",
          "link": "http://arxiv.org/abs/2307.14993",
          "publishedOn": "2023-07-29T00:48:57.458Z",
          "wordCount": null,
          "title": "Thinker: Learning to Plan and Act. (arXiv:2307.14993v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14623",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hassan_S/0/1/0/all/0/1\">Sheikh Md Shakeel Hassan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feeney_A/0/1/0/all/0/1\">Arthur Feeney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhruv_A/0/1/0/all/0/1\">Akash Dhruv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jihoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suh_Y/0/1/0/all/0/1\">Youngjoon Suh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryu_J/0/1/0/all/0/1\">Jaiyoung Ryu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Won_Y/0/1/0/all/0/1\">Yoonjin Won</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandramowlishwaran_A/0/1/0/all/0/1\">Aparna Chandramowlishwaran</a>",
          "description": "In the field of phase change phenomena, the lack of accessible and diverse\ndatasets suitable for machine learning (ML) training poses a significant\nchallenge. Existing experimental datasets are often restricted, with limited\navailability and sparse ground truth data, impeding our understanding of this\ncomplex multi-physics phenomena. To bridge this gap, we present the BubbleML\nDataset(https://github.com/HPCForge/BubbleML) which leverages physics-driven\nsimulations to provide accurate ground truth information for various boiling\nscenarios, encompassing nucleate pool boiling, flow boiling, and sub-cooled\nboiling. This extensive dataset covers a wide range of parameters, including\nvarying gravity conditions, flow rates, sub-cooling levels, and wall superheat,\ncomprising 51 simulations. BubbleML is validated against experimental\nobservations and trends, establishing it as an invaluable resource for ML\nresearch. Furthermore, we showcase its potential to facilitate exploration of\ndiverse downstream tasks by introducing two benchmarks: (a) optical flow\nanalysis to capture bubble dynamics, and (b) operator networks for learning\ntemperature dynamics. The BubbleML dataset and its benchmarks serve as a\ncatalyst for advancements in ML-driven research on multi-physics phase change\nphenomena, enabling the development and comparison of state-of-the-art\ntechniques and models.",
          "link": "http://arxiv.org/abs/2307.14623",
          "publishedOn": "2023-07-29T00:48:57.457Z",
          "wordCount": null,
          "title": "BubbleML: A Multi-Physics Dataset and Benchmarks for Machine Learning. (arXiv:2307.14623v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Williams_W/0/1/0/all/0/1\">Warren R. Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glandon_S/0/1/0/all/0/1\">S. Ross Glandon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morris_L/0/1/0/all/0/1\">Luke L. Morris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1\">Jing-Ru C. Cheng</a>",
          "description": "Performance Benchmarking of HPC systems is an ongoing effort that seeks to\nprovide information that will allow for increased performance and improve the\njob schedulers that manage these systems. We develop a benchmarking tool that\nutilizes machine learning models and gathers performance data on\nGPU-accelerated nodes while they perform material segmentation analysis. The\nbenchmark uses a ML model that has been converted from Caffe to PyTorch using\nthe MMdnn toolkit and the MINC-2500 dataset. Performance data is gathered on\ntwo ERDC DSRC systems, Onyx and Vulcanite. The data reveals that while\nVulcanite has faster model times in a large number of benchmarks, and it is\nalso more subject to some environmental factors that can cause performances\nslower than Onyx. In contrast the model times from Onyx are consistent across\nbenchmarks.",
          "link": "http://arxiv.org/abs/2307.14921",
          "publishedOn": "2023-07-29T00:48:57.457Z",
          "wordCount": null,
          "title": "Benchmarking Performance of Deep Learning Model for Material Segmentation on Two HPC Systems. (arXiv:2307.14921v1 [cs.PF])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14928",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cosenza_E/0/1/0/all/0/1\">Emanuele Cosenza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valenti_A/0/1/0/all/0/1\">Andrea Valenti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bacciu_D/0/1/0/all/0/1\">Davide Bacciu</a>",
          "description": "Graphs can be leveraged to model polyphonic multitrack symbolic music, where\nnotes, chords and entire sections may be linked at different levels of the\nmusical hierarchy by tonal and rhythmic relationships. Nonetheless, there is a\nlack of works that consider graph representations in the context of deep\nlearning systems for music generation. This paper bridges this gap by\nintroducing a novel graph representation for music and a deep Variational\nAutoencoder that generates the structure and the content of musical graphs\nseparately, one after the other, with a hierarchical architecture that matches\nthe structural priors of music. By separating the structure and content of\nmusical graphs, it is possible to condition generation by specifying which\ninstruments are played at certain times. This opens the door to a new form of\nhuman-computer interaction in the context of music co-creation. After training\nthe model on existing MIDI datasets, the experiments show that the model is\nable to generate appealing short and long musical sequences and to\nrealistically interpolate between them, producing music that is tonally and\nrhythmically consistent. Finally, the visualization of the embeddings shows\nthat the model is able to organize its latent space in accordance with known\nmusical concepts.",
          "link": "http://arxiv.org/abs/2307.14928",
          "publishedOn": "2023-07-29T00:48:57.456Z",
          "wordCount": null,
          "title": "Graph-based Polyphonic Multitrack Music Generation. (arXiv:2307.14928v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Elbatel_M/0/1/0/all/0/1\">Marawan Elbatel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hualiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marti_R/0/1/0/all/0/1\">Robert Mart&#xed;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1\">Huazhu Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaomeng Li</a>",
          "description": "In the medical field, federated learning commonly deals with highly\nimbalanced datasets, including skin lesions and gastrointestinal images.\nExisting federated methods under highly imbalanced datasets primarily focus on\noptimizing a global model without incorporating the intra-class variations that\ncan arise in medical imaging due to different populations, findings, and\nscanners. In this paper, we study the inter-client intra-class variations with\npublicly available self-supervised auxiliary networks. Specifically, we find\nthat employing a shared auxiliary pre-trained model, like MoCo-V2, locally on\nevery client yields consistent divergence measurements. Based on these\nfindings, we derive a dynamic balanced model aggregation via self-supervised\npriors (MAS) to guide the global model optimization. Fed-MAS can be utilized\nwith different local learning methods for effective model aggregation toward a\nhighly robust and unbiased global model. Our code is available at\n\\url{https://github.com/xmed-lab/Fed-MAS}.",
          "link": "http://arxiv.org/abs/2307.14959",
          "publishedOn": "2023-07-29T00:48:57.455Z",
          "wordCount": null,
          "title": "Federated Model Aggregation via Self-Supervised Priors for Highly Imbalanced Medical Image Classification. (arXiv:2307.14959v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14459",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Viszlai_J/0/1/0/all/0/1\">Joshua Viszlai</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Tomesh_T/0/1/0/all/0/1\">Teague Tomesh</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gokhale_P/0/1/0/all/0/1\">Pranav Gokhale</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Anschuetz_E/0/1/0/all/0/1\">Eric Anschuetz</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Chong_F/0/1/0/all/0/1\">Frederic T. Chong</a>",
          "description": "Recent work has proposed and explored using coreset techniques for quantum\nalgorithms that operate on classical data sets to accelerate the applicability\nof these algorithms on near-term quantum devices. We apply these ideas to\nQuantum Boltzmann Machines (QBM) where gradient-based steps which require Gibbs\nstate sampling are the main computational bottleneck during training. By using\na coreset in place of the full data set, we try to minimize the number of steps\nneeded and accelerate the overall training time. In a regime where\ncomputational time on quantum computers is a precious resource, we propose this\nmight lead to substantial practical savings. We evaluate this approach on 6x6\nbinary images from an augmented bars and stripes data set using a QBM with 36\nvisible units and 8 hidden units. Using an Inception score inspired metric, we\ncompare QBM training times with and without using coresets.",
          "link": "http://arxiv.org/abs/2307.14459",
          "publishedOn": "2023-07-29T00:48:57.423Z",
          "wordCount": null,
          "title": "Training Quantum Boltzmann Machines with Coresets. (arXiv:2307.14459v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14654",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Reddy_P/0/1/0/all/0/1\">P. Jyoteeshkumar Reddy</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chinta_S/0/1/0/all/0/1\">Sandeep Chinta</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Matear_R/0/1/0/all/0/1\">Richard Matear</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Taylor_J/0/1/0/all/0/1\">John Taylor</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Baki_H/0/1/0/all/0/1\">Harish Baki</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Thatcher_M/0/1/0/all/0/1\">Marcus Thatcher</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kala_J/0/1/0/all/0/1\">Jatin Kala</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sharples_J/0/1/0/all/0/1\">Jason Sharples</a>",
          "description": "Heatwaves and bushfires cause substantial impacts on society and ecosystems\nacross the globe. Accurate information of heat extremes is needed to support\nthe development of actionable mitigation and adaptation strategies. Regional\nclimate models are commonly used to better understand the dynamics of these\nevents. These models have very large input parameter sets, and the parameters\nwithin the physics schemes substantially influence the model's performance.\nHowever, parameter sensitivity analysis (SA) of regional models for heat\nextremes is largely unexplored. Here, we focus on the southeast Australian\nregion, one of the global hotspots of heat extremes. In southeast Australia\nWeather Research and Forecasting (WRF) model is the widely used regional model\nto simulate extreme weather events across the region. Hence in this study, we\nfocus on the sensitivity of WRF model parameters to surface meteorological\nvariables such as temperature, relative humidity, and wind speed during two\nextreme heat events over southeast Australia. Due to the presence of multiple\nparameters and their complex relationship with output variables, a machine\nlearning (ML) surrogate-based global sensitivity analysis method is considered\nfor the SA. The ML surrogate-based Sobol SA is used to identify the sensitivity\nof 24 adjustable parameters in seven different physics schemes of the WRF\nmodel. Results show that out of these 24, only three parameters, namely the\nscattering tuning parameter, multiplier of saturated soil water content, and\nprofile shape exponent in the momentum diffusivity coefficient, are important\nfor the considered meteorological variables. These SA results are consistent\nfor the two different extreme heat events. Further, we investigated the\nphysical significance of sensitive parameters. This study's results will help\nin further optimising WRF parameters to improve model simulation.",
          "link": "http://arxiv.org/abs/2307.14654",
          "publishedOn": "2023-07-29T00:48:57.423Z",
          "wordCount": null,
          "title": "Machine Learning based Parameter Sensitivity of Regional Climate Models -- A Case Study of the WRF Model for Heat Extremes over Southeast Australia. (arXiv:2307.14654v1 [physics.ao-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14675",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gijon_A/0/1/0/all/0/1\">Alfonso Gij&#xf3;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pujana_Goitia_A/0/1/0/all/0/1\">Ainhoa Pujana-Goitia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perea_E/0/1/0/all/0/1\">Eugenio Perea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molina_Solana_M/0/1/0/all/0/1\">Miguel Molina-Solana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_Romero_J/0/1/0/all/0/1\">Juan G&#xf3;mez-Romero</a>",
          "description": "The ever-growing use of wind energy makes necessary the optimization of\nturbine operations through pitch angle controllers and their maintenance with\nearly fault detection. It is crucial to have accurate and robust models\nimitating the behavior of wind turbines, especially to predict the generated\npower as a function of the wind speed. Existing empirical and physics-based\nmodels have limitations in capturing the complex relations between the input\nvariables and the power, aggravated by wind variability. Data-driven methods\noffer new opportunities to enhance wind turbine modeling of large datasets by\nimproving accuracy and efficiency. In this study, we used physics-informed\nneural networks to reproduce historical data coming from 4 turbines in a wind\nfarm, while imposing certain physical constraints to the model. The developed\nmodels for regression of the power, torque, and power coefficient as output\nvariables showed great accuracy for both real data and physical equations\ngoverning the system. Lastly, introducing an efficient evidential layer\nprovided uncertainty estimations of the predictions, proved to be consistent\nwith the absolute error, and made possible the definition of a confidence\ninterval in the power curve.",
          "link": "http://arxiv.org/abs/2307.14675",
          "publishedOn": "2023-07-29T00:48:57.423Z",
          "wordCount": null,
          "title": "Prediction of wind turbines power with physics-informed neural networks and evidential uncertainty quantification. (arXiv:2307.14675v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14380",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kaluza_D/0/1/0/all/0/1\">Daniel Ka&#x142;u&#x17c;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Janusz_A/0/1/0/all/0/1\">Andrzej Janusz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slezak_D/0/1/0/all/0/1\">Dominik &#x15a;l&#x119;zak</a>",
          "description": "Supervised classification algorithms are used to solve a growing number of\nreal-life problems around the globe. Their performance is strictly connected\nwith the quality of labels used in training. Unfortunately, acquiring\ngood-quality annotations for many tasks is infeasible or too expensive to be\ndone in practice. To tackle this challenge, active learning algorithms are\ncommonly employed to select only the most relevant data for labeling. However,\nthis is possible only when the quality and quantity of labels acquired from\nexperts are sufficient. Unfortunately, in many applications, a trade-off\nbetween annotating individual samples by multiple annotators to increase label\nquality vs. annotating new samples to increase the total number of labeled\ninstances is necessary. In this paper, we address the issue of faulty data\nannotations in the context of active learning. In particular, we propose two\nnovel annotation unification algorithms that utilize unlabeled parts of the\nsample space. The proposed methods require little to no intersection between\nsamples annotated by different experts. Our experiments on four public datasets\nindicate the robustness and superiority of the proposed methods in both, the\nestimation of the annotator's reliability, and the assignment of actual labels,\nagainst the state-of-the-art algorithms and the simple majority voting.",
          "link": "http://arxiv.org/abs/2307.14380",
          "publishedOn": "2023-07-29T00:48:57.422Z",
          "wordCount": null,
          "title": "Robust Assignment of Labels for Active Learning with Sparse and Noisy Annotations. (arXiv:2307.14380v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1\">Zezhi Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yuchen Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_G/0/1/0/all/0/1\">Guangyin Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yongjun Xu</a>",
          "description": "Traffic forecasting, which aims to predict traffic conditions based on\nhistorical observations, has been an enduring research topic and is widely\nrecognized as an essential component of intelligent transportation. Recent\nproposals on Spatial-Temporal Graph Neural Networks (STGNNs) have made\nsignificant progress by combining sequential models with graph convolution\nnetworks. However, due to high complexity issues, STGNNs only focus on\nshort-term traffic forecasting, e.g., 1-hour forecasting, while ignoring more\npractical long-term forecasting. In this paper, we make the first attempt to\nexplore long-term traffic forecasting, e.g., 1-day forecasting. To this end, we\nfirst reveal its unique challenges in exploiting multi-scale representations.\nThen, we propose a novel Hierarchical U-net TransFormer (HUTFormer) to address\nthe issues of long-term traffic forecasting. HUTFormer consists of a\nhierarchical encoder and decoder to jointly generate and utilize multi-scale\nrepresentations of traffic data. Specifically, for the encoder, we propose\nwindow self-attention and segment merging to extract multi-scale\nrepresentations from long-term traffic data. For the decoder, we design a\ncross-scale attention mechanism to effectively incorporate multi-scale\nrepresentations. In addition, HUTFormer employs an efficient input embedding\nstrategy to address the complexity issues. Extensive experiments on four\ntraffic datasets show that the proposed HUTFormer significantly outperforms\nstate-of-the-art traffic forecasting and long time series forecasting\nbaselines.",
          "link": "http://arxiv.org/abs/2307.14596",
          "publishedOn": "2023-07-29T00:48:57.422Z",
          "wordCount": null,
          "title": "HUTFormer: Hierarchical U-Net Transformer for Long-Term Traffic Forecasting. (arXiv:2307.14596v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14628",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chennu_S/0/1/0/all/0/1\">Srivas Chennu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maher_A/0/1/0/all/0/1\">Andrew Maher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pangerl_C/0/1/0/all/0/1\">Christian Pangerl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prabanantham_S/0/1/0/all/0/1\">Subash Prabanantham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bae_J/0/1/0/all/0/1\">Jae Hyeon Bae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_J/0/1/0/all/0/1\">Jamie Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goswami_B/0/1/0/all/0/1\">Bud Goswami</a>",
          "description": "AB testing aids business operators with their decision making, and is\nconsidered the gold standard method for learning from data to improve digital\nuser experiences. However, there is usually a gap between the requirements of\npractitioners, and the constraints imposed by the statistical hypothesis\ntesting methodologies commonly used for analysis of AB tests. These include the\nlack of statistical power in multivariate designs with many factors,\ncorrelations between these factors, the need of sequential testing for early\nstopping, and the inability to pool knowledge from past tests. Here, we propose\na solution that applies hierarchical Bayesian estimation to address the above\nlimitations. In comparison to current sequential AB testing methodology, we\nincrease statistical power by exploiting correlations between factors, enabling\nsequential testing and progressive early stopping, without incurring excessive\nfalse positive risk. We also demonstrate how this methodology can be extended\nto enable the extraction of composite global learnings from past AB tests, to\naccelerate future tests. We underpin our work with a solid theoretical\nframework that articulates the value of hierarchical estimation. We demonstrate\nits utility using both numerical simulations and a large set of real-world AB\ntests. Together, these results highlight the practical value of our approach\nfor statistical inference in the technology industry.",
          "link": "http://arxiv.org/abs/2307.14628",
          "publishedOn": "2023-07-29T00:48:57.422Z",
          "wordCount": null,
          "title": "Rapid and Scalable Bayesian AB Testing. (arXiv:2307.14628v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1\">Sen Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1\">Weishen Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Changshui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>",
          "description": "Algorithmic fairness has been a serious concern and received lots of interest\nin machine learning community. In this paper, we focus on the bipartite ranking\nscenario, where the instances come from either the positive or negative class\nand the goal is to learn a ranking function that ranks positive instances\nhigher than negative ones. While there could be a trade-off between fairness\nand performance, we propose a model agnostic post-processing framework xOrder\nfor achieving fairness in bipartite ranking and maintaining the algorithm\nclassification performance. In particular, we optimize a weighted sum of the\nutility as identifying an optimal warping path across different protected\ngroups and solve it through a dynamic programming process. xOrder is compatible\nwith various classification models and ranking fairness metrics, including\nsupervised and unsupervised fairness metrics. In addition to binary groups,\nxOrder can be applied to multiple protected groups. We evaluate our proposed\nalgorithm on four benchmark data sets and two real-world patient electronic\nhealth record repositories. xOrder consistently achieves a better balance\nbetween the algorithm utility and ranking fairness on a variety of datasets\nwith different metrics. From the visualization of the calibrated ranking\nscores, xOrder mitigates the score distribution shifts of different groups\ncompared with baselines. Moreover, additional analytical results verify that\nxOrder achieves a robust performance when faced with fewer samples and a bigger\ndifference between training and testing ranking score distributions.",
          "link": "http://arxiv.org/abs/2307.14668",
          "publishedOn": "2023-07-29T00:48:57.421Z",
          "wordCount": null,
          "title": "Bipartite Ranking Fairness through a Model Agnostic Ordering Adjustment. (arXiv:2307.14668v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bralios_D/0/1/0/all/0/1\">Dimitrios Bralios</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzinis_E/0/1/0/all/0/1\">Efthymios Tzinis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smaragdis_P/0/1/0/all/0/1\">Paris Smaragdis</a>",
          "description": "Recent approaches in source separation leverage semantic information about\ntheir input mixtures and constituent sources that when used in conditional\nseparation models can achieve impressive performance. Most approaches along\nthese lines have focused on simple descriptions, which are not always useful\nfor varying types of input mixtures. In this work, we present an approach in\nwhich a model, given an input mixture and partial semantic information about a\ntarget source, is trained to extract additional semantic data. We then leverage\nthis pre-trained model to improve the separation performance of an uncoupled\nmulti-conditional separation network. Our experiments demonstrate that the\nseparation performance of this multi-conditional model is significantly\nimproved, approaching the performance of an oracle model with complete semantic\ninformation. Furthermore, our approach achieves performance levels that are\ncomparable to those of the best performing specialized single conditional\nmodels, thus providing an easier to use alternative.",
          "link": "http://arxiv.org/abs/2307.14609",
          "publishedOn": "2023-07-29T00:48:57.420Z",
          "wordCount": null,
          "title": "Complete and separate: Conditional separation with missing target source attribute completion. (arXiv:2307.14609v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14729",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bungert_T/0/1/0/all/0/1\">Till J. Bungert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kobelke_L/0/1/0/all/0/1\">Levin Kobelke</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jaeger_P/0/1/0/all/0/1\">Paul F. Jaeger</a>",
          "description": "To ensure the reliable use of classification systems in medical applications,\nit is crucial to prevent silent failures. This can be achieved by either\ndesigning classifiers that are robust enough to avoid failures in the first\nplace, or by detecting remaining failures using confidence scoring functions\n(CSFs). A predominant source of failures in image classification is\ndistribution shifts between training data and deployment data. To understand\nthe current state of silent failure prevention in medical imaging, we conduct\nthe first comprehensive analysis comparing various CSFs in four biomedical\ntasks and a diverse range of distribution shifts. Based on the result that none\nof the benchmarked CSFs can reliably prevent silent failures, we conclude that\na deeper understanding of the root causes of failures in the data is required.\nTo facilitate this, we introduce SF-Visuals, an interactive analysis tool that\nuses latent space clustering to visualize shifts and failures. On the basis of\nvarious examples, we demonstrate how this tool can help researchers gain\ninsight into the requirements for safe application of classification systems in\nthe medical domain. The open-source benchmark and tool are at:\nhttps://github.com/IML-DKFZ/sf-visuals.",
          "link": "http://arxiv.org/abs/2307.14729",
          "publishedOn": "2023-07-29T00:48:57.420Z",
          "wordCount": null,
          "title": "Understanding Silent Failures in Medical Image Classification. (arXiv:2307.14729v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14367",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Abdine_H/0/1/0/all/0/1\">Hadi Abdine</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chatzianastasis_M/0/1/0/all/0/1\">Michail Chatzianastasis</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bouyioukos_C/0/1/0/all/0/1\">Costas Bouyioukos</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Vazirgiannis_M/0/1/0/all/0/1\">Michalis Vazirgiannis</a>",
          "description": "The complex nature of big biological systems pushed some scientists to\nclassify its understanding under the inconceivable missions. Different leveled\nchallenges complicated this task, one of is the prediction of a protein's\nfunction. In recent years, significant progress has been made in this field\nthrough the development of various machine learning approaches. However, most\nexisting methods formulate the task as a multi-classification problem, i.e\nassigning predefined labels to proteins. In this work, we propose a novel\napproach, \\textbf{Prot2Text}, which predicts a protein function's in a free\ntext style, moving beyond the conventional binary or categorical\nclassifications. By combining Graph Neural Networks(GNNs) and Large Language\nModels(LLMs), in an encoder-decoder framework, our model effectively integrates\ndiverse data types including proteins' sequences, structures, and textual\nannotations. This multimodal approach allows for a holistic representation of\nproteins' functions, enabling the generation of detailed and accurate\ndescriptions. To evaluate our model, we extracted a multimodal protein dataset\nfrom SwissProt, and demonstrate empirically the effectiveness of Prot2Text.\nThese results highlight the transformative impact of multimodal models,\nspecifically the fusion of GNNs and LLMs, empowering researchers with powerful\ntools for more accurate prediction of proteins' functions. The code, the models\nand a demo will be publicly released.",
          "link": "http://arxiv.org/abs/2307.14367",
          "publishedOn": "2023-07-29T00:48:57.380Z",
          "wordCount": null,
          "title": "Prot2Text: Multimodal Protein's Function Generation with GNNs and Transformers. (arXiv:2307.14367v1 [q-bio.QM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.02109",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdisarabshali_P/0/1/0/all/0/1\">Payam Abdisarabshali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Accurso_N/0/1/0/all/0/1\">Nicholas Accurso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malandra_F/0/1/0/all/0/1\">Filippo Malandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1\">Weifeng Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosseinalipour_S/0/1/0/all/0/1\">Seyyedali Hosseinalipour</a>",
          "description": "Federated learning (FL) is the most popular distributed machine learning\ntechnique. However, implementation of FL over modern wireless networks faces\nkey challenges caused by (i) dynamics of the network conditions and (ii) the\ncoexistence of multiple FL services/tasks and other network services in the\nsystem, which are not jointly considered in prior works. Motivated by these\nchallenges, we introduce a generic FL paradigm over NextG networks, called\ndynamic multi-service FL (DMS-FL). We identify three unexplored design\nconsiderations in DMS-FL: (i) FL service operator accumulation, (ii) wireless\nresource fragmentation, and (iii) signal strength fluctuations. We take the\nfirst steps towards addressing these design considerations by proposing a novel\ndistributed ML architecture called elastic virtualized FL (EV-FL). EV-FL\nunleashes the full potential of Open RAN (O-RAN) systems and introduces an\nelastic resource provisioning methodology to execute FL services. It further\nconstitutes a multi-time-scale FL management system that introduces three\ndimensions into existing FL architectures: (i) virtualization, (ii)\nscalability, and (iii) elasticity. Through investigating EV-FL, we reveal a\nseries of open research directions for future work. We finally simulate EV-FL\nto demonstrate its potential in saving wireless resources and increasing\nfairness among FL services.",
          "link": "http://arxiv.org/abs/2305.02109",
          "publishedOn": "2023-07-29T00:48:57.380Z",
          "wordCount": null,
          "title": "Synergies Between Federated Learning and O-RAN: Towards an Elastic Virtualized Architecture for Multiple Distributed Machine Learning Services. (arXiv:2305.02109v2 [cs.NI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14500",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dvir_N/0/1/0/all/0/1\">Nimrod Dvir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friedman_E/0/1/0/all/0/1\">Elaine Friedman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Commuri_S/0/1/0/all/0/1\">Suraj Commuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+yang_F/0/1/0/all/0/1\">Fan yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romano_J/0/1/0/all/0/1\">Jennifer Romano</a>",
          "description": "This study introduces and empirically tests a novel predictive model for\ndigital information engagement (IE) - the READ model, an acronym for the four\npivotal attributes of engaging information: Representativeness, Ease-of-use,\nAffect, and Distribution. Conceptualized within the theoretical framework of\nCumulative Prospect Theory, the model integrates key cognitive biases with\ncomputational linguistics and natural language processing to develop a\nmultidimensional perspective on information engagement. A rigorous testing\nprotocol was implemented, involving 50 randomly selected pairs of synonymous\nwords (100 words in total) from the WordNet database. These words' engagement\nlevels were evaluated through a large-scale online survey (n = 80,500) to\nderive empirical IE metrics. The READ attributes for each word were then\ncomputed and their predictive efficacy examined. The findings affirm the READ\nmodel's robustness, accurately predicting a word's IE level and distinguishing\nthe more engaging word from a pair of synonyms with an 84% accuracy rate. The\nREAD model's potential extends across various domains, including business,\neducation, government, and healthcare, where it could enhance content\nengagement and inform AI language model development and generative text work.\nFuture research should address the model's scalability and adaptability across\ndifferent domains and languages, thereby broadening its applicability and\nefficacy.",
          "link": "http://arxiv.org/abs/2307.14500",
          "publishedOn": "2023-07-29T00:48:57.379Z",
          "wordCount": null,
          "title": "A Predictive Model of Digital Information Engagement: Forecasting User Engagement With English Words by Incorporating Cognitive Biases, Computational Linguistics and Natural Language Processing. (arXiv:2307.14500v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14531",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geifman_A/0/1/0/all/0/1\">Amnon Geifman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barzilai_D/0/1/0/all/0/1\">Daniel Barzilai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basri_R/0/1/0/all/0/1\">Ronen Basri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galun_M/0/1/0/all/0/1\">Meirav Galun</a>",
          "description": "Wide neural networks are biased towards learning certain functions,\ninfluencing both the rate of convergence of gradient descent (GD) and the\nfunctions that are reachable with GD in finite training time. As such, there is\na great need for methods that can modify this bias according to the task at\nhand. To that end, we introduce Modified Spectrum Kernels (MSKs), a novel\nfamily of constructed kernels that can be used to approximate kernels with\ndesired eigenvalues for which no closed form is known. We leverage the duality\nbetween wide neural networks and Neural Tangent Kernels and propose a\npreconditioned gradient descent method, which alters the trajectory of GD. As a\nresult, this allows for a polynomial and, in some cases, exponential training\nspeedup without changing the final solution. Our method is both computationally\nefficient and simple to implement.",
          "link": "http://arxiv.org/abs/2307.14531",
          "publishedOn": "2023-07-29T00:48:57.379Z",
          "wordCount": null,
          "title": "Controlling the Inductive Bias of Wide Neural Networks by Modifying the Kernel's Spectrum. (arXiv:2307.14531v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1\">Xin Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianfeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhengyuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1\">Kevin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zicheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lijuan Wang</a>",
          "description": "In this paper, we study the denoising diffusion probabilistic model (DDPM) in\nwavelet space, instead of pixel space, for visual synthesis. Considering the\nwavelet transform represents the image in spatial and frequency domains, we\ncarefully design a novel architecture SFUNet to effectively capture the\ncorrelation for both domains. Specifically, in the standard denoising U-Net for\npixel data, we supplement the 2D convolutions and spatial-only attention layers\nwith our spatial frequency-aware convolution and attention modules to jointly\nmodel the complementary information from spatial and frequency domains in\nwavelet data. Our new architecture can be used as a drop-in replacement to the\npixel-based network and is compatible with the vanilla DDPM training process.\nBy explicitly modeling the wavelet signals, we find our model is able to\ngenerate images with higher quality on CIFAR-10, FFHQ, LSUN-Bedroom, and\nLSUN-Church datasets, than the pixel-based counterpart.",
          "link": "http://arxiv.org/abs/2307.14648",
          "publishedOn": "2023-07-29T00:48:57.379Z",
          "wordCount": null,
          "title": "Spatial-Frequency U-Net for Denoising Diffusion Probabilistic Models. (arXiv:2307.14648v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14384",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_X/0/1/0/all/0/1\">Xinting Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weiming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chaochao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Pengyang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Huabin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1\">Yanchao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1\">Yue Qi</a>",
          "description": "Federated learning (FL) collaboratively models user data in a decentralized\nway. However, in the real world, non-identical and independent data\ndistributions (non-IID) among clients hinder the performance of FL due to three\nissues, i.e., (1) the class statistics shifting, (2) the insufficient\nhierarchical information utilization, and (3) the inconsistency in aggregating\nclients. To address the above issues, we propose HyperFed which contains three\nmain modules, i.e., hyperbolic prototype Tammes initialization (HPTI),\nhyperbolic prototype learning (HPL), and consistent aggregation (CA). Firstly,\nHPTI in the server constructs uniformly distributed and fixed class prototypes,\nand shares them with clients to match class statistics, further guiding\nconsistent feature representation for local clients. Secondly, HPL in each\nclient captures the hierarchical information in local data with the supervision\nof shared class prototypes in the hyperbolic model space. Additionally, CA in\nthe server mitigates the impact of the inconsistent deviations from clients to\nserver. Extensive studies of four datasets prove that HyperFed is effective in\nenhancing the performance of FL under the non-IID set.",
          "link": "http://arxiv.org/abs/2307.14384",
          "publishedOn": "2023-07-29T00:48:57.378Z",
          "wordCount": null,
          "title": "HyperFed: Hyperbolic Prototypes Exploration with Consistent Aggregation for Non-IID Data in Federated Learning. (arXiv:2307.14384v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14634",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_R/0/1/0/all/0/1\">Razi Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Ge Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalra_M/0/1/0/all/0/1\">Mannudeep Kalra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_P/0/1/0/all/0/1\">Pingkun Yan</a>",
          "description": "With advances in generative artificial intelligence (AI), it is now possible\nto produce realistic-looking automated reports for preliminary reads of\nradiology images. This can expedite clinical workflows, improve accuracy and\nreduce overall costs. However, it is also well-known that such models often\nhallucinate, leading to false findings in the generated reports. In this paper,\nwe propose a new method of fact-checking of AI-generated reports using their\nassociated images. Specifically, the developed examiner differentiates real and\nfake sentences in reports by learning the association between an image and\nsentences describing real or potentially fake findings. To train such an\nexaminer, we first created a new dataset of fake reports by perturbing the\nfindings in the original ground truth radiology reports associated with images.\nText encodings of real and fake sentences drawn from these reports are then\npaired with image encodings to learn the mapping to real/fake labels. The\nutility of such an examiner is demonstrated for verifying automatically\ngenerated reports by detecting and removing fake sentences. Future generative\nAI approaches can use the resulting tool to validate their reports leading to a\nmore responsible use of AI in expediting clinical workflows.",
          "link": "http://arxiv.org/abs/2307.14634",
          "publishedOn": "2023-07-29T00:48:57.378Z",
          "wordCount": null,
          "title": "Fact-Checking of AI-Generated Reports. (arXiv:2307.14634v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14917",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Abhijith Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Munz_P/0/1/0/all/0/1\">Phil Munz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayan_A/0/1/0/all/0/1\">Apurva Narayan</a>",
          "description": "Visual AI systems are vulnerable to natural and synthetic physical corruption\nin the real-world. Such corruption often arises unexpectedly and alters the\nmodel's performance. In recent years, the primary focus has been on adversarial\nattacks. However, natural corruptions (e.g., snow, fog, dust) are an\nomnipresent threat to visual AI systems and should be considered equally\nimportant. Many existing works propose interesting solutions to train robust\nmodels against natural corruption. These works either leverage image\naugmentations, which come with the additional cost of model training, or place\nsuspicious patches in the scene to design unadversarial examples. In this work,\nwe propose the idea of naturalistic support artifacts (NSA) for robust\nprediction. The NSAs are shown to be beneficial in scenarios where model\nparameters are inaccessible and adding artifacts in the scene is feasible. The\nNSAs are natural looking objects generated through artifact training using\nDC-GAN to have high visual fidelity in the scene. We test against natural\ncorruptions on the Imagenette dataset and observe the improvement in prediction\nconfidence score by four times. We also demonstrate NSA's capability to\nincrease adversarial accuracy by 8\\% on average. Lastly, we qualitatively\nanalyze NSAs using saliency maps to understand how they help improve prediction\nconfidence.",
          "link": "http://arxiv.org/abs/2307.14917",
          "publishedOn": "2023-07-29T00:48:57.378Z",
          "wordCount": null,
          "title": "NSA: Naturalistic Support Artifact to Boost Network Confidence. (arXiv:2307.14917v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14375",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Ying Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hou-biao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu-pu Zhang</a>",
          "description": "With the development of Big data technology, data analysis has become\nincreasingly important. Traditional clustering algorithms such as K-means are\nhighly sensitive to the initial centroid selection and perform poorly on\nnon-convex datasets. In this paper, we address these problems by proposing a\ndata-driven Bregman divergence parameter optimization clustering algorithm\n(DBGSA), which combines the Universal Gravitational Algorithm to bring similar\npoints closer in the dataset. We construct a gravitational coefficient equation\nwith a special property that gradually reduces the influence factor as the\niteration progresses. Furthermore, we introduce the Bregman divergence\ngeneralized power mean information loss minimization to identify cluster\ncenters and build a hyperparameter identification optimization model, which\neffectively solves the problems of manual adjustment and uncertainty in the\nimproved dataset. Extensive experiments are conducted on four simulated\ndatasets and six real datasets. The results demonstrate that DBGSA\nsignificantly improves the accuracy of various clustering algorithms by an\naverage of 63.8\\% compared to other similar approaches like enhanced clustering\nalgorithms and improved datasets. Additionally, a three-dimensional grid search\nwas established to compare the effects of different parameter values within\nthreshold conditions, and it was discovered the parameter set provided by our\nmodel is optimal. This finding provides strong evidence of the high accuracy\nand robustness of the algorithm.",
          "link": "http://arxiv.org/abs/2307.14375",
          "publishedOn": "2023-07-29T00:48:57.369Z",
          "wordCount": null,
          "title": "DBGSA: A Novel Data Adaptive Bregman Clustering Algorithm. (arXiv:2307.14375v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14371",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cruz_F/0/1/0/all/0/1\">Fred Torres Cruz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flores_E/0/1/0/all/0/1\">Evelyn Eliana Coaquira Flores</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quispe_S/0/1/0/all/0/1\">Sebastian Jarom Condori Quispe</a>",
          "description": "This study presents a machine learning model based on the Naive Bayes\nclassifier for predicting the level of depression in university students, the\nobjective was to improve prediction accuracy using a machine learning model\ninvolving 70% training data and 30% validation data based on the Naive Bayes\nclassifier, the collected data includes factors associated with depression from\n519 university students, the results showed an accuracy of 78.03%, high\nsensitivity in detecting positive cases of depression, especially at moderate\nand severe levels, and significant specificity in correctly classifying\nnegative cases, these findings highlight the effectiveness of the model in\nearly detection and treatment of depression, benefiting vulnerable sectors and\ncontributing to the improvement of mental health in the student population.",
          "link": "http://arxiv.org/abs/2307.14371",
          "publishedOn": "2023-07-29T00:48:57.367Z",
          "wordCount": null,
          "title": "Prediction of depression status in college students using a Naive Bayes classifier based machine learning model. (arXiv:2307.14371v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14474",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Polloreno_A/0/1/0/all/0/1\">Anthony M. Polloreno</a>",
          "description": "In this work, we bound a machine's ability to learn based on computational\nlimitations implied by physicality. We start by considering the information\nprocessing capacity (IPC), a normalized measure of the expected squared error\nof a collection of signals to a complete basis of functions. We use the IPC to\nmeasure the degradation under noise of the performance of reservoir computers,\na particular kind of recurrent network, when constrained by physical\nconsiderations. First, we show that the IPC is at most a polynomial in the\nsystem size $n$, even when considering the collection of $2^n$ possible\npointwise products of the $n$ output signals. Next, we argue that this\ndegradation implies that the family of functions represented by the reservoir\nrequires an exponential number of samples to learn in the presence of the\nreservoir's noise. Finally, we conclude with a discussion of the performance of\nthe same collection of $2^n$ functions without noise when being used for binary\nclassification.",
          "link": "http://arxiv.org/abs/2307.14474",
          "publishedOn": "2023-07-29T00:48:57.366Z",
          "wordCount": null,
          "title": "Limits to Reservoir Learning. (arXiv:2307.14474v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14354",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Linden_P/0/1/0/all/0/1\">Putri A. van der Linden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romero_D/0/1/0/all/0/1\">David W. Romero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bekkers_E/0/1/0/all/0/1\">Erik J. Bekkers</a>",
          "description": "Neural operations that rely on neighborhood information are much more\nexpensive when deployed on point clouds than on grid data due to the irregular\ndistances between points in a point cloud. In a grid, on the other hand, we can\ncompute the kernel only once and reuse it for all query positions. As a result,\noperations that rely on neighborhood information scale much worse for point\nclouds than for grid data, specially for large inputs and large neighborhoods.\n\nIn this work, we address the scalability issue of point cloud methods by\ntackling its root cause: the irregularity of the data. We propose learnable\ngridification as the first step in a point cloud processing pipeline to\ntransform the point cloud into a compact, regular grid. Thanks to\ngridification, subsequent layers can use operations defined on regular grids,\ne.g., Conv3D, which scale much better than native point cloud methods. We then\nextend gridification to point cloud to point cloud tasks, e.g., segmentation,\nby adding a learnable de-gridification step at the end of the point cloud\nprocessing pipeline to map the compact, regular grid back to its original point\ncloud form. Through theoretical and empirical analysis, we show that gridified\nnetworks scale better in terms of memory and time than networks directly\napplied on raw point cloud data, while being able to achieve competitive\nresults. Our code is publicly available at\nhttps://github.com/computri/gridifier.",
          "link": "http://arxiv.org/abs/2307.14354",
          "publishedOn": "2023-07-29T00:48:57.364Z",
          "wordCount": null,
          "title": "Learned Gridification for Efficient Point Cloud Processing. (arXiv:2307.14354v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14448",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Teng_X/0/1/0/all/0/1\">Xian Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_Y/0/1/0/all/0/1\">Yongsu Ahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yu-Ru Lin</a>",
          "description": "Big data and machine learning tools have jointly empowered humans in making\ndata-driven decisions. However, many of them capture empirical associations\nthat might be spurious due to confounding factors and subgroup heterogeneity.\nThe famous Simpson's paradox is such a phenomenon where aggregated and\nsubgroup-level associations contradict with each other, causing cognitive\nconfusions and difficulty in making adequate interpretations and decisions.\nExisting tools provide little insights for humans to locate, reason about, and\nprevent pitfalls of spurious association in practice. We propose VISPUR, a\nvisual analytic system that provides a causal analysis framework and a\nhuman-centric workflow for tackling spurious associations. These include a\nCONFOUNDER DASHBOARD, which can automatically identify possible confounding\nfactors, and a SUBGROUP VIEWER, which allows for the visualization and\ncomparison of diverse subgroup patterns that likely or potentially result in a\nmisinterpretation of causality. Additionally, we propose a REASONING\nSTORYBOARD, which uses a flow-based approach to illustrate paradoxical\nphenomena, as well as an interactive DECISION DIAGNOSIS panel that helps ensure\naccountable decision-making. Through an expert interview and a controlled user\nexperiment, our qualitative and quantitative results demonstrate that the\nproposed \"de-paradox\" workflow and the designed visual analytic system are\neffective in helping human users to identify and understand spurious\nassociations, as well as to make accountable causal decisions.",
          "link": "http://arxiv.org/abs/2307.14448",
          "publishedOn": "2023-07-29T00:48:57.364Z",
          "wordCount": null,
          "title": "VISPUR: Visual Aids for Identifying and Interpreting Spurious Associations in Data-Driven Decisions. (arXiv:2307.14448v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14373",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+McCarty_S/0/1/0/all/0/1\">Sarah McCarty</a>",
          "description": "This paper analyzes representations of continuous piecewise linear functions\nwith infinite width, finite cost shallow neural networks using the rectified\nlinear unit (ReLU) as an activation function. Through its integral\nrepresentation, a shallow neural network can be identified by the corresponding\nsigned, finite measure on an appropriate parameter space. We map these measures\non the parameter space to measures on the projective $n$-sphere cross\n$\\mathbb{R}$, allowing points in the parameter space to be bijectively mapped\nto hyperplanes in the domain of the function. We prove a conjecture of Ongie et\nal. that every continuous piecewise linear function expressible with this kind\nof infinite width neural network is expressible as a finite width shallow ReLU\nneural network.",
          "link": "http://arxiv.org/abs/2307.14373",
          "publishedOn": "2023-07-29T00:48:57.360Z",
          "wordCount": null,
          "title": "Piecewise Linear Functions Representable with Infinite Width Shallow ReLU Neural Networks. (arXiv:2307.14373v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14362",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Pedersen_C/0/1/0/all/0/1\">Christian Pedersen</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Eickenberg_M/0/1/0/all/0/1\">Michael Eickenberg</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ho_S/0/1/0/all/0/1\">Shirley Ho</a>",
          "description": "Convolutional neural networks (CNNs) have been shown to both extract more\ninformation than the traditional two-point statistics from cosmological fields,\nand marginalise over astrophysical effects extremely well. However, CNNs\nrequire large amounts of training data, which is potentially problematic in the\ndomain of expensive cosmological simulations, and it is difficult to interpret\nthe network. In this work we apply the learnable scattering transform, a kind\nof convolutional neural network that uses trainable wavelets as filters, to the\nproblem of cosmological inference and marginalisation over astrophysical\neffects. We present two models based on the scattering transform, one\nconstructed for performance, and one constructed for interpretability, and\nperform a comparison with a CNN. We find that scattering architectures are able\nto outperform a CNN, significantly in the case of small training data samples.\nAdditionally we present a lightweight scattering network that is highly\ninterpretable.",
          "link": "http://arxiv.org/abs/2307.14362",
          "publishedOn": "2023-07-29T00:48:57.358Z",
          "wordCount": null,
          "title": "Learnable wavelet neural networks for cosmological inference. (arXiv:2307.14362v1 [astro-ph.IM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14374",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sadhukhan_S/0/1/0/all/0/1\">Suchetana Sadhukhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_V/0/1/0/all/0/1\">Vivek Kumar Yadav</a>",
          "description": "This study provides a comprehensive time series analysis of daily\nindustry-specific, country-wise CO$_2$ emissions from January 2019 to February\n2023. The research focuses on the Power, Industry, Ground Transport, Domestic\nAviation, and International Aviation sectors in European countries (EU27 & UK,\nItaly, Germany, Spain) and India, utilizing near-real-time activity data from\nthe Carbon Monitor research initiative. To identify regular emission patterns,\nthe data from the year 2020 is excluded due to the disruptive effects caused by\nthe COVID-19 pandemic. The study then performs a principal component analysis\n(PCA) to determine the key contributors to CO$_2$ emissions. The analysis\nreveals that the Power, Industry, and Ground Transport sectors account for a\nsignificant portion of the variance in the dataset. A 7-day moving averaged\ndataset is employed for further analysis to facilitate robust predictions. This\ndataset captures both short-term and long-term trends and enhances the quality\nof the data for prediction purposes. The study utilizes Long Short-Term Memory\n(LSTM) models on the 7-day moving averaged dataset to effectively predict\nemissions and provide insights for policy decisions, mitigation strategies, and\nclimate change efforts. During the training phase, the stability and\nconvergence of the LSTM models are ensured, which guarantees their reliability\nin the testing phase. The evaluation of the loss function indicates this\nreliability. The model achieves high efficiency, as demonstrated by $R^2$\nvalues ranging from 0.8242 to 0.995 for various countries and sectors.\nFurthermore, there is a proposal for utilizing scandium and\nboron/aluminium-based thin films as exceptionally efficient materials for\ncapturing CO$_2$ (with a binding energy range from -3.0 to -3.5 eV). These\nmaterials are shown to surpass the affinity of graphene and boron nitride\nsheets in this regard.",
          "link": "http://arxiv.org/abs/2307.14374",
          "publishedOn": "2023-07-29T00:48:57.358Z",
          "wordCount": null,
          "title": "Forecasting, capturing and activation of carbon-dioxide (CO$_2$): Integration of Time Series Analysis, Machine Learning, and Material Design. (arXiv:2307.14374v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14490",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mayer_B/0/1/0/all/0/1\">Brandon Mayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsitsulin_A/0/1/0/all/0/1\">Anton Tsitsulin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fichtenberger_H/0/1/0/all/0/1\">Hendrik Fichtenberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Halcrow_J/0/1/0/all/0/1\">Jonathan Halcrow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perozzi_B/0/1/0/all/0/1\">Bryan Perozzi</a>",
          "description": "Graphs are a representation of structured data that captures the\nrelationships between sets of objects. With the ubiquity of available network\ndata, there is increasing industrial and academic need to quickly analyze\ngraphs with billions of nodes and trillions of edges. A common first step for\nnetwork understanding is Graph Embedding, the process of creating a continuous\nrepresentation of nodes in a graph. A continuous representation is often more\namenable, especially at scale, for solving downstream machine learning tasks\nsuch as classification, link prediction, and clustering. A high-performance\ngraph embedding architecture leveraging Tensor Processing Units (TPUs) with\nconfigurable amounts of high-bandwidth memory is presented that simplifies the\ngraph embedding problem and can scale to graphs with billions of nodes and\ntrillions of edges. We verify the embedding space quality on real and synthetic\nlarge-scale datasets.",
          "link": "http://arxiv.org/abs/2307.14490",
          "publishedOn": "2023-07-29T00:48:57.358Z",
          "wordCount": null,
          "title": "HUGE: Huge Unsupervised Graph Embeddings with TPUs. (arXiv:2307.14490v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14395",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhuoyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hongsheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hongye Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1\">Bin Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_B/0/1/0/all/0/1\">Bei Hua</a>",
          "description": "Recently, using neural networks to simulate spatio-temporal dynamics has\nreceived a lot of attention. However, most existing methods adopt pure\ndata-driven black-box models, which have limited accuracy and interpretability.\nBy combining trainable difference operators with black-box models, we propose a\nnew hybrid architecture explicitly embedded with partial prior knowledge of the\nunderlying PDEs named PDE-Net++. Furthermore, we introduce two distinct options\ncalled the trainable flipping difference layer (TFDL) and the trainable dynamic\ndifference layer (TDDL) for the difference operators. Numerous numerical\nexperiments have demonstrated that PDE-Net++ has superior prediction accuracy\nand better extrapolation performance than black-box models.",
          "link": "http://arxiv.org/abs/2307.14395",
          "publishedOn": "2023-07-29T00:48:57.357Z",
          "wordCount": null,
          "title": "Learning to simulate partially known spatio-temporal dynamics with trainable difference operators. (arXiv:2307.14395v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14502",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Close_G/0/1/0/all/0/1\">George Close</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hain_T/0/1/0/all/0/1\">Thomas Hain</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Goetze_S/0/1/0/all/0/1\">Stefan Goetze</a>",
          "description": "Recent work in the field of speech enhancement (SE) has involved the use of\nself-supervised speech representations (SSSRs) as feature transformations in\nloss functions. However, in prior work, very little attention has been paid to\nthe relationship between the language of the audio used to train the\nself-supervised representation and that used to train the SE system.\nEnhancement models trained using a loss function which incorporates a\nself-supervised representation that shares exactly the language of the noisy\ndata used to train the SE system show better performance than those which do\nnot match exactly. This may lead to enhancement systems which are language\nspecific and as such do not generalise well to unseen languages, unlike models\ntrained using traditional spectrogram or time domain loss functions. In this\nwork, SE models are trained and tested on a number of different languages, with\nself-supervised representations which themselves are trained using different\nlanguage combinations and with differing network structures as loss function\nrepresentations. These models are then tested across unseen languages and their\nperformances are analysed. It is found that the training language of the\nself-supervised representation appears to have a minor effect on enhancement\nperformance, the amount of training data of a particular language, however,\ngreatly affects performance.",
          "link": "http://arxiv.org/abs/2307.14502",
          "publishedOn": "2023-07-29T00:48:57.357Z",
          "wordCount": null,
          "title": "The Effect of Spoken Language on Speech Enhancement using Self-Supervised Speech Representation Loss Functions. (arXiv:2307.14502v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14364",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Jiao_Y/0/1/0/all/0/1\">Yang Jiao</a>, <a href=\"http://arxiv.org/find/math/1/au:+Yang_K/0/1/0/all/0/1\">Kai Yang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Song_D/0/1/0/all/0/1\">Dongjin Song</a>",
          "description": "Distributionally Robust Optimization (DRO), which aims to find an optimal\ndecision that minimizes the worst case cost over the ambiguity set of\nprobability distribution, has been widely applied in diverse applications,\ne.g., network behavior analysis, risk management, etc. However, existing DRO\ntechniques face three key challenges: 1) how to deal with the asynchronous\nupdating in a distributed environment; 2) how to leverage the prior\ndistribution effectively; 3) how to properly adjust the degree of robustness\naccording to different scenarios. To this end, we propose an asynchronous\ndistributed algorithm, named Asynchronous Single-looP alternatIve gRadient\nprojEction (ASPIRE) algorithm with the itErative Active SEt method (EASE) to\ntackle the federated distributionally robust optimization (FDRO) problem.\nFurthermore, a new uncertainty set, i.e., constrained D-norm uncertainty set,\nis developed to effectively leverage the prior distribution and flexibly\ncontrol the degree of robustness. Finally, our theoretical analysis elucidates\nthat the proposed algorithm is guaranteed to converge and the iteration\ncomplexity is also analyzed. Extensive empirical studies on real-world datasets\ndemonstrate that the proposed method can not only achieve fast convergence, and\nremain robust against data heterogeneity as well as malicious attacks, but also\ntradeoff robustness with performance.",
          "link": "http://arxiv.org/abs/2307.14364",
          "publishedOn": "2023-07-29T00:48:57.354Z",
          "wordCount": null,
          "title": "Federated Distributionally Robust Optimization with Non-Convex Objectives: Algorithm and Analysis. (arXiv:2307.14364v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14465",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khairunnesa_S/0/1/0/all/0/1\">Samantha Syeda Khairunnesa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1\">Shibbir Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imtiaz_S/0/1/0/all/0/1\">Sayem Mohammad Imtiaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajan_H/0/1/0/all/0/1\">Hridesh Rajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leavens_G/0/1/0/all/0/1\">Gary T. Leavens</a>",
          "description": "Recent work has shown that Machine Learning (ML) programs are error-prone and\ncalled for contracts for ML code. Contracts, as in the design by contract\nmethodology, help document APIs and aid API users in writing correct code. The\nquestion is: what kinds of contracts would provide the most help to API users?\nWe are especially interested in what kinds of contracts help API users catch\nerrors at earlier stages in the ML pipeline. We describe an empirical study of\nposts on Stack Overflow of the four most often-discussed ML libraries:\nTensorFlow, Scikit-learn, Keras, and PyTorch. For these libraries, our study\nextracted 413 informal (English) API specifications. We used these\nspecifications to understand the following questions. What are the root causes\nand effects behind ML contract violations? Are there common patterns of ML\ncontract violations? When does understanding ML contracts require an advanced\nlevel of ML software expertise? Could checking contracts at the API level help\ndetect the violations in early ML pipeline stages? Our key findings are that\nthe most commonly needed contracts for ML APIs are either checking constraints\non single arguments of an API or on the order of API calls. The software\nengineering community could employ existing contract mining approaches to mine\nthese contracts to promote an increased understanding of ML APIs. We also noted\na need to combine behavioral and temporal contract mining approaches. We report\non categories of required ML contracts, which may help designers of contract\nlanguages.",
          "link": "http://arxiv.org/abs/2307.14465",
          "publishedOn": "2023-07-29T00:48:57.354Z",
          "wordCount": null,
          "title": "What Kinds of Contracts Do ML APIs Need?. (arXiv:2307.14465v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14363",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Catalan_T/0/1/0/all/0/1\">Tabita Catal&#xe1;n</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Courdurier_M/0/1/0/all/0/1\">Mat&#xed;as Courdurier</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Osses_A/0/1/0/all/0/1\">Axel Osses</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Botnar_R/0/1/0/all/0/1\">Ren&#xe9; Botnar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Costabal_F/0/1/0/all/0/1\">Francisco Sahli Costabal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prieto_C/0/1/0/all/0/1\">Claudia Prieto</a>",
          "description": "Cardiac cine MRI is the gold standard for cardiac functional assessment, but\nthe inherently slow acquisition process creates the necessity of reconstruction\napproaches for accelerated undersampled acquisitions. Several regularization\napproaches that exploit spatial-temporal redundancy have been proposed to\nreconstruct undersampled cardiac cine MRI. More recently, methods based on\nsupervised deep learning have been also proposed to further accelerate\nacquisition and reconstruction. However, these techniques rely on usually large\ndataset for training, which are not always available. In this work, we propose\nan unsupervised approach based on implicit neural field representations for\ncardiac cine MRI (so called NF-cMRI). The proposed method was evaluated in\nin-vivo undersampled golden-angle radial multi-coil acquisitions for\nundersampling factors of 26x and 52x, achieving good image quality, and\ncomparable spatial and improved temporal depiction than a state-of-the-art\nreconstruction technique.",
          "link": "http://arxiv.org/abs/2307.14363",
          "publishedOn": "2023-07-29T00:48:57.353Z",
          "wordCount": null,
          "title": "Unsupervised reconstruction of accelerated cardiac cine MRI using Neural Fields. (arXiv:2307.14363v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14530",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Noskov_F/0/1/0/all/0/1\">Fedor Noskov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Panov_M/0/1/0/all/0/1\">Maxim Panov</a>",
          "description": "Community detection is one of the most critical problems in modern network\nscience. Its applications can be found in various fields, from protein modeling\nto social network analysis. Recently, many papers appeared studying the problem\nof overlapping community detection, where each node of a network may belong to\nseveral communities. In this work, we consider Mixed-Membership Stochastic\nBlock Model (MMSB) first proposed by Airoldi et al. (2008). MMSB provides quite\na general setting for modeling overlapping community structure in graphs. The\ncentral question of this paper is to reconstruct relations between communities\ngiven an observed network. We compare different approaches and establish the\nminimax lower bound on the estimation error. Then, we propose a new estimator\nthat matches this lower bound. Theoretical results are proved under fairly\ngeneral conditions on the considered model. Finally, we illustrate the theory\nin a series of experiments.",
          "link": "http://arxiv.org/abs/2307.14530",
          "publishedOn": "2023-07-29T00:48:57.353Z",
          "wordCount": null,
          "title": "Optimal Estimation in Mixed-Membership Stochastic Block Models. (arXiv:2307.14530v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14397",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdollahzadeh_M/0/1/0/all/0/1\">Milad Abdollahzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malekzadeh_T/0/1/0/all/0/1\">Touba Malekzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teo_C/0/1/0/all/0/1\">Christopher T. H. Teo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandrasegaran_K/0/1/0/all/0/1\">Keshigeyan Chandrasegaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guimeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheung_N/0/1/0/all/0/1\">Ngai-Man Cheung</a>",
          "description": "In machine learning, generative modeling aims to learn to generate new data\nstatistically similar to the training data distribution. In this paper, we\nsurvey learning generative models under limited data, few shots and zero shot,\nreferred to as Generative Modeling under Data Constraint (GM-DC). This is an\nimportant topic when data acquisition is challenging, e.g. healthcare\napplications. We discuss background, challenges, and propose two taxonomies:\none on GM-DC tasks and another on GM-DC approaches. Importantly, we study\ninteractions between different GM-DC tasks and approaches. Furthermore, we\nhighlight research gaps, research trends, and potential avenues for future\nexploration. Project website: https://gmdc-survey.github.io.",
          "link": "http://arxiv.org/abs/2307.14397",
          "publishedOn": "2023-07-29T00:48:57.352Z",
          "wordCount": null,
          "title": "A Survey on Generative Modeling with Limited Data, Few Shots, and Zero Shot. (arXiv:2307.14397v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.05776",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wu_S/0/1/0/all/0/1\">Sidi Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Beaulac_C/0/1/0/all/0/1\">C&#xe9;dric Beaulac</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cao_J/0/1/0/all/0/1\">Jiguo Cao</a>",
          "description": "The regression of a functional response on a set of scalar predictors can be\na challenging task, especially if there is a large number of predictors, or the\nrelationship between those predictors and the response is nonlinear. In this\nwork, we propose a solution to this problem: a feed-forward neural network (NN)\ndesigned to predict a functional response using scalar inputs. First, we\ntransform the functional response to a finite-dimensional representation and\nconstruct an NN that outputs this representation. Then, we propose to modify\nthe output of an NN via the objective function and introduce different\nobjective functions for network training. The proposed models are suited for\nboth regularly and irregularly spaced data, and a roughness penalty can be\nfurther applied to control the smoothness of the predicted curve. The\ndifficulty in implementing both those features lies in the definition of\nobjective functions that can be back-propagated. In our experiments, we\ndemonstrate that our model outperforms the conventional function-on-scalar\nregression model in multiple scenarios while computationally scaling better\nwith the dimension of the predictors.",
          "link": "http://arxiv.org/abs/2208.05776",
          "publishedOn": "2023-07-29T00:48:57.327Z",
          "wordCount": null,
          "title": "Neural Networks for Scalar Input and Functional Output. (arXiv:2208.05776v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.08424",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Besbes_O/0/1/0/all/0/1\">Omar Besbes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Will Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mouchtaki_O/0/1/0/all/0/1\">Omar Mouchtaki</a>",
          "description": "In this work, we explore a framework for contextual decision-making to study\nhow the relevance and quantity of past data affects the performance of a\ndata-driven policy. We analyze a contextual Newsvendor problem in which a\ndecision-maker needs to trade-off between an underage and an overage cost in\nthe face of uncertain demand. We consider a setting in which past demands\nobserved under ``close by'' contexts come from close by distributions and\nanalyze the performance of data-driven algorithms through a notion of\ncontext-dependent worst-case expected regret. We analyze the broad class of\nWeighted Empirical Risk Minimization (WERM) policies which weigh past data\naccording to their similarity in the contextual space. This class includes\nclassical policies such as ERM, k-Nearest Neighbors and kernel-based policies.\nOur main methodological contribution is to characterize exactly the worst-case\nregret of any WERM policy on any given configuration of contexts. To the best\nof our knowledge, this provides the first understanding of tight performance\nguarantees in any contextual decision-making problem, with past literature\nfocusing on upper bounds via concentration inequalities. We instead take an\noptimization approach, and isolate a structure in the Newsvendor loss function\nthat allows to reduce the infinite-dimensional optimization problem over\nworst-case distributions to a simple line search.\n\nThis in turn allows us to unveil fundamental insights that were obfuscated by\nprevious general-purpose bounds. We characterize actual guaranteed performance\nas a function of the contexts, as well as granular insights on the learning\ncurve of algorithms.",
          "link": "http://arxiv.org/abs/2302.08424",
          "publishedOn": "2023-07-29T00:48:57.323Z",
          "wordCount": null,
          "title": "From Contextual Data to Newsvendor Decisions: On the Actual Performance of Data-Driven Algorithms. (arXiv:2302.08424v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.10255",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cate_B/0/1/0/all/0/1\">Balder ten Cate</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Funk_M/0/1/0/all/0/1\">Maurice Funk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_J/0/1/0/all/0/1\">Jean Christoph Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lutz_C/0/1/0/all/0/1\">Carsten Lutz</a>",
          "description": "This note serves three purposes: (i) we provide a self-contained exposition\nof the fact that conjunctive queries are not efficiently learnable in the\nProbably-Approximately-Correct (PAC) model, paying clear attention to the\ncomplicating fact that this concept class lacks the polynomial-size fitting\nproperty, a property that is tacitly assumed in much of the computational\nlearning theory literature; (ii) we establish a strong negative PAC\nlearnability result that applies to many restricted classes of conjunctive\nqueries (CQs), including acyclic CQs for a wide range of notions of\n\"acyclicity\"; (iii) we show that CQs (and UCQs) are efficiently PAC learnable\nwith membership queries.",
          "link": "http://arxiv.org/abs/2208.10255",
          "publishedOn": "2023-07-29T00:48:57.321Z",
          "wordCount": null,
          "title": "On the non-efficient PAC learnability of conjunctive queries. (arXiv:2208.10255v2 [cs.DB] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14751",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tekgul_B/0/1/0/all/0/1\">Buse G. A. Tekgul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asokan_N/0/1/0/all/0/1\">N. Asokan</a>",
          "description": "We propose FLARE, the first fingerprinting mechanism to verify whether a\nsuspected Deep Reinforcement Learning (DRL) policy is an illegitimate copy of\nanother (victim) policy. We first show that it is possible to find\nnon-transferable, universal adversarial masks, i.e., perturbations, to generate\nadversarial examples that can successfully transfer from a victim policy to its\nmodified versions but not to independently trained policies. FLARE employs\nthese masks as fingerprints to verify the true ownership of stolen DRL policies\nby measuring an action agreement value over states perturbed via such masks.\nOur empirical evaluations show that FLARE is effective (100% action agreement\non stolen copies) and does not falsely accuse independent policies (no false\npositives). FLARE is also robust to model modification attacks and cannot be\neasily evaded by more informed adversaries without negatively impacting agent\nperformance. We also show that not all universal adversarial masks are suitable\ncandidates for fingerprints due to the inherent characteristics of DRL\npolicies. The spatio-temporal dynamics of DRL problems and sequential\ndecision-making process make characterizing the decision boundary of DRL\npolicies more difficult, as well as searching for universal masks that capture\nthe geometry of it.",
          "link": "http://arxiv.org/abs/2307.14751",
          "publishedOn": "2023-07-29T00:48:57.320Z",
          "wordCount": null,
          "title": "FLARE: Fingerprinting Deep Reinforcement Learning Agents using Universal Adversarial Masks. (arXiv:2307.14751v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14381",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sikdokur_I/0/1/0/all/0/1\">Ilkay Sikdokur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baytas_I/0/1/0/all/0/1\">&#x130;nci M. Bayta&#x15f;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yurdakul_A/0/1/0/all/0/1\">Arda Yurdakul</a>",
          "description": "Deep edge intelligence aims to deploy deep learning models that demand\ncomputationally expensive training in the edge network with limited\ncomputational power. Moreover, many deep edge intelligence applications require\nhandling distributed data that cannot be transferred to a central server due to\nprivacy concerns. Decentralized learning methods, such as federated learning,\noffer solutions where models are learned collectively by exchanging learned\nweights. However, they often require complex models that edge devices may not\nhandle and multiple rounds of network communication to achieve state-of-the-art\nperformances. This study proposes a convolutional ensemble learning approach,\ncoined EdgeConvEns, that facilitates training heterogeneous weak models on edge\nand learning to ensemble them where data on edge are heterogeneously\ndistributed. Edge models are implemented and trained independently on\nField-Programmable Gate Array (FPGA) devices with various computational\ncapacities. Learned data representations are transferred to a central server\nwhere the ensemble model is trained with the learned features received from the\nedge devices to boost the overall prediction performance. Extensive experiments\ndemonstrate that the EdgeConvEns can outperform the state-of-the-art\nperformance with fewer communications and less data in various training\nscenarios.",
          "link": "http://arxiv.org/abs/2307.14381",
          "publishedOn": "2023-07-29T00:48:57.319Z",
          "wordCount": null,
          "title": "EdgeConvEns: Convolutional Ensemble Learning for Edge Intelligence. (arXiv:2307.14381v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14366",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gale_A/0/1/0/all/0/1\">Abraham Gale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marian_A/0/1/0/all/0/1\">Am&#xc9;lie Marian</a>",
          "description": "Ranking functions that are used in decision systems often produce disparate\nresults for different populations because of bias in the underlying data.\nAddressing, and compensating for, these disparate outcomes is a critical\nproblem for fair decision-making. Recent compensatory measures have mostly\nfocused on opaque transformations of the ranking functions to satisfy fairness\nguarantees or on the use of quotas or set-asides to guarantee a minimum number\nof positive outcomes to members of underrepresented groups. In this paper we\npropose easily explainable data-driven compensatory measures for ranking\nfunctions. Our measures rely on the generation of bonus points given to members\nof underrepresented groups to address disparity in the ranking function. The\nbonus points can be set in advance, and can be combined, allowing for\nconsidering the intersections of representations and giving better transparency\nto stakeholders. We propose efficient sampling-based algorithms to calculate\nthe number of bonus points to minimize disparity. We validate our algorithms\nusing real-world school admissions and recidivism datasets, and compare our\nresults with that of existing fair ranking algorithms.",
          "link": "http://arxiv.org/abs/2307.14366",
          "publishedOn": "2023-07-29T00:48:57.317Z",
          "wordCount": null,
          "title": "Explainable Disparity Compensation for Efficient Fair Ranking. (arXiv:2307.14366v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.06589",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hyungeun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1\">Kijung Yoon</a>",
          "description": "Graph neural networks (GNNs) have become compelling models designed to\nperform learning and inference on graph-structured data. However, little work\nhas been done to understand the fundamental limitations of GNNs for scaling to\nlarger graphs and generalizing to out-of-distribution (OOD) inputs. In this\npaper, we use a random graph generator to systematically investigate how the\ngraph size and structural properties affect the predictive performance of GNNs.\nWe present specific evidence that the average node degree is a key feature in\ndetermining whether GNNs can generalize to unseen graphs, and that the use of\nmultiple node update functions can improve the generalization performance of\nGNNs when dealing with graphs of multimodal degree distributions. Accordingly,\nwe propose a multi-module GNN framework that allows the network to adapt\nflexibly to new graphs by generalizing a single canonical nonlinear\ntransformation over aggregated inputs. Our results show that the multi-module\nGNNs improve the OOD generalization on a variety of inference tasks in the\ndirection of diverse structural features.",
          "link": "http://arxiv.org/abs/2209.06589",
          "publishedOn": "2023-07-29T00:48:57.286Z",
          "wordCount": null,
          "title": "Towards Better Generalization with Flexible Representation of Multi-Module Graph Neural Networks. (arXiv:2209.06589v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.15043",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zou_A/0/1/0/all/0/1\">Andy Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1\">J. Zico Kolter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fredrikson_M/0/1/0/all/0/1\">Matt Fredrikson</a>",
          "description": "Because \"out-of-the-box\" large language models are capable of generating a\ngreat deal of objectionable content, recent work has focused on aligning these\nmodels in an attempt to prevent undesirable generation. While there has been\nsome success at circumventing these measures -- so-called \"jailbreaks\" against\nLLMs -- these attacks have required significant human ingenuity and are brittle\nin practice. In this paper, we propose a simple and effective attack method\nthat causes aligned language models to generate objectionable behaviors.\nSpecifically, our approach finds a suffix that, when attached to a wide range\nof queries for an LLM to produce objectionable content, aims to maximize the\nprobability that the model produces an affirmative response (rather than\nrefusing to answer). However, instead of relying on manual engineering, our\napproach automatically produces these adversarial suffixes by a combination of\ngreedy and gradient-based search techniques, and also improves over past\nautomatic prompt generation methods.\n\nSurprisingly, we find that the adversarial prompts generated by our approach\nare quite transferable, including to black-box, publicly released LLMs.\nSpecifically, we train an adversarial attack suffix on multiple prompts (i.e.,\nqueries asking for many different types of objectionable content), as well as\nmultiple models (in our case, Vicuna-7B and 13B). When doing so, the resulting\nattack suffix is able to induce objectionable content in the public interfaces\nto ChatGPT, Bard, and Claude, as well as open source LLMs such as LLaMA-2-Chat,\nPythia, Falcon, and others. In total, this work significantly advances the\nstate-of-the-art in adversarial attacks against aligned language models,\nraising important questions about how such systems can be prevented from\nproducing objectionable information. Code is available at\ngithub.com/llm-attacks/llm-attacks.",
          "link": "http://arxiv.org/abs/2307.15043",
          "publishedOn": "2023-07-29T00:48:57.284Z",
          "wordCount": null,
          "title": "Universal and Transferable Adversarial Attacks on Aligned Language Models. (arXiv:2307.15043v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saxena_P/0/1/0/all/0/1\">Priyansh Saxena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1\">Raahat Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maheshwari_A/0/1/0/all/0/1\">Akshat Maheshwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maheshwari_S/0/1/0/all/0/1\">Saumil Maheshwari</a>",
          "description": "Semantic inpainting or image completion alludes to the task of inferring\narbitrary large missing regions in images based on image semantics. Since the\nprediction of image pixels requires an indication of high-level context, this\nmakes it significantly tougher than image completion, which is often more\nconcerned with correcting data corruption and removing entire objects from the\ninput image. On the other hand, image enhancement attempts to eliminate\nunwanted noise and blur from the image, along with sustaining most of the image\ndetails. Efficient image completion and enhancement model should be able to\nrecover the corrupted and masked regions in images and then refine the image\nfurther to increase the quality of the output image. Generative Adversarial\nNetworks (GAN), have turned out to be helpful in picture completion tasks. In\nthis chapter, we will discuss the underlying GAN architecture and how they can\nbe used used for image completion tasks.",
          "link": "http://arxiv.org/abs/2307.14748",
          "publishedOn": "2023-07-29T00:48:57.265Z",
          "wordCount": null,
          "title": "Semantic Image Completion and Enhancement using GANs. (arXiv:2307.14748v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14549",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1\">Jianjun Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woon_W/0/1/0/all/0/1\">Wei Lee Woon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coba_L/0/1/0/all/0/1\">Ludovik Coba</a>",
          "description": "This paper presents an efficient algorithm to solve the sleeping bandit with\nmultiple plays problem in the context of an online recommendation system. The\nproblem involves bounded, adversarial loss and unknown i.i.d. distributions for\narm availability. The proposed algorithm extends the sleeping bandit algorithm\nfor single arm selection and is guaranteed to achieve theoretical performance\nwith regret upper bounded by $\\bigO(kN^2\\sqrt{T\\log T})$, where $k$ is the\nnumber of arms selected per time step, $N$ is the total number of arms, and $T$\nis the time horizon.",
          "link": "http://arxiv.org/abs/2307.14549",
          "publishedOn": "2023-07-29T00:48:57.243Z",
          "wordCount": null,
          "title": "Adversarial Sleeping Bandit Problems with Multiple Plays: Algorithm and Ranking Application. (arXiv:2307.14549v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Almeida_T/0/1/0/all/0/1\">Tiago Rodrigues de Almeida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozos_O/0/1/0/all/0/1\">Oscar Martinez Mozos</a>",
          "description": "Autonomous systems in the road transportation network require intelligent\nmechanisms that cope with uncertainty to foresee the future. In this paper, we\npropose a multi-stage probabilistic approach for trajectory forecasting:\ntrajectory transformation to displacement space, clustering of displacement\ntime series, trajectory proposals, and ranking proposals. We introduce a new\ndeep feature clustering method, underlying self-conditioned GAN, which copes\nbetter with distribution shifts than traditional methods. Additionally, we\npropose novel distance-based ranking proposals to assign probabilities to the\ngenerated trajectories that are more efficient yet accurate than an auxiliary\nneural network. The overall system surpasses context-free deep generative\nmodels in human and road agents trajectory data while performing similarly to\npoint estimators when comparing the most probable trajectory.",
          "link": "http://arxiv.org/abs/2307.14788",
          "publishedOn": "2023-07-29T00:48:57.242Z",
          "wordCount": null,
          "title": "Likely, Light, and Accurate Context-Free Clusters-based Trajectory Prediction. (arXiv:2307.14788v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharir_O/0/1/0/all/0/1\">Or Sharir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>",
          "description": "Deep learning often faces the challenge of efficiently processing dynamic\ninputs, such as sensor data or user inputs. For example, an AI writing\nassistant is required to update its suggestions in real time as a document is\nedited. Re-running the model each time is expensive, even with compression\ntechniques like knowledge distillation, pruning, or quantization. Instead, we\ntake an incremental computing approach, looking to reuse calculations as the\ninputs change. However, the dense connectivity of conventional architectures\nposes a major obstacle to incremental computation, as even minor input changes\ncascade through the network and restrict information reuse. To address this, we\nuse vector quantization to discretize intermediate values in the network, which\nfilters out noisy and unnecessary modifications to hidden neurons, facilitating\nthe reuse of their values. We apply this approach to the transformers\narchitecture, creating an efficient incremental inference algorithm with\ncomplexity proportional to the fraction of the modified inputs. Our experiments\nwith adapting the OPT-125M pre-trained language model demonstrate comparable\naccuracy on document classification while requiring 12.1X (median) fewer\noperations for processing sequences of atomic edits.",
          "link": "http://arxiv.org/abs/2307.14988",
          "publishedOn": "2023-07-29T00:48:57.239Z",
          "wordCount": null,
          "title": "Incrementally-Computable Neural Networks: Efficient Inference for Dynamic Inputs. (arXiv:2307.14988v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14839",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+English_E/0/1/0/all/0/1\">Eshant English</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kirchler_M/0/1/0/all/0/1\">Matthias Kirchler</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lippert_C/0/1/0/all/0/1\">Christoph Lippert</a>",
          "description": "Normalising Flows are generative models characterised by their invertible\narchitecture. However, the requirement of invertibility imposes constraints on\ntheir expressiveness, necessitating a large number of parameters and innovative\narchitectural designs to achieve satisfactory outcomes. Whilst flow-based\nmodels predominantly rely on neural-network-based transformations for\nexpressive designs, alternative transformation methods have received limited\nattention. In this work, we present Ferumal flow, a novel kernelised\nnormalising flow paradigm that integrates kernels into the framework. Our\nresults demonstrate that a kernelised flow can yield competitive or superior\nresults compared to neural network-based flows whilst maintaining parameter\nefficiency. Kernelised flows excel especially in the low-data regime, enabling\nflexible non-parametric density estimation in applications with sparse data\navailability.",
          "link": "http://arxiv.org/abs/2307.14839",
          "publishedOn": "2023-07-29T00:48:57.222Z",
          "wordCount": null,
          "title": "Kernelised Normalising Flows. (arXiv:2307.14839v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14935",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chernishev_G/0/1/0/all/0/1\">George Chernishev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polyntsov_M/0/1/0/all/0/1\">Michael Polyntsov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chizhov_A/0/1/0/all/0/1\">Anton Chizhov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stupakov_K/0/1/0/all/0/1\">Kirill Stupakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shchuckin_I/0/1/0/all/0/1\">Ilya Shchuckin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smirnov_A/0/1/0/all/0/1\">Alexander Smirnov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strutovsky_M/0/1/0/all/0/1\">Maxim Strutovsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shlyonskikh_A/0/1/0/all/0/1\">Alexey Shlyonskikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Firsov_M/0/1/0/all/0/1\">Mikhail Firsov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manannikov_S/0/1/0/all/0/1\">Stepan Manannikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bobrov_N/0/1/0/all/0/1\">Nikita Bobrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goncharov_D/0/1/0/all/0/1\">Daniil Goncharov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barutkin_I/0/1/0/all/0/1\">Ilia Barutkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shalnev_V/0/1/0/all/0/1\">Vladislav Shalnev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muraviev_K/0/1/0/all/0/1\">Kirill Muraviev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rakhmukova_A/0/1/0/all/0/1\">Anna Rakhmukova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shcheka_D/0/1/0/all/0/1\">Dmitriy Shcheka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chernikov_A/0/1/0/all/0/1\">Anton Chernikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vyrodov_M/0/1/0/all/0/1\">Mikhail Vyrodov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yaroslav_K/0/1/0/all/0/1\">Kurbatov Yaroslav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fofanov_M/0/1/0/all/0/1\">Maxim Fofanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sergei_B/0/1/0/all/0/1\">Belokonnyi Sergei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavel_A/0/1/0/all/0/1\">Anosov Pavel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saliou_A/0/1/0/all/0/1\">Arthur Saliou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaisin_E/0/1/0/all/0/1\">Eduard Gaisin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smirnov_K/0/1/0/all/0/1\">Kirill Smirnov</a>",
          "description": "Data profiling is an essential process in modern data-driven industries. One\nof its critical components is the discovery and validation of complex\nstatistics, including functional dependencies, data constraints, association\nrules, and others.\n\nHowever, most existing data profiling systems that focus on complex\nstatistics do not provide proper integration with the tools used by\ncontemporary data scientists. This creates a significant barrier to the\nadoption of these tools in the industry. Moreover, existing systems were not\ncreated with industrial-grade workloads in mind. Finally, they do not aim to\nprovide descriptive explanations, i.e. why a given pattern is not found. It is\na significant issue as it is essential to understand the underlying reasons for\na specific pattern's absence to make informed decisions based on the data.\n\nBecause of that, these patterns are effectively rest in thin air: their\napplication scope is rather limited, they are rarely used by the broader\npublic. At the same time, as we are going to demonstrate in this presentation,\ncomplex statistics can be efficiently used to solve many classic data quality\nproblems.\n\nDesbordante is an open-source data profiler that aims to close this gap. It\nis built with emphasis on industrial application: it is efficient, scalable,\nresilient to crashes, and provides explanations. Furthermore, it provides\nseamless Python integration by offloading various costly operations to the C++\ncore, not only mining.\n\nIn this demonstration, we show several scenarios that allow end users to\nsolve different data quality problems. Namely, we showcase typo detection, data\ndeduplication, and data anomaly detection scenarios.",
          "link": "http://arxiv.org/abs/2307.14935",
          "publishedOn": "2023-07-29T00:48:57.221Z",
          "wordCount": null,
          "title": "Solving Data Quality Problems with Desbordante: a Demo. (arXiv:2307.14935v1 [cs.DB])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14952",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mclaughlin_C/0/1/0/all/0/1\">Connor Mclaughlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Matthew Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Edogmus_D/0/1/0/all/0/1\">Denis Edogmus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_L/0/1/0/all/0/1\">Lili Su</a>",
          "description": "As the network scale increases, existing fully distributed solutions start to\nlag behind the real-world challenges such as (1) slow information propagation,\n(2) network communication failures, and (3) external adversarial attacks. In\nthis paper, we focus on hierarchical system architecture and address the\nproblem of non-Bayesian learning over networks that are vulnerable to\ncommunication failures and adversarial attacks. On network communication, we\nconsider packet-dropping link failures.\n\nWe first propose a hierarchical robust push-sum algorithm that can achieve\naverage consensus despite frequent packet-dropping link failures. We provide a\nsparse information fusion rule between the parameter server and arbitrarily\nselected network representatives. Then, interleaving the consensus update step\nwith a dual averaging update with Kullback-Leibler (KL) divergence as the\nproximal function, we obtain a packet-dropping fault-tolerant non-Bayesian\nlearning algorithm with provable convergence guarantees.\n\nOn external adversarial attacks, we consider Byzantine attacks in which the\ncompromised agents can send maliciously calibrated messages to others\n(including both the agents and the parameter server). To avoid the curse of\ndimensionality of Byzantine consensus, we solve the non-Bayesian learning\nproblem via running multiple dynamics, each of which only involves Byzantine\nconsensus with scalar inputs. To facilitate resilient information propagation\nacross sub-networks, we use a novel Byzantine-resilient gossiping-type rule at\nthe parameter server.",
          "link": "http://arxiv.org/abs/2307.14952",
          "publishedOn": "2023-07-29T00:48:57.220Z",
          "wordCount": null,
          "title": "Network Fault-tolerant and Byzantine-resilient Social Learning via Collaborative Hierarchical Non-Bayesian Learning. (arXiv:2307.14952v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14482",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kline_T/0/1/0/all/0/1\">Timothy L. Kline</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ramanathan_S/0/1/0/all/0/1\">Sumana Ramanathan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gottlich_H/0/1/0/all/0/1\">Harrison C. Gottlich</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Korfiatis_P/0/1/0/all/0/1\">Panagiotis Korfiatis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gregory_A/0/1/0/all/0/1\">Adriana V. Gregory</a>",
          "description": "Purpose: This study evaluated the out-of-domain performance and\ngeneralization capabilities of automated medical image segmentation models,\nwith a particular focus on adaptation to new image acquisitions and disease\ntype.\n\nMaterials: Datasets from both non-contrast and contrast-enhanced abdominal CT\nscans of healthy patients and those with polycystic kidney disease (PKD) were\nused. A total of 400 images (100 non-contrast controls, 100 contrast controls,\n100 non-contrast PKD, 100 contrast PKD) were utilized for training/validation\nof models to segment kidneys, livers, and spleens, and the final models were\nthen tested on 100 non-contrast CT images of patients affected by PKD.\nPerformance was evaluated using Dice, Jaccard, TPR, and Precision.\n\nResults: Models trained on a diverse range of data showed no worse\nperformance than models trained exclusively on in-domain data when tested on\nin-domain data. For instance, the Dice similarity of the model trained on 25%\nfrom each dataset was found to be non-inferior to the model trained purely on\nin-domain data.\n\nConclusions: The results indicate that broader training examples\nsignificantly enhances model generalization and out-of-domain performance,\nthereby improving automated segmentation tools' applicability in clinical\nsettings. The study's findings provide a roadmap for future research to adopt a\ndata-centric approach in medical image AI model development.",
          "link": "http://arxiv.org/abs/2307.14482",
          "publishedOn": "2023-07-29T00:48:57.219Z",
          "wordCount": null,
          "title": "Role of Image Acquisition and Patient Phenotype Variations in Automatic Segmentation Model Generalization. (arXiv:2307.14482v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14568",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Angulo_B/0/1/0/all/0/1\">Brian Angulo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gorbov_G/0/1/0/all/0/1\">Gregory Gorbov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panov_A/0/1/0/all/0/1\">Aleksandr Panov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yakovlev_K/0/1/0/all/0/1\">Konstantin Yakovlev</a>",
          "description": "While reinforcement learning algorithms have had great success in the field\nof autonomous navigation, they cannot be straightforwardly applied to the real\nautonomous systems without considering the safety constraints. The later are\ncrucial to avoid unsafe behaviors of the autonomous vehicle on the road. To\nhighlight the importance of these constraints, in this study, we compare two\nlearnable navigation policies: safe and unsafe. The safe policy takes the\nconstraints into account, while the other does not. We show that the safe\npolicy is able to generate trajectories with more clearance (distance to the\nobstacles) and makes less collisions while training without sacrificing the\noverall performance.",
          "link": "http://arxiv.org/abs/2307.14568",
          "publishedOn": "2023-07-29T00:48:57.129Z",
          "wordCount": null,
          "title": "Evaluation of Safety Constraints in Autonomous Navigation with Deep Reinforcement Learning. (arXiv:2307.14568v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14361",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Aburass_S/0/1/0/all/0/1\">Sanad Aburass</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Dorgham_O/0/1/0/all/0/1\">Osama Dorgham</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Shaqsi_J/0/1/0/all/0/1\">Jamil Al Shaqsi</a>",
          "description": "This study presents an ensemble model combining LSTM, BiLSTM, CNN, GRU, and\nGloVe to classify gene mutations using Kaggle's Personalized Medicine:\nRedefining Cancer Treatment dataset. The results were compared against\nwell-known transformers like as BERT, Electra, Roberta, XLNet, Distilbert, and\ntheir LSTM ensembles. Our model outperformed all other models in terms of\naccuracy, precision, recall, F1 score, and Mean Squared Error. Surprisingly, it\nalso needed less training time, resulting in a perfect combination of\nperformance and efficiency. This study demonstrates the utility of ensemble\nmodels for difficult tasks such as gene mutation classification.",
          "link": "http://arxiv.org/abs/2307.14361",
          "publishedOn": "2023-07-29T00:48:57.128Z",
          "wordCount": null,
          "title": "A Hybrid Machine Learning Model for Classifying Gene Mutations in Cancer using LSTM, BiLSTM, CNN, GRU, and GloVe. (arXiv:2307.14361v1 [q-bio.QM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14619",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Block_A/0/1/0/all/0/1\">Adam Block</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfrommer_D/0/1/0/all/0/1\">Daniel Pfrommer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simchowitz_M/0/1/0/all/0/1\">Max Simchowitz</a>",
          "description": "We propose a theoretical framework for studying the imitation of stochastic,\nnon-Markovian, potentially multi-modal (i.e. \"complex\" ) expert demonstrations\nin nonlinear dynamical systems. Our framework invokes low-level controllers -\neither learned or implicit in position-command control - to stabilize imitation\npolicies around expert demonstrations. We show that with (a) a suitable\nlow-level stability guarantee and (b) a stochastic continuity property of the\nlearned policy we call \"total variation continuity\" (TVC), an imitator that\naccurately estimates actions on the demonstrator's state distribution closely\nmatches the demonstrator's distribution over entire trajectories. We then show\nthat TVC can be ensured with minimal degradation of accuracy by combining a\npopular data-augmentation regimen with a novel algorithmic trick: adding\naugmentation noise at execution time. We instantiate our guarantees for\npolicies parameterized by diffusion models and prove that if the learner\naccurately estimates the score of the (noise-augmented) expert policy, then the\ndistribution of imitator trajectories is close to the demonstrator distribution\nin a natural optimal transport distance. Our analysis constructs intricate\ncouplings between noise-augmented trajectories, a technique that may be of\nindependent interest. We conclude by empirically validating our algorithmic\nrecommendations.",
          "link": "http://arxiv.org/abs/2307.14619",
          "publishedOn": "2023-07-29T00:48:57.127Z",
          "wordCount": null,
          "title": "Imitating Complex Trajectories: Bridging Low-Level Stability and High-Level Behavior. (arXiv:2307.14619v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14403",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ciotola_M/0/1/0/all/0/1\">Matteo Ciotola</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Poggi_G/0/1/0/all/0/1\">Giovanni Poggi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Scarpa_G/0/1/0/all/0/1\">Giuseppe Scarpa</a>",
          "description": "In latest years, deep learning has gained a leading role in the pansharpening\nof multiresolution images. Given the lack of ground truth data, most deep\nlearning-based methods carry out supervised training in a reduced-resolution\ndomain. However, models trained on downsized images tend to perform poorly on\nhigh-resolution target images. For this reason, several research groups are now\nturning to unsupervised training in the full-resolution domain, through the\ndefinition of appropriate loss functions and training paradigms. In this\ncontext, we have recently proposed a full-resolution training framework which\ncan be applied to many existing architectures.\n\nHere, we propose a new deep learning-based pansharpening model that fully\nexploits the potential of this approach and provides cutting-edge performance.\nBesides architectural improvements with respect to previous work, such as the\nuse of residual attention modules, the proposed model features a novel loss\nfunction that jointly promotes the spectral and spatial quality of the\npansharpened data. In addition, thanks to a new fine-tuning strategy, it\nimproves inference-time adaptation to target images. Experiments on a large\nvariety of test images, performed in challenging scenarios, demonstrate that\nthe proposed method compares favorably with the state of the art both in terms\nof numerical results and visual output. Code is available online at\nhttps://github.com/matciotola/Lambda-PNN.",
          "link": "http://arxiv.org/abs/2307.14403",
          "publishedOn": "2023-07-29T00:48:57.115Z",
          "wordCount": null,
          "title": "Unsupervised Deep Learning-based Pansharpening with Jointly-Enhanced Spectral and Spatial Fidelity. (arXiv:2307.14403v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.12012",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guharoy_R/0/1/0/all/0/1\">Rabel Guharoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jana_N/0/1/0/all/0/1\">Nanda Dulal Jana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biswas_S/0/1/0/all/0/1\">Suparna Biswas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_L/0/1/0/all/0/1\">Lalit Garg</a>",
          "description": "An Electroencephalogram (EEG) is a non-invasive exam that records the\nelectrical activity of the brain. This exam is used to help diagnose conditions\nsuch as different brain problems. EEG signals are taken for the purpose of\nepilepsy detection and with Discrete Wavelet Transform (DWT) and machine\nlearning classifier, they perform epilepsy detection. In Epilepsy seizure\ndetection, mainly machine learning classifiers and statistical features are\nused. The hidden information in the EEG signal is useful for detecting diseases\naffecting the brain. Sometimes it is very difficult to identify the minimum\nchanges in the EEG in the time and frequency domains purpose. The DWT can give\na good decomposition of the signals in different frequency bands and feature\nextraction. We use the tri-dimensionality reduction algorithm.; Principal\nComponent Analysis (PCA), Independent Component Analysis (ICA), and Linear\nDiscriminant Analysis (LDA). Finally, features are selected by using a fusion\nrule and at the last step three different classifiers Support Vector Machine\n(SVM), Naive Bayes (NB) and K-Nearest-Neighbor(KNN) have been used individually\nfor the classification. The proposed framework is tested on the Bonn dataset\nand the simulation results provide the accuracy for the combination of LDA and\nSVM 89.17%, LDA and KNN 80.42%, PCA and NB 89.92%, PCA and SVM 85.58%, PCA and\nKNN 80.42%, ICA and NB 82.33%, ICA and SVM 90.42%, and ICA and KNN 90%, LDA and\nNB 100%, accuracy. It shows the sensitivity, specificity, accuracy, Precision,\nand Recall of 100%, 100%, 100%, 100%, and 100%. This combination of LDA with NB\nmethod provides the accuracy of 100% outperforming all existing methods. The\nresults prove the effectiveness of this model.",
          "link": "http://arxiv.org/abs/2302.12012",
          "publishedOn": "2023-07-29T00:48:57.114Z",
          "wordCount": null,
          "title": "Empirical analysis of Different Dimensionality Reduction and classification Techniques for Epileptic Seizure detection. (arXiv:2302.12012v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fontana_M/0/1/0/all/0/1\">Maxime Fontana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spratling_M/0/1/0/all/0/1\">Michael Spratling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_M/0/1/0/all/0/1\">Miaojing Shi</a>",
          "description": "Multi-Task Learning (MTL) aims to learn multiple tasks simultaneously while\nexploiting their mutual relationships. By using shared resources to\nsimultaneously calculate multiple outputs, this learning paradigm has the\npotential to have lower memory requirements and inference times compared to the\ntraditional approach of using separate methods for each task. Previous work in\nMTL has mainly focused on fully-supervised methods, as task relationships can\nnot only be leveraged to lower the level of data-dependency of those methods\nbut they can also improve performance. However, MTL introduces a set of\nchallenges due to a complex optimisation scheme and a higher labeling\nrequirement. This review focuses on how MTL could be utilised under different\npartial supervision settings to address these challenges. First, this review\nanalyses how MTL traditionally uses different parameter sharing techniques to\ntransfer knowledge in between tasks. Second, it presents the different\nchallenges arising from such a multi-objective optimisation scheme. Third, it\nintroduces how task groupings can be achieved by analysing task relationships.\nFourth, it focuses on how partially supervised methods applied to MTL can\ntackle the aforementioned challenges. Lastly, this review presents the\navailable datasets, tools and benchmarking results of such methods.",
          "link": "http://arxiv.org/abs/2307.14382",
          "publishedOn": "2023-07-29T00:48:57.074Z",
          "wordCount": null,
          "title": "When Multi-Task Learning Meets Partial Supervision: A Computer Vision Review. (arXiv:2307.14382v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.11277",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hendrickx_K/0/1/0/all/0/1\">Kilian Hendrickx</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perini_L/0/1/0/all/0/1\">Lorenzo Perini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plas_D/0/1/0/all/0/1\">Dries Van der Plas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meert_W/0/1/0/all/0/1\">Wannes Meert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1\">Jesse Davis</a>",
          "description": "Machine learning models always make a prediction, even when it is likely to\nbe inaccurate. This behavior should be avoided in many decision support\napplications, where mistakes can have severe consequences. Albeit already\nstudied in 1970, machine learning with rejection recently gained interest. This\nmachine learning subfield enables machine learning models to abstain from\nmaking a prediction when likely to make a mistake.\n\nThis survey aims to provide an overview on machine learning with rejection.\nWe introduce the conditions leading to two types of rejection, ambiguity and\nnovelty rejection, which we carefully formalize. Moreover, we review and\ncategorize strategies to evaluate a model's predictive and rejective quality.\nAdditionally, we define the existing architectures for models with rejection\nand describe the standard techniques for learning such models. Finally, we\nprovide examples of relevant application domains and show how machine learning\nwith rejection relates to other machine learning research areas.",
          "link": "http://arxiv.org/abs/2107.11277",
          "publishedOn": "2023-07-29T00:48:57.024Z",
          "wordCount": null,
          "title": "Machine Learning with a Reject Option: A survey. (arXiv:2107.11277v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kortvelesy_R/0/1/0/all/0/1\">Ryan Kortvelesy</a>",
          "description": "It is often useful to perform integration over learned functions represented\nby neural networks. However, this integration is usually performed numerically,\nas analytical integration over learned functions (especially neural networks)\nis generally viewed as intractable. In this work, we present a method for\nrepresenting the analytical integral of a learned function $f$. This allows the\nexact integral of a neural network to be computed, and enables constrained\nneural networks to be parametrised by applying constraints directly to the\nintegral. Crucially, we also introduce a method to constrain $f$ to be\npositive, a necessary condition for many applications (e.g. probability\ndistributions, distance metrics, etc). Finally, we introduce several\napplications where our fixed-integral neural network (FINN) can be utilised.",
          "link": "http://arxiv.org/abs/2307.14439",
          "publishedOn": "2023-07-29T00:48:57.023Z",
          "wordCount": null,
          "title": "Fixed Integral Neural Networks. (arXiv:2307.14439v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14389",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kim_S/0/1/0/all/0/1\">Soowon Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_Y/0/1/0/all/0/1\">Young-Eun Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1\">Seo-Hyun Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1\">Seong-Whan Lee</a>",
          "description": "Decoding EEG signals for imagined speech is a challenging task due to the\nhigh-dimensional nature of the data and low signal-to-noise ratio. In recent\nyears, denoising diffusion probabilistic models (DDPMs) have emerged as\npromising approaches for representation learning in various domains. Our study\nproposes a novel method for decoding EEG signals for imagined speech using\nDDPMs and a conditional autoencoder named Diff-E. Results indicate that Diff-E\nsignificantly improves the accuracy of decoding EEG signals for imagined speech\ncompared to traditional machine learning techniques and baseline models. Our\nfindings suggest that DDPMs can be an effective tool for EEG signal decoding,\nwith potential implications for the development of brain-computer interfaces\nthat enable communication through imagined speech.",
          "link": "http://arxiv.org/abs/2307.14389",
          "publishedOn": "2023-07-29T00:48:56.008Z",
          "wordCount": 641,
          "title": "Diff-E: Diffusion-based Learning for Decoding Imagined Speech EEG. (arXiv:2307.14389v1 [eess.AS])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14394",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yifan Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiashu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_S/0/1/0/all/0/1\">Shihui Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yue Gao</a>",
          "description": "The isomorphism problem is a fundamental problem in network analysis, which\ninvolves capturing both low-order and high-order structural information. In\nterms of extracting low-order structural information, graph isomorphism\nalgorithms analyze the structural equivalence to reduce the solver space\ndimension, which demonstrates its power in many applications, such as protein\ndesign, chemical pathways, and community detection. For the more commonly\noccurring high-order relationships in real-life scenarios, the problem of\nhypergraph isomorphism, which effectively captures these high-order structural\nrelationships, cannot be straightforwardly addressed using graph isomorphism\nmethods. Besides, the existing hypergraph kernel methods may suffer from high\nmemory consumption or inaccurate sub-structure identification, thus yielding\nsub-optimal performance. In this paper, to address the abovementioned problems,\nwe first propose the hypergraph Weisfiler-Lehman test algorithm for the\nhypergraph isomorphism test problem by generalizing the Weisfiler-Lehman test\nalgorithm from graphs to hypergraphs. Secondly, based on the presented\nalgorithm, we propose a general hypergraph Weisfieler-Lehman kernel framework\nand implement two instances, which are Hypergraph Weisfeiler-Lehamn Subtree\nKernel and Hypergraph Weisfeiler-Lehamn Hyperedge Kernel. In order to fulfill\nour research objectives, a comprehensive set of experiments was meticulously\ndesigned, including seven graph classification datasets and 12 hypergraph\nclassification datasets. Results on hypergraph classification datasets show\nsignificant improvements compared to other typical kernel-based methods, which\ndemonstrates the effectiveness of the proposed methods. In our evaluation, we\nfound that our proposed methods outperform the second-best method in terms of\nruntime, running over 80 times faster when handling complex hypergraph\nstructures.",
          "link": "http://arxiv.org/abs/2307.14394",
          "publishedOn": "2023-07-29T00:48:55.960Z",
          "wordCount": 720,
          "title": "Hypergraph Isomorphism Computation. (arXiv:2307.14394v1 [cs.DS])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14346",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_N/0/1/0/all/0/1\">Ning Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Junrui Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Meng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1\">Ming Tang</a>",
          "description": "Mobile edge computing (MEC) is essential for next-generation mobile network\napplications that prioritize various performance metrics, including delays and\nenergy consumption. However, conventional single-objective scheduling solutions\ncannot be directly applied to practical systems in which the preferences of\nthese applications (i.e., the weights of different objectives) are often\nunknown or challenging to specify in advance. In this study, we address this\nissue by formulating a multi-objective offloading problem for MEC with multiple\nedges to minimize expected long-term energy consumption and transmission delay\nwhile considering unknown preferences as parameters. To address the challenge\nof unknown preferences, we design a multi-objective (deep) reinforcement\nlearning (MORL)-based resource scheduling scheme with proximal policy\noptimization (PPO). In addition, we introduce a well-designed state encoding\nmethod for constructing features for multiple edges in MEC systems, a\nsophisticated reward function for accurately computing the utilities of delay\nand energy consumption. Simulation results demonstrate that our proposed MORL\nscheme enhances the hypervolume of the Pareto front by up to 233.1% compared to\nbenchmarks. Our full framework is available at\nhttps://github.com/gracefulning/mec_morl_multipolicy.",
          "link": "http://arxiv.org/abs/2307.14346",
          "publishedOn": "2023-07-29T00:48:55.953Z",
          "wordCount": 680,
          "title": "Multi-objective Deep Reinforcement Learning for Mobile Edge Computing. (arXiv:2307.14346v1 [cs.NI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14359",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Wong_B/0/1/0/all/0/1\">Benny Wong</a>",
          "description": "Optimization methods are essential in solving complex problems across various\ndomains. In this research paper, we introduce a novel optimization method\ncalled Gaussian Crunching Search (GCS). Inspired by the behaviour of particles\nin a Gaussian distribution, GCS aims to efficiently explore the solution space\nand converge towards the global optimum. We present a comprehensive analysis of\nGCS, including its working mechanism, and potential applications. Through\nexperimental evaluations and comparisons with existing optimization methods, we\nhighlight the advantages and strengths of GCS. This research paper serves as a\nvaluable resource for researchers, practitioners, and students interested in\noptimization, providing insights into the development and potential of Gaussian\nCrunching Search as a new and promising approach.",
          "link": "http://arxiv.org/abs/2307.14359",
          "publishedOn": "2023-07-29T00:48:55.946Z",
          "wordCount": 596,
          "title": "A new derivative-free optimization method: Gaussian Crunching Search. (arXiv:2307.14359v1 [math.OC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10805",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oh_Y/0/1/0/all/0/1\">Yongjeong Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jaeho Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brinton_C/0/1/0/all/0/1\">Christopher G. Brinton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeon_Y/0/1/0/all/0/1\">Yo-Seb Jeon</a>",
          "description": "This paper proposes a novel communication-efficient split learning (SL)\nframework, named SplitFC, which reduces the communication overhead required for\ntransmitting intermediate feature and gradient vectors during the SL training\nprocess. The key idea of SplitFC is to leverage different dispersion degrees\nexhibited in the columns of the matrices. SplitFC incorporates two compression\nstrategies: (i) adaptive feature-wise dropout and (ii) adaptive feature-wise\nquantization. In the first strategy, the intermediate feature vectors are\ndropped with adaptive dropout probabilities determined based on the standard\ndeviation of these vectors. Then, by the chain rule, the intermediate gradient\nvectors associated with the dropped feature vectors are also dropped. In the\nsecond strategy, the non-dropped intermediate feature and gradient vectors are\nquantized using adaptive quantization levels determined based on the ranges of\nthe vectors. To minimize the quantization error, the optimal quantization\nlevels of this strategy are derived in a closed-form expression. Simulation\nresults on the MNIST, CIFAR-10, and CelebA datasets demonstrate that SplitFC\nprovides more than a 5.6% increase in classification accuracy compared to\nstate-of-the-art SL frameworks, while they require 320 times less communication\noverhead compared to the vanilla SL framework without compression.",
          "link": "http://arxiv.org/abs/2307.10805",
          "publishedOn": "2023-07-22T00:55:26.985Z",
          "wordCount": 697,
          "title": "Communication-Efficient Split Learning via Adaptive Feature-Wise Compression. (arXiv:2307.10805v1 [cs.DC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.08292",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Almin_A/0/1/0/all/0/1\">Alexandre Almin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lemarie_L/0/1/0/all/0/1\">L&#xe9;o Lemari&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duong_A/0/1/0/all/0/1\">Anh Duong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiran_B/0/1/0/all/0/1\">B Ravi Kiran</a>",
          "description": "Autonomous driving (AD) perception today relies heavily on deep learning\nbased architectures requiring large scale annotated datasets with their\nassociated costs for curation and annotation. The 3D semantic data are useful\nfor core perception tasks such as obstacle detection and ego-vehicle\nlocalization. We propose a new dataset, Navya 3D Segmentation (Navya3DSeg),\nwith a diverse label space corresponding to a large scale production grade\noperational domain, including rural, urban, industrial sites and universities\nfrom 13 countries. It contains 23 labeled sequences and 25 supplementary\nsequences without labels, designed to explore self-supervised and\nsemi-supervised semantic segmentation benchmarks on point clouds. We also\npropose a novel method for sequential dataset split generation based on\niterative multi-label stratification, and demonstrated to achieve a +1.2% mIoU\nimprovement over the original split proposed by SemanticKITTI dataset. A\ncomplete benchmark for semantic segmentation task was performed, with state of\nthe art methods. Finally, we demonstrate an Active Learning (AL) based dataset\ndistillation framework. We introduce a novel heuristic-free sampling method\ncalled ego-pose distance based sampling in the context of AL. A detailed\npresentation on the dataset is available here\nhttps://www.youtube.com/watch?v=5m6ALIs-s20.",
          "link": "http://arxiv.org/abs/2302.08292",
          "publishedOn": "2023-07-22T00:55:26.977Z",
          "wordCount": 749,
          "title": "Navya3DSeg -- Navya 3D Semantic Segmentation Dataset & split generation for autonomous vehicles. (arXiv:2302.08292v3 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2208.06501",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1\">Zifeng Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zongyue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_R/0/1/0/all/0/1\">Ruoxia Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jingpei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1\">Bailan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yunpu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1\">Zhao Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_R/0/1/0/all/0/1\">Ruotong Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1\">Zhen Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tresp_V/0/1/0/all/0/1\">Volker Tresp</a>",
          "description": "Question answering over temporal knowledge graphs (TKGQA) has recently found\nincreasing interest. TKGQA requires temporal reasoning techniques to extract\nthe relevant information from temporal knowledge bases. The only existing TKGQA\ndataset, i.e., CronQuestions, consists of temporal questions based on the facts\nfrom a fixed time period, where a temporal knowledge graph (TKG) spanning the\nsame period can be fully used for answer inference, allowing the TKGQA models\nto use even the future knowledge to answer the questions based on the past\nfacts. In real-world scenarios, however, it is also common that given the\nknowledge until now, we wish the TKGQA systems to answer the questions asking\nabout the future. As humans constantly seek plans for the future, building\nTKGQA systems for answering such forecasting questions is important.\nNevertheless, this has still been unexplored in previous research. In this\npaper, we propose a novel task: forecasting question answering over temporal\nknowledge graphs. We also propose a large-scale TKGQA benchmark dataset, i.e.,\nForecastTKGQuestions, for this task. It includes three types of questions,\ni.e., entity prediction, yes-no, and fact reasoning questions. For every\nforecasting question in our dataset, QA models can only have access to the TKG\ninformation before the timestamp annotated in the given question for answer\ninference. We find that the state-of-the-art TKGQA methods perform poorly on\nforecasting questions, and they are unable to answer yes-no questions and fact\nreasoning questions. To this end, we propose ForecastTKGQA, a TKGQA model that\nemploys a TKG forecasting module for future inference, to answer all three\ntypes of questions. Experimental results show that ForecastTKGQA outperforms\nrecent TKGQA methods on the entity prediction questions, and it also shows\ngreat effectiveness in answering the other two types of questions.",
          "link": "http://arxiv.org/abs/2208.06501",
          "publishedOn": "2023-07-22T00:55:26.900Z",
          "wordCount": 846,
          "title": "ForecastTKGQuestions: A Benchmark for Temporal Question Answering and Forecasting over Temporal Knowledge Graphs. (arXiv:2208.06501v2 [cs.AI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2110.05216",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koniusz_P/0/1/0/all/0/1\">Piotr Koniusz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1\">Ke Sun</a>",
          "description": "We aim at capturing high-order statistics of feature vectors formed by a\nneural network, and propose end-to-end second- and higher-order pooling to form\na tensor descriptor. Tensor descriptors require a robust similarity measure due\nto low numbers of aggregated vectors and the burstiness phenomenon, when a\ngiven feature appears more/less frequently than statistically expected. The\nHeat Diffusion Process (HDP) on a graph Laplacian is closely related to the\nEigenvalue Power Normalization (EPN) of the covariance/auto-correlation matrix,\nwhose inverse forms a loopy graph Laplacian. We show that the HDP and the EPN\nplay the same role, i.e., to boost or dampen the magnitude of the eigenspectrum\nthus preventing the burstiness. We equip higher-order tensors with EPN which\nacts as a spectral detector of higher-order occurrences to prevent burstiness.\nWe also prove that for a tensor of order r built from d dimensional feature\ndescriptors, such a detector gives the likelihood if at least one higher-order\noccurrence is 'projected' into one of binom(d,r) subspaces represented by the\ntensor; thus forming a tensor power normalization metric endowed with\nbinom(d,r) such 'detectors'. For experimental contributions, we apply several\nsecond- and higher-order pooling variants to action recognition, provide\npreviously not presented comparisons of such pooling variants, and show\nstate-of-the-art results on HMDB-51, YUP++ and MPII Cooking Activities.",
          "link": "http://arxiv.org/abs/2110.05216",
          "publishedOn": "2023-07-22T00:55:26.861Z",
          "wordCount": 750,
          "title": "High-order Tensor Pooling with Attention for Action Recognition. (arXiv:2110.05216v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.14319",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Harkonen_M/0/1/0/all/0/1\">Marc H&#xe4;rk&#xf6;nen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lange_Hegermann_M/0/1/0/all/0/1\">Markus Lange-Hegermann</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Raita_B/0/1/0/all/0/1\">Bogdan Rai&#x163;&#x103;</a>",
          "description": "Partial differential equations (PDEs) are important tools to model physical\nsystems and including them into machine learning models is an important way of\nincorporating physical knowledge. Given any system of linear PDEs with constant\ncoefficients, we propose a family of Gaussian process (GP) priors, which we\ncall EPGP, such that all realizations are exact solutions of this system. We\napply the Ehrenpreis-Palamodov fundamental principle, which works as a\nnon-linear Fourier transform, to construct GP kernels mirroring standard\nspectral methods for GPs. Our approach can infer probable solutions of linear\nPDE systems from any data such as noisy measurements, or pointwise defined\ninitial and boundary conditions. Constructing EPGP-priors is algorithmic,\ngenerally applicable, and comes with a sparse version (S-EPGP) that learns the\nrelevant spectral frequencies and works better for big data sets. We\ndemonstrate our approach on three families of systems of PDEs, the heat\nequation, wave equation, and Maxwell's equations, where we improve upon the\nstate of the art in computation time and precision, in some experiments by\nseveral orders of magnitude.",
          "link": "http://arxiv.org/abs/2212.14319",
          "publishedOn": "2023-07-22T00:55:26.834Z",
          "wordCount": 896,
          "title": "Gaussian Process Priors for Systems of Linear Partial Differential Equations with Constant Coefficients. (arXiv:2212.14319v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.09614",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Brusch_T/0/1/0/all/0/1\">Thea Br&#xfc;sch</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schmidt_M/0/1/0/all/0/1\">Mikkel N. Schmidt</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Alstrom_T/0/1/0/all/0/1\">Tommy S. Alstr&#xf8;m</a>",
          "description": "Labeling of multivariate biomedical time series data is a laborious and\nexpensive process. Self-supervised contrastive learning alleviates the need for\nlarge, labeled datasets through pretraining on unlabeled data. However, for\nmultivariate time series data, the set of input channels often varies between\napplications, and most existing work does not allow for transfer between\ndatasets with different sets of input channels. We propose learning one encoder\nto operate on all input channels individually. We then use a message passing\nneural network to extract a single representation across channels. We\ndemonstrate the potential of this method by pretraining our model on a dataset\nwith six EEG channels and then fine-tuning it on a dataset with two different\nEEG channels. We compare models with and without the message passing neural\nnetwork across different contrastive loss functions. We show that our method,\ncombined with the TS2Vec loss, outperforms all other methods in most settings.",
          "link": "http://arxiv.org/abs/2307.09614",
          "publishedOn": "2023-07-22T00:55:26.794Z",
          "wordCount": 689,
          "title": "Multi-view self-supervised learning for multivariate variable-channel time series. (arXiv:2307.09614v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.08396",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Khan_A/0/1/0/all/0/1\">Abdul Rehman Khan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Khan_A/0/1/0/all/0/1\">Asifullah Khan</a>",
          "description": "Convolutional Neural Networks (CNNs) have made significant strides in medical\nimage analysis in recent years. However, the local nature of the convolution\noperator may pose a limitation for capturing global and long-range interactions\nin CNNs. Recently, Transformers have gained popularity in the computer vision\ncommunity and also medical image segmentation due to their ability to process\nglobal features effectively. The scalability issues of self-attention mechanism\nand lack of the CNN-like inductive bias may have limited their adoption.\nTherefore, hybrid Vision transformers (CNN-Transformer), exploiting advantages\nof both Convolution and Self-attention Mechanisms, have gained importance. In\nthis work, we present MaxViT-UNet, an Encoder-Decoder based hybrid vision\ntransformer (CNN-Transformer) for medical image segmentation. The proposed\nHybrid Decoder, based on MaxViT-block, is designed to harness the power of both\nthe convolution and self-attention mechanisms at each decoding stage with\nnominal computational burden. The inclusion of multi-axis self-attention,\nwithin each decoder stage, significantly enhances the discriminating capacity\nbetween the object and background regions, and thereby helps in improving the\nsegmentation efficiency. In the Hybrid Decoder block, the fusion process\ncommences by integrating the upsampled lower level decoder features, obtained\nthrough transpose convolution, with the skip-connection features derived from\nthe hybrid encoder. Subsequently, the fused features undergo refinement through\nthe utilization of a multi-axis attention mechanism. The proposed decoder block\nis repeated multiple times to progressively segment the nuclei regions.\nExperimental results on MoNuSeg18 and MoNuSAC20 dataset demonstrates the\neffectiveness of the proposed technique.",
          "link": "http://arxiv.org/abs/2305.08396",
          "publishedOn": "2023-07-22T00:55:26.765Z",
          "wordCount": 776,
          "title": "MaxViT-UNet: Multi-Axis Attention for Medical Image Segmentation. (arXiv:2305.08396v3 [eess.IV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2003.01052",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Chebotarev_P/0/1/0/all/0/1\">Pavel Chebotarev</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gubanov_D/0/1/0/all/0/1\">Dmitry Gubanov</a>",
          "description": "Centrality metrics are vital for network analysis, but selecting the most\nappropriate measures for specific applications remains challenging among the\n400+ proposed indices. Existing approaches -- model-based, data-driven, and\naxiomatic -- have limitations. To address this, we introduce the culling\nmethod, leveraging expert preferences regarding centrality behavior on simple\ngraphs. It involves forming a set of candidate measures, generating a list of\nas small graphs as possible needed to ``separate'' measures from each other,\nconstructing a decision-tree survey, and identifying the measure consistent\nwith expert responses. We apply this method to a diverse set of 40\ncentralities, including new kernel-based measures, and combine it with the\naxiomatic approach. Remarkably, only 13 small 1-trees suffice to separate all\n40 measures, among which there are pairs of close ones. The culling method\noffers a low-cost solution in terms of labor and time, complements existing\nmethods for measure selection, and reveals important peculiarities of\ncentrality measures.",
          "link": "http://arxiv.org/abs/2003.01052",
          "publishedOn": "2023-07-22T00:55:26.756Z",
          "wordCount": 743,
          "title": "How to choose the most appropriate centrality measure? A decision tree approach. (arXiv:2003.01052v5 [physics.soc-ph] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.18088",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Aqeel_I/0/1/0/all/0/1\">Imra Aqeel</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Majid_A/0/1/0/all/0/1\">Abdul Majid</a>",
          "description": "The COVID-19 pandemic has created a global health crisis, driving the need\nfor the rapid identification of potential therapeutics. To meet this challenge,\ndrug repurposing is the only solution with saving cost, time, and labor. In\nthis study, we used the Zinc database to screen the world-approved including\nFDA-approved 5903 drugs for repurposing as potential COVID-19 treatments\ntargeting the main protease 3CL of SARS-CoV-2. We performed molecular docking\nand checked the efficacy of drug molecules. To enhance the efficiency of drug\nrepurposing approach, we modeled the binding affinities using several machine\nlearning regression approaches for QSAR modeling such as decision tree, extra\ntrees, MLP, KNN, XGBoost, and gradient boosting. The computational results\ndemonstrated that Decision Tree Regression (DTR) model has improved statistical\nmeasures of R2 and RMSE. These simulated results helped to identify drugs with\nhigh binding affinity. From the docking and other statistical analysis, we\nshortlisted six promising drugs with their respective Zinc IDs (ZINC3873365,\nZINC85432544, ZINC203757351, ZINC85536956, ZINC8214470 and ZINC261494640)\nwithin the range of -15 kcal/mol to -13 kcal/mol. In the study, the repurposed\ndrugs are novel except ZINC203757351 antiviral compound that has already\nidentified against COVID-19 in other studies. Further, we analyzed the\nphysiochemical and pharmacokinetic properties of these top-ranked selected\ndrugs with respect to their best binding interaction for specific target\nprotease 3CLpro. Our study has provided an efficient framework for drug\nrepurposing against COVID-19. This highlights the potential of combining\nmolecular docking with machine learning regression approaches to accelerate the\nidentification of potential therapeutic candidates.",
          "link": "http://arxiv.org/abs/2305.18088",
          "publishedOn": "2023-07-22T00:55:26.749Z",
          "wordCount": 852,
          "title": "Drug Repurposing Targeting COVID-19 3CL Protease using Molecular Docking and Machine Learning Regression Approach. (arXiv:2305.18088v4 [q-bio.BM] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.11112",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tolbert_A/0/1/0/all/0/1\">Alexander Williams Tolbert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diana_E/0/1/0/all/0/1\">Emily Diana</a>",
          "description": "We consider the problem of learning from data corrupted by\nunderrepresentation bias, where positive examples are filtered from the data at\ndifferent, unknown rates for a fixed number of sensitive groups. We show that\nwith a small amount of unbiased data, we can efficiently estimate the\ngroup-wise drop-out parameters, even in settings where intersectional group\nmembership makes learning each intersectional rate computationally infeasible.\nUsing this estimate for the group-wise drop-out rate, we construct a\nre-weighting scheme that allows us to approximate the loss of any hypothesis on\nthe true distribution, even if we only observe the empirical error on a biased\nsample. Finally, we present an algorithm encapsulating this learning and\nre-weighting process, and we provide strong PAC-style guarantees that, with\nhigh probability, our estimate of the risk of the hypothesis over the true\ndistribution will be arbitrarily close to the true risk.",
          "link": "http://arxiv.org/abs/2306.11112",
          "publishedOn": "2023-07-22T00:55:26.738Z",
          "wordCount": 680,
          "title": "Correcting Underrepresentation and Intersectional Bias for Fair Classification. (arXiv:2306.11112v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10779",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_J/0/1/0/all/0/1\">Jishnu Ray Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caragea_C/0/1/0/all/0/1\">Cornelia Caragea</a>",
          "description": "Beam Tree Recursive Neural Network (BT-RvNN) was recently proposed as a\nsimple extension of Gumbel Tree RvNN and it was shown to achieve\nstate-of-the-art length generalization performance in ListOps while maintaining\ncomparable performance on other tasks. However, although not the worst in its\nkind, BT-RvNN can be still exorbitantly expensive in memory usage. In this\npaper, we identify the main bottleneck in BT-RvNN's memory usage to be the\nentanglement of the scorer function and the recursive cell function. We propose\nstrategies to remove this bottleneck and further simplify its memory usage.\nOverall, our strategies not only reduce the memory usage of BT-RvNN by\n$10$-$16$ times but also create a new state-of-the-art in ListOps while\nmaintaining similar performance in other tasks. In addition, we also propose a\nstrategy to utilize the induced latent-tree node representations produced by\nBT-RvNN to turn BT-RvNN from a sentence encoder of the form $f:\\mathbb{R}^{n\n\\times d} \\rightarrow \\mathbb{R}^{d}$ into a sequence contextualizer of the\nform $f:\\mathbb{R}^{n \\times d} \\rightarrow \\mathbb{R}^{n \\times d}$. Thus, our\nproposals not only open up a path for further scalability of RvNNs but also\nstandardize a way to use BT-RvNNs as another building block in the deep\nlearning toolkit that can be easily stacked or interfaced with other popular\nmodels such as Transformers and Structured State Space models.",
          "link": "http://arxiv.org/abs/2307.10779",
          "publishedOn": "2023-07-22T00:55:26.703Z",
          "wordCount": 704,
          "title": "Efficient Beam Tree Recursion. (arXiv:2307.10779v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.00143",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Podkopaev_A/0/1/0/all/0/1\">Aleksandr Podkopaev</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>",
          "description": "We study the problems of sequential nonparametric two-sample and independence\ntesting. Sequential tests process data online and allow using observed data to\ndecide whether to stop and reject the null hypothesis or to collect more data,\nwhile maintaining type I error control. We build upon the principle of\n(nonparametric) testing by betting, where a gambler places bets on future\nobservations and their wealth measures evidence against the null hypothesis.\nWhile recently developed kernel-based betting strategies often work well on\nsimple distributions, selecting a suitable kernel for high-dimensional or\nstructured data, such as images, is often nontrivial. To address this drawback,\nwe design prediction-based betting strategies that rely on the following fact:\nif a sequentially updated predictor starts to consistently determine (a) which\ndistribution an instance is drawn from, or (b) whether an instance is drawn\nfrom the joint distribution or the product of the marginal distributions (the\nlatter produced by external randomization), it provides evidence against the\ntwo-sample or independence nulls respectively. We empirically demonstrate the\nsuperiority of our tests over kernel-based approaches under structured\nsettings. Our tests can be applied beyond the case of independent and\nidentically distributed data, remaining valid and powerful even when the data\ndistribution drifts over time.",
          "link": "http://arxiv.org/abs/2305.00143",
          "publishedOn": "2023-07-22T00:55:26.697Z",
          "wordCount": 718,
          "title": "Sequential Predictive Two-Sample and Independence Testing. (arXiv:2305.00143v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sebag_I/0/1/0/all/0/1\">Ilana Sebag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1\">Samuel Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deisenroth_M/0/1/0/all/0/1\">Marc Peter Deisenroth</a>",
          "description": "Imitation learning (IL) seeks to teach agents specific tasks through expert\ndemonstrations. One of the key approaches to IL is to define a distance between\nagent and expert and to find an agent policy that minimizes that distance.\nOptimal transport methods have been widely used in imitation learning as they\nprovide ways to measure meaningful distances between agent and expert\ntrajectories. However, the problem of how to optimally combine multiple expert\ndemonstrations has not been widely studied. The standard method is to simply\nconcatenate state (-action) trajectories, which is problematic when\ntrajectories are multi-modal. We propose an alternative method that uses a\nmulti-marginal optimal transport distance and enables the combination of\nmultiple and diverse state-trajectories in the OT sense, providing a more\nsensible geometric average of the demonstrations. Our approach enables an agent\nto learn from several experts, and its efficiency is analyzed on OpenAI Gym\ncontrol environments and demonstrates that the standard method is not always\noptimal.",
          "link": "http://arxiv.org/abs/2307.10810",
          "publishedOn": "2023-07-22T00:55:26.690Z",
          "wordCount": 684,
          "title": "On Combining Expert Demonstrations in Imitation Learning via Optimal Transport. (arXiv:2307.10810v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.09767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiong_P/0/1/0/all/0/1\">Peiyu Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tegegn_M/0/1/0/all/0/1\">Michael Tegegn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarin_J/0/1/0/all/0/1\">Jaskeerat Singh Sarin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_S/0/1/0/all/0/1\">Shubhraneel Pal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_J/0/1/0/all/0/1\">Julia Rubin</a>",
          "description": "Adversarial examples are inputs to machine learning models that an attacker\nhas intentionally designed to confuse the model into making a mistake. Such\nexamples pose a serious threat to the applicability of machine-learning-based\nsystems, especially in life- and safety-critical domains. To address this\nproblem, the area of adversarial robustness investigates mechanisms behind\nadversarial attacks and defenses against these attacks. This survey reviews a\nparticular subset of this literature that focuses on investigating properties\nof training data in the context of model robustness under evasion attacks. It\nfirst summarizes the main properties of data leading to adversarial\nvulnerability. It then discusses guidelines and techniques for improving\nadversarial robustness by enhancing the data representation and learning\nprocedures, as well as techniques for estimating robustness guarantees given\nparticular data. Finally, it discusses gaps of knowledge and promising future\nresearch directions in this area.",
          "link": "http://arxiv.org/abs/2303.09767",
          "publishedOn": "2023-07-22T00:55:26.663Z",
          "wordCount": 705,
          "title": "It Is All About Data: A Survey on the Effects of Data on Adversarial Robustness. (arXiv:2303.09767v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10891",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chau_C/0/1/0/all/0/1\">Calvin Chau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kretinsky_J/0/1/0/all/0/1\">Jan K&#x159;et&#xed;nsk&#xfd;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohr_S/0/1/0/all/0/1\">Stefanie Mohr</a>",
          "description": "Abstraction is a key verification technique to improve scalability. However,\nits use for neural networks is so far extremely limited. Previous approaches\nfor abstracting classification networks replace several neurons with one of\nthem that is similar enough. We can classify the similarity as defined either\nsyntactically (using quantities on the connections between neurons) or\nsemantically (on the activation values of neurons for various inputs).\nUnfortunately, the previous approaches only achieve moderate reductions, when\nimplemented at all. In this work, we provide a more flexible framework where a\nneuron can be replaced with a linear combination of other neurons, improving\nthe reduction. We apply this approach both on syntactic and semantic\nabstractions, and implement and evaluate them experimentally. Further, we\nintroduce a refinement method for our abstractions, allowing for finding a\nbetter balance between reduction and precision.",
          "link": "http://arxiv.org/abs/2307.10891",
          "publishedOn": "2023-07-22T00:55:26.635Z",
          "wordCount": 656,
          "title": "Syntactic vs Semantic Linear Abstraction and Refinement of Neural Networks. (arXiv:2307.10891v1 [cs.LO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2206.08309",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chadebec_C/0/1/0/all/0/1\">Cl&#xe9;ment Chadebec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vincent_L/0/1/0/all/0/1\">Louis J. Vincent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allassonniere_S/0/1/0/all/0/1\">St&#xe9;phanie Allassonni&#xe8;re</a>",
          "description": "In recent years, deep generative models have attracted increasing interest\ndue to their capacity to model complex distributions. Among those models,\nvariational autoencoders have gained popularity as they have proven both to be\ncomputationally efficient and yield impressive results in multiple fields.\nFollowing this breakthrough, extensive research has been done in order to\nimprove the original publication, resulting in a variety of different VAE\nmodels in response to different tasks. In this paper we present Pythae, a\nversatile open-source Python library providing both a unified implementation\nand a dedicated framework allowing straightforward, reproducible and reliable\nuse of generative autoencoder models. We then propose to use this library to\nperform a case study benchmark where we present and compare 19 generative\nautoencoder models representative of some of the main improvements on\ndownstream tasks such as image reconstruction, generation, classification,\nclustering and interpolation. The open-source library can be found at\nhttps://github.com/clementchadebec/benchmark_VAE.",
          "link": "http://arxiv.org/abs/2206.08309",
          "publishedOn": "2023-07-22T00:55:26.626Z",
          "wordCount": 701,
          "title": "Pythae: Unifying Generative Autoencoders in Python -- A Benchmarking Use Case. (arXiv:2206.08309v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2208.09418",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xingyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_G/0/1/0/all/0/1\">Gaojie Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiaowei Huang</a>",
          "description": "Interpretability of Deep Learning (DL) is a barrier to trustworthy AI.\nDespite great efforts made by the Explainable AI (XAI) community, explanations\nlack robustness -- indistinguishable input perturbations may lead to different\nXAI results. Thus, it is vital to assess how robust DL interpretability is,\ngiven an XAI method. In this paper, we identify several challenges that the\nstate-of-the-art is unable to cope with collectively: i) existing metrics are\nnot comprehensive; ii) XAI techniques are highly heterogeneous; iii)\nmisinterpretations are normally rare events. To tackle these challenges, we\nintroduce two black-box evaluation methods, concerning the worst-case\ninterpretation discrepancy and a probabilistic notion of how robust in general,\nrespectively. Genetic Algorithm (GA) with bespoke fitness function is used to\nsolve constrained optimisation for efficient worst-case evaluation. Subset\nSimulation (SS), dedicated to estimate rare event probabilities, is used for\nevaluating overall robustness. Experiments show that the accuracy, sensitivity,\nand efficiency of our methods outperform the state-of-the-arts. Finally, we\ndemonstrate two applications of our methods: ranking robust XAI methods and\nselecting training schemes to improve both classification and interpretation\nrobustness.",
          "link": "http://arxiv.org/abs/2208.09418",
          "publishedOn": "2023-07-22T00:55:26.618Z",
          "wordCount": 728,
          "title": "SAFARI: Versatile and Efficient Evaluations for Robustness of Interpretability. (arXiv:2208.09418v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.06223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koyuncu_B/0/1/0/all/0/1\">Batuhan Koyuncu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_Martin_P/0/1/0/all/0/1\">Pablo Sanchez-Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peis_I/0/1/0/all/0/1\">Ignacio Peis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olmos_P/0/1/0/all/0/1\">Pablo M. Olmos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valera_I/0/1/0/all/0/1\">Isabel Valera</a>",
          "description": "Recent approaches build on implicit neural representations (INRs) to propose\ngenerative models over function spaces. However, they are computationally\ncostly when dealing with inference tasks, such as missing data imputation, or\ndirectly cannot tackle them. In this work, we propose a novel deep generative\nmodel, named VAMoH. VAMoH combines the capabilities of modeling continuous\nfunctions using INRs and the inference capabilities of Variational Autoencoders\n(VAEs). In addition, VAMoH relies on a normalizing flow to define the prior,\nand a mixture of hypernetworks to parametrize the data log-likelihood. This\ngives VAMoH a high expressive capability and interpretability. Through\nexperiments on a diverse range of data types, such as images, voxels, and\nclimate data, we show that VAMoH can effectively learn rich distributions over\ncontinuous functions. Furthermore, it can perform inference-related tasks, such\nas conditional super-resolution generation and in-painting, as well or better\nthan previous approaches, while being less computationally demanding.",
          "link": "http://arxiv.org/abs/2302.06223",
          "publishedOn": "2023-07-22T00:55:26.610Z",
          "wordCount": 696,
          "title": "Variational Mixture of HyperGenerators for Learning Distributions Over Functions. (arXiv:2302.06223v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07666",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guanlin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhihan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Han Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_L/0/1/0/all/0/1\">Lifeng Lai</a>",
          "description": "Robust reinforcement learning (RL) aims to find a policy that optimizes the\nworst-case performance in the face of uncertainties. In this paper, we focus on\naction robust RL with the probabilistic policy execution uncertainty, in which,\ninstead of always carrying out the action specified by the policy, the agent\nwill take the action specified by the policy with probability $1-\\rho$ and an\nalternative adversarial action with probability $\\rho$. We establish the\nexistence of an optimal policy on the action robust MDPs with probabilistic\npolicy execution uncertainty and provide the action robust Bellman optimality\nequation for its solution. Furthermore, we develop Action Robust Reinforcement\nLearning with Certificates (ARRLC) algorithm that achieves minimax optimal\nregret and sample complexity. Furthermore, we conduct numerical experiments to\nvalidate our approach's robustness, demonstrating that ARRLC outperforms\nnon-robust RL algorithms and converges faster than the robust TD algorithm in\nthe presence of action perturbations.",
          "link": "http://arxiv.org/abs/2307.07666",
          "publishedOn": "2023-07-22T00:55:26.586Z",
          "wordCount": 687,
          "title": "Efficient Action Robust Reinforcement Learning with Probabilistic Policy Execution Uncertainty. (arXiv:2307.07666v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10803",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hanchen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wengen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_J/0/1/0/all/0/1\">Jihong Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Shuigeng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jiannong Cao</a>",
          "description": "With the increasing amount of spatial-temporal~(ST) ocean data, numerous\nspatial-temporal data mining (STDM) studies have been conducted to address\nvarious oceanic issues, e.g., climate forecasting and disaster warning.\nCompared with typical ST data (e.g., traffic data), ST ocean data is more\ncomplicated with some unique characteristics, e.g., diverse regionality and\nhigh sparsity. These characteristics make it difficult to design and train STDM\nmodels. Unfortunately, an overview of these studies is still missing, hindering\ncomputer scientists to identify the research issues in ocean while discouraging\nresearchers in ocean science from applying advanced STDM techniques. To remedy\nthis situation, we provide a comprehensive survey to summarize existing STDM\nstudies in ocean. Concretely, we first summarize the widely-used ST ocean\ndatasets and identify their unique characteristics. Then, typical ST ocean data\nquality enhancement techniques are discussed. Next, we classify existing STDM\nstudies for ocean into four types of tasks, i.e., prediction, event detection,\npattern mining, and anomaly detection, and elaborate the techniques for these\ntasks. Finally, promising research opportunities are highlighted. This survey\nwill help scientists from the fields of both computer science and ocean science\nhave a better understanding of the fundamental concepts, key techniques, and\nopen challenges of STDM in ocean.",
          "link": "http://arxiv.org/abs/2307.10803",
          "publishedOn": "2023-07-22T00:55:26.577Z",
          "wordCount": 754,
          "title": "Spatial-Temporal Data Mining for Ocean Science: Data, Methodologies, and Opportunities. (arXiv:2307.10803v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.16716",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Grande_V/0/1/0/all/0/1\">Vincent P. Grande</a>, <a href=\"http://arxiv.org/find/math/1/au:+Schaub_M/0/1/0/all/0/1\">Michael T. Schaub</a>",
          "description": "We present Topological Point Cloud Clustering (TPCC), a new method to cluster\npoints in an arbitrary point cloud based on their contribution to global\ntopological features. TPCC synthesizes desirable features from spectral\nclustering and topological data analysis and is based on considering the\nspectral properties of a simplicial complex associated to the considered point\ncloud. As it is based on considering sparse eigenvector computations, TPCC is\nsimilarly easy to interpret and implement as spectral clustering. However, by\nfocusing not just on a single matrix associated to a graph created from the\npoint cloud data, but on a whole set of Hodge-Laplacians associated to an\nappropriately constructed simplicial complex, we can leverage a far richer set\nof topological features to characterize the data points within the point cloud\nand benefit from the relative robustness of topological techniques against\nnoise. We test the performance of TPCC on both synthetic and real-world data\nand compare it with classical spectral clustering.",
          "link": "http://arxiv.org/abs/2303.16716",
          "publishedOn": "2023-07-22T00:55:26.538Z",
          "wordCount": 688,
          "title": "Topological Point Cloud Clustering. (arXiv:2303.16716v2 [math.AT] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.10159",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Chen_H/0/1/0/all/0/1\">Hao-Yuan Chen</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Chang_Y/0/1/0/all/0/1\">Yen-Jui Chang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Chang_C/0/1/0/all/0/1\">Ching-Ray Chang</a>",
          "description": "Quantum computing holds great potential for advancing the limitations of\nmachine learning algorithms to handle higher data dimensions and reduce overall\ntraining parameters in deep neural network (DNN) models. This study uses a\nparameterized quantum circuit (PQC) on a gate-based quantum computer to\ninvestigate the potential for quantum advantage in a model-free reinforcement\nlearning problem. Through a comprehensive investigation and evaluation of the\ncurrent model and capabilities of quantum computers, we designed and trained a\nnovel hybrid Quantum neural network based on the latest Qiskit and PyTorch\nframework. We compared its performance with a full-classical DNN with and\nwithout an integrated PQC. Our research provides insights into the potential of\ndeep quantum learning to solve a maze problem and, potentially, other\nreinforcement learning problems. We conclude that various reinforcement\nlearning problems can be effective with reasonable training epochs. Moreover, a\ncomparative discussion of the various quantum reinforcement learning model on\nmaze problems is discussed to evaluate our research's overall potential and\nadvantages.",
          "link": "http://arxiv.org/abs/2304.10159",
          "publishedOn": "2023-07-22T00:55:26.525Z",
          "wordCount": 693,
          "title": "Deep-Q Learning with Hybrid Quantum Neural Network on Solving Maze Problems. (arXiv:2304.10159v2 [quant-ph] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06092",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Favaro_S/0/1/0/all/0/1\">Stefano Favaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanin_B/0/1/0/all/0/1\">Boris Hanin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marinucci_D/0/1/0/all/0/1\">Domenico Marinucci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nourdin_I/0/1/0/all/0/1\">Ivan Nourdin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peccati_G/0/1/0/all/0/1\">Giovanni Peccati</a>",
          "description": "We study the distribution of a fully connected neural network with random\nGaussian weights and biases in which the hidden layer widths are proportional\nto a large constant $n$. Under mild assumptions on the non-linearity, we obtain\nquantitative bounds on normal approximations valid at large but finite $n$ and\nany fixed network depth. Our theorems show both for the finite-dimensional\ndistributions and the entire process, that the distance between a random fully\nconnected network (and its derivatives) to the corresponding infinite width\nGaussian process scales like $n^{-\\gamma}$ for $\\gamma>0$, with the exponent\ndepending on the metric used to measure discrepancy. Our bounds are strictly\nstronger in terms of their dependence on network width than any previously\navailable in the literature; in the one-dimensional case, we also prove that\nthey are optimal, i.e., we establish matching lower bounds.",
          "link": "http://arxiv.org/abs/2307.06092",
          "publishedOn": "2023-07-22T00:55:26.471Z",
          "wordCount": null,
          "title": "Quantitative CLTs in Deep Neural Networks. (arXiv:2307.06092v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.06089",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gourdeau_P/0/1/0/all/0/1\">Pascale Gourdeau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanade_V/0/1/0/all/0/1\">Varun Kanade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwiatkowska_M/0/1/0/all/0/1\">Marta Kwiatkowska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Worrell_J/0/1/0/all/0/1\">James Worrell</a>",
          "description": "Distributional assumptions have been shown to be necessary for the robust\nlearnability of concept classes when considering the exact-in-the-ball robust\nrisk and access to random examples by Gourdeau et al. (2019). In this paper, we\nstudy learning models where the learner is given more power through the use of\nlocal queries, and give the first distribution-free algorithms that perform\nrobust empirical risk minimization (ERM) for this notion of robustness. The\nfirst learning model we consider uses local membership queries (LMQ), where the\nlearner can query the label of points near the training sample. We show that,\nunder the uniform distribution, LMQs do not increase the robustness threshold\nof conjunctions and any superclass, e.g., decision lists and halfspaces. Faced\nwith this negative result, we introduce the local equivalence query\n($\\mathsf{LEQ}$) oracle, which returns whether the hypothesis and target\nconcept agree in the perturbation region around a point in the training sample,\nas well as a counterexample if it exists. We show a separation result: on the\none hand, if the query radius $\\lambda$ is strictly smaller than the\nadversary's perturbation budget $\\rho$, then distribution-free robust learning\nis impossible for a wide variety of concept classes; on the other hand, the\nsetting $\\lambda=\\rho$ allows us to develop robust ERM algorithms. We then\nbound the query complexity of these algorithms based on online learning\nguarantees and further improve these bounds for the special case of\nconjunctions. We finish by giving robust learning algorithms for halfspaces on\n$\\{0,1\\}^n$ and then obtaining robustness guarantees for halfspaces in\n$\\mathbb{R}^n$ against precision-bounded adversaries.",
          "link": "http://arxiv.org/abs/2210.06089",
          "publishedOn": "2023-07-22T00:55:26.466Z",
          "wordCount": null,
          "title": "When are Local Queries Useful for Robust Learning?. (arXiv:2210.06089v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2012.07881",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kleyko_D/0/1/0/all/0/1\">Denis Kleyko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosato_A/0/1/0/all/0/1\">Antonello Rosato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frady_E/0/1/0/all/0/1\">E. Paxon Frady</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panella_M/0/1/0/all/0/1\">Massimo Panella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sommer_F/0/1/0/all/0/1\">Friedrich T. Sommer</a>",
          "description": "Multilayer neural networks set the current state of the art for many\ntechnical classification problems. But, these networks are still, essentially,\nblack boxes in terms of analyzing them and predicting their performance. Here,\nwe develop a statistical theory for the one-layer perceptron and show that it\ncan predict performances of a surprisingly large variety of neural networks\nwith different architectures. A general theory of classification with\nperceptrons is developed by generalizing an existing theory for analyzing\nreservoir computing models and connectionist models for symbolic reasoning\nknown as vector symbolic architectures. Our statistical theory offers three\nformulas leveraging the signal statistics with increasing detail. The formulas\nare analytically intractable, but can be evaluated numerically. The description\nlevel that captures maximum details requires stochastic sampling methods.\nDepending on the network model, the simpler formulas already yield high\nprediction accuracy. The quality of the theory predictions is assessed in three\nexperimental settings, a memorization task for echo state networks (ESNs) from\nreservoir computing literature, a collection of classification datasets for\nshallow randomly connected networks, and the ImageNet dataset for deep\nconvolutional neural networks. We find that the second description level of the\nperceptron theory can predict the performance of types of ESNs, which could not\nbe described previously. The theory can predict deep multilayer neural networks\nby being applied to their output layer. While other methods for prediction of\nneural networks performance commonly require to train an estimator model, the\nproposed theory requires only the first two moments of the distribution of the\npostsynaptic sums in the output neurons. The perceptron theory compares\nfavorably to other methods that do not rely on training an estimator model.",
          "link": "http://arxiv.org/abs/2012.07881",
          "publishedOn": "2023-07-22T00:55:26.452Z",
          "wordCount": 848,
          "title": "Perceptron Theory Can Predict the Accuracy of Neural Networks. (arXiv:2012.07881v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mostafavi_S/0/1/0/all/0/1\">Samie Mostafavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_G/0/1/0/all/0/1\">Gourav Prateek Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gross_J/0/1/0/all/0/1\">James Gross</a>",
          "description": "With the emergence of new application areas, such as cyber-physical systems\nand human-in-the-loop applications, there is a need to guarantee a certain\nlevel of end-to-end network latency with extremely high reliability, e.g.,\n99.999%. While mechanisms specified under IEEE 802.1as time-sensitive\nnetworking (TSN) can be used to achieve these requirements for switched\nEthernet networks, implementing TSN mechanisms in wireless networks is\nchallenging due to their stochastic nature. To conform the wireless link to a\nreliability level of 99.999%, the behavior of extremely rare outliers in the\nlatency probability distribution, or the tail of the distribution, must be\nanalyzed and controlled. This work proposes predicting the tail of the latency\ndistribution using state-of-the-art data-driven approaches, such as mixture\ndensity networks (MDN) and extreme value mixture models, to estimate the\nlikelihood of rare latencies conditioned on the network parameters, which can\nbe used to make more informed decisions in wireless transmission. Actual\nlatency measurements of IEEE 802.11g (WiFi), commercial private and a\nsoftware-defined 5G network are used to benchmark the proposed approaches and\nevaluate their sensitivities concerning the tail probabilities.",
          "link": "http://arxiv.org/abs/2307.10648",
          "publishedOn": "2023-07-22T00:55:26.436Z",
          "wordCount": null,
          "title": "Data-Driven Latency Probability Prediction for Wireless Networks: Focusing on Tail Probabilities. (arXiv:2307.10648v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.11498",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thakur_N/0/1/0/all/0/1\">Nandan Thakur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reimers_N/0/1/0/all/0/1\">Nils Reimers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jimmy Lin</a>",
          "description": "Dense retrieval overcome the lexical gap and has shown great success in\nad-hoc information retrieval (IR). Despite their success, dense retrievers are\nexpensive to serve across practical use cases. For use cases requiring to\nsearch from millions of documents, the dense index becomes bulky and requires\nhigh memory usage for storing the index. More recently, learning-to-hash (LTH)\ntechniques, for e.g., BPR and JPQ, produce binary document vectors, thereby\nreducing the memory requirement to efficiently store the dense index. LTH\ntechniques are supervised and finetune the retriever using a ranking loss. They\noutperform their counterparts, i.e., traditional out-of-the-box vector\ncompression techniques such as PCA or PQ. A missing piece from prior work is\nthat existing techniques have been evaluated only in-domain, i.e., on a single\ndataset such as MS MARCO. In our work, we evaluate LTH and vector compression\ntechniques for improving the downstream zero-shot retrieval accuracy of the\nTAS-B dense retriever while maintaining efficiency at inference. Our results\ndemonstrate that, unlike prior work, LTH strategies when applied naively can\nunderperform the zero-shot TAS-B dense retriever on average by up to 14%\nnDCG@10 on the BEIR benchmark. To solve this limitation, in our work, we\npropose an easy yet effective solution of injecting domain adaptation with\nexisting supervised LTH techniques. We experiment with two well-known\nunsupervised domain adaptation techniques: GenQ and GPL. Our domain adaptation\ninjection technique can improve the downstream zero-shot retrieval\neffectiveness for both BPR and JPQ variants of the TAS-B model by on average\n11.5% and 8.2% nDCG@10 while both maintaining 32$\\times$ memory efficiency and\n14$\\times$ and 2$\\times$ speedup respectively in CPU retrieval latency on BEIR.\nAll our code, models, and data are publicly available at\nhttps://github.com/thakur-nandan/income.",
          "link": "http://arxiv.org/abs/2205.11498",
          "publishedOn": "2023-07-22T00:55:26.435Z",
          "wordCount": null,
          "title": "Injecting Domain Adaptation with Learning-to-hash for Effective and Efficient Zero-shot Dense Retrieval. (arXiv:2205.11498v2 [cs.IR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.14085",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zunkovic_B/0/1/0/all/0/1\">Bojan &#x17d;unkovi&#x10d;</a>",
          "description": "Positive unlabeled learning is a binary classification problem with positive\nand unlabeled data. It is common in domains where negative labels are costly or\nimpossible to obtain, e.g., medicine and personalized advertising. Most\napproaches to positive unlabeled learning apply to specific data types (e.g.,\nimages, categorical data) and can not generate new positive and negative\nsamples. This work introduces a feature-space distance-based tensor network\napproach to the positive unlabeled learning problem. The presented method is\nnot domain specific and significantly improves the state-of-the-art results on\nthe MNIST image and 15 categorical/mixed datasets. The trained tensor network\nmodel is also a generative model and enables the generation of new positive and\nnegative instances.",
          "link": "http://arxiv.org/abs/2211.14085",
          "publishedOn": "2023-07-22T00:55:26.420Z",
          "wordCount": null,
          "title": "Positive unlabeled learning with tensor networks. (arXiv:2211.14085v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.13501",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mankovich_N/0/1/0/all/0/1\">Nathan Mankovich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birdal_T/0/1/0/all/0/1\">Tolga Birdal</a>",
          "description": "This paper presents a new, provably-convergent algorithm for computing the\nflag-mean and flag-median of a set of points on a flag manifold under the\nchordal metric. The flag manifold is a mathematical space consisting of flags,\nwhich are sequences of nested subspaces of a vector space that increase in\ndimension. The flag manifold is a superset of a wide range of known matrix\nspaces, including Stiefel and Grassmanians, making it a general object that is\nuseful in a wide variety computer vision problems.\n\nTo tackle the challenge of computing first order flag statistics, we first\ntransform the problem into one that involves auxiliary variables constrained to\nthe Stiefel manifold. The Stiefel manifold is a space of orthogonal frames, and\nleveraging the numerical stability and efficiency of Stiefel-manifold\noptimization enables us to compute the flag-mean effectively. Through a series\nof experiments, we show the competence of our method in Grassmann and rotation\naveraging, as well as principal component analysis. We release our source code\nunder https://github.com/nmank/FlagAveraging.",
          "link": "http://arxiv.org/abs/2303.13501",
          "publishedOn": "2023-07-22T00:55:26.399Z",
          "wordCount": 706,
          "title": "Chordal Averaging on Flag Manifolds and Its Applications. (arXiv:2303.13501v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10655",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1\">Jiawei Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zijian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wenqiang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tailin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yuchang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lumin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zehong Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jun Zhang</a>",
          "description": "Federated learning (FL) has emerged as a highly effective paradigm for\nprivacy-preserving collaborative training among different parties. Unlike\ntraditional centralized learning, which requires collecting data from each\nparty, FL allows clients to share privacy-preserving information without\nexposing private datasets. This approach not only guarantees enhanced privacy\nprotection but also facilitates more efficient and secure collaboration among\nmultiple participants. Therefore, FL has gained considerable attention from\nresearchers, promoting numerous surveys to summarize the related works.\nHowever, the majority of these surveys concentrate on methods sharing model\nparameters during the training process, while overlooking the potential of\nsharing other forms of local information. In this paper, we present a\nsystematic survey from a new perspective, i.e., what to share in FL, with an\nemphasis on the model utility, privacy leakage, and communication efficiency.\nThis survey differs from previous ones due to four distinct contributions.\nFirst, we present a new taxonomy of FL methods in terms of the sharing methods,\nwhich includes three categories of shared information: model sharing, synthetic\ndata sharing, and knowledge sharing. Second, we analyze the vulnerability of\ndifferent sharing methods to privacy attacks and review the defense mechanisms\nthat provide certain privacy guarantees. Third, we conduct extensive\nexperiments to compare the performance and communication overhead of various\nsharing methods in FL. Besides, we assess the potential privacy leakage through\nmodel inversion and membership inference attacks, while comparing the\neffectiveness of various defense approaches. Finally, we discuss potential\ndeficiencies in current methods and outline future directions for improvement.",
          "link": "http://arxiv.org/abs/2307.10655",
          "publishedOn": "2023-07-22T00:55:26.100Z",
          "wordCount": null,
          "title": "A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency. (arXiv:2307.10655v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.10515",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Jarrett_D/0/1/0/all/0/1\">Daniel Jarrett</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tallec_C/0/1/0/all/0/1\">Corentin Tallec</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Altche_F/0/1/0/all/0/1\">Florent Altch&#xe9;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mesnard_T/0/1/0/all/0/1\">Thomas Mesnard</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Munos_R/0/1/0/all/0/1\">R&#xe9;mi Munos</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Valko_M/0/1/0/all/0/1\">Michal Valko</a>",
          "description": "Consider the problem of exploration in sparse-reward or reward-free\nenvironments, such as in Montezuma's Revenge. In the curiosity-driven paradigm,\nthe agent is rewarded for how much each realized outcome differs from their\npredicted outcome. But using predictive error as intrinsic motivation is\nfragile in stochastic environments, as the agent may become trapped by\nhigh-entropy areas of the state-action space, such as a \"noisy TV\". In this\nwork, we study a natural solution derived from structural causal models of the\nworld: Our key idea is to learn representations of the future that capture\nprecisely the unpredictable aspects of each outcome -- which we use as\nadditional input for predictions, such that intrinsic rewards only reflect the\npredictable aspects of world dynamics. First, we propose incorporating such\nhindsight representations into models to disentangle \"noise\" from \"novelty\",\nyielding Curiosity in Hindsight: a simple and scalable generalization of\ncuriosity that is robust to stochasticity. Second, we instantiate this\nframework for the recently introduced BYOL-Explore algorithm as our prime\nexample, resulting in the noise-robust BYOL-Hindsight. Third, we illustrate its\nbehavior under a variety of different stochasticities in a grid world, and find\nimprovements over BYOL-Explore in hard-exploration Atari games with sticky\nactions. Notably, we show state-of-the-art results in exploring Montezuma's\nRevenge with sticky actions, while preserving performance in the non-sticky\nsetting.",
          "link": "http://arxiv.org/abs/2211.10515",
          "publishedOn": "2023-07-22T00:55:26.098Z",
          "wordCount": null,
          "title": "Curiosity in Hindsight: Intrinsic Exploration in Stochastic Environments. (arXiv:2211.10515v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10580",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1\">Yanfei Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qinghong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_R/0/1/0/all/0/1\">Ruixue Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_Y/0/1/0/all/0/1\">Yang Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiaomeng Huang</a>",
          "description": "Accurate and timely prediction of sea fog is very important for effectively\nmanaging maritime and coastal economic activities. Given the intricate nature\nand inherent variability of sea fog, traditional numerical and statistical\nforecasting methods are often proven inadequate. This study aims to develop an\nadvanced sea fog forecasting method embedded in a numerical weather prediction\nmodel using the Yangtze River Estuary (YRE) coastal area as a case study. Prior\nto training our machine learning model, we employ a time-lagged correlation\nanalysis technique to identify key predictors and decipher the underlying\nmechanisms driving sea fog occurrence. In addition, we implement ensemble\nlearning and a focal loss function to address the issue of imbalanced data,\nthereby enhancing the predictive ability of our model. To verify the accuracy\nof our method, we evaluate its performance using a comprehensive dataset\nspanning one year, which encompasses both weather station observations and\nhistorical forecasts. Remarkably, our machine learning-based approach surpasses\nthe predictive performance of two conventional methods, the weather research\nand forecasting nonhydrostatic mesoscale model (WRF-NMM) and the algorithm\ndeveloped by the National Oceanic and Atmospheric Administration (NOAA)\nForecast Systems Laboratory (FSL). Specifically, in regard to predicting sea\nfog with a visibility of less than or equal to 1 km with a lead time of 60\nhours, our methodology achieves superior results by increasing the probability\nof detection (POD) while simultaneously reducing the false alarm ratio (FAR).",
          "link": "http://arxiv.org/abs/2307.10580",
          "publishedOn": "2023-07-22T00:55:26.097Z",
          "wordCount": null,
          "title": "Intelligent model for offshore China sea fog forecasting. (arXiv:2307.10580v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.07902",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiangmeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiang_W/0/1/0/all/0/1\">Wenwen Qiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yanan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mo_W/0/1/0/all/0/1\">Wenyi Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Changwen Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_B/0/1/0/all/0/1\">Bing Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Hui Xiong</a>",
          "description": "As a successful approach to self-supervised learning, contrastive learning\naims to learn invariant information shared among distortions of the input\nsample. While contrastive learning has yielded continuous advancements in\nsampling strategy and architecture design, it still remains two persistent\ndefects: the interference of task-irrelevant information and sample\ninefficiency, which are related to the recurring existence of trivial constant\nsolutions. From the perspective of dimensional analysis, we find out that the\ndimensional redundancy and dimensional confounder are the intrinsic issues\nbehind the phenomena, and provide experimental evidence to support our\nviewpoint. We further propose a simple yet effective approach MetaMask, short\nfor the dimensional Mask learned by Meta-learning, to learn representations\nagainst dimensional redundancy and confounder. MetaMask adopts the\nredundancy-reduction technique to tackle the dimensional redundancy issue and\ninnovatively introduces a dimensional mask to reduce the gradient effects of\nspecific dimensions containing the confounder, which is trained by employing a\nmeta-learning paradigm with the objective of improving the performance of\nmasked representations on a typical self-supervised task. We provide solid\ntheoretical analyses to prove MetaMask can obtain tighter risk bounds for\ndownstream classification compared to typical contrastive methods. Empirically,\nour method achieves state-of-the-art performance on various benchmarks.",
          "link": "http://arxiv.org/abs/2209.07902",
          "publishedOn": "2023-07-22T00:55:26.090Z",
          "wordCount": null,
          "title": "MetaMask: Revisiting Dimensional Confounder for Self-Supervised Learning. (arXiv:2209.07902v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.05610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adams_J/0/1/0/all/0/1\">Jadie Adams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elhabian_S/0/1/0/all/0/1\">Shireen Elhabian</a>",
          "description": "Statistical Shape Modeling (SSM) is a valuable tool for investigating and\nquantifying anatomical variations within populations of anatomies. However,\ntraditional correspondence-based SSM generation methods have a prohibitive\ninference process and require complete geometric proxies (e.g., high-resolution\nbinary volumes or surface meshes) as input shapes to construct the SSM.\nUnordered 3D point cloud representations of shapes are more easily acquired\nfrom various medical imaging practices (e.g., thresholded images and surface\nscanning). Point cloud deep networks have recently achieved remarkable success\nin learning permutation-invariant features for different point cloud tasks\n(e.g., completion, semantic segmentation, classification). However, their\napplication to learning SSM from point clouds is to-date unexplored. In this\nwork, we demonstrate that existing point cloud encoder-decoder-based completion\nnetworks can provide an untapped potential for SSM, capturing population-level\nstatistical representations of shapes while reducing the inference burden and\nrelaxing the input requirement. We discuss the limitations of these techniques\nto the SSM application and suggest future improvements. Our work paves the way\nfor further exploration of point cloud deep learning for SSM, a promising\navenue for advancing shape analysis literature and broadening SSM to diverse\nuse cases.",
          "link": "http://arxiv.org/abs/2305.05610",
          "publishedOn": "2023-07-22T00:55:26.089Z",
          "wordCount": null,
          "title": "Can point cloud networks learn statistical shape models of anatomies?. (arXiv:2305.05610v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.07989",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schulte_O/0/1/0/all/0/1\">Oliver Schulte</a>",
          "description": "This note describes a new approach to classifying graphs that leverages graph\ngenerative models (GGM). Assuming a GGM that defines a joint probability\ndistribution over graphs and their class labels, I derive classification\nformulas for the probability of a class label given a graph. A new conditional\nELBO can be used to train a generative graph auto-encoder model for\ndiscrimination. While leveraging generative models for classification has been\nwell explored for non-relational i.i.d. data, to our knowledge it is a novel\napproach to graph classification.",
          "link": "http://arxiv.org/abs/2302.07989",
          "publishedOn": "2023-07-22T00:55:26.088Z",
          "wordCount": null,
          "title": "From Graph Generation to Graph Classification. (arXiv:2302.07989v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.08982",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1\">Yuyol Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_Y/0/1/0/all/0/1\">Yoonjin Yoon</a>",
          "description": "The complex spatial-temporal correlations in transportation networks make the\ntraffic forecasting problem challenging. Since transportation system inherently\npossesses graph structures, much research efforts have been put with graph\nneural networks. Recently, constructing adaptive graphs to the data has shown\npromising results over the models relying on a single static graph structure.\nHowever, the graph adaptations are applied during the training phases, and do\nnot reflect the data used during the testing phases. Such shortcomings can be\nproblematic especially in traffic forecasting since the traffic data often\nsuffers from the unexpected changes and irregularities in the time series. In\nthis study, we propose a novel traffic forecasting framework called Progressive\nGraph Convolutional Network (PGCN). PGCN constructs a set of graphs by\nprogressively adapting to input data during the training and the testing\nphases. Specifically, we implemented the model to construct progressive\nadjacency matrices by learning trend similarities among graph nodes. Then, the\nmodel is combined with the dilated causal convolution and gated activation unit\nto extract temporal features. With residual and skip connections, PGCN performs\nthe traffic prediction. When applied to four real-world traffic datasets of\ndiverse geometric nature, the proposed model achieves state-of-the-art\nperformance with consistency in all datasets. We conclude that the ability of\nPGCN to progressively adapt to input data enables the model to generalize in\ndifferent study sites with robustness.",
          "link": "http://arxiv.org/abs/2202.08982",
          "publishedOn": "2023-07-22T00:55:26.086Z",
          "wordCount": null,
          "title": "PGCN: Progressive Graph Convolutional Networks for Spatial-Temporal Traffic Forecasting. (arXiv:2202.08982v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10654",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Richman_R/0/1/0/all/0/1\">Ronald Richman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wuthrich_M/0/1/0/all/0/1\">Mario V. W&#xfc;thrich</a>",
          "description": "A very popular model-agnostic technique for explaining predictive models is\nthe SHapley Additive exPlanation (SHAP). The two most popular versions of SHAP\nare a conditional expectation version and an unconditional expectation version\n(the latter is also known as interventional SHAP). Except for tree-based\nmethods, usually the unconditional version is used (for computational reasons).\nWe provide a (surrogate) neural network approach which allows us to efficiently\ncalculate the conditional version for both neural networks and other regression\nmodels, and which properly considers the dependence structure in the feature\ncomponents. This proposal is also useful to provide drop1 and anova analyses in\ncomplex regression models which are similar to their generalized linear model\n(GLM) counterparts, and we provide a partial dependence plot (PDP) counterpart\nthat considers the right dependence structure in the feature components.",
          "link": "http://arxiv.org/abs/2307.10654",
          "publishedOn": "2023-07-22T00:55:26.081Z",
          "wordCount": null,
          "title": "Conditional expectation network for SHAP. (arXiv:2307.10654v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10792",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Santos_J/0/1/0/all/0/1\">Jo&#xe3;o Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Triet Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rippel_O/0/1/0/all/0/1\">Oliver Rippel</a>",
          "description": "Few-shot anomaly detection (AD) is an emerging sub-field of general AD, and\ntries to distinguish between normal and anomalous data using only few selected\nsamples. While newly proposed few-shot AD methods do compare against\npre-existing algorithms developed for the full-shot domain as baselines, they\ndo not dedicatedly optimize them for the few-shot setting. It thus remains\nunclear if the performance of such pre-existing algorithms can be further\nimproved. We address said question in this work. Specifically, we present a\nstudy on the AD/anomaly segmentation (AS) performance of PatchCore, the current\nstate-of-the-art full-shot AD/AS algorithm, in both the few-shot and the\nmany-shot settings. We hypothesize that further performance improvements can be\nrealized by (I) optimizing its various hyperparameters, and by (II)\ntransferring techniques known to improve few-shot supervised learning to the AD\ndomain. Exhaustive experiments on the public VisA and MVTec AD datasets reveal\nthat (I) significant performance improvements can be realized by optimizing\nhyperparameters such as the underlying feature extractor, and that (II)\nimage-level augmentations can, but are not guaranteed, to improve performance.\nBased on these findings, we achieve a new state of the art in few-shot AD on\nVisA, further demonstrating the merit of adapting pre-existing AD/AS methods to\nthe few-shot setting. Last, we identify the investigation of feature extractors\nwith a strong inductive bias as a potential future research direction for\n(few-shot) AD/AS.",
          "link": "http://arxiv.org/abs/2307.10792",
          "publishedOn": "2023-07-22T00:55:26.077Z",
          "wordCount": null,
          "title": "Optimizing PatchCore for Few/many-shot Anomaly Detection. (arXiv:2307.10792v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.04974",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wagenmaker_A/0/1/0/all/0/1\">Andrew Wagenmaker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pacchiano_A/0/1/0/all/0/1\">Aldo Pacchiano</a>",
          "description": "Two central paradigms have emerged in the reinforcement learning (RL)\ncommunity: online RL and offline RL. In the online RL setting, the agent has no\nprior knowledge of the environment, and must interact with it in order to find\nan $\\epsilon$-optimal policy. In the offline RL setting, the learner instead\nhas access to a fixed dataset to learn from, but is unable to otherwise\ninteract with the environment, and must obtain the best policy it can from this\noffline data. Practical scenarios often motivate an intermediate setting: if we\nhave some set of offline data and, in addition, may also interact with the\nenvironment, how can we best use the offline data to minimize the number of\nonline interactions necessary to learn an $\\epsilon$-optimal policy?\n\nIn this work, we consider this setting, which we call the \\textsf{FineTuneRL}\nsetting, for MDPs with linear structure. We characterize the necessary number\nof online samples needed in this setting given access to some offline dataset,\nand develop an algorithm, \\textsc{FTPedel}, which is provably optimal, up to\n$H$ factors. We show through an explicit example that combining offline data\nwith online interactions can lead to a provable improvement over either purely\noffline or purely online RL. Finally, our results illustrate the distinction\nbetween \\emph{verifiable} learning, the typical setting considered in online\nRL, and \\emph{unverifiable} learning, the setting often considered in offline\nRL, and show that there is a formal separation between these regimes.",
          "link": "http://arxiv.org/abs/2211.04974",
          "publishedOn": "2023-07-22T00:55:26.076Z",
          "wordCount": null,
          "title": "Leveraging Offline Data in Online Reinforcement Learning. (arXiv:2211.04974v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Duong_H/0/1/0/all/0/1\">Hai Duong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linhan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">ThanhVu Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dwyer_M/0/1/0/all/0/1\">Matthew Dwyer</a>",
          "description": "Deep Neural Networks (DNNs) have emerged as an effective approach to tackling\nreal-world problems. However, like human-written software,\nautomatically-generated DNNs can have bugs and be attacked. This thus attracts\nmany recent interests in developing effective and scalable DNN verification\ntechniques and tools. In this work, we introduce a NeuralSAT, a new constraint\nsolving approach to DNN verification. The design of NeuralSAT follows the\nDPLL(T) algorithm used modern SMT solving, which includes (conflict) clause\nlearning, abstraction, and theory solving, and thus NeuralSAT can be considered\nas an SMT framework for DNNs. Preliminary results show that the NeuralSAT\nprototype is competitive to the state-of-the-art. We hope, with proper\noptimization and engineering, NeuralSAT will carry the power and success of\nmodern SAT/SMT solvers to DNN verification. NeuralSAT is avaliable from:\nhttps://github.com/dynaroars/neuralsat-solver",
          "link": "http://arxiv.org/abs/2307.10266",
          "publishedOn": "2023-07-22T00:55:26.069Z",
          "wordCount": null,
          "title": "A DPLL(T) Framework for Verifying Deep Neural Networks. (arXiv:2307.10266v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2207.12395",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Negrea_J/0/1/0/all/0/1\">Jeffrey Negrea</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_J/0/1/0/all/0/1\">Jun Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Feng_H/0/1/0/all/0/1\">Haoyue Feng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Roy_D/0/1/0/all/0/1\">Daniel M. Roy</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huggins_J/0/1/0/all/0/1\">Jonathan H. Huggins</a>",
          "description": "The tuning of stochastic gradient algorithms (SGAs) for optimization and\nsampling is often based on heuristics and trial-and-error rather than\ngeneralizable theory. We address this theory--practice gap by characterizing\nthe large-sample statistical asymptotics of SGAs via a joint\nstep-size--sample-size scaling limit. We show that iterate averaging with a\nlarge fixed step size is robust to the choice of tuning parameters and\nasymptotically has covariance proportional to that of the MLE sampling\ndistribution. We also prove a Bernstein--von Mises-like theorem to guide\ntuning, including for generalized posteriors that are robust to model\nmisspecification. Numerical experiments validate our results and\nrecommendations in realistic finite-sample regimes. Our work lays the\nfoundation for a systematic analysis of other stochastic gradient Markov chain\nMonte Carlo algorithms for a wide range of models.",
          "link": "http://arxiv.org/abs/2207.12395",
          "publishedOn": "2023-07-22T00:55:26.056Z",
          "wordCount": null,
          "title": "Tuning Stochastic Gradient Algorithms for Statistical Inference via Large-Sample Asymptotics. (arXiv:2207.12395v3 [stat.CO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10492",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jaberzadeh_A/0/1/0/all/0/1\">Amir Jaberzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shrestha_A/0/1/0/all/0/1\">Ajay Kumar Shrestha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1\">Faijan Ahamad Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaikh_M/0/1/0/all/0/1\">Mohammed Afaan Shaikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dave_B/0/1/0/all/0/1\">Bhargav Dave</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_J/0/1/0/all/0/1\">Jason Geng</a>",
          "description": "With the increasing importance of data sharing for collaboration and\ninnovation, it is becoming more important to ensure that data is managed and\nshared in a secure and trustworthy manner. Data governance is a common approach\nto managing data, but it faces many challenges such as data silos, data\nconsistency, privacy, security, and access control. To address these\nchallenges, this paper proposes a comprehensive framework that integrates data\ntrust in federated learning with InterPlanetary File System, blockchain, and\nsmart contracts to facilitate secure and mutually beneficial data sharing while\nproviding incentives, access control mechanisms, and penalizing any dishonest\nbehavior. The experimental results demonstrate that the proposed model is\neffective in improving the accuracy of federated learning models while ensuring\nthe security and fairness of the data-sharing process. The research paper also\npresents a decentralized federated learning platform that successfully trained\na CNN model on the MNIST dataset using blockchain technology. The platform\nenables multiple workers to train the model simultaneously while maintaining\ndata privacy and security. The decentralized architecture and use of blockchain\ntechnology allow for efficient communication and coordination between workers.\nThis platform has the potential to facilitate decentralized machine learning\nand support privacy-preserving collaboration in various domains.",
          "link": "http://arxiv.org/abs/2307.10492",
          "publishedOn": "2023-07-22T00:55:26.013Z",
          "wordCount": null,
          "title": "Blockchain-Based Federated Learning: Incentivizing Data Sharing and Penalizing Dishonest Behavior. (arXiv:2307.10492v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10274",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liao_F/0/1/0/all/0/1\">Feng-Ting Liao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chan_Y/0/1/0/all/0/1\">Yung-Chieh Chan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1\">Yi-Chang Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hsu_C/0/1/0/all/0/1\">Chan-Jan Hsu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shiu_D/0/1/0/all/0/1\">Da-shan Shiu</a>",
          "description": "In this work, we propose a method to create domain-sensitive speech\nrecognition models that utilize textual domain information by conditioning its\ngeneration on a given text prompt. This is accomplished by fine-tuning a\npre-trained, end-to-end model (Whisper) to learn from demonstrations with\nprompt examples. We show that this ability can be generalized to different\ndomains and even various prompt contexts, with our model gaining a Word Error\nRate (WER) reduction of up to 33% on unseen datasets from various domains, such\nas medical conversation, air traffic control communication, and financial\nmeetings. Considering the limited availability of audio-transcript pair data,\nwe further extend our method to text-only fine-tuning to achieve domain\nsensitivity as well as domain adaptation. We demonstrate that our text-only\nfine-tuned model can also attend to various prompt contexts, with the model\nreaching the most WER reduction of 29% on the medical conversation dataset.",
          "link": "http://arxiv.org/abs/2307.10274",
          "publishedOn": "2023-07-22T00:55:26.009Z",
          "wordCount": null,
          "title": "Zero-shot Domain-sensitive Speech Recognition with Prompt-conditioning Fine-tuning. (arXiv:2307.10274v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10323",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kishore_V/0/1/0/all/0/1\">Varsha Kishore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_C/0/1/0/all/0/1\">Chao Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lovelace_J/0/1/0/all/0/1\">Justin Lovelace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artzi_Y/0/1/0/all/0/1\">Yoav Artzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weinberger_K/0/1/0/all/0/1\">Kilian Q. Weinberger</a>",
          "description": "Differentiable Search Index is a recently proposed paradigm for document\nretrieval, that encodes information about a corpus of documents within the\nparameters of a neural network and directly maps queries to corresponding\ndocuments. These models have achieved state-of-the-art performances for\ndocument retrieval across many benchmarks. These kinds of models have a\nsignificant limitation: it is not easy to add new documents after a model is\ntrained. We propose IncDSI, a method to add documents in real time (about\n20-50ms per document), without retraining the model on the entire dataset (or\neven parts thereof). Instead we formulate the addition of documents as a\nconstrained optimization problem that makes minimal changes to the network\nparameters. Although orders of magnitude faster, our approach is competitive\nwith re-training the model on the whole dataset and enables the development of\ndocument retrieval systems that can be updated with new information in\nreal-time. Our code for IncDSI is available at\nhttps://github.com/varshakishore/IncDSI.",
          "link": "http://arxiv.org/abs/2307.10323",
          "publishedOn": "2023-07-22T00:55:26.003Z",
          "wordCount": null,
          "title": "IncDSI: Incrementally Updatable Document Retrieval. (arXiv:2307.10323v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10252",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Noor_U/0/1/0/all/0/1\">Umara Noor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahid_S/0/1/0/all/0/1\">Sawera Shahid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanwal_R/0/1/0/all/0/1\">Rimsha Kanwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rashid_Z/0/1/0/all/0/1\">Zahid Rashid</a>",
          "description": "Cyber threat attribution is the process of identifying the actor of an attack\nincident in cyberspace. An accurate and timely threat attribution plays an\nimportant role in deterring future attacks by applying appropriate and timely\ndefense mechanisms. Manual analysis of attack patterns gathered by honeypot\ndeployments, intrusion detection systems, firewalls, and via trace-back\nprocedures is still the preferred method of security analysts for cyber threat\nattribution. Such attack patterns are low-level Indicators of Compromise (IOC).\nThey represent Tactics, Techniques, Procedures (TTP), and software tools used\nby the adversaries in their campaigns. The adversaries rarely re-use them. They\ncan also be manipulated, resulting in false and unfair attribution. To\nempirically evaluate and compare the effectiveness of both kinds of IOC, there\nare two problems that need to be addressed. The first problem is that in recent\nresearch works, the ineffectiveness of low-level IOC for cyber threat\nattribution has been discussed intuitively. An empirical evaluation for the\nmeasure of the effectiveness of low-level IOC based on a real-world dataset is\nmissing. The second problem is that the available dataset for high-level IOC\nhas a single instance for each predictive class label that cannot be used\ndirectly for training machine learning models. To address these problems in\nthis research work, we empirically evaluate the effectiveness of low-level IOC\nbased on a real-world dataset that is specifically built for comparative\nanalysis with high-level IOC. The experimental results show that the high-level\nIOC trained models effectively attribute cyberattacks with an accuracy of 95%\nas compared to the low-level IOC trained models where accuracy is 40%.",
          "link": "http://arxiv.org/abs/2307.10252",
          "publishedOn": "2023-07-22T00:55:25.999Z",
          "wordCount": null,
          "title": "A Machine Learning based Empirical Evaluation of Cyber Threat Actors High Level Attack Patterns over Low level Attack Patterns in Attributing Attacks. (arXiv:2307.10252v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.09826",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bohdal_O/0/1/0/all/0/1\">Ondrej Bohdal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hospedales_T/0/1/0/all/0/1\">Timothy Hospedales</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip H.S. Torr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barez_F/0/1/0/all/0/1\">Fazl Barez</a>",
          "description": "Successful deployment of artificial intelligence (AI) in various settings has\nled to numerous positive outcomes for individuals and society. However, AI\nsystems have also been shown to harm parts of the population due to biased\npredictions. AI fairness focuses on mitigating such biases to ensure AI\ndecision making is not discriminatory towards certain groups. We take a closer\nlook at AI fairness and analyze how lack of AI fairness can lead to deepening\nof biases over time and act as a social stressor. More specifically, we discuss\nhow biased models can lead to more negative real-world outcomes for certain\ngroups, which may then become more prevalent by deploying new AI models trained\non increasingly biased data, resulting in a feedback loop. If the issues\npersist, they could be reinforced by interactions with other risks and have\nsevere implications on society in the form of social unrest. We examine current\nstrategies for improving AI fairness, assess their limitations in terms of\nreal-world deployment, and explore potential paths forward to ensure we reap\nAI's benefits without causing society's collapse.",
          "link": "http://arxiv.org/abs/2304.09826",
          "publishedOn": "2023-07-22T00:55:25.997Z",
          "wordCount": null,
          "title": "Fairness in AI and Its Long-Term Implications on Society. (arXiv:2304.09826v2 [cs.CY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10617",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baby_A/0/1/0/all/0/1\">Anusuya Baby</a>",
          "description": "In recent years, online reviews play a vital role for promoting any kind of\nproduct or services. Businesses may embed fake reviews in order to attract\ncustomers to purchase their products. They may even highlight the benefits of\ntheir own product or criticize the competition's product. Marketers,\nadvertisers, and other online business users have incentive to create fake\npositive reviews for products which they want to promote or give fake negative\nreviews for products which they really don't like. So now-a-days writing a\ndeceptive review is inevitable thing for promoting their own business or\ndegrading competitor's reputation. Thus, identifying deceptive reviews is an\nintense and on-going research area. This research paper proposes machine\nlearning model approach to identify deceptive reviews. The paper investigates\nthe performance of the several experiments done on a Deceptive Opinion Spam\nCorpus dataset of restaurants reviews. We developed a n-gram model and max\nfeatures to identify deceptive contents with a particular focus on fake\nreviews. Further, we conduct a benchmark study to investigate the performance\nof two different features extraction techniques and apply five machine learning\nclassification techniques. The experimental results show that passive\naggressive classifier outperforms other algorithms, and it reaches the highest\naccuracy not only in text classification but also to fake reviews. We also\nstudy the data augmentation and implement different deep learning techniques.",
          "link": "http://arxiv.org/abs/2307.10617",
          "publishedOn": "2023-07-22T00:55:25.996Z",
          "wordCount": null,
          "title": "Detecting deceptive reviews using text classification. (arXiv:2307.10617v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10219",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1\">Zifeng Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jingcheng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jingpei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yan Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tresp_V/0/1/0/all/0/1\">Volker Tresp</a>",
          "description": "Stemming from traditional knowledge graphs (KGs), hyper-relational KGs (HKGs)\nprovide additional key-value pairs (i.e., qualifiers) for each KG fact that\nhelp to better restrict the fact validity. In recent years, there has been an\nincreasing interest in studying graph reasoning over HKGs. In the meantime, due\nto the ever-evolving nature of world knowledge, extensive parallel works have\nbeen focusing on reasoning over temporal KGs (TKGs), where each TKG fact can be\nviewed as a KG fact coupled with a timestamp (or time period) specifying its\ntime validity. The existing HKG reasoning approaches do not consider temporal\ninformation because it is not explicitly specified in previous benchmark\ndatasets. Besides, all the previous TKG reasoning methods only lay emphasis on\ntemporal reasoning and have no way to learn from qualifiers. To this end, we\naim to fill the gap between TKG reasoning and HKG reasoning. We develop two new\nbenchmark hyper-relational TKG (HTKG) datasets, i.e., Wiki-hy and YAGO-hy, and\npropose a HTKG reasoning model that efficiently models both temporal facts and\nqualifiers. We further exploit additional time-invariant relational knowledge\nfrom the Wikidata knowledge base and study its effectiveness in HTKG reasoning.\nTime-invariant relational knowledge serves as the knowledge that remains\nunchanged in time (e.g., Sasha Obama is the child of Barack Obama), and it has\nnever been fully explored in previous TKG reasoning benchmarks and approaches.\nExperimental results show that our model substantially outperforms previous\nrelated methods on HTKG link prediction and can be enhanced by jointly\nleveraging both temporal and time-invariant relational knowledge.",
          "link": "http://arxiv.org/abs/2307.10219",
          "publishedOn": "2023-07-22T00:55:25.995Z",
          "wordCount": null,
          "title": "Exploring Link Prediction over Hyper-Relational Temporal Knowledge Graphs Enhanced with Time-Invariant Relational Knowledge. (arXiv:2307.10219v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.13867",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frieder_S/0/1/0/all/0/1\">Simon Frieder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinchetti_L/0/1/0/all/0/1\">Luca Pinchetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chevalier_A/0/1/0/all/0/1\">Alexis Chevalier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griffiths_R/0/1/0/all/0/1\">Ryan-Rhys Griffiths</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salvatori_T/0/1/0/all/0/1\">Tommaso Salvatori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukasiewicz_T/0/1/0/all/0/1\">Thomas Lukasiewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petersen_P/0/1/0/all/0/1\">Philipp Christian Petersen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berner_J/0/1/0/all/0/1\">Julius Berner</a>",
          "description": "We investigate the mathematical capabilities of two iterations of ChatGPT\n(released 9-January-2023 and 30-January-2023) and of GPT-4 by testing them on\npublicly available datasets, as well as hand-crafted ones, using a novel\nmethodology. In contrast to formal mathematics, where large databases of formal\nproofs are available (e.g., the Lean Mathematical Library), current datasets of\nnatural-language mathematics, used to benchmark language models, either cover\nonly elementary mathematics or are very small. We address this by publicly\nreleasing two new datasets: GHOSTS and miniGHOSTS. These are the first\nnatural-language datasets curated by working researchers in mathematics that\n(1) aim to cover graduate-level mathematics, (2) provide a holistic overview of\nthe mathematical capabilities of language models, and (3) distinguish multiple\ndimensions of mathematical reasoning. These datasets also test whether ChatGPT\nand GPT-4 can be helpful assistants to professional mathematicians by emulating\nuse cases that arise in the daily professional activities of mathematicians. We\nbenchmark the models on a range of fine-grained performance metrics. For\nadvanced mathematics, this is the most detailed evaluation effort to date. We\nfind that ChatGPT can be used most successfully as a mathematical assistant for\nquerying facts, acting as a mathematical search engine and knowledge base\ninterface. GPT-4 can additionally be used for undergraduate-level mathematics\nbut fails on graduate-level difficulty. Contrary to many positive reports in\nthe media about GPT-4 and ChatGPT's exam-solving abilities (a potential case of\nselection bias), their overall mathematical performance is well below the level\nof a graduate student. Hence, if your goal is to use ChatGPT to pass a\ngraduate-level math exam, you would be better off copying from your average\npeer!",
          "link": "http://arxiv.org/abs/2301.13867",
          "publishedOn": "2023-07-22T00:55:25.993Z",
          "wordCount": null,
          "title": "Mathematical Capabilities of ChatGPT. (arXiv:2301.13867v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10845",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cong_W/0/1/0/all/0/1\">Wei Cong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cong_Y/0/1/0/all/0/1\">Yang Cong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_G/0/1/0/all/0/1\">Gan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jiahua Dong</a>",
          "description": "Continual learning algorithms which keep the parameters of new tasks close to\nthat of previous tasks, are popular in preventing catastrophic forgetting in\nsequential task learning settings. However, 1) the performance for the new\ncontinual learner will be degraded without distinguishing the contributions of\npreviously learned tasks; 2) the computational cost will be greatly increased\nwith the number of tasks, since most existing algorithms need to regularize all\nprevious tasks when learning new tasks. To address the above challenges, we\npropose a self-paced Weight Consolidation (spWC) framework to attain robust\ncontinual learning via evaluating the discriminative contributions of previous\ntasks. To be specific, we develop a self-paced regularization to reflect the\npriorities of past tasks via measuring difficulty based on key performance\nindicator (i.e., accuracy). When encountering a new task, all previous tasks\nare sorted from \"difficult\" to \"easy\" based on the priorities. Then the\nparameters of the new continual learner will be learned via selectively\nmaintaining the knowledge amongst more difficult past tasks, which could well\novercome catastrophic forgetting with less computational cost. We adopt an\nalternative convex search to iteratively update the model parameters and\npriority weights in the bi-convex formulation. The proposed spWC framework is\nplug-and-play, which is applicable to most continual learning algorithms (e.g.,\nEWC, MAS and RCIL) in different directions (e.g., classification and\nsegmentation). Experimental results on several public benchmark datasets\ndemonstrate that our proposed framework can effectively improve performance\nwhen compared with other popular continual learning algorithms.",
          "link": "http://arxiv.org/abs/2307.10845",
          "publishedOn": "2023-07-22T00:55:25.992Z",
          "wordCount": null,
          "title": "Self-paced Weight Consolidation for Continual Learning. (arXiv:2307.10845v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10550",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Daegyeom Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1\">Seongho Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yong-Hoon Choi</a>",
          "description": "Expressive speech synthesis models are trained by adding corpora with diverse\nspeakers, various emotions, and different speaking styles to the dataset, in\norder to control various characteristics of speech and generate the desired\nvoice. In this paper, we propose a style control (SC) VALL-E model based on the\nneural codec language model (called VALL-E), which follows the structure of the\ngenerative pretrained transformer 3 (GPT-3). The proposed SC VALL-E takes input\nfrom text sentences and prompt audio and is designed to generate controllable\nspeech by not simply mimicking the characteristics of the prompt audio but by\ncontrolling the attributes to produce diverse voices. We identify tokens in the\nstyle embedding matrix of the newly designed style network that represent\nattributes such as emotion, speaking rate, pitch, and voice intensity, and\ndesign a model that can control these attributes. To evaluate the performance\nof SC VALL-E, we conduct comparative experiments with three representative\nexpressive speech synthesis models: global style token (GST) Tacotron2,\nvariational autoencoder (VAE) Tacotron2, and original VALL-E. We measure word\nerror rate (WER), F0 voiced error (FVE), and F0 gross pitch error (F0GPE) as\nevaluation metrics to assess the accuracy of generated sentences. For comparing\nthe quality of synthesized speech, we measure comparative mean option score\n(CMOS) and similarity mean option score (SMOS). To evaluate the style control\nability of the generated speech, we observe the changes in F0 and\nmel-spectrogram by modifying the trained tokens. When using prompt audio that\nis not present in the training data, SC VALL-E generates a variety of\nexpressive sounds and demonstrates competitive performance compared to the\nexisting models. Our implementation, pretrained models, and audio samples are\nlocated on GitHub.",
          "link": "http://arxiv.org/abs/2307.10550",
          "publishedOn": "2023-07-22T00:55:25.989Z",
          "wordCount": null,
          "title": "SC VALL-E: Style-Controllable Zero-Shot Text to Speech Synthesizer. (arXiv:2307.10550v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10588",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tayarani_H/0/1/0/all/0/1\">Hanif Tayarani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramadoss_T/0/1/0/all/0/1\">Trisha V. Ramadoss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karanam_V/0/1/0/all/0/1\">Vaishnavi Karanam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tal_G/0/1/0/all/0/1\">Gil Tal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nitta_C/0/1/0/all/0/1\">Christopher Nitta</a>",
          "description": "Energy systems, climate change, and public health are among the primary\nreasons for moving toward electrification in transportation. Transportation\nelectrification is being promoted worldwide to reduce emissions. As a result,\nmany automakers will soon start making only battery electric vehicles (BEVs).\nBEV adoption rates are rising in California, mainly due to climate change and\nair pollution concerns. While great for climate and pollution goals, improperly\nmanaged BEV charging can lead to insufficient charging infrastructure and power\noutages. This study develops a novel Micro Clustering Deep Neural Network\n(MCDNN), an artificial neural network algorithm that is highly effective at\nlearning BEVs trip and charging data to forecast BEV charging events,\ninformation that is essential for electricity load aggregators and utility\nmanagers to provide charging stations and electricity capacity effectively. The\nMCDNN is configured using a robust dataset of trips and charges that occurred\nin California between 2015 and 2020 from 132 BEVs, spanning 5 BEV models for a\ntotal of 1570167 vehicle miles traveled. The numerical findings revealed that\nthe proposed MCDNN is more effective than benchmark approaches in this field,\nsuch as support vector machine, k nearest neighbors, decision tree, and other\nneural network-based models in predicting the charging events.",
          "link": "http://arxiv.org/abs/2307.10588",
          "publishedOn": "2023-07-22T00:55:25.984Z",
          "wordCount": null,
          "title": "Forecasting Battery Electric Vehicle Charging Behavior: A Deep Learning Approach Equipped with Micro-Clustering and SMOTE Techniques. (arXiv:2307.10588v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10738",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yuxin Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zelei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zhuan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Han Yu</a>",
          "description": "Federated learning (FL) has enabled multiple data owners (a.k.a. FL clients)\nto train machine learning models collaboratively without revealing private\ndata. Since the FL server can only engage a limited number of clients in each\ntraining round, FL client selection has become an important research problem.\nExisting approaches generally focus on either enhancing FL model performance or\nenhancing the fair treatment of FL clients. The problem of balancing\nperformance and fairness considerations when selecting FL clients remains open.\nTo address this problem, we propose the Fairness-aware Federated Client\nSelection (FairFedCS) approach. Based on Lyapunov optimization, it dynamically\nadjusts FL clients' selection probabilities by jointly considering their\nreputations, times of participation in FL tasks and contributions to the\nresulting model performance. By not using threshold-based reputation filtering,\nit provides FL clients with opportunities to redeem their reputations after a\nperceived poor performance, thereby further enhancing fair client treatment.\nExtensive experiments based on real-world multimedia datasets show that\nFairFedCS achieves 19.6% higher fairness and 0.73% higher test accuracy on\naverage than the best-performing state-of-the-art approach.",
          "link": "http://arxiv.org/abs/2307.10738",
          "publishedOn": "2023-07-22T00:55:25.984Z",
          "wordCount": null,
          "title": "Fairness-Aware Client Selection for Federated Learning. (arXiv:2307.10738v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10773",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junfei Zhang</a>",
          "description": "Music recommendation systems have emerged as a vital component to enhance\nuser experience and satisfaction for the music streaming services, which\ndominates music consumption. The key challenge in improving these recommender\nsystems lies in comprehending the complexity of music data, specifically for\nthe underpinning music genre classification. The limitations of manual genre\nclassification have highlighted the need for a more advanced system, namely the\nAutomatic Music Genre Classification (AMGC) system. While traditional machine\nlearning techniques have shown potential in genre classification, they heavily\nrely on manually engineered features and feature selection, failing to capture\nthe full complexity of music data. On the other hand, deep learning\nclassification architectures like the traditional Convolutional Neural Networks\n(CNN) are effective in capturing the spatial hierarchies but struggle to\ncapture the temporal dynamics inherent in music data. To address these\nchallenges, this study proposes a novel approach using visual spectrograms as\ninput, and propose a hybrid model that combines the strength of the Residual\nneural Network (ResNet) and the Gated Recurrent Unit (GRU). This model is\ndesigned to provide a more comprehensive analysis of music data, offering the\npotential to improve the music recommender systems through achieving a more\ncomprehensive analysis of music data and hence potentially more accurate genre\nclassification.",
          "link": "http://arxiv.org/abs/2307.10773",
          "publishedOn": "2023-07-22T00:55:25.983Z",
          "wordCount": null,
          "title": "Music Genre Classification with ResNet and Bi-GRU Using Visual Spectrograms. (arXiv:2307.10773v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10633",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Upadhyay_S/0/1/0/all/0/1\">Shriyash K. Upadhyay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ginsberg_E/0/1/0/all/0/1\">Etan J. Ginsberg</a>",
          "description": "Large Language Models have many methods for solving the same problem. This\nintroduces novel strengths (different methods may work well for different\nproblems) and weaknesses (it may be difficult for users to know which method to\nuse). In this paper, we introduce Multi-Method Self-Training (MMST), where one\nmethod is trained on the filtered outputs of another, allowing us to augment\nthe strengths and ameliorate the weaknesses of each method. Using a 176B\nparameter model trained on both language and code, we show that MMST can 1)\nimprove the less performant method (up to 30%) making the model easier to use,\n2) improve the more performant method (up to 32.2%) making the model more\nperformant, and 3) improve the performance of related but distinct tasks (up to\n10.3%) by improving the ability of the model to generate rationales. We then\nconduct ablation analyses to explore why MMST works. We show that MMST\ngenerates more data than traditional self-training, but the improvement in\nperformance is driven by the use of multiple methods. We also analyze\nprompt-engineering and anti-correlated performance between methods as means of\nmaking MMST more effective. We hope the evidence from our paper motivates\nmachine learning researchers to explore ways in which advances in language\nmodels allow for new forms of training.",
          "link": "http://arxiv.org/abs/2307.10633",
          "publishedOn": "2023-07-22T00:55:25.979Z",
          "wordCount": null,
          "title": "Multi-Method Self-Training: Improving Code Generation With Text, And Vice Versa. (arXiv:2307.10633v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1\">Ziyao Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1\">Yan Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1\">Lixin Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Linghua Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_T/0/1/0/all/0/1\">Tao Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1\">Yongxin Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qiang Yang</a>",
          "description": "SecureBoost is a tree-boosting algorithm leveraging homomorphic encryption to\nprotect data privacy in vertical federated learning setting. It is widely used\nin fields such as finance and healthcare due to its interpretability,\neffectiveness, and privacy-preserving capability. However, SecureBoost suffers\nfrom high computational complexity and risk of label leakage. To harness the\nfull potential of SecureBoost, hyperparameters of SecureBoost should be\ncarefully chosen to strike an optimal balance between utility, efficiency, and\nprivacy. Existing methods either set hyperparameters empirically or\nheuristically, which are far from optimal. To fill this gap, we propose a\nConstrained Multi-Objective SecureBoost (CMOSB) algorithm to find Pareto\noptimal solutions that each solution is a set of hyperparameters achieving\noptimal tradeoff between utility loss, training cost, and privacy leakage. We\ndesign measurements of the three objectives. In particular, the privacy leakage\nis measured using our proposed instance clustering attack. Experimental results\ndemonstrate that the CMOSB yields not only hyperparameters superior to the\nbaseline but also optimal sets of hyperparameters that can support the flexible\nrequirements of FL participants.",
          "link": "http://arxiv.org/abs/2307.10579",
          "publishedOn": "2023-07-22T00:55:25.975Z",
          "wordCount": null,
          "title": "SecureBoost Hyperparameter Tuning via Multi-Objective Federated Learning. (arXiv:2307.10579v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10802",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yiyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_K/0/1/0/all/0/1\">Kaixiong Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaipeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongsheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1\">Wanli Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1\">Xiangyu Yue</a>",
          "description": "Multimodal learning aims to build models that can process and relate\ninformation from multiple modalities. Despite years of development in this\nfield, it still remains challenging to design a unified network for processing\nvarious modalities ($\\textit{e.g.}$ natural language, 2D images, 3D point\nclouds, audio, video, time series, tabular data) due to the inherent gaps among\nthem. In this work, we propose a framework, named Meta-Transformer, that\nleverages a $\\textbf{frozen}$ encoder to perform multimodal perception without\nany paired multimodal training data. In Meta-Transformer, the raw input data\nfrom various modalities are mapped into a shared token space, allowing a\nsubsequent encoder with frozen parameters to extract high-level semantic\nfeatures of the input data. Composed of three main components: a unified data\ntokenizer, a modality-shared encoder, and task-specific heads for downstream\ntasks, Meta-Transformer is the first framework to perform unified learning\nacross 12 modalities with unpaired data. Experiments on different benchmarks\nreveal that Meta-Transformer can handle a wide range of tasks including\nfundamental perception (text, image, point cloud, audio, video), practical\napplication (X-Ray, infrared, hyperspectral, and IMU), and data mining (graph,\ntabular, and time-series). Meta-Transformer indicates a promising future for\ndeveloping unified multimodal intelligence with transformers. Code will be\navailable at https://github.com/invictus717/MetaTransformer",
          "link": "http://arxiv.org/abs/2307.10802",
          "publishedOn": "2023-07-22T00:55:25.971Z",
          "wordCount": null,
          "title": "Meta-Transformer: A Unified Framework for Multimodal Learning. (arXiv:2307.10802v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lai_T/0/1/0/all/0/1\">Tin Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farid_F/0/1/0/all/0/1\">Farnaz Farid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bello_A/0/1/0/all/0/1\">Abubakar Bello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabrina_F/0/1/0/all/0/1\">Fariza Sabrina</a>",
          "description": "The Internet of Things (IoT) integrates more than billions of intelligent\ndevices over the globe with the capability of communicating with other\nconnected devices with little to no human intervention. IoT enables data\naggregation and analysis on a large scale to improve life quality in many\ndomains. In particular, data collected by IoT contain a tremendous amount of\ninformation for anomaly detection. The heterogeneous nature of IoT is both a\nchallenge and an opportunity for cybersecurity. Traditional approaches in\ncybersecurity monitoring often require different kinds of data pre-processing\nand handling for various data types, which might be problematic for datasets\nthat contain heterogeneous features. However, heterogeneous types of network\ndevices can often capture a more diverse set of signals than a single type of\ndevice readings, which is particularly useful for anomaly detection. In this\npaper, we present a comprehensive study on using ensemble machine learning\nmethods for enhancing IoT cybersecurity via anomaly detection. Rather than\nusing one single machine learning model, ensemble learning combines the\npredictive power from multiple models, enhancing their predictive accuracy in\nheterogeneous datasets rather than using one single machine learning model. We\npropose a unified framework with ensemble learning that utilises Bayesian\nhyperparameter optimisation to adapt to a network environment that contains\nmultiple IoT sensor readings. Experimentally, we illustrate their high\npredictive power when compared to traditional methods.",
          "link": "http://arxiv.org/abs/2307.10596",
          "publishedOn": "2023-07-22T00:55:25.970Z",
          "wordCount": null,
          "title": "Ensemble Learning based Anomaly Detection for IoT Cybersecurity via Bayesian Hyperparameters Sensitivity Analysis. (arXiv:2307.10596v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bohdal_O/0/1/0/all/0/1\">Ondrej Bohdal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Da Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hospedales_T/0/1/0/all/0/1\">Timothy Hospedales</a>",
          "description": "Source-free domain adaptation has become popular because of its practical\nusefulness and no need to access source data. However, the adaptation process\nstill takes a considerable amount of time and is predominantly based on\noptimization that relies on back-propagation. In this work we present a simple\nfeed-forward approach that challenges the need for back-propagation based\nadaptation. Our approach is based on computing prototypes of classes under the\ndomain shift using a pre-trained model. It achieves strong improvements in\naccuracy compared to the pre-trained model and requires only a small fraction\nof time of existing domain adaptation methods.",
          "link": "http://arxiv.org/abs/2307.10787",
          "publishedOn": "2023-07-22T00:55:25.968Z",
          "wordCount": null,
          "title": "Feed-Forward Source-Free Domain Adaptation via Class Prototypes. (arXiv:2307.10787v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10317",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kao_C/0/1/0/all/0/1\">Chia-Hsiang Kao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Chiang Frank Wang</a>",
          "description": "Federated Learning (FL) offers a collaborative training framework, allowing\nmultiple clients to contribute to a shared model without compromising data\nprivacy. Due to the heterogeneous nature of local datasets, updated client\nmodels may overfit and diverge from one another, commonly known as the problem\nof client drift. In this paper, we propose FedBug (Federated Learning with\nBottom-Up Gradual Unfreezing), a novel FL framework designed to effectively\nmitigate client drift. FedBug adaptively leverages the client model parameters,\ndistributed by the server at each global round, as the reference points for\ncross-client alignment. Specifically, on the client side, FedBug begins by\nfreezing the entire model, then gradually unfreezes the layers, from the input\nlayer to the output layer. This bottom-up approach allows models to train the\nnewly thawed layers to project data into a latent space, wherein the separating\nhyperplanes remain consistent across all clients. We theoretically analyze\nFedBug in a novel over-parameterization FL setup, revealing its superior\nconvergence rate compared to FedAvg. Through comprehensive experiments,\nspanning various datasets, training conditions, and network architectures, we\nvalidate the efficacy of FedBug. Our contributions encompass a novel FL\nframework, theoretical analysis, and empirical validation, demonstrating the\nwide potential and applicability of FedBug.",
          "link": "http://arxiv.org/abs/2307.10317",
          "publishedOn": "2023-07-22T00:55:25.967Z",
          "wordCount": null,
          "title": "FedBug: A Bottom-Up Gradual Unfreezing Framework for Federated Learning. (arXiv:2307.10317v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10763",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mondal_A/0/1/0/all/0/1\">Anindya Mondal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nag_S/0/1/0/all/0/1\">Sauradip Nag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prada_J/0/1/0/all/0/1\">Joaquin M Prada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiatian Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dutta_A/0/1/0/all/0/1\">Anjan Dutta</a>",
          "description": "Existing action recognition methods are typically actor-specific due to the\nintrinsic topological and apparent differences among the actors. This requires\nactor-specific pose estimation (e.g., humans vs. animals), leading to\ncumbersome model design complexity and high maintenance costs. Moreover, they\noften focus on learning the visual modality alone and single-label\nclassification whilst neglecting other available information sources (e.g.,\nclass name text) and the concurrent occurrence of multiple actions. To overcome\nthese limitations, we propose a new approach called 'actor-agnostic multi-modal\nmulti-label action recognition,' which offers a unified solution for various\ntypes of actors, including humans and animals. We further formulate a novel\nMulti-modal Semantic Query Network (MSQNet) model in a transformer-based object\ndetection framework (e.g., DETR), characterized by leveraging visual and\ntextual modalities to represent the action classes better. The elimination of\nactor-specific model designs is a key advantage, as it removes the need for\nactor pose estimation altogether. Extensive experiments on five publicly\navailable benchmarks show that our MSQNet consistently outperforms the prior\narts of actor-specific alternatives on human and animal single- and multi-label\naction recognition tasks by up to 50%. Code will be released at\nhttps://github.com/mondalanindya/MSQNet.",
          "link": "http://arxiv.org/abs/2307.10763",
          "publishedOn": "2023-07-22T00:55:25.967Z",
          "wordCount": null,
          "title": "MSQNet: Actor-agnostic Action Recognition with Multi-modal Query. (arXiv:2307.10763v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10184",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yudong Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Honglong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_P/0/1/0/all/0/1\">Peng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junjian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Anqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhibo Wang</a>",
          "description": "Backdoor attacks pose serious security threats to deep neural networks\n(DNNs). Backdoored models make arbitrarily (targeted) incorrect predictions on\ninputs embedded with well-designed triggers while behaving normally on clean\ninputs. Many works have explored the invisibility of backdoor triggers to\nimprove attack stealthiness. However, most of them only consider the\ninvisibility in the spatial domain without explicitly accounting for the\ngeneration of invisible triggers in the frequency domain, making the generated\npoisoned images be easily detected by recent defense methods. To address this\nissue, in this paper, we propose a DUal stealthy BAckdoor attack method named\nDUBA, which simultaneously considers the invisibility of triggers in both the\nspatial and frequency domains, to achieve desirable attack performance, while\nensuring strong stealthiness. Specifically, we first use Discrete Wavelet\nTransform to embed the high-frequency information of the trigger image into the\nclean image to ensure attack effectiveness. Then, to attain strong\nstealthiness, we incorporate Fourier Transform and Discrete Cosine Transform to\nmix the poisoned image and clean image in the frequency domain. Moreover, the\nproposed DUBA adopts a novel attack strategy, in which the model is trained\nwith weak triggers and attacked with strong triggers to further enhance the\nattack performance and stealthiness. We extensively evaluate DUBA against\npopular image classifiers on four datasets. The results demonstrate that it\nsignificantly outperforms the state-of-the-art backdoor attacks in terms of the\nattack success rate and stealthiness",
          "link": "http://arxiv.org/abs/2307.10184",
          "publishedOn": "2023-07-22T00:55:25.962Z",
          "wordCount": null,
          "title": "A Dual Stealthy Backdoor: From Both Spatial and Frequency Perspectives. (arXiv:2307.10184v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10864",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yumeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keuper_M/0/1/0/all/0/1\">Margret Keuper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khoreva_A/0/1/0/all/0/1\">Anna Khoreva</a>",
          "description": "Emerging large-scale text-to-image generative models, e.g., Stable Diffusion\n(SD), have exhibited overwhelming results with high fidelity. Despite the\nmagnificent progress, current state-of-the-art models still struggle to\ngenerate images fully adhering to the input prompt. Prior work, Attend &\nExcite, has introduced the concept of Generative Semantic Nursing (GSN), aiming\nto optimize cross-attention during inference time to better incorporate the\nsemantics. It demonstrates promising results in generating simple prompts,\ne.g., ``a cat and a dog''. However, its efficacy declines when dealing with\nmore complex prompts, and it does not explicitly address the problem of\nimproper attribute binding. To address the challenges posed by complex prompts\nor scenarios involving multiple entities and to achieve improved attribute\nbinding, we propose Divide & Bind. We introduce two novel loss objectives for\nGSN: a novel attendance loss and a binding loss. Our approach stands out in its\nability to faithfully synthesize desired objects with improved attribute\nalignment from complex prompts and exhibits superior performance across\nmultiple evaluation benchmarks. More videos and updates can be found on the\nproject page \\url{https://sites.google.com/view/divide-and-bind}.",
          "link": "http://arxiv.org/abs/2307.10864",
          "publishedOn": "2023-07-22T00:55:25.961Z",
          "wordCount": null,
          "title": "Divide & Bind Your Attention for Improved Generative Semantic Nursing. (arXiv:2307.10864v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10504",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kalibhat_N/0/1/0/all/0/1\">Neha Kalibhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhardwaj_S/0/1/0/all/0/1\">Shweta Bhardwaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruss_B/0/1/0/all/0/1\">Bayan Bruss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Firooz_H/0/1/0/all/0/1\">Hamed Firooz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanjabi_M/0/1/0/all/0/1\">Maziar Sanjabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1\">Soheil Feizi</a>",
          "description": "We propose Automatic Feature Explanation using Contrasting Concepts (FALCON),\nan interpretability framework to explain features of image representations. For\na target feature, FALCON captions its highly activating cropped images using a\nlarge captioning dataset (like LAION-400m) and a pre-trained vision-language\nmodel like CLIP. Each word among the captions is scored and ranked leading to a\nsmall number of shared, human-understandable concepts that closely describe the\ntarget feature. FALCON also applies contrastive interpretation using lowly\nactivating (counterfactual) images, to eliminate spurious concepts. Although\nmany existing approaches interpret features independently, we observe in\nstate-of-the-art self-supervised and supervised models, that less than 20% of\nthe representation space can be explained by individual features. We show that\nfeatures in larger spaces become more interpretable when studied in groups and\ncan be explained with high-order scoring concepts through FALCON. We discuss\nhow extracted concepts can be used to explain and debug failures in downstream\ntasks. Finally, we present a technique to transfer concepts from one\n(explainable) representation space to another unseen representation space by\nlearning a simple linear transformation.",
          "link": "http://arxiv.org/abs/2307.10504",
          "publishedOn": "2023-07-22T00:55:25.959Z",
          "wordCount": null,
          "title": "Identifying Interpretable Subspaces in Image Representations. (arXiv:2307.10504v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10436",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Piyush_V/0/1/0/all/0/1\">Ved Piyush</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yan_Y/0/1/0/all/0/1\">Yuchen Yan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuzhen Zhou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yin_Y/0/1/0/all/0/1\">Yanbin Yin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ghosh_S/0/1/0/all/0/1\">Souparno Ghosh</a>",
          "description": "Deep Learners (DLs) are the state-of-art predictive mechanism with\napplications in many fields requiring complex high dimensional data processing.\nAlthough conventional DLs get trained via gradient descent with\nback-propagation, Kalman Filter (KF)-based techniques that do not need gradient\ncomputation have been developed to approximate DLs. We propose a multi-arm\nextension of a KF-based DL approximator that can mimic DL when the sample size\nis too small to train a multi-arm DL. The proposed Matrix Ensemble Kalman\nFilter-based multi-arm ANN (MEnKF-ANN) also performs explicit model stacking\nthat becomes relevant when the training sample has an unequal-size feature set.\nOur proposed technique can approximate Long Short-term Memory (LSTM) Networks\nand attach uncertainty to the predictions obtained from these LSTMs with\ndesirable coverage. We demonstrate how MEnKF-ANN can \"adequately\" approximate\nan LSTM network trained to classify what carbohydrate substrates are digested\nand utilized by a microbiome sample whose genomic sequences consist of\npolysaccharide utilization loci (PULs) and their encoded genes.",
          "link": "http://arxiv.org/abs/2307.10436",
          "publishedOn": "2023-07-22T00:55:25.958Z",
          "wordCount": null,
          "title": "A Matrix Ensemble Kalman Filter-based Multi-arm Neural Network to Adequately Approximate Deep Neural Networks. (arXiv:2307.10436v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1\">Shaokui Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mingda Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1\">Hongyuan Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Baoyuan Wu</a>",
          "description": "Backdoor attacks are serious security threats to machine learning models\nwhere an adversary can inject poisoned samples into the training set, causing a\nbackdoored model which predicts poisoned samples with particular triggers to\nparticular target classes, while behaving normally on benign samples. In this\npaper, we explore the task of purifying a backdoored model using a small clean\ndataset. By establishing the connection between backdoor risk and adversarial\nrisk, we derive a novel upper bound for backdoor risk, which mainly captures\nthe risk on the shared adversarial examples (SAEs) between the backdoored model\nand the purified model. This upper bound further suggests a novel bi-level\noptimization problem for mitigating backdoor using adversarial training\ntechniques. To solve it, we propose Shared Adversarial Unlearning (SAU).\nSpecifically, SAU first generates SAEs, and then, unlearns the generated SAEs\nsuch that they are either correctly classified by the purified model and/or\ndifferently classified by the two models, such that the backdoor effect in the\nbackdoored model will be mitigated in the purified model. Experiments on\nvarious benchmark datasets and network architectures show that our proposed\nmethod achieves state-of-the-art performance for backdoor defense.",
          "link": "http://arxiv.org/abs/2307.10562",
          "publishedOn": "2023-07-22T00:55:25.957Z",
          "wordCount": null,
          "title": "Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples. (arXiv:2307.10562v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10314",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahajebin_M/0/1/0/all/0/1\">Maliha Mahajebin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rashid_M/0/1/0/all/0/1\">Mohammad Rifat Ahmmad Rashid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansoor_N/0/1/0/all/0/1\">Nafees Mansoor</a>",
          "description": "Music can evoke various emotions, and with the advancement of technology, it\nhas become more accessible to people. Bangla music, which portrays different\nhuman emotions, lacks sufficient research. The authors of this article aim to\nanalyze Bangla songs and classify their moods based on the lyrics. To achieve\nthis, this research has compiled a dataset of 4000 Bangla song lyrics, genres,\nand used Natural Language Processing and the Bert Algorithm to analyze the\ndata. Among the 4000 songs, 1513 songs are represented for the sad mood, 1362\nfor the romantic mood, 886 for happiness, and the rest 239 are classified as\nrelaxation. By embedding the lyrics of the songs, the authors have classified\nthe songs into four moods: Happy, Sad, Romantic, and Relaxed. This research is\ncrucial as it enables a multi-class classification of songs' moods, making the\nmusic more relatable to people's emotions. The article presents the automated\nresult of the four moods accurately derived from the song lyrics.",
          "link": "http://arxiv.org/abs/2307.10314",
          "publishedOn": "2023-07-22T00:55:25.952Z",
          "wordCount": null,
          "title": "Mood Classification of Bangla Songs Based on Lyrics. (arXiv:2307.10314v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10524",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tongxin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yiheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Shaolei Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wierman_A/0/1/0/all/0/1\">Adam Wierman</a>",
          "description": "We study the tradeoff between consistency and robustness in the context of a\nsingle-trajectory time-varying Markov Decision Process (MDP) with untrusted\nmachine-learned advice. Our work departs from the typical approach of treating\nadvice as coming from black-box sources by instead considering a setting where\nadditional information about how the advice is generated is available. We prove\na first-of-its-kind consistency and robustness tradeoff given Q-value advice\nunder a general MDP model that includes both continuous and discrete\nstate/action spaces. Our results highlight that utilizing Q-value advice\nenables dynamic pursuit of the better of machine-learned advice and a robust\nbaseline, thus result in near-optimal performance guarantees, which provably\nimproves what can be obtained solely with black-box advice.",
          "link": "http://arxiv.org/abs/2307.10524",
          "publishedOn": "2023-07-22T00:55:25.931Z",
          "wordCount": null,
          "title": "Beyond Black-Box Advice: Learning-Augmented Algorithms for MDPs with Q-Value Predictions. (arXiv:2307.10524v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghauri_J/0/1/0/all/0/1\">Junaid Ahmed Ghauri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_Budack_E/0/1/0/all/0/1\">Eric M&#xfc;ller-Budack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ewerth_R/0/1/0/all/0/1\">Ralph Ewerth</a>",
          "description": "Due to the swift growth of patent applications each year, information and\nmultimedia retrieval approaches that facilitate patent exploration and\nretrieval are of utmost importance. Different types of visualizations (e.g.,\ngraphs, technical drawings) and perspectives (e.g., side view, perspective) are\nused to visualize details of innovations in patents. The classification of\nthese images enables a more efficient search and allows for further analysis.\nSo far, datasets for image type classification miss some important\nvisualization types for patents. Furthermore, related work does not make use of\nrecent deep learning approaches including transformers. In this paper, we adopt\nstate-of-the-art deep learning methods for the classification of visualization\ntypes and perspectives in patent images. We extend the CLEF-IP dataset for\nimage type classification in patents to ten classes and provide manual ground\ntruth annotations. In addition, we derive a set of hierarchical classes from a\ndataset that provides weakly-labeled data for image perspectives. Experimental\nresults have demonstrated the feasibility of the proposed approaches. Source\ncode, models, and dataset will be made publicly available.",
          "link": "http://arxiv.org/abs/2307.10471",
          "publishedOn": "2023-07-22T00:55:25.914Z",
          "wordCount": null,
          "title": "Classification of Visualization Types and Perspectives in Patents. (arXiv:2307.10471v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10246",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Oota_S/0/1/0/all/0/1\">Subba Reddy Oota</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Gupta_M/0/1/0/all/0/1\">Manish Gupta</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bapi_R/0/1/0/all/0/1\">Raju S. Bapi</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Jobard_G/0/1/0/all/0/1\">Gael Jobard</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Alexandre_F/0/1/0/all/0/1\">Frederic Alexandre</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hinaut_X/0/1/0/all/0/1\">Xavier Hinaut</a>",
          "description": "How does the brain represent different modes of information? Can we design a\nsystem that automatically understands what the user is thinking? Such questions\ncan be answered by studying brain recordings like functional magnetic resonance\nimaging (fMRI). As a first step, the neuroscience community has contributed\nseveral large cognitive neuroscience datasets related to passive\nreading/listening/viewing of concept words, narratives, pictures and movies.\nEncoding and decoding models using these datasets have also been proposed in\nthe past two decades. These models serve as additional tools for basic research\nin cognitive science and neuroscience. Encoding models aim at generating fMRI\nbrain representations given a stimulus automatically. They have several\npractical applications in evaluating and diagnosing neurological conditions and\nthus also help design therapies for brain damage. Decoding models solve the\ninverse problem of reconstructing the stimuli given the fMRI. They are useful\nfor designing brain-machine or brain-computer interfaces. Inspired by the\neffectiveness of deep learning models for natural language processing, computer\nvision, and speech, recently several neural encoding and decoding models have\nbeen proposed. In this survey, we will first discuss popular representations of\nlanguage, vision and speech stimuli, and present a summary of neuroscience\ndatasets. Further, we will review popular deep learning based encoding and\ndecoding architectures and note their benefits and limitations. Finally, we\nwill conclude with a brief summary and discussion about future trends. Given\nthe large amount of recently published work in the `computational cognitive\nneuroscience' community, we believe that this survey nicely organizes the\nplethora of work and presents it as a coherent story.",
          "link": "http://arxiv.org/abs/2307.10246",
          "publishedOn": "2023-07-22T00:55:25.908Z",
          "wordCount": null,
          "title": "Deep Neural Networks and Brain Alignment: Brain Encoding and Decoding (Survey). (arXiv:2307.10246v1 [q-bio.NC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bolatov_A/0/1/0/all/0/1\">Arman Bolatov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tezekbayev_M/0/1/0/all/0/1\">Maxat Tezekbayev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melnykov_I/0/1/0/all/0/1\">Igor Melnykov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pak_A/0/1/0/all/0/1\">Artur Pak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikoulina_V/0/1/0/all/0/1\">Vassilina Nikoulina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Assylbekov_Z/0/1/0/all/0/1\">Zhenisbek Assylbekov</a>",
          "description": "We suggest a simple Gaussian mixture model for data generation that complies\nwith Feldman's long tail theory (2020). We demonstrate that a linear classifier\ncannot decrease the generalization error below a certain level in the proposed\nmodel, whereas a nonlinear classifier with a memorization capacity can. This\nconfirms that for long-tailed distributions, rare training examples must be\nconsidered for optimal generalization to new data. Finally, we show that the\nperformance gap between linear and nonlinear models can be lessened as the tail\nbecomes shorter in the subpopulation frequency distribution, as confirmed by\nexperiments on synthetic and real data.",
          "link": "http://arxiv.org/abs/2307.10736",
          "publishedOn": "2023-07-22T00:55:25.907Z",
          "wordCount": null,
          "title": "Long-Tail Theory under Gaussian Mixtures. (arXiv:2307.10736v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10843",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahimi_R/0/1/0/all/0/1\">Reyhaneh Rahimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ebtehaj_A/0/1/0/all/0/1\">Ardeshir Ebtehaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Behrangi_A/0/1/0/all/0/1\">Ali Behrangi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1\">Jackson Tan</a>",
          "description": "This paper presents a deep learning architecture for nowcasting of\nprecipitation almost globally every 30 min with a 4-hour lead time. The\narchitecture fuses a U-Net and a convolutional long short-term memory (LSTM)\nneural network and is trained using data from the Integrated MultisatellitE\nRetrievals for GPM (IMERG) and a few key precipitation drivers from the Global\nForecast System (GFS). The impacts of different training loss functions,\nincluding the mean-squared error (regression) and the focal-loss\n(classification), on the quality of precipitation nowcasts are studied. The\nresults indicate that the regression network performs well in capturing light\nprecipitation (below 1.6 mm/hr), but the classification network can outperform\nthe regression network for nowcasting of precipitation extremes (>8 mm/hr), in\nterms of the critical success index (CSI).. Using the Wasserstein distance, it\nis shown that the predicted precipitation by the classification network has a\ncloser class probability distribution to the IMERG than the regression network.\nIt is uncovered that the inclusion of the physical variables can improve\nprecipitation nowcasting, especially at longer lead times in both networks.\nTaking IMERG as a relative reference, a multi-scale analysis in terms of\nfractions skill score (FSS), shows that the nowcasting machine remains skillful\n(FSS > 0.5) at the resolution of 10 km compared to 50 km for GFS. For\nprecipitation rates greater than 4~mm/hr, only the classification network\nremains FSS-skillful on scales greater than 50 km within a 2-hour lead time.",
          "link": "http://arxiv.org/abs/2307.10843",
          "publishedOn": "2023-07-22T00:55:25.906Z",
          "wordCount": null,
          "title": "Global Precipitation Nowcasting of Integrated Multi-satellitE Retrievals for GPM: A U-Net Convolutional LSTM Architecture. (arXiv:2307.10843v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kong_F/0/1/0/all/0/1\">Fang Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuai Li</a>",
          "description": "The problem of matching markets has been studied for a long time in the\nliterature due to its wide range of applications. Finding a stable matching is\na common equilibrium objective in this problem. Since market participants are\nusually uncertain of their preferences, a rich line of recent works study the\nonline setting where one-side participants (players) learn their unknown\npreferences from iterative interactions with the other side (arms). Most\nprevious works in this line are only able to derive theoretical guarantees for\nplayer-pessimal stable regret, which is defined compared with the players'\nleast-preferred stable matching. However, under the pessimal stable matching,\nplayers only obtain the least reward among all stable matchings. To maximize\nplayers' profits, player-optimal stable matching would be the most desirable.\nThough \\citet{basu21beyond} successfully bring an upper bound for\nplayer-optimal stable regret, their result can be exponentially large if\nplayers' preference gap is small. Whether a polynomial guarantee for this\nregret exists is a significant but still open problem. In this work, we provide\na new algorithm named explore-then-Gale-Shapley (ETGS) and show that the\noptimal stable regret of each player can be upper bounded by $O(K\\log\nT/\\Delta^2)$ where $K$ is the number of arms, $T$ is the horizon and $\\Delta$\nis the players' minimum preference gap among the first $N+1$-ranked arms. This\nresult significantly improves previous works which either have a weaker\nplayer-pessimal stable matching objective or apply only to markets with special\nassumptions. When the preferences of participants satisfy some special\nconditions, our regret upper bound also matches the previously derived lower\nbound.",
          "link": "http://arxiv.org/abs/2307.10890",
          "publishedOn": "2023-07-22T00:55:25.906Z",
          "wordCount": null,
          "title": "Player-optimal Stable Regret for Bandit Learning in Matching Markets. (arXiv:2307.10890v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.15382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Whittaker_T/0/1/0/all/0/1\">Tim Whittaker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Janik_R/0/1/0/all/0/1\">Romuald A. Janik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oz_Y/0/1/0/all/0/1\">Yaron Oz</a>",
          "description": "Chaos and turbulence are complex physical phenomena, yet a precise definition\nof the complexity measure that quantifies them is still lacking. In this work\nwe consider the relative complexity of chaos and turbulence from the\nperspective of deep neural networks. We analyze a set of classification\nproblems, where the network has to distinguish images of fluid profiles in the\nturbulent regime from other classes of images such as fluid profiles in the\nchaotic regime, various constructions of noise and real world images. We\nanalyze incompressible as well as weakly compressible fluid flows. We quantify\nthe complexity of the computation performed by the network via the intrinsic\ndimensionality of the internal feature representations, and calculate the\neffective number of independent features which the network uses in order to\ndistinguish between classes. In addition to providing a numerical estimate of\nthe complexity of the computation, the measure also characterizes the neural\nnetwork processing at intermediate and final stages. We construct adversarial\nexamples and use them to identify the two point correlation spectra for the\nchaotic and turbulent vorticity as the feature used by the network for\nclassification.",
          "link": "http://arxiv.org/abs/2211.15382",
          "publishedOn": "2023-07-22T00:55:25.905Z",
          "wordCount": null,
          "title": "Neural Network Complexity of Chaos and Turbulence. (arXiv:2211.15382v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10768",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Sikarwar_A/0/1/0/all/0/1\">Ankur Sikarwar</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_M/0/1/0/all/0/1\">Mengmi Zhang</a>",
          "description": "Working memory (WM), a fundamental cognitive process facilitating the\ntemporary storage, integration, manipulation, and retrieval of information,\nplays a vital role in reasoning and decision-making tasks. Robust benchmark\ndatasets that capture the multifaceted nature of WM are crucial for the\neffective development and evaluation of AI WM models. Here, we introduce a\ncomprehensive Working Memory (WorM) benchmark dataset for this purpose. WorM\ncomprises 10 tasks and a total of 1 million trials, assessing 4\nfunctionalities, 3 domains, and 11 behavioral and neural characteristics of WM.\nWe jointly trained and tested state-of-the-art recurrent neural networks and\ntransformers on all these tasks. We also include human behavioral benchmarks as\nan upper bound for comparison. Our results suggest that AI models replicate\nsome characteristics of WM in the brain, most notably primacy and recency\neffects, and neural clusters and correlates specialized for different domains\nand functionalities of WM. In the experiments, we also reveal some limitations\nin existing models to approximate human behavior. This dataset serves as a\nvaluable resource for communities in cognitive psychology, neuroscience, and\nAI, offering a standardized framework to compare and enhance WM models,\ninvestigate WM's neural underpinnings, and develop WM models with human-like\ncapabilities. Our source code and data are available at\nhttps://github.com/ZhangLab-DeepNeuroCogLab/WorM.",
          "link": "http://arxiv.org/abs/2307.10768",
          "publishedOn": "2023-07-22T00:55:25.904Z",
          "wordCount": null,
          "title": "Decoding the Enigma: Benchmarking Humans and AIs on the Many Facets of Working Memory. (arXiv:2307.10768v1 [q-bio.NC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10788",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heredia_L/0/1/0/all/0/1\">Lucas Gnecco Heredia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Negrevergne_B/0/1/0/all/0/1\">Benjamin Negrevergne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chevaleyre_Y/0/1/0/all/0/1\">Yann Chevaleyre</a>",
          "description": "Mixtures of classifiers (a.k.a. randomized ensembles) have been proposed as a\nway to improve robustness against adversarial attacks. However, it has been\nshown that existing attacks are not well suited for this kind of classifiers.\nIn this paper, we discuss the problem of attacking a mixture in a principled\nway and introduce two desirable properties of attacks based on a geometrical\nanalysis of the problem (effectiveness and maximality). We then show that\nexisting attacks do not meet both of these properties. Finally, we introduce a\nnew attack called lattice climber attack with theoretical guarantees on the\nbinary linear setting, and we demonstrate its performance by conducting\nexperiments on synthetic and real datasets.",
          "link": "http://arxiv.org/abs/2307.10788",
          "publishedOn": "2023-07-22T00:55:25.903Z",
          "wordCount": null,
          "title": "Adversarial attacks for mixtures of classifiers. (arXiv:2307.10788v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10177",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Chakraborty_A/0/1/0/all/0/1\">Abhisek Chakraborty</a>",
          "description": "Advances in neuroscience have enabled researchers to measure the activities\nof large numbers of neurons simultaneously in behaving animals. We have access\nto the fluorescence of each of the neurons which provides a first-order\napproximation of the neural activity over time. Determining the exact spike of\na neuron from this fluorescence trace constitutes an active area of research\nwithin the field of computational neuroscience. We propose a novel Bayesian\napproach based on a mixture of half-non-local prior densities and point masses\nfor this task. Instead of a computationally expensive MCMC algorithm, we adopt\na stochastic search-based approach that is capable of taking advantage of\nmodern computing environments often equipped with multiple processors, to\nexplore all possible arrangements of spikes and lack thereof in an observed\nspike train. It then reports the highest posterior probability arrangement of\nspikes and posterior probability for a spike at each location of the spike\ntrain. Our proposals lead to substantial improvements over existing proposals\nbased on L1 regularization, and enjoy comparable estimation accuracy to the\nstate-of-the-art L0 proposal, in simulations, and on recent calcium imaging\ndata sets. Notably, contrary to optimization-based frequentist approaches, our\nmethodology yields automatic uncertainty quantification associated with the\nspike-train inference.",
          "link": "http://arxiv.org/abs/2307.10177",
          "publishedOn": "2023-07-22T00:55:25.902Z",
          "wordCount": null,
          "title": "Bayesian Spike Train Inference via Non-Local Priors. (arXiv:2307.10177v1 [q-bio.NC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10234",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kheiri_K/0/1/0/all/0/1\">Kiana Kheiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karimi_H/0/1/0/all/0/1\">Hamid Karimi</a>",
          "description": "This study presents a thorough examination of various Generative Pretrained\nTransformer (GPT) methodologies in sentiment analysis, specifically in the\ncontext of Task 4 on the SemEval 2017 dataset. Three primary strategies are\nemployed: 1) prompt engineering using the advanced GPT-3.5 Turbo, 2)\nfine-tuning GPT models, and 3) an inventive approach to embedding\nclassification. The research yields detailed comparative insights among these\nstrategies and individual GPT models, revealing their unique strengths and\npotential limitations. Additionally, the study compares these GPT-based\nmethodologies with other contemporary, high-performing models previously used\nwith the same dataset. The results illustrate the significant superiority of\nthe GPT approaches in terms of predictive performance, more than 22% in\nF1-score compared to the state-of-the-art. Further, the paper addresses common\nchallenges in sentiment analysis tasks, such as understanding context and\ndetecting sarcasm. It underscores the enhanced capabilities of the GPT models\nto effectively navigate these complexities. Collectively, these findings\nhighlight the promising potential of GPT models in sentiment analysis, setting\nthe stage for future research in this field. The code can be found at\nhttps://github.com/DSAatUSU/SentimentGPT.",
          "link": "http://arxiv.org/abs/2307.10234",
          "publishedOn": "2023-07-22T00:55:25.902Z",
          "wordCount": null,
          "title": "SentimentGPT: Exploiting GPT for Advanced Sentiment Analysis and its Departure from Current Machine Learning. (arXiv:2307.10234v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10348",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Martinez_P/0/1/0/all/0/1\">Pablo Antonio Mart&#xed;nez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernabe_G/0/1/0/all/0/1\">Gregorio Bernab&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_J/0/1/0/all/0/1\">Jos&#xe9; Manuel Garc&#xed;a</a>",
          "description": "Large language models (LLMs) have been massively applied to many tasks, often\nsurpassing state-of-the-art approaches. While their effectiveness in code\ngeneration has been extensively studied (e.g., AlphaCode), their potential for\ncode detection remains unexplored.\n\nThis work presents the first analysis of code detection using LLMs. Our study\nexamines essential kernels, including matrix multiplication, convolution, and\nfast-fourier transform, implemented in C/C++. We propose both a preliminary,\nnaive prompt and a novel prompting strategy for code detection.\n\nResults reveal that conventional prompting achieves great precision but poor\naccuracy (68.8%, 22.3%, and 79.2% for GEMM, convolution, and FFT, respectively)\ndue to a high number of false positives. Our novel prompting strategy\nsubstantially reduces false positives, resulting in excellent overall accuracy\n(91.1%, 97.9%, and 99.7%, respectively). These results pose a considerable\nchallenge to existing state-of-the-art code detection methods.",
          "link": "http://arxiv.org/abs/2307.10348",
          "publishedOn": "2023-07-22T00:55:25.901Z",
          "wordCount": null,
          "title": "Code Detection for Hardware Acceleration Using Large Language Models. (arXiv:2307.10348v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1\">Vinayak Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bedathur_S/0/1/0/all/0/1\">Srikanta Bedathur</a>",
          "description": "Human beings always engage in a vast range of activities and tasks that\ndemonstrate their ability to adapt to different scenarios. Any human activity\ncan be represented as a temporal sequence of actions performed to achieve a\ncertain goal. Unlike the time series datasets extracted from electronics or\nmachines, these action sequences are highly disparate in their nature -- the\ntime to finish a sequence of actions can vary between different persons.\nTherefore, understanding the dynamics of these sequences is essential for many\ndownstream tasks such as activity length prediction, goal prediction, next\naction recommendation, etc. Existing neural network-based approaches that learn\na continuous-time activity sequence (or CTAS) are limited to the presence of\nonly visual data or are designed specifically for a particular task, i.e.,\nlimited to next action or goal prediction. In this paper, we present ProActive,\na neural marked temporal point process (MTPP) framework for modeling the\ncontinuous-time distribution of actions in an activity sequence while\nsimultaneously addressing three high-impact problems -- next action prediction,\nsequence-goal prediction, and end-to-end sequence generation. Specifically, we\nutilize a self-attention module with temporal normalizing flows to model the\ninfluence and the inter-arrival times between actions in a sequence. In\naddition, we propose a novel addition over the ProActive model that can handle\nvariations in the order of actions, i.e., different methods of achieving a\ngiven goal. We demonstrate that this variant can learn the order in which the\nperson or actor prefers to do their actions. Extensive experiments on sequences\nderived from three activity recognition datasets show the significant accuracy\nboost of ProActive over the state-of-the-art in terms of action and goal\nprediction, and the first-ever application of end-to-end action sequence\ngeneration.",
          "link": "http://arxiv.org/abs/2307.10305",
          "publishedOn": "2023-07-22T00:55:25.900Z",
          "wordCount": null,
          "title": "Tapestry of Time and Actions: Modeling Human Activity Sequences using Temporal Point Process Flows. (arXiv:2307.10305v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10644",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nielsen_F/0/1/0/all/0/1\">Frank Nielsen</a>",
          "description": "Data sets of multivariate normal distributions abound in many scientific\nareas like diffusion tensor imaging, structure tensor computer vision, radar\nsignal processing, machine learning, just to name a few. In order to process\nthose normal data sets for downstream tasks like filtering, classification or\nclustering, one needs to define proper notions of dissimilarities between\nnormals and paths joining them. The Fisher-Rao distance defined as the\nRiemannian geodesic distance induced by the Fisher information metric is such a\nprincipled metric distance which however is not known in closed-form excepts\nfor a few particular cases. In this work, we first report a fast and robust\nmethod to approximate arbitrarily finely the Fisher-Rao distance between\nmultivariate normal distributions. Second, we introduce a class of distances\nbased on diffeomorphic embeddings of the normal manifold into a submanifold of\nthe higher-dimensional symmetric positive-definite cone corresponding to the\nmanifold of centered normal distributions. We show that the projective Hilbert\ndistance on the cone yields a metric on the embedded normal submanifold and we\npullback that cone distance with its associated straight line Hilbert cone\ngeodesics to obtain a distance and smooth paths between normal distributions.\nCompared to the Fisher-Rao distance approximation, the pullback Hilbert cone\ndistance is computationally light since it requires to compute only the extreme\nminimal and maximal eigenvalues of matrices. Finally, we show how to use those\ndistances in clustering tasks.",
          "link": "http://arxiv.org/abs/2307.10644",
          "publishedOn": "2023-07-22T00:55:25.900Z",
          "wordCount": null,
          "title": "Fisher-Rao distance and pullback SPD cone distances between multivariate normal distributions. (arXiv:2307.10644v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10422",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Zhihan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xingjian Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Boran Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xiaoyong Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maddix_D/0/1/0/all/0/1\">Danielle Maddix</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuyang Wang</a>",
          "description": "Earth system forecasting has traditionally relied on complex physical models\nthat are computationally expensive and require significant domain expertise. In\nthe past decade, the unprecedented increase in spatiotemporal Earth observation\ndata has enabled data-driven forecasting models using deep learning techniques.\nThese models have shown promise for diverse Earth system forecasting tasks but\neither struggle with handling uncertainty or neglect domain-specific prior\nknowledge, resulting in averaging possible futures to blurred forecasts or\ngenerating physically implausible predictions. To address these limitations, we\npropose a two-stage pipeline for probabilistic spatiotemporal forecasting: 1)\nWe develop PreDiff, a conditional latent diffusion model capable of\nprobabilistic forecasts. 2) We incorporate an explicit knowledge control\nmechanism to align forecasts with domain-specific physical constraints. This is\nachieved by estimating the deviation from imposed constraints at each denoising\nstep and adjusting the transition distribution accordingly. We conduct\nempirical studies on two datasets: N-body MNIST, a synthetic dataset with\nchaotic behavior, and SEVIR, a real-world precipitation nowcasting dataset.\nSpecifically, we impose the law of conservation of energy in N-body MNIST and\nanticipated precipitation intensity in SEVIR. Experiments demonstrate the\neffectiveness of PreDiff in handling uncertainty, incorporating domain-specific\nprior knowledge, and generating forecasts that exhibit high operational\nutility.",
          "link": "http://arxiv.org/abs/2307.10422",
          "publishedOn": "2023-07-22T00:55:25.899Z",
          "wordCount": null,
          "title": "PreDiff: Precipitation Nowcasting with Latent Diffusion Models. (arXiv:2307.10422v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10256",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Raghavan_A/0/1/0/all/0/1\">Aditya Raghavan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Troia_F/0/1/0/all/0/1\">Fabio Di Troia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stamp_M/0/1/0/all/0/1\">Mark Stamp</a>",
          "description": "Effective and efficient malware detection is at the forefront of research\ninto building secure digital systems. As with many other fields, malware\ndetection research has seen a dramatic increase in the application of machine\nlearning algorithms. One machine learning technique that has been used widely\nin the field of pattern matching in general-and malware detection in\nparticular-is hidden Markov models (HMMs). HMM training is based on a hill\nclimb, and hence we can often improve a model by training multiple times with\ndifferent initial values. In this research, we compare boosted HMMs (using\nAdaBoost) to HMMs trained with multiple random restarts, in the context of\nmalware detection. These techniques are applied to a variety of challenging\nmalware datasets. We find that random restarts perform surprisingly well in\ncomparison to boosting. Only in the most difficult \"cold start\" cases (where\ntraining data is severely limited) does boosting appear to offer sufficient\nimprovement to justify its higher computational cost in the scoring phase.",
          "link": "http://arxiv.org/abs/2307.10256",
          "publishedOn": "2023-07-22T00:55:25.895Z",
          "wordCount": null,
          "title": "Hidden Markov Models with Random Restarts vs Boosting for Malware Detection. (arXiv:2307.10256v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10260",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Svabensky_V/0/1/0/all/0/1\">Valdemar &#x160;v&#xe1;bensk&#xfd;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vykopal_J/0/1/0/all/0/1\">Jan Vykopal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celeda_P/0/1/0/all/0/1\">Pavel &#x10c;eleda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tkacik_K/0/1/0/all/0/1\">Kristi&#xe1;n Tk&#xe1;&#x10d;ik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popovic_D/0/1/0/all/0/1\">Daniel Popovi&#x10d;</a>",
          "description": "Hands-on cybersecurity training allows students and professionals to practice\nvarious tools and improve their technical skills. The training occurs in an\ninteractive learning environment that enables completing sophisticated tasks in\nfull-fledged operating systems, networks, and applications. During the\ntraining, the learning environment allows collecting data about trainees'\ninteractions with the environment, such as their usage of command-line tools.\nThese data contain patterns indicative of trainees' learning processes, and\nrevealing them allows to assess the trainees and provide feedback to help them\nlearn. However, automated analysis of these data is challenging. The training\ntasks feature complex problem-solving, and many different solution approaches\nare possible. Moreover, the trainees generate vast amounts of interaction data.\nThis paper explores a dataset from 18 cybersecurity training sessions using\ndata mining and machine learning techniques. We employed pattern mining and\nclustering to analyze 8834 commands collected from 113 trainees, revealing\ntheir typical behavior, mistakes, solution strategies, and difficult training\nstages. Pattern mining proved suitable in capturing timing information and tool\nusage frequency. Clustering underlined that many trainees often face the same\nissues, which can be addressed by targeted scaffolding. Our results show that\ndata mining methods are suitable for analyzing cybersecurity training data.\nEducational researchers and practitioners can apply these methods in their\ncontexts to assess trainees, support them, and improve the training design.\nArtifacts associated with this research are publicly available.",
          "link": "http://arxiv.org/abs/2307.10260",
          "publishedOn": "2023-07-22T00:55:25.894Z",
          "wordCount": null,
          "title": "Student Assessment in Cybersecurity Training Automated by Pattern Mining and Clustering. (arXiv:2307.10260v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10350",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thao Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gadre_S/0/1/0/all/0/1\">Samir Yitzhak Gadre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilharco_G/0/1/0/all/0/1\">Gabriel Ilharco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Sewoong Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1\">Ludwig Schmidt</a>",
          "description": "Massive web datasets play a key role in the success of large vision-language\nmodels like CLIP and Flamingo. However, the raw web data is noisy, and existing\nfiltering methods to reduce noise often come at the expense of data diversity.\nOur work focuses on caption quality as one major source of noise, and studies\nhow generated captions can increase the utility of web-scraped datapoints with\nnondescript text. Through exploring different mixing strategies for raw and\ngenerated captions, we outperform the best filtering method proposed by the\nDataComp benchmark by 2% on ImageNet and 4% on average across 38 tasks, given a\ncandidate pool of 128M image-text pairs. Our best approach is also 2x better at\nFlickr and MS-COCO retrieval. We then analyze what makes synthetic captions an\neffective source of text supervision. In experimenting with different image\ncaptioning models, we also demonstrate that the performance of a model on\nstandard image captioning benchmarks (e.g., NoCaps CIDEr) is not a reliable\nindicator of the utility of the captions it generates for multimodal training.\nFinally, our experiments with using generated captions at DataComp's large\nscale (1.28B image-text pairs) offer insights into the limitations of synthetic\ntext, as well as the importance of image curation with increasing training data\nquantity.",
          "link": "http://arxiv.org/abs/2307.10350",
          "publishedOn": "2023-07-22T00:55:25.892Z",
          "wordCount": null,
          "title": "Improving Multimodal Datasets with Image Captioning. (arXiv:2307.10350v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10187",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fay_D/0/1/0/all/0/1\">Dominik Fay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mair_S/0/1/0/all/0/1\">Sebastian Mair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sjolund_J/0/1/0/all/0/1\">Jens Sj&#xf6;lund</a>",
          "description": "We examine the privacy-enhancing properties of subsampling a data set via\nimportance sampling as a pre-processing step for differentially private\nmechanisms. This extends the established privacy amplification by subsampling\nresult to importance sampling where each data point is weighted by the\nreciprocal of its selection probability. The implications for privacy of\nweighting each point are not obvious. On the one hand, a lower selection\nprobability leads to a stronger privacy amplification. On the other hand, the\nhigher the weight, the stronger the influence of the point on the output of the\nmechanism in the event that the point does get selected. We provide a general\nresult that quantifies the trade-off between these two effects. We show that\nheterogeneous sampling probabilities can lead to both stronger privacy and\nbetter utility than uniform subsampling while retaining the subsample size. In\nparticular, we formulate and solve the problem of privacy-optimal sampling,\nthat is, finding the importance weights that minimize the expected subset size\nsubject to a given privacy budget. Empirically, we evaluate the privacy,\nefficiency, and accuracy of importance sampling-based privacy amplification on\nthe example of k-means clustering.",
          "link": "http://arxiv.org/abs/2307.10187",
          "publishedOn": "2023-07-22T00:55:25.890Z",
          "wordCount": null,
          "title": "Privacy Amplification via Importance Sampling. (arXiv:2307.10187v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10460",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brodie_M/0/1/0/all/0/1\">Michael L. Brodie</a>",
          "description": "Data science is not a science. It is a research paradigm with an unfathomed\nscope, scale, complexity, and power for knowledge discovery that is not\notherwise possible and can be beyond human reasoning. It is changing our world\npractically and profoundly already widely deployed in tens of thousands of\napplications in every discipline in an AI Arms Race that, due to its\ninscrutability, can lead to unfathomed risks. This paper presents an axiology\nof data science, its purpose, nature, importance, risks, and value for problem\nsolving, by exploring and evaluating its remarkable, definitive features. As\ndata science is in its infancy, this initial, speculative axiology is intended\nto aid in understanding and defining data science to recognize its potential\nbenefits, risks, and open research challenges. AI based data science is\ninherently about uncertainty that may be more realistic than our preference for\nthe certainty of science. Data science will have impacts far beyond knowledge\ndiscovery and will take us into new ways of understanding the world.",
          "link": "http://arxiv.org/abs/2307.10460",
          "publishedOn": "2023-07-22T00:55:25.886Z",
          "wordCount": null,
          "title": "A data science axiology: the nature, value, and risks of data science. (arXiv:2307.10460v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10204",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oh_K/0/1/0/all/0/1\">Keisho Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nishimura_N/0/1/0/all/0/1\">Naoki Nishimura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_M/0/1/0/all/0/1\">Minje Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kobayashi_K/0/1/0/all/0/1\">Ken Kobayashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakata_K/0/1/0/all/0/1\">Kazuhide Nakata</a>",
          "description": "In modern recommendation systems, unbiased learning-to-rank (LTR) is crucial\nfor prioritizing items from biased implicit user feedback, such as click data.\nSeveral techniques, such as Inverse Propensity Weighting (IPW), have been\nproposed for single-sided markets. However, less attention has been paid to\ntwo-sided markets, such as job platforms or dating services, where successful\nconversions require matching preferences from both users. This paper addresses\nthe complex interaction of biases between users in two-sided markets and\nproposes a tailored LTR approach. We first present a formulation of feedback\nmechanisms in two-sided matching platforms and point out that their implicit\nfeedback may include position bias from both user groups. On the basis of this\nobservation, we extend the IPW estimator and propose a new estimator, named\ntwo-sided IPW, to address the position bases in two-sided markets. We prove\nthat the proposed estimator satisfies the unbiasedness for the ground-truth\nranking metric. We conducted numerical experiments on real-world two-sided\nplatforms and demonstrated the effectiveness of our proposed method in terms of\nboth precision and robustness. Our experiments showed that our method\noutperformed baselines especially when handling rare items, which are less\nfrequently observed in the training data.",
          "link": "http://arxiv.org/abs/2307.10204",
          "publishedOn": "2023-07-22T00:55:25.885Z",
          "wordCount": null,
          "title": "An IPW-based Unbiased Ranking Metric in Two-sided Markets. (arXiv:2307.10204v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10459",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Konstantinov_A/0/1/0/all/0/1\">Andrei V. Konstantinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Utkin_L/0/1/0/all/0/1\">Lev V. Utkin</a>",
          "description": "A new computationally simple method of imposing hard convex constraints on\nthe neural network output values is proposed. The key idea behind the method is\nto map a vector of hidden parameters of the network to a point that is\nguaranteed to be inside the feasible set defined by a set of constraints. The\nmapping is implemented by the additional neural network layer with constraints\nfor output. The proposed method is simply extended to the case when constraints\nare imposed not only on the output vectors, but also on joint constraints\ndepending on inputs. The projection approach to imposing constraints on outputs\ncan simply be implemented in the framework of the proposed method. It is shown\nhow to incorporate different types of constraints into the proposed method,\nincluding linear and quadratic constraints, equality constraints, and dynamic\nconstraints, constraints in the form of boundaries. An important feature of the\nmethod is its computational simplicity. Complexities of the forward pass of the\nproposed neural network layer by linear and quadratic constraints are O(n*m)\nand O(n^2*m), respectively, where n is the number of variables, m is the number\nof constraints. Numerical experiments illustrate the method by solving\noptimization and classification problems. The code implementing the method is\npublicly available.",
          "link": "http://arxiv.org/abs/2307.10459",
          "publishedOn": "2023-07-22T00:55:25.885Z",
          "wordCount": null,
          "title": "A New Computationally Simple Approach for Implementing Neural Networks with Output Hard Constraints. (arXiv:2307.10459v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10438",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Shengli Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_S/0/1/0/all/0/1\">Shiyi Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lehn_R/0/1/0/all/0/1\">Reid C. Van Lehn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balaprakash_P/0/1/0/all/0/1\">Prasanna Balaprakash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zavala_V/0/1/0/all/0/1\">Victor M. Zavala</a>",
          "description": "Graph Neural Networks (GNNs) have emerged as a prominent class of data-driven\nmethods for molecular property prediction. However, a key limitation of typical\nGNN models is their inability to quantify uncertainties in the predictions.\nThis capability is crucial for ensuring the trustworthy use and deployment of\nmodels in downstream tasks. To that end, we introduce AutoGNNUQ, an automated\nuncertainty quantification (UQ) approach for molecular property prediction.\nAutoGNNUQ leverages architecture search to generate an ensemble of\nhigh-performing GNNs, enabling the estimation of predictive uncertainties. Our\napproach employs variance decomposition to separate data (aleatoric) and model\n(epistemic) uncertainties, providing valuable insights for reducing them. In\nour computational experiments, we demonstrate that AutoGNNUQ outperforms\nexisting UQ methods in terms of both prediction accuracy and UQ performance on\nmultiple benchmark datasets. Additionally, we utilize t-SNE visualization to\nexplore correlations between molecular features and uncertainty, offering\ninsight for dataset improvement. AutoGNNUQ has broad applicability in domains\nsuch as drug discovery and materials science, where accurate uncertainty\nquantification is crucial for decision-making.",
          "link": "http://arxiv.org/abs/2307.10438",
          "publishedOn": "2023-07-22T00:55:25.881Z",
          "wordCount": null,
          "title": "Uncertainty Quantification for Molecular Property Predictions with Graph Neural Architecture Search. (arXiv:2307.10438v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10188",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pahune_S/0/1/0/all/0/1\">Saurabh Pahune</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandrasekharan_M/0/1/0/all/0/1\">Manoj Chandrasekharan</a>",
          "description": "Large Language Models(LLMs)have become effective tools for natural language\nprocessing and have been used in many different fields. This essay offers a\nsuccinct summary of various LLM subcategories. The survey emphasizes recent\ndevelopments and efforts made for various LLM kinds, including task-based\nfinancial LLMs, multilingual language LLMs, biomedical and clinical LLMs,\nvision language LLMs, and code language models. The survey gives a general\nsummary of the methods, attributes, datasets, transformer models, and\ncomparison metrics applied in each category of LLMs. Furthermore, it highlights\nunresolved problems in the field of developing chatbots and virtual assistants,\nsuch as boosting natural language processing, enhancing chatbot intelligence,\nand resolving moral and legal dilemmas. The purpose of this study is to provide\nreaders, developers, academics, and users interested in LLM-based chatbots and\nvirtual intelligent assistant technologies with useful information and future\ndirections.",
          "link": "http://arxiv.org/abs/2307.10188",
          "publishedOn": "2023-07-22T00:55:25.870Z",
          "wordCount": null,
          "title": "Several categories of Large Language Models (LLMs): A Short Survey. (arXiv:2307.10188v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10355",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Herle_A/0/1/0/all/0/1\">A. Herle</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+ORiordan_C/0/1/0/all/0/1\">C. M. O&#x27;Riordan</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Vegetti_S/0/1/0/all/0/1\">S. Vegetti</a>",
          "description": "Convolution Neural Networks trained for the task of lens finding with similar\narchitecture and training data as is commonly found in the literature are\nbiased classifiers. An understanding of the selection function of lens finding\nneural networks will be key to fully realising the potential of the large\nsamples of strong gravitational lens systems that will be found in upcoming\nwide-field surveys. We use three training datasets, representative of those\nused to train galaxy-galaxy and galaxy-quasar lens finding neural networks. The\nnetworks preferentially select systems with larger Einstein radii and larger\nsources with more concentrated source-light distributions. Increasing the\ndetection significance threshold to 12$\\sigma$ from 8$\\sigma$ results in 50 per\ncent of the selected strong lens systems having Einstein radii\n$\\theta_\\mathrm{E}$ $\\ge$ 1.04 arcsec from $\\theta_\\mathrm{E}$ $\\ge$ 0.879\narcsec, source radii $R_S$ $\\ge$ 0.194 arcsec from $R_S$ $\\ge$ 0.178 arcsec and\nsource S\\'ersic indices $n_{\\mathrm{Sc}}^{\\mathrm{S}}$ $\\ge$ 2.62 from\n$n_{\\mathrm{Sc}}^{\\mathrm{S}}$ $\\ge$ 2.55. The model trained to find lensed\nquasars shows a stronger preference for higher lens ellipticities than those\ntrained to find lensed galaxies. The selection function is independent of the\nslope of the power-law of the mass profiles, hence measurements of this\nquantity will be unaffected. The lens finder selection function reinforces that\nof the lensing cross-section, and thus we expect our findings to be a general\nresult for all galaxy-galaxy and galaxy-quasar lens finding neural networks.",
          "link": "http://arxiv.org/abs/2307.10355",
          "publishedOn": "2023-07-22T00:55:25.869Z",
          "wordCount": null,
          "title": "Selection functions of strong lens finding neural networks. (arXiv:2307.10355v1 [astro-ph.CO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10253",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuankai Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Huanyu Li</a>",
          "description": "Non-core drilling has gradually become the primary exploration method in\ngeological engineering, and well logging curves have increasingly gained\nimportance as the main carriers of geological information. However, factors\nsuch as geological environment, logging equipment, borehole quality, and\nunexpected events can all impact the quality of well logging curves. Previous\nmethods of re-logging or manual corrections have been associated with high\ncosts and low efficiency. This paper proposes a machine learning method that\nutilizes existing data to predict missing well logging curves, and its\neffectiveness and feasibility have been validated through experiments. The\nproposed method builds upon the traditional Long Short-Term Memory (LSTM)\nneural network by incorporating a self-attention mechanism to analyze the\nspatial dependencies of the data. It selectively includes the dominant\ncomputational results in the LSTM, reducing the computational complexity from\nO(n^2) to O(nlogn) and improving model efficiency. Experimental results\ndemonstrate that the proposed method achieves higher accuracy compared to\ntraditional curve synthesis methods based on Fully Connected Neural Networks\n(FCNN) and LSTM. This accurate, efficient, and cost-effective prediction method\nholds practical value in engineering applications.",
          "link": "http://arxiv.org/abs/2307.10253",
          "publishedOn": "2023-07-22T00:55:25.868Z",
          "wordCount": null,
          "title": "Efficient selective attention LSTM for well log curve synthesis. (arXiv:2307.10253v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10262",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bartz_Beielstein_T/0/1/0/all/0/1\">Thomas Bartz-Beielstein</a>",
          "description": "This document provides a comprehensive guide to hyperparameter tuning using\nspotPython for scikit-learn, PyTorch, and river. The first part introduces\nspotPython's surrogate model-based optimization process, while the second part\nfocuses on hyperparameter tuning. Several case studies are presented, including\nhyperparameter tuning for sklearn models such as Support Vector Classification,\nRandom Forests, Gradient Boosting (XGB), and K-nearest neighbors (KNN), as well\nas a Hoeffding Adaptive Tree Regressor from river. The integration of\nspotPython into the PyTorch and PyTorch Lightning training workflow is also\ndiscussed. With a hands-on approach and step-by-step explanations, this\ncookbook serves as a practical starting point for anyone interested in\nhyperparameter tuning with Python. Highlights include the interplay between\nTensorboard, PyTorch Lightning, spotPython, and river. This publication is\nunder development, with updates available on the corresponding webpage.",
          "link": "http://arxiv.org/abs/2307.10262",
          "publishedOn": "2023-07-22T00:55:25.868Z",
          "wordCount": null,
          "title": "Hyperparameter Tuning Cookbook: A guide for scikit-learn, PyTorch, river, and spotPython. (arXiv:2307.10262v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10193",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Woodland_M/0/1/0/all/0/1\">McKell Woodland</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wood_J/0/1/0/all/0/1\">John Wood</a>, <a href=\"http://arxiv.org/find/eess/1/au:+OConnor_C/0/1/0/all/0/1\">Caleb O&#x27;Connor</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Patel_A/0/1/0/all/0/1\">Ankit B. Patel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Brock_K/0/1/0/all/0/1\">Kristy K. Brock</a>",
          "description": "One barrier to the clinical deployment of deep learning-based models is the\npresence of images at runtime that lie far outside the training distribution of\na given model. We aim to detect these out-of-distribution (OOD) images with a\ngenerative adversarial network (GAN). Our training dataset was comprised of\n3,234 liver-containing computed tomography (CT) scans from 456 patients. Our\nOOD test data consisted of CT images of the brain, head and neck, lung, cervix,\nand abnormal livers. A StyleGAN2-ADA architecture was employed to model the\ntraining distribution. Images were reconstructed using backpropagation.\nReconstructions were evaluated using the Wasserstein distance, mean squared\nerror, and the structural similarity index measure. OOD detection was evaluated\nwith the area under the receiver operating characteristic curve (AUROC). Our\nparadigm distinguished between liver and non-liver CT with greater than 90%\nAUROC. It was also completely unable to reconstruct liver artifacts, such as\nneedles and ascites.",
          "link": "http://arxiv.org/abs/2307.10193",
          "publishedOn": "2023-07-22T00:55:25.867Z",
          "wordCount": null,
          "title": "StyleGAN2-based Out-of-Distribution Detection for Medical Imaging. (arXiv:2307.10193v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10244",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_D/0/1/0/all/0/1\">Dongning Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_X/0/1/0/all/0/1\">Xun Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1\">Fred Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mengshi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desmaison_A/0/1/0/all/0/1\">Alban Desmaison</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sellinger_T/0/1/0/all/0/1\">Thomas Sellinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moore_D/0/1/0/all/0/1\">Daniel Moore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankar_S/0/1/0/all/0/1\">Sriram Sankar</a>",
          "description": "Deep recommendation systems (DRS) heavily depend on specialized HPC hardware\nand accelerators to optimize energy, efficiency, and recommendation quality.\nDespite the growing number of hardware errors observed in large-scale fleet\nsystems where DRS are deployed, the robustness of DRS has been largely\noverlooked. This paper presents the first systematic study of DRS robustness\nagainst hardware errors. We develop Terrorch, a user-friendly, efficient and\nflexible error injection framework on top of the widely-used PyTorch. We\nevaluate a wide range of models and datasets and observe that the DRS\nrobustness against hardware errors is influenced by various factors from model\nparameters to input characteristics. We also explore 3 error mitigation methods\nincluding algorithm based fault tolerance (ABFT), activation clipping and\nselective bit protection (SBP). We find that applying activation clipping can\nrecover up to 30% of the degraded AUC-ROC score, making it a promising\nmitigation method.",
          "link": "http://arxiv.org/abs/2307.10244",
          "publishedOn": "2023-07-22T00:55:25.867Z",
          "wordCount": null,
          "title": "Evaluating and Enhancing Robustness of Deep Recommendation Systems Against Hardware Errors. (arXiv:2307.10244v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10529",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1\">Xueying Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yue Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akoglu_L/0/1/0/all/0/1\">Leman Akoglu</a>",
          "description": "Outlier detection (OD) finds many applications with a rich literature of\nnumerous techniques. Deep neural network based OD (DOD) has seen a recent surge\nof attention thanks to the many advances in deep learning. In this paper, we\nconsider a critical-yet-understudied challenge with unsupervised DOD, that is,\neffective hyperparameter (HP) tuning/model selection. While several prior work\nreport the sensitivity of OD models to HPs, it becomes ever so critical for the\nmodern DOD models that exhibit a long list of HPs. We introduce HYPER for\ntuning DOD models, tackling two fundamental challenges: (1) validation without\nsupervision (due to lack of labeled anomalies), and (2) efficient search of the\nHP/model space (due to exponential growth in the number of HPs). A key idea is\nto design and train a novel hypernetwork (HN) that maps HPs onto optimal\nweights of the main DOD model. In turn, HYPER capitalizes on a single HN that\ncan dynamically generate weights for many DOD models (corresponding to varying\nHPs), which offers significant speed-up. In addition, it employs meta-learning\non historical OD tasks with labels to train a proxy validation function,\nlikewise trained with our proposed HN efficiently. Extensive experiments on 35\nOD tasks show that HYPER achieves high performance against 8 baselines with\nsignificant efficiency gains.",
          "link": "http://arxiv.org/abs/2307.10529",
          "publishedOn": "2023-07-22T00:55:25.867Z",
          "wordCount": null,
          "title": "Fast Unsupervised Deep Outlier Model Selection with Hypernetworks. (arXiv:2307.10529v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10284",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wodlinger_M/0/1/0/all/0/1\">Matthias W&#xf6;dlinger</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kotera_J/0/1/0/all/0/1\">Jan Kotera</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Keglevic_M/0/1/0/all/0/1\">Manuel Keglevic</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_J/0/1/0/all/0/1\">Jan Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sablatnig_R/0/1/0/all/0/1\">Robert Sablatnig</a>",
          "description": "In this paper, we present ECSIC, a novel learned method for stereo image\ncompression. Our proposed method compresses the left and right images in a\njoint manner by exploiting the mutual information between the images of the\nstereo image pair using a novel stereo cross attention (SCA) module and two\nstereo context modules. The SCA module performs cross-attention restricted to\nthe corresponding epipolar lines of the two images and processes them in\nparallel. The stereo context modules improve the entropy estimation of the\nsecond encoded image by using the first image as a context. We conduct an\nextensive ablation study demonstrating the effectiveness of the proposed\nmodules and a comprehensive quantitative and qualitative comparison with\nexisting methods. ECSIC achieves state-of-the-art performance among stereo\nimage compression models on the two popular stereo image datasets Cityscapes\nand InStereo2k while allowing for fast encoding and decoding, making it highly\npractical for real-time applications.",
          "link": "http://arxiv.org/abs/2307.10284",
          "publishedOn": "2023-07-22T00:55:25.866Z",
          "wordCount": null,
          "title": "ECSIC: Epipolar Cross Attention for Stereo Image Compression. (arXiv:2307.10284v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bousbiat_H/0/1/0/all/0/1\">Hafsa Bousbiat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Himeur_Y/0/1/0/all/0/1\">Yassine Himeur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amira_A/0/1/0/all/0/1\">Abbes Amira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansoor_W/0/1/0/all/0/1\">Wathiq Mansoor</a>",
          "description": "Non-intrusive Load Monitoring (NILM) algorithms, commonly referred to as load\ndisaggregation algorithms, are fundamental tools for effective energy\nmanagement. Despite the success of deep models in load disaggregation, they\nface various challenges, particularly those pertaining to privacy and security.\nThis paper investigates the sensitivity of prominent deep NILM baselines to\nadversarial attacks, which have proven to be a significant threat in domains\nsuch as computer vision and speech recognition. Adversarial attacks entail the\nintroduction of imperceptible noise into the input data with the aim of\nmisleading the neural network into generating erroneous outputs. We investigate\nthe Fast Gradient Sign Method (FGSM), a well-known adversarial attack, to\nperturb the input sequences fed into two commonly employed CNN-based NILM\nbaselines: the Sequence-to-Sequence (S2S) and Sequence-to-Point (S2P) models.\nOur findings provide compelling evidence for the vulnerability of these models,\nparticularly the S2P model which exhibits an average decline of 20\\% in the\nF1-score even with small amounts of noise. Such weakness has the potential to\ngenerate profound implications for energy management systems in residential and\nindustrial sectors reliant on NILM models.",
          "link": "http://arxiv.org/abs/2307.10209",
          "publishedOn": "2023-07-22T00:55:25.865Z",
          "wordCount": null,
          "title": "On the Sensitivity of Deep Load Disaggregation to Adversarial Attacks. (arXiv:2307.10209v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10200",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1\">Sujan Dutta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_P/0/1/0/all/0/1\">Parth Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solunke_V/0/1/0/all/0/1\">Vaishnavi Solunke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nath_S/0/1/0/all/0/1\">Swaprava Nath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+KhudaBukhsh_A/0/1/0/all/0/1\">Ashiqur R. KhudaBukhsh</a>",
          "description": "Divorce is the legal dissolution of a marriage by a court. Since this is\nusually an unpleasant outcome of a marital union, each party may have reasons\nto call the decision to quit which is generally documented in detail in the\ncourt proceedings. Via a substantial corpus of 17,306 court proceedings, this\npaper investigates gender inequality through the lens of divorce court\nproceedings. While emerging data sources (e.g., public court records) on\nsensitive societal issues hold promise in aiding social science research,\nbiases present in cutting-edge natural language processing (NLP) methods may\ninterfere with or affect such studies. We thus require a thorough analysis of\npotential gaps and limitations present in extant NLP resources. In this paper,\non the methodological side, we demonstrate that existing NLP resources required\nseveral non-trivial modifications to quantify societal inequalities. On the\nsubstantive side, we find that while a large number of court cases perhaps\nsuggest changing norms in India where women are increasingly challenging\npatriarchy, AI-powered analyses of these court proceedings indicate striking\ngender inequality with women often subjected to domestic violence.",
          "link": "http://arxiv.org/abs/2307.10200",
          "publishedOn": "2023-07-22T00:55:25.864Z",
          "wordCount": null,
          "title": "Disentangling Societal Inequality from Model Biases: Gender Inequality in Divorce Court Proceedings. (arXiv:2307.10200v1 [cs.CY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abodo_F/0/1/0/all/0/1\">Franklin Abodo</a>",
          "description": "Traffic simulation software is used by transportation researchers and\nengineers to design and evaluate changes to roadways. These simulators are\ndriven by models of microscopic driver behavior from which macroscopic measures\nlike flow and congestion can be derived. Many models are designed for a subset\nof possible traffic scenarios and roadway configurations, while others have no\nexplicit constraints on their application. Work zones (WZs) are one scenario\nfor which no model to date has reproduced realistic driving behavior. This\nmakes it difficult to optimize for safety and other metrics when designing a\nWZ. The Federal Highway Administration commissioned the USDOT Volpe Center to\ndevelop a car-following (CF) model for use in microscopic simulators that can\ncapture and reproduce driver behavior accurately within and outside of WZs.\nVolpe also performed a naturalistic driving study to collect telematics data\nfrom vehicles driven on roads with WZs for use in model calibration. During\nmodel development, Volpe researchers observed difficulties in calibrating their\nmodel, leaving them to question whether there existed flaws in their model, in\nthe data, or in the procedure used to calibrate the model using the data. In\nthis thesis, I use Bayesian methods for data analysis and parameter estimation\nto explore and, where possible, address these questions. First, I use Bayesian\ninference to measure the sufficiency of the size of the data set. Second, I\ncompare the procedure and results of the genetic algorithm based calibration\nperformed by the Volpe researchers with those of Bayesian calibration. Third, I\nexplore the benefits of modeling CF hierarchically. Finally, I apply what was\nlearned in the first three phases using an established CF model, Wiedemann 99,\nto the probabilistic modeling of the Volpe model. Validation is performed using\ninformation criteria as an estimate of predictive accuracy.",
          "link": "http://arxiv.org/abs/2307.10437",
          "publishedOn": "2023-07-22T00:55:25.864Z",
          "wordCount": null,
          "title": "A Bayesian Programming Approach to Car-following Model Calibration and Validation using Limited Data. (arXiv:2307.10437v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10490",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bagdasaryan_E/0/1/0/all/0/1\">Eugene Bagdasaryan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_T/0/1/0/all/0/1\">Tsung-Yin Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nassi_B/0/1/0/all/0/1\">Ben Nassi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shmatikov_V/0/1/0/all/0/1\">Vitaly Shmatikov</a>",
          "description": "We demonstrate how images and sounds can be used for indirect prompt and\ninstruction injection in multi-modal LLMs. An attacker generates an adversarial\nperturbation corresponding to the prompt and blends it into an image or audio\nrecording. When the user asks the (unmodified, benign) model about the\nperturbed image or audio, the perturbation steers the model to output the\nattacker-chosen text and/or make the subsequent dialog follow the attacker's\ninstruction. We illustrate this attack with several proof-of-concept examples\ntargeting LLaVa and PandaGPT.",
          "link": "http://arxiv.org/abs/2307.10490",
          "publishedOn": "2023-07-22T00:55:25.860Z",
          "wordCount": null,
          "title": "(Ab)using Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs. (arXiv:2307.10490v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15776",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1\">Zheng Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Ming Li</a>",
          "description": "Weakly supervised learning aims to empower machine learning when the perfect\nsupervision is unavailable, which has drawn great attention from researchers.\nAmong various types of weak supervision, one of the most challenging cases is\nto learn from multiple unlabeled (U) datasets with only a little knowledge of\nthe class priors, or U$^m$ learning for short. In this paper, we study the\nproblem of building an AUC (area under ROC curve) optimization model from\nmultiple unlabeled datasets, which maximizes the pairwise ranking ability of\nthe classifier. We propose U$^m$-AUC, an AUC optimization approach that\nconverts the U$^m$ data into a multi-label AUC optimization problem, and can be\ntrained efficiently. We show that the proposed U$^m$-AUC is effective\ntheoretically and empirically.",
          "link": "http://arxiv.org/abs/2305.15776",
          "publishedOn": "2023-07-22T00:55:25.855Z",
          "wordCount": null,
          "title": "AUC Optimization from Multiple Unlabeled Datasets. (arXiv:2305.15776v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10485",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao-Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guoxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_D/0/1/0/all/0/1\">Daochen Zha</a>",
          "description": "Large language models (LLMs) have demonstrated remarkable proficiency in\nunderstanding and generating human-like texts, which may potentially\nrevolutionize the finance industry. However, existing LLMs often fall short in\nthe financial field, which is mainly attributed to the disparities between\ngeneral text data and financial text data. Unfortunately, there is only a\nlimited number of financial text datasets available (quite small size), and\nBloombergGPT, the first financial LLM (FinLLM), is close-sourced (only the\ntraining logs were released). In light of this, we aim to democratize\nInternet-scale financial data for LLMs, which is an open challenge due to\ndiverse data sources, low signal-to-noise ratio, and high time-validity. To\naddress the challenges, we introduce an open-sourced and data-centric\nframework, \\textit{Financial Generative Pre-trained Transformer (FinGPT)}, that\nautomates the collection and curation of real-time financial data from >34\ndiverse sources on the Internet, providing researchers and practitioners with\naccessible and transparent resources to develop their FinLLMs. Additionally, we\npropose a simple yet effective strategy for fine-tuning FinLLM using the\ninherent feedback from the market, dubbed Reinforcement Learning with Stock\nPrices (RLSP). We also adopt the Low-rank Adaptation (LoRA, QLoRA) method that\nenables users to customize their own FinLLMs from open-source general-purpose\nLLMs at a low cost. Finally, we showcase several FinGPT applications, including\nrobo-advisor, sentiment analysis for algorithmic trading, and low-code\ndevelopment. FinGPT aims to democratize FinLLMs, stimulate innovation, and\nunlock new opportunities in open finance. The codes are available at\nhttps://github.com/AI4Finance-Foundation/FinGPT and\nhttps://github.com/AI4Finance-Foundation/FinNLP",
          "link": "http://arxiv.org/abs/2307.10485",
          "publishedOn": "2023-07-22T00:55:25.854Z",
          "wordCount": null,
          "title": "FinGPT: Democratizing Internet-scale Data for Financial Large Language Models. (arXiv:2307.10485v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10237",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jawade_B/0/1/0/all/0/1\">Bhavin Jawade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohan_D/0/1/0/all/0/1\">Deen Dayal Mohan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fedorishin_D/0/1/0/all/0/1\">Dennis Fedorishin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Setlur_S/0/1/0/all/0/1\">Srirangaraj Setlur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Govindaraju_V/0/1/0/all/0/1\">Venu Govindaraju</a>",
          "description": "Face recognition from image sets acquired under unregulated and uncontrolled\nsettings, such as at large distances, low resolutions, varying viewpoints,\nillumination, pose, and atmospheric conditions, is challenging. Face feature\naggregation, which involves aggregating a set of N feature representations\npresent in a template into a single global representation, plays a pivotal role\nin such recognition systems. Existing works in traditional face feature\naggregation either utilize metadata or high-dimensional intermediate feature\nrepresentations to estimate feature quality for aggregation. However,\ngenerating high-quality metadata or style information is not feasible for\nextremely low-resolution faces captured in long-range and high altitude\nsettings. To overcome these limitations, we propose a feature distribution\nconditioning approach called CoNAN for template aggregation. Specifically, our\nmethod aims to learn a context vector conditioned over the distribution\ninformation of the incoming feature set, which is utilized to weigh the\nfeatures based on their estimated informativeness. The proposed method produces\nstate-of-the-art results on long-range unconstrained face recognition datasets\nsuch as BTS, and DroneSURF, validating the advantages of such an aggregation\nstrategy.",
          "link": "http://arxiv.org/abs/2307.10237",
          "publishedOn": "2023-07-22T00:55:25.853Z",
          "wordCount": null,
          "title": "CoNAN: Conditional Neural Aggregation Network For Unconstrained Face Feature Fusion. (arXiv:2307.10237v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10488",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thakur_N/0/1/0/all/0/1\">Nandan Thakur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kexin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jimmy Lin</a>",
          "description": "Traditionally, sparse retrieval systems relied on lexical representations to\nretrieve documents, such as BM25, dominated information retrieval tasks. With\nthe onset of pre-trained transformer models such as BERT, neural sparse\nretrieval has led to a new paradigm within retrieval. Despite the success,\nthere has been limited software supporting different sparse retrievers running\nin a unified, common environment. This hinders practitioners from fairly\ncomparing different sparse models and obtaining realistic evaluation results.\nAnother missing piece is, that a majority of prior work evaluates sparse\nretrieval models on in-domain retrieval, i.e. on a single dataset: MS MARCO.\nHowever, a key requirement in practical retrieval systems requires models that\ncan generalize well to unseen out-of-domain, i.e. zero-shot retrieval tasks. In\nthis work, we provide SPRINT, a unified Python toolkit based on Pyserini and\nLucene, supporting a common interface for evaluating neural sparse retrieval.\nThe toolkit currently includes five built-in models: uniCOIL, DeepImpact,\nSPARTA, TILDEv2 and SPLADEv2. Users can also easily add customized models by\ndefining their term weighting method. Using our toolkit, we establish strong\nand reproducible zero-shot sparse retrieval baselines across the\nwell-acknowledged benchmark, BEIR. Our results demonstrate that SPLADEv2\nachieves the best average score of 0.470 nDCG@10 on BEIR amongst all neural\nsparse retrievers. In this work, we further uncover the reasons behind its\nperformance gain. We show that SPLADEv2 produces sparse representations with a\nmajority of tokens outside of the original query and document which is often\ncrucial for its performance gains, i.e. a limitation among its other sparse\ncounterparts. We provide our SPRINT toolkit, models, and data used in our\nexperiments publicly here at https://github.com/thakur-nandan/sprint.",
          "link": "http://arxiv.org/abs/2307.10488",
          "publishedOn": "2023-07-22T00:55:25.797Z",
          "wordCount": null,
          "title": "SPRINT: A Unified Toolkit for Evaluating and Demystifying Zero-shot Neural Sparse Retrieval. (arXiv:2307.10488v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10205",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Guanlin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1\">Guowen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianwei Zhang</a>",
          "description": "In this paper, we study adversarial training on datasets that obey the\nlong-tailed distribution, which is practical but rarely explored in previous\nworks. Compared with conventional adversarial training on balanced datasets,\nthis process falls into the dilemma of generating uneven adversarial examples\n(AEs) and an unbalanced feature embedding space, causing the resulting model to\nexhibit low robustness and accuracy on tail data. To combat that, we propose a\nnew adversarial training framework -- Re-balancing Adversarial Training (REAT).\nThis framework consists of two components: (1) a new training strategy inspired\nby the term effective number to guide the model to generate more balanced and\ninformative AEs; (2) a carefully constructed penalty function to force a\nsatisfactory feature space. Evaluation results on different datasets and model\nstructures prove that REAT can effectively enhance the model's robustness and\npreserve the model's clean accuracy. The code can be found in\nhttps://github.com/GuanlinLee/REAT.",
          "link": "http://arxiv.org/abs/2307.10205",
          "publishedOn": "2023-07-22T00:55:25.787Z",
          "wordCount": null,
          "title": "Adversarial Training Over Long-Tailed Distribution. (arXiv:2307.10205v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10181",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Bannadabhavi_A/0/1/0/all/0/1\">Anushree Bannadabhavi</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lee_S/0/1/0/all/0/1\">Soojin Lee</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Deng_W/0/1/0/all/0/1\">Wenlong Deng</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Li_X/0/1/0/all/0/1\">Xiaoxiao Li</a>",
          "description": "Autism spectrum disorder(ASD) is a lifelong neurodevelopmental condition that\naffects social communication and behavior. Investigating functional magnetic\nresonance imaging (fMRI)-based brain functional connectome can aid in the\nunderstanding and diagnosis of ASD, leading to more effective treatments. The\nbrain is modeled as a network of brain Regions of Interest (ROIs), and ROIs\nform communities and knowledge of these communities is crucial for ASD\ndiagnosis. On the one hand, Transformer-based models have proven to be highly\neffective across several tasks, including fMRI connectome analysis to learn\nuseful representations of ROIs. On the other hand, existing transformer-based\nmodels treat all ROIs equally and overlook the impact of community-specific\nassociations when learning node embeddings. To fill this gap, we propose a\nnovel method, Com-BrainTF, a hierarchical local-global transformer architecture\nthat learns intra and inter-community aware node embeddings for ASD prediction\ntask. Furthermore, we avoid over-parameterization by sharing the local\ntransformer parameters for different communities but optimize unique learnable\nprompt tokens for each community. Our model outperforms state-of-the-art (SOTA)\narchitecture on ABIDE dataset and has high interpretability, evident from the\nattention module. Our code is available at\nhttps://github.com/ubc-tea/Com-BrainTF.",
          "link": "http://arxiv.org/abs/2307.10181",
          "publishedOn": "2023-07-22T00:55:25.786Z",
          "wordCount": null,
          "title": "Community-Aware Transformer for Autism Prediction in fMRI Connectome. (arXiv:2307.10181v1 [q-bio.NC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10472",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dige_O/0/1/0/all/0/1\">Omkar Dige</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_J/0/1/0/all/0/1\">Jacob-Junqi Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Emerson_D/0/1/0/all/0/1\">David Emerson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khattak_F/0/1/0/all/0/1\">Faiza Khan Khattak</a>",
          "description": "As the breadth and depth of language model applications continue to expand\nrapidly, it is increasingly important to build efficient frameworks for\nmeasuring and mitigating the learned or inherited social biases of these\nmodels. In this paper, we present our work on evaluating instruction fine-tuned\nlanguage models' ability to identify bias through zero-shot prompting,\nincluding Chain-of-Thought (CoT) prompts. Across LLaMA and its two instruction\nfine-tuned versions, Alpaca 7B performs best on the bias identification task\nwith an accuracy of 56.7%. We also demonstrate that scaling up LLM size and\ndata diversity could lead to further performance gain. This is a\nwork-in-progress presenting the first component of our bias mitigation\nframework. We will keep updating this work as we get more results.",
          "link": "http://arxiv.org/abs/2307.10472",
          "publishedOn": "2023-07-22T00:55:25.786Z",
          "wordCount": null,
          "title": "Can Instruction Fine-Tuned Language Models Identify Social Bias through Prompting?. (arXiv:2307.10472v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.09208",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Heddes_M/0/1/0/all/0/1\">Mike Heddes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nunes_I/0/1/0/all/0/1\">Igor Nunes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verges_P/0/1/0/all/0/1\">Pere Verg&#xe9;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleyko_D/0/1/0/all/0/1\">Denis Kleyko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abraham_D/0/1/0/all/0/1\">Danny Abraham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Givargis_T/0/1/0/all/0/1\">Tony Givargis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nicolau_A/0/1/0/all/0/1\">Alexandru Nicolau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veidenbaum_A/0/1/0/all/0/1\">Alexander Veidenbaum</a>",
          "description": "Hyperdimensional computing (HD), also known as vector symbolic architectures\n(VSA), is a framework for computing with distributed representations by\nexploiting properties of random high-dimensional vector spaces. The commitment\nof the scientific community to aggregate and disseminate research in this\nparticularly multidisciplinary area has been fundamental for its advancement.\nJoining these efforts, we present Torchhd, a high-performance open source\nPython library for HD/VSA. Torchhd seeks to make HD/VSA more accessible and\nserves as an efficient foundation for further research and application\ndevelopment. The easy-to-use library builds on top of PyTorch and features\nstate-of-the-art HD/VSA functionality, clear documentation, and implementation\nexamples from well-known publications. Comparing publicly available code with\ntheir corresponding Torchhd implementation shows that experiments can run up to\n100x faster. Torchhd is available at:\nhttps://github.com/hyperdimensional-computing/torchhd.",
          "link": "http://arxiv.org/abs/2205.09208",
          "publishedOn": "2023-07-22T00:55:25.775Z",
          "wordCount": null,
          "title": "Torchhd: An Open Source Python Library to Support Research on Hyperdimensional Computing and Vector Symbolic Architectures. (arXiv:2205.09208v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10430",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Castellon_R/0/1/0/all/0/1\">Rodrigo Castellon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopal_A/0/1/0/all/0/1\">Achintya Gopal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bloniarz_B/0/1/0/all/0/1\">Brian Bloniarz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosenberg_D/0/1/0/all/0/1\">David Rosenberg</a>",
          "description": "The generation of synthetic tabular data that preserves differential privacy\nis a problem of growing importance. While traditional marginal-based methods\nhave achieved impressive results, recent work has shown that deep\nlearning-based approaches tend to lag behind. In this work, we present\nDifferentially-Private TaBular AutoRegressive Transformer (DP-TBART), a\ntransformer-based autoregressive model that maintains differential privacy and\nachieves performance competitive with marginal-based methods on a wide variety\nof datasets, capable of even outperforming state-of-the-art methods in certain\nsettings. We also provide a theoretical framework for understanding the\nlimitations of marginal-based approaches and where deep learning-based\napproaches stand to contribute most. These results suggest that deep\nlearning-based techniques should be considered as a viable alternative to\nmarginal-based methods in the generation of differentially private synthetic\ntabular data.",
          "link": "http://arxiv.org/abs/2307.10430",
          "publishedOn": "2023-07-22T00:55:25.767Z",
          "wordCount": null,
          "title": "DP-TBART: A Transformer-based Autoregressive Model for Differentially Private Tabular Data Generation. (arXiv:2307.10430v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10440",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xiaoling Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chao Chen</a>",
          "description": "Overconfidence is a common issue for deep neural networks, limiting their\ndeployment in real-world applications. To better estimate confidence, existing\nmethods mostly focus on fully-supervised scenarios and rely on training labels.\nIn this paper, we propose the first confidence estimation method for a\nsemi-supervised setting, when most training labels are unavailable. We\nstipulate that even with limited training labels, we can still reasonably\napproximate the confidence of model on unlabeled samples by inspecting the\nprediction consistency through the training process. We use training\nconsistency as a surrogate function and propose a consistency ranking loss for\nconfidence estimation. On both image classification and segmentation tasks, our\nmethod achieves state-of-the-art performances in confidence estimation.\nFurthermore, we show the benefit of the proposed method through a downstream\nactive learning task. The code is available at\nhttps://github.com/TopoXLab/consistency-ranking-loss",
          "link": "http://arxiv.org/abs/2307.10440",
          "publishedOn": "2023-07-22T00:55:25.767Z",
          "wordCount": null,
          "title": "Confidence Estimation Using Unlabeled Data. (arXiv:2307.10440v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10318",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Takahashi_H/0/1/0/all/0/1\">Hideaki Takahashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingjing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>",
          "description": "Vertical federated learning (VFL) enables multiple parties with disjoint\nfeatures of a common user set to train a machine learning model without sharing\ntheir private data. Tree-based models have become prevalent in VFL due to their\ninterpretability and efficiency. However, the vulnerability of tree-based VFL\nhas not been sufficiently investigated. In this study, we first introduce a\nnovel label inference attack, ID2Graph, which utilizes the sets of record-IDs\nassigned to each node (i.e., instance space) to deduce private training labels.\nThe ID2Graph attack generates a graph structure from training samples, extracts\ncommunities from the graph, and clusters the local dataset using community\ninformation. To counteract label leakage from the instance space, we propose an\neffective defense mechanism, ID-LMID, which prevents label leakage by focusing\non mutual information regularization. Comprehensive experiments conducted on\nvarious datasets reveal that the ID2Graph attack presents significant risks to\ntree-based models such as Random Forest and XGBoost. Further evaluations on\nthese benchmarks demonstrate that ID-LMID effectively mitigates label leakage\nin such instances.",
          "link": "http://arxiv.org/abs/2307.10318",
          "publishedOn": "2023-07-22T00:55:25.764Z",
          "wordCount": null,
          "title": "Eliminating Label Leakage in Tree-Based Vertical Federated Learning. (arXiv:2307.10318v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10247",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruiqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Leyang Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Songtuan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haslum_P/0/1/0/all/0/1\">Patrik Haslum</a>",
          "description": "Action models, which take the form of precondition/effect axioms, facilitate\ncausal and motivational connections between actions for AI agents. Action model\nacquisition has been identified as a bottleneck in the application of planning\ntechnology, especially within narrative planning. Acquiring action models from\nnarrative texts in an automated way is essential, but challenging because of\nthe inherent complexities of such texts. We present NaRuto, a system that\nextracts structured events from narrative text and subsequently generates\nplanning-language-style action models based on predictions of commonsense event\nrelations, as well as textual contradictions and similarities, in an\nunsupervised manner. Experimental results in classical narrative planning\ndomains show that NaRuto can generate action models of significantly better\nquality than existing fully automated methods, and even on par with those of\nsemi-automated methods.",
          "link": "http://arxiv.org/abs/2307.10247",
          "publishedOn": "2023-07-22T00:55:25.763Z",
          "wordCount": null,
          "title": "Automated Action Model Acquisition from Narrative Texts. (arXiv:2307.10247v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10231",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ta_P/0/1/0/all/0/1\">Pralaypati Ta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_B/0/1/0/all/0/1\">Bhumika Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Arihant Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+C_S/0/1/0/all/0/1\">Sneha Sree C</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_A/0/1/0/all/0/1\">Arunima Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ram_K/0/1/0/all/0/1\">Keerthi Ram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivaprakasam_M/0/1/0/all/0/1\">Mohanasankar Sivaprakasam</a>",
          "description": "Clinical Practice Guidelines (CPGs) for cancer diseases evolve rapidly due to\nnew evidence generated by active research. Currently, CPGs are primarily\npublished in a document format that is ill-suited for managing this developing\nknowledge. A knowledge model of the guidelines document suitable for\nprogrammatic interaction is required. This work proposes an automated method\nfor extraction of knowledge from National Comprehensive Cancer Network (NCCN)\nCPGs in Oncology and generating a structured model containing the retrieved\nknowledge. The proposed method was tested using two versions of NCCN Non-Small\nCell Lung Cancer (NSCLC) CPG to demonstrate the effectiveness in faithful\nextraction and modeling of knowledge. Three enrichment strategies using Cancer\nstaging information, Unified Medical Language System (UMLS) Metathesaurus &\nNational Cancer Institute thesaurus (NCIt) concepts, and Node classification\nare also presented to enhance the model towards enabling programmatic traversal\nand querying of cancer care guidelines. The Node classification was performed\nusing a Support Vector Machine (SVM) model, achieving a classification accuracy\nof 0.81 with 10-fold cross-validation.",
          "link": "http://arxiv.org/abs/2307.10231",
          "publishedOn": "2023-07-22T00:55:25.762Z",
          "wordCount": null,
          "title": "Automated Knowledge Modeling for Cancer Clinical Practice Guidelines. (arXiv:2307.10231v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.06362",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cunha_B/0/1/0/all/0/1\">Barbara Cunha</a> (LTDS), <a href=\"http://arxiv.org/find/cs/1/au:+Droz_C/0/1/0/all/0/1\">Christophe Droz</a> (I4S), <a href=\"http://arxiv.org/find/cs/1/au:+Zine_A/0/1/0/all/0/1\">Abdelmalek Zine</a> (ICJ), <a href=\"http://arxiv.org/find/cs/1/au:+Foulard_S/0/1/0/all/0/1\">St&#xe9;phane Foulard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ichchou_M/0/1/0/all/0/1\">Mohamed Ichchou</a> (LTDS)",
          "description": "The use of Machine Learning (ML) has rapidly spread across several fields,\nhaving encountered many applications in Structural Dynamics and Vibroacoustic\n(SD\\&V). The increasing capabilities of ML to unveil insights from data, driven\nby unprecedented data availability, algorithms advances and computational\npower, enhance decision making, uncertainty handling, patterns recognition and\nreal-time assessments. Three main applications in SD\\&V have taken advantage of\nthese benefits. In Structural Health Monitoring, ML detection and prognosis\nlead to safe operation and optimized maintenance schedules. System\nidentification and control design are leveraged by ML techniques in Active\nNoise Control and Active Vibration Control. Finally, the so-called ML-based\nsurrogate models provide fast alternatives to costly simulations, enabling\nrobust and optimized product design. Despite the many works in the area, they\nhave not been reviewed and analyzed. Therefore, to keep track and understand\nthis ongoing integration of fields, this paper presents a survey of ML\napplications in SD\\&V analyses, shedding light on the current state of\nimplementation and emerging opportunities. The main methodologies, advantages,\nlimitations, and recommendations based on scientific knowledge were identified\nfor each of the three applications. Moreover, the paper considers the role of\nDigital Twins and Physics Guided ML to overcome current challenges and power\nfuture research progress. As a result, the survey provides a broad overview of\nthe present landscape of ML applied in SD\\&V and guides the reader to an\nadvanced understanding of progress and prospects in the field.",
          "link": "http://arxiv.org/abs/2204.06362",
          "publishedOn": "2023-07-22T00:55:25.760Z",
          "wordCount": 818,
          "title": "A Review of Machine Learning Methods Applied to Structural Dynamics and Vibroacoustic. (arXiv:2204.06362v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10495",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chapman_J/0/1/0/all/0/1\">James Chapman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bohan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1\">Zheng Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calder_J/0/1/0/all/0/1\">Jeff Calder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_K/0/1/0/all/0/1\">Kevin Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bertozzi_A/0/1/0/all/0/1\">Andrea L. Bertozzi</a>",
          "description": "Active learning improves the performance of machine learning methods by\njudiciously selecting a limited number of unlabeled data points to query for\nlabels, with the aim of maximally improving the underlying classifier's\nperformance. Recent gains have been made using sequential active learning for\nsynthetic aperture radar (SAR) data arXiv:2204.00005. In each iteration,\nsequential active learning selects a query set of size one while batch active\nlearning selects a query set of multiple datapoints. While batch active\nlearning methods exhibit greater efficiency, the challenge lies in maintaining\nmodel accuracy relative to sequential active learning methods. We developed a\nnovel, two-part approach for batch active learning: Dijkstra's Annulus Core-Set\n(DAC) for core-set generation and LocalMax for batch sampling. The batch active\nlearning process that combines DAC and LocalMax achieves nearly identical\naccuracy as sequential active learning but is more efficient, proportional to\nthe batch size. As an application, a pipeline is built based on transfer\nlearning feature embedding, graph learning, DAC, and LocalMax to classify the\nFUSAR-Ship and OpenSARShip datasets. Our pipeline outperforms the\nstate-of-the-art CNN-based methods.",
          "link": "http://arxiv.org/abs/2307.10495",
          "publishedOn": "2023-07-22T00:55:25.751Z",
          "wordCount": null,
          "title": "Novel Batch Active Learning Approach and Its Application to Synthetic Aperture Radar Datasets. (arXiv:2307.10495v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10304",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Min_L/0/1/0/all/0/1\">Lejun Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Junyan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_G/0/1/0/all/0/1\">Gus Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jingwei Zhao</a>",
          "description": "We propose Polyffusion, a diffusion model that generates polyphonic music\nscores by regarding music as image-like piano roll representations. The model\nis capable of controllable music generation with two paradigms: internal\ncontrol and external control. Internal control refers to the process in which\nusers pre-define a part of the music and then let the model infill the rest,\nsimilar to the task of masked music generation (or music inpainting). External\ncontrol conditions the model with external yet related information, such as\nchord, texture, or other features, via the cross-attention mechanism. We show\nthat by using internal and external controls, Polyffusion unifies a wide range\nof music creation tasks, including melody generation given accompaniment,\naccompaniment generation given melody, arbitrary music segment inpainting, and\nmusic arrangement given chords or textures. Experimental results show that our\nmodel significantly outperforms existing Transformer and sampling-based\nbaselines, and using pre-trained disentangled representations as external\nconditions yields more effective controls.",
          "link": "http://arxiv.org/abs/2307.10304",
          "publishedOn": "2023-07-22T00:55:25.750Z",
          "wordCount": null,
          "title": "Polyffusion: A Diffusion Model for Polyphonic Score Generation with Internal and External Controls. (arXiv:2307.10304v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10320",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Semmelrock_H/0/1/0/all/0/1\">Harald Semmelrock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kopeinik_S/0/1/0/all/0/1\">Simone Kopeinik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theiler_D/0/1/0/all/0/1\">Dieter Theiler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ross_Hellauer_T/0/1/0/all/0/1\">Tony Ross-Hellauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kowald_D/0/1/0/all/0/1\">Dominik Kowald</a>",
          "description": "Research is facing a reproducibility crisis, in which the results and\nfindings of many studies are difficult or even impossible to reproduce. This is\nalso the case in machine learning (ML) and artificial intelligence (AI)\nresearch. Often, this is the case due to unpublished data and/or source-code,\nand due to sensitivity to ML training conditions. Although different solutions\nto address this issue are discussed in the research community such as using ML\nplatforms, the level of reproducibility in ML-driven research is not increasing\nsubstantially. Therefore, in this mini survey, we review the literature on\nreproducibility in ML-driven research with three main aims: (i) reflect on the\ncurrent situation of ML reproducibility in various research fields, (ii)\nidentify reproducibility issues and barriers that exist in these research\nfields applying ML, and (iii) identify potential drivers such as tools,\npractices, and interventions that support ML reproducibility. With this, we\nhope to contribute to decisions on the viability of different solutions for\nsupporting ML reproducibility.",
          "link": "http://arxiv.org/abs/2307.10320",
          "publishedOn": "2023-07-22T00:55:25.750Z",
          "wordCount": null,
          "title": "Reproducibility in Machine Learning-Driven Research. (arXiv:2307.10320v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10869",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gu_W/0/1/0/all/0/1\">Wenwei Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jinyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhuangbin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jianping Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yuxin Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jiazhen Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_C/0/1/0/all/0/1\">Cong Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zengyin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1\">Michael Lyu</a>",
          "description": "Performance issues permeate large-scale cloud service systems, which can lead\nto huge revenue losses. To ensure reliable performance, it's essential to\naccurately identify and localize these issues using service monitoring metrics.\nGiven the complexity and scale of modern cloud systems, this task can be\nchallenging and may require extensive expertise and resources beyond the\ncapacity of individual humans. Some existing methods tackle this problem by\nanalyzing each metric independently to detect anomalies. However, this could\nincur overwhelming alert storms that are difficult for engineers to diagnose\nmanually. To pursue better performance, not only the temporal patterns of\nmetrics but also the correlation between metrics (i.e., relational patterns)\nshould be considered, which can be formulated as a multivariate metrics anomaly\ndetection problem. However, most of the studies fall short of extracting these\ntwo types of features explicitly. Moreover, there exist some unlabeled\nanomalies mixed in the training data, which may hinder the detection\nperformance. To address these limitations, we propose the Relational- Temporal\nAnomaly Detection Model (RTAnomaly) that combines the relational and temporal\ninformation of metrics. RTAnomaly employs a graph attention layer to learn the\ndependencies among metrics, which will further help pinpoint the anomalous\nmetrics that may cause the anomaly effectively. In addition, we exploit the\nconcept of positive unlabeled learning to address the issue of potential\nanomalies in the training data. To evaluate our method, we conduct experiments\non a public dataset and two industrial datasets. RTAnomaly outperforms all the\nbaseline models by achieving an average F1 score of 0.929 and Hit@3 of 0.920,\ndemonstrating its superiority.",
          "link": "http://arxiv.org/abs/2307.10869",
          "publishedOn": "2023-07-22T00:55:25.713Z",
          "wordCount": 784,
          "title": "Performance Issue Identification in Cloud Systems with Relational-Temporal Anomaly Detection. (arXiv:2307.10869v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.08363",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tian Yu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mirzasoleiman_B/0/1/0/all/0/1\">Baharan Mirzasoleiman</a>",
          "description": "Data augmentation is essential to achieve state-of-the-art performance in\nmany deep learning applications. However, the most effective augmentation\ntechniques become computationally prohibitive for even medium-sized datasets.\nTo address this, we propose a rigorous technique to select subsets of data\npoints that when augmented, closely capture the training dynamics of full data\naugmentation. We first show that data augmentation, modeled as additive\nperturbations, improves learning and generalization by relatively enlarging and\nperturbing the smaller singular values of the network Jacobian, while\npreserving its prominent directions. This prevents overfitting and enhances\nlearning the harder to learn information. Then, we propose a framework to\niteratively extract small subsets of training data that when augmented, closely\ncapture the alignment of the fully augmented Jacobian with labels/residuals. We\nprove that stochastic gradient descent applied to the augmented subsets found\nby our approach has similar training dynamics to that of fully augmented data.\nOur experiments demonstrate that our method achieves 6.3x speedup on CIFAR10\nand 2.2x speedup on SVHN, and outperforms the baselines by up to 10% across\nvarious subset sizes. Similarly, on TinyImageNet and ImageNet, our method beats\nthe baselines by up to 8%, while achieving up to 3.3x speedup across various\nsubset sizes. Finally, training on and augmenting 50% subsets using our method\non a version of CIFAR10 corrupted with label noise even outperforms using the\nfull dataset. Our code is available at:\nhttps://github.com/tianyu139/data-efficient-augmentation",
          "link": "http://arxiv.org/abs/2210.08363",
          "publishedOn": "2023-07-22T00:55:25.705Z",
          "wordCount": 761,
          "title": "Data-Efficient Augmentation for Training Neural Networks. (arXiv:2210.08363v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.11408",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Papi_S/0/1/0/all/0/1\">Sara Papi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turchi_M/0/1/0/all/0/1\">Marco Turchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Negri_M/0/1/0/all/0/1\">Matteo Negri</a>",
          "description": "Attention is the core mechanism of today's most used architectures for\nnatural language processing and has been analyzed from many perspectives,\nincluding its effectiveness for machine translation-related tasks. Among these\nstudies, attention resulted to be a useful source of information to get\ninsights about word alignment also when the input text is substituted with\naudio segments, as in the case of the speech translation (ST) task. In this\npaper, we propose AlignAtt, a novel policy for simultaneous ST (SimulST) that\nexploits the attention information to generate source-target alignments that\nguide the model during inference. Through experiments on the 8 language pairs\nof MuST-C v1.0, we show that AlignAtt outperforms previous state-of-the-art\nSimulST policies applied to offline-trained models with gains in terms of BLEU\nof 2 points and latency reductions ranging from 0.5s to 0.8s across the 8\nlanguages.",
          "link": "http://arxiv.org/abs/2305.11408",
          "publishedOn": "2023-07-22T00:55:25.697Z",
          "wordCount": 687,
          "title": "AlignAtt: Using Attention-based Audio-Translation Alignments as a Guide for Simultaneous Speech Translation. (arXiv:2305.11408v2 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2111.03950",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Singh_R/0/1/0/all/0/1\">Rahul Singh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xu_L/0/1/0/all/0/1\">Liyuan Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1\">Arthur Gretton</a>",
          "description": "We propose simple nonparametric estimators for mediated and time-varying dose\nresponse curves based on kernel ridge regression. By embedding Pearl's\nmediation formula and Robins' g-formula with kernels, we allow treatments,\nmediators, and covariates to be continuous in general spaces, and also allow\nfor nonlinear treatment-confounder feedback. Our key innovation is a\nreproducing kernel Hilbert space technique called sequential kernel embedding,\nwhich we use to construct simple estimators for complex causal estimands. Our\nestimators preserve the generality of classic identification while also\nachieving nonasymptotic uniform rates. In nonlinear simulations with many\ncovariates, we demonstrate strong performance. We estimate mediated and\ntime-varying dose response curves of the US Job Corps, and clean data that may\nserve as a benchmark in future work. We extend our results to mediated and\ntime-varying treatment effects and counterfactual distributions, verifying\nsemiparametric efficiency and weak convergence.",
          "link": "http://arxiv.org/abs/2111.03950",
          "publishedOn": "2023-07-22T00:55:25.689Z",
          "wordCount": 737,
          "title": "Sequential Kernel Embedding for Mediated and Time-Varying Dose Response Curves. (arXiv:2111.03950v4 [stat.ME] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2102.03403",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Paul_D/0/1/0/all/0/1\">Debolina Paul</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chakraborty_S/0/1/0/all/0/1\">Saptarshi Chakraborty</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Das_S/0/1/0/all/0/1\">Swagatam Das</a>",
          "description": "Principal Component Analysis (PCA) is a fundamental tool for data\nvisualization, denoising, and dimensionality reduction. It is widely popular in\nStatistics, Machine Learning, Computer Vision, and related fields. However, PCA\nis well-known to fall prey to outliers and often fails to detect the true\nunderlying low-dimensional structure within the dataset. Following the Median\nof Means (MoM) philosophy, recent supervised learning methods have shown great\nsuccess in dealing with outlying observations without much compromise to their\nlarge sample theoretical properties. This paper proposes a PCA procedure based\non the MoM principle. Called the \\textbf{M}edian of \\textbf{M}eans\n\\textbf{P}rincipal \\textbf{C}omponent \\textbf{A}nalysis (MoMPCA), the proposed\nmethod is not only computationally appealing but also achieves optimal\nconvergence rates under minimal assumptions. In particular, we explore the\nnon-asymptotic error bounds of the obtained solution via the aid of the\nRademacher complexities while granting absolutely no assumption on the outlying\nobservations. The derived concentration results are not dependent on the\ndimension because the analysis is conducted in a separable Hilbert space, and\nthe results only depend on the fourth moment of the underlying distribution in\nthe corresponding norm. The proposal's efficacy is also thoroughly showcased\nthrough simulations and real data applications.",
          "link": "http://arxiv.org/abs/2102.03403",
          "publishedOn": "2023-07-22T00:55:25.639Z",
          "wordCount": 721,
          "title": "Robust Principal Component Analysis: A Median of Means Approach. (arXiv:2102.03403v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10343",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Tu_T/0/1/0/all/0/1\">Tony Tu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Krishna_G/0/1/0/all/0/1\">Gautham Krishna</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Aghazadeh_A/0/1/0/all/0/1\">Amirali Aghazadeh</a>",
          "description": "Prokaryotic gene prediction plays an important role in understanding the\nbiology of organisms and their function with applications in medicine and\nbiotechnology. Although the current gene finders are highly sensitive in\nfinding long genes, their sensitivity decreases noticeably in finding shorter\ngenes (<180 nts). The culprit is insufficient annotated gene data to identify\ndistinguishing features in short open reading frames (ORFs). We develop a deep\nlearning-based method called ProtiGeno, specifically targeting short\nprokaryotic genes using a protein language model trained on millions of evolved\nproteins. In systematic large-scale experiments on 4,288 prokaryotic genomes,\nwe demonstrate that ProtiGeno predicts short coding and noncoding genes with\nhigher accuracy and recall than the current state-of-the-art gene finders. We\ndiscuss the predictive features of ProtiGeno and possible limitations by\nvisualizing the three-dimensional structure of the predicted short genes. Data,\ncodes, and models are available at https://github.com/tonytu16/protigeno.",
          "link": "http://arxiv.org/abs/2307.10343",
          "publishedOn": "2023-07-22T00:55:25.614Z",
          "wordCount": null,
          "title": "ProtiGeno: a prokaryotic short gene finder using protein language models. (arXiv:2307.10343v1 [q-bio.GN])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10705",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Che_Q/0/1/0/all/0/1\">Quang Huy Che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Dinh Phuc Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_M/0/1/0/all/0/1\">Minh Quan Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_D/0/1/0/all/0/1\">Duc Khai Lam</a>",
          "description": "Semantic segmentation is a common task in autonomous driving to understand\nthe surrounding environment. Driveable Area Segmentation and Lane Detection are\nparticularly important for safe and efficient navigation on the road. However,\noriginal semantic segmentation models are computationally expensive and require\nhigh-end hardware, which is not feasible for embedded systems in autonomous\nvehicles. This paper proposes a lightweight model for the driveable area and\nlane line segmentation. TwinLiteNet is designed cheaply but achieves accurate\nand efficient segmentation results. We evaluate TwinLiteNet on the BDD100K\ndataset and compare it with modern models. Experimental results show that our\nTwinLiteNet performs similarly to existing approaches, requiring significantly\nfewer computational resources. Specifically, TwinLiteNet achieves a mIoU score\nof 91.3% for the Drivable Area task and 31.08% IoU for the Lane Detection task\nwith only 0.4 million parameters and achieves 415 FPS on GPU RTX A5000.\nFurthermore, TwinLiteNet can run in real-time on embedded devices with limited\ncomputing power, especially since it achieves 60FPS on Jetson Xavier NX, making\nit an ideal solution for self-driving vehicles. Code is available:\nurl{https://github.com/chequanghuy/TwinLiteNet}.",
          "link": "http://arxiv.org/abs/2307.10705",
          "publishedOn": "2023-07-22T00:55:25.613Z",
          "wordCount": null,
          "title": "TwinLiteNet: An Efficient and Lightweight Model for Driveable Area and Lane Segmentation in Self-Driving Cars. (arXiv:2307.10705v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.13960",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kuipers_T/0/1/0/all/0/1\">Thijs P. Kuipers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bekkers_E/0/1/0/all/0/1\">Erik J. Bekkers</a>",
          "description": "Regular group convolutional neural networks (G-CNNs) have been shown to\nincrease model performance and improve equivariance to different geometrical\nsymmetries. This work addresses the problem of SE(3), i.e., roto-translation\nequivariance, on volumetric data. Volumetric image data is prevalent in many\nmedical settings. Motivated by the recent work on separable group convolutions,\nwe devise a SE(3) group convolution kernel separated into a continuous SO(3)\n(rotation) kernel and a spatial kernel. We approximate equivariance to the\ncontinuous setting by sampling uniform SO(3) grids. Our continuous SO(3) kernel\nis parameterized via RBF interpolation on similarly uniform grids. We\ndemonstrate the advantages of our approach in volumetric medical image\nanalysis. Our SE(3) equivariant models consistently outperform CNNs and regular\ndiscrete G-CNNs on challenging medical classification tasks and show\nsignificantly improved generalization capabilities. Our approach achieves up to\na 16.5% gain in accuracy over regular CNNs.",
          "link": "http://arxiv.org/abs/2306.13960",
          "publishedOn": "2023-07-22T00:55:25.613Z",
          "wordCount": null,
          "title": "Regular SE(3) Group Convolutions for Volumetric Medical Image Analysis. (arXiv:2306.13960v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10303",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Miraoui_Y/0/1/0/all/0/1\">Yanis Miraoui</a>",
          "description": "In this paper, we carefully investigate how we can use multiple different\nNatural Language Processing techniques and methods in order to automatically\nrecognize the main actions in sports events. We aim to extract insights by\nanalyzing live sport commentaries from different sources and by classifying\nthese major actions into different categories. We also study if sentiment\nanalysis could help detect these main actions.",
          "link": "http://arxiv.org/abs/2307.10303",
          "publishedOn": "2023-07-22T00:55:25.523Z",
          "wordCount": null,
          "title": "Analyzing sports commentary in order to automatically recognize events and extract insights. (arXiv:2307.10303v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10443",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Foolad_S/0/1/0/all/0/1\">Shima Foolad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiani_K/0/1/0/all/0/1\">Kourosh Kiani</a>",
          "description": "Despite the significant progress made by transformer models in machine\nreading comprehension tasks, they still face limitations in handling complex\nreasoning tasks due to the absence of explicit knowledge in the input sequence.\nThis paper proposes a novel attention pattern to overcome this limitation,\nwhich integrates reasoning knowledge derived from a heterogeneous graph into\nthe transformer architecture using a graph-enhanced self-attention mechanism.\nThe proposed attention pattern comprises three key elements: global-local\nattention for word tokens, graph attention for entity tokens that exhibit\nstrong attention towards tokens connected in the graph as opposed to those\nunconnected, and the consideration of the type of relationship between each\nentity token and word token. This results in optimized attention between the\ntwo if a relationship exists. The pattern is coupled with special relative\nposition labels, allowing it to integrate with LUKE's entity-aware\nself-attention mechanism. The experimental findings corroborate that our model\noutperforms both the cutting-edge LUKE-Graph and the baseline LUKE model on the\nReCoRD dataset that focuses on commonsense reasoning.",
          "link": "http://arxiv.org/abs/2307.10443",
          "publishedOn": "2023-07-22T00:55:25.513Z",
          "wordCount": null,
          "title": "Integrating a Heterogeneous Graph with Entity-aware Self-attention using Relative Position Labels for Reading Comprehension Model. (arXiv:2307.10443v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10186",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lin_M/0/1/0/all/0/1\">Moule Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jing_W/0/1/0/all/0/1\">Weipeng Jing</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Di_D/0/1/0/all/0/1\">Donglin Di</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_G/0/1/0/all/0/1\">Guangsheng Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Song_H/0/1/0/all/0/1\">Houbing Song</a>",
          "description": "Hyperspectral images have significant applications in various domains, since\nthey register numerous semantic and spatial information in the spectral band\nwith spatial variability of spectral signatures. Two critical challenges in\nidentifying pixels of the hyperspectral image are respectively representing the\ncorrelated information among the local and global, as well as the abundant\nparameters of the model. To tackle this challenge, we propose a Multi-Scale\nU-shape Multi-Layer Perceptron (MUMLP) a model consisting of the designed MSC\n(Multi-Scale Channel) block and the UMLP (U-shape Multi-Layer Perceptron)\nstructure. MSC transforms the channel dimension and mixes spectral band feature\nto embed the deep-level representation adequately. UMLP is designed by the\nencoder-decoder structure with multi-layer perceptron layers, which is capable\nof compressing the large-scale parameters. Extensive experiments are conducted\nto demonstrate our model can outperform state-of-the-art methods\nacross-the-board on three wide-adopted public datasets, namely Pavia\nUniversity, Houston 2013 and Houston 2018",
          "link": "http://arxiv.org/abs/2307.10186",
          "publishedOn": "2023-07-22T00:55:25.512Z",
          "wordCount": null,
          "title": "Multi-Scale U-Shape MLP for Hyperspectral Image Classification. (arXiv:2307.10186v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10496",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ukorigho_O/0/1/0/all/0/1\">Okezzi F. Ukorigho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Owoyele_O/0/1/0/all/0/1\">Opeoluwa Owoyele</a>",
          "description": "Complex systems in science and engineering sometimes exhibit behavior that\nchanges across different regimes. Traditional global models struggle to capture\nthe full range of this complex behavior, limiting their ability to accurately\nrepresent the system. In response to this challenge, we propose a novel\ncompetitive learning approach for obtaining data-driven models of physical\nsystems. The primary idea behind the proposed approach is to employ dynamic\nloss functions for a set of models that are trained concurrently on the data.\nEach model competes for each observation during training, allowing for the\nidentification of distinct functional regimes within the dataset. To\ndemonstrate the effectiveness of the learning approach, we coupled it with\nvarious regression methods that employ gradient-based optimizers for training.\nThe proposed approach was tested on various problems involving model discovery\nand function approximation, demonstrating its ability to successfully identify\nfunctional regimes, discover true governing equations, and reduce test errors.",
          "link": "http://arxiv.org/abs/2307.10496",
          "publishedOn": "2023-07-22T00:55:25.494Z",
          "wordCount": null,
          "title": "A Competitive Learning Approach for Specialized Models: A Solution for Complex Physical Systems with Distinct Functional Regimes. (arXiv:2307.10496v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10704",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zafar_S/0/1/0/all/0/1\">Sharyal Zafar</a> (ENS Rennes, SATIE), <a href=\"http://arxiv.org/find/cs/1/au:+Feraud_R/0/1/0/all/0/1\">Rapha&#xeb;l Feraud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blavette_A/0/1/0/all/0/1\">Anne Blavette</a> (ENS Rennes, SATIE), <a href=\"http://arxiv.org/find/cs/1/au:+Camilleri_G/0/1/0/all/0/1\">Guy Camilleri</a> (UT3, IRIT), <a href=\"http://arxiv.org/find/cs/1/au:+Ben_H/0/1/0/all/0/1\">Hamid Ben</a> (SATIE, ENS Rennes)",
          "description": "The drastic growth of electric vehicles and photovoltaics can introduce new\nchallenges, such as electrical current congestion and voltage limit violations\ndue to peak load demands. These issues can be mitigated by controlling the\noperation of electric vehicles i.e., smart charging. Centralized smart charging\nsolutions have already been proposed in the literature. But such solutions may\nlack scalability and suffer from inherent drawbacks of centralization, such as\na single point of failure, and data privacy concerns. Decentralization can help\ntackle these challenges. In this paper, a fully decentralized smart charging\nsystem is proposed using the philosophy of adaptive multi-agent systems. The\nproposed system utilizes multi-armed bandit learning to handle uncertainties in\nthe system. The presented system is decentralized, scalable, real-time,\nmodel-free, and takes fairness among different players into account. A detailed\ncase study is also presented for performance evaluation.",
          "link": "http://arxiv.org/abs/2307.10704",
          "publishedOn": "2023-07-22T00:55:25.449Z",
          "wordCount": 689,
          "title": "Decentralized Smart Charging of Large-Scale EVs using Adaptive Multi-Agent Multi-Armed Bandits. (arXiv:2307.10704v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10774",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Calefato_F/0/1/0/all/0/1\">Fabio Calefato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quaranta_L/0/1/0/all/0/1\">Luigi Quaranta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lanubile_F/0/1/0/all/0/1\">Filippo Lanubile</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalinowski_M/0/1/0/all/0/1\">Marcos Kalinowski</a>",
          "description": "Background. Due to the widespread adoption of Artificial Intelligence (AI)\nand Machine Learning (ML) for building software applications, companies are\nstruggling to recruit employees with a deep understanding of such technologies.\nIn this scenario, AutoML is soaring as a promising solution to fill the AI/ML\nskills gap since it promises to automate the building of end-to-end AI/ML\npipelines that would normally be engineered by specialized team members. Aims.\nDespite the growing interest and high expectations, there is a dearth of\ninformation about the extent to which AutoML is currently adopted by teams\ndeveloping AI/ML-enabled systems and how it is perceived by practitioners and\nresearchers. Method. To fill these gaps, in this paper, we present a\nmixed-method study comprising a benchmark of 12 end-to-end AutoML tools on two\nSE datasets and a user survey with follow-up interviews to further our\nunderstanding of AutoML adoption and perception. Results. We found that AutoML\nsolutions can generate models that outperform those trained and optimized by\nresearchers to perform classification tasks in the SE domain. Also, our\nfindings show that the currently available AutoML solutions do not live up to\ntheir names as they do not equally support automation across the stages of the\nML development workflow and for all the team members. Conclusions. We derive\ninsights to inform the SE research community on how AutoML can facilitate their\nactivities and tool builders on how to design the next generation of AutoML\ntechnologies.",
          "link": "http://arxiv.org/abs/2307.10774",
          "publishedOn": "2023-07-22T00:55:25.434Z",
          "wordCount": 759,
          "title": "Assessing the Use of AutoML for Data-Driven Software Engineering. (arXiv:2307.10774v1 [cs.SE])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ko_J/0/1/0/all/0/1\">Jaekyun Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sanghwan Lee</a>",
          "description": "Recently, denoising methods based on supervised learning have exhibited\npromising performance. However, their reliance on external datasets containing\nnoisy-clean image pairs restricts their applicability. To address this\nlimitation, researchers have focused on training denoising networks using\nsolely a set of noisy inputs. To improve the feasibility of denoising\nprocedures, in this study, we proposed a single-image self-supervised learning\nmethod in which only the noisy input image is used for network training. Gated\nconvolution was used for feature extraction and no-reference image quality\nassessment was used for guiding the training process. Moreover, the proposed\nmethod sampled instances from the input image dataset using Bernoulli sampling\nwith a certain dropout rate for training. The corresponding result was produced\nby averaging the generated predictions from various instances of the trained\nnetwork with dropouts. The experimental results indicated that the proposed\nmethod achieved state-of-the-art denoising performance on both synthetic and\nreal-world datasets. This highlights the effectiveness and practicality of our\nmethod as a potential solution for various noise removal tasks.",
          "link": "http://arxiv.org/abs/2307.10695",
          "publishedOn": "2023-07-22T00:55:25.410Z",
          "wordCount": 707,
          "title": "Self2Self+: Single-Image Denoising with Self-Supervised Learning and Image Quality Assessment Loss. (arXiv:2307.10695v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10867",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Ashish Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_P/0/1/0/all/0/1\">Prateek Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zixuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Arpita Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sungchul Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bursztyn_V/0/1/0/all/0/1\">Victor Bursztyn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vlassis_N/0/1/0/all/0/1\">Nikos Vlassis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossi_R/0/1/0/all/0/1\">Ryan A. Rossi</a>",
          "description": "Captions are crucial for understanding scientific visualizations and\ndocuments. Existing captioning methods for scientific figures rely on\nfigure-caption pairs extracted from documents for training, many of which fall\nshort with respect to metrics like helpfulness, explainability, and\nvisual-descriptiveness [15] leading to generated captions being misaligned with\nreader preferences. To enable the generation of high-quality figure captions,\nwe introduce FigCaps-HF a new framework for figure-caption generation that can\nincorporate domain expert feedback in generating captions optimized for reader\npreferences. Our framework comprises of 1) an automatic method for evaluating\nquality of figure-caption pairs, 2) a novel reinforcement learning with human\nfeedback (RLHF) method to optimize a generative figure-to-caption model for\nreader preferences. We demonstrate the effectiveness of our simple learning\nframework by improving performance over standard fine-tuning across different\ntypes of models. In particular, when using BLIP as the base model, our RLHF\nframework achieves a mean gain of 35.7%, 16.9%, and 9% in ROUGE, BLEU, and\nMeteor, respectively. Finally, we release a large-scale benchmark dataset with\nhuman feedback on figure-caption pairs to enable further evaluation and\ndevelopment of RLHF techniques for this problem.",
          "link": "http://arxiv.org/abs/2307.10867",
          "publishedOn": "2023-07-22T00:55:25.403Z",
          "wordCount": 721,
          "title": "FigCaps-HF: A Figure-to-Caption Generative Framework and Benchmark with Human Feedback. (arXiv:2307.10867v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carranza_A/0/1/0/all/0/1\">Andres Carranza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pai_D/0/1/0/all/0/1\">Dhruv Pai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaeffer_R/0/1/0/all/0/1\">Rylan Schaeffer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tandon_A/0/1/0/all/0/1\">Arnuv Tandon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koyejo_S/0/1/0/all/0/1\">Sanmi Koyejo</a>",
          "description": "As the capabilities of large machine learning models continue to grow, and as\nthe autonomy afforded to such models continues to expand, the spectre of a new\nadversary looms: the models themselves. The threat that a model might behave in\na seemingly reasonable manner, while secretly and subtly modifying its behavior\nfor ulterior reasons is often referred to as deceptive alignment in the AI\nSafety & Alignment communities. Consequently, we call this new direction\nDeceptive Alignment Monitoring. In this work, we identify emerging directions\nin diverse machine learning subfields that we believe will become increasingly\nimportant and intertwined in the near future for deceptive alignment\nmonitoring, and we argue that advances in these fields present both long-term\nchallenges and new research opportunities. We conclude by advocating for\ngreater involvement by the adversarial machine learning community in these\nemerging directions.",
          "link": "http://arxiv.org/abs/2307.10569",
          "publishedOn": "2023-07-22T00:55:25.383Z",
          "wordCount": 640,
          "title": "Deceptive Alignment Monitoring. (arXiv:2307.10569v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10635",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Ziniu Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1\">Pan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanqiao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jieyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subramaniam_S/0/1/0/all/0/1\">Satyen Subramaniam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loomba_A/0/1/0/all/0/1\">Arjun R. Loomba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shichang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yizhou Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>",
          "description": "Recent advances in large language models (LLMs) have demonstrated notable\nprogress on many mathematical benchmarks. However, most of these benchmarks\nonly feature problems grounded in junior and senior high school subjects,\ncontain only multiple-choice questions, and are confined to a limited scope of\nelementary arithmetic operations. To address these issues, this paper\nintroduces an expansive benchmark suite SciBench that aims to systematically\nexamine the reasoning capabilities required for complex scientific problem\nsolving. SciBench contains two carefully curated datasets: an open set\nfeaturing a range of collegiate-level scientific problems drawn from\nmathematics, chemistry, and physics textbooks, and a closed set comprising\nproblems from undergraduate-level exams in computer science and mathematics.\nBased on the two datasets, we conduct an in-depth benchmark study of two\nrepresentative LLMs with various prompting strategies. The results reveal that\ncurrent LLMs fall short of delivering satisfactory performance, with an overall\nscore of merely 35.80%. Furthermore, through a detailed user study, we\ncategorize the errors made by LLMs into ten problem-solving abilities. Our\nanalysis indicates that no single prompting strategy significantly outperforms\nothers and some strategies that demonstrate improvements in certain\nproblem-solving skills result in declines in other skills. We envision that\nSciBench will catalyze further developments in the reasoning abilities of LLMs,\nthereby ultimately contributing to scientific research and discovery.",
          "link": "http://arxiv.org/abs/2307.10635",
          "publishedOn": "2023-07-22T00:55:25.369Z",
          "wordCount": 795,
          "title": "SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models. (arXiv:2307.10635v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10870",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Meunier_D/0/1/0/all/0/1\">Dimitri Meunier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_Z/0/1/0/all/0/1\">Zhu Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1\">Arthur Gretton</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kpotufe_S/0/1/0/all/0/1\">Samory Kpotufe</a>",
          "description": "Many recent theoretical works on \\emph{meta-learning} aim to achieve\nguarantees in leveraging similar representational structures from related tasks\ntowards simplifying a target task. Importantly, the main aim in theory works on\nthe subject is to understand the extent to which convergence rates -- in\nlearning a common representation -- \\emph{may scale with the number $N$ of\ntasks} (as well as the number of samples per task). First steps in this setting\ndemonstrate this property when both the shared representation amongst tasks,\nand task-specific regression functions, are linear. This linear setting readily\nreveals the benefits of aggregating tasks, e.g., via averaging arguments. In\npractice, however, the representation is often highly nonlinear, introducing\nnontrivial biases in each task that cannot easily be averaged out as in the\nlinear case. In the present work, we derive theoretical guarantees for\nmeta-learning with nonlinear representations. In particular, assuming the\nshared nonlinearity maps to an infinite-dimensional RKHS, we show that\nadditional biases can be mitigated with careful regularization that leverages\nthe smoothness of task-specific regression functions,",
          "link": "http://arxiv.org/abs/2307.10870",
          "publishedOn": "2023-07-22T00:55:25.335Z",
          "wordCount": 669,
          "title": "Nonlinear Meta-Learning Can Guarantee Faster Rates. (arXiv:2307.10870v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10749",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ueda_R/0/1/0/all/0/1\">Ryosuke Ueda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takeuchi_K/0/1/0/all/0/1\">Koh Takeuchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kashima_H/0/1/0/all/0/1\">Hisashi Kashima</a>",
          "description": "The aggregation of multiple opinions plays a crucial role in decision-making,\nsuch as in hiring and loan review, and in labeling data for supervised\nlearning. Although majority voting and existing opinion aggregation models are\neffective for simple tasks, they are inappropriate for tasks without\nobjectively true labels in which disagreements may occur. In particular, when\nvoter attributes such as gender or race introduce bias into opinions, the\naggregation results may vary depending on the composition of voter attributes.\nA balanced group of voters is desirable for fair aggregation results but may be\ndifficult to prepare. In this study, we consider methods to achieve fair\nopinion aggregation based on voter attributes and evaluate the fairness of the\naggregated results. To this end, we consider an approach that combines opinion\naggregation models such as majority voting and the Dawid and Skene model (D&S\nmodel) with fairness options such as sample weighting. To evaluate the fairness\nof opinion aggregation, probabilistic soft labels are preferred over discrete\nclass labels. First, we address the problem of soft label estimation without\nconsidering voter attributes and identify some issues with the D&S model. To\naddress these limitations, we propose a new Soft D&S model with improved\naccuracy in estimating soft labels. Moreover, we evaluated the fairness of an\nopinion aggregation model, including Soft D&S, in combination with different\nfairness options using synthetic and semi-synthetic data. The experimental\nresults suggest that the combination of Soft D&S and data splitting as a\nfairness option is effective for dense data, whereas weighted majority voting\nis effective for sparse data. These findings should prove particularly valuable\nin supporting decision-making by human and machine-learning models with\nbalanced opinion aggregation.",
          "link": "http://arxiv.org/abs/2307.10749",
          "publishedOn": "2023-07-22T00:55:25.320Z",
          "wordCount": 807,
          "title": "Mitigating Voter Attribute Bias for Fair Opinion Aggregation. (arXiv:2307.10749v1 [cs.HC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10683",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Feng_S/0/1/0/all/0/1\">Shikun Feng</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ni_Y/0/1/0/all/0/1\">Yuyan Ni</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lan_Y/0/1/0/all/0/1\">Yanyan Lan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ma_Z/0/1/0/all/0/1\">Zhi-Ming Ma</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ma_W/0/1/0/all/0/1\">Wei-Ying Ma</a>",
          "description": "Coordinate denoising is a promising 3D molecular pre-training method, which\nhas achieved remarkable performance in various downstream drug discovery tasks.\nTheoretically, the objective is equivalent to learning the force field, which\nis revealed helpful for downstream tasks. Nevertheless, there are two\nchallenges for coordinate denoising to learn an effective force field, i.e. low\ncoverage samples and isotropic force field. The underlying reason is that\nmolecular distributions assumed by existing denoising methods fail to capture\nthe anisotropic characteristic of molecules. To tackle these challenges, we\npropose a novel hybrid noise strategy, including noises on both dihedral angel\nand coordinate. However, denoising such hybrid noise in a traditional way is no\nmore equivalent to learning the force field. Through theoretical deductions, we\nfind that the problem is caused by the dependency of the input conformation for\ncovariance. To this end, we propose to decouple the two types of noise and\ndesign a novel fractional denoising method (Frad), which only denoises the\nlatter coordinate part. In this way, Frad enjoys both the merits of sampling\nmore low-energy structures and the force field equivalence. Extensive\nexperiments show the effectiveness of Frad in molecular representation, with a\nnew state-of-the-art on 9 out of 12 tasks of QM9 and on 7 out of 8 targets of\nMD17.",
          "link": "http://arxiv.org/abs/2307.10683",
          "publishedOn": "2023-07-22T00:55:25.299Z",
          "wordCount": 728,
          "title": "Fractional Denoising for 3D Molecular Pre-training. (arXiv:2307.10683v1 [q-bio.QM])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10653",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_M/0/1/0/all/0/1\">Manqing Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhanxiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_Y/0/1/0/all/0/1\">Yitong Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wentao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Huai Jiang</a>",
          "description": "Time series anomaly detection is crucial for industrial monitoring services\nthat handle a large volume of data, aiming to ensure reliability and optimize\nsystem performance. Existing methods often require extensive labeled resources\nand manual parameter selection, highlighting the need for automation. This\npaper proposes a comprehensive framework for automatic parameter optimization\nin time series anomaly detection models. The framework introduces three\noptimization targets: prediction score, shape score, and sensitivity score,\nwhich can be easily adapted to different model backbones without prior\nknowledge or manual labeling efforts. The proposed framework has been\nsuccessfully applied online for over six months, serving more than 50,000 time\nseries every minute. It simplifies the user's experience by requiring only an\nexpected sensitive value, offering a user-friendly interface, and achieving\ndesired detection results. Extensive evaluations conducted on public datasets\nand comparison with other methods further confirm the effectiveness of the\nproposed framework.",
          "link": "http://arxiv.org/abs/2307.10653",
          "publishedOn": "2023-07-22T00:55:25.253Z",
          "wordCount": 706,
          "title": "Refining the Optimization Target for Automatic Univariate Time Series Anomaly Detection in Monitoring Services. (arXiv:2307.10653v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10718",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Forouzesh_M/0/1/0/all/0/1\">Mahsa Forouzesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thiran_P/0/1/0/all/0/1\">Patrick Thiran</a>",
          "description": "Extracting noisy or incorrectly labeled samples from a labeled dataset with\nhard/difficult samples is an important yet under-explored topic. Two general\nand often independent lines of work exist, one focuses on addressing noisy\nlabels, and another deals with hard samples. However, when both types of data\nare present, most existing methods treat them equally, which results in a\ndecline in the overall performance of the model. In this paper, we first design\nvarious synthetic datasets with custom hardness and noisiness levels for\ndifferent samples. Our proposed systematic empirical study enables us to better\nunderstand the similarities and more importantly the differences between\nhard-to-learn samples and incorrectly-labeled samples. These controlled\nexperiments pave the way for the development of methods that distinguish\nbetween hard and noisy samples. Through our study, we introduce a simple yet\neffective metric that filters out noisy-labeled samples while keeping the hard\nsamples. We study various data partitioning methods in the presence of label\nnoise and observe that filtering out noisy samples from hard samples with this\nproposed metric results in the best datasets as evidenced by the high test\naccuracy achieved after models are trained on the filtered datasets. We\ndemonstrate this for both our created synthetic datasets and for datasets with\nreal-world label noise. Furthermore, our proposed data partitioning method\nsignificantly outperforms other methods when employed within a semi-supervised\nlearning framework.",
          "link": "http://arxiv.org/abs/2307.10718",
          "publishedOn": "2023-07-22T00:55:25.244Z",
          "wordCount": 727,
          "title": "Differences Between Hard and Noisy-labeled Samples: An Empirical Study. (arXiv:2307.10718v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10842",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bohdal_O/0/1/0/all/0/1\">Ondrej Bohdal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Da Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hospedales_T/0/1/0/all/0/1\">Timothy Hospedales</a>",
          "description": "Performance of a pre-trained semantic segmentation model is likely to\nsubstantially decrease on data from a new domain. We show a pre-trained model\ncan be adapted to unlabelled target domain data by calculating soft-label\nprototypes under the domain shift and making predictions according to the\nprototype closest to the vector with predicted class probabilities. The\nproposed adaptation procedure is fast, comes almost for free in terms of\ncomputational resources and leads to considerable performance improvements. We\ndemonstrate the benefits of such label calibration on the highly-practical\nsynthetic-to-real semantic segmentation problem.",
          "link": "http://arxiv.org/abs/2307.10842",
          "publishedOn": "2023-07-22T00:55:25.234Z",
          "wordCount": 614,
          "title": "Label Calibration for Semantic Segmentation Under Domain Shift. (arXiv:2307.10842v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10703",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Elvira_V/0/1/0/all/0/1\">V&#xed;ctor Elvira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chouzenoux_E/0/1/0/all/0/1\">&#xc9;milie Chouzenoux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cerda_J/0/1/0/all/0/1\">Jordi Cerd&#xe0;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camps_Valls_G/0/1/0/all/0/1\">Gustau Camps-Valls</a>",
          "description": "Granger causality (GC) is often considered not an actual form of causality.\nStill, it is arguably the most widely used method to assess the predictability\nof a time series from another one. Granger causality has been widely used in\nmany applied disciplines, from neuroscience and econometrics to Earth sciences.\nWe revisit GC under a graphical perspective of state-space models. For that, we\nuse GraphEM, a recently presented expectation-maximisation algorithm for\nestimating the linear matrix operator in the state equation of a\nlinear-Gaussian state-space model. Lasso regularisation is included in the\nM-step, which is solved using a proximal splitting Douglas-Rachford algorithm.\nExperiments in toy examples and challenging climate problems illustrate the\nbenefits of the proposed model and inference technique over standard Granger\ncausality methods.",
          "link": "http://arxiv.org/abs/2307.10703",
          "publishedOn": "2023-07-22T00:55:25.216Z",
          "wordCount": 654,
          "title": "Graphs in State-Space Models for Granger Causality in Climate Science. (arXiv:2307.10703v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10559",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pang_Y/0/1/0/all/0/1\">Yutian Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jueming Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lieber_C/0/1/0/all/0/1\">Christopher S. Lieber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cooke_N/0/1/0/all/0/1\">Nancy J. Cooke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yongming Liu</a>",
          "description": "Air traffic control (ATC) is a safety-critical service system that demands\nconstant attention from ground air traffic controllers (ATCos) to maintain\ndaily aviation operations. The workload of the ATCos can have negative effects\non operational safety and airspace usage. To avoid overloading and ensure an\nacceptable workload level for the ATCos, it is important to predict the ATCos'\nworkload accurately for mitigation actions. In this paper, we first perform a\nreview of research on ATCo workload, mostly from the air traffic perspective.\nThen, we briefly introduce the setup of the human-in-the-loop (HITL)\nsimulations with retired ATCos, where the air traffic data and workload labels\nare obtained. The simulations are conducted under three Phoenix approach\nscenarios while the human ATCos are requested to self-evaluate their workload\nratings (i.e., low-1 to high-7). Preliminary data analysis is conducted. Next,\nwe propose a graph-based deep-learning framework with conformal prediction to\nidentify the ATCo workload levels. The number of aircraft under the\ncontroller's control varies both spatially and temporally, resulting in\ndynamically evolving graphs. The experiment results suggest that (a) besides\nthe traffic density feature, the traffic conflict feature contributes to the\nworkload prediction capabilities (i.e., minimum horizontal/vertical separation\ndistance); (b) directly learning from the spatiotemporal graph layout of\nairspace with graph neural network can achieve higher prediction accuracy,\ncompare to hand-crafted traffic complexity features; (c) conformal prediction\nis a valuable tool to further boost model prediction accuracy, resulting a\nrange of predicted workload labels. The code used is available at\n\\href{https://github.com/ymlasu/para-atm-collection/blob/master/air-traffic-prediction/ATC-Workload-Prediction/}{$\\mathsf{Link}$}.",
          "link": "http://arxiv.org/abs/2307.10559",
          "publishedOn": "2023-07-22T00:55:25.183Z",
          "wordCount": 777,
          "title": "Air Traffic Controller Workload Level Prediction using Conformalized Dynamical Graph Learning. (arXiv:2307.10559v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.09943",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+McDonald_T/0/1/0/all/0/1\">Thomas M. McDonald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maystre_L/0/1/0/all/0/1\">Lucas Maystre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lalmas_M/0/1/0/all/0/1\">Mounia Lalmas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russo_D/0/1/0/all/0/1\">Daniel Russo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ciosek_K/0/1/0/all/0/1\">Kamil Ciosek</a>",
          "description": "Recommender systems are a ubiquitous feature of online platforms.\nIncreasingly, they are explicitly tasked with increasing users' long-term\nsatisfaction. In this context, we study a content exploration task, which we\nformalize as a multi-armed bandit problem with delayed rewards. We observe that\nthere is an apparent trade-off in choosing the learning signal: Waiting for the\nfull reward to become available might take several weeks, hurting the rate at\nwhich learning happens, whereas measuring short-term proxy rewards reflects the\nactual long-term goal only imperfectly. We address this challenge in two steps.\nFirst, we develop a predictive model of delayed rewards that incorporates all\ninformation obtained to date. Full observations as well as partial (short or\nmedium-term) outcomes are combined through a Bayesian filter to obtain a\nprobabilistic belief. Second, we devise a bandit algorithm that takes advantage\nof this new predictive model. The algorithm quickly learns to identify content\naligned with long-term success by carefully balancing exploration and\nexploitation. We apply our approach to a podcast recommendation problem, where\nwe seek to identify shows that users engage with repeatedly over two months. We\nempirically validate that our approach results in substantially better\nperformance compared to approaches that either optimize for short-term proxies,\nor wait for the long-term outcome to be fully realized.",
          "link": "http://arxiv.org/abs/2307.09943",
          "publishedOn": "2023-07-22T00:55:25.170Z",
          "wordCount": 776,
          "title": "Impatient Bandits: Optimizing Recommendations for the Long-Term Without Delay. (arXiv:2307.09943v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10710",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhiao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_L/0/1/0/all/0/1\">Litian Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1\">Zhan Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuanlin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chuang Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hao Su</a>",
          "description": "We investigate the challenge of parametrizing policies for reinforcement\nlearning (RL) in high-dimensional continuous action spaces. Our objective is to\ndevelop a multimodal policy that overcomes limitations inherent in the\ncommonly-used Gaussian parameterization. To achieve this, we propose a\nprincipled framework that models the continuous RL policy as a generative model\nof optimal trajectories. By conditioning the policy on a latent variable, we\nderive a novel variational bound as the optimization objective, which promotes\nexploration of the environment. We then present a practical model-based RL\nmethod, called Reparameterized Policy Gradient (RPG), which leverages the\nmultimodal policy parameterization and learned world model to achieve strong\nexploration capabilities and high data efficiency. Empirical results\ndemonstrate that our method can help agents evade local optima in tasks with\ndense rewards and solve challenging sparse-reward environments by incorporating\nan object-centric intrinsic reward. Our method consistently outperforms\nprevious approaches across a range of tasks. Code and supplementary materials\nare available on the project page https://haosulab.github.io/RPG/",
          "link": "http://arxiv.org/abs/2307.10710",
          "publishedOn": "2023-07-22T00:55:25.156Z",
          "wordCount": 666,
          "title": "Reparameterized Policy Learning for Multimodal Trajectory Optimization. (arXiv:2307.10710v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xinke Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Junchi Lu</a>",
          "description": "The popularity of point cloud deep models for safety-critical purposes has\nincreased, but the reliability and security of these models can be compromised\nby intentional or naturally occurring point cloud noise. To combat this issue,\nwe present a novel point cloud outlier removal method called PointCVaR, which\nempowers standard-trained models to eliminate additional outliers and restore\nthe data. Our approach begins by conducting attribution analysis to determine\nthe influence of each point on the model output, which we refer to as point\nrisk. We then optimize the process of filtering high-risk points using\nConditional Value at Risk (CVaR) as the objective. The rationale for this\napproach is based on the observation that noise points in point clouds tend to\ncluster in the tail of the risk distribution, with a low frequency but a high\nlevel of risk, resulting in significant interference with classification\nresults. Despite requiring no additional training effort, our method produces\nexceptional results in various removal-and-classification experiments for noisy\npoint clouds, which are corrupted by random noise, adversarial noise, and\nbackdoor trigger noise. Impressively, it achieves 87% accuracy in defense\nagainst the backdoor attack by removing triggers. Overall, the proposed\nPointCVaR effectively eliminates noise points and enhances point cloud\nclassification, making it a promising plug-in module for various models in\ndifferent scenarios.",
          "link": "http://arxiv.org/abs/2307.10875",
          "publishedOn": "2023-07-22T00:55:25.111Z",
          "wordCount": 722,
          "title": "Risk-optimized Outlier Removal for Robust Point Cloud Classification. (arXiv:2307.10875v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10507",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Minghui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Meirui Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_Q/0/1/0/all/0/1\">Qi Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zehua Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoxiao Li</a>",
          "description": "Cross-silo federated learning (FL) enables the development of machine\nlearning models on datasets distributed across data centers such as hospitals\nand clinical research laboratories. However, recent research has found that\ncurrent FL algorithms face a trade-off between local and global performance\nwhen confronted with distribution shifts. Specifically, personalized FL methods\nhave a tendency to overfit to local data, leading to a sharp valley in the\nlocal model and inhibiting its ability to generalize to out-of-distribution\ndata. In this paper, we propose a novel federated model soup method (i.e.,\nselective interpolation of model parameters) to optimize the trade-off between\nlocal and global performance. Specifically, during the federated training\nphase, each client maintains its own global model pool by monitoring the\nperformance of the interpolated model between the local and global models. This\nallows us to alleviate overfitting and seek flat minima, which can\nsignificantly improve the model's generalization performance. We evaluate our\nmethod on retinal and pathological image classification tasks, and our proposed\nmethod achieves significant improvements for out-of-distribution\ngeneralization. Our code is available at https://github.com/ubc-tea/FedSoup.",
          "link": "http://arxiv.org/abs/2307.10507",
          "publishedOn": "2023-07-22T00:55:25.089Z",
          "wordCount": 711,
          "title": "FedSoup: Improving Generalization and Personalization in Federated Learning via Selective Model Interpolation. (arXiv:2307.10507v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10563",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pai_D/0/1/0/all/0/1\">Dhruv Pai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carranza_A/0/1/0/all/0/1\">Andres Carranza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaeffer_R/0/1/0/all/0/1\">Rylan Schaeffer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tandon_A/0/1/0/all/0/1\">Arnuv Tandon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koyejo_S/0/1/0/all/0/1\">Sanmi Koyejo</a>",
          "description": "We present FACADE, a novel probabilistic and geometric framework designed for\nunsupervised mechanistic anomaly detection in deep neural networks. Its primary\ngoal is advancing the understanding and mitigation of adversarial attacks.\nFACADE aims to generate probabilistic distributions over circuits, which\nprovide critical insights to their contribution to changes in the manifold\nproperties of pseudo-classes, or high-dimensional modes in activation space,\nyielding a powerful tool for uncovering and combating adversarial attacks. Our\napproach seeks to improve model robustness, enhance scalable model oversight,\nand demonstrates promising applications in real-world deployment settings.",
          "link": "http://arxiv.org/abs/2307.10563",
          "publishedOn": "2023-07-22T00:55:25.076Z",
          "wordCount": 617,
          "title": "FACADE: A Framework for Adversarial Circuit Anomaly Detection and Evaluation. (arXiv:2307.10563v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10404",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nauta_M/0/1/0/all/0/1\">Meike Nauta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hegeman_J/0/1/0/all/0/1\">Johannes H. Hegeman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geerdink_J/0/1/0/all/0/1\">Jeroen Geerdink</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schlotterer_J/0/1/0/all/0/1\">J&#xf6;rg Schl&#xf6;tterer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keulen_M/0/1/0/all/0/1\">Maurice van Keulen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seifert_C/0/1/0/all/0/1\">Christin Seifert</a>",
          "description": "Part-prototype models are explainable-by-design image classifiers, and a\npromising alternative to black box AI. This paper explores the applicability\nand potential of interpretable machine learning, in particular PIP-Net, for\nautomated diagnosis support on real-world medical imaging data. PIP-Net learns\nhuman-understandable prototypical image parts and we evaluate its accuracy and\ninterpretability for fracture detection and skin cancer diagnosis. We find that\nPIP-Net's decision making process is in line with medical classification\nstandards, while only provided with image-level class labels. Because of\nPIP-Net's unsupervised pretraining of prototypes, data quality problems such as\nundesired text in an X-ray or labelling errors can be easily identified.\nAdditionally, we are the first to show that humans can manually correct the\nreasoning of PIP-Net by directly disabling undesired prototypes. We conclude\nthat part-prototype models are promising for medical applications due to their\ninterpretability and potential for advanced model debugging.",
          "link": "http://arxiv.org/abs/2307.10404",
          "publishedOn": "2023-07-22T00:55:25.064Z",
          "wordCount": 659,
          "title": "Interpreting and Correcting Medical Image Classification with PIP-Net. (arXiv:2307.10404v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10586",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Corso_A/0/1/0/all/0/1\">Anthony Corso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karamadian_D/0/1/0/all/0/1\">David Karamadian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valentin_R/0/1/0/all/0/1\">Romeo Valentin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cooper_M/0/1/0/all/0/1\">Mary Cooper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1\">Mykel J. Kochenderfer</a>",
          "description": "As machine learning (ML) systems increasingly permeate high-stakes settings\nsuch as healthcare, transportation, military, and national security, concerns\nregarding their reliability have emerged. Despite notable progress, the\nperformance of these systems can significantly diminish due to adversarial\nattacks or environmental changes, leading to overconfident predictions,\nfailures to detect input faults, and an inability to generalize in unexpected\nscenarios. This paper proposes a holistic assessment methodology for the\nreliability of ML systems. Our framework evaluates five key properties:\nin-distribution accuracy, distribution-shift robustness, adversarial\nrobustness, calibration, and out-of-distribution detection. A reliability score\nis also introduced and used to assess the overall system reliability. To\nprovide insights into the performance of different algorithmic approaches, we\nidentify and categorize state-of-the-art techniques, then evaluate a selection\non real-world tasks using our proposed reliability metrics and reliability\nscore. Our analysis of over 500 models reveals that designing for one metric\ndoes not necessarily constrain others but certain algorithmic techniques can\nimprove reliability across multiple metrics simultaneously. This study\ncontributes to a more comprehensive understanding of ML reliability and\nprovides a roadmap for future research and development.",
          "link": "http://arxiv.org/abs/2307.10586",
          "publishedOn": "2023-07-22T00:55:25.014Z",
          "wordCount": 695,
          "title": "A Holistic Assessment of the Reliability of Machine Learning Systems. (arXiv:2307.10586v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10865",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Girrbach_L/0/1/0/all/0/1\">Leander Girrbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christensen_A/0/1/0/all/0/1\">Anders Christensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winther_O/0/1/0/all/0/1\">Ole Winther</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akata_Z/0/1/0/all/0/1\">Zeynep Akata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koepke_A/0/1/0/all/0/1\">A. Sophia Koepke</a>",
          "description": "Neural Persistence is a prominent measure for quantifying neural network\ncomplexity, proposed in the emerging field of topological data analysis in deep\nlearning. In this work, however, we find both theoretically and empirically\nthat the variance of network weights and spatial concentration of large weights\nare the main factors that impact neural persistence. Whilst this captures\nuseful information for linear classifiers, we find that no relevant spatial\nstructure is present in later layers of deep neural networks, making neural\npersistence roughly equivalent to the variance of weights. Additionally, the\nproposed averaging procedure across layers for deep neural networks does not\nconsider interaction between layers. Based on our analysis, we propose an\nextension of the filtration underlying neural persistence to the whole neural\nnetwork instead of single layers, which is equivalent to calculating neural\npersistence on one particular matrix. This yields our deep graph persistence\nmeasure, which implicitly incorporates persistent paths through the network and\nalleviates variance-related issues through standardisation. Code is available\nat https://github.com/ExplainableML/Deep-Graph-Persistence .",
          "link": "http://arxiv.org/abs/2307.10865",
          "publishedOn": "2023-07-22T00:55:24.760Z",
          "wordCount": null,
          "title": "Addressing caveats of neural persistence with deep graph persistence. (arXiv:2307.10865v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10634",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Ihtiyar_M/0/1/0/all/0/1\">Musa Nuri Ihtiyar</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ozgur_A/0/1/0/all/0/1\">Arzucan Ozgur</a>",
          "description": "Language models, primarily transformer-based ones, obtained colossal success\nin NLP. To be more precise, studies like BERT in NLU and works such as GPT-3\nfor NLG are very crucial. DNA sequences are very close to natural language in\nterms of structure, so if the DNA-related bioinformatics domain is concerned,\ndiscriminative models, like DNABert, exist. Yet, the generative side of the\ncoin is mainly unexplored to the best of our knowledge. Consequently, we\nfocused on developing an autoregressive generative language model like GPT-3\nfor DNA sequences. Because working with whole DNA sequences is challenging\nwithout substantial computational resources, we decided to carry out our study\non a smaller scale, focusing on nucleotide sequences of human genes, unique\nparts in DNA with specific functionalities, instead of the whole DNA. This\ndecision did not change the problem structure a lot due to the fact that both\nDNA and genes can be seen as 1D sequences consisting of four different\nnucleotides without losing much information and making too much simplification.\nFirst of all, we systematically examined an almost entirely unexplored problem\nand observed that RNNs performed the best while simple techniques like N-grams\nwere also promising. Another beneficial point was learning how to work with\ngenerative models on languages we do not understand, unlike natural language.\nHow essential using real-life tasks beyond the classical metrics such as\nperplexity is observed. Furthermore, checking whether the data-hungry nature of\nthese models can be changed through selecting a language with minimal\nvocabulary size, four owing to four different types of nucleotides, is\nexamined. The reason for reviewing this was that choosing such a language might\nmake the problem easier. However, what we observed in this study was it did not\nprovide that much of a change in the amount of data needed.",
          "link": "http://arxiv.org/abs/2307.10634",
          "publishedOn": "2023-07-22T00:55:24.746Z",
          "wordCount": null,
          "title": "Generative Language Models on Nucleotide Sequences of Human Genes. (arXiv:2307.10634v1 [q-bio.GN])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10575",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1\">Huy Q. Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_C/0/1/0/all/0/1\">Choong Seon Hong</a>",
          "description": "As a distributed machine learning technique, federated learning (FL) requires\nclients to collaboratively train a shared model with an edge server without\nleaking their local data. However, the heterogeneous data distribution among\nclients often leads to a decrease in model performance. To tackle this issue,\nthis paper introduces a prototype-based regularization strategy to address the\nheterogeneity in the data distribution. Specifically, the regularization\nprocess involves the server aggregating local prototypes from distributed\nclients to generate a global prototype, which is then sent back to the\nindividual clients to guide their local training. The experimental results on\nMNIST and Fashion-MNIST show that our proposal achieves improvements of 3.3%\nand 8.9% in average test accuracy, respectively, compared to the most popular\nbaseline FedAvg. Furthermore, our approach has a fast convergence rate in\nheterogeneous settings.",
          "link": "http://arxiv.org/abs/2307.10575",
          "publishedOn": "2023-07-22T00:55:24.735Z",
          "wordCount": null,
          "title": "Boosting Federated Learning Convergence with Prototype Regularization. (arXiv:2307.10575v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10352",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tanguy_E/0/1/0/all/0/1\">Eloi Tanguy</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Flamary_R/0/1/0/all/0/1\">R&#xe9;mi Flamary</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Delon_J/0/1/0/all/0/1\">Julie Delon</a>",
          "description": "The Sliced Wasserstein (SW) distance has become a popular alternative to the\nWasserstein distance for comparing probability measures. Widespread\napplications include image processing, domain adaptation and generative\nmodelling, where it is common to optimise some parameters in order to minimise\nSW, which serves as a loss function between discrete probability measures\n(since measures admitting densities are numerically unattainable). All these\noptimisation problems bear the same sub-problem, which is minimising the Sliced\nWasserstein energy. In this paper we study the properties of $\\mathcal{E}: Y\n\\longmapsto \\mathrm{SW}_2^2(\\gamma_Y, \\gamma_Z)$, i.e. the SW distance between\ntwo uniform discrete measures with the same amount of points as a function of\nthe support $Y \\in \\mathbb{R}^{n \\times d}$ of one of the measures. We\ninvestigate the regularity and optimisation properties of this energy, as well\nas its Monte-Carlo approximation $\\mathcal{E}_p$ (estimating the expectation in\nSW using only $p$ samples) and show convergence results on the critical points\nof $\\mathcal{E}_p$ to those of $\\mathcal{E}$, as well as an almost-sure uniform\nconvergence. Finally, we show that in a certain sense, Stochastic Gradient\nDescent methods minimising $\\mathcal{E}$ and $\\mathcal{E}_p$ converge towards\n(Clarke) critical points of these energies.",
          "link": "http://arxiv.org/abs/2307.10352",
          "publishedOn": "2023-07-22T00:55:24.727Z",
          "wordCount": null,
          "title": "Properties of Discrete Sliced Wasserstein Losses. (arXiv:2307.10352v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10541",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hall_A/0/1/0/all/0/1\">Adam W. Hall</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Greeff_M/0/1/0/all/0/1\">Melissa Greeff</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schoellig_A/0/1/0/all/0/1\">Angela P. Schoellig</a>",
          "description": "Learning-based optimal control algorithms control unknown systems using past\ntrajectory data and a learned model of the system dynamics. These controllers\nuse either a linear approximation of the learned dynamics, trading performance\nfor faster computation, or nonlinear optimization methods, which typically\nperform better but can limit real-time applicability. In this work, we present\na novel nonlinear controller that exploits differential flatness to achieve\nsimilar performance to state-of-the-art learning-based controllers but with\nsignificantly less computational effort. Differential flatness is a property of\ndynamical systems whereby nonlinear systems can be exactly linearized through a\nnonlinear input mapping. Here, the nonlinear transformation is learned as a\nGaussian process and is used in a safety filter that guarantees, with high\nprobability, stability as well as input and flat state constraint satisfaction.\nThis safety filter is then used to refine inputs from a flat model predictive\ncontroller to perform constrained nonlinear learning-based optimal control\nthrough two successive convex optimizations. We compare our method to\nstate-of-the-art learning-based control strategies and achieve similar\nperformance, but with significantly better computational efficiency, while also\nrespecting flat state and input constraints, and guaranteeing stability.",
          "link": "http://arxiv.org/abs/2307.10541",
          "publishedOn": "2023-07-22T00:55:24.686Z",
          "wordCount": null,
          "title": "Differentially Flat Learning-based Model Predictive Control Using a Stability, State, and Input Constraining Safety Filter. (arXiv:2307.10541v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10296",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sierra_Franco_C/0/1/0/all/0/1\">Cesar A. Sierra-Franco</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hurtado_J/0/1/0/all/0/1\">Jan Hurtado</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Thomaz_V/0/1/0/all/0/1\">Victor de A. Thomaz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cruz_L/0/1/0/all/0/1\">Leonardo C. da Cruz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Silva_S/0/1/0/all/0/1\">Santiago V. Silva</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Raposo_A/0/1/0/all/0/1\">Alberto B. Raposo</a>",
          "description": "Mammography images are widely used to detect non-palpable breast lesions or\nnodules, preventing cancer and providing the opportunity to plan interventions\nwhen necessary. The identification of some structures of interest is essential\nto make a diagnosis and evaluate image adequacy. Thus, computer-aided detection\nsystems can be helpful in assisting medical interpretation by automatically\nsegmenting these landmark structures. In this paper, we propose a deep\nlearning-based framework for the segmentation of the nipple, the pectoral\nmuscle, the fibroglandular tissue, and the fatty tissue on standard-view\nmammography images. We introduce a large private segmentation dataset and\nextensive experiments considering different deep-learning model architectures.\nOur experiments demonstrate accurate segmentation performance on variate and\nchallenging cases, showing that this framework can be integrated into clinical\npractice.",
          "link": "http://arxiv.org/abs/2307.10296",
          "publishedOn": "2023-07-22T00:55:24.638Z",
          "wordCount": null,
          "title": "Towards Automated Semantic Segmentation in Mammography Images. (arXiv:2307.10296v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.09753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1\">Xiaosong Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1\">Penghao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Li Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Junchi Yan</a>",
          "description": "Encoding a driving scene into vector representations has been an essential\ntask for autonomous driving that can benefit downstream tasks e.g. trajectory\nprediction. The driving scene often involves heterogeneous elements such as the\ndifferent types of objects (agents, lanes, traffic signs) and the semantic\nrelations between objects are rich and diverse. Meanwhile, there also exist\nrelativity across elements, which means that the spatial relation is a relative\nconcept and need be encoded in a ego-centric manner instead of in a global\ncoordinate system. Based on these observations, we propose Heterogeneous\nDriving Graph Transformer (HDGT), a backbone modelling the driving scene as a\nheterogeneous graph with different types of nodes and edges. For heterogeneous\ngraph construction, we connect different types of nodes according to diverse\nsemantic relations. For spatial relation encoding, the coordinates of the node\nas well as its in-edges are in the local node-centric coordinate system. For\nthe aggregation module in the graph neural network (GNN), we adopt the\ntransformer structure in a hierarchical way to fit the heterogeneous nature of\ninputs. Experimental results show that HDGT achieves state-of-the-art\nperformance for the task of trajectory prediction, on INTERACTION Prediction\nChallenge and Waymo Open Motion Challenge.",
          "link": "http://arxiv.org/abs/2205.09753",
          "publishedOn": "2023-07-22T00:55:24.431Z",
          "wordCount": 756,
          "title": "HDGT: Heterogeneous Driving Graph Transformer for Multi-Agent Trajectory Prediction via Scene Encoding. (arXiv:2205.09753v2 [cs.AI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.03718",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1\">Shulei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xinyu Yang</a>",
          "description": "Existing melody harmonization models have made great progress in improving\nthe quality of generated harmonies, but most of them ignored the emotions\nbeneath the music. Meanwhile, the variability of harmonies generated by\nprevious methods is insufficient. To solve these problems, we propose a novel\nLSTM-based Hierarchical Variational Auto-Encoder (LHVAE) to investigate the\ninfluence of emotional conditions on melody harmonization, while improving the\nquality of generated harmonies and capturing the abundant variability of chord\nprogressions. Specifically, LHVAE incorporates latent variables and emotional\nconditions at different levels (piece- and bar-level) to model the global and\nlocal music properties. Additionally, we introduce an attention-based melody\ncontext vector at each step to better learn the correspondence between melodies\nand harmonies. Objective experimental results show that our proposed model\noutperforms other LSTM-based models. Through subjective evaluation, we conclude\nthat only altering the types of chords hardly changes the overall emotion of\nthe music. The qualitative analysis demonstrates the ability of our model to\ngenerate variable harmonies.",
          "link": "http://arxiv.org/abs/2306.03718",
          "publishedOn": "2023-07-22T00:55:24.422Z",
          "wordCount": 701,
          "title": "Emotion-Conditioned Melody Harmonization with Hierarchical Variational Autoencoder. (arXiv:2306.03718v4 [cs.SD] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.02405",
          "author": "<a href=\"http://arxiv.org/find/hep-ph/1/au:+Raine_J/0/1/0/all/0/1\">John Andrew Raine</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Leigh_M/0/1/0/all/0/1\">Matthew Leigh</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Zoch_K/0/1/0/all/0/1\">Knut Zoch</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Golling_T/0/1/0/all/0/1\">Tobias Golling</a>",
          "description": "In this work we introduce $\\nu^2$-Flows, an extension of the $\\nu$-Flows\nmethod to final states containing multiple neutrinos. The architecture can\nnatively scale for all combinations of object types and multiplicities in the\nfinal state for any desired neutrino multiplicities. In $t\\bar{t}$ dilepton\nevents, the momenta of both neutrinos and correlations between them are\nreconstructed more accurately than when using the most popular standard\nanalytical techniques, and solutions are found for all events. Inference time\nis significantly faster than competing methods, and can be reduced further by\nevaluating in parallel on graphics processing units. We apply $\\nu^2$-Flows to\n$t\\bar{t}$ dilepton events and show that the per-bin uncertainties in unfolded\ndistributions is much closer to the limit of performance set by perfect\nneutrino reconstruction than standard techniques. For the chosen double\ndifferential observables $\\nu^2$-Flows results in improved statistical\nprecision for each bin by a factor of 1.5 to 2 in comparison to the Neutrino\nWeighting method and up to a factor of four in comparison to the Ellipse\napproach.",
          "link": "http://arxiv.org/abs/2307.02405",
          "publishedOn": "2023-07-22T00:55:24.413Z",
          "wordCount": 741,
          "title": "$\\nu^2$-Flows: Fast and improved neutrino reconstruction in multi-neutrino final states with conditional normalizing flows. (arXiv:2307.02405v2 [hep-ph] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04603",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Lee_J/0/1/0/all/0/1\">Jaemyung Lee</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Han_K/0/1/0/all/0/1\">Kyeongtak Han</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Kim_J/0/1/0/all/0/1\">Jaehoon Kim</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Yu_H/0/1/0/all/0/1\">Hasun Yu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lee_Y/0/1/0/all/0/1\">Youhan Lee</a>",
          "description": "Consistency and reliability are crucial for conducting AI research. Many\nfamous research fields, such as object detection, have been compared and\nvalidated with solid benchmark frameworks. After AlphaFold2, the protein\nfolding task has entered a new phase, and many methods are proposed based on\nthe component of AlphaFold2. The importance of a unified research framework in\nprotein folding contains implementations and benchmarks to consistently and\nfairly compare various approaches. To achieve this, we present Solvent, an\nprotein folding framework that supports significant components of\nstate-of-the-art models in the manner of off-the-shelf interface Solvent\ncontains different models implemented in a unified codebase and supports\ntraining and evaluation for defined models on the same dataset. We benchmark\nwell-known algorithms and their components and provide experiments that give\nhelpful insights into the protein structure modeling field. We hope that\nSolvent will increase the reliability and consistency of proposed models and\ngives efficiency in both speed and costs, resulting in acceleration on protein\nfolding modeling research. The code is available at\nhttps://github.com/kakaobrain/solvent, and the project will continue to be\ndeveloped.",
          "link": "http://arxiv.org/abs/2307.04603",
          "publishedOn": "2023-07-22T00:55:24.383Z",
          "wordCount": 711,
          "title": "Solvent: A Framework for Protein Folding. (arXiv:2307.04603v4 [q-bio.BM] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2208.10224",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tian Yu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mirzasoleiman_B/0/1/0/all/0/1\">Baharan Mirzasoleiman</a>",
          "description": "A powerful category of (invisible) data poisoning attacks modify a subset of\ntraining examples by small adversarial perturbations to change the prediction\nof certain test-time data. Existing defense mechanisms are not desirable to\ndeploy in practice, as they often either drastically harm the generalization\nperformance, or are attack-specific, and prohibitively slow to apply. Here, we\npropose a simple but highly effective approach that unlike existing methods\nbreaks various types of invisible poisoning attacks with the slightest drop in\nthe generalization performance. We make the key observation that attacks\nintroduce local sharp regions of high training loss, which when minimized,\nresults in learning the adversarial perturbations and makes the attack\nsuccessful. To break poisoning attacks, our key idea is to alleviate the sharp\nloss regions introduced by poisons. To do so, our approach comprises two\ncomponents: an optimized friendly noise that is generated to maximally perturb\nexamples without degrading the performance, and a randomly varying noise\ncomponent. The combination of both components builds a very light-weight but\nextremely effective defense against the most powerful triggerless targeted and\nhidden-trigger backdoor poisoning attacks, including Gradient Matching,\nBulls-eye Polytope, and Sleeper Agent. We show that our friendly noise is\ntransferable to other architectures, and adaptive attacks cannot break our\ndefense due to its random noise component. Our code is available at:\nhttps://github.com/tianyu139/friendly-noise",
          "link": "http://arxiv.org/abs/2208.10224",
          "publishedOn": "2023-07-22T00:55:24.312Z",
          "wordCount": 784,
          "title": "Friendly Noise against Adversarial Noise: A Powerful Defense against Data Poisoning Attacks. (arXiv:2208.10224v4 [cs.CR] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2207.12877",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aouad_A/0/1/0/all/0/1\">Ali Aouad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desir_A/0/1/0/all/0/1\">Antoine D&#xe9;sir</a>",
          "description": "Motivated by the successes of deep learning, we propose a class of neural\nnetwork-based discrete choice models, called RUMnets, inspired by the random\nutility maximization (RUM) framework. This model formulates the agents' random\nutility function using a sample average approximation. We show that RUMnets\nsharply approximate the class of RUM discrete choice models: any model derived\nfrom random utility maximization has choice probabilities that can be\napproximated arbitrarily closely by a RUMnet. Reciprocally, any RUMnet is\nconsistent with the RUM principle. We derive an upper bound on the\ngeneralization error of RUMnets fitted on choice data, and gain theoretical\ninsights on their ability to predict choices on new, unseen data depending on\ncritical parameters of the dataset and architecture. By leveraging open-source\nlibraries for neural networks, we find that RUMnets are competitive against\nseveral choice modeling and machine learning methods in terms of predictive\naccuracy on two real-world datasets.",
          "link": "http://arxiv.org/abs/2207.12877",
          "publishedOn": "2023-07-22T00:55:24.299Z",
          "wordCount": 679,
          "title": "Representing Random Utility Choice Models with Neural Networks. (arXiv:2207.12877v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08529",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Li_T/0/1/0/all/0/1\">Tianyi Li</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Biferale_L/0/1/0/all/0/1\">Luca Biferale</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bonaccorso_F/0/1/0/all/0/1\">Fabio Bonaccorso</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Scarpolini_M/0/1/0/all/0/1\">Martino Andrea Scarpolini</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Buzzicotti_M/0/1/0/all/0/1\">Michele Buzzicotti</a>",
          "description": "Lagrangian turbulence lies at the core of numerous applied and fundamental\nproblems related to the physics of dispersion and mixing in engineering,\nbio-fluids, atmosphere, oceans, and astrophysics. Despite exceptional\ntheoretical, numerical, and experimental efforts conducted over the past thirty\nyears, no existing models are capable of faithfully reproducing statistical and\ntopological properties exhibited by particle trajectories in turbulence. We\npropose a machine learning approach, based on a state-of-the-art Diffusion\nModel, to generate single-particle trajectories in three-dimensional turbulence\nat high Reynolds numbers, thereby bypassing the need for direct numerical\nsimulations or experiments to obtain reliable Lagrangian data. Our model\ndemonstrates the ability to quantitatively reproduce all relevant statistical\nbenchmarks over the entire range of time scales, including the presence of fat\ntails distribution for the velocity increments, anomalous power law, and\nenhancement of intermittency around the dissipative scale. The model exhibits\ngood generalizability for extreme events, achieving unprecedented intensity and\nrarity. This paves the way for producing synthetic high-quality datasets for\npre-training various downstream applications of Lagrangian turbulence.",
          "link": "http://arxiv.org/abs/2307.08529",
          "publishedOn": "2023-07-22T00:55:24.202Z",
          "wordCount": 684,
          "title": "Synthetic Lagrangian Turbulence by Generative Diffusion Models. (arXiv:2307.08529v1 [physics.flu-dyn] CROSS LISTED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2205.10060",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meinert_N/0/1/0/all/0/1\">Nis Meinert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gawlikowski_J/0/1/0/all/0/1\">Jakob Gawlikowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lavin_A/0/1/0/all/0/1\">Alexander Lavin</a>",
          "description": "There is a significant need for principled uncertainty reasoning in machine\nlearning systems as they are increasingly deployed in safety-critical domains.\nA new approach with uncertainty-aware regression-based neural networks (NNs),\nbased on learning evidential distributions for aleatoric and epistemic\nuncertainties, shows promise over traditional deterministic methods and typical\nBayesian NNs, notably with the capabilities to disentangle aleatoric and\nepistemic uncertainties. Despite some empirical success of Deep Evidential\nRegression (DER), there are important gaps in the mathematical foundation that\nraise the question of why the proposed technique seemingly works. We detail the\ntheoretical shortcomings and analyze the performance on synthetic and\nreal-world data sets, showing that Deep Evidential Regression is a heuristic\nrather than an exact uncertainty quantification. We go on to discuss\ncorrections and redefinitions of how aleatoric and epistemic uncertainties\nshould be extracted from NNs.",
          "link": "http://arxiv.org/abs/2205.10060",
          "publishedOn": "2023-07-22T00:55:24.194Z",
          "wordCount": 700,
          "title": "The Unreasonable Effectiveness of Deep Evidential Regression. (arXiv:2205.10060v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2105.11166",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jankowski_M/0/1/0/all/0/1\">Mikolaj Jankowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunduz_D/0/1/0/all/0/1\">Deniz Gunduz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mikolajczyk_K/0/1/0/all/0/1\">Krystian Mikolajczyk</a>",
          "description": "State-of-the-art performance for many edge applications is achieved by deep\nneural networks (DNNs). Often, these DNNs are location- and time-sensitive, and\nmust be delivered over a wireless channel rapidly and efficiently. In this\npaper, we introduce AirNet, a family of novel training and transmission methods\nthat allow DNNs to be efficiently delivered over wireless channels under\nstringent transmit power and latency constraints. This corresponds to a new\nclass of joint source-channel coding problems, aimed at delivering DNNs with\nthe goal of maximizing their accuracy at the receiver, rather than recovering\nthem with high fidelity. In AirNet, we propose the direct mapping of the DNN\nparameters to transmitted channel symbols, while the network is trained to meet\nthe channel constraints, and exhibit robustness against channel noise. AirNet\nachieves higher accuracy compared to separation-based alternatives. We further\nimprove the performance of AirNet by pruning the network below the available\nbandwidth, and expanding it for improved robustness. We also benefit from\nunequal error protection by selectively expanding important layers of the\nnetwork. Finally, we develop an approach, which simultaneously trains a\nspectrum of DNNs, each targeting a different channel condition, resolving the\nimpractical memory requirements of training distinct networks for different\nchannel conditions.",
          "link": "http://arxiv.org/abs/2105.11166",
          "publishedOn": "2023-07-22T00:55:24.186Z",
          "wordCount": 770,
          "title": "AirNet: Neural Network Transmission over the Air. (arXiv:2105.11166v6 [cs.NI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2207.02575",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wagenmaker_A/0/1/0/all/0/1\">Andrew Wagenmaker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jamieson_K/0/1/0/all/0/1\">Kevin Jamieson</a>",
          "description": "While much progress has been made in understanding the minimax sample\ncomplexity of reinforcement learning (RL) -- the complexity of learning on the\n\"worst-case\" instance -- such measures of complexity often do not capture the\ntrue difficulty of learning. In practice, on an \"easy\" instance, we might hope\nto achieve a complexity far better than that achievable on the worst-case\ninstance. In this work we seek to understand the \"instance-dependent\"\ncomplexity of learning near-optimal policies (PAC RL) in the setting of RL with\nlinear function approximation. We propose an algorithm, \\textsc{Pedel}, which\nachieves a fine-grained instance-dependent measure of complexity, the first of\nits kind in the RL with function approximation setting, thereby capturing the\ndifficulty of learning on each particular problem instance. Through an explicit\nexample, we show that \\textsc{Pedel} yields provable gains over low-regret,\nminimax-optimal algorithms and that such algorithms are unable to hit the\ninstance-optimal rate. Our approach relies on a novel online experiment\ndesign-based procedure which focuses the exploration budget on the \"directions\"\nmost relevant to learning a near-optimal policy, and may be of independent\ninterest.",
          "link": "http://arxiv.org/abs/2207.02575",
          "publishedOn": "2023-07-22T00:55:24.168Z",
          "wordCount": 715,
          "title": "Instance-Dependent Near-Optimal Policy Identification in Linear MDPs via Online Experiment Design. (arXiv:2207.02575v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10677",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leygonie_R/0/1/0/all/0/1\">Rebecca Leygonie</a> (LIPADE), <a href=\"http://arxiv.org/find/cs/1/au:+Lobry_S/0/1/0/all/0/1\">Sylvain Lobry</a> (LIPADE)), <a href=\"http://arxiv.org/find/cs/1/au:+%28LIPADE%29_L/0/1/0/all/0/1\">Laurent Wendling (LIPADE)</a>",
          "description": "We wish to define the limits of a classical classification model based on\ndeep learning when applied to abstract images, which do not represent visually\nidentifiable objects.QR codes (Quick Response codes) fall into this category of\nabstract images: one bit corresponding to one encoded character, QR codes were\nnot designed to be decoded manually. To understand the limitations of a deep\nlearning-based model for abstract image classification, we train an image\nclassification model on QR codes generated from information obtained when\nreading a health pass. We compare a classification model with a classical\n(deterministic) decoding method in the presence of noise. This study allows us\nto conclude that a model based on deep learning can be relevant for the\nunderstanding of abstract images.",
          "link": "http://arxiv.org/abs/2307.10677",
          "publishedOn": "2023-07-22T00:55:24.134Z",
          "wordCount": 660,
          "title": "Deep learning for classification of noisy QR codes. (arXiv:2307.10677v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.04777",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Godon_T/0/1/0/all/0/1\">Thibaud Godon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bauvin_B/0/1/0/all/0/1\">Baptiste Bauvin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Germain_P/0/1/0/all/0/1\">Pascal Germain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corbeil_J/0/1/0/all/0/1\">Jacques Corbeil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drouin_A/0/1/0/all/0/1\">Alexandre Drouin</a>",
          "description": "Rule-based models, such as decision trees, appeal to practitioners due to\ntheir interpretable nature. However, the learning algorithms that produce such\nmodels are often vulnerable to spurious associations and thus, they are not\nguaranteed to extract causally-relevant insights. In this work, we build on\nideas from the invariant causal prediction literature to propose Invariant\nCausal Set Covering Machines, an extension of the classical Set Covering\nMachine algorithm for conjunctions/disjunctions of binary-valued rules that\nprovably avoids spurious associations. We demonstrate both theoretically and\nempirically that our method can identify the causal parents of a variable of\ninterest in polynomial time.",
          "link": "http://arxiv.org/abs/2306.04777",
          "publishedOn": "2023-07-22T00:55:24.126Z",
          "wordCount": 620,
          "title": "Invariant Causal Set Covering Machines. (arXiv:2306.04777v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2009.03259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bian_R/0/1/0/all/0/1\">Rongzheng Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1\">Yumeng Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Liang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Baoquan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weiskopf_D/0/1/0/all/0/1\">Daniel Weiskopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yunhai Wang</a>",
          "description": "We propose a visualization method to understand the effect of\nmultidimensional projection on local subspaces, using implicit function\ndifferentiation. Here, we understand the local subspace as the multidimensional\nlocal neighborhood of data points. Existing methods focus on the projection of\nmultidimensional data points, and the neighborhood information is ignored. Our\nmethod is able to analyze the shape and directional information of the local\nsubspace to gain more insights into the global structure of the data through\nthe perception of local structures. Local subspaces are fitted by\nmultidimensional ellipses that are spanned by basis vectors. An accurate and\nefficient vector transformation method is proposed based on analytical\ndifferentiation of multidimensional projections formulated as implicit\nfunctions. The results are visualized as glyphs and analyzed using a full set\nof specifically-designed interactions supported in our efficient web-based\nvisualization tool. The usefulness of our method is demonstrated using various\nmulti- and high-dimensional benchmark datasets. Our implicit differentiation\nvector transformation is evaluated through numerical comparisons; the overall\nmethod is evaluated through exploration examples and use cases.",
          "link": "http://arxiv.org/abs/2009.03259",
          "publishedOn": "2023-07-22T00:55:24.117Z",
          "wordCount": 751,
          "title": "Implicit Multidimensional Projection of Local Subspaces. (arXiv:2009.03259v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04668",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alatawi_F/0/1/0/all/0/1\">Faisal Alatawi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheth_P/0/1/0/all/0/1\">Paras Sheth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huan Liu</a>",
          "description": "The rise of social media platforms has facilitated the formation of echo\nchambers, which are online spaces where users predominantly encounter\nviewpoints that reinforce their existing beliefs while excluding dissenting\nperspectives. This phenomenon significantly hinders information dissemination\nacross communities and fuels societal polarization. Therefore, it is crucial to\ndevelop methods for quantifying echo chambers. In this paper, we present the\nEcho Chamber Score (ECS), a novel metric that assesses the cohesion and\nseparation of user communities by measuring distances between users in the\nembedding space. In contrast to existing approaches, ECS is able to function\nwithout labels for user ideologies and makes no assumptions about the structure\nof the interaction graph. To facilitate measuring distances between users, we\npropose EchoGAE, a self-supervised graph autoencoder-based user embedding model\nthat leverages users' posts and the interaction graph to embed them in a manner\nthat reflects their ideological similarity. To assess the effectiveness of ECS,\nwe use a Twitter dataset consisting of four topics - two polarizing and two\nnon-polarizing. Our results showcase ECS's effectiveness as a tool for\nquantifying echo chambers and shedding light on the dynamics of online\ndiscourse.",
          "link": "http://arxiv.org/abs/2307.04668",
          "publishedOn": "2023-07-22T00:55:24.106Z",
          "wordCount": 725,
          "title": "Quantifying the Echo Chamber Effect: An Embedding Distance-based Approach. (arXiv:2307.04668v2 [cs.SI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04001",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peihao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shenghao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>",
          "description": "Set representation has become ubiquitous in deep learning for modeling the\ninductive bias of neural networks that are insensitive to the input order.\nDeepSets is the most widely used neural network architecture for set\nrepresentation. It involves embedding each set element into a latent space with\ndimension $L$, followed by a sum pooling to obtain a whole-set embedding, and\nfinally mapping the whole-set embedding to the output. In this work, we\ninvestigate the impact of the dimension $L$ on the expressive power of\nDeepSets. Previous analyses either oversimplified high-dimensional features to\nbe one-dimensional features or were limited to analytic activations, thereby\ndiverging from practical use or resulting in $L$ that grows exponentially with\nthe set size $N$ and feature dimension $D$. To investigate the minimal value of\n$L$ that achieves sufficient expressive power, we present two set-element\nembedding layers: (a) linear + power activation (LP) and (b) linear +\nexponential activations (LE). We demonstrate that $L$ being poly$(N, D)$ is\nsufficient for set representation using both embedding layers. We also provide\na lower bound of $L$ for the LP embedding layer. Furthermore, we extend our\nresults to permutation-equivariant set functions and the complex field.",
          "link": "http://arxiv.org/abs/2307.04001",
          "publishedOn": "2023-07-22T00:55:24.082Z",
          "wordCount": 726,
          "title": "Polynomial Width is Sufficient for Set Representation with High-dimensional Features. (arXiv:2307.04001v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.16200",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1\">Dan Hendrycks</a>",
          "description": "For billions of years, evolution has been the driving force behind the\ndevelopment of life, including humans. Evolution endowed humans with high\nintelligence, which allowed us to become one of the most successful species on\nthe planet. Today, humans aim to create artificial intelligence systems that\nsurpass even our own intelligence. As artificial intelligences (AIs) evolve and\neventually surpass us in all domains, how might evolution shape our relations\nwith AIs? By analyzing the environment that is shaping the evolution of AIs, we\nargue that the most successful AI agents will likely have undesirable traits.\nCompetitive pressures among corporations and militaries will give rise to AI\nagents that automate human roles, deceive others, and gain power. If such\nagents have intelligence that exceeds that of humans, this could lead to\nhumanity losing control of its future. More abstractly, we argue that natural\nselection operates on systems that compete and vary, and that selfish species\ntypically have an advantage over species that are altruistic to other species.\nThis Darwinian logic could also apply to artificial agents, as agents may\neventually be better able to persist into the future if they behave selfishly\nand pursue their own interests with little regard for humans, which could pose\ncatastrophic risks. To counteract these risks and evolutionary forces, we\nconsider interventions such as carefully designing AI agents' intrinsic\nmotivations, introducing constraints on their actions, and institutions that\nencourage cooperation. These steps, or others that resolve the problems we\npose, will be necessary in order to ensure the development of artificial\nintelligence is a positive one.",
          "link": "http://arxiv.org/abs/2303.16200",
          "publishedOn": "2023-07-22T00:55:24.075Z",
          "wordCount": 801,
          "title": "Natural Selection Favors AIs over Humans. (arXiv:2303.16200v4 [cs.CY] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.13426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Helen Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuwen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1\">Zachary C. Lipton</a>",
          "description": "Machine learning (ML) models deployed in healthcare systems must face data\ndrawn from continually evolving environments. However, researchers proposing\nsuch models typically evaluate them in a time-agnostic manner, splitting\ndatasets according to patients sampled randomly throughout the entire study\ntime period. This work proposes the Evaluation on Medical Datasets Over Time\n(EMDOT) framework, which evaluates the performance of a model class across\ntime. Inspired by the concept of backtesting, EMDOT simulates possible training\nprocedures that practitioners might have been able to execute at each point in\ntime and evaluates the resulting models on all future time points. Evaluating\nboth linear and more complex models on six distinct medical data sources\n(tabular and imaging), we show how depending on the dataset, using all\nhistorical data may be ideal in many cases, whereas using a window of the most\nrecent data could be advantageous in others. In datasets where models suffer\nfrom sudden degradations in performance, we investigate plausible explanations\nfor these shocks. We release the EMDOT package to help facilitate further works\nin deployment-oriented evaluation over time.",
          "link": "http://arxiv.org/abs/2305.13426",
          "publishedOn": "2023-07-22T00:55:24.066Z",
          "wordCount": 722,
          "title": "Evaluating Model Performance in Medical Datasets Over Time. (arXiv:2305.13426v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08122",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tian Yu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golatkar_A/0/1/0/all/0/1\">Aditya Golatkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>",
          "description": "We introduce Tangent Attention Fine-Tuning (TAFT), a method for fine-tuning\nlinearized transformers obtained by computing a First-order Taylor Expansion\naround a pre-trained initialization. We show that the Jacobian-Vector Product\nresulting from linearization can be computed efficiently in a single forward\npass, reducing training and inference cost to the same order of magnitude as\nits original non-linear counterpart, while using the same number of parameters.\nFurthermore, we show that, when applied to various downstream visual\nclassification tasks, the resulting Tangent Transformer fine-tuned with TAFT\ncan perform comparably with fine-tuning the original non-linear network. Since\nTangent Transformers are linear with respect to the new set of weights, and the\nresulting fine-tuning loss is convex, we show that TAFT enjoys several\nadvantages compared to non-linear fine-tuning when it comes to model\ncomposition, parallel training, machine unlearning, and differential privacy.",
          "link": "http://arxiv.org/abs/2307.08122",
          "publishedOn": "2023-07-22T00:55:24.059Z",
          "wordCount": 657,
          "title": "Tangent Transformers for Composition, Privacy and Removal. (arXiv:2307.08122v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.13732",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_R/0/1/0/all/0/1\">Renteng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdel_Aty_M/0/1/0/all/0/1\">Mohamed Abdel-Aty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_X/0/1/0/all/0/1\">Xin Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_O/0/1/0/all/0/1\">Ou Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_Q/0/1/0/all/0/1\">Qiaojun Xiang</a>",
          "description": "Accurately detecting and predicting lane change (LC)processes of human-driven\nvehicles can help autonomous vehicles better understand their surrounding\nenvironment, recognize potential safety hazards, and improve traffic safety.\nThis paper focuses on LC processes, first developing a temporal convolutional\nnetwork with an attention mechanism (TCN-ATM) model to recognize LC intention.\nConsidering the intrinsic relationship among output variables, the Multi-task\nLearning (MTL)framework is employed to simultaneously predict multiple LC\nvehicle status indicators. Furthermore, a unified modeling framework for LC\nintention recognition and driving status prediction (LC-IR-SP) is developed.\nThe results indicate that the classification accuracy of LC intention was\nimproved from 96.14% to 98.20% when incorporating the attention mechanism into\nthe TCN model. For LC vehicle status prediction issues, three multi-tasking\nlearning models are constructed based on MTL framework. The results indicate\nthat the MTL-LSTM model outperforms the MTL-TCN and MTL-TCN-ATM models.\nCompared to the corresponding single-task model, the MTL-LSTM model\ndemonstrates an average decrease of 26.04% in MAE and 25.19% in RMSE.",
          "link": "http://arxiv.org/abs/2304.13732",
          "publishedOn": "2023-07-22T00:55:24.052Z",
          "wordCount": 697,
          "title": "Lane Change Intention Recognition and Vehicle Status Prediction for Autonomous Vehicles. (arXiv:2304.13732v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.13252",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_M/0/1/0/all/0/1\">Ming Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Xiang Wang</a>",
          "description": "We study linear bandits when the underlying reward function is not linear.\nExisting work relies on a uniform misspecification parameter $\\epsilon$ that\nmeasures the sup-norm error of the best linear approximation. This results in\nan unavoidable linear regret whenever $\\epsilon > 0$. We describe a more\nnatural model of misspecification which only requires the approximation error\nat each input $x$ to be proportional to the suboptimality gap at $x$. It\ncaptures the intuition that, for optimization problems, near-optimal regions\nshould matter more and we can tolerate larger approximation errors in\nsuboptimal regions. Quite surprisingly, we show that the classical LinUCB\nalgorithm -- designed for the realizable case -- is automatically robust\nagainst such gap-adjusted misspecification. It achieves a near-optimal\n$\\sqrt{T}$ regret for problems that the best-known regret is almost linear in\ntime horizon $T$. Technically, our proof relies on a novel self-bounding\nargument that bounds the part of the regret due to misspecification by the\nregret itself.",
          "link": "http://arxiv.org/abs/2302.13252",
          "publishedOn": "2023-07-22T00:55:24.020Z",
          "wordCount": 681,
          "title": "No-Regret Linear Bandits beyond Realizability. (arXiv:2302.13252v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.12658",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Wenxuan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1\">Xing Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kun Zhang</a>",
          "description": "To improve the uncertainty quantification of variance networks, we propose a\nnovel tree-structured local neural network model that partitions the feature\nspace into multiple regions based on uncertainty heterogeneity. A tree is built\nupon giving the training data, whose leaf nodes represent different regions\nwhere region-specific neural networks are trained to predict both the mean and\nthe variance for quantifying uncertainty. The proposed Uncertainty-Splitting\nNeural Regression Tree (USNRT) employs novel splitting criteria. At each node,\na neural network is trained on the full data first, and a statistical test for\nthe residuals is conducted to find the best split, corresponding to the two\nsub-regions with the most significant uncertainty heterogeneity between them.\nUSNRT is computationally friendly because very few leaf nodes are sufficient\nand pruning is unnecessary. Furthermore, an ensemble version can be easily\nconstructed to estimate the total uncertainty including the aleatory and\nepistemic. On extensive UCI datasets, USNRT or its ensemble shows superior\nperformance compared to some recent popular methods for quantifying uncertainty\nwith variances. Through comprehensive visualization and analysis, we uncover\nhow USNRT works and show its merits, revealing that uncertainty heterogeneity\ndoes exist in many datasets and can be learned by USNRT.",
          "link": "http://arxiv.org/abs/2212.12658",
          "publishedOn": "2023-07-22T00:55:24.012Z",
          "wordCount": 725,
          "title": "Improving Uncertainty Quantification of Variance Networks by Tree-Structured Learning. (arXiv:2212.12658v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.10074",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Forel_A/0/1/0/all/0/1\">Alexandre Forel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parmentier_A/0/1/0/all/0/1\">Axel Parmentier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidal_T/0/1/0/all/0/1\">Thibaut Vidal</a>",
          "description": "Data-driven optimization uses contextual information and machine learning\nalgorithms to find solutions to decision problems with uncertain parameters.\nWhile a vast body of work is dedicated to interpreting machine learning models\nin the classification setting, explaining decision pipelines involving learning\nalgorithms remains unaddressed. This lack of interpretability can block the\nadoption of data-driven solutions as practitioners may not understand or trust\nthe recommended decisions. We bridge this gap by introducing a counterfactual\nexplanation methodology tailored to explain solutions to data-driven problems.\nWe introduce two classes of explanations and develop methods to find nearest\nexplanations of random forest and nearest-neighbor predictors. We demonstrate\nour approach by explaining key problems in operations management such as\ninventory management and routing.",
          "link": "http://arxiv.org/abs/2301.10074",
          "publishedOn": "2023-07-22T00:55:24.002Z",
          "wordCount": 690,
          "title": "Explainable Data-Driven Optimization: From Context to Decision and Back Again. (arXiv:2301.10074v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10616",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1\">Mang Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1\">Xiuwen Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1\">Bo Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuen_P/0/1/0/all/0/1\">Pong C. Yuen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "Federated learning (FL) has drawn increasing attention owing to its potential\nuse in large-scale industrial applications. Existing federated learning works\nmainly focus on model homogeneous settings. However, practical federated\nlearning typically faces the heterogeneity of data distributions, model\narchitectures, network environments, and hardware devices among participant\nclients. Heterogeneous Federated Learning (HFL) is much more challenging, and\ncorresponding solutions are diverse and complex. Therefore, a systematic survey\non this topic about the research challenges and state-of-the-art is essential.\nIn this survey, we firstly summarize the various research challenges in HFL\nfrom five aspects: statistical heterogeneity, model heterogeneity,\ncommunication heterogeneity, device heterogeneity, and additional challenges.\nIn addition, recent advances in HFL are reviewed and a new taxonomy of existing\nHFL methods is proposed with an in-depth analysis of their pros and cons. We\nclassify existing methods from three different levels according to the HFL\nprocedure: data-level, model-level, and server-level. Finally, several critical\nand promising future research directions in HFL are discussed, which may\nfacilitate further developments in this field. A periodically updated\ncollection on HFL is available at https://github.com/marswhu/HFL_Survey.",
          "link": "http://arxiv.org/abs/2307.10616",
          "publishedOn": "2023-07-22T00:55:23.835Z",
          "wordCount": 702,
          "title": "Heterogeneous Federated Learning: State-of-the-art and Research Challenges. (arXiv:2307.10616v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2205.12900",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Harder_F/0/1/0/all/0/1\">Fredrik Harder</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Asadabadi_M/0/1/0/all/0/1\">Milad Jalali Asadabadi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sutherland_D/0/1/0/all/0/1\">Danica J. Sutherland</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Park_M/0/1/0/all/0/1\">Mijung Park</a>",
          "description": "Training even moderately-sized generative models with differentially-private\nstochastic gradient descent (DP-SGD) is difficult: the required level of noise\nfor reasonable levels of privacy is simply too large. We advocate instead\nbuilding off a good, relevant representation on an informative public dataset,\nthen learning to model the private data with that representation. In\nparticular, we minimize the maximum mean discrepancy (MMD) between private\ntarget data and a generator's distribution, using a kernel based on perceptual\nfeatures learned from a public dataset. With the MMD, we can simply privatize\nthe data-dependent term once and for all, rather than introducing noise at each\nstep of optimization as in DP-SGD. Our algorithm allows us to generate\nCIFAR10-level images with $\\epsilon \\approx 2$ which capture distinctive\nfeatures in the distribution, far surpassing the current state of the art,\nwhich mostly focuses on datasets such as MNIST and FashionMNIST at a large\n$\\epsilon \\approx 10$. Our work introduces simple yet powerful foundations for\nreducing the gap between private and non-private deep generative models. Our\ncode is available at \\url{https://github.com/ParkLabML/DP-MEPF}.",
          "link": "http://arxiv.org/abs/2205.12900",
          "publishedOn": "2023-07-22T00:55:23.810Z",
          "wordCount": 733,
          "title": "Pre-trained Perceptual Features Improve Differentially Private Image Generation. (arXiv:2205.12900v4 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2211.09100",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Xiang Wang</a>",
          "description": "We consider the problem of global optimization with noisy zeroth order\noracles - a well-motivated problem useful for various applications ranging from\nhyper-parameter tuning for deep learning to new material design. Existing work\nrelies on Gaussian processes or other non-parametric family, which suffers from\nthe curse of dimensionality. In this paper, we propose a new algorithm GO-UCB\nthat leverages a parametric family of functions (e.g., neural networks)\ninstead. Under a realizable assumption and a few other mild geometric\nconditions, we show that GO-UCB achieves a cumulative regret of \\~O$(\\sqrt{T})$\nwhere $T$ is the time horizon. At the core of GO-UCB is a carefully designed\nuncertainty set over parameters based on gradients that allows optimistic\nexploration. Synthetic and real-world experiments illustrate GO-UCB works\nbetter than popular Bayesian optimization approaches, even if the model is\nmisspecified.",
          "link": "http://arxiv.org/abs/2211.09100",
          "publishedOn": "2023-07-22T00:55:23.782Z",
          "wordCount": 668,
          "title": "Global Optimization with Parametric Function Approximation. (arXiv:2211.09100v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2109.12509",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zheqing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Benjamin Van Roy</a>",
          "description": "Modern recommendation systems ought to benefit by probing for and learning\nfrom delayed feedback. Research has tended to focus on learning from a user's\nresponse to a single recommendation. Such work, which leverages methods of\nsupervised and bandit learning, forgoes learning from the user's subsequent\nbehavior. Where past work has aimed to learn from subsequent behavior, there\nhas been a lack of effective methods for probing to elicit informative delayed\nfeedback. Effective exploration through probing for delayed feedback becomes\nparticularly challenging when rewards are sparse. To address this, we develop\ndeep exploration methods for recommendation systems. In particular, we\nformulate recommendation as a sequential decision problem and demonstrate\nbenefits of deep exploration over single-step exploration. Our experiments are\ncarried out with high-fidelity industrial-grade simulators and establish large\nimprovements over existing algorithms.",
          "link": "http://arxiv.org/abs/2109.12509",
          "publishedOn": "2023-07-22T00:55:23.772Z",
          "wordCount": 658,
          "title": "Deep Exploration for Recommendation Systems. (arXiv:2109.12509v3 [cs.IR] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.01834",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dimitriadis_D/0/1/0/all/0/1\">Dimitrios Dimitriadis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koyejo_S/0/1/0/all/0/1\">Sanmi Koyejo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tople_S/0/1/0/all/0/1\">Shruti Tople</a>",
          "description": "Federated learning is gaining popularity as it enables training high-utility\nmodels across several clients without directly sharing their private data. As a\ndownside, the federated setting makes the model vulnerable to various\nadversarial attacks in the presence of malicious clients. Despite the\ntheoretical and empirical success in defending against attacks that aim to\ndegrade models' utility, defense against backdoor attacks that increase model\naccuracy on backdoor samples exclusively without hurting the utility on other\nsamples remains challenging. To this end, we first analyze the vulnerability of\nfederated learning to backdoor attacks over a flat loss landscape which is\ncommon for well-designed neural networks such as Resnet [He et al., 2015] but\nis often overlooked by previous works. Over a flat loss landscape, misleading\nfederated learning models to exclusively benefit malicious clients with\nbackdoor samples do not require a significant difference between malicious and\nbenign client-wise updates, making existing defenses insufficient. In contrast,\nwe propose an invariant aggregator that redirects the aggregated update to\ninvariant directions that are generally useful via selectively masking out the\ngradient elements that favor few and possibly malicious clients regardless of\nthe difference magnitude. Theoretical results suggest that our approach\nprovably mitigates backdoor attacks over both flat and sharp loss landscapes.\nEmpirical results on three datasets with different modalities and varying\nnumbers of clients further demonstrate that our approach mitigates a broad\nclass of backdoor attacks with a negligible cost on the model utility.",
          "link": "http://arxiv.org/abs/2210.01834",
          "publishedOn": "2023-07-22T00:55:23.736Z",
          "wordCount": 766,
          "title": "Invariant Aggregator for Defending against Federated Backdoor Attacks. (arXiv:2210.01834v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2107.03455",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ghosh_A/0/1/0/all/0/1\">Avishek Ghosh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sankararaman_A/0/1/0/all/0/1\">Abishek Sankararaman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramchandran_K/0/1/0/all/0/1\">Kannan Ramchandran</a>",
          "description": "We consider the problem of model selection for the general stochastic\ncontextual bandits under the realizability assumption. We propose a successive\nrefinement based algorithm called Adaptive Contextual Bandit ({\\ttfamily ACB}),\nthat works in phases and successively eliminates model classes that are too\nsimple to fit the given instance. We prove that this algorithm is adaptive,\ni.e., the regret rate order-wise matches that of any provable contextual bandit\nalgorithm (ex. \\cite{falcon}), that needs the knowledge of the true model\nclass. The price of not knowing the correct model class turns out to be only an\nadditive term contributing to the second order term in the regret bound. This\ncost possess the intuitive property that it becomes smaller as the model class\nbecomes easier to identify, and vice-versa. We also show that a much simpler\nexplore-then-commit (ETC) style algorithm also obtains similar regret bound,\ndespite not knowing the true model class. However, the cost of model selection\nis higher in ETC as opposed to in {\\ttfamily ACB}, as expected. Furthermore,\nfor the special case of linear contextual bandits, we propose specialized\nalgorithms that obtain sharper guarantees compared to the generic setup.",
          "link": "http://arxiv.org/abs/2107.03455",
          "publishedOn": "2023-07-22T00:55:23.728Z",
          "wordCount": 720,
          "title": "Model Selection for Generic Contextual Bandits. (arXiv:2107.03455v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.09702",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Willard_B/0/1/0/all/0/1\">Brandon T. Willard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Louf_R/0/1/0/all/0/1\">R&#xe9;mi Louf</a>",
          "description": "In this article we describe an efficient approach to guiding language model\ntext generation with regular expressions and context-free grammars. Our\napproach adds little to no overhead to the token sequence generation process,\nand makes guided generation feasible in practice. An implementation is provided\nin the open source Python library Outlines.",
          "link": "http://arxiv.org/abs/2307.09702",
          "publishedOn": "2023-07-22T00:55:23.693Z",
          "wordCount": 565,
          "title": "Efficient Guided Generation for Large Language Models. (arXiv:2307.09702v2 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2106.01001",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lambrechts_G/0/1/0/all/0/1\">Gaspard Lambrechts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geeter_F/0/1/0/all/0/1\">Florent De Geeter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vecoven_N/0/1/0/all/0/1\">Nicolas Vecoven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ernst_D/0/1/0/all/0/1\">Damien Ernst</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drion_G/0/1/0/all/0/1\">Guillaume Drion</a>",
          "description": "Training recurrent neural networks is known to be difficult when time\ndependencies become long. In this work, we show that most standard cells only\nhave one stable equilibrium at initialisation, and that learning on tasks with\nlong time dependencies generally occurs once the number of network stable\nequilibria increases; a property known as multistability. Multistability is\noften not easily attained by initially monostable networks, making learning of\nlong time dependencies between inputs and outputs difficult. This insight leads\nto the design of a novel way to initialise any recurrent cell connectivity\nthrough a procedure called \"warmup\" to improve its capability to learn\narbitrarily long time dependencies. This initialisation procedure is designed\nto maximise network reachable multistability, i.e., the number of equilibria\nwithin the network that can be reached through relevant input trajectories, in\nfew gradient steps. We show on several information restitution, sequence\nclassification, and reinforcement learning benchmarks that warming up greatly\nimproves learning speed and performance, for multiple recurrent cells, but\nsometimes impedes precision. We therefore introduce a double-layer architecture\ninitialised with a partial warmup that is shown to greatly improve learning of\nlong time dependencies while maintaining high levels of precision. This\napproach provides a general framework for improving learning abilities of any\nrecurrent cell when long time dependencies are present. We also show\nempirically that other initialisation and pretraining procedures from the\nliterature implicitly foster reachable multistability of recurrent cells.",
          "link": "http://arxiv.org/abs/2106.01001",
          "publishedOn": "2023-07-22T00:55:23.686Z",
          "wordCount": 802,
          "title": "Warming up recurrent neural networks to maximise reachable multistability greatly improves learning. (arXiv:2106.01001v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2208.06620",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Calderon_P/0/1/0/all/0/1\">Pio Calderon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ram_R/0/1/0/all/0/1\">Rohit Ram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rizoiu_M/0/1/0/all/0/1\">Marian-Andrei Rizoiu</a>",
          "description": "Online extremism has severe societal consequences, including normalizing hate\nspeech, user radicalization, and increased social divisions. Various mitigation\nstrategies have been explored to address these consequences. One such strategy\nuses positive interventions: controlled signals that add attention to the\nopinion ecosystem to boost certain opinions. To evaluate the effectiveness of\npositive interventions, we introduce the Opinion Market Model (OMM), a two-tier\nonline opinion ecosystem model that considers both inter-opinion interactions\nand the role of positive interventions. The size of the opinion attention\nmarket is modeled in the first tier using the multivariate discrete-time Hawkes\nprocess; in the second tier, opinions cooperate and compete for market share,\ngiven limited attention using the market share attraction model. We demonstrate\nthe convergence of our proposed estimation scheme on a synthetic dataset. Next,\nwe test OMM on two learning tasks, applying to two real-world datasets to\npredict attention market shares and uncover latent relationships between online\nitems. The first dataset comprises Facebook and Twitter discussions containing\nmoderate and far-right opinions about bushfires and climate change. The second\ndataset captures popular VEVO artists' YouTube and Twitter attention volumes.\nOMM outperforms the state-of-the-art predictive models on both datasets and\ncaptures latent cooperation-competition relations. We uncover (1) self- and\ncross-reinforcement between far-right and moderate opinions on the bushfires\nand (2) pairwise artist relations that correlate with real-world interactions\nsuch as collaborations and long-lasting feuds. Lastly, we use OMM as a testbed\nfor positive interventions and show how media coverage modulates the spread of\nfar-right opinions.",
          "link": "http://arxiv.org/abs/2208.06620",
          "publishedOn": "2023-07-22T00:55:23.678Z",
          "wordCount": 790,
          "title": "Opinion Market Model: Stemming Far-Right Opinion Spread using Positive Interventions. (arXiv:2208.06620v2 [cs.SI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2207.01110",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wunderlich_A/0/1/0/all/0/1\">Adam Wunderlich</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sklar_J/0/1/0/all/0/1\">Jack Sklar</a>",
          "description": "Random noise arising from physical processes is an inherent characteristic of\nmeasurements and a limiting factor for most signal processing and data analysis\ntasks. Given the recent interest in generative adversarial networks (GANs) for\ndata-driven modeling, it is important to determine to what extent GANs can\nfaithfully reproduce noise in target data sets. In this paper, we present an\nempirical investigation that aims to shed light on this issue for time series.\nNamely, we assess two general-purpose GANs for time series that are based on\nthe popular deep convolutional GAN (DCGAN) architecture, a direct time-series\nmodel and an image-based model that uses a short-time Fourier transform (STFT)\ndata representation. The GAN models are trained and quantitatively evaluated\nusing distributions of simulated noise time series with known ground-truth\nparameters. Target time series distributions include a broad range of noise\ntypes commonly encountered in physical measurements, electronics, and\ncommunication systems: band-limited thermal noise, power law noise, shot noise,\nand impulsive noise. We find that GANs are capable of learning many noise\ntypes, although they predictably struggle when the GAN architecture is not well\nsuited to some aspects of the noise, e.g., impulsive time-series with extreme\noutliers. Our findings provide insights into the capabilities and potential\nlimitations of current approaches to time-series GANs and highlight areas for\nfurther research. In addition, our battery of tests provides a useful benchmark\nto aid the development of deep generative models for time series.",
          "link": "http://arxiv.org/abs/2207.01110",
          "publishedOn": "2023-07-22T00:55:23.665Z",
          "wordCount": 783,
          "title": "Data-Driven Modeling of Noise Time Series with Convolutional Generative Adversarial Networks. (arXiv:2207.01110v3 [eess.SP] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.00405",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_R/0/1/0/all/0/1\">Ruiquan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yingbin Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jing Yang</a>",
          "description": "The general sequential decision-making problem, which includes Markov\ndecision processes (MDPs) and partially observable MDPs (POMDPs) as special\ncases, aims at maximizing a cumulative reward by making a sequence of decisions\nbased on a history of observations and actions over time. Recent studies have\nshown that the sequential decision-making problem is statistically learnable if\nit admits a low-rank structure modeled by predictive state representations\n(PSRs). Despite these advancements, existing approaches typically involve\noracles or steps that are not computationally efficient. On the other hand, the\nupper confidence bound (UCB) based approaches, which have served successfully\nas computationally efficient methods in bandits and MDPs, have not been\ninvestigated for more general PSRs, due to the difficulty of optimistic bonus\ndesign in these more challenging settings. This paper proposes the first known\nUCB-type approach for PSRs, featuring a novel bonus term that upper bounds the\ntotal variation distance between the estimated and true models. We further\ncharacterize the sample complexity bounds for our designed UCB-type algorithms\nfor both online and offline PSRs. In contrast to existing approaches for PSRs,\nour UCB-type algorithms enjoy computational efficiency, last-iterate guaranteed\nnear-optimal policy, and guaranteed model accuracy.",
          "link": "http://arxiv.org/abs/2307.00405",
          "publishedOn": "2023-07-22T00:55:23.642Z",
          "wordCount": 722,
          "title": "Provably Efficient UCB-type Algorithms For Learning Predictive State Representations. (arXiv:2307.00405v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.10980",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_S/0/1/0/all/0/1\">Sihui Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahloujifar_S/0/1/0/all/0/1\">Saeed Mahloujifar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_C/0/1/0/all/0/1\">Chong Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sehwag_V/0/1/0/all/0/1\">Vikash Sehwag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1\">Prateek Mittal</a>",
          "description": "The bulk of existing research in defending against adversarial examples\nfocuses on defending against a single (typically bounded Lp-norm) attack, but\nfor a practical setting, machine learning (ML) models should be robust to a\nwide variety of attacks. In this paper, we present the first unified framework\nfor considering multiple attacks against ML models. Our framework is able to\nmodel different levels of learner's knowledge about the test-time adversary,\nallowing us to model robustness against unforeseen attacks and robustness\nagainst unions of attacks. Using our framework, we present the first\nleaderboard, MultiRobustBench, for benchmarking multiattack evaluation which\ncaptures performance across attack types and attack strengths. We evaluate the\nperformance of 16 defended models for robustness against a set of 9 different\nattack types, including Lp-based threat models, spatial transformations, and\ncolor changes, at 20 different attack strengths (180 attacks total).\nAdditionally, we analyze the state of current defenses against multiple\nattacks. Our analysis shows that while existing defenses have made progress in\nterms of average robustness across the set of attacks used, robustness against\nthe worst-case attack is still a big open problem as all existing models\nperform worse than random guessing.",
          "link": "http://arxiv.org/abs/2302.10980",
          "publishedOn": "2023-07-22T00:55:23.632Z",
          "wordCount": 727,
          "title": "MultiRobustBench: Benchmarking Robustness Against Multiple Attacks. (arXiv:2302.10980v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.14030",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chavan_T/0/1/0/all/0/1\">Tanmay Chavan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gokhale_O/0/1/0/all/0/1\">Omkar Gokhale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kane_A/0/1/0/all/0/1\">Aditya Kane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patankar_S/0/1/0/all/0/1\">Shantanu Patankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1\">Raviraj Joshi</a>",
          "description": "The research on code-mixed data is limited due to the unavailability of\ndedicated code-mixed datasets and pre-trained language models. In this work, we\nfocus on the low-resource Indian language Marathi which lacks any prior work in\ncode-mixing. We present L3Cube-MeCorpus, a large code-mixed Marathi-English\n(Mr-En) corpus with 10 million social media sentences for pretraining. We also\nrelease L3Cube-MeBERT and MeRoBERTa, code-mixed BERT-based transformer models\npre-trained on MeCorpus. Furthermore, for benchmarking, we present three\nsupervised datasets MeHate, MeSent, and MeLID for downstream tasks like\ncode-mixed Mr-En hate speech detection, sentiment analysis, and language\nidentification respectively. These evaluation datasets individually consist of\nmanually annotated \\url{~}12,000 Marathi-English code-mixed tweets. Ablations\nshow that the models trained on this novel corpus significantly outperform the\nexisting state-of-the-art BERT models. This is the first work that presents\nartifacts for code-mixed Marathi research. All datasets and models are publicly\nreleased at https://github.com/l3cube-pune/MarathiNLP .",
          "link": "http://arxiv.org/abs/2306.14030",
          "publishedOn": "2023-07-22T00:55:23.623Z",
          "wordCount": 682,
          "title": "My Boli: Code-mixed Marathi-English Corpora, Pretrained Language Models and Evaluation Benchmarks. (arXiv:2306.14030v2 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10560",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Huang_P/0/1/0/all/0/1\">Po-Wei Huang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Rebentrost_P/0/1/0/all/0/1\">Patrick Rebentrost</a>",
          "description": "Quantum computing has the potential to provide substantial computational\nadvantages over current state-of-the-art classical supercomputers. However,\ncurrent hardware is not advanced enough to execute fault-tolerant quantum\nalgorithms. An alternative of using hybrid quantum-classical computing with\nvariational algorithms can exhibit barren plateau issues, causing slow\nconvergence of gradient-based optimization techniques. In this paper, we\ndiscuss \"post-variational strategies\", which shift tunable parameters from the\nquantum computer to the classical computer, opting for ensemble strategies when\noptimizing quantum models. We discuss various strategies and design principles\nfor constructing individual quantum circuits, where the resulting ensembles can\nbe optimized with convex programming. Further, we discuss architectural designs\nof post-variational quantum neural networks and analyze the propagation of\nestimation errors throughout such neural networks. Lastly, we show that our\nalgorithm can be applied to real-world applications such as image\nclassification on handwritten digits, producing a 96% classification accuracy.",
          "link": "http://arxiv.org/abs/2307.10560",
          "publishedOn": "2023-07-22T00:55:23.555Z",
          "wordCount": null,
          "title": "Post-variational quantum neural networks. (arXiv:2307.10560v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10299",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Shen_X/0/1/0/all/0/1\">Xinwei Shen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Buhlmann_P/0/1/0/all/0/1\">Peter B&#xfc;hlmann</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Taeb_A/0/1/0/all/0/1\">Armeen Taeb</a>",
          "description": "Since distribution shifts are common in real-world applications, there is a\npressing need for developing prediction models that are robust against such\nshifts. Existing frameworks, such as empirical risk minimization or\ndistributionally robust optimization, either lack generalizability for unseen\ndistributions or rely on postulated distance measures. Alternatively, causality\noffers a data-driven and structural perspective to robust predictions. However,\nthe assumptions necessary for causal inference can be overly stringent, and the\nrobustness offered by such causal models often lacks flexibility. In this\npaper, we focus on causality-oriented robustness and propose Distributional\nRobustness via Invariant Gradients (DRIG), a method that exploits general\nadditive interventions in training data for robust predictions against unseen\ninterventions, and naturally interpolates between in-distribution prediction\nand causality. In a linear setting, we prove that DRIG yields predictions that\nare robust among a data-dependent class of distribution shifts. Furthermore, we\nshow that our framework includes anchor regression (Rothenh\\\"ausler et al.\\\n2021) as a special case, and that it yields prediction models that protect\nagainst more diverse perturbations. We extend our approach to the\nsemi-supervised domain adaptation setting to further improve prediction\nperformance. Finally, we empirically validate our methods on synthetic\nsimulations and on single-cell data.",
          "link": "http://arxiv.org/abs/2307.10299",
          "publishedOn": "2023-07-22T00:55:22.908Z",
          "wordCount": 689,
          "title": "Causality-oriented robustness: exploiting general additive interventions. (arXiv:2307.10299v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10214",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Siracusano_G/0/1/0/all/0/1\">Giuseppe Siracusano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanvito_D/0/1/0/all/0/1\">Davide Sanvito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_R/0/1/0/all/0/1\">Roberto Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_M/0/1/0/all/0/1\">Manikantan Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamatchi_S/0/1/0/all/0/1\">Sivakaman Kamatchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takahashi_W/0/1/0/all/0/1\">Wataru Takahashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawakita_M/0/1/0/all/0/1\">Masaru Kawakita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakumaru_T/0/1/0/all/0/1\">Takahiro Kakumaru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bifulco_R/0/1/0/all/0/1\">Roberto Bifulco</a>",
          "description": "Cyber Threat Intelligence (CTI) plays a crucial role in assessing risks and\nenhancing security for organizations. However, the process of extracting\nrelevant information from unstructured text sources can be expensive and\ntime-consuming. Our empirical experience shows that existing tools for\nautomated structured CTI extraction have performance limitations. Furthermore,\nthe community lacks a common benchmark to quantitatively assess their\nperformance. We fill these gaps providing a new large open benchmark dataset\nand aCTIon, a structured CTI information extraction tool. The dataset includes\n204 real-world publicly available reports and their corresponding structured\nCTI information in STIX format. Our team curated the dataset involving three\nindependent groups of CTI analysts working over the course of several months.\nTo the best of our knowledge, this dataset is two orders of magnitude larger\nthan previously released open source datasets. We then design aCTIon,\nleveraging recently introduced large language models (GPT3.5) in the context of\ntwo custom information extraction pipelines. We compare our method with 10\nsolutions presented in previous work, for which we develop our own\nimplementations when open-source implementations were lacking. Our results show\nthat aCTIon outperforms previous work for structured CTI extraction with an\nimprovement of the F1-score from 10%points to 50%points across all tasks.",
          "link": "http://arxiv.org/abs/2307.10214",
          "publishedOn": "2023-07-22T00:55:22.884Z",
          "wordCount": 731,
          "title": "Time for aCTIon: Automated Analysis of Cyber Threat Intelligence in the Wild. (arXiv:2307.10214v1 [cs.CR])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10455",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gharaee_Z/0/1/0/all/0/1\">Zahra Gharaee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Z/0/1/0/all/0/1\">ZeMing Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pellegrino_N/0/1/0/all/0/1\">Nicholas Pellegrino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zarubiieva_I/0/1/0/all/0/1\">Iuliia Zarubiieva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haurum_J/0/1/0/all/0/1\">Joakim Bruslund Haurum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lowe_S/0/1/0/all/0/1\">Scott C. Lowe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKeown_J/0/1/0/all/0/1\">Jaclyn T.A. McKeown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_C/0/1/0/all/0/1\">Chris C.Y. Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McLeod_J/0/1/0/all/0/1\">Joschka McLeod</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yi-Yun C Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agda_J/0/1/0/all/0/1\">Jireh Agda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratnasingham_S/0/1/0/all/0/1\">Sujeevan Ratnasingham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinke_D/0/1/0/all/0/1\">Dirk Steinke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_A/0/1/0/all/0/1\">Angel X. Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taylor_G/0/1/0/all/0/1\">Graham W. Taylor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fieguth_P/0/1/0/all/0/1\">Paul Fieguth</a>",
          "description": "In an effort to catalog insect biodiversity, we propose a new large dataset\nof hand-labelled insect images, the BIOSCAN-Insect Dataset. Each record is\ntaxonomically classified by an expert, and also has associated genetic\ninformation including raw nucleotide barcode sequences and assigned barcode\nindex numbers, which are genetically-based proxies for species classification.\nThis paper presents a curated million-image dataset, primarily to train\ncomputer-vision models capable of providing image-based taxonomic assessment,\nhowever, the dataset also presents compelling characteristics, the study of\nwhich would be of interest to the broader machine learning community. Driven by\nthe biological nature inherent to the dataset, a characteristic long-tailed\nclass-imbalance distribution is exhibited. Furthermore, taxonomic labelling is\na hierarchical classification scheme, presenting a highly fine-grained\nclassification problem at lower levels. Beyond spurring interest in\nbiodiversity research within the machine learning community, progress on\ncreating an image-based taxonomic classifier will also further the ultimate\ngoal of all BIOSCAN research: to lay the foundation for a comprehensive survey\nof global biodiversity. This paper introduces the dataset and explores the\nclassification task through the implementation and analysis of a baseline\nclassifier.",
          "link": "http://arxiv.org/abs/2307.10455",
          "publishedOn": "2023-07-22T00:55:22.876Z",
          "wordCount": 730,
          "title": "A Step Towards Worldwide Biodiversity Assessment: The BIOSCAN-1M Insect Dataset. (arXiv:2307.10455v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10434",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1\">Ameesh Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vazquez_Chanlatte_M/0/1/0/all/0/1\">Marcell Vazquez-Chanlatte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Junges_S/0/1/0/all/0/1\">Sebastian Junges</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seshia_S/0/1/0/all/0/1\">Sanjit A. Seshia</a>",
          "description": "Active learning is a well-studied approach to learning formal specifications,\nsuch as automata. In this work, we extend active specification learning by\nproposing a novel framework that strategically requests a combination of\nmembership labels and pair-wise preferences, a popular alternative to\nmembership labels. The combination of pair-wise preferences and membership\nlabels allows for a more flexible approach to active specification learning,\nwhich previously relied on membership labels only. We instantiate our framework\nin two different domains, demonstrating the generality of our approach. Our\nresults suggest that learning from both modalities allows us to robustly and\nconveniently identify specifications via membership and preferences.",
          "link": "http://arxiv.org/abs/2307.10434",
          "publishedOn": "2023-07-22T00:55:22.869Z",
          "wordCount": 628,
          "title": "Learning Formal Specifications from Membership and Preference Queries. (arXiv:2307.10434v1 [cs.FL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08466",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seitz_S/0/1/0/all/0/1\">Steffen Seitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gotz_T/0/1/0/all/0/1\">Thomas G&#xf6;tz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindenberg_C/0/1/0/all/0/1\">Christopher Lindenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tetzlaff_R/0/1/0/all/0/1\">Ronald Tetzlaff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schlegel_S/0/1/0/all/0/1\">Stephan Schlegel</a>",
          "description": "Undetected partial discharges (PDs) are a safety critical issue in high\nvoltage (HV) gas insulated systems (GIS). While the diagnosis of PDs under AC\nvoltage is well-established, the analysis of PDs under DC voltage remains an\nactive research field. A key focus of these investigations is the\nclassification of different PD sources to enable subsequent sophisticated\nanalysis.\n\nIn this paper, we propose and analyze a neural network-based approach for\nclassifying PD signals caused by metallic protrusions and conductive particles\non the insulator of HVDC GIS, without relying on pulse sequence analysis\nfeatures. In contrast to previous approaches, our proposed model can\ndiscriminate the studied PD signals obtained at negative and positive\npotentials, while also generalizing to unseen operating voltage multiples.\nAdditionally, we compare the performance of time- and frequency-domain input\nsignals and explore the impact of different normalization schemes to mitigate\nthe influence of free-space path loss between the sensor and defect location.",
          "link": "http://arxiv.org/abs/2307.08466",
          "publishedOn": "2023-07-19T01:53:31.809Z",
          "wordCount": 734,
          "title": "Generalizable Classification of UHF Partial Discharge Signals in Gas-Insulated HVDC Systems Using Neural Networks. (arXiv:2307.08466v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.13024",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghaderi_H/0/1/0/all/0/1\">Hamid Ghaderi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foreman_B/0/1/0/all/0/1\">Brandon Foreman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nayebi_A/0/1/0/all/0/1\">Amin Nayebi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tipirneni_S/0/1/0/all/0/1\">Sindhu Tipirneni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_C/0/1/0/all/0/1\">Chandan K. Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subbian_V/0/1/0/all/0/1\">Vignesh Subbian</a>",
          "description": "Determining clinically relevant physiological states from multivariate time\nseries data with missing values is essential for providing appropriate\ntreatment for acute conditions such as Traumatic Brain Injury (TBI),\nrespiratory failure, and heart failure. Utilizing non-temporal clustering or\ndata imputation and aggregation techniques may lead to loss of valuable\ninformation and biased analyses. In our study, we apply the SLAC-Time\nalgorithm, an innovative self-supervision-based approach that maintains data\nintegrity by avoiding imputation or aggregation, offering a more useful\nrepresentation of acute patient states. By using SLAC-Time to cluster data in a\nlarge research dataset, we identified three distinct TBI physiological states\nand their specific feature profiles. We employed various clustering evaluation\nmetrics and incorporated input from a clinical domain expert to validate and\ninterpret the identified physiological states. Further, we discovered how\nspecific clinical events and interventions can influence patient states and\nstate transitions.",
          "link": "http://arxiv.org/abs/2303.13024",
          "publishedOn": "2023-07-19T01:53:30.819Z",
          "wordCount": 698,
          "title": "Identifying TBI Physiological States by Clustering Multivariate Clinical Time-Series Data. (arXiv:2303.13024v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.09263",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_K/0/1/0/all/0/1\">Kecheng Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1\">Xiumei Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xuefeng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Ming Ding</a>",
          "description": "As an efficient distributed machine learning approach, Federated learning\n(FL) can obtain a shared model by iterative local model training at the user\nside and global model aggregating at the central server side, thereby\nprotecting privacy of users. Mobile users in FL systems typically communicate\nwith base stations (BSs) via wireless channels, where training performance\ncould be degraded due to unreliable access caused by user mobility. However,\nexisting work only investigates a static scenario or random initialization of\nuser locations, which fail to capture mobility in real-world networks. To\ntackle this issue, we propose a practical model for user mobility in FL across\nmultiple BSs, and develop a user scheduling and resource allocation method to\nminimize the training delay with constrained communication resources.\nSpecifically, we first formulate an optimization problem with user mobility\nthat jointly considers user selection, BS assignment to users, and bandwidth\nallocation to minimize the latency in each communication round. This\noptimization problem turned out to be NP-hard and we proposed a delay-aware\ngreedy search algorithm (DAGSA) to solve it. Simulation results show that the\nproposed algorithm achieves better performance than the state-of-the-art\nbaselines and a certain level of user mobility could improve training\nperformance.",
          "link": "http://arxiv.org/abs/2307.09263",
          "publishedOn": "2023-07-19T01:53:30.802Z",
          "wordCount": 725,
          "title": "Mobility-Aware Joint User Scheduling and Resource Allocation for Low Latency Federated Learning. (arXiv:2307.09263v1 [cs.DC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08939",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xugui Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Anqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kouzel_M/0/1/0/all/0/1\">Maxfield Kouzel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1\">Haotian Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCarty_M/0/1/0/all/0/1\">Morgan McCarty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nita_Rotaru_C/0/1/0/all/0/1\">Cristina Nita-Rotaru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alemzadeh_H/0/1/0/all/0/1\">Homa Alemzadeh</a>",
          "description": "Adaptive Cruise Control (ACC) is a widely used driver assistance feature for\nmaintaining desired speed and safe distance to the leading vehicles. This paper\nevaluates the security of the deep neural network (DNN) based ACC systems under\nstealthy perception attacks that strategically inject perturbations into camera\ndata to cause forward collisions. We present a combined\nknowledge-and-data-driven approach to design a context-aware strategy for the\nselection of the most critical times for triggering the attacks and a novel\noptimization-based method for the adaptive generation of image perturbations at\nrun-time. We evaluate the effectiveness of the proposed attack using an actual\ndriving dataset and a realistic simulation platform with the control software\nfrom a production ACC system and a physical-world driving simulator while\nconsidering interventions by the driver and safety features such as Automatic\nEmergency Braking (AEB) and Forward Collision Warning (FCW). Experimental\nresults show that the proposed attack achieves 142.9x higher success rate in\ncausing accidents than random attacks and is mitigated 89.6% less by the safety\nfeatures while being stealthy and robust to real-world factors and dynamic\nchanges in the environment. This study provides insights into the role of human\noperators and basic safety interventions in preventing attacks.",
          "link": "http://arxiv.org/abs/2307.08939",
          "publishedOn": "2023-07-19T01:53:30.785Z",
          "wordCount": 765,
          "title": "Experimental Security Analysis of DNN-based Adaptive Cruise Control under Context-Aware Perception Attacks. (arXiv:2307.08939v1 [cs.CR])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08535",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Beetz_M/0/1/0/all/0/1\">Marcel Beetz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Banerjee_A/0/1/0/all/0/1\">Abhirup Banerjee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ossenberg_Engels_J/0/1/0/all/0/1\">Julius Ossenberg-Engels</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Grau_V/0/1/0/all/0/1\">Vicente Grau</a>",
          "description": "Cine magnetic resonance imaging (MRI) is the current gold standard for the\nassessment of cardiac anatomy and function. However, it typically only acquires\na set of two-dimensional (2D) slices of the underlying three-dimensional (3D)\nanatomy of the heart, thus limiting the understanding and analysis of both\nhealthy and pathological cardiac morphology and physiology. In this paper, we\npropose a novel fully automatic surface reconstruction pipeline capable of\nreconstructing multi-class 3D cardiac anatomy meshes from raw cine MRI\nacquisitions. Its key component is a multi-class point cloud completion network\n(PCCN) capable of correcting both the sparsity and misalignment issues of the\n3D reconstruction task in a unified model. We first evaluate the PCCN on a\nlarge synthetic dataset of biventricular anatomies and observe Chamfer\ndistances between reconstructed and gold standard anatomies below or similar to\nthe underlying image resolution for multiple levels of slice misalignment.\nFurthermore, we find a reduction in reconstruction error compared to a\nbenchmark 3D U-Net by 32% and 24% in terms of Hausdorff distance and mean\nsurface distance, respectively. We then apply the PCCN as part of our automated\nreconstruction pipeline to 1000 subjects from the UK Biobank study in a\ncross-domain transfer setting and demonstrate its ability to reconstruct\naccurate and topologically plausible biventricular heart meshes with clinical\nmetrics comparable to the previous literature. Finally, we investigate the\nrobustness of our proposed approach and observe its capacity to successfully\nhandle multiple common outlier conditions.",
          "link": "http://arxiv.org/abs/2307.08535",
          "publishedOn": "2023-07-19T01:53:30.779Z",
          "wordCount": 800,
          "title": "Multi-class point cloud completion networks for 3D cardiac anatomy reconstruction from cine magnetic resonance images. (arXiv:2307.08535v2 [eess.IV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08782",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kongmanee_J/0/1/0/all/0/1\">Jaturong Kongmanee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chignell_M/0/1/0/all/0/1\">Mark Chignell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jerath_K/0/1/0/all/0/1\">Khilan Jerath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raman_A/0/1/0/all/0/1\">Abhay Raman</a>",
          "description": "Exfiltration of data via email is a serious cybersecurity threat for many\norganizations. Detecting data exfiltration (anomaly) patterns typically\nrequires labeling, most often done by a human annotator, to reduce the high\nnumber of false alarms. Active Learning (AL) is a promising approach for\nlabeling data efficiently, but it needs to choose an efficient order in which\ncases are to be labeled, and there are uncertainties as to what scoring\nprocedure should be used to prioritize cases for labeling, especially when\ndetecting rare cases of interest is crucial. We propose an adaptive AL sampling\nstrategy that leverages the underlying prior data distribution, as well as\nmodel uncertainty, to produce batches of cases to be labeled that contain\ninstances of rare anomalies. We show that (1) the classifier benefits from a\nbatch of representative and informative instances of both normal and anomalous\nexamples, (2) unsupervised anomaly detection plays a useful role in building\nthe classifier in the early stages of training when relatively little labeling\nhas been done thus far. Our approach to AL for anomaly detection outperformed\nexisting AL approaches on three highly unbalanced UCI benchmarks and on one\nreal-world redacted email data set.",
          "link": "http://arxiv.org/abs/2307.08782",
          "publishedOn": "2023-07-19T01:53:29.881Z",
          "wordCount": 735,
          "title": "Unsupervised Learning of Distributional Properties can Supplement Human Labeling and Increase Active Learning Efficiency in Anomaly Detection. (arXiv:2307.08782v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.09006",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huh_J/0/1/0/all/0/1\">Jaesung Huh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bain_M/0/1/0/all/0/1\">Max Bain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zisserman_A/0/1/0/all/0/1\">Andrew Zisserman</a>",
          "description": "This report presents the technical details of our submission on the EGO4D\nAudio-Visual (AV) Automatic Speech Recognition Challenge 2023 from the\nOxfordVGG team. We present WhisperX, a system for efficient speech\ntranscription of long-form audio with word-level time alignment, along with two\ntext normalisers which are publicly available. Our final submission obtained\n56.0% of the Word Error Rate (WER) on the challenge test set, ranked 1st on the\nleaderboard. All baseline codes and models are available on\nhttps://github.com/m-bain/whisperX.",
          "link": "http://arxiv.org/abs/2307.09006",
          "publishedOn": "2023-07-19T01:53:29.876Z",
          "wordCount": 586,
          "title": "OxfordVGG Submission to the EGO4D AV Transcription Challenge. (arXiv:2307.09006v1 [cs.SD])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.00497",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Babakniya_S/0/1/0/all/0/1\">Sara Babakniya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fabian_Z/0/1/0/all/0/1\">Zalan Fabian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1\">Chaoyang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soltanolkotabi_M/0/1/0/all/0/1\">Mahdi Soltanolkotabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avestimehr_S/0/1/0/all/0/1\">Salman Avestimehr</a>",
          "description": "Deep learning models are prone to forgetting information learned in the past\nwhen trained on new data. This problem becomes even more pronounced in the\ncontext of federated learning (FL), where data is decentralized and subject to\nindependent changes for each user. Continual Learning (CL) studies this\nso-called \\textit{catastrophic forgetting} phenomenon primarily in centralized\nsettings, where the learner has direct access to the complete training dataset.\nHowever, applying CL techniques to FL is not straightforward due to privacy\nconcerns and resource limitations. This paper presents a framework for\nfederated class incremental learning that utilizes a generative model to\nsynthesize samples from past distributions instead of storing part of past\ndata. Then, clients can leverage the generative model to mitigate catastrophic\nforgetting locally. The generative model is trained on the server using\ndata-free methods at the end of each task without requesting data from clients.\nTherefore, it reduces the risk of data leakage as opposed to training it on the\nclient's private data. We demonstrate significant improvements for the\nCIFAR-100 dataset compared to existing baselines.",
          "link": "http://arxiv.org/abs/2307.00497",
          "publishedOn": "2023-07-19T01:53:29.870Z",
          "wordCount": 719,
          "title": "Don't Memorize; Mimic The Past: Federated Class Incremental Learning Without Episodic Memory. (arXiv:2307.00497v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08929",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Ma_X/0/1/0/all/0/1\">Xingyue Ma</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Bellaiche_L/0/1/0/all/0/1\">L. Bellaiche</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Wu_D/0/1/0/all/0/1\">Di Wu</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Yang_Y/0/1/0/all/0/1\">Yurong Yang</a>",
          "description": "The first-principles-based effective Hamiltonian is widely used to predict\nand simulate the properties of ferroelectrics and relaxor ferroelectrics.\nHowever, the parametrization method of the effective Hamiltonian is complicated\nand hardly can resolve the systems with complex interactions and/or complex\ncomponents. Here, we developed an on-the-fly machine learning approach to\nparametrize the effective Hamiltonian based on Bayesian linear regression. The\nparametrization is completed in molecular dynamics simulations, with the\nenergy, forces and stress predicted at each step along with their\nuncertainties. First-principles calculations are executed when the\nuncertainties are large to retrain the parameters. This approach provides a\nuniversal and automatic way to compute the effective Hamiltonian parameters for\nany considered systems including complex systems which previous methods can not\nhandle. BaTiO3 and Pb(Sc,Ta)O3 are taken as examples to show the accurateness\nof this approach comparing with conventional first-principles parametrization\nmethod.",
          "link": "http://arxiv.org/abs/2307.08929",
          "publishedOn": "2023-07-19T01:53:29.865Z",
          "wordCount": 668,
          "title": "On-the-fly machine learning for parametrization of the effective Hamiltonian. (arXiv:2307.08929v1 [cond-mat.mtrl-sci])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08962",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Murthy_R/0/1/0/all/0/1\">Rithesh Murthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heinecke_S/0/1/0/all/0/1\">Shelby Heinecke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niebles_J/0/1/0/all/0/1\">Juan Carlos Niebles</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_L/0/1/0/all/0/1\">Le Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1\">Weiran Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yihao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zeyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gokul_A/0/1/0/all/0/1\">Akash Gokul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arpit_D/0/1/0/all/0/1\">Devansh Arpit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ran Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mui_P/0/1/0/all/0/1\">Phil Mui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1\">Silvio Savarese</a>",
          "description": "In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.",
          "link": "http://arxiv.org/abs/2307.08962",
          "publishedOn": "2023-07-19T01:53:29.802Z",
          "wordCount": 680,
          "title": "REX: Rapid Exploration and eXploitation for AI Agents. (arXiv:2307.08962v1 [cs.AI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08558",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Xia_F/0/1/0/all/0/1\">Fei Xia</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kim_K/0/1/0/all/0/1\">Kyungduk Kim</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Eliezer_Y/0/1/0/all/0/1\">Yaniv Eliezer</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Shaughnessy_L/0/1/0/all/0/1\">Liam Shaughnessy</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gigan_S/0/1/0/all/0/1\">Sylvain Gigan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Cao_H/0/1/0/all/0/1\">Hui Cao</a>",
          "description": "Deep learning has fundamentally transformed artificial intelligence, but the\never-increasing complexity in deep learning models calls for specialized\nhardware accelerators. Optical accelerators can potentially offer enhanced\nperformance, scalability, and energy efficiency. However, achieving nonlinear\nmapping, a critical component of neural networks, remains challenging\noptically. Here, we introduce a design that leverages multiple scattering in a\nreverberating cavity to passively induce optical nonlinear random mapping,\nwithout the need for additional laser power. A key advantage emerging from our\nwork is that we show we can perform optical data compression, facilitated by\nmultiple scattering in the cavity, to efficiently compress and retain vital\ninformation while also decreasing data dimensionality. This allows rapid\noptical information processing and generation of low dimensional mixtures of\nhighly nonlinear features. These are particularly useful for applications\ndemanding high-speed analysis and responses such as in edge computing devices.\nUtilizing rapid optical information processing capabilities, our optical\nplatforms could potentially offer more efficient and real-time processing\nsolutions for a broad range of applications. We demonstrate the efficacy of our\ndesign in improving computational performance across tasks, including\nclassification, image reconstruction, key-point detection, and object\ndetection, all achieved through optical data compression combined with a\ndigital decoder. Notably, we observed high performance, at an extreme\ncompression ratio, for real-time pedestrian detection. Our findings pave the\nway for novel algorithms and architectural designs for optical computing.",
          "link": "http://arxiv.org/abs/2307.08558",
          "publishedOn": "2023-07-19T01:53:29.797Z",
          "wordCount": 763,
          "title": "Deep Learning with Passive Optical Nonlinear Mapping. (arXiv:2307.08558v2 [physics.optics] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2206.10381",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carballo_K/0/1/0/all/0/1\">Kimberly Villalobos Carballo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Na_L/0/1/0/all/0/1\">Liangyuan Na</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boussioux_L/0/1/0/all/0/1\">L&#xe9;onard Boussioux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_C/0/1/0/all/0/1\">Cynthia Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soenksen_L/0/1/0/all/0/1\">Luis R. Soenksen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bertsimas_D/0/1/0/all/0/1\">Dimitris Bertsimas</a>",
          "description": "Tabular data is essential for applying machine learning tasks across various\nindustries. However, traditional data processing methods do not fully utilize\nall the information available in the tables, ignoring important contextual\ninformation such as column header descriptions. In addition, pre-processing\ndata into a tabular format can remain a labor-intensive bottleneck in model\ndevelopment. This work introduces TabText, a processing and feature extraction\nframework that extracts contextual information from tabular data structures.\nTabText addresses processing difficulties by converting the content into\nlanguage and utilizing pre-trained large language models (LLMs). We evaluate\nour framework on nine healthcare prediction tasks ranging from patient\ndischarge, ICU admission, and mortality. We show that 1) applying our TabText\nframework enables the generation of high-performing and simple machine learning\nbaseline models with minimal data pre-processing, and 2) augmenting\npre-processed tabular data with TabText representations improves the average\nand worst-case AUC performance of standard machine learning models by as much\nas 6%.",
          "link": "http://arxiv.org/abs/2206.10381",
          "publishedOn": "2023-07-19T01:53:29.781Z",
          "wordCount": 703,
          "title": "TabText: A Flexible and Contextual Approach to Tabular Data Representation. (arXiv:2206.10381v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.09072",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ovadia_O/0/1/0/all/0/1\">Oded Ovadia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turkel_E/0/1/0/all/0/1\">Eli Turkel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kahana_A/0/1/0/all/0/1\">Adar Kahana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1\">George Em Karniadakis</a>",
          "description": "Solving partial differential equations (PDEs) using a data-driven approach\nhas become increasingly common. The recent development of the operator learning\nparadigm has enabled the solution of a broader range of PDE-related problems.\nWe propose an operator learning method to solve time-dependent PDEs\ncontinuously in time without needing any temporal discretization. The proposed\napproach, named DiTTO, is inspired by latent diffusion models. While diffusion\nmodels are usually used in generative artificial intelligence tasks, their\ntime-conditioning mechanism is extremely useful for PDEs. The\ndiffusion-inspired framework is combined with elements from the Transformer\narchitecture to improve its capabilities.\n\nWe demonstrate the effectiveness of the new approach on a wide variety of\nPDEs in multiple dimensions, namely the 1-D Burgers' equation, 2-D\nNavier-Stokes equations, and the acoustic wave equation in 2-D and 3-D. DiTTO\nachieves state-of-the-art results in terms of accuracy for these problems. We\nalso present a method to improve the performance of DiTTO by using fast\nsampling concepts from diffusion models. Finally, we show that DiTTO can\naccurately perform zero-shot super-resolution in time.",
          "link": "http://arxiv.org/abs/2307.09072",
          "publishedOn": "2023-07-19T01:53:29.768Z",
          "wordCount": 681,
          "title": "DiTTO: Diffusion-inspired Temporal Transformer Operator. (arXiv:2307.09072v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04550",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bae_S/0/1/0/all/0/1\">Seohui Bae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seoyoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_H/0/1/0/all/0/1\">Hyemin Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_W/0/1/0/all/0/1\">Woohyung Lim</a>",
          "description": "Recent regulation on right-to-be-forgotten emerges tons of interest in\nunlearning pre-trained machine learning models. While approximating a\nstraightforward yet expensive approach of retrain-from-scratch, recent machine\nunlearning methods unlearn a sample by updating weights to remove its influence\non the weight parameters. In this paper, we introduce a simple yet effective\napproach to remove a data influence on the deep generative model. Inspired by\nworks in multi-task learning, we propose to manipulate gradients to regularize\nthe interplay of influence among samples by projecting gradients onto the\nnormal plane of the gradients to be retained. Our work is agnostic to\nstatistics of the removal samples, outperforming existing baselines while\nproviding theoretical analysis for the first time in unlearning a generative\nmodel.",
          "link": "http://arxiv.org/abs/2307.04550",
          "publishedOn": "2023-07-19T01:53:29.761Z",
          "wordCount": 654,
          "title": "Gradient Surgery for One-shot Unlearning on Generative Model. (arXiv:2307.04550v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08674",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zha_L/0/1/0/all/0/1\">Liangyu Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Junlin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Liyao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qingyi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Saisai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1\">Jing Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1\">Changbao Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_A/0/1/0/all/0/1\">Aofeng Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chen Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shou_K/0/1/0/all/0/1\">Kaizhe Shou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Miao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wufang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1\">Guoshan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_C/0/1/0/all/0/1\">Chao Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1\">Yali Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1\">Wentao Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yiming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1\">Xinglong Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jie Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haobo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Gang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Junbo Zhao</a>",
          "description": "Tables are prevalent in real-world databases, requiring significant time and\neffort for humans to analyze and manipulate. The advancements in large language\nmodels (LLMs) have made it possible to interact with tables using natural\nlanguage input, bringing this capability closer to reality. In this paper, we\npresent TableGPT, a unified fine-tuned framework that enables LLMs to\nunderstand and operate on tables using external functional commands. It\nintroduces the capability to seamlessly interact with tables, enabling a wide\nrange of functionalities such as question answering, data manipulation (e.g.,\ninsert, delete, query, and modify operations), data visualization, analysis\nreport generation, and automated prediction. TableGPT aims to provide\nconvenience and accessibility to users by empowering them to effortlessly\nleverage tabular data. At the core of TableGPT lies the novel concept of global\ntabular representations, which empowers LLMs to gain a comprehensive\nunderstanding of the entire table beyond meta-information. By jointly training\nLLMs on both table and text modalities, TableGPT achieves a deep understanding\nof tabular data and the ability to perform complex operations on tables through\nchain-of-command instructions. Importantly, TableGPT offers the advantage of\nbeing a self-contained system rather than relying on external API interfaces.\nMoreover, it supports efficient data process flow, query rejection (when\nappropriate) and private deployment, enabling faster domain data fine-tuning\nand ensuring data privacy, which enhances the framework's adaptability to\nspecific use cases.",
          "link": "http://arxiv.org/abs/2307.08674",
          "publishedOn": "2023-07-19T01:53:29.218Z",
          "wordCount": 800,
          "title": "TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT. (arXiv:2307.08674v2 [cs.AI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08706",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shetiya_S/0/1/0/all/0/1\">Suraj Shetiya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_S/0/1/0/all/0/1\">Shohedul Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asudeh_A/0/1/0/all/0/1\">Abolfazl Asudeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_G/0/1/0/all/0/1\">Gautam Das</a>",
          "description": "Linear Regression is a seminal technique in statistics and machine learning,\nwhere the objective is to build linear predictive models between a response\n(i.e., dependent) variable and one or more predictor (i.e., independent)\nvariables. In this paper, we revisit the classical technique of Quantile\nRegression (QR), which is statistically a more robust alternative to the other\nclassical technique of Ordinary Least Square Regression (OLS). However, while\nthere exist efficient algorithms for OLS, almost all of the known results for\nQR are only weakly polynomial. Towards filling this gap, this paper proposes\nseveral efficient strongly polynomial algorithms for QR for various settings.\nFor two dimensional QR, making a connection to the geometric concept of\n$k$-set, we propose an algorithm with a deterministic worst-case time\ncomplexity of $\\mathcal{O}(n^{4/3} polylog(n))$ and an expected time complexity\nof $\\mathcal{O}(n^{4/3})$ for the randomized version. We also propose a\nrandomized divide-and-conquer algorithm -- RandomizedQR with an expected time\ncomplexity of $\\mathcal{O}(n\\log^2{(n)})$ for two dimensional QR problem. For\nthe general case with more than two dimensions, our RandomizedQR algorithm has\nan expected time complexity of $\\mathcal{O}(n^{d-1}\\log^2{(n)})$.",
          "link": "http://arxiv.org/abs/2307.08706",
          "publishedOn": "2023-07-19T01:53:29.161Z",
          "wordCount": 681,
          "title": "Efficient Strongly Polynomial Algorithms for Quantile Regression. (arXiv:2307.08706v1 [cs.CG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.06849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1\">Wenqian Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yunsheng Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1\">Xu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1\">Kun Tang</a>",
          "description": "Though Transformers have achieved promising results in many computer vision\ntasks, they tend to be over-confident in predictions, as the standard Dot\nProduct Self-Attention (DPSA) can barely preserve distance for the unbounded\ninput domain. In this work, we fill this gap by proposing a novel Lipschitz\nRegularized Transformer (LRFormer). Specifically, we present a new similarity\nfunction with the distance within Banach Space to ensure the Lipschitzness and\nalso regularize the term by a contractive Lipschitz Bound. The proposed method\nis analyzed with a theoretical guarantee, providing a rigorous basis for its\neffectiveness and reliability. Extensive experiments conducted on standard\nvision benchmarks demonstrate that our method outperforms the state-of-the-art\nsingle forward pass approaches in prediction, calibration, and uncertainty\nestimation.",
          "link": "http://arxiv.org/abs/2306.06849",
          "publishedOn": "2023-07-19T01:53:29.049Z",
          "wordCount": null,
          "title": "Mitigating Transformer Overconfidence via Lipschitz Regularization. (arXiv:2306.06849v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08920",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wallace_B/0/1/0/all/0/1\">Brent A. Wallace</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Si_J/0/1/0/all/0/1\">Jennie Si</a>",
          "description": "Continuous-time nonlinear optimal control problems hold great promise in\nreal-world applications. After decades of development, reinforcement learning\n(RL) has achieved some of the greatest successes as a general nonlinear control\ndesign method. However, a recent comprehensive analysis of state-of-the-art\ncontinuous-time RL (CT-RL) methods, namely, adaptive dynamic programming\n(ADP)-based CT-RL algorithms, reveals they face significant design challenges\ndue to their complexity, numerical conditioning, and dimensional scaling\nissues. Despite advanced theoretical results, existing ADP CT-RL synthesis\nmethods are inadequate in solving even small, academic problems. The goal of\nthis work is thus to introduce a suite of new CT-RL algorithms for control of\naffine nonlinear systems. Our design approach relies on two important factors.\nFirst, our methods are applicable to physical systems that can be partitioned\ninto smaller subproblems. This constructive consideration results in reduced\ndimensionality and greatly improved intuitiveness of design. Second, we\nintroduce a new excitation framework to improve persistence of excitation (PE)\nand numerical conditioning performance via classical input/output insights.\nSuch a design-centric approach is the first of its kind in the ADP CT-RL\ncommunity. In this paper, we progressively introduce a suite of (decentralized)\nexcitable integral reinforcement learning (EIRL) algorithms. We provide\nconvergence and closed-loop stability guarantees, and we demonstrate these\nguarantees on a significant application problem of controlling an unstable,\nnonminimum phase hypersonic vehicle (HSV).",
          "link": "http://arxiv.org/abs/2307.08920",
          "publishedOn": "2023-07-19T01:53:29.046Z",
          "wordCount": null,
          "title": "Continuous-Time Reinforcement Learning: New Design Algorithms with Theoretical Insights and Performance Guarantees. (arXiv:2307.08920v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09055",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wu_T/0/1/0/all/0/1\">Tong Wu</a>",
          "description": "Low-rank tensor analysis has received widespread attention with many\npractical applications. However, the tensor data are often contaminated by\noutliers or sample-specific corruptions. How to recover the tensor data that\nare corrupted by outliers and perform data clustering remains a challenging\nproblem. This paper develops an outlier-robust tensor low-rank representation\n(OR-TLRR) method for simultaneous outlier detection and tensor data clustering\nbased on the tensor singular value decomposition (t-SVD) algebraic framework.\nIt is motivated by the recently proposed tensor-tensor product induced by\ninvertible linear transforms that satisfy certain conditions. For tensor\nobservations with arbitrary outlier corruptions, OR-TLRR has provable\nperformance guarantee for exactly recovering the row space of clean data and\ndetecting outliers under mild conditions. Moreover, an extension of OR-TLRR is\nalso proposed to handle the case when parts of the data are missing. Finally,\nextensive experimental results on both synthetic and real data demonstrate the\neffectiveness of the proposed algorithms.",
          "link": "http://arxiv.org/abs/2307.09055",
          "publishedOn": "2023-07-19T01:53:29.046Z",
          "wordCount": null,
          "title": "Outlier-Robust Tensor Low-Rank Representation for Data Clustering. (arXiv:2307.09055v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.01426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kujanpaa_K/0/1/0/all/0/1\">Kalle Kujanp&#xe4;&#xe4;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babadi_A/0/1/0/all/0/1\">Amin Babadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kannala_J/0/1/0/all/0/1\">Juho Kannala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilin_A/0/1/0/all/0/1\">Alexander Ilin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pajarinen_J/0/1/0/all/0/1\">Joni Pajarinen</a>",
          "description": "In many complex sequential decision-making tasks, online planning is crucial\nfor high performance. For efficient online planning, Monte Carlo Tree Search\n(MCTS) employs a principled mechanism for trading off exploration for\nexploitation. MCTS outperforms comparison methods in many discrete\ndecision-making domains such as Go, Chess, and Shogi. Following, extensions of\nMCTS to continuous domains have been proposed. However, the inherent high\nbranching factor and the resulting explosion of search tree size are limiting\nexisting methods. To address this problem, we propose Continuous Monte Carlo\nGraph Search (CMCGS), a novel extension of MCTS to online planning in\nenvironments with continuous state and action spaces. CMCGS takes advantage of\nthe insight that, during planning, sharing the same action policy between\nseveral states can yield high performance. To implement this idea, at each time\nstep, CMCGS clusters similar states into a limited number of stochastic action\nbandit nodes, which produce a layered directed graph instead of an MCTS search\ntree. Experimental evaluation shows that CMCGS outperforms comparable planning\nmethods in several complex continuous DeepMind Control Suite benchmarks and a\n2D navigation task with limited sample budgets. Furthermore, CMCGS can be\nparallelized to scale up and it outperforms the Cross-Entropy Method (CEM) in\ncontinuous control with learned dynamics models.",
          "link": "http://arxiv.org/abs/2210.01426",
          "publishedOn": "2023-07-19T01:53:29.046Z",
          "wordCount": null,
          "title": "Continuous Monte Carlo Graph Search. (arXiv:2210.01426v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09458",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lieberum_T/0/1/0/all/0/1\">Tom Lieberum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahtz_M/0/1/0/all/0/1\">Matthew Rahtz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kramar_J/0/1/0/all/0/1\">J&#xe1;nos Kram&#xe1;r</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irving_G/0/1/0/all/0/1\">Geoffrey Irving</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1\">Rohin Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mikulik_V/0/1/0/all/0/1\">Vladimir Mikulik</a>",
          "description": "\\emph{Circuit analysis} is a promising technique for understanding the\ninternal mechanisms of language models. However, existing analyses are done in\nsmall models far from the state of the art. To address this, we present a case\nstudy of circuit analysis in the 70B Chinchilla model, aiming to test the\nscalability of circuit analysis. In particular, we study multiple-choice\nquestion answering, and investigate Chinchilla's capability to identify the\ncorrect answer \\emph{label} given knowledge of the correct answer \\emph{text}.\nWe find that the existing techniques of logit attribution, attention pattern\nvisualization, and activation patching naturally scale to Chinchilla, allowing\nus to identify and categorize a small set of `output nodes' (attention heads\nand MLPs).\n\nWe further study the `correct letter' category of attention heads aiming to\nunderstand the semantics of their features, with mixed results. For normal\nmultiple-choice question answers, we significantly compress the query, key and\nvalue subspaces of the head without loss of performance when operating on the\nanswer labels for multiple-choice questions, and we show that the query and key\nsubspaces represent an `Nth item in an enumeration' feature to at least some\nextent. However, when we attempt to use this explanation to understand the\nheads' behaviour on a more general distribution including randomized answer\nlabels, we find that it is only a partial explanation, suggesting there is more\nto learn about the operation of `correct letter' heads on multiple choice\nquestion answering.",
          "link": "http://arxiv.org/abs/2307.09458",
          "publishedOn": "2023-07-19T01:53:29.045Z",
          "wordCount": null,
          "title": "Does Circuit Analysis Interpretability Scale? Evidence from Multiple Choice Capabilities in Chinchilla. (arXiv:2307.09458v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08955",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Namvar_A/0/1/0/all/0/1\">Anahita Namvar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thapa_C/0/1/0/all/0/1\">Chandra Thapa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanhere_S/0/1/0/all/0/1\">Salil S. Kanhere</a>",
          "description": "IoT device identification is the process of recognizing and verifying\nconnected IoT devices to the network. This is an essential process for ensuring\nthat only authorized devices can access the network, and it is necessary for\nnetwork management and maintenance. In recent years, machine learning models\nhave been used widely for automating the process of identifying devices in the\nnetwork. However, these models are vulnerable to adversarial attacks that can\ncompromise their accuracy and effectiveness. To better secure device\nidentification models, discretization techniques enable reduction in the\nsensitivity of machine learning models to adversarial attacks contributing to\nthe stability and reliability of the model. On the other hand, Ensemble methods\ncombine multiple heterogeneous models to reduce the impact of remaining noise\nor errors in the model. Therefore, in this paper, we integrate discretization\ntechniques and ensemble methods and examine it on model robustness against\nadversarial attacks. In other words, we propose a discretization-based ensemble\nstacking technique to improve the security of our ML models. We evaluate the\nperformance of different ML-based IoT device identification models against\nwhite box and black box attacks using a real-world dataset comprised of network\ntraffic from 28 IoT devices. We demonstrate that the proposed method enables\nrobustness to the models for IoT device identification.",
          "link": "http://arxiv.org/abs/2307.08955",
          "publishedOn": "2023-07-19T01:53:29.030Z",
          "wordCount": null,
          "title": "Discretization-based ensemble model for robust learning in IoT. (arXiv:2307.08955v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08982",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yao_S/0/1/0/all/0/1\">Shibo Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dantong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koutis_I/0/1/0/all/0/1\">Ioannis Koutis</a>",
          "description": "Neural networks have achieved remarkable performance in various application\ndomains. Nevertheless, a large number of weights in pre-trained deep neural\nnetworks prohibit them from being deployed on smartphones and embedded systems.\nIt is highly desirable to obtain lightweight versions of neural networks for\ninference in edge devices. Many cost-effective approaches were proposed to\nprune dense and convolutional layers that are common in deep neural networks\nand dominant in the parameter space. However, a unified theoretical foundation\nfor the problem mostly is missing. In this paper, we identify the close\nconnection between matrix spectrum learning and neural network training for\ndense and convolutional layers and argue that weight pruning is essentially a\nmatrix sparsification process to preserve the spectrum. Based on the analysis,\nwe also propose a matrix sparsification algorithm tailored for neural network\npruning that yields better pruning result. We carefully design and conduct\nexperiments to support our arguments. Hence we provide a consolidated viewpoint\nfor neural network pruning and enhance the interpretability of deep neural\nnetworks by identifying and preserving the critical neural weights.",
          "link": "http://arxiv.org/abs/2307.08982",
          "publishedOn": "2023-07-19T01:53:29.030Z",
          "wordCount": null,
          "title": "Neural Network Pruning as Spectrum Preserving Process. (arXiv:2307.08982v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.09211",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ali_M/0/1/0/all/0/1\">Momina Liaqat Ali</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rauf_Z/0/1/0/all/0/1\">Zunaira Rauf</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Khan_A/0/1/0/all/0/1\">Asifullah Khan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sohail_A/0/1/0/all/0/1\">Anabia Sohail</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ullah_R/0/1/0/all/0/1\">Rafi Ullah</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gwak_J/0/1/0/all/0/1\">Jeonghwan Gwak</a>",
          "description": "Transformers, due to their ability to learn long range dependencies, have\novercome the shortcomings of convolutional neural networks (CNNs) for global\nperspective learning. Therefore, they have gained the focus of researchers for\nseveral vision related tasks including medical diagnosis. However, their\nmulti-head attention module only captures global level feature representations,\nwhich is insufficient for medical images. To address this issue, we propose a\nChannel Boosted Hybrid Vision Transformer (CB HVT) that uses transfer learning\nto generate boosted channels and employs both transformers and CNNs to analyse\nlymphocytes in histopathological images. The proposed CB HVT comprises five\nmodules, including a channel generation module, channel exploitation module,\nchannel merging module, region-aware module, and a detection and segmentation\nhead, which work together to effectively identify lymphocytes. The channel\ngeneration module uses the idea of channel boosting through transfer learning\nto extract diverse channels from different auxiliary learners. In the CB HVT,\nthese boosted channels are first concatenated and ranked using an attention\nmechanism in the channel exploitation module. A fusion block is then utilized\nin the channel merging module for a gradual and systematic merging of the\ndiverse boosted channels to improve the network's learning representations. The\nCB HVT also employs a proposal network in its region aware module and a head to\neffectively identify objects, even in overlapping regions and with artifacts.\nWe evaluated the proposed CB HVT on two publicly available datasets for\nlymphocyte assessment in histopathological images. The results show that CB HVT\noutperformed other state of the art detection models, and has good\ngeneralization ability, demonstrating its value as a tool for pathologists.",
          "link": "http://arxiv.org/abs/2305.09211",
          "publishedOn": "2023-07-19T01:53:29.030Z",
          "wordCount": null,
          "title": "CB-HVTNet: A channel-boosted hybrid vision transformer network for lymphocyte assessment in histopathological images. (arXiv:2305.09211v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08713",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sajid_M/0/1/0/all/0/1\">M. Sajid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malik_A/0/1/0/all/0/1\">A.K. Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanveer_M/0/1/0/all/0/1\">M. Tanveer</a>",
          "description": "In the realm of data classification, broad learning system (BLS) has proven\nto be a potent tool that utilizes a layer-by-layer feed-forward neural network.\nIt consists of feature learning and enhancement segments, working together to\nextract intricate features from input data. The traditional BLS treats all\nsamples as equally significant, which makes it less robust and less effective\nfor real-world datasets with noises and outliers. To address this issue, we\npropose the fuzzy BLS (F-BLS) model, which assigns a fuzzy membership value to\neach training point to reduce the influence of noises and outliers. In\nassigning the membership value, the F-BLS model solely considers the distance\nfrom samples to the class center in the original feature space without\nincorporating the extent of non-belongingness to a class. We further propose a\nnovel BLS based on intuitionistic fuzzy theory (IF-BLS). The proposed IF-BLS\nutilizes intuitionistic fuzzy numbers based on fuzzy membership and\nnon-membership values to assign scores to training points in the\nhigh-dimensional feature space by using a kernel function. We evaluate the\nperformance of proposed F-BLS and IF-BLS models on 44 UCI benchmark datasets\nacross diverse domains. Furthermore, Gaussian noise is added to some UCI\ndatasets to assess the robustness of the proposed F-BLS and IF-BLS models.\nExperimental results demonstrate superior generalization performance of the\nproposed F-BLS and IF-BLS models compared to baseline models, both with and\nwithout Gaussian noise. Additionally, we implement the proposed F-BLS and\nIF-BLS models on the Alzheimers Disease Neuroimaging Initiative (ADNI) dataset,\nand promising results showcase the models effectiveness in real-world\napplications. The proposed methods offer a promising solution to enhance the\nBLS frameworks ability to handle noise and outliers.",
          "link": "http://arxiv.org/abs/2307.08713",
          "publishedOn": "2023-07-19T01:53:29.028Z",
          "wordCount": null,
          "title": "Intuitionistic Fuzzy Broad Learning System: Enhancing Robustness Against Noise and Outliers. (arXiv:2307.08713v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09143",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kondo_Y/0/1/0/all/0/1\">Yuki Kondo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ukita_N/0/1/0/all/0/1\">Norimichi Ukita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamaguchi_T/0/1/0/all/0/1\">Takayuki Yamaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_H/0/1/0/all/0/1\">Hao-Yu Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_M/0/1/0/all/0/1\">Mu-Yi Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_C/0/1/0/all/0/1\">Chia-Chi Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_E/0/1/0/all/0/1\">En-Ming Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yu-Chen Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yu-Cheng Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chien-Yao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chun-Yi Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huo_D/0/1/0/all/0/1\">Da Huo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kastner_M/0/1/0/all/0/1\">Marc A. Kastner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tingwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawanishi_Y/0/1/0/all/0/1\">Yasutomo Kawanishi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirayama_T/0/1/0/all/0/1\">Takatsugu Hirayama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Komamizu_T/0/1/0/all/0/1\">Takahiro Komamizu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ide_I/0/1/0/all/0/1\">Ichiro Ide</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shinya_Y/0/1/0/all/0/1\">Yosuke Shinya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xinyao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_G/0/1/0/all/0/1\">Guang Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yasui_S/0/1/0/all/0/1\">Syusuke Yasui</a>",
          "description": "Small Object Detection (SOD) is an important machine vision topic because (i)\na variety of real-world applications require object detection for distant\nobjects and (ii) SOD is a challenging task due to the noisy, blurred, and\nless-informative image appearances of small objects. This paper proposes a new\nSOD dataset consisting of 39,070 images including 137,121 bird instances, which\nis called the Small Object Detection for Spotting Birds (SOD4SB) dataset. The\ndetail of the challenge with the SOD4SB dataset is introduced in this paper. In\ntotal, 223 participants joined this challenge. This paper briefly introduces\nthe award-winning methods. The dataset, the baseline code, and the website for\nevaluation on the public testset are publicly available.",
          "link": "http://arxiv.org/abs/2307.09143",
          "publishedOn": "2023-07-19T01:53:29.020Z",
          "wordCount": null,
          "title": "MVA2023 Small Object Detection Challenge for Spotting Birds: Dataset, Methods, and Results. (arXiv:2307.09143v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.12906",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weber_R/0/1/0/all/0/1\">Romann M. Weber</a>",
          "description": "Implicit generative modeling (IGM) aims to produce samples of synthetic data\nmatching the characteristics of a target data distribution. Recent work (e.g.\nscore-matching networks, diffusion models) has approached the IGM problem from\nthe perspective of pushing synthetic source data toward the target distribution\nvia dynamical perturbations or flows in the ambient space. In this direction,\nwe present the score difference (SD) between arbitrary target and source\ndistributions as a flow that optimally reduces the Kullback-Leibler divergence\nbetween them while also solving the Schroedinger bridge problem. We apply the\nSD flow to convenient proxy distributions, which are aligned if and only if the\noriginal distributions are aligned. We demonstrate the formal equivalence of\nthis formulation to denoising diffusion models under certain conditions. We\nalso show that the training of generative adversarial networks includes a\nhidden data-optimization sub-problem, which induces the SD flow under certain\nchoices of loss function when the discriminator is optimal. As a result, the SD\nflow provides a theoretical link between model classes that individually\naddress the three challenges of the \"generative modeling trilemma\" -- high\nsample quality, mode coverage, and fast sampling -- thereby setting the stage\nfor a unified approach.",
          "link": "http://arxiv.org/abs/2304.12906",
          "publishedOn": "2023-07-19T01:53:29.019Z",
          "wordCount": null,
          "title": "The Score-Difference Flow for Implicit Generative Modeling. (arXiv:2304.12906v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.07848",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Trinh_Q/0/1/0/all/0/1\">Quoc-Huy Trinh</a>",
          "description": "In recent years, polyp segmentation has gained significant importance, and\nmany methods have been developed using CNN, Vision Transformer, and Transformer\ntechniques to achieve competitive results. However, these methods often face\ndifficulties when dealing with out-of-distribution datasets, missing\nboundaries, and small polyps. In 2022, Meta-Former was introduced as a new\nbaseline for vision, which not only improved the performance of multi-task\ncomputer vision but also addressed the limitations of the Vision Transformer\nand CNN family backbones. To further enhance segmentation, we propose a fusion\nof Meta-Former with UNet, along with the introduction of a Multi-scale\nUpsampling block with a level-up combination in the decoder stage to enhance\nthe texture, also we propose the Convformer block base on the idea of the\nMeta-former to enhance the crucial information of the local feature. These\nblocks enable the combination of global information, such as the overall shape\nof the polyp, with local information and boundary information, which is crucial\nfor the decision of the medical segmentation. Our proposed approach achieved\ncompetitive performance and obtained the top result in the State of the Art on\nthe CVC-300 dataset, Kvasir, and CVC-ColonDB dataset. Apart from Kvasir-SEG,\nothers are out-of-distribution datasets. The implementation can be found at:\nhttps://github.com/huyquoctrinh/MetaPolyp-CBMS2023.",
          "link": "http://arxiv.org/abs/2305.07848",
          "publishedOn": "2023-07-19T01:53:28.995Z",
          "wordCount": null,
          "title": "Meta-Polyp: a baseline for efficient Polyp segmentation. (arXiv:2305.07848v3 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09169",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Liu_Z/0/1/0/all/0/1\">Zihan Liu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wang_J/0/1/0/all/0/1\">Jiaqi Wang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Luo_Y/0/1/0/all/0/1\">Yun Luo</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhao_S/0/1/0/all/0/1\">Shuang Zhao</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Li_W/0/1/0/all/0/1\">Wenbin Li</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Li_S/0/1/0/all/0/1\">Stan Z. Li</a>",
          "description": "In recent years, there has been an explosion of research on the application\nof deep learning to the prediction of various peptide properties, due to the\nsignificant development and market potential of peptides. Molecular dynamics\nhas enabled the efficient collection of large peptide datasets, providing\nreliable training data for deep learning. However, the lack of systematic\nanalysis of the peptide encoding, which is essential for AI-assisted\npeptide-related tasks, makes it an urgent problem to be solved for the\nimprovement of prediction accuracy. To address this issue, we first collect a\nhigh-quality, colossal simulation dataset of peptide self-assembly containing\nover 62,000 samples generated by coarse-grained molecular dynamics (CGMD).\nThen, we systematically investigate the effect of peptide encoding of amino\nacids into sequences and molecular graphs using state-of-the-art sequential\n(i.e., RNN, LSTM, and Transformer) and structural deep learning models (i.e.,\nGCN, GAT, and GraphSAGE), on the accuracy of peptide self-assembly prediction,\nan essential physiochemical process prior to any peptide-related applications.\nExtensive benchmarking studies have proven Transformer to be the most powerful\nsequence-encoding-based deep learning model, pushing the limit of peptide\nself-assembly prediction to decapeptides. In summary, this work provides a\ncomprehensive benchmark analysis of peptide encoding with advanced deep\nlearning models, serving as a guide for a wide range of peptide-related\npredictions such as isoelectric points, hydration free energy, etc.",
          "link": "http://arxiv.org/abs/2307.09169",
          "publishedOn": "2023-07-19T01:53:28.994Z",
          "wordCount": null,
          "title": "Efficient Prediction of Peptide Self-assembly through Sequential and Graphical Encoding. (arXiv:2307.09169v1 [q-bio.BM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09321",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhibin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koniusz_P/0/1/0/all/0/1\">Piotr Koniusz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pagendam_D/0/1/0/all/0/1\">Daniel Edward Pagendam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moghadam_P/0/1/0/all/0/1\">Peyman Moghadam</a>",
          "description": "Traditional approaches for learning on categorical data underexploit the\ndependencies between columns (\\aka fields) in a dataset because they rely on\nthe embedding of data points driven alone by the classification/regression\nloss. In contrast, we propose a novel method for learning on categorical data\nwith the goal of exploiting dependencies between fields. Instead of modelling\nstatistics of features globally (i.e., by the covariance matrix of features),\nwe learn a global field dependency matrix that captures dependencies between\nfields and then we refine the global field dependency matrix at the\ninstance-wise level with different weights (so-called local dependency\nmodelling) w.r.t. each field to improve the modelling of the field\ndependencies. Our algorithm exploits the meta-learning paradigm, i.e., the\ndependency matrices are refined in the inner loop of the meta-learning\nalgorithm without the use of labels, whereas the outer loop intertwines the\nupdates of the embedding matrix (the matrix performing projection) and global\ndependency matrix in a supervised fashion (with the use of labels). Our method\nis simple yet it outperforms several state-of-the-art methods on six popular\ndataset benchmarks. Detailed ablation studies provide additional insights into\nour method.",
          "link": "http://arxiv.org/abs/2307.09321",
          "publishedOn": "2023-07-19T01:53:28.994Z",
          "wordCount": null,
          "title": "Exploiting Field Dependencies for Learning on Categorical Data. (arXiv:2307.09321v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsitsulin_A/0/1/0/all/0/1\">Anton Tsitsulin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Munkhoeva_M/0/1/0/all/0/1\">Marina Munkhoeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perozzi_B/0/1/0/all/0/1\">Bryan Perozzi</a>",
          "description": "Unsupervised learning has recently significantly gained in popularity,\nespecially with deep learning-based approaches. Despite numerous successes and\napproaching supervised-level performance on a variety of academic benchmarks,\nit is still hard to train and evaluate SSL models in practice due to the\nunsupervised nature of the problem. Even with networks trained in a supervised\nfashion, it is often unclear whether they will perform well when transferred to\nanother domain.\n\nPast works are generally limited to assessing the amount of information\ncontained in embeddings, which is most relevant for self-supervised learning of\ndeep neural networks. This works chooses to follow a different approach: can we\nquantify how easy it is to linearly separate the data in a stable way? We\nsurvey the literature and uncover three methods that could be potentially used\nfor evaluating quality of representations. We also introduce one novel method\nbased on recent advances in understanding the high-dimensional geometric\nstructure of self-supervised learning.\n\nWe conduct extensive experiments and study the properties of these metrics\nand ones introduced in the previous work. Our results suggest that while there\nis no free lunch, there are metrics that can robustly estimate embedding\nquality in an unsupervised way.",
          "link": "http://arxiv.org/abs/2305.16562",
          "publishedOn": "2023-07-19T01:53:28.993Z",
          "wordCount": null,
          "title": "Unsupervised Embedding Quality Evaluation. (arXiv:2305.16562v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09269",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Martins_D/0/1/0/all/0/1\">Denis Mayr Lima Martins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lulf_C/0/1/0/all/0/1\">Christian L&#xfc;lf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gieseke_F/0/1/0/all/0/1\">Fabian Gieseke</a>",
          "description": "Hyperbox-based classification has been seen as a promising technique in which\ndecisions on the data are represented as a series of orthogonal,\nmultidimensional boxes (i.e., hyperboxes) that are often interpretable and\nhuman-readable. However, existing methods are no longer capable of efficiently\nhandling the increasing volume of data many application domains face nowadays.\nWe address this gap by proposing a novel, fully differentiable framework for\nhyperbox-based classification via neural networks. In contrast to previous\nwork, our hyperbox models can be efficiently trained in an end-to-end fashion,\nwhich leads to significantly reduced training times and superior classification\nresults.",
          "link": "http://arxiv.org/abs/2307.09269",
          "publishedOn": "2023-07-19T01:53:28.992Z",
          "wordCount": null,
          "title": "End-to-End Neural Network Training for Hyperbox-Based Classification. (arXiv:2307.09269v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09463",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Marcotte_F/0/1/0/all/0/1\">Fr&#xe9;d&#xe9;ric Marcotte</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Mouny_P/0/1/0/all/0/1\">Pierre-Antoine Mouny</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Yon_V/0/1/0/all/0/1\">Victor Yon</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Dagnew_G/0/1/0/all/0/1\">Gebremedhin A. Dagnew</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kulchytskyy_B/0/1/0/all/0/1\">Bohdan Kulchytskyy</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Rochette_S/0/1/0/all/0/1\">Sophie Rochette</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Beilliard_Y/0/1/0/all/0/1\">Yann Beilliard</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Drouin_D/0/1/0/all/0/1\">Dominique Drouin</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Ronagh_P/0/1/0/all/0/1\">Pooya Ronagh</a>",
          "description": "Neural decoders for quantum error correction (QEC) rely on neural networks to\nclassify syndromes extracted from error correction codes and find appropriate\nrecovery operators to protect logical information against errors. Despite the\ngood performance of neural decoders, important practical requirements remain to\nbe achieved, such as minimizing the decoding time to meet typical rates of\nsyndrome generation in repeated error correction schemes, and ensuring the\nscalability of the decoding approach as the code distance increases. Designing\na dedicated integrated circuit to perform the decoding task in co-integration\nwith a quantum processor appears necessary to reach these decoding time and\nscalability requirements, as routing signals in and out of a cryogenic\nenvironment to be processed externally leads to unnecessary delays and an\neventual wiring bottleneck. In this work, we report the design and performance\nanalysis of a neural decoder inference accelerator based on an in-memory\ncomputing (IMC) architecture, where crossbar arrays of resistive memory devices\nare employed to both store the synaptic weights of the decoder neural network\nand perform analog matrix-vector multiplications during inference. In\nproof-of-concept numerical experiments supported by experimental measurements,\nwe investigate the impact of TiO$_\\textrm{x}$-based memristive devices'\nnon-idealities on decoding accuracy. Hardware-aware training methods are\ndeveloped to mitigate the loss in accuracy, allowing the memristive neural\ndecoders to achieve a pseudo-threshold of $9.23\\times 10^{-4}$ for the\ndistance-three surface code, whereas the equivalent digital neural decoder\nachieves a pseudo-threshold of $1.01\\times 10^{-3}$. This work provides a\npathway to scalable, fast, and low-power cryogenic IMC hardware for integrated\nQEC.",
          "link": "http://arxiv.org/abs/2307.09463",
          "publishedOn": "2023-07-19T01:53:28.991Z",
          "wordCount": null,
          "title": "A Cryogenic Memristive Neural Decoder for Fault-tolerant Quantum Error Correction. (arXiv:2307.09463v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.13108",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ramachandran_A/0/1/0/all/0/1\">Adithya Ramachandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_S/0/1/0/all/0/1\">Satyaki Chatterjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bayer_S/0/1/0/all/0/1\">Siming Bayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maier_A/0/1/0/all/0/1\">Andreas Maier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flensmark_T/0/1/0/all/0/1\">Thorkil Flensmark</a>",
          "description": "One of the primal challenges faced by utility companies is ensuring efficient\nsupply with minimal greenhouse gas emissions. The advent of smart meters and\nsmart grids provide an unprecedented advantage in realizing an optimised supply\nof thermal energies through proactive techniques such as load forecasting. In\nthis paper, we propose a forecasting framework for heat demand based on neural\nnetworks where the time series are encoded as scalograms equipped with the\ncapacity of embedding exogenous variables such as weather, and\nholiday/non-holiday. Subsequently, CNNs are utilized to predict the heat load\nmulti-step ahead. Finally, the proposed framework is compared with other\nstate-of-the-art methods, such as SARIMAX and LSTM. The quantitative results\nfrom retrospective experiments show that the proposed framework consistently\noutperforms the state-of-the-art baseline method with real-world data acquired\nfrom Denmark. A minimal mean error of 7.54% for MAPE and 417kW for RMSE is\nachieved with the proposed framework in comparison to all other methods.",
          "link": "http://arxiv.org/abs/2210.13108",
          "publishedOn": "2023-07-19T01:53:28.990Z",
          "wordCount": null,
          "title": "Heat Demand Forecasting with Multi-Resolutional Representation of Heterogeneous Temporal Ensemble. (arXiv:2210.13108v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09361",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gidaris_S/0/1/0/all/0/1\">Spyros Gidaris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bursuc_A/0/1/0/all/0/1\">Andrei Bursuc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simeoni_O/0/1/0/all/0/1\">Oriane Simeoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vobecky_A/0/1/0/all/0/1\">Antonin Vobecky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Komodakis_N/0/1/0/all/0/1\">Nikos Komodakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cord_M/0/1/0/all/0/1\">Matthieu Cord</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_P/0/1/0/all/0/1\">Patrick P&#xe9;rez</a>",
          "description": "Self-supervised learning can be used for mitigating the greedy needs of\nVision Transformer networks for very large fully-annotated datasets. Different\nclasses of self-supervised learning offer representations with either good\ncontextual reasoning properties, e.g., using masked image modeling strategies,\nor invariance to image perturbations, e.g., with contrastive methods. In this\nwork, we propose a single-stage and standalone method, MOCA, which unifies both\ndesired properties using novel mask-and-predict objectives defined with\nhigh-level features (instead of pixel-level details). Moreover, we show how to\neffectively employ both learning paradigms in a synergistic and\ncomputation-efficient way. Doing so, we achieve new state-of-the-art results on\nlow-shot settings and strong experimental results in various evaluation\nprotocols with a training that is at least 3 times faster than prior methods.",
          "link": "http://arxiv.org/abs/2307.09361",
          "publishedOn": "2023-07-19T01:53:28.983Z",
          "wordCount": null,
          "title": "MOCA: Self-supervised Representation Learning by Predicting Masked Online Codebook Assignments. (arXiv:2307.09361v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_G/0/1/0/all/0/1\">Gehua Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1\">Rui Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Huajin Tang</a>",
          "description": "Networks of spiking neurons underpin the extraordinary information-processing\ncapabilities of the brain and have become pillar models in neuromorphic\nartificial intelligence. Despite extensive research on spiking neural networks\n(SNNs), most studies are established on deterministic models, overlooking the\ninherent non-deterministic, noisy nature of neural computations. This study\nintroduces the noisy spiking neural network (NSNN) and the noise-driven\nlearning rule (NDL) by incorporating noisy neuronal dynamics to exploit the\ncomputational advantages of noisy neural processing. NSNN provides a\ntheoretical framework that yields scalable, flexible, and reliable computation.\nWe demonstrate that NSNN leads to spiking neural models with competitive\nperformance, improved robustness against challenging perturbations than\ndeterministic SNNs, and better reproducing probabilistic neural computation in\nneural coding. This study offers a powerful and easy-to-use tool for machine\nlearning, neuromorphic intelligence practitioners, and computational\nneuroscience researchers.",
          "link": "http://arxiv.org/abs/2305.16044",
          "publishedOn": "2023-07-19T01:53:28.981Z",
          "wordCount": null,
          "title": "Exploiting Noise as a Resource for Computation and Learning in Spiking Neural Networks. (arXiv:2305.16044v5 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09477",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stumme_G/0/1/0/all/0/1\">Gerd Stumme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrschnabel_D/0/1/0/all/0/1\">Dominik D&#xfc;rrschnabel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanika_T/0/1/0/all/0/1\">Tom Hanika</a>",
          "description": "Order is one of the main instruments to measure the relationship between\nobjects in (empirical) data. However, compared to methods that use numerical\nproperties of objects, the amount of ordinal methods developed is rather small.\nOne reason for this is the limited availability of computational resources in\nthe last century that would have been required for ordinal computations.\nAnother reason -- particularly important for this line of research -- is that\norder-based methods are often seen as too mathematically rigorous for applying\nthem to real-world data. In this paper, we will therefore discuss different\nmeans for measuring and 'calculating' with ordinal structures -- a specific\nclass of directed graphs -- and show how to infer knowledge from them. Our aim\nis to establish Ordinal Data Science as a fundamentally new research agenda.\nBesides cross-fertilization with other cornerstone machine learning and\nknowledge representation methods, a broad range of disciplines will benefit\nfrom this endeavor, including, psychology, sociology, economics, web science,\nknowledge engineering, scientometrics.",
          "link": "http://arxiv.org/abs/2307.09477",
          "publishedOn": "2023-07-19T01:53:28.980Z",
          "wordCount": null,
          "title": "Towards Ordinal Data Science. (arXiv:2307.09477v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09457",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wu_Y/0/1/0/all/0/1\">Yunan Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Castro_Macias_F/0/1/0/all/0/1\">Francisco M. Castro-Mac&#xed;as</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Morales_Alvarez_P/0/1/0/all/0/1\">Pablo Morales-&#xc1;lvarez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Molina_R/0/1/0/all/0/1\">Rafael Molina</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Katsaggelos_A/0/1/0/all/0/1\">Aggelos K. Katsaggelos</a>",
          "description": "Multiple Instance Learning (MIL) has been widely applied to medical imaging\ndiagnosis, where bag labels are known and instance labels inside bags are\nunknown. Traditional MIL assumes that instances in each bag are independent\nsamples from a given distribution. However, instances are often spatially or\nsequentially ordered, and one would expect similar diagnostic importance for\nneighboring instances. To address this, in this study, we propose a smooth\nattention deep MIL (SA-DMIL) model. Smoothness is achieved by the introduction\nof first and second order constraints on the latent function encoding the\nattention paid to each instance in a bag. The method is applied to the\ndetection of intracranial hemorrhage (ICH) on head CT scans. The results show\nthat this novel SA-DMIL: (a) achieves better performance than the non-smooth\nattention MIL at both scan (bag) and slice (instance) levels; (b) learns\nspatial dependencies between slices; and (c) outperforms current\nstate-of-the-art MIL methods on the same ICH test set.",
          "link": "http://arxiv.org/abs/2307.09457",
          "publishedOn": "2023-07-19T01:53:28.976Z",
          "wordCount": null,
          "title": "Smooth Attention for Deep Multiple Instance Learning: Application to CT Intracranial Hemorrhage Detection. (arXiv:2307.09457v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.05118",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Gengwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_G/0/1/0/all/0/1\">Guoliang Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Ling Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yunchao Wei</a>",
          "description": "The goal of continual learning is to improve the performance of recognition\nmodels in learning sequentially arrived data. Although most existing works are\nestablished on the premise of learning from scratch, growing efforts have been\ndevoted to incorporating the benefits of pre-training. However, how to\nadaptively exploit the pre-trained knowledge for each incremental task while\nmaintaining its generalizability remains an open question. In this work, we\npresent an extensive analysis for continual learning on a pre-trained model\n(CLPM), and attribute the key challenge to a progressive overfitting problem.\nObserving that selectively reducing the learning rate can almost resolve this\nissue in the representation layer, we propose a simple but extremely effective\napproach named Slow Learner with Classifier Alignment (SLCA), which further\nimproves the classification layer by modeling the class-wise distributions and\naligning the classification layers in a post-hoc fashion. Across a variety of\nscenarios, our proposal provides substantial improvements for CLPM (e.g., up to\n49.76%, 50.05%, 44.69% and 40.16% on Split CIFAR-100, Split ImageNet-R, Split\nCUB-200 and Split Cars-196, respectively), and thus outperforms\nstate-of-the-art approaches by a large margin. Based on such a strong baseline,\ncritical factors and promising directions are analyzed in-depth to facilitate\nsubsequent research.",
          "link": "http://arxiv.org/abs/2303.05118",
          "publishedOn": "2023-07-19T01:53:28.967Z",
          "wordCount": null,
          "title": "SLCA: Slow Learner with Classifier Alignment for Continual Learning on a Pre-trained Model. (arXiv:2303.05118v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.10426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wilson_D/0/1/0/all/0/1\">Daniel Wilson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schirrmeister_R/0/1/0/all/0/1\">Robin Tibor Schirrmeister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gemein_L/0/1/0/all/0/1\">Lukas Alexander Wilhelm Gemein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ball_T/0/1/0/all/0/1\">Tonio Ball</a>",
          "description": "State-of-the-art performance in electroencephalography (EEG) decoding tasks\nis currently often achieved with either Deep-Learning (DL) or\nRiemannian-Geometry-based decoders (RBDs). Recently, there is growing interest\nin Deep Riemannian Networks (DRNs) possibly combining the advantages of both\nprevious classes of methods. However, there are still a range of topics where\nadditional insight is needed to pave the way for a more widespread application\nof DRNs in EEG. These include architecture design questions such as network\nsize and end-to-end ability.How these factors affect model performance has not\nbeen explored. Additionally, it is not clear how the data within these networks\nis transformed, and whether this would correlate with traditional EEG decoding.\nOur study aims to lay the groundwork in the area of these topics through the\nanalysis of DRNs for EEG with a wide range of hyperparameters. Networks were\ntested on two public EEG datasets and compared with state-of-the-art ConvNets.\nHere we propose end-to-end EEG SPDNet (EE(G)-SPDNet), and we show that this\nwide, end-to-end DRN can outperform the ConvNets, and in doing so use\nphysiologically plausible frequency regions. We also show that the end-to-end\napproach learns more complex filters than traditional band-pass filters\ntargeting the classical alpha, beta, and gamma frequency bands of the EEG, and\nthat performance can benefit from channel specific filtering approaches.\nAdditionally, architectural analysis revealed areas for further improvement due\nto the possible loss of Riemannian specific information throughout the network.\nOur study thus shows how to design and train DRNs to infer task-related\ninformation from the raw EEG without the need of handcrafted filterbanks and\nhighlights the potential of end-to-end DRNs such as EE(G)-SPDNet for\nhigh-performance EEG decoding.",
          "link": "http://arxiv.org/abs/2212.10426",
          "publishedOn": "2023-07-19T01:53:28.942Z",
          "wordCount": null,
          "title": "Deep Riemannian Networks for EEG Decoding. (arXiv:2212.10426v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09423",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tuyls_J/0/1/0/all/0/1\">Jens Tuyls</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madeka_D/0/1/0/all/0/1\">Dhruv Madeka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torkkola_K/0/1/0/all/0/1\">Kari Torkkola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1\">Dean Foster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1\">Karthik Narasimhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1\">Sham Kakade</a>",
          "description": "Imitation Learning (IL) is one of the most widely used methods in machine\nlearning. Yet, while powerful, many works find it is often not able to fully\nrecover the underlying expert behavior. However, none of these works deeply\ninvestigate the role of scaling up the model and data size. Inspired by recent\nwork in Natural Language Processing (NLP) where \"scaling up\" has resulted in\nincreasingly more capable LLMs, we investigate whether carefully scaling up\nmodel and data size can bring similar improvements in the imitation learning\nsetting. To demonstrate our findings, we focus on the game of NetHack, a\nchallenging environment featuring procedural generation, stochasticity,\nlong-term dependencies, and partial observability. We find IL loss and mean\nreturn scale smoothly with the compute budget and are strongly correlated,\nresulting in power laws for training compute-optimal IL agents with respect to\nmodel size and number of samples. We forecast and train several NetHack agents\nwith IL and find they outperform prior state-of-the-art by at least 2x in all\nsettings. Our work both demonstrates the scaling behavior of imitation learning\nin a challenging domain, as well as the viability of scaling up current\napproaches for increasingly capable agents in NetHack, a game that remains\nelusively hard for current AI systems.",
          "link": "http://arxiv.org/abs/2307.09423",
          "publishedOn": "2023-07-19T01:53:28.937Z",
          "wordCount": null,
          "title": "Scaling Laws for Imitation Learning in NetHack. (arXiv:2307.09423v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09230",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paterson_M/0/1/0/all/0/1\">Mary Paterson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moor_J/0/1/0/all/0/1\">James Moor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cutillo_L/0/1/0/all/0/1\">Luisa Cutillo</a>",
          "description": "In this work we perform a scoping review of the current literature on the\ndetection of throat cancer from speech recordings using machine learning and\nartificial intelligence. We find 22 papers within this area and discuss their\nmethods and results. We split these papers into two groups - nine performing\nbinary classification, and 13 performing multi-class classification. The papers\npresent a range of methods with neural networks being most commonly\nimplemented. Many features are also extracted from the audio before\nclassification, with the most common bring mel-frequency cepstral coefficients.\nNone of the papers found in this search have associated code repositories and\nas such are not reproducible. Therefore, we create a publicly available code\nrepository of our own classifiers. We use transfer learning on a multi-class\nproblem, classifying three pathologies and healthy controls. Using this\ntechnique we achieve an unweighted average recall of 53.54%, sensitivity of\n83.14%, and specificity of 64.00%. We compare our classifiers with the results\nobtained on the same dataset and find similar results.",
          "link": "http://arxiv.org/abs/2307.09230",
          "publishedOn": "2023-07-19T01:53:28.935Z",
          "wordCount": null,
          "title": "Detecting Throat Cancer from Speech Signals Using Machine Learning: A Reproducible Literature Review. (arXiv:2307.09230v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09254",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sangdon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Taesoo Kim</a>",
          "description": "Uncertainty learning and quantification of models are crucial tasks to\nenhance the trustworthiness of the models. Importantly, the recent surge of\ngenerative language models (GLMs) emphasizes the need for reliable uncertainty\nquantification due to the concerns on generating hallucinated facts. In this\npaper, we propose to learn neural prediction set models that comes with the\nprobably approximately correct (PAC) guarantee for quantifying the uncertainty\nof GLMs. Unlike existing prediction set models, which are parameterized by a\nscalar value, we propose to parameterize prediction sets via neural networks,\nwhich achieves more precise uncertainty quantification but still satisfies the\nPAC guarantee. We demonstrate the efficacy of our method on four types of\nlanguage datasets and six types of models by showing that our method improves\nthe quantified uncertainty by $63\\%$ on average, compared to a standard\nbaseline method.",
          "link": "http://arxiv.org/abs/2307.09254",
          "publishedOn": "2023-07-19T01:53:28.934Z",
          "wordCount": null,
          "title": "PAC Neural Prediction Set Learning to Quantify the Uncertainty of Generative Language Models. (arXiv:2307.09254v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.15656",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_F/0/1/0/all/0/1\">Fu-Ming Guo</a>",
          "description": "This paper introduces SparseOptimizer, a novel deep learning optimizer that\nexploits Moreau-Yosida regularization to naturally induce sparsity in large\nlanguage models such as BERT, ALBERT and GPT. Key to the design of\nSparseOptimizer is an embedded shrinkage operator, which imparts sparsity\ndirectly within the optimization process. This operator, backed by a sound\ntheoretical framework, includes an analytical solution, thereby reinforcing the\noptimizer's robustness and efficacy. Crucially, SparseOptimizer's plug-and-play\nfunctionality eradicates the need for code modifications, making it a\nuniversally adaptable tool for a wide array of large language models. Empirical\nevaluations on benchmark datasets such as GLUE, RACE, SQuAD1, and SQuAD2\nconfirm that SparseBERT and SparseALBERT, when sparsified using\nSparseOptimizer, achieve performance comparable to their dense counterparts,\nBERT and ALBERT, while significantly reducing their parameter count. Further,\nthis work proposes an innovative optimizer-compiler co-design strategy,\ndemonstrating the potential of inference acceleration (\\textbf{3.37x},\n\\textbf{6.30x}, and \\textbf{7.15x} in comparison with Pytorch, TensorFlow, and\nLLVM generic compile, respectively) in SparseBERT when paired with an\nappropriately designed compiler. This study represents a significant step\nforward in the evolution of efficient, scalable, and high-performing large\nlanguage models, setting a precedent for future exploration and optimization in\nthis domain. The SparseOptimizer code and SparseALBERT model will be publicly\navailable upon paper acceptance.",
          "link": "http://arxiv.org/abs/2306.15656",
          "publishedOn": "2023-07-19T01:53:28.933Z",
          "wordCount": null,
          "title": "SparseOptimizer: Sparsify Language Models through Moreau-Yosida Regularization and Accelerate via Compiler Co-design. (arXiv:2306.15656v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.12765",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jain_M/0/1/0/all/0/1\">Moksh Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raparthy_S/0/1/0/all/0/1\">Sharath Chandra Raparthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Garcia_A/0/1/0/all/0/1\">Alex Hernandez-Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rector_Brooks_J/0/1/0/all/0/1\">Jarrid Rector-Brooks</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miret_S/0/1/0/all/0/1\">Santiago Miret</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_E/0/1/0/all/0/1\">Emmanuel Bengio</a>",
          "description": "We study the problem of generating diverse candidates in the context of\nMulti-Objective Optimization. In many applications of machine learning such as\ndrug discovery and material design, the goal is to generate candidates which\nsimultaneously optimize a set of potentially conflicting objectives. Moreover,\nthese objectives are often imperfect evaluations of some underlying property of\ninterest, making it important to generate diverse candidates to have multiple\noptions for expensive downstream evaluations. We propose Multi-Objective\nGFlowNets (MOGFNs), a novel method for generating diverse Pareto optimal\nsolutions, based on GFlowNets. We introduce two variants of MOGFNs: MOGFN-PC,\nwhich models a family of independent sub-problems defined by a scalarization\nfunction, with reward-conditional GFlowNets, and MOGFN-AL, which solves a\nsequence of sub-problems defined by an acquisition function in an active\nlearning loop. Our experiments on wide variety of synthetic and benchmark tasks\ndemonstrate advantages of the proposed methods in terms of the Pareto\nperformance and importantly, improved candidate diversity, which is the main\ncontribution of this work.",
          "link": "http://arxiv.org/abs/2210.12765",
          "publishedOn": "2023-07-19T01:53:28.932Z",
          "wordCount": null,
          "title": "Multi-Objective GFlowNets. (arXiv:2210.12765v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05520",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rey_S/0/1/0/all/0/1\">Santiago del Rey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinez_Fernandez_S/0/1/0/all/0/1\">Silverio Mart&#xed;nez-Fern&#xe1;ndez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cruz_L/0/1/0/all/0/1\">Lu&#xed;s Cruz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Franch_X/0/1/0/all/0/1\">Xavier Franch</a>",
          "description": "Current research in the computer vision field mainly focuses on improving\nDeep Learning (DL) correctness and inference time performance. However, there\nis still little work on the huge carbon footprint that has training DL models.\nThis study aims to analyze the impact of the model architecture and training\nenvironment when training greener computer vision models. We divide this goal\ninto two research questions. First, we analyze the effects of model\narchitecture on achieving greener models while keeping correctness at optimal\nlevels. Second, we study the influence of the training environment on producing\ngreener models. To investigate these relationships, we collect multiple metrics\nrelated to energy efficiency and model correctness during the models' training.\nThen, we outline the trade-offs between the measured energy efficiency and the\nmodels' correctness regarding model architecture, and their relationship with\nthe training environment. We conduct this research in the context of a computer\nvision system for image classification. In conclusion, we show that selecting\nthe proper model architecture and training environment can reduce energy\nconsumption dramatically (up to 98.83%) at the cost of negligible decreases in\ncorrectness. Also, we find evidence that GPUs should scale with the models'\ncomputational complexity for better energy efficiency.",
          "link": "http://arxiv.org/abs/2307.05520",
          "publishedOn": "2023-07-19T01:53:28.932Z",
          "wordCount": null,
          "title": "Do DL models and training environments have an impact on energy consumption?. (arXiv:2307.05520v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09238",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aganian_D/0/1/0/all/0/1\">Dustin Aganian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kohler_M/0/1/0/all/0/1\">Mona K&#xf6;hler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stephan_B/0/1/0/all/0/1\">Benedict Stephan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eisenbach_M/0/1/0/all/0/1\">Markus Eisenbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gross_H/0/1/0/all/0/1\">Horst-Michael Gross</a>",
          "description": "As collaborative robots (cobots) continue to gain popularity in industrial\nmanufacturing, effective human-robot collaboration becomes crucial. Cobots\nshould be able to recognize human actions to assist with assembly tasks and act\nautonomously. To achieve this, skeleton-based approaches are often used due to\ntheir ability to generalize across various people and environments. Although\nbody skeleton approaches are widely used for action recognition, they may not\nbe accurate enough for assembly actions where the worker's fingers and hands\nplay a significant role. To address this limitation, we propose a method in\nwhich less detailed body skeletons are combined with highly detailed hand\nskeletons. We investigate CNNs and transformers, the latter of which are\nparticularly adept at extracting and combining important information from both\nskeleton types using attention. This paper demonstrates the effectiveness of\nour proposed approach in enhancing action recognition in assembly scenarios.",
          "link": "http://arxiv.org/abs/2307.09238",
          "publishedOn": "2023-07-19T01:53:28.928Z",
          "wordCount": null,
          "title": "Fusing Hand and Body Skeletons for Human Action Recognition in Assembly. (arXiv:2307.09238v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08572",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Silvestrin_L/0/1/0/all/0/1\">Luis Pedro Silvestrin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Shujian Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoogendoorn_M/0/1/0/all/0/1\">Mark Hoogendoorn</a>",
          "description": "Coping with distributional shifts is an important part of transfer learning\nmethods in order to perform well in real-life tasks. However, most of the\nexisting approaches in this area either focus on an ideal scenario in which the\ndata does not contain noises or employ a complicated training paradigm or model\ndesign to deal with distributional shifts. In this paper, we revisit the\nrobustness of the minimum error entropy (MEE) criterion, a widely used\nobjective in statistical signal processing to deal with non-Gaussian noises,\nand investigate its feasibility and usefulness in real-life transfer learning\nregression tasks, where distributional shifts are common. Specifically, we put\nforward a new theoretical result showing the robustness of MEE against\ncovariate shift. We also show that by simply replacing the mean squared error\n(MSE) loss with the MEE on basic transfer learning algorithms such as\nfine-tuning and linear probing, we can achieve competitive performance with\nrespect to state-of-the-art transfer learning algorithms. We justify our\narguments on both synthetic data and 5 real-world time-series data.",
          "link": "http://arxiv.org/abs/2307.08572",
          "publishedOn": "2023-07-19T01:53:28.926Z",
          "wordCount": null,
          "title": "Revisiting the Robustness of the Minimum Error Entropy Criterion: A Transfer Learning Case Study. (arXiv:2307.08572v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.00046",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1\">Davis Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Godfrey_C/0/1/0/all/0/1\">Charles Godfrey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nizinski_C/0/1/0/all/0/1\">Cody Nizinski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_J/0/1/0/all/0/1\">Jonathan Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kvinge_H/0/1/0/all/0/1\">Henry Kvinge</a>",
          "description": "The current trend toward ever-larger models makes standard retraining\nprocedures an ever-more expensive burden. For this reason, there is growing\ninterest in model editing, which enables computationally inexpensive,\ninterpretable, post-hoc model modifications. While many model editing\ntechniques are promising, research on the properties of edited models is\nlargely limited to evaluation of validation accuracy. The robustness of edited\nmodels is an important and yet mostly unexplored topic. In this paper, we\nemploy recently developed techniques from the field of deep learning robustness\nto investigate both how model editing affects the general robustness of a\nmodel, as well as the robustness of the specific behavior targeted by the edit.\nWe find that edits tend to reduce general robustness, but that the degree of\ndegradation depends on the editing algorithm and layers chosen. Motivated by\nthese observations we introduce a new model editing algorithm, 1-layer\ninterpolation (1-LI), which uses weight-space interpolation to navigate the\ntrade-off between editing task accuracy and general robustness.",
          "link": "http://arxiv.org/abs/2303.00046",
          "publishedOn": "2023-07-19T01:53:28.925Z",
          "wordCount": null,
          "title": "Edit at your own risk: evaluating the robustness of edited models to distribution shifts. (arXiv:2303.00046v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09302",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stutz_D/0/1/0/all/0/1\">David Stutz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1\">Abhijit Guha Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matejovicova_T/0/1/0/all/0/1\">Tatiana Matejovicova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strachan_P/0/1/0/all/0/1\">Patricia Strachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cemgil_A/0/1/0/all/0/1\">Ali Taylan Cemgil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doucet_A/0/1/0/all/0/1\">Arnaud Doucet</a>",
          "description": "In safety-critical classification tasks, conformal prediction allows to\nperform rigorous uncertainty quantification by providing confidence sets\nincluding the true class with a user-specified probability. This generally\nassumes the availability of a held-out calibration set with access to ground\ntruth labels. Unfortunately, in many domains, such labels are difficult to\nobtain and usually approximated by aggregating expert opinions. In fact, this\nholds true for almost all datasets, including well-known ones such as CIFAR and\nImageNet. Applying conformal prediction using such labels underestimates\nuncertainty. Indeed, when expert opinions are not resolvable, there is inherent\nambiguity present in the labels. That is, we do not have ``crisp'', definitive\nground truth labels and this uncertainty should be taken into account during\ncalibration. In this paper, we develop a conformal prediction framework for\nsuch ambiguous ground truth settings which relies on an approximation of the\nunderlying posterior distribution of labels given inputs. We demonstrate our\nmethodology on synthetic and real datasets, including a case study of skin\ncondition classification in dermatology.",
          "link": "http://arxiv.org/abs/2307.09302",
          "publishedOn": "2023-07-19T01:53:28.924Z",
          "wordCount": null,
          "title": "Conformal prediction under ambiguous ground truth. (arXiv:2307.09302v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09018",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Belyaeva_A/0/1/0/all/0/1\">Anastasiya Belyaeva</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Cosentino_J/0/1/0/all/0/1\">Justin Cosentino</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hormozdiari_F/0/1/0/all/0/1\">Farhad Hormozdiari</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+McLean_C/0/1/0/all/0/1\">Cory Y. McLean</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Furlotte_N/0/1/0/all/0/1\">Nicholas A. Furlotte</a>",
          "description": "Foundation large language models (LLMs) have shown an impressive ability to\nsolve tasks across a wide range of fields including health. To effectively\nsolve personalized health tasks, LLMs need the ability to ingest a diversity of\ndata modalities that are relevant to an individual's health status. In this\npaper, we take a step towards creating multimodal LLMs for health that are\ngrounded in individual-specific data by developing a framework (HeLM: Health\nLarge Language Model for Multimodal Understanding) that enables LLMs to use\nhigh-dimensional clinical modalities to estimate underlying disease risk. HeLM\nencodes complex data modalities by learning an encoder that maps them into the\nLLM's token embedding space and for simple modalities like tabular data by\nserializing the data into text. Using data from the UK Biobank, we show that\nHeLM can effectively use demographic and clinical features in addition to\nhigh-dimensional time-series data to estimate disease risk. For example, HeLM\nachieves an AUROC of 0.75 for asthma prediction when combining tabular and\nspirogram data modalities compared with 0.49 when only using tabular data.\nOverall, we find that HeLM outperforms or performs at parity with classical\nmachine learning approaches across a selection of eight binary traits.\nFurthermore, we investigate the downstream uses of this model such as its\ngeneralizability to out-of-distribution traits and its ability to power\nconversations around individual health and wellness.",
          "link": "http://arxiv.org/abs/2307.09018",
          "publishedOn": "2023-07-19T01:53:28.921Z",
          "wordCount": null,
          "title": "Multimodal LLMs for health grounded in individual-specific data. (arXiv:2307.09018v1 [q-bio.QM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Henzinger_M/0/1/0/all/0/1\">Monika Henzinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Upadhyay_J/0/1/0/all/0/1\">Jalaj Upadhyay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Upadhyay_S/0/1/0/all/0/1\">Sarvagya Upadhyay</a>",
          "description": "We study the problem of maintaining a differentially private decaying sum\nunder continual observation. We give a unifying framework and an efficient\nalgorithm for this problem for \\emph{any sufficiently smooth} function. Our\nalgorithm is the first differentially private algorithm that does not have a\nmultiplicative error for polynomially-decaying weights. Our algorithm improves\non all prior works on differentially private decaying sums under continual\nobservation and recovers exactly the additive error for the special case of\ncontinual counting from Henzinger et al. (SODA 2023) as a corollary.\n\nOur algorithm is a variant of the factorization mechanism whose error depends\non the $\\gamma_2$ and $\\gamma_F$ norm of the underlying matrix. We give a\nconstructive proof for an almost exact upper bound on the $\\gamma_2$ and\n$\\gamma_F$ norm and an almost tight lower bound on the $\\gamma_2$ norm for a\nlarge class of lower-triangular matrices. This is the first non-trivial lower\nbound for lower-triangular matrices whose non-zero entries are not all the\nsame. It includes matrices for all continual decaying sums problems, resulting\nin an upper bound on the additive error of any differentially private decaying\nsums algorithm under continual observation.\n\nWe also explore some implications of our result in discrepancy theory and\noperator algebra. Given the importance of the $\\gamma_2$ norm in computer\nscience and the extensive work in mathematics, we believe our result will have\nfurther applications.",
          "link": "http://arxiv.org/abs/2307.08970",
          "publishedOn": "2023-07-19T01:53:28.920Z",
          "wordCount": null,
          "title": "A Unifying Framework for Differentially Private Sums under Continual Observation. (arXiv:2307.08970v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09295",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Junwen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yifan Feng</a>",
          "description": "We study the problem of best-item identification from choice-based feedback.\nIn this problem, a company sequentially and adaptively shows display sets to a\npopulation of customers and collects their choices. The objective is to\nidentify the most preferred item with the least number of samples and at a high\nconfidence level. We propose an elimination-based algorithm, namely Nested\nElimination (NE), which is inspired by the nested structure implied by the\ninformation-theoretic lower bound. NE is simple in structure, easy to\nimplement, and has a strong theoretical guarantee for sample complexity.\nSpecifically, NE utilizes an innovative elimination criterion and circumvents\nthe need to solve any complex combinatorial optimization problem. We provide an\ninstance-specific and non-asymptotic bound on the expected sample complexity of\nNE. We also show NE achieves high-order worst-case asymptotic optimality.\nFinally, numerical experiments from both synthetic and real data corroborate\nour theoretical findings.",
          "link": "http://arxiv.org/abs/2307.09295",
          "publishedOn": "2023-07-19T01:53:28.919Z",
          "wordCount": null,
          "title": "Nested Elimination: A Simple Algorithm for Best-Item Identification from Choice-Based Feedback. (arXiv:2307.09295v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.16596",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chiu_C/0/1/0/all/0/1\">Chih-Yuan Chiu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kulkarni_K/0/1/0/all/0/1\">Kshitij Kulkarni</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sastry_S/0/1/0/all/0/1\">Shankar Sastry</a>",
          "description": "Causal phenomena associated with rare events occur across a wide range of\nengineering problems, such as risk-sensitive safety analysis, accident analysis\nand prevention, and extreme value theory. However, current methods for causal\ndiscovery are often unable to uncover causal links, between random variables in\na dynamic setting, that manifest only when the variables first experience\nlow-probability realizations. To address this issue, we introduce a novel\nstatistical independence test on data collected from time-invariant dynamical\nsystems in which rare but consequential events occur. In particular, we exploit\nthe time-invariance of the underlying data to construct a superimposed dataset\nof the system state before rare events happen at different timesteps. We then\ndesign a conditional independence test on the reorganized data. We provide\nnon-asymptotic sample complexity bounds for the consistency of our method, and\nvalidate its performance across various simulated and real-world datasets,\nincluding incident data collected from the Caltrans Performance Measurement\nSystem (PeMS). Code containing the datasets and experiments is publicly\navailable.",
          "link": "http://arxiv.org/abs/2211.16596",
          "publishedOn": "2023-07-19T01:53:28.919Z",
          "wordCount": null,
          "title": "Towards Dynamic Causal Discovery with Rare Events: A Nonparametric Conditional Independence Test. (arXiv:2211.16596v5 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.11997",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hamman_F/0/1/0/all/0/1\">Faisal Hamman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Noorani_E/0/1/0/all/0/1\">Erfaun Noorani</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mishra_S/0/1/0/all/0/1\">Saumitra Mishra</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Magazzeni_D/0/1/0/all/0/1\">Daniele Magazzeni</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dutta_S/0/1/0/all/0/1\">Sanghamitra Dutta</a>",
          "description": "There is an emerging interest in generating robust counterfactual\nexplanations that would remain valid if the model is updated or changed even\nslightly. Towards finding robust counterfactuals, existing literature often\nassumes that the original model $m$ and the new model $M$ are bounded in the\nparameter space, i.e., $\\|\\text{Params}(M){-}\\text{Params}(m)\\|{<}\\Delta$.\nHowever, models can often change significantly in the parameter space with\nlittle to no change in their predictions or accuracy on the given dataset. In\nthis work, we introduce a mathematical abstraction termed\n\\emph{naturally-occurring} model change, which allows for arbitrary changes in\nthe parameter space such that the change in predictions on points that lie on\nthe data manifold is limited. Next, we propose a measure -- that we call\n\\emph{Stability} -- to quantify the robustness of counterfactuals to potential\nmodel changes for differentiable models, e.g., neural networks. Our main\ncontribution is to show that counterfactuals with sufficiently high value of\n\\emph{Stability} as defined by our measure will remain valid after potential\n``naturally-occurring'' model changes with high probability (leveraging\nconcentration bounds for Lipschitz function of independent Gaussians). Since\nour quantification depends on the local Lipschitz constant around a data point\nwhich is not always available, we also examine practical relaxations of our\nproposed measure and demonstrate experimentally how they can be incorporated to\nfind robust counterfactuals for neural networks that are close, realistic, and\nremain valid after potential model changes. This work also has interesting\nconnections with model multiplicity, also known as, the Rashomon effect.",
          "link": "http://arxiv.org/abs/2305.11997",
          "publishedOn": "2023-07-19T01:53:28.916Z",
          "wordCount": null,
          "title": "Robust Counterfactual Explanations for Neural Networks With Probabilistic Guarantees. (arXiv:2305.11997v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09377",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Duvvur_V/0/1/0/all/0/1\">Vikram Duvvur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_A/0/1/0/all/0/1\">Aashay Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_E/0/1/0/all/0/1\">Edward Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Bo Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1\">Ken Yew Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1\">Jeff Schneider</a>",
          "description": "The use of machine learning in algorithmic trading systems is increasingly\ncommon. In a typical set-up, supervised learning is used to predict the future\nprices of assets, and those predictions drive a simple trading and execution\nstrategy. This is quite effective when the predictions have sufficient signal,\nmarkets are liquid, and transaction costs are low. However, those conditions\noften do not hold in thinly traded financial markets and markets for\ndifferentiated assets such as real estate or vehicles. In these markets, the\ntrading strategy must consider the long-term effects of taking positions that\nare relatively more difficult to change. In this work, we propose a\nReinforcement Learning (RL) algorithm that trades based on signals from a\nlearned predictive model and addresses these challenges. We test our algorithm\non 20+ years of equity data from Bursa Malaysia.",
          "link": "http://arxiv.org/abs/2307.09377",
          "publishedOn": "2023-07-19T01:53:28.915Z",
          "wordCount": null,
          "title": "Data Cross-Segmentation for Improved Generalization in Reinforcement Learning Based Algorithmic Trading. (arXiv:2307.09377v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09009",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lingjiao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaharia_M/0/1/0/all/0/1\">Matei Zaharia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>",
          "description": "GPT-3.5 and GPT-4 are the two most widely used large language model (LLM)\nservices. However, when and how these models are updated over time is opaque.\nHere, we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 on\nfour diverse tasks: 1) solving math problems, 2) answering sensitive/dangerous\nquestions, 3) generating code and 4) visual reasoning. We find that the\nperformance and behavior of both GPT-3.5 and GPT-4 can vary greatly over time.\nFor example, GPT-4 (March 2023) was very good at identifying prime numbers\n(accuracy 97.6%) but GPT-4 (June 2023) was very poor on these same questions\n(accuracy 2.4%). Interestingly GPT-3.5 (June 2023) was much better than GPT-3.5\n(March 2023) in this task. GPT-4 was less willing to answer sensitive questions\nin June than in March, and both GPT-4 and GPT-3.5 had more formatting mistakes\nin code generation in June than in March. Overall, our findings shows that the\nbehavior of the same LLM service can change substantially in a relatively short\namount of time, highlighting the need for continuous monitoring of LLM quality.",
          "link": "http://arxiv.org/abs/2307.09009",
          "publishedOn": "2023-07-19T01:53:28.913Z",
          "wordCount": null,
          "title": "How is ChatGPT's behavior changing over time?. (arXiv:2307.09009v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09248",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tan_L/0/1/0/all/0/1\">Longxing Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_H/0/1/0/all/0/1\">Hongying Yue</a>",
          "description": "Nowadays, wind energy has drawn increasing attention as its important role in\ncarbon neutrality and sustainable development. When wind power is integrated\ninto the power grid, precise forecasting is necessary for the sustainability\nand security of the system. However, the unpredictable nature and long sequence\nprediction make it especially challenging. In this technical report, we\nintroduce the BERT model applied for Baidu KDD Cup 2022, and the daily\nfluctuation is added by post-processing to make the predicted results in line\nwith daily periodicity. Our solution achieves 3rd place of 2490 teams. The code\nis released athttps://github.com/LongxingTan/KDD2022-Baidu",
          "link": "http://arxiv.org/abs/2307.09248",
          "publishedOn": "2023-07-19T01:53:28.910Z",
          "wordCount": null,
          "title": "Application of BERT in Wind Power Forecasting-Teletraan's Solution in Baidu KDD Cup 2022. (arXiv:2307.09248v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09365",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lukasik_J/0/1/0/all/0/1\">Jovita Lukasik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moeller_M/0/1/0/all/0/1\">Michael Moeller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keuper_M/0/1/0/all/0/1\">Margret Keuper</a>",
          "description": "Zero-cost proxies are nowadays frequently studied and used to search for\nneural architectures. They show an impressive ability to predict the\nperformance of architectures by making use of their untrained weights. These\ntechniques allow for immense search speed-ups. So far the joint search for\nwell-performing and robust architectures has received much less attention in\nthe field of NAS. Therefore, the main focus of zero-cost proxies is the clean\naccuracy of architectures, whereas the model robustness should play an evenly\nimportant part. In this paper, we analyze the ability of common zero-cost\nproxies to serve as performance predictors for robustness in the popular\nNAS-Bench-201 search space. We are interested in the single prediction task for\nrobustness and the joint multi-objective of clean and robust accuracy. We\nfurther analyze the feature importance of the proxies and show that predicting\nthe robustness makes the prediction task from existing zero-cost proxies more\nchallenging. As a result, the joint consideration of several proxies becomes\nnecessary to predict a model's robustness while the clean accuracy can be\nregressed from a single such feature.",
          "link": "http://arxiv.org/abs/2307.09365",
          "publishedOn": "2023-07-19T01:53:28.910Z",
          "wordCount": null,
          "title": "An Evaluation of Zero-Cost Proxies -- from Neural Architecture Performance to Model Robustness. (arXiv:2307.09365v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.03181",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Saxena_N/0/1/0/all/0/1\">Naman Saxena</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sandeep_G/0/1/0/all/0/1\">Gorantla Sandeep</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jagtap_P/0/1/0/all/0/1\">Pushpak Jagtap</a>",
          "description": "Signal Temporal Logic (STL) is a powerful framework for describing the\ncomplex temporal and logical behaviour of the dynamical system. Numerous\nstudies have attempted to employ reinforcement learning to learn a controller\nthat enforces STL specifications; however, they have been unable to effectively\ntackle the challenges of ensuring robust satisfaction in continuous state space\nand maintaining tractability. In this paper, leveraging the concept of funnel\nfunctions, we propose a tractable reinforcement learning algorithm to learn a\ntime-dependent policy for robust satisfaction of STL specification in\ncontinuous state space. We demonstrate the utility of our approach on several\nSTL tasks using different environments.",
          "link": "http://arxiv.org/abs/2212.03181",
          "publishedOn": "2023-07-19T01:53:28.860Z",
          "wordCount": null,
          "title": "Funnel-based Reward Shaping for Signal Temporal Logic Tasks in Reinforcement Learning. (arXiv:2212.03181v2 [eess.SY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2207.09920",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhong_K/0/1/0/all/0/1\">Kailiang Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_F/0/1/0/all/0/1\">Fengtong Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1\">Yan Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yaorong Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1\">Wenqing Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaofeng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cen_L/0/1/0/all/0/1\">Ling Cen</a>",
          "description": "Causal Inference has wide applications in various areas such as E-commerce\nand precision medicine, and its performance heavily relies on the accurate\nestimation of the Individual Treatment Effect (ITE). Conventionally, ITE is\npredicted by modeling the treated and control response functions separately in\ntheir individual sample spaces. However, such an approach usually encounters\ntwo issues in practice, i.e. divergent distribution between treated and control\ngroups due to treatment bias, and significant sample imbalance of their\npopulation sizes. This paper proposes Deep Entire Space Cross Networks (DESCN)\nto model treatment effects from an end-to-end perspective. DESCN captures the\nintegrated information of the treatment propensity, the response, and the\nhidden treatment effect through a cross network in a multi-task learning\nmanner. Our method jointly learns the treatment and response functions in the\nentire sample space to avoid treatment bias and employs an intermediate pseudo\ntreatment effect prediction network to relieve sample imbalance. Extensive\nexperiments are conducted on a synthetic dataset and a large-scaled production\ndataset from the E-commerce voucher distribution business. The results indicate\nthat DESCN can successfully enhance the accuracy of ITE estimation and improve\nthe uplift ranking performance. A sample of the production dataset and the\nsource code are released to facilitate future research in the community, which\nis, to the best of our knowledge, the first large-scale public biased treatment\ndataset for causal inference.",
          "link": "http://arxiv.org/abs/2207.09920",
          "publishedOn": "2023-07-19T01:53:28.855Z",
          "wordCount": null,
          "title": "DESCN: Deep Entire Space Cross Networks for Individual Treatment Effect Estimation. (arXiv:2207.09920v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.02057",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Self_R/0/1/0/all/0/1\">Ryan Self</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Coleman_K/0/1/0/all/0/1\">Kevin Coleman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bai_H/0/1/0/all/0/1\">He Bai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kamalapurkar_R/0/1/0/all/0/1\">Rushikesh Kamalapurkar</a>",
          "description": "In this paper, a novel approach to the output-feedback inverse reinforcement\nlearning (IRL) problem is developed by casting the IRL problem, for linear\nsystems with quadratic cost functions, as a state estimation problem. Two\nobserver-based techniques for IRL are developed, including a novel observer\nmethod that re-uses previous state estimates via history stacks. Theoretical\nguarantees for convergence and robustness are established under appropriate\nexcitation conditions. Simulations demonstrate the performance of the developed\nobservers and filters under noisy and noise-free measurements.",
          "link": "http://arxiv.org/abs/2011.02057",
          "publishedOn": "2023-07-19T01:53:28.854Z",
          "wordCount": null,
          "title": "Online Observer-Based Inverse Reinforcement Learning. (arXiv:2011.02057v3 [eess.SY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09060",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Miloshevich_G/0/1/0/all/0/1\">George Miloshevich</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lucente_D/0/1/0/all/0/1\">Dario Lucente</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Yiou_P/0/1/0/all/0/1\">Pascal Yiou</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bouchet_F/0/1/0/all/0/1\">Freddy Bouchet</a>",
          "description": "We present a data-driven emulator, stochastic weather generator (SWG),\nsuitable for estimating probabilities of prolonged heatwaves in France and\nScandinavia. This emulator is based on the method of analogs of circulation to\nwhich we add temperature and soil moisture as predictor fields. We train the\nemulator on an intermediate complexity climate model run and show that it is\ncapable of predicting conditional probabilities (forecasting) of heatwaves out\nof sample. Special attention is payed that this prediction is evaluated using\nproper score appropriate for rare events. To accelerate the computation of\nanalogs dimensionality reduction techniques are applied and the performance is\nevaluated. The probabilistic prediction achieved with SWG is compared with the\none achieved with\n\nConvolutional Neural Network (CNN). With the availability of hundreds of\nyears of training data CNNs perform better at the task of probabilistic\nprediction. In addition, we show that the SWG emulator trained on 80 years of\ndata is capable of estimating extreme return times of order of thousands of\nyears for heatwaves longer than several days more precisely than the fit based\non generalised extreme value distribution. Finally, the quality of its\nsynthetic extreme teleconnection patterns obtained with stochastic weather\ngenerator is studied. We showcase two examples of such synthetic teleconnection\npatterns for heatwaves in France and Scandinavia that compare favorably to the\nvery long climate model control run.",
          "link": "http://arxiv.org/abs/2307.09060",
          "publishedOn": "2023-07-19T01:53:28.845Z",
          "wordCount": null,
          "title": "Extreme heatwave sampling and prediction with analog Markov chain and comparisons with deep learning. (arXiv:2307.09060v1 [physics.ao-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09372",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rastogi_S/0/1/0/all/0/1\">Sambhav Jain Reshma Rastogi</a>",
          "description": "Support Vector Machines (SVM) have gathered significant acclaim as\nclassifiers due to their successful implementation of Statistical Learning\nTheory. However, in the context of multiclass and multilabel settings, the\nreliance on vector-based formulations in existing SVM-based models poses\nlimitations regarding flexibility and ease of incorporating additional terms to\nhandle specific challenges. To overcome these limitations, our research paper\nfocuses on introducing a matrix formulation for SVM that effectively addresses\nthese constraints. By employing the Accelerated Gradient Descent method in the\ndual, we notably enhance the efficiency of solving the Matrix-SVM problem.\nExperimental evaluations on multilabel and multiclass datasets demonstrate that\nMatrix SVM achieves superior time efficacy while delivering similar results to\nBinary Relevance SVM.\n\nMoreover, our matrix formulation unveils crucial insights and advantages that\nmay not be readily apparent in traditional vector-based notations. We emphasize\nthat numerous multilabel models can be viewed as extensions of SVM, with\ncustomised modifications to meet specific requirements. The matrix formulation\npresented in this paper establishes a solid foundation for developing more\nsophisticated models capable of effectively addressing the distinctive\nchallenges encountered in multilabel learning.",
          "link": "http://arxiv.org/abs/2307.09372",
          "publishedOn": "2023-07-19T01:53:28.844Z",
          "wordCount": null,
          "title": "Enhancing Pattern Classification in Support Vector Machines through Matrix Formulation. (arXiv:2307.09372v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.02011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Harar_P/0/1/0/all/0/1\">Pavol Harar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herrmann_L/0/1/0/all/0/1\">Lukas Herrmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grohs_P/0/1/0/all/0/1\">Philipp Grohs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haselbach_D/0/1/0/all/0/1\">David Haselbach</a>",
          "description": "Particle localization and -classification constitute two of the most\nfundamental problems in computational microscopy. In recent years, deep\nlearning based approaches have been introduced for these tasks with great\nsuccess. A key shortcoming of these supervised learning methods is their need\nfor large training data sets, typically generated from particle models in\nconjunction with complex numerical forward models simulating the physics of\ntransmission electron microscopes. Computer implementations of such forward\nmodels are computationally extremely demanding and limit the scope of their\napplicability. In this paper we propose a method for simulating the forward\noperator of an electron microscope based on additive noise and Neural Style\nTransfer techniques. We evaluate the method on localization and classification\ntasks using one of the established state-of-the-art architectures showing\nperformance on par with the benchmark. In contrast to previous approaches, our\nmethod accelerates the data generation process by a factor of 750 while using\n33 times less memory and scales well to typical transmission electron\nmicroscope detector sizes. It utilizes GPU acceleration and parallel\nprocessing. It can be used to adapt a synthetic training data set according to\nreference data from any transmission electron microscope. The source code is\navailable at https://gitlab.com/deepet/faket.",
          "link": "http://arxiv.org/abs/2304.02011",
          "publishedOn": "2023-07-19T01:53:28.837Z",
          "wordCount": null,
          "title": "FakET: Simulating Cryo-Electron Tomograms with Neural Style Transfer. (arXiv:2304.02011v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09470",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1\">Chanwoo Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaiqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozdaglar_A/0/1/0/all/0/1\">Asuman Ozdaglar</a>",
          "description": "We study a new class of Markov games (MGs), \\textit{Multi-player Zero-sum\nMarkov Games} with {\\it Networked separable interactions} (MZNMGs), to model\nthe local interaction structure in non-cooperative multi-agent sequential\ndecision-making. We define an MZNMG as a model where {the payoffs of the\nauxiliary games associated with each state are zero-sum and} have some\nseparable (i.e., polymatrix) structure across the neighbors over some\ninteraction network. We first identify the necessary and sufficient conditions\nunder which an MG can be presented as an MZNMG, and show that the set of Markov\ncoarse correlated equilibrium (CCE) collapses to the set of Markov Nash\nequilibrium (NE) in these games, in that the {product of} per-state\nmarginalization of the former for all players yields the latter. Furthermore,\nwe show that finding approximate Markov \\emph{stationary} CCE in\ninfinite-horizon discounted MZNMGs is \\texttt{PPAD}-hard, unless the underlying\nnetwork has a ``star topology''. Then, we propose fictitious-play-type\ndynamics, the classical learning dynamics in normal-form games, for MZNMGs, and\nestablish convergence guarantees to Markov stationary NE under a star-shaped\nnetwork structure. Finally, in light of the hardness result, we focus on\ncomputing a Markov \\emph{non-stationary} NE and provide finite-iteration\nguarantees for a series of value-iteration-based algorithms. We also provide\nnumerical experiments to corroborate our theoretical results.",
          "link": "http://arxiv.org/abs/2307.09470",
          "publishedOn": "2023-07-19T01:53:28.832Z",
          "wordCount": null,
          "title": "Multi-Player Zero-Sum Markov Games with Networked Separable Interactions. (arXiv:2307.09470v1 [cs.GT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08794",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Emami_P/0/1/0/all/0/1\">Patrick Emami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biagioni_D/0/1/0/all/0/1\">David Biagioni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zamzam_A/0/1/0/all/0/1\">Ahmed S. Zamzam</a>",
          "description": "In multi-timescale multi-agent reinforcement learning (MARL), agents interact\nacross different timescales. In general, policies for time-dependent behaviors,\nsuch as those induced by multiple timescales, are non-stationary. Learning\nnon-stationary policies is challenging and typically requires sophisticated or\ninefficient algorithms. Motivated by the prevalence of this control problem in\nreal-world complex systems, we introduce a simple framework for learning\nnon-stationary policies for multi-timescale MARL. Our approach uses available\ninformation about agent timescales to define a periodic time encoding. In\ndetail, we theoretically demonstrate that the effects of non-stationarity\nintroduced by multiple timescales can be learned by a periodic multi-agent\npolicy. To learn such policies, we propose a policy gradient algorithm that\nparameterizes the actor and critic with phase-functioned neural networks, which\nprovide an inductive bias for periodicity. The framework's ability to\neffectively learn multi-timescale policies is validated on a gridworld and\nbuilding energy management environment.",
          "link": "http://arxiv.org/abs/2307.08794",
          "publishedOn": "2023-07-19T01:53:28.831Z",
          "wordCount": null,
          "title": "Non-Stationary Policy Learning for Multi-Timescale Multi-Agent Reinforcement Learning. (arXiv:2307.08794v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.13816",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shojaee_P/0/1/0/all/0/1\">Parshin Shojaee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Aneesh Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tipirneni_S/0/1/0/all/0/1\">Sindhu Tipirneni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_C/0/1/0/all/0/1\">Chandan K. Reddy</a>",
          "description": "The utilization of programming language (PL) models, pre-trained on\nlarge-scale code corpora, as a means of automating software engineering\nprocesses has demonstrated considerable potential in streamlining various code\ngeneration tasks such as code completion, code translation, and program\nsynthesis. However, current approaches mainly rely on supervised fine-tuning\nobjectives borrowed from text generation, neglecting unique sequence-level\ncharacteristics of code, including but not limited to compilability as well as\nsyntactic and functional correctness. To address this limitation, we propose\nPPOCoder, a new framework for code generation that synergistically combines\npre-trained PL models with Proximal Policy Optimization (PPO) which is a widely\nused deep reinforcement learning technique. By utilizing non-differentiable\nfeedback from code execution and structure alignment, PPOCoder seamlessly\nintegrates external code-specific knowledge into the model optimization\nprocess. It's important to note that PPOCoder is a task-agnostic and\nmodel-agnostic framework that can be used across different code generation\ntasks and PLs. Extensive experiments on three code generation tasks demonstrate\nthe effectiveness of our proposed approach compared to SOTA methods, achieving\nsignificant improvements in compilation success rates and functional\ncorrectness across different PLs.",
          "link": "http://arxiv.org/abs/2301.13816",
          "publishedOn": "2023-07-19T01:53:28.829Z",
          "wordCount": null,
          "title": "Execution-based Code Generation using Deep Reinforcement Learning. (arXiv:2301.13816v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.02877",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Assouli_M/0/1/0/all/0/1\">Mouhcine Assouli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Missaoui_B/0/1/0/all/0/1\">Badr Missaoui</a>",
          "description": "This paper introduces a new method based on Deep Galerkin Methods (DGMs) for\nsolving high-dimensional stochastic Mean Field Games (MFGs). We achieve this by\nusing two neural networks to approximate the unknown solutions of the MFG\nsystem and forward-backward conditions. Our method is efficient, even with a\nsmall number of iterations, and is capable of handling up to 300 dimensions\nwith a single layer, which makes it faster than other approaches. In contrast,\nmethods based on Generative Adversarial Networks (GANs) cannot solve MFGs with\nnon-separable Hamiltonians. We demonstrate the effectiveness of our approach by\napplying it to a traffic flow problem, which was previously solved using the\nNewton iteration method only in the deterministic case. We compare the results\nof our method to analytical solutions and previous approaches, showing its\nefficiency. We also prove the convergence of our neural network approximation\nwith a single hidden layer using the universal approximation theorem.",
          "link": "http://arxiv.org/abs/2301.02877",
          "publishedOn": "2023-07-19T01:53:28.827Z",
          "wordCount": null,
          "title": "Deep Learning for Mean Field Games with non-separable Hamiltonians. (arXiv:2301.02877v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09244",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pirnat_A/0/1/0/all/0/1\">An&#x17e;e Pirnat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bertalanic_B/0/1/0/all/0/1\">Bla&#x17e; Bertalani&#x10d;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cerar_G/0/1/0/all/0/1\">Gregor Cerar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohorcic_M/0/1/0/all/0/1\">Mihael Mohor&#x10d;i&#x10d;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fortuna_C/0/1/0/all/0/1\">Carolina Fortuna</a>",
          "description": "Non-intrusive load monitoring (NILM) is the process of obtaining\nappliance-level data from a single metering point, measuring total electricity\nconsumption of a household or a business. Appliance-level data can be directly\nused for demand response applications and energy management systems as well as\nfor awareness raising and motivation for improvements in energy efficiency and\nreduction in the carbon footprint. Recently, classical machine learning and\ndeep learning (DL) techniques became very popular and proved as highly\neffective for NILM classification, but with the growing complexity these\nmethods are faced with significant computational and energy demands during both\ntheir training and operation. In this paper, we introduce a novel DL model\naimed at enhanced multi-label classification of NILM with improved computation\nand energy efficiency. We also propose a testing methodology for comparison of\ndifferent models using data synthesized from the measurement datasets so as to\nbetter represent real-world scenarios. Compared to the state-of-the-art, the\nproposed model has its carbon footprint reduced by more than 23% while\nproviding on average approximately 8 percentage points in performance\nimprovement when testing on data derived from REFIT and UK-DALE datasets.",
          "link": "http://arxiv.org/abs/2307.09244",
          "publishedOn": "2023-07-19T01:53:28.826Z",
          "wordCount": null,
          "title": "Towards Sustainable Deep Learning for Multi-Label Classification on NILM. (arXiv:2307.09244v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08533",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Yildirim_M/0/1/0/all/0/1\">Mustafa Yildirim</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Dinc_N/0/1/0/all/0/1\">Niyazi Ulas Dinc</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Oguz_I/0/1/0/all/0/1\">Ilker Oguz</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Psaltis_D/0/1/0/all/0/1\">Demetri Psaltis</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Moser_C/0/1/0/all/0/1\">Christophe Moser</a>",
          "description": "Deep neural networks have achieved remarkable breakthroughs by leveraging\nmultiple layers of data processing to extract hidden representations, albeit at\nthe cost of large electronic computing power. To enhance energy efficiency and\nspeed, the optical implementation of neural networks aims to harness the\nadvantages of optical bandwidth and the energy efficiency of optical\ninterconnections. In the absence of low-power optical nonlinearities, the\nchallenge in the implementation of multilayer optical networks lies in\nrealizing multiple optical layers without resorting to electronic components.\nIn this study, we present a novel framework that uses multiple scattering that\nis capable of synthesizing programmable linear and nonlinear transformations\nconcurrently at low optical power by leveraging the nonlinear relationship\nbetween the scattering potential, represented by data, and the scattered field.\nTheoretical and experimental investigations show that repeating the data by\nmultiple scattering enables non-linear optical computing at low power\ncontinuous wave light.",
          "link": "http://arxiv.org/abs/2307.08533",
          "publishedOn": "2023-07-19T01:53:28.823Z",
          "wordCount": null,
          "title": "Nonlinear Processing with Linear Optics. (arXiv:2307.08533v2 [physics.optics] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08897",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jalolia_M/0/1/0/all/0/1\">Mehrad Jalolia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cescon_M/0/1/0/all/0/1\">Marzia Cescon</a>",
          "description": "This paper presents a novel multi-agent reinforcement learning (RL) approach\nfor personalized glucose control in individuals with type 1 diabetes (T1D). The\nmethod employs a closed-loop system consisting of a blood glucose (BG)\nmetabolic model and a multi-agent soft actor-critic RL model acting as the\nbasal-bolus advisor. Performance evaluation is conducted in three scenarios,\ncomparing the RL agents to conventional therapy. Evaluation metrics include\nglucose levels (minimum, maximum, and mean), time spent in different BG ranges,\nand average daily bolus and basal insulin dosages. Results demonstrate that the\nRL-based basal-bolus advisor significantly improves glucose control, reducing\nglycemic variability and increasing time spent within the target range (70-180\nmg/dL). Hypoglycemia events are effectively prevented, and severe hyperglycemia\nevents are reduced. The RL approach also leads to a statistically significant\nreduction in average daily basal insulin dosage compared to conventional\ntherapy. These findings highlight the effectiveness of the multi-agent RL\napproach in achieving better glucose control and mitigating the risk of severe\nhyperglycemia in individuals with T1D.",
          "link": "http://arxiv.org/abs/2307.08897",
          "publishedOn": "2023-07-19T01:53:28.775Z",
          "wordCount": null,
          "title": "Basal-Bolus Advisor for Type 1 Diabetes (T1D) Patients Using Multi-Agent Reinforcement Learning (RL) Methodology. (arXiv:2307.08897v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09286",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiu Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erol_M/0/1/0/all/0/1\">Mehmet Hamza Erol</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_J/0/1/0/all/0/1\">Joon Son Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Senocak_A/0/1/0/all/0/1\">Arda Senocak</a>",
          "description": "The objective of this work is to give patch-size flexibility to Audio\nSpectrogram Transformers (AST). Recent advancements in ASTs have shown superior\nperformance in various audio-based tasks. However, the performance of standard\nASTs degrades drastically when evaluated using different patch sizes from that\nused during training. As a result, AST models are typically re-trained to\naccommodate changes in patch sizes. To overcome this limitation, this paper\nproposes a training procedure to provide flexibility to standard AST models\nwithout architectural changes, allowing them to work with various patch sizes\nat the inference stage - FlexiAST. This proposed training approach simply\nutilizes random patch size selection and resizing of patch and positional\nembedding weights. Our experiments show that FlexiAST gives similar performance\nto standard AST models while maintaining its evaluation ability at various\npatch sizes on different datasets for audio classification tasks.",
          "link": "http://arxiv.org/abs/2307.09286",
          "publishedOn": "2023-07-19T01:53:28.773Z",
          "wordCount": null,
          "title": "FlexiAST: Flexibility is What AST Needs. (arXiv:2307.09286v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08999",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1\">Sumegha Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_C/0/1/0/all/0/1\">Christopher Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reingold_O/0/1/0/all/0/1\">Omer Reingold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_A/0/1/0/all/0/1\">Aaron Roth</a>",
          "description": "A recent line of work has shown a surprising connection between\nmulticalibration, a multi-group fairness notion, and omniprediction, a learning\nparadigm that provides simultaneous loss minimization guarantees for a large\nfamily of loss functions. Prior work studies omniprediction in the batch\nsetting. We initiate the study of omniprediction in the online adversarial\nsetting. Although there exist algorithms for obtaining notions of\nmulticalibration in the online adversarial setting, unlike batch algorithms,\nthey work only for small finite classes of benchmark functions $F$, because\nthey require enumerating every function $f \\in F$ at every round. In contrast,\nomniprediction is most interesting for learning theoretic hypothesis classes\n$F$, which are generally continuously large.\n\nWe develop a new online multicalibration algorithm that is well defined for\ninfinite benchmark classes $F$, and is oracle efficient (i.e. for any class\n$F$, the algorithm has the form of an efficient reduction to a no-regret\nlearning algorithm for $F$). The result is the first efficient online\nomnipredictor -- an oracle efficient prediction algorithm that can be used to\nsimultaneously obtain no regret guarantees to all Lipschitz convex loss\nfunctions. For the class $F$ of linear functions, we show how to make our\nalgorithm efficient in the worst case. Also, we show upper and lower bounds on\nthe extent to which our rates can be improved: our oracle efficient algorithm\nactually promises a stronger guarantee called swap-omniprediction, and we prove\na lower bound showing that obtaining $O(\\sqrt{T})$ bounds for\nswap-omniprediction is impossible in the online setting. On the other hand, we\ngive a (non-oracle efficient) algorithm which can obtain the optimal\n$O(\\sqrt{T})$ omniprediction bounds without going through multicalibration,\ngiving an information theoretic separation between these two solution concepts.",
          "link": "http://arxiv.org/abs/2307.08999",
          "publishedOn": "2023-07-19T01:53:28.771Z",
          "wordCount": null,
          "title": "Oracle Efficient Online Multicalibration and Omniprediction. (arXiv:2307.08999v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.09662",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1\">Cheng Ruei Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_J/0/1/0/all/0/1\">Jun Wei Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teng_S/0/1/0/all/0/1\">Shin You Teng</a>",
          "description": "Existing traffic signal control systems rely on oversimplified rule-based\nmethods, and even RL-based methods are often suboptimal and unstable. To\naddress this, we propose a cooperative multi-objective architecture called\nMulti-Objective Multi-Agent Deep Deterministic Policy Gradient (MOMA-DDPG),\nwhich estimates multiple reward terms for traffic signal control optimization\nusing age-decaying weights. Our approach involves two types of agents: one\nfocuses on optimizing local traffic at each intersection, while the other aims\nto optimize global traffic throughput. We evaluate our method using real-world\ntraffic data collected from an Asian country's traffic cameras. Despite the\ninclusion of a global agent, our solution remains decentralized as this agent\nis no longer necessary during the inference stage. Our results demonstrate the\neffectiveness of MOMA-DDPG, outperforming state-of-the-art methods across all\nperformance metrics. Additionally, our proposed system minimizes both waiting\ntime and carbon emissions. Notably, this paper is the first to link carbon\nemissions and global agents in traffic signal control.",
          "link": "http://arxiv.org/abs/2306.09662",
          "publishedOn": "2023-07-19T01:53:28.767Z",
          "wordCount": null,
          "title": "Cooperative Multi-Objective Reinforcement Learning for Traffic Signal Control and Carbon Emission Reduction. (arXiv:2306.09662v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09441",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Hauptmann_A/0/1/0/all/0/1\">Andreas Hauptmann</a>, <a href=\"http://arxiv.org/find/math/1/au:+Mukherjee_S/0/1/0/all/0/1\">Subhadip Mukherjee</a>, <a href=\"http://arxiv.org/find/math/1/au:+Schonlieb_C/0/1/0/all/0/1\">Carola-Bibiane Sch&#xf6;nlieb</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sherry_F/0/1/0/all/0/1\">Ferdia Sherry</a>",
          "description": "Plug-and-play (PnP) denoising is a popular iterative framework for solving\nimaging inverse problems using off-the-shelf image denoisers. Their empirical\nsuccess has motivated a line of research that seeks to understand the\nconvergence of PnP iterates under various assumptions on the denoiser. While a\nsignificant amount of research has gone into establishing the convergence of\nthe PnP iteration for different regularity conditions on the denoisers, not\nmuch is known about the asymptotic properties of the converged solution as the\nnoise level in the measurement tends to zero, i.e., whether PnP methods are\nprovably convergent regularization schemes under reasonable assumptions on the\ndenoiser. This paper serves two purposes: first, we provide an overview of the\nclassical regularization theory in inverse problems and survey a few notable\nrecent data-driven methods that are provably convergent regularization schemes.\nWe then continue to discuss PnP algorithms and their established convergence\nguarantees. Subsequently, we consider PnP algorithms with linear denoisers and\npropose a novel spectral filtering technique to control the strength of\nregularization arising from the denoiser. Further, by relating the implicit\nregularization of the denoiser to an explicit regularization functional, we\nrigorously show that PnP with linear denoisers leads to a convergent\nregularization scheme. More specifically, we prove that in the limit as the\nnoise vanishes, the PnP reconstruction converges to the minimizer of a\nregularization potential subject to the solution satisfying the noiseless\noperator equation. The theoretical analysis is corroborated by numerical\nexperiments for the classical inverse problem of tomographic image\nreconstruction.",
          "link": "http://arxiv.org/abs/2307.09441",
          "publishedOn": "2023-07-19T01:53:28.766Z",
          "wordCount": null,
          "title": "Convergent regularization in inverse problems and linear plug-and-play denoisers. (arXiv:2307.09441v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.13697",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hebert_L/0/1/0/all/0/1\">Liam Hebert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golab_L/0/1/0/all/0/1\">Lukasz Golab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poupart_P/0/1/0/all/0/1\">Pascal Poupart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_R/0/1/0/all/0/1\">Robin Cohen</a>",
          "description": "A core issue in multi-agent federated reinforcement learning is defining how\nto aggregate insights from multiple agents. This is commonly done by taking the\naverage of each participating agent's model weights into one common model\n(FedAvg). We instead propose FedFormer, a novel federation strategy that\nutilizes Transformer Attention to contextually aggregate embeddings from models\noriginating from different learner agents. In so doing, we attentively weigh\nthe contributions of other agents with respect to the current agent's\nenvironment and learned relationships, thus providing a more effective and\nefficient federation. We evaluate our methods on the Meta-World environment and\nfind that our approach yields significant improvements over FedAvg and\nnon-federated Soft Actor-Critic single-agent methods. Our results compared to\nSoft Actor-Critic show that FedFormer achieves higher episodic return while\nstill abiding by the privacy constraints of federated learning. Finally, we\nalso demonstrate improvements in effectiveness with increased agent pools\nacross all methods in certain tasks. This is contrasted by FedAvg, which fails\nto make noticeable improvements when scaled.",
          "link": "http://arxiv.org/abs/2205.13697",
          "publishedOn": "2023-07-19T01:53:28.761Z",
          "wordCount": null,
          "title": "FedFormer: Contextual Federation with Attention in Reinforcement Learning. (arXiv:2205.13697v3 [cs.LG] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09366",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Behdin_K/0/1/0/all/0/1\">Kayhan Behdin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazumder_R/0/1/0/all/0/1\">Rahul Mazumder</a>",
          "description": "We consider the problem of learning a sparse graph underlying an undirected\nGaussian graphical model, a key problem in statistical machine learning. Given\n$n$ samples from a multivariate Gaussian distribution with $p$ variables, the\ngoal is to estimate the $p \\times p$ inverse covariance matrix (aka precision\nmatrix), assuming it is sparse (i.e., has a few nonzero entries). We propose\nGraphL0BnB, a new estimator based on an $\\ell_0$-penalized version of the\npseudolikelihood function, while most earlier approaches are based on the\n$\\ell_1$-relaxation. Our estimator can be formulated as a convex mixed integer\nprogram (MIP) which can be difficult to compute at scale using off-the-shelf\ncommercial solvers. To solve the MIP, we propose a custom nonlinear\nbranch-and-bound (BnB) framework that solves node relaxations with tailored\nfirst-order methods. As a by-product of our BnB framework, we propose\nlarge-scale solvers for obtaining good primal solutions that are of independent\ninterest. We derive novel statistical guarantees (estimation and variable\nselection) for our estimator and discuss how our approach improves upon\nexisting estimators. Our numerical experiments on real/synthetic datasets\nsuggest that our method can solve, to near-optimality, problem instances with\n$p = 10^4$ -- corresponding to a symmetric matrix of size $p \\times p$ with\n$p^2/2$ binary variables. We demonstrate the usefulness of GraphL0BnB versus\nvarious state-of-the-art approaches on a range of datasets.",
          "link": "http://arxiv.org/abs/2307.09366",
          "publishedOn": "2023-07-19T01:53:28.758Z",
          "wordCount": null,
          "title": "Sparse Gaussian Graphical Models with Discrete Optimization: Computational and Statistical Perspectives. (arXiv:2307.09366v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09207",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Yang_Y/0/1/0/all/0/1\">Yuanyuan Yang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Birnie_C/0/1/0/all/0/1\">Claire Birnie</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Alkhalifah_T/0/1/0/all/0/1\">Tariq Alkhalifah</a>",
          "description": "Microseismic event detection and location are two primary components in\nmicroseismic monitoring, which offers us invaluable insights into the\nsubsurface during reservoir stimulation and evolution. Conventional approaches\nfor event detection and location often suffer from manual intervention and/or\nheavy computation, while current machine learning-assisted approaches typically\naddress detection and location separately; such limitations hinder the\npotential for real-time microseismic monitoring. We propose an approach to\nunify event detection and source location into a single framework by adapting a\nConvolutional Neural Network backbone and an encoder-decoder Transformer with a\nset-based Hungarian loss, which is applied directly to recorded waveforms. The\nproposed network is trained on synthetic data simulating multiple microseismic\nevents corresponding to random source locations in the area of suspected\nmicroseismic activities. A synthetic test on a 2D profile of the SEAM Time\nLapse model illustrates the capability of the proposed method in detecting the\nevents properly and locating them in the subsurface accurately; while, a field\ntest using the Arkoma Basin data further proves its practicability, efficiency,\nand its potential in paving the way for real-time monitoring of microseismic\nevents.",
          "link": "http://arxiv.org/abs/2307.09207",
          "publishedOn": "2023-07-19T01:53:28.755Z",
          "wordCount": null,
          "title": "Joint Microseismic Event Detection and Location with a Detection Transformer. (arXiv:2307.09207v1 [physics.geo-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08686",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Anderson_J/0/1/0/all/0/1\">Joshua Wolff Anderson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rakovski_C/0/1/0/all/0/1\">Cyril Rakovski</a>",
          "description": "This article explains the usage of R package CausalModels, which is publicly\navailable on the Comprehensive R Archive Network. While packages are available\nfor sufficiently estimating causal effects, there lacks a package that provides\na collection of structural models using the conventional statistical approach\ndeveloped by Hernan and Robins (2020). CausalModels addresses this deficiency\nof software in R concerning causal inference by offering tools for methods that\naccount for biases in observational data without requiring extensive\nstatistical knowledge. These methods should not be ignored and may be more\nappropriate or efficient in solving particular problems. While implementations\nof these statistical models are distributed among a number of causal packages,\nCausalModels introduces a simple and accessible framework for a consistent\nmodeling pipeline among a variety of statistical methods for estimating causal\neffects in a single R package. It consists of common methods including\nstandardization, IP weighting, G-estimation, outcome regression, instrumental\nvariables and propensity matching.",
          "link": "http://arxiv.org/abs/2307.08686",
          "publishedOn": "2023-07-19T01:53:28.754Z",
          "wordCount": null,
          "title": "An R package for parametric estimation of causal effects. (arXiv:2307.08686v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07916",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_M/0/1/0/all/0/1\">Mingyuan Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Cen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chengyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wenmeng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jun Huang</a>",
          "description": "Split learning enables collaborative deep learning model training while\npreserving data privacy and model security by avoiding direct sharing of raw\ndata and model details (i.e., sever and clients only hold partial sub-networks\nand exchange intermediate computations). However, existing research has mainly\nfocused on examining its reliability for privacy protection, with little\ninvestigation into model security. Specifically, by exploring full models,\nattackers can launch adversarial attacks, and split learning can mitigate this\nsevere threat by only disclosing part of models to untrusted servers.This paper\naims to evaluate the robustness of split learning against adversarial attacks,\nparticularly in the most challenging setting where untrusted servers only have\naccess to the intermediate layers of the model.Existing adversarial attacks\nmostly focus on the centralized setting instead of the collaborative setting,\nthus, to better evaluate the robustness of split learning, we develop a\ntailored attack called SPADV, which comprises two stages: 1) shadow model\ntraining that addresses the issue of lacking part of the model and 2) local\nadversarial attack that produces adversarial examples to evaluate.The first\nstage only requires a few unlabeled non-IID data, and, in the second stage,\nSPADV perturbs the intermediate output of natural samples to craft the\nadversarial ones. The overall cost of the proposed attack process is relatively\nlow, yet the empirical attack effectiveness is significantly high,\ndemonstrating the surprising vulnerability of split learning to adversarial\nattacks.",
          "link": "http://arxiv.org/abs/2307.07916",
          "publishedOn": "2023-07-19T01:53:28.750Z",
          "wordCount": null,
          "title": "On the Robustness of Split Learning against Adversarial Attacks. (arXiv:2307.07916v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.07617",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Defresne_M/0/1/0/all/0/1\">Marianne Defresne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barbe_S/0/1/0/all/0/1\">Sophie Barbe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schiex_T/0/1/0/all/0/1\">Thomas Schiex</a>",
          "description": "In the ongoing quest for hybridizing discrete reasoning with neural nets,\nthere is an increasing interest in neural architectures that can learn how to\nsolve discrete reasoning or optimization problems from natural inputs. In this\npaper, we introduce a scalable neural architecture and loss function dedicated\nto learning the constraints and criteria of NP-hard reasoning problems\nexpressed as discrete Graphical Models. Our loss function solves one of the\nmain limitations of Besag's pseudo-loglikelihood, enabling learning of high\nenergies. We empirically show it is able to efficiently learn how to solve\nNP-hard reasoning problems from natural inputs as the symbolic, visual or\nmany-solutions Sudoku problems as well as the energy optimization formulation\nof the protein design problem, providing data efficiency, interpretability, and\n\\textit{a posteriori} control over predictions.",
          "link": "http://arxiv.org/abs/2305.07617",
          "publishedOn": "2023-07-19T01:53:28.749Z",
          "wordCount": null,
          "title": "Scalable Coupling of Deep Learning with Logical Reasoning. (arXiv:2305.07617v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08944",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sheng_T/0/1/0/all/0/1\">Taoran Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huber_M/0/1/0/all/0/1\">Manfred Huber</a>",
          "description": "Deep learning has been successfully applied to human activity recognition.\nHowever, training deep neural networks requires explicitly labeled data which\nis difficult to acquire. In this paper, we present a model with multiple\nsiamese networks that are trained by using only the information about the\nsimilarity between pairs of data samples without knowing the explicit labels.\nThe trained model maps the activity data samples into fixed size representation\nvectors such that the distance between the vectors in the representation space\napproximates the similarity of the data samples in the input space. Thus, the\ntrained model can work as a metric for a wide range of different clustering\nalgorithms. The training process minimizes a similarity loss function that\nforces the distance metric to be small for pairs of samples from the same kind\nof activity, and large for pairs of samples from different kinds of activities.\nWe evaluate the model on three datasets to verify its effectiveness in\nsegmentation and recognition of continuous human activity sequences.",
          "link": "http://arxiv.org/abs/2307.08944",
          "publishedOn": "2023-07-19T01:53:28.748Z",
          "wordCount": null,
          "title": "Siamese Networks for Weakly Supervised Human Activity Recognition. (arXiv:2307.08944v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09379",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Loukas_A/0/1/0/all/0/1\">Andreas Loukas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kessel_P/0/1/0/all/0/1\">Pan Kessel</a>",
          "description": "We study the generalization properties of batched predictors, i.e., models\ntasked with predicting the mean label of a small set (or batch) of examples.\nThe batched prediction paradigm is particularly relevant for models deployed to\ndetermine the quality of a group of compounds in preparation for offline\ntesting. By utilizing a suitable generalization of the Rademacher complexity,\nwe prove that batched predictors come with exponentially stronger\ngeneralization guarantees as compared to the standard per-sample approach.\nSurprisingly, the proposed bound holds independently of overparametrization.\nOur theoretical insights are validated experimentally for various tasks,\narchitectures, and applications.",
          "link": "http://arxiv.org/abs/2307.09379",
          "publishedOn": "2023-07-19T01:53:28.747Z",
          "wordCount": null,
          "title": "Batched Predictors Generalize within Distribution. (arXiv:2307.09379v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.05439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_F/0/1/0/all/0/1\">Fei Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krovi_V/0/1/0/all/0/1\">Venkat Krovi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1\">Feng Luo</a>",
          "description": "Clustering continues to be a significant and challenging task. Recent studies\nhave demonstrated impressive results by applying clustering to feature\nrepresentations acquired through self-supervised learning, particularly on\nsmall datasets. However, when dealing with datasets containing a large number\nof clusters, such as ImageNet, current methods struggle to achieve satisfactory\nclustering performance. In this paper, we introduce a novel method called\nContrastive representation Disentanglement for Clustering (CDC) that leverages\ncontrastive learning to directly disentangle the feature representation for\nclustering. In CDC, we decompose the representation into two distinct\ncomponents: one component encodes categorical information under an\nequipartition constraint, and the other component captures instance-specific\nfactors. To train our model, we propose a contrastive loss that effectively\nutilizes both components of the representation. We conduct a theoretical\nanalysis of the proposed loss and highlight how it assigns different weights to\nnegative samples during the process of disentangling the feature\nrepresentation. Further analysis of the gradients reveals that larger weights\nemphasize a stronger focus on hard negative samples. As a result, the proposed\nloss exhibits strong expressiveness, enabling efficient disentanglement of\ncategorical information. Through experimental evaluation on various benchmark\ndatasets, our method demonstrates either state-of-the-art or highly competitive\nclustering performance. Notably, on the complete ImageNet dataset, we achieve\nan accuracy of 53.4%, surpassing existing methods by a substantial margin of\n+10.2%.",
          "link": "http://arxiv.org/abs/2306.05439",
          "publishedOn": "2023-07-19T01:53:28.738Z",
          "wordCount": null,
          "title": "Contrastive Representation Disentanglement for Clustering. (arXiv:2306.05439v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09109",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lambert_H/0/1/0/all/0/1\">Hugues Lambert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slade_E/0/1/0/all/0/1\">Emma Slade</a>",
          "description": "Several Active Learning (AL) policies require retraining a target model\nseveral times in order to identify the most informative samples and rarely\noffer the option to focus on the acquisition of samples from underrepresented\nclasses. Here the Mining of Single-Class by Active Learning (MiSiCAL) paradigm\nis introduced where an AL policy is constructed through deep reinforcement\nlearning and exploits quantity-accuracy correlations to build datasets on which\nhigh-performance models can be trained with regards to specific classes.\nMiSiCAL is especially helpful in the case of very large batch sizes since it\ndoes not require repeated model training sessions as is common in other AL\nmethods. This is thanks to its ability to exploit fixed representations of the\ncandidate data points. We find that MiSiCAL is able to outperform a random\npolicy on 150 out of 171 COCO10k classes, while the strongest baseline only\noutperforms random on 101 classes.",
          "link": "http://arxiv.org/abs/2307.09109",
          "publishedOn": "2023-07-19T01:53:28.736Z",
          "wordCount": null,
          "title": "Mining of Single-Class by Active Learning for Semantic Segmentation. (arXiv:2307.09109v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.02689",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chenyu You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1\">Weicheng Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_Y/0/1/0/all/0/1\">Yifei Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staib_L/0/1/0/all/0/1\">Lawrence Staib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sekhon_J/0/1/0/all/0/1\">Jasjeet S. Sekhon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duncan_J/0/1/0/all/0/1\">James S. Duncan</a>",
          "description": "Medical data often exhibits long-tail distributions with heavy class\nimbalance, which naturally leads to difficulty in classifying the minority\nclasses (i.e., boundary regions or rare objects). Recent work has significantly\nimproved semi-supervised medical image segmentation in long-tailed scenarios by\nequipping them with unsupervised contrastive criteria. However, it remains\nunclear how well they will perform in the labeled portion of data where class\ndistribution is also highly imbalanced. In this work, we present ACTION++, an\nimproved contrastive learning framework with adaptive anatomical contrast for\nsemi-supervised medical segmentation. Specifically, we propose an adaptive\nsupervised contrastive loss, where we first compute the optimal locations of\nclass centers uniformly distributed on the embedding space (i.e., off-line),\nand then perform online contrastive matching training by encouraging different\nclass features to adaptively match these distinct and uniformly distributed\nclass centers. Moreover, we argue that blindly adopting a constant temperature\n$\\tau$ in the contrastive loss on long-tailed medical data is not optimal, and\npropose to use a dynamic $\\tau$ via a simple cosine schedule to yield better\nseparation between majority and minority classes. Empirically, we evaluate\nACTION++ on ACDC and LA benchmarks and show that it achieves state-of-the-art\nacross two semi-supervised settings. Theoretically, we analyze the performance\nof adaptive anatomical contrast and confirm its superiority in label\nefficiency.",
          "link": "http://arxiv.org/abs/2304.02689",
          "publishedOn": "2023-07-19T01:53:28.732Z",
          "wordCount": null,
          "title": "ACTION++: Improving Semi-supervised Medical Image Segmentation with Adaptive Anatomical Contrast. (arXiv:2304.02689v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1\">Zeyang Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_Michael_E/0/1/0/all/0/1\">Eli Ben-Michael</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imai_K/0/1/0/all/0/1\">Kosuke Imai</a>",
          "description": "Algorithmic and data-driven decisions and recommendations are commonly used\nin high-stakes decision-making settings such as criminal justice, medicine, and\npublic policy. We investigate whether it would have been possible to improve a\nsecurity assessment algorithm employed during the Vietnam War, using outcomes\nmeasured immediately after its introduction in late 1969. This empirical\napplication raises several methodological challenges that frequently arise in\nhigh-stakes algorithmic decision-making. First, before implementing a new\nalgorithm, it is essential to characterize and control the risk of yielding\nworse outcomes than the existing algorithm. Second, the existing algorithm is\ndeterministic, and learning a new algorithm requires transparent extrapolation.\nThird, the existing algorithm involves discrete decision tables that are common\nbut difficult to optimize over.\n\nTo address these challenges, we introduce the Average Conditional Risk\n(ACRisk), which first quantifies the risk that a new algorithmic policy leads\nto worse outcomes for subgroups of individual units and then averages this over\nthe distribution of subgroups. We also propose a Bayesian policy learning\nframework that maximizes the posterior expected value while controlling the\nposterior expected ACRisk. This framework separates the estimation of\nheterogeneous treatment effects from policy optimization, enabling flexible\nestimation of effects and optimization over complex policy classes. We\ncharacterize the resulting chance-constrained optimization problem as a\nconstrained linear programming problem. Our analysis shows that compared to the\nactual algorithm used during the Vietnam War, the learned algorithm assesses\nmost regions as more secure and emphasizes economic and political factors over\nmilitary factors.",
          "link": "http://arxiv.org/abs/2307.08840",
          "publishedOn": "2023-07-19T01:53:28.729Z",
          "wordCount": null,
          "title": "Bayesian Safe Policy Learning with Chance Constrained Optimization: Application to Military Security Assessment during the Vietnam War. (arXiv:2307.08840v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09342",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ulrich_Oltean_F/0/1/0/all/0/1\">Felix Ulrich-Oltean</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nightingale_P/0/1/0/all/0/1\">Peter Nightingale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walker_J/0/1/0/all/0/1\">James Alfred Walker</a>",
          "description": "Many constraint satisfaction and optimisation problems can be solved\neffectively by encoding them as instances of the Boolean Satisfiability problem\n(SAT). However, even the simplest types of constraints have many encodings in\nthe literature with widely varying performance, and the problem of selecting\nsuitable encodings for a given problem instance is not trivial. We explore the\nproblem of selecting encodings for pseudo-Boolean and linear constraints using\na supervised machine learning approach. We show that it is possible to select\nencodings effectively using a standard set of features for constraint problems;\nhowever we obtain better performance with a new set of features specifically\ndesigned for the pseudo-Boolean and linear constraints. In fact, we achieve\ngood results when selecting encodings for unseen problem classes. Our results\ncompare favourably to AutoFolio when using the same feature set. We discuss the\nrelative importance of instance features to the task of selecting the best\nencodings, and compare several variations of the machine learning method.",
          "link": "http://arxiv.org/abs/2307.09342",
          "publishedOn": "2023-07-19T01:53:28.698Z",
          "wordCount": null,
          "title": "Learning to Select SAT Encodings for Pseudo-Boolean and Linear Integer Constraints. (arXiv:2307.09342v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09320",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Randazzo_E/0/1/0/all/0/1\">Ettore Randazzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mordvintsev_A/0/1/0/all/0/1\">Alexander Mordvintsev</a>",
          "description": "We introduce Biomaker CA: a Biome Maker project using Cellular Automata (CA).\nIn Biomaker CA, morphogenesis is a first class citizen and small seeds need to\ngrow into plant-like organisms to survive in a nutrient starved environment and\neventually reproduce with variation so that a biome survives for long\ntimelines. We simulate complex biomes by means of CA rules in 2D grids and\nparallelize all of its computation on GPUs through the Python JAX framework. We\nshow how this project allows for several different kinds of environments and\nlaws of 'physics', alongside different model architectures and mutation\nstrategies. We further analyze some configurations to show how plant agents can\ngrow, survive, reproduce, and evolve, forming stable and unstable biomes. We\nthen demonstrate how one can meta-evolve models to survive in a harsh\nenvironment either through end-to-end meta-evolution or by a more surgical and\nefficient approach, called Petri dish meta-evolution. Finally, we show how to\nperform interactive evolution, where the user decides how to evolve a plant\nmodel interactively and then deploys it in a larger environment. We open source\nBiomaker CA at: https://tinyurl.com/2x8yu34s .",
          "link": "http://arxiv.org/abs/2307.09320",
          "publishedOn": "2023-07-19T01:53:28.662Z",
          "wordCount": null,
          "title": "Biomaker CA: a Biome Maker project using Cellular Automata. (arXiv:2307.09320v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09249",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yazheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Ledell Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qi Liu</a>",
          "description": "Recent advancements in Natural Language Processing (NLP) have witnessed the\ngroundbreaking impact of pretrained models, yielding impressive outcomes across\nvarious tasks. This study seeks to extend the power of pretraining\nmethodologies to tabular data, a domain traditionally overlooked, yet\ninherently challenging due to the plethora of table schemas intrinsic to\ndifferent tasks. The primary research questions underpinning this work revolve\naround the adaptation to heterogeneous table structures, the establishment of a\nuniversal pretraining protocol for tabular data, the generalizability and\ntransferability of learned knowledge across tasks, the adaptation to diverse\ndownstream applications, and the incorporation of incremental columns over\ntime. In response to these challenges, we introduce UniTabE, a pioneering\nmethod designed to process tables in a uniform manner, devoid of constraints\nimposed by specific table structures. UniTabE's core concept relies on\nrepresenting each basic table element with a module, termed TabUnit. This is\nsubsequently followed by a Transformer encoder to refine the representation.\nMoreover, our model is designed to facilitate pretraining and finetuning\nthrough the utilization of free-form prompts. In order to implement the\npretraining phase, we curated an expansive tabular dataset comprising\napproximately 13 billion samples, meticulously gathered from the Kaggle\nplatform. Rigorous experimental testing and analyses were performed under a\nmyriad of scenarios to validate the effectiveness of our methodology. The\nexperimental results demonstrate UniTabE's superior performance against several\nbaseline models across a multitude of benchmark datasets. This, therefore,\nunderscores UniTabE's potential to significantly enhance the semantic\nrepresentation of tabular data, thereby marking a significant stride in the\nfield of tabular data analysis.",
          "link": "http://arxiv.org/abs/2307.09249",
          "publishedOn": "2023-07-19T01:53:28.658Z",
          "wordCount": null,
          "title": "UniTabE: Pretraining a Unified Tabular Encoder for Heterogeneous Tabular Data. (arXiv:2307.09249v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08809",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cho_Y/0/1/0/all/0/1\">Yae Jee Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_G/0/1/0/all/0/1\">Gauri Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dimitriadis_D/0/1/0/all/0/1\">Dimitrios Dimitriadis</a>",
          "description": "Many existing FL methods assume clients with fully-labeled data, while in\nrealistic settings, clients have limited labels due to the expensive and\nlaborious process of labeling. Limited labeled local data of the clients often\nleads to their local model having poor generalization abilities to their larger\nunlabeled local data, such as having class-distribution mismatch with the\nunlabeled data. As a result, clients may instead look to benefit from the\nglobal model trained across clients to leverage their unlabeled data, but this\nalso becomes difficult due to data heterogeneity across clients. In our work,\nwe propose FedLabel where clients selectively choose the local or global model\nto pseudo-label their unlabeled data depending on which is more of an expert of\nthe data. We further utilize both the local and global models' knowledge via\nglobal-local consistency regularization which minimizes the divergence between\nthe two models' outputs when they have identical pseudo-labels for the\nunlabeled data. Unlike other semi-supervised FL baselines, our method does not\nrequire additional experts other than the local or global model, nor require\nadditional parameters to be communicated. We also do not assume any\nserver-labeled data or fully labeled clients. For both cross-device and\ncross-silo settings, we show that FedLabel outperforms other semi-supervised FL\nbaselines by $8$-$24\\%$, and even outperforms standard fully supervised FL\nbaselines ($100\\%$ labeled data) with only $5$-$20\\%$ of labeled data.",
          "link": "http://arxiv.org/abs/2307.08809",
          "publishedOn": "2023-07-19T01:53:28.563Z",
          "wordCount": null,
          "title": "Local or Global: Selective Knowledge Assimilation for Federated Learning with Limited Labels. (arXiv:2307.08809v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09388",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghoorchian_S/0/1/0/all/0/1\">Saeed Ghoorchian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kortukov_E/0/1/0/all/0/1\">Evgenii Kortukov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maghsudi_S/0/1/0/all/0/1\">Setareh Maghsudi</a>",
          "description": "Maximizing long-term rewards is the primary goal in sequential\ndecision-making problems. The majority of existing methods assume that side\ninformation is freely available, enabling the learning agent to observe all\nfeatures' states before making a decision. In real-world problems, however,\ncollecting beneficial information is often costly. That implies that, besides\nindividual arms' reward, learning the observations of the features' states is\nessential to improve the decision-making strategy. The problem is aggravated in\na non-stationary environment where reward and cost distributions undergo abrupt\nchanges over time. To address the aforementioned dual learning problem, we\nextend the contextual bandit setting and allow the agent to observe subsets of\nfeatures' states. The objective is to maximize the long-term average gain,\nwhich is the difference between the accumulated rewards and the paid costs on\naverage. Therefore, the agent faces a trade-off between minimizing the cost of\ninformation acquisition and possibly improving the decision-making process\nusing the obtained information. To this end, we develop an algorithm that\nguarantees a sublinear regret in time. Numerical results demonstrate the\nsuperiority of our proposed policy in a real-world scenario.",
          "link": "http://arxiv.org/abs/2307.09388",
          "publishedOn": "2023-07-19T01:53:28.516Z",
          "wordCount": null,
          "title": "Online Learning with Costly Features in Non-stationary Environments. (arXiv:2307.09388v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venkit_P/0/1/0/all/0/1\">Pranav Narayanan Venkit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinath_M/0/1/0/all/0/1\">Mukund Srinath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_S/0/1/0/all/0/1\">Shomir Wilson</a>",
          "description": "We analyze sentiment analysis and toxicity detection models to detect the\npresence of explicit bias against people with disability (PWD). We employ the\nbias identification framework of Perturbation Sensitivity Analysis to examine\nconversations related to PWD on social media platforms, specifically Twitter\nand Reddit, in order to gain insight into how disability bias is disseminated\nin real-world social settings. We then create the \\textit{Bias Identification\nTest in Sentiment} (BITS) corpus to quantify explicit disability bias in any\nsentiment analysis and toxicity detection models. Our study utilizes BITS to\nuncover significant biases in four open AIaaS (AI as a Service) sentiment\nanalysis tools, namely TextBlob, VADER, Google Cloud Natural Language API,\nDistilBERT and two toxicity detection models, namely two versions of\nToxic-BERT. Our findings indicate that all of these models exhibit\nstatistically significant explicit bias against PWD.",
          "link": "http://arxiv.org/abs/2307.09209",
          "publishedOn": "2023-07-19T01:53:28.513Z",
          "wordCount": null,
          "title": "Automated Ableism: An Exploration of Explicit Disability Biases in Sentiment and Toxicity Analysis Models. (arXiv:2307.09209v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nishikawa_N/0/1/0/all/0/1\">Naoki Nishikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ike_Y/0/1/0/all/0/1\">Yuichi Ike</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamanishi_K/0/1/0/all/0/1\">Kenji Yamanishi</a>",
          "description": "Machine learning for point clouds has been attracting much attention, with\nmany applications in various fields, such as shape recognition and material\nscience. To enhance the accuracy of such machine learning methods, it is known\nto be effective to incorporate global topological features, which are typically\nextracted by persistent homology. In the calculation of persistent homology for\na point cloud, we need to choose a filtration for the point clouds, an\nincreasing sequence of spaces. Because the performance of machine learning\nmethods combined with persistent homology is highly affected by the choice of a\nfiltration, we need to tune it depending on data and tasks. In this paper, we\npropose a framework that learns a filtration adaptively with the use of neural\nnetworks. In order to make the resulting persistent homology\nisometry-invariant, we develop a neural network architecture with such\ninvariance. Additionally, we theoretically show a finite-dimensional\napproximation result that justifies our architecture. Experimental results\ndemonstrated the efficacy of our framework in several classification tasks.",
          "link": "http://arxiv.org/abs/2307.09259",
          "publishedOn": "2023-07-19T01:53:28.510Z",
          "wordCount": null,
          "title": "Adaptive Topological Feature via Persistent Homology: Filtration Learning for Point Clouds. (arXiv:2307.09259v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08945",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+De_Arteaga_M/0/1/0/all/0/1\">Maria De-Arteaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saar_Tsechansky_M/0/1/0/all/0/1\">Maytal Saar-Tsechansky</a>",
          "description": "Growing concerns regarding algorithmic fairness have led to a surge in\nmethodologies to mitigate algorithmic bias. However, such methodologies largely\nassume that observed labels in training data are correct. This is problematic\nbecause bias in labels is pervasive across important domains, including\nhealthcare, hiring, and content moderation. In particular, human-generated\nlabels are prone to encoding societal biases. While the presence of labeling\nbias has been discussed conceptually, there is a lack of methodologies to\naddress this problem. We propose a pruning method -- Decoupled Confident\nLearning (DeCoLe) -- specifically designed to mitigate label bias. After\nillustrating its performance on a synthetic dataset, we apply DeCoLe in the\ncontext of hate speech detection, where label bias has been recognized as an\nimportant challenge, and show that it successfully identifies biased labels and\noutperforms competing approaches.",
          "link": "http://arxiv.org/abs/2307.08945",
          "publishedOn": "2023-07-19T01:53:28.509Z",
          "wordCount": null,
          "title": "Mitigating Label Bias via Decoupled Confident Learning. (arXiv:2307.08945v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08847",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Elhussein_A/0/1/0/all/0/1\">Ahmed Elhussein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gursoy_G/0/1/0/all/0/1\">Gamze Gursoy</a>",
          "description": "Federated Learning (FL) is a machine learning framework that enables multiple\norganizations to train a model without sharing their data with a central\nserver. However, it experiences significant performance degradation if the data\nis non-identically independently distributed (non-IID). This is a problem in\nmedical settings, where variations in the patient population contribute\nsignificantly to distribution differences across hospitals. Personalized FL\naddresses this issue by accounting for site-specific distribution differences.\nClustered FL, a Personalized FL variant, was used to address this problem by\nclustering patients into groups across hospitals and training separate models\non each group. However, privacy concerns remained as a challenge as the\nclustering process requires exchange of patient-level information. This was\npreviously solved by forming clusters using aggregated data, which led to\ninaccurate groups and performance degradation. In this study, we propose\nPrivacy-preserving Community-Based Federated machine Learning (PCBFL), a novel\nClustered FL framework that can cluster patients using patient-level data while\nprotecting privacy. PCBFL uses Secure Multiparty Computation, a cryptographic\ntechnique, to securely calculate patient-level similarity scores across\nhospitals. We then evaluate PCBFL by training a federated mortality prediction\nmodel using 20 sites from the eICU dataset. We compare the performance gain\nfrom PCBFL against traditional and existing Clustered FL frameworks. Our\nresults show that PCBFL successfully forms clinically meaningful cohorts of\nlow, medium, and high-risk patients. PCBFL outperforms traditional and existing\nClustered FL frameworks with an average AUC improvement of 4.3% and AUPRC\nimprovement of 7.8%.",
          "link": "http://arxiv.org/abs/2307.08847",
          "publishedOn": "2023-07-19T01:53:28.508Z",
          "wordCount": null,
          "title": "Privacy-preserving patient clustering for personalized federated learning. (arXiv:2307.08847v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09212",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Safran_I/0/1/0/all/0/1\">Itay Safran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reichman_D/0/1/0/all/0/1\">Daniel Reichman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valiant_P/0/1/0/all/0/1\">Paul Valiant</a>",
          "description": "We study the size of a neural network needed to approximate the maximum\nfunction over $d$ inputs, in the most basic setting of approximating with\nrespect to the $L_2$ norm, for continuous distributions, for a network that\nuses ReLU activations. We provide new lower and upper bounds on the width\nrequired for approximation across various depths. Our results establish new\ndepth separations between depth 2 and 3, and depth 3 and 5 networks, as well as\nproviding a depth $\\mathcal{O}(\\log(\\log(d)))$ and width $\\mathcal{O}(d)$\nconstruction which approximates the maximum function, significantly improving\nupon the depth requirements of the best previously known bounds for networks\nwith linearly-bounded width. Our depth separation results are facilitated by a\nnew lower bound for depth 2 networks approximating the maximum function over\nthe uniform distribution, assuming an exponential upper bound on the size of\nthe weights. Furthermore, we are able to use this depth 2 lower bound to\nprovide tight bounds on the number of neurons needed to approximate the maximum\nby a depth 3 network. Our lower bounds are of potentially broad interest as\nthey apply to the widely studied and used \\emph{max} function, in contrast to\nmany previous results that base their bounds on specially constructed or\npathological functions and distributions.",
          "link": "http://arxiv.org/abs/2307.09212",
          "publishedOn": "2023-07-19T01:53:28.506Z",
          "wordCount": null,
          "title": "How Many Neurons Does it Take to Approximate the Maximum?. (arXiv:2307.09212v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.07528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zeyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yi Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Hui Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yiran Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramanian_R/0/1/0/all/0/1\">Rishab Balasubramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qingyun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huazheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mengdi Wang</a>",
          "description": "Off-policy Learning to Rank (LTR) aims to optimize a ranker from data\ncollected by a deployed logging policy. However, existing off-policy learning\nto rank methods often make strong assumptions about how users generate the\nclick data, i.e., the click model, and hence need to tailor their methods\nspecifically under different click models. In this paper, we unified the\nranking process under general stochastic click models as a Markov Decision\nProcess (MDP), and the optimal ranking could be learned with offline\nreinforcement learning (RL) directly. Building upon this, we leverage offline\nRL techniques for off-policy LTR and propose the Click Model-Agnostic Unified\nOff-policy Learning to Rank (CUOLR) method, which could be easily applied to a\nwide range of click models. Through a dedicated formulation of the MDP, we show\nthat offline RL algorithms can adapt to various click models without complex\ndebiasing techniques and prior knowledge of the model. Results on various\nlarge-scale datasets demonstrate that CUOLR consistently outperforms the\nstate-of-the-art off-policy learning to rank algorithms while maintaining\nconsistency and robustness under different click models.",
          "link": "http://arxiv.org/abs/2306.07528",
          "publishedOn": "2023-07-19T01:53:28.505Z",
          "wordCount": null,
          "title": "Unified Off-Policy Learning to Rank: a Reinforcement Learning Perspective. (arXiv:2306.07528v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09357",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gallo_M/0/1/0/all/0/1\">Manuel Le Gallo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lammie_C/0/1/0/all/0/1\">Corey Lammie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buechel_J/0/1/0/all/0/1\">Julian Buechel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carta_F/0/1/0/all/0/1\">Fabio Carta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fagbohungbe_O/0/1/0/all/0/1\">Omobayode Fagbohungbe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mackin_C/0/1/0/all/0/1\">Charles Mackin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsai_H/0/1/0/all/0/1\">Hsinyu Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayanan_V/0/1/0/all/0/1\">Vijay Narayanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sebastian_A/0/1/0/all/0/1\">Abu Sebastian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maghraoui_K/0/1/0/all/0/1\">Kaoutar El Maghraoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rasch_M/0/1/0/all/0/1\">Malte J. Rasch</a>",
          "description": "Analog In-Memory Computing (AIMC) is a promising approach to reduce the\nlatency and energy consumption of Deep Neural Network (DNN) inference and\ntraining. However, the noisy and non-linear device characteristics, and the\nnon-ideal peripheral circuitry in AIMC chips, require adapting DNNs to be\ndeployed on such hardware to achieve equivalent accuracy to digital computing.\nIn this tutorial, we provide a deep dive into how such adaptations can be\nachieved and evaluated using the recently released IBM Analog Hardware\nAcceleration Kit (AIHWKit), freely available at https://github.com/IBM/aihwkit.\nThe AIHWKit is a Python library that simulates inference and training of DNNs\nusing AIMC. We present an in-depth description of the AIHWKit design,\nfunctionality, and best practices to properly perform inference and training.\nWe also present an overview of the Analog AI Cloud Composer, that provides the\nbenefits of using the AIHWKit simulation platform in a fully managed cloud\nsetting. Finally, we show examples on how users can expand and customize\nAIHWKit for their own needs. This tutorial is accompanied by comprehensive\nJupyter Notebook code examples that can be run using AIHWKit, which can be\ndownloaded from https://github.com/IBM/aihwkit/tree/master/notebooks/tutorial.",
          "link": "http://arxiv.org/abs/2307.09357",
          "publishedOn": "2023-07-19T01:53:28.503Z",
          "wordCount": null,
          "title": "Using the IBM Analog In-Memory Hardware Acceleration Kit for Neural Network Training and Inference. (arXiv:2307.09357v1 [cs.ET])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08813",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_G/0/1/0/all/0/1\">Gilchan Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_B/0/1/0/all/0/1\">Byung-Jun Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1\">Xihaier Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopez_Marrero_V/0/1/0/all/0/1\">Vanessa L&#xf3;pez-Marrero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnstone_P/0/1/0/all/0/1\">Patrick Johnstone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_S/0/1/0/all/0/1\">Shinjae Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alexander_F/0/1/0/all/0/1\">Francis J. Alexander</a>",
          "description": "Understanding protein interactions and pathway knowledge is crucial for\nunraveling the complexities of living systems and investigating the underlying\nmechanisms of biological functions and complex diseases. While existing\ndatabases provide curated biological data from literature and other sources,\nthey are often incomplete and their maintenance is labor-intensive,\nnecessitating alternative approaches. In this study, we propose to harness the\ncapabilities of large language models to address these issues by automatically\nextracting such knowledge from the relevant scientific literature. Toward this\ngoal, in this work, we investigate the effectiveness of different large\nlanguage models in tasks that involve recognizing protein interactions,\npathways, and gene regulatory relations. We thoroughly evaluate the performance\nof various models, highlight the significant findings, and discuss both the\nfuture opportunities and the remaining challenges associated with this\napproach. The code and data are available at:\nhttps://github.com/boxorange/BioIE-LLM",
          "link": "http://arxiv.org/abs/2307.08813",
          "publishedOn": "2023-07-19T01:53:28.473Z",
          "wordCount": null,
          "title": "Comparative Performance Evaluation of Large Language Models for Extracting Molecular Interactions and Pathway Knowledge. (arXiv:2307.08813v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09478",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cesa_Bianchi_N/0/1/0/all/0/1\">Nicol&#xf2; Cesa-Bianchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cesari_T/0/1/0/all/0/1\">Tommaso Cesari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colomboni_R/0/1/0/all/0/1\">Roberto Colomboni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fusco_F/0/1/0/all/0/1\">Federico Fusco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leonardi_S/0/1/0/all/0/1\">Stefano Leonardi</a>",
          "description": "We study the problem of regret minimization for a single bidder in a sequence\nof first-price auctions where the bidder knows the item's value only if the\nauction is won. Our main contribution is a complete characterization, up to\nlogarithmic factors, of the minimax regret in terms of the auction's\ntransparency, which regulates the amount of information on competing bids\ndisclosed by the auctioneer at the end of each auction. Our results hold under\ndifferent assumptions (stochastic, adversarial, and their smoothed variants) on\nthe environment generating the bidder's valuations and competing bids. These\nminimax rates reveal how the interplay between transparency and the nature of\nthe environment affects how fast one can learn to bid optimally in first-price\nauctions.",
          "link": "http://arxiv.org/abs/2307.09478",
          "publishedOn": "2023-07-19T01:53:28.472Z",
          "wordCount": null,
          "title": "The Role of Transparency in Repeated First-Price Auctions with Unknown Valuations. (arXiv:2307.09478v1 [cs.GT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08810",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Edwards_S/0/1/0/all/0/1\">Samuel J. Edwards</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_M/0/1/0/all/0/1\">Michael Levine</a>",
          "description": "This paper will present a multi-fidelity, data-adaptive approach with a Long\nShort-Term Memory (LSTM) neural network to estimate ship response statistics in\nbimodal, bidirectional seas. The study will employ a fast low-fidelity,\nvolume-based tool SimpleCode and a higher-fidelity tool known as the Large\nAmplitude Motion Program (LAMP). SimpleCode and LAMP data were generated by\ncommon bi-modal, bi-directional sea conditions in the North Atlantic as\ntraining data. After training an LSTM network with LAMP ship motion response\ndata, a sample route was traversed and randomly sampled historical weather was\ninput into SimpleCode and the LSTM network, and compared against the higher\nfidelity results.",
          "link": "http://arxiv.org/abs/2307.08810",
          "publishedOn": "2023-07-19T01:53:28.469Z",
          "wordCount": null,
          "title": "Operator Guidance Informed by AI-Augmented Simulations. (arXiv:2307.08810v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08807",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ilie_Ablachim_D/0/1/0/all/0/1\">Denis C. Ilie-Ablachim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dumitrescu_B/0/1/0/all/0/1\">Bogdan Dumitrescu</a>",
          "description": "In this paper we present new methods of anomaly detection based on Dictionary\nLearning (DL) and Kernel Dictionary Learning (KDL). The main contribution\nconsists in the adaption of known DL and KDL algorithms in the form of\nunsupervised methods, used for outlier detection. We propose a reduced kernel\nversion (RKDL), which is useful for problems with large data sets, due to the\nlarge kernel matrix. We also improve the DL and RKDL methods by the use of a\nrandom selection of signals, which aims to eliminate the outliers from the\ntraining procedure. All our algorithms are introduced in an anomaly detection\ntoolbox and are compared to standard benchmark results.",
          "link": "http://arxiv.org/abs/2307.08807",
          "publishedOn": "2023-07-19T01:53:28.467Z",
          "wordCount": null,
          "title": "Anomaly Detection with Selective Dictionary Learning. (arXiv:2307.08807v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhe Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_R/0/1/0/all/0/1\">Ruijie Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aeron_S/0/1/0/all/0/1\">Shuchin Aeron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hughes_M/0/1/0/all/0/1\">Michael C. Hughes</a>",
          "description": "For many applications of classifiers to medical images, a trustworthy label\nfor each image can be difficult or expensive to obtain. In contrast, images\nwithout labels are more readily available. Two major research directions both\npromise that additional unlabeled data can improve classifier performance:\nself-supervised learning pretrains useful representations on unlabeled data\nonly, then fine-tunes a classifier on these representations via the labeled\nset; semi-supervised learning directly trains a classifier on labeled and\nunlabeled data simultaneously. Recent methods from both directions have claimed\nsignificant gains on non-medical tasks, but do not systematically assess\nmedical images and mostly compare only to methods in the same direction. This\nstudy contributes a carefully-designed benchmark to help answer a\npractitioner's key question: given a small labeled dataset and a limited budget\nof hours to spend on training, what gains from additional unlabeled images are\npossible and which methods best achieve them? Unlike previous benchmarks, ours\nuses realistic-sized validation sets to select hyperparameters, assesses\nruntime-performance tradeoffs, and bridges two research fields. By comparing 6\nsemi-supervised methods and 5 self-supervised methods to strong labeled-only\nbaselines on 3 medical datasets with 30-1000 labels per class, we offer\ninsights to resource-constrained, results-focused practitioners: MixMatch,\nSimCLR, and BYOL represent strong choices that were not surpassed by more\nrecent methods. After much effort selecting hyperparameters on one dataset, we\npublish settings that enable strong methods to perform well on new medical\ntasks within a few hours, with further search over dozens of hours delivering\nmodest additional gains.",
          "link": "http://arxiv.org/abs/2307.08919",
          "publishedOn": "2023-07-19T01:53:28.466Z",
          "wordCount": null,
          "title": "Accuracy versus time frontiers of semi-supervised and self-supervised learning on medical images. (arXiv:2307.08919v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08893",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yun_T/0/1/0/all/0/1\">Taedong Yun</a>",
          "description": "High-dimensional clinical data have become invaluable resources for genetic\nstudies, due to their accessibility in biobank-scale datasets and the\ndevelopment of high performance modeling techniques especially using deep\nlearning. Recent work has shown that low dimensional embeddings of these\nclinical data learned by variational autoencoders (VAE) can be used for\ngenome-wide association studies and polygenic risk prediction. In this work, we\nconsider multiple unsupervised learning methods for learning disentangled\nrepresentations, namely autoencoders, VAE, beta-VAE, and FactorVAE, in the\ncontext of genetic association studies. Using spirograms from UK Biobank as a\nrunning example, we observed improvements in the number of genome-wide\nsignificant loci, heritability, and performance of polygenic risk scores for\nasthma and chronic obstructive pulmonary disease by using FactorVAE or\nbeta-VAE, compared to standard VAE or non-variational autoencoders. FactorVAEs\nperformed effectively across multiple values of the regularization\nhyperparameter, while beta-VAEs were much more sensitive to the hyperparameter\nvalues.",
          "link": "http://arxiv.org/abs/2307.08893",
          "publishedOn": "2023-07-19T01:53:28.465Z",
          "wordCount": null,
          "title": "Evaluating unsupervised disentangled representation learning for genomic discovery and disease risk prediction. (arXiv:2307.08893v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.13556",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haghifam_M/0/1/0/all/0/1\">Mahdi Haghifam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_Galvez_B/0/1/0/all/0/1\">Borja Rodr&#xed;guez-G&#xe1;lvez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thobaben_R/0/1/0/all/0/1\">Ragnar Thobaben</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skoglund_M/0/1/0/all/0/1\">Mikael Skoglund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_D/0/1/0/all/0/1\">Daniel M. Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dziugaite_G/0/1/0/all/0/1\">Gintare Karolina Dziugaite</a>",
          "description": "To date, no \"information-theoretic\" frameworks for reasoning about\ngeneralization error have been shown to establish minimax rates for gradient\ndescent in the setting of stochastic convex optimization. In this work, we\nconsider the prospect of establishing such rates via several existing\ninformation-theoretic frameworks: input-output mutual information bounds,\nconditional mutual information bounds and variants, PAC-Bayes bounds, and\nrecent conditional variants thereof. We prove that none of these bounds are\nable to establish minimax rates. We then consider a common tactic employed in\nstudying gradient methods, whereby the final iterate is corrupted by Gaussian\nnoise, producing a noisy \"surrogate\" algorithm. We prove that minimax rates\ncannot be established via the analysis of such surrogates. Our results suggest\nthat new ideas are required to analyze gradient descent using\ninformation-theoretic techniques.",
          "link": "http://arxiv.org/abs/2212.13556",
          "publishedOn": "2023-07-19T01:53:28.464Z",
          "wordCount": null,
          "title": "Limitations of Information-Theoretic Generalization Bounds for Gradient Descent Methods in Stochastic Convex Optimization. (arXiv:2212.13556v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09206",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guttikonda_S/0/1/0/all/0/1\">Suresh Guttikonda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Achterhold_J/0/1/0/all/0/1\">Jan Achterhold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haolong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boedecker_J/0/1/0/all/0/1\">Joschka Boedecker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stueckler_J/0/1/0/all/0/1\">Joerg Stueckler</a>",
          "description": "In autonomous navigation settings, several quantities can be subject to\nvariations. Terrain properties such as friction coefficients may vary over time\ndepending on the location of the robot. Also, the dynamics of the robot may\nchange due to, e.g., different payloads, changing the system's mass, or wear\nand tear, changing actuator gains or joint friction. An autonomous agent should\nthus be able to adapt to such variations. In this paper, we develop a novel\nprobabilistic, terrain- and robot-aware forward dynamics model, termed TRADYN,\nwhich is able to adapt to the above-mentioned variations. It builds on recent\nadvances in meta-learning forward dynamics models based on Neural Processes. We\nevaluate our method in a simulated 2D navigation setting with a unicycle-like\nrobot and different terrain layouts with spatially varying friction\ncoefficients. In our experiments, the proposed model exhibits lower prediction\nerror for the task of long-horizon trajectory prediction, compared to\nnon-adaptive ablation models. We also evaluate our model on the downstream task\nof navigation planning, which demonstrates improved performance in planning\ncontrol-efficient paths by taking robot and terrain properties into account.",
          "link": "http://arxiv.org/abs/2307.09206",
          "publishedOn": "2023-07-19T01:53:28.463Z",
          "wordCount": null,
          "title": "Context-Conditional Navigation with a Learning-Based Terrain- and Robot-Aware Dynamics Model. (arXiv:2307.09206v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.15548",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hahne_C/0/1/0/all/0/1\">Christopher Hahne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sznitman_R/0/1/0/all/0/1\">Raphael Sznitman</a>",
          "description": "Contrast-Enhanced Ultra-Sound (CEUS) has become a viable method for\nnon-invasive, dynamic visualization in medical diagnostics, yet Ultrasound\nLocalization Microscopy (ULM) has enabled a revolutionary breakthrough by\noffering ten times higher resolution. To date, Delay-And-Sum (DAS) beamformers\nare used to render ULM frames, ultimately determining the image resolution\ncapability. To take full advantage of ULM, this study questions whether\nbeamforming is the most effective processing step for ULM, suggesting an\nalternative approach that relies solely on Time-Difference-of-Arrival (TDoA)\ninformation. To this end, a novel geometric framework for micro bubble\nlocalization via ellipse intersections is proposed to overcome existing\nbeamforming limitations. We present a benchmark comparison based on a public\ndataset for which our geometric ULM outperforms existing baseline methods in\nterms of accuracy and robustness while only utilizing a portion of the\navailable transducer data.",
          "link": "http://arxiv.org/abs/2306.15548",
          "publishedOn": "2023-07-19T01:53:28.463Z",
          "wordCount": null,
          "title": "Geometric Ultrasound Localization Microscopy. (arXiv:2306.15548v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.00270",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mengdi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xufeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jae Hee Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_C/0/1/0/all/0/1\">Cornelius Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wermter_S/0/1/0/all/0/1\">Stefan Wermter</a>",
          "description": "We study a class of reinforcement learning problems where the reward signals\nfor policy learning are generated by a discriminator that is dependent on and\njointly optimized with the policy. This interdependence between the policy and\nthe discriminator leads to an unstable learning process because reward signals\nfrom an immature discriminator are noisy and impede policy learning, and\nconversely, an under-optimized policy impedes discriminator learning. We call\nthis learning setting \\textit{Internally Rewarded Reinforcement Learning}\n(IRRL) as the reward is not provided directly by the environment but\n\\textit{internally} by the discriminator. In this paper, we formally formulate\nIRRL and present a class of problems that belong to IRRL. We theoretically\nderive and empirically analyze the effect of the reward function in IRRL and\nbased on these analyses propose the clipped linear reward function.\nExperimental results show that the proposed reward function can consistently\nstabilize the training process by reducing the impact of reward noise, which\nleads to faster convergence and higher performance compared with baselines in\ndiverse tasks.",
          "link": "http://arxiv.org/abs/2302.00270",
          "publishedOn": "2023-07-19T01:53:28.462Z",
          "wordCount": null,
          "title": "Internally Rewarded Reinforcement Learning. (arXiv:2302.00270v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.06825",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kong_F/0/1/0/all/0/1\">Fang Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Canzhe Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuai Li</a>",
          "description": "The linear bandit problem has been studied for many years in both stochastic\nand adversarial settings. Designing an algorithm that can optimize the\nenvironment without knowing the loss type attracts lots of interest.\n\\citet{LeeLWZ021} propose an algorithm that actively detects the loss type and\nthen switches between different algorithms specially designed for specific\nsettings. However, such an approach requires meticulous designs to perform well\nin all environments. Follow-the-regularized-leader (FTRL) is another type of\npopular algorithm that can adapt to different environments. This algorithm is\nof simple design and the regret bounds are shown to be optimal in traditional\nmulti-armed bandit problems compared with the detect-switch type. Designing an\nFTRL-type algorithm for linear bandits is an important question that has been\nopen for a long time. In this paper, we prove that the FTRL algorithm with a\nnegative entropy regularizer can achieve the best-of-three-world results for\nthe linear bandit problem. Our regret bounds achieve the same or nearly the\nsame order as the previous detect-switch type algorithm but with a much simpler\nalgorithmic design.",
          "link": "http://arxiv.org/abs/2303.06825",
          "publishedOn": "2023-07-19T01:53:28.461Z",
          "wordCount": null,
          "title": "Best-of-three-worlds Analysis for Linear Bandits with Follow-the-regularized-leader Algorithm. (arXiv:2303.06825v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08753",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Van_Lane_P/0/1/0/all/0/1\">Phil Van-Lane</a> (1), <a href=\"http://arxiv.org/find/astro-ph/1/au:+Speagle_J/0/1/0/all/0/1\">Joshua S. Speagle</a> (2 and 1 and 3 and 4), <a href=\"http://arxiv.org/find/astro-ph/1/au:+Douglas_S/0/1/0/all/0/1\">Stephanie Douglas</a> (5) ((1) Department of Astronomy &amp; Astrophysics, University of Toronto, Canada, (2) Department of Statistical Sciences, University of Toronto, Canada, (3) Dunlap Institute of Astronomy &amp; Astrophysics, University of Toronto, Canada, (4) Data Sciences Institute, University of Toronto, Canada, (5) Department of Physics, Lafayette College, United States)",
          "description": "Stellar ages are critical building blocks of evolutionary models, but\nchallenging to measure for low mass main sequence stars. An unexplored solution\nin this regime is the application of probabilistic machine learning methods to\ngyrochronology, a stellar dating technique that is uniquely well suited for\nthese stars. While accurate analytical gyrochronological models have proven\nchallenging to develop, here we apply conditional normalizing flows to\nphotometric data from open star clusters, and demonstrate that a data-driven\napproach can constrain gyrochronological ages with a precision comparable to\nother standard techniques. We evaluate the flow results in the context of a\nBayesian framework, and show that our inferred ages recover literature values\nwell. This work demonstrates the potential of a probabilistic data-driven\nsolution to widen the applicability of gyrochronological stellar dating.",
          "link": "http://arxiv.org/abs/2307.08753",
          "publishedOn": "2023-07-19T01:53:28.459Z",
          "wordCount": null,
          "title": "A Novel Application of Conditional Normalizing Flows: Stellar Age Inference with Gyrochronology. (arXiv:2307.08753v1 [astro-ph.SR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.06534",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hanchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tarpey_T/0/1/0/all/0/1\">Thaddeus Tarpey</a>",
          "description": "This paper introduces a novel self-consistency clustering algorithm\n($K$-Tensors) designed for {partitioning a distribution of}\npositive-semidefinite matrices based on their eigenstructures. As positive\nsemi-definite matrices can be represented as ellipsoids in $\\mathbb R^p$, $p\n\\ge 2$, it is critical to maintain their structural information to perform\neffective clustering. However, traditional clustering algorithms {applied to\nmatrices} often {involve vectorization of} the matrices, resulting in a loss of\nessential structural information. To address this issue, we propose a distance\nmetric {for clustering} that is specifically based on the structural\ninformation of positive semi-definite matrices. This distance metric enables\nthe clustering algorithm to consider the differences between positive\nsemi-definite matrices and their projections onto {a} common space spanned by\n\\thadJulyTen{orthonormal vectors defined from a set of} positive semi-definite\nmatrices. This innovative approach to clustering positive semi-definite\nmatrices has broad applications in several domains including financial and\nbiomedical research, such as analyzing functional connectivity data. By\nmaintaining the structural information of positive semi-definite matrices, our\nproposed algorithm promises to cluster the positive semi-definite matrices in a\nmore meaningful way, thereby facilitating deeper insights into the underlying\ndata in various applications.",
          "link": "http://arxiv.org/abs/2306.06534",
          "publishedOn": "2023-07-19T01:53:28.458Z",
          "wordCount": null,
          "title": "K-Tensors: Clustering Positive Semi-Definite Matrices. (arXiv:2306.06534v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09469",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Bouri_I/0/1/0/all/0/1\">Ioanna Bouri</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Franssila_F/0/1/0/all/0/1\">Fanni Franssila</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Alho_M/0/1/0/all/0/1\">Markku Alho</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Cozzani_G/0/1/0/all/0/1\">Giulia Cozzani</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zaitsev_I/0/1/0/all/0/1\">Ivan Zaitsev</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Palmroth_M/0/1/0/all/0/1\">Minna Palmroth</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Roos_T/0/1/0/all/0/1\">Teemu Roos</a>",
          "description": "Topological analysis of the magnetic field in simulated plasmas allows the\nstudy of various physical phenomena in a wide range of settings. One such\napplication is magnetic reconnection, a phenomenon related to the dynamics of\nthe magnetic field topology, which is difficult to detect and characterize in\nthree dimensions. We propose a scalable pipeline for topological data analysis\nand spatiotemporal graph representation of three-dimensional magnetic vector\nfields. We demonstrate our methods on simulations of the Earth's magnetosphere\nproduced by Vlasiator, a supercomputer-scale Vlasov theory-based simulation for\nnear-Earth space. The purpose of this work is to challenge the machine learning\ncommunity to explore graph-based machine learning approaches to address a\nlargely open scientific problem with wide-ranging potential impact.",
          "link": "http://arxiv.org/abs/2307.09469",
          "publishedOn": "2023-07-19T01:53:28.455Z",
          "wordCount": null,
          "title": "Graph Representation of the Magnetic Field Topology in High-Fidelity Plasma Simulations for Machine Learning Applications. (arXiv:2307.09469v1 [physics.plasm-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.04422",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhang_L/0/1/0/all/0/1\">Linglin Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Brown_Mulry_B/0/1/0/all/0/1\">Beatrice Brown-Mulry</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nalla_V/0/1/0/all/0/1\">Vineela Nalla</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hwang_I/0/1/0/all/0/1\">InChan Hwang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gichoya_J/0/1/0/all/0/1\">Judy Wawira Gichoya</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gastounioti_A/0/1/0/all/0/1\">Aimilia Gastounioti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Banerjee_I/0/1/0/all/0/1\">Imon Banerjee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Seyyed_Kalantari_L/0/1/0/all/0/1\">Laleh Seyyed-Kalantari</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Woo_M/0/1/0/all/0/1\">MinJae Woo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Trivedi_H/0/1/0/all/0/1\">Hari Trivedi</a>",
          "description": "Even though deep learning models for abnormality classification can perform\nwell in screening mammography, the demographic and imaging characteristics\nassociated with increased risk of failure for abnormality classification in\nscreening mammograms remain unclear. This retrospective study used data from\nthe Emory BrEast Imaging Dataset (EMBED) including mammograms from 115,931\npatients imaged at Emory University Healthcare between 2013 to 2020. Clinical\nand imaging data includes Breast Imaging Reporting and Data System (BI-RADS)\nassessment, region of interest coordinates for abnormalities, imaging features,\npathologic outcomes, and patient demographics. Deep learning models including\nInceptionV3, VGG16, ResNet50V2, and ResNet152V2 were developed to distinguish\nbetween patches of abnormal tissue and randomly selected patches of normal\ntissue from the screening mammograms. The distributions of the training,\nvalidation and test sets are 29,144 (55.6%) patches of 10,678 (54.2%) patients,\n9,910 (18.9%) patches of 3,609 (18.3%) patients, and 13,390 (25.5%) patches of\n5,404 (27.5%) patients. We assessed model performance overall and within\nsubgroups defined by age, race, pathologic outcome, and imaging characteristics\nto evaluate reasons for misclassifications. On the test set, a ResNet152V2\nmodel trained to classify normal versus abnormal tissue patches achieved an\naccuracy of 92.6% (95%CI=92.0-93.2%), and area under the receiver operative\ncharacteristics curve 0.975 (95%CI=0.972-0.978). Imaging characteristics\nassociated with higher misclassifications of images include higher tissue\ndensities (risk ratio [RR]=1.649; p=.010, BI-RADS density C and RR=2.026;\np=.003, BI-RADS density D), and presence of architectural distortion (RR=1.026;\np<.001). Small but statistically significant differences in performance were\nobserved by age, race, pathologic outcome, and other imaging features (p<.001).",
          "link": "http://arxiv.org/abs/2305.04422",
          "publishedOn": "2023-07-19T01:53:28.452Z",
          "wordCount": null,
          "title": "Performance Gaps of Artificial Intelligence Models Screening Mammography -- Towards Fair and Interpretable Models. (arXiv:2305.04422v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09067",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_F/0/1/0/all/0/1\">Fangyijie Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Silvestre_G/0/1/0/all/0/1\">Gu&#xe9;nol&#xe9; Silvestre</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Curran_K/0/1/0/all/0/1\">Kathleen M. Curran</a>",
          "description": "Fetal head segmentation is a crucial step in measuring the fetal head\ncircumference (HC) during gestation, an important biometric in obstetrics for\nmonitoring fetal growth. However, manual biometry generation is time-consuming\nand results in inconsistent accuracy. To address this issue, convolutional\nneural network (CNN) models have been utilized to improve the efficiency of\nmedical biometry. But training a CNN network from scratch is a challenging\ntask, we proposed a Transfer Learning (TL) method. Our approach involves\nfine-tuning (FT) a U-Net network with a lightweight MobileNet as the encoder to\nperform segmentation on a set of fetal head ultrasound (US) images with limited\neffort. This method addresses the challenges associated with training a CNN\nnetwork from scratch. It suggests that our proposed FT strategy yields\nsegmentation performance that is comparable when trained with a reduced number\nof parameters by 85.8%. And our proposed FT strategy outperforms other\nstrategies with smaller trainable parameter sizes below 4.4 million. Thus, we\ncontend that it can serve as a dependable FT approach for reducing the size of\nmodels in medical image analysis. Our key findings highlight the importance of\nthe balance between model performance and size in developing Artificial\nIntelligence (AI) applications by TL methods. Code is available at\nhttps://github.com/13204942/FT_Methods_for_Fetal_Head_Segmentation.",
          "link": "http://arxiv.org/abs/2307.09067",
          "publishedOn": "2023-07-19T01:53:28.448Z",
          "wordCount": null,
          "title": "Evaluate Fine-tuning Strategies for Fetal Head Ultrasound Image Segmentation with U-Net. (arXiv:2307.09067v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08859",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vakil_N/0/1/0/all/0/1\">Nidhi Vakil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amiri_H/0/1/0/all/0/1\">Hadi Amiri</a>",
          "description": "A curriculum is a planned sequence of learning materials and an effective one\ncan make learning efficient and effective for both humans and machines. Recent\nstudies developed effective data-driven curriculum learning approaches for\ntraining graph neural networks in language applications. However, existing\ncurriculum learning approaches often employ a single criterion of difficulty in\ntheir training paradigms. In this paper, we propose a new perspective on\ncurriculum learning by introducing a novel approach that builds on graph\ncomplexity formalisms (as difficulty criteria) and model competence during\ntraining. The model consists of a scheduling scheme which derives effective\ncurricula by accounting for different views of sample difficulty and model\ncompetence during training. The proposed solution advances existing research in\ncurriculum learning for graph neural networks with the ability to incorporate a\nfine-grained spectrum of graph difficulty criteria in their training paradigms.\nExperimental results on real-world link prediction and node classification\ntasks illustrate the effectiveness of the proposed approach.",
          "link": "http://arxiv.org/abs/2307.08859",
          "publishedOn": "2023-07-19T01:53:28.407Z",
          "wordCount": null,
          "title": "Curriculum Learning for Graph Neural Networks: A Multiview Competence-based Approach. (arXiv:2307.08859v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09142",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Kiyani_E/0/1/0/all/0/1\">Elham Kiyani</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kooshkbaghi_M/0/1/0/all/0/1\">Mahdi Kooshkbaghi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Shukla_K/0/1/0/all/0/1\">Khemraj Shukla</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Koneru_R/0/1/0/all/0/1\">Rahul Babu Koneru</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Li_Z/0/1/0/all/0/1\">Zhen Li</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bravo_L/0/1/0/all/0/1\">Luis Bravo</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ghoshal_A/0/1/0/all/0/1\">Anindya Ghoshal</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Karniadakis_G/0/1/0/all/0/1\">George Em Karniadakis</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Karttunen_M/0/1/0/all/0/1\">Mikko Karttunen</a>",
          "description": "The molten sand, a mixture of calcia, magnesia, alumina, and silicate, known\nas CMAS, is characterized by its high viscosity, density, and surface tension.\nThe unique properties of CMAS make it a challenging material to deal with in\nhigh-temperature applications, requiring innovative solutions and materials to\nprevent its buildup and damage to critical equipment. Here, we use multiphase\nmany-body dissipative particle dynamics (mDPD) simulations to study the wetting\ndynamics of highly viscous molten CMAS droplets. The simulations are performed\nin three dimensions, with varying initial droplet sizes and equilibrium contact\nangles. We propose a coarse parametric ordinary differential equation (ODE)\nthat captures the spreading radius behavior of the CMAS droplets. The ODE\nparameters are then identified based on the Physics-Informed Neural Network\n(PINN) framework. Subsequently, the closed form dependency of parameter values\nfound by PINN on the initial radii and contact angles are given using symbolic\nregression. Finally, we employ Bayesian PINNs (B-PINNs) to assess and quantify\nthe uncertainty associated with the discovered parameters. In brief, this study\nprovides insight into spreading dynamics of CMAS droplets by fusing simple\nparametric ODE modeling and state-of-the-art machine learning techniques.",
          "link": "http://arxiv.org/abs/2307.09142",
          "publishedOn": "2023-07-19T01:53:28.406Z",
          "wordCount": null,
          "title": "Characterization of partial wetting by CMAS droplets using multiphase many-body dissipative particle dynamics and data-driven discovery based on PINNs. (arXiv:2307.09142v1 [physics.flu-dyn])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08766",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dias_F/0/1/0/all/0/1\">Felipe M. Dias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toledo_M/0/1/0/all/0/1\">Marcelo A. F. Toledo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cardenas_D/0/1/0/all/0/1\">Diego A. C. Cardenas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Almeida_D/0/1/0/all/0/1\">Douglas A. Almeida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oliveira_F/0/1/0/all/0/1\">Filipe A. C. Oliveira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_E/0/1/0/all/0/1\">Estela Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krieger_J/0/1/0/all/0/1\">Jose E. Krieger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gutierrez_M/0/1/0/all/0/1\">Marco A. Gutierrez</a>",
          "description": "Photoplethysmography (PPG) is a non-invasive technology that measures changes\nin blood volume in the microvascular bed of tissue. It is commonly used in\nmedical devices such as pulse oximeters and wrist worn heart rate monitors to\nmonitor cardiovascular hemodynamics. PPG allows for the assessment of\nparameters (e.g., heart rate, pulse waveform, and peripheral perfusion) that\ncan indicate conditions such as vasoconstriction or vasodilation, and provides\ninformation about microvascular blood flow, making it a valuable tool for\nmonitoring cardiovascular health. However, PPG is subject to a number of\nsources of variations that can impact its accuracy and reliability, especially\nwhen using a wearable device for continuous monitoring, such as motion\nartifacts, skin pigmentation, and vasomotion. In this study, we extracted 27\nstatistical features from the PPG signal for training machine-learning models\nbased on gradient boosting (XGBoost and CatBoost) and Random Forest (RF)\nalgorithms to assess quality of PPG signals that were labeled as good or poor\nquality. We used the PPG time series from a publicly available dataset and\nevaluated the algorithm s performance using Sensitivity (Se), Positive\nPredicted Value (PPV), and F1-score (F1) metrics. Our model achieved Se, PPV,\nand F1-score of 94.4, 95.6, and 95.0 for XGBoost, 94.7, 95.9, and 95.3 for\nCatBoost, and 93.7, 91.3 and 92.5 for RF, respectively. Our findings are\ncomparable to state-of-the-art reported in the literature but using a much\nsimpler model, indicating that ML models are promising for developing remote,\nnon-invasive, and continuous measurement devices.",
          "link": "http://arxiv.org/abs/2307.08766",
          "publishedOn": "2023-07-19T01:53:28.397Z",
          "wordCount": null,
          "title": "Quality Assessment of Photoplethysmography Signals For Cardiovascular Biomarkers Monitoring Using Wearable Devices. (arXiv:2307.08766v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08857",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Tung Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uhlmann_J/0/1/0/all/0/1\">Jeffrey Uhlmann</a>",
          "description": "In this paper, we propose a new constraint, called shift-consistency, for\nsolving matrix/tensor completion problems in the context of recommender\nsystems. Our method provably guarantees several key mathematical properties:\n(1) satisfies a recently established admissibility criterion for recommender\nsystems; (2) satisfies a definition of fairness that eliminates a specific\nclass of potential opportunities for users to maliciously influence system\nrecommendations; and (3) offers robustness by exploiting provable uniqueness of\nmissing-value imputation. We provide a rigorous mathematical description of the\nmethod, including its generalization from matrix to tensor form to permit\nrepresentation and exploitation of complex structural relationships among sets\nof user and product attributes. We argue that our analysis suggests a\nstructured means for defining latent-space projections that can permit provable\nperformance properties to be established for machine learning methods.",
          "link": "http://arxiv.org/abs/2307.08857",
          "publishedOn": "2023-07-19T01:53:28.394Z",
          "wordCount": null,
          "title": "An Admissible Shift-Consistent Method for Recommender Systems. (arXiv:2307.08857v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09476",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Halawi_D/0/1/0/all/0/1\">Danny Halawi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Denain_J/0/1/0/all/0/1\">Jean-Stanislas Denain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1\">Jacob Steinhardt</a>",
          "description": "Modern language models can imitate complex patterns through few-shot\nlearning, enabling them to complete challenging tasks without fine-tuning.\nHowever, imitation can also lead models to reproduce inaccuracies or harmful\ncontent if present in the context. We study harmful imitation through the lens\nof a model's internal representations, and identify two related phenomena:\noverthinking and false induction heads. The first phenomenon, overthinking,\nappears when we decode predictions from intermediate layers, given correct vs.\nincorrect few-shot demonstrations. At early layers, both demonstrations induce\nsimilar model behavior, but the behavior diverges sharply at some \"critical\nlayer\", after which the accuracy given incorrect demonstrations progressively\ndecreases. The second phenomenon, false induction heads, are a possible\nmechanistic cause of overthinking: these are heads in late layers that attend\nto and copy false information from previous demonstrations, and whose ablation\nreduces overthinking. Beyond scientific understanding, our results suggest that\nstudying intermediate model computations could be a promising avenue for\nunderstanding and guarding against harmful model behaviors.",
          "link": "http://arxiv.org/abs/2307.09476",
          "publishedOn": "2023-07-19T01:53:28.388Z",
          "wordCount": null,
          "title": "Overthinking the Truth: Understanding how Language Models Process False Demonstrations. (arXiv:2307.09476v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08722",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yannan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingbo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chao Wang</a>",
          "description": "We propose a method for certifying the fairness of the classification result\nof a widely used supervised learning algorithm, the k-nearest neighbors (KNN),\nunder the assumption that the training data may have historical bias caused by\nsystematic mislabeling of samples from a protected minority group. To the best\nof our knowledge, this is the first certification method for KNN based on three\nvariants of the fairness definition: individual fairness, $\\epsilon$-fairness,\nand label-flipping fairness. We first define the fairness certification problem\nfor KNN and then propose sound approximations of the complex arithmetic\ncomputations used in the state-of-the-art KNN algorithm. This is meant to lift\nthe computation results from the concrete domain to an abstract domain, to\nreduce the computational cost. We show effectiveness of this abstract\ninterpretation based technique through experimental evaluation on six datasets\nwidely used in the fairness research literature. We also show that the method\nis accurate enough to obtain fairness certifications for a large number of test\ninputs, despite the presence of historical bias in the datasets.",
          "link": "http://arxiv.org/abs/2307.08722",
          "publishedOn": "2023-07-19T01:53:28.384Z",
          "wordCount": null,
          "title": "Certifying the Fairness of KNN in the Presence of Dataset Bias. (arXiv:2307.08722v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zharmagambetov_A/0/1/0/all/0/1\">Arman Zharmagambetov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amos_B/0/1/0/all/0/1\">Brandon Amos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferber_A/0/1/0/all/0/1\">Aaron Ferber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1\">Taoan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dilkina_B/0/1/0/all/0/1\">Bistra Dilkina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuandong Tian</a>",
          "description": "Recent works in learning-integrated optimization have shown promise in\nsettings where the optimization problem is only partially observed or where\ngeneral-purpose optimizers perform poorly without expert tuning. By learning an\noptimizer $\\mathbf{g}$ to tackle these challenging problems with $f$ as the\nobjective, the optimization process can be substantially accelerated by\nleveraging past experience. The optimizer can be trained with supervision from\nknown optimal solutions or implicitly by optimizing the compound function\n$f\\circ \\mathbf{g}$. The implicit approach may not require optimal solutions as\nlabels and is capable of handling problem uncertainty; however, it is slow to\ntrain and deploy due to frequent calls to optimizer $\\mathbf{g}$ during both\ntraining and testing. The training is further challenged by sparse gradients of\n$\\mathbf{g}$, especially for combinatorial solvers. To address these\nchallenges, we propose using a smooth and learnable Landscape Surrogate $M$ as\na replacement for $f\\circ \\mathbf{g}$. This surrogate, learnable by neural\nnetworks, can be computed faster than the solver $\\mathbf{g}$, provides dense\nand smooth gradients during training, can generalize to unseen optimization\nproblems, and is efficiently learned via alternating optimization. We test our\napproach on both synthetic problems, including shortest path and\nmultidimensional knapsack, and real-world problems such as portfolio\noptimization, achieving comparable or superior objective values compared to\nstate-of-the-art baselines while reducing the number of calls to $\\mathbf{g}$.\nNotably, our approach outperforms existing methods for computationally\nexpensive high-dimensional problems.",
          "link": "http://arxiv.org/abs/2307.08964",
          "publishedOn": "2023-07-19T01:53:28.383Z",
          "wordCount": null,
          "title": "Landscape Surrogate: Learning Decision Losses for Mathematical Optimization Under Partial Information. (arXiv:2307.08964v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09093",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghoorchian_S/0/1/0/all/0/1\">Saeed Ghoorchian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maghsudi_S/0/1/0/all/0/1\">Setareh Maghsudi</a>",
          "description": "Sequential decision-making under uncertainty is often associated with long\nfeedback delays. Such delays degrade the performance of the learning agent in\nidentifying a subset of arms with the optimal collective reward in the long\nrun. This problem becomes significantly challenging in a non-stationary\nenvironment with structural dependencies amongst the reward distributions\nassociated with the arms. Therefore, besides adapting to delays and\nenvironmental changes, learning the causal relations alleviates the adverse\neffects of feedback delay on the decision-making process. We formalize the\ndescribed setting as a non-stationary and delayed combinatorial semi-bandit\nproblem with causally related rewards. We model the causal relations by a\ndirected graph in a stationary structural equation model. The agent maximizes\nthe long-term average payoff, defined as a linear function of the base arms'\nrewards. We develop a policy that learns the structural dependencies from\ndelayed feedback and utilizes that to optimize the decision-making while\nadapting to drifts. We prove a regret bound for the performance of the proposed\nalgorithm. Besides, we evaluate our method via numerical analysis using\nsynthetic and real-world datasets to detect the regions that contribute the\nmost to the spread of Covid-19 in Italy.",
          "link": "http://arxiv.org/abs/2307.09093",
          "publishedOn": "2023-07-19T01:53:28.381Z",
          "wordCount": null,
          "title": "Non-stationary Delayed Combinatorial Semi-Bandit with Causally Related Rewards. (arXiv:2307.09093v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.05097",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Doshi_V/0/1/0/all/0/1\">Vishwaraj Doshi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hu_J/0/1/0/all/0/1\">Jie Hu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Eun_D/0/1/0/all/0/1\">Do Young Eun</a>",
          "description": "We consider random walks on discrete state spaces, such as general undirected\ngraphs, where the random walkers are designed to approximate a target quantity\nover the network topology via sampling and neighborhood exploration in the form\nof Markov chain Monte Carlo (MCMC) procedures. Given any Markov chain\ncorresponding to a target probability distribution, we design a self-repellent\nrandom walk (SRRW) which is less likely to transition to nodes that were highly\nvisited in the past, and more likely to transition to seldom visited nodes. For\na class of SRRWs parameterized by a positive real {\\alpha}, we prove that the\nempirical distribution of the process converges almost surely to the the target\n(stationary) distribution of the underlying Markov chain kernel. We then\nprovide a central limit theorem and derive the exact form of the arising\nasymptotic co-variance matrix, which allows us to show that the SRRW with a\nstronger repellence (larger {\\alpha}) always achieves a smaller asymptotic\ncovariance, in the sense of Loewner ordering of co-variance matrices.\nEspecially for SRRW-driven MCMC algorithms, we show that the decrease in the\nasymptotic sampling variance is of the order O(1/{\\alpha}), eventually going\ndown to zero. Finally, we provide numerical simulations complimentary to our\ntheoretical results, also empirically testing a version of SRRW with {\\alpha}\nincreasing in time to combine the benefits of smaller asymptotic variance due\nto large {\\alpha}, with empirically observed faster mixing properties of SRRW\nwith smaller {\\alpha}.",
          "link": "http://arxiv.org/abs/2305.05097",
          "publishedOn": "2023-07-19T01:53:28.378Z",
          "wordCount": null,
          "title": "Self-Repellent Random Walks on General Graphs -- Achieving Minimal Sampling Variance via Nonlinear Markov Chains. (arXiv:2305.05097v2 [math.PR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07674",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vemgal_N/0/1/0/all/0/1\">Nikhil Vemgal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lau_E/0/1/0/all/0/1\">Elaine Lau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1\">Doina Precup</a>",
          "description": "Reinforcement Learning (RL) algorithms aim to learn an optimal policy by\niteratively sampling actions to learn how to maximize the total expected\nreturn, $R(x)$. GFlowNets are a special class of algorithms designed to\ngenerate diverse candidates, $x$, from a discrete set, by learning a policy\nthat approximates the proportional sampling of $R(x)$. GFlowNets exhibit\nimproved mode discovery compared to conventional RL algorithms, which is very\nuseful for applications such as drug discovery and combinatorial search.\nHowever, since GFlowNets are a relatively recent class of algorithms, many\ntechniques which are useful in RL have not yet been associated with them. In\nthis paper, we study the utilization of a replay buffer for GFlowNets. We\nexplore empirically various replay buffer sampling techniques and assess the\nimpact on the speed of mode discovery and the quality of the modes discovered.\nOur experimental results in the Hypergrid toy domain and a molecule synthesis\nenvironment demonstrate significant improvements in mode discovery when\ntraining with a replay buffer, compared to training only with trajectories\ngenerated on-policy.",
          "link": "http://arxiv.org/abs/2307.07674",
          "publishedOn": "2023-07-19T01:53:28.378Z",
          "wordCount": null,
          "title": "An Empirical Study of the Effectiveness of Using a Replay Buffer on Mode Discovery in GFlowNets. (arXiv:2307.07674v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08951",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhengjing Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_G/0/1/0/all/0/1\">Gang Mei</a>",
          "description": "Forecasting how landslides will evolve over time or whether they will fail is\na challenging task due to a variety of factors, both internal and external.\nDespite their considerable potential to address these challenges, deep learning\ntechniques lack interpretability, undermining the credibility of the forecasts\nthey produce. The recent development of transformer-based deep learning offers\nuntapped possibilities for forecasting landslides with unprecedented\ninterpretability and nonlinear feature learning capabilities. Here, we present\na deep learning pipeline that is capable of predicting landslide behavior\nholistically, which employs a transformer-based network called LFIT to learn\ncomplex nonlinear relationships from prior knowledge and multiple source data,\nidentifying the most relevant variables, and demonstrating a comprehensive\nunderstanding of landslide evolution and temporal patterns. By integrating\nprior knowledge, we provide improvement in holistic landslide forecasting,\nenabling us to capture diverse responses to various influencing factors in\ndifferent local landslide areas. Using deformation observations as proxies for\nmeasuring the kinetics of landslides, we validate our approach by training\nmodels to forecast reservoir landslides in the Three Gorges Reservoir and\ncreeping landslides on the Tibetan Plateau. When prior knowledge is\nincorporated, we show that interpretable landslide forecasting effectively\nidentifies influential factors across various landslides. It further elucidates\nhow local areas respond to these factors, making landslide behavior and trends\nmore interpretable and predictable. The findings from this study will\ncontribute to understanding landslide behavior in a new way and make the\nproposed approach applicable to other complex disasters influenced by internal\nand external factors in the future.",
          "link": "http://arxiv.org/abs/2307.08951",
          "publishedOn": "2023-07-19T01:53:28.369Z",
          "wordCount": null,
          "title": "Knowledge-infused Deep Learning Enables Interpretable Landslide Forecasting. (arXiv:2307.08951v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09065",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1\">Avishkar Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendez_O/0/1/0/all/0/1\">Oscar Mendez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russell_C/0/1/0/all/0/1\">Chris Russell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bowden_R/0/1/0/all/0/1\">Richard Bowden</a>",
          "description": "Graph convolutional networks (GCNs) enable end-to-end learning on graph\nstructured data. However, many works assume a given graph structure. When the\ninput graph is noisy or unavailable, one approach is to construct or learn a\nlatent graph structure. These methods typically fix the choice of node degree\nfor the entire graph, which is suboptimal. Instead, we propose a novel\nend-to-end differentiable graph generator which builds graph topologies where\neach node selects both its neighborhood and its size. Our module can be readily\nintegrated into existing pipelines involving graph convolution operations,\nreplacing the predetermined or existing adjacency matrix with one that is\nlearned, and optimized, as part of the general objective. As such it is\napplicable to any GCN. We integrate our module into trajectory prediction,\npoint cloud classification and node classification pipelines resulting in\nimproved accuracy over other structure-learning methods across a wide range of\ndatasets and GCN backbones.",
          "link": "http://arxiv.org/abs/2307.09065",
          "publishedOn": "2023-07-19T01:53:28.364Z",
          "wordCount": null,
          "title": "Learning Adaptive Neighborhoods for Graph Neural Networks. (arXiv:2307.09065v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2207.02149",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Holdijk_L/0/1/0/all/0/1\">Lars Holdijk</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Du_Y/0/1/0/all/0/1\">Yuanqi Du</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hooft_F/0/1/0/all/0/1\">Ferry Hooft</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Jaini_P/0/1/0/all/0/1\">Priyank Jaini</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ensing_B/0/1/0/all/0/1\">Bernd Ensing</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Welling_M/0/1/0/all/0/1\">Max Welling</a>",
          "description": "We consider the problem of sampling transition paths between two given\nmetastable states of a molecular system, e.g. a folded and unfolded protein or\nproducts and reactants of a chemical reaction. Due to the existence of high\nenergy barriers separating the states, these transition paths are unlikely to\nbe sampled with standard Molecular Dynamics (MD) simulation. Traditional\nmethods to augment MD with a bias potential to increase the probability of the\ntransition rely on a dimensionality reduction step based on Collective\nVariables (CVs). Unfortunately, selecting appropriate CVs requires chemical\nintuition and traditional methods are therefore not always applicable to larger\nsystems. Additionally, when incorrect CVs are used, the bias potential might\nnot be minimal and bias the system along dimensions irrelevant to the\ntransition. Showing a formal relation between the problem of sampling molecular\ntransition paths, the Schr\\\"odinger bridge problem and stochastic optimal\ncontrol with neural network policies, we propose a machine learning method for\nsampling said transitions. Unlike previous non-machine learning approaches our\nmethod, named PIPS, does not depend on CVs. We show that our method successful\ngenerates low energy transitions for Alanine Dipeptide as well as the larger\nPolyproline and Chignolin proteins.",
          "link": "http://arxiv.org/abs/2207.02149",
          "publishedOn": "2023-07-19T01:53:28.361Z",
          "wordCount": null,
          "title": "Stochastic Optimal Control for Collective Variable Free Sampling of Molecular Transition Paths. (arXiv:2207.02149v2 [q-bio.BM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.15764",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_F/0/1/0/all/0/1\">Fabio De Sousa Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_T/0/1/0/all/0/1\">Tian Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monteiro_M/0/1/0/all/0/1\">Miguel Monteiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pawlowski_N/0/1/0/all/0/1\">Nick Pawlowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glocker_B/0/1/0/all/0/1\">Ben Glocker</a>",
          "description": "We present a general causal generative modelling framework for accurate\nestimation of high fidelity image counterfactuals with deep structural causal\nmodels. Estimation of interventional and counterfactual queries for\nhigh-dimensional structured variables, such as images, remains a challenging\ntask. We leverage ideas from causal mediation analysis and advances in\ngenerative modelling to design new deep causal mechanisms for structured\nvariables in causal models. Our experiments demonstrate that our proposed\nmechanisms are capable of accurate abduction and estimation of direct, indirect\nand total effects as measured by axiomatic soundness of counterfactuals.",
          "link": "http://arxiv.org/abs/2306.15764",
          "publishedOn": "2023-07-19T01:53:28.357Z",
          "wordCount": null,
          "title": "High Fidelity Image Counterfactuals with Probabilistic Causal Models. (arXiv:2306.15764v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.13399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dolev_E/0/1/0/all/0/1\">Eden Dolev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awad_A/0/1/0/all/0/1\">Alaa Awad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_D/0/1/0/all/0/1\">Denisa Roberts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ebrahimzadeh_Z/0/1/0/all/0/1\">Zahra Ebrahimzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mejran_M/0/1/0/all/0/1\">Marcin Mejran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malpani_V/0/1/0/all/0/1\">Vaibhav Malpani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yavuz_M/0/1/0/all/0/1\">Mahir Yavuz</a>",
          "description": "In this article, we present our approach to single-modality visual\nrepresentation learning. Understanding visual representations of items is vital\nfor fashion recommendations in e-commerce. We detail and contrast techniques\nused to finetune large-scale visual representation learning models in an\nefficient manner under low-resource settings, including several pretrained\nbackbone architectures, both in the convolutional neural network as well as the\nvision transformer family. We describe the challenges for e-commerce\napplications at-scale and highlight the efforts to more efficiently train,\nevaluate, and serve visual representations. We present ablation studies\nevaluating the representation offline performance for several downstream tasks,\nincluding visually similar ad recommendations on mobile devices. To this end,\nwe present a novel multilingual text-to-image generative offline evaluation\nmethod for visually similar recommendation systems. Finally, we include online\nresults from deployed machine learning systems in production at Etsy.",
          "link": "http://arxiv.org/abs/2305.13399",
          "publishedOn": "2023-07-19T01:53:28.353Z",
          "wordCount": null,
          "title": "Efficient Large-Scale Visual Representation Learning And Evaluation. (arXiv:2305.13399v4 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.13115",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongjun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Lun Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Q/0/1/0/all/0/1\">Qiang Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xuan Song</a>",
          "description": "Recent years have witnessed the great potential of attention mechanism in\ngraph representation learning. However, while variants of attention-based GNNs\nare setting new benchmarks for numerous real-world datasets, recent works have\npointed out that their induced attentions are less robust and generalizable\nagainst noisy graphs due to lack of direct supervision. In this paper, we\npresent a new framework which utilizes the tool of causality to provide a\npowerful supervision signal for the learning process of attention functions.\nSpecifically, we estimate the direct causal effect of attention to the final\nprediction, and then maximize such effect to guide attention attending to more\nmeaningful neighbors. Our method can serve as a plug-and-play module for any\ncanonical attention-based GNNs in an end-to-end fashion. Extensive experiments\non a wide range of benchmark datasets illustrated that, by directly supervising\nattention functions, the model is able to converge faster with a clearer\ndecision boundary, and thus yields better performances.",
          "link": "http://arxiv.org/abs/2305.13115",
          "publishedOn": "2023-07-19T01:53:28.350Z",
          "wordCount": null,
          "title": "Causal-Based Supervision of Attention in Graph Neural Network: A Better and Simpler Choice towards Powerful Attention. (arXiv:2305.13115v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.06289",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Curtis_C/0/1/0/all/0/1\">Christopher W. Curtis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alford_Lago_D/0/1/0/all/0/1\">D. Jay Alford-Lago</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bollt_E/0/1/0/all/0/1\">Erik Bollt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuma_A/0/1/0/all/0/1\">Andrew Tuma</a>",
          "description": "While the acquisition of time series has become more straightforward,\ndeveloping dynamical models from time series is still a challenging and\nevolving problem domain. Within the last several years, to address this\nproblem, there has been a merging of machine learning tools with what is called\nthe dynamic mode decomposition (DMD). This general approach has been shown to\nbe an especially promising avenue for accurate model development. Building on\nthis prior body of work, we develop a deep learning DMD based method which\nmakes use of the fundamental insight of Takens' Embedding Theorem to build an\nadaptive learning scheme that better approximates higher dimensional and\nchaotic dynamics. We call this method the Deep Learning Hankel DMD (DLHDMD). We\nlikewise explore how our method learns mappings which tend, after successful\ntraining, to significantly change the mutual information between dimensions in\nthe dynamics. This appears to be a key feature in enhancing the DMD overall,\nand it should help provide further insight for developing other deep learning\nmethods for time series analysis and model generation.",
          "link": "http://arxiv.org/abs/2303.06289",
          "publishedOn": "2023-07-19T01:53:28.349Z",
          "wordCount": null,
          "title": "Machine Learning Enhanced Hankel Dynamic-Mode Decomposition. (arXiv:2303.06289v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.00999",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Sadiev_A/0/1/0/all/0/1\">Abdurakhmon Sadiev</a>, <a href=\"http://arxiv.org/find/math/1/au:+Danilova_M/0/1/0/all/0/1\">Marina Danilova</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gorbunov_E/0/1/0/all/0/1\">Eduard Gorbunov</a>, <a href=\"http://arxiv.org/find/math/1/au:+Horvath_S/0/1/0/all/0/1\">Samuel Horv&#xe1;th</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gidel_G/0/1/0/all/0/1\">Gauthier Gidel</a>, <a href=\"http://arxiv.org/find/math/1/au:+Dvurechensky_P/0/1/0/all/0/1\">Pavel Dvurechensky</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gasnikov_A/0/1/0/all/0/1\">Alexander Gasnikov</a>, <a href=\"http://arxiv.org/find/math/1/au:+Richtarik_P/0/1/0/all/0/1\">Peter Richt&#xe1;rik</a>",
          "description": "During recent years the interest of optimization and machine learning\ncommunities in high-probability convergence of stochastic optimization methods\nhas been growing. One of the main reasons for this is that high-probability\ncomplexity bounds are more accurate and less studied than in-expectation ones.\nHowever, SOTA high-probability non-asymptotic convergence results are derived\nunder strong assumptions such as the boundedness of the gradient noise variance\nor of the objective's gradient itself. In this paper, we propose several\nalgorithms with high-probability convergence results under less restrictive\nassumptions. In particular, we derive new high-probability convergence results\nunder the assumption that the gradient/operator noise has bounded central\n$\\alpha$-th moment for $\\alpha \\in (1,2]$ in the following setups: (i) smooth\nnon-convex / Polyak-Lojasiewicz / convex / strongly convex / quasi-strongly\nconvex minimization problems, (ii) Lipschitz / star-cocoercive and monotone /\nquasi-strongly monotone variational inequalities. These results justify the\nusage of the considered methods for solving problems that do not fit standard\nfunctional classes studied in stochastic optimization.",
          "link": "http://arxiv.org/abs/2302.00999",
          "publishedOn": "2023-07-19T01:53:28.348Z",
          "wordCount": null,
          "title": "High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance. (arXiv:2302.00999v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.14568",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dey_B/0/1/0/all/0/1\">Biprateep Dey</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhao_D/0/1/0/all/0/1\">David Zhao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Newman_J/0/1/0/all/0/1\">Jeffrey A. Newman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Andrews_B/0/1/0/all/0/1\">Brett H. Andrews</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Izbicki_R/0/1/0/all/0/1\">Rafael Izbicki</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_A/0/1/0/all/0/1\">Ann B. Lee</a>",
          "description": "Uncertainty quantification is crucial for assessing the predictive ability of\nAI algorithms. Much research has been devoted to describing the predictive\ndistribution (PD) $F(y|\\mathbf{x})$ of a target variable $y \\in \\mathbb{R}$\ngiven complex input features $\\mathbf{x} \\in \\mathcal{X}$. However,\noff-the-shelf PDs (from, e.g., normalizing flows and Bayesian neural networks)\noften lack conditional calibration with the probability of occurrence of an\nevent given input $\\mathbf{x}$ being significantly different from the predicted\nprobability. Current calibration methods do not fully assess and enforce\nconditionally calibrated PDs. Here we propose \\texttt{Cal-PIT}, a method that\naddresses both PD diagnostics and recalibration by learning a single\nprobability-probability map from calibration data. The key idea is to regress\nprobability integral transform scores against $\\mathbf{x}$. The estimated\nregression provides interpretable diagnostics of conditional coverage across\nthe feature space. The same regression function morphs the misspecified PD to a\nre-calibrated PD for all $\\mathbf{x}$. We benchmark our corrected prediction\nbands (a by-product of corrected PDs) against oracle bands and state-of-the-art\npredictive inference algorithms for synthetic data. We also provide results for\ntwo applications: (i) probabilistic nowcasting given sequences of satellite\nimages, and (ii) conditional density estimation of galaxy distances given\nimaging data (so-called photometric redshift estimation). Our code is available\nas a Python package https://github.com/lee-group-cmu/Cal-PIT .",
          "link": "http://arxiv.org/abs/2205.14568",
          "publishedOn": "2023-07-19T01:53:28.344Z",
          "wordCount": null,
          "title": "Conditionally Calibrated Predictive Distributions by Probability-Probability Map: Application to Galaxy Redshift Estimation and Probabilistic Forecasting. (arXiv:2205.14568v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16189",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Siahkoohi_A/0/1/0/all/0/1\">Ali Siahkoohi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morel_R/0/1/0/all/0/1\">Rudy Morel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balestriero_R/0/1/0/all/0/1\">Randall Balestriero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allys_E/0/1/0/all/0/1\">Erwan Allys</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sainton_G/0/1/0/all/0/1\">Gr&#xe9;gory Sainton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawamura_T/0/1/0/all/0/1\">Taichi Kawamura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoop_M/0/1/0/all/0/1\">Maarten V. de Hoop</a>",
          "description": "Unsupervised source separation involves unraveling an unknown set of source\nsignals recorded through a mixing operator, with limited prior knowledge about\nthe sources, and only access to a dataset of signal mixtures. This problem is\ninherently ill-posed and is further challenged by the variety of time-scales\nexhibited by sources in time series data. Existing methods typically rely on a\npreselected window size that limits their capacity to handle multi-scale\nsources. To address this issue, instead of operating in the time domain, we\npropose an unsupervised multi-scale clustering and source separation framework\nby leveraging wavelet scattering covariances that provide a low-dimensional\nrepresentation of stochastic processes, capable of distinguishing between\ndifferent non-Gaussian stochastic processes. Nested within this representation\nspace, we develop a factorial Gaussian-mixture variational autoencoder that is\ntrained to (1) probabilistically cluster sources at different time-scales and\n(2) independently sample scattering covariance representations associated with\neach cluster. Using samples from each cluster as prior information, we\nformulate source separation as an optimization problem in the wavelet\nscattering covariance representation space, resulting in separated sources in\nthe time domain. When applied to seismic data recorded during the NASA InSight\nmission on Mars, our multi-scale nested approach proves to be a powerful tool\nfor discriminating between sources varying greatly in time-scale, e.g.,\nminute-long transient one-sided pulses (known as ``glitches'') and structured\nambient noises resulting from atmospheric activities that typically last for\ntens of minutes. These results provide an opportunity to conduct further\ninvestigations into the isolated sources related to atmospheric-surface\ninteractions, thermal relaxations, and other complex phenomena.",
          "link": "http://arxiv.org/abs/2305.16189",
          "publishedOn": "2023-07-19T01:53:28.343Z",
          "wordCount": null,
          "title": "Martian time-series unraveled: A multi-scale nested approach with factorial variational autoencoders. (arXiv:2305.16189v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.03719",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aguiar_G/0/1/0/all/0/1\">Gabriel Aguiar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krawczyk_B/0/1/0/all/0/1\">Bartosz Krawczyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cano_A/0/1/0/all/0/1\">Alberto Cano</a>",
          "description": "Class imbalance poses new challenges when it comes to classifying data\nstreams. Many algorithms recently proposed in the literature tackle this\nproblem using a variety of data-level, algorithm-level, and ensemble\napproaches. However, there is a lack of standardized and agreed-upon procedures\nand benchmarks on how to evaluate these algorithms. This work proposes a\nstandardized, exhaustive, and comprehensive experimental framework to evaluate\nalgorithms in a collection of diverse and challenging imbalanced data stream\nscenarios. The experimental study evaluates 24 state-of-the-art data streams\nalgorithms on 515 imbalanced data streams that combine static and dynamic class\nimbalance ratios, instance-level difficulties, concept drift, real-world and\nsemi-synthetic datasets in binary and multi-class scenarios. This leads to a\nlarge-scale experimental study comparing state-of-the-art classifiers in the\ndata stream mining domain. We discuss the advantages and disadvantages of\nstate-of-the-art classifiers in each of these scenarios and we provide general\nrecommendations to end-users for selecting the best algorithms for imbalanced\ndata streams. Additionally, we formulate open challenges and future directions\nfor this domain. Our experimental framework is fully reproducible and easy to\nextend with new methods. This way, we propose a standardized approach to\nconducting experiments in imbalanced data streams that can be used by other\nresearchers to create complete, trustworthy, and fair evaluation of newly\nproposed methods. Our experimental framework can be downloaded from\nhttps://github.com/canoalberto/imbalanced-streams.",
          "link": "http://arxiv.org/abs/2204.03719",
          "publishedOn": "2023-07-19T01:53:28.341Z",
          "wordCount": null,
          "title": "A survey on learning from imbalanced data streams: taxonomy, challenges, empirical study, and reproducible experimental framework. (arXiv:2204.03719v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kori_A/0/1/0/all/0/1\">Avinash Kori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Locatello_F/0/1/0/all/0/1\">Francesco Locatello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toni_F/0/1/0/all/0/1\">Francesca Toni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glocker_B/0/1/0/all/0/1\">Ben Glocker</a>",
          "description": "Extracting object-level representations for downstream reasoning tasks is an\nemerging area in AI. Learning object-centric representations in an unsupervised\nsetting presents multiple challenges, a key one being binding an arbitrary\nnumber of object instances to a specialized object slot. Recent object-centric\nrepresentation methods like Slot Attention utilize iterative attention to learn\ncomposable representations with dynamic inference level binding but fail to\nachieve specialized slot level binding. To address this, in this paper we\npropose Unsupervised Conditional Slot Attention using a novel Probabilistic\nSlot Dictionary (PSD). We define PSD with (i) abstract object-level property\nvectors as key and (ii) parametric Gaussian distribution as its corresponding\nvalue. We demonstrate the benefits of the learnt specific object-level\nconditioning distributions in multiple downstream tasks, namely object\ndiscovery, compositional scene generation, and compositional visual reasoning.\nWe show that our method provides scene composition capabilities and a\nsignificant boost in a few shot adaptability tasks of compositional visual\nreasoning, while performing similarly or better than slot attention in object\ndiscovery tasks",
          "link": "http://arxiv.org/abs/2307.09437",
          "publishedOn": "2023-07-19T01:53:28.339Z",
          "wordCount": null,
          "title": "Unsupervised Conditional Slot Attention for Object Centric Learning. (arXiv:2307.09437v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.16299",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Town_J/0/1/0/all/0/1\">Jared Town</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Morrison_Z/0/1/0/all/0/1\">Zachary Morrison</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kamalapurkar_R/0/1/0/all/0/1\">Rushikesh Kamalapurkar</a>",
          "description": "A key challenge in solving the deterministic inverse reinforcement learning\n(IRL) problem online and in real-time is the existence of multiple solutions.\nNonuniqueness necessitates the study of the notion of equivalent solutions,\ni.e., solutions that result in a different cost functional but same feedback\nmatrix, and convergence to such solutions. While offline algorithms that result\nin convergence to equivalent solutions have been developed in the literature,\nonline, real-time techniques that address nonuniqueness are not available. In\nthis paper, a regularized history stack observer that converges to\napproximately equivalent solutions of the IRL problem is developed. Novel\ndata-richness conditions are developed to facilitate the analysis and\nsimulation results are provided to demonstrate the effectiveness of the\ndeveloped technique.",
          "link": "http://arxiv.org/abs/2210.16299",
          "publishedOn": "2023-07-19T01:53:28.327Z",
          "wordCount": null,
          "title": "Nonuniqueness and Convergence to Equivalent Solutions in Observer-based Inverse Reinforcement Learning. (arXiv:2210.16299v2 [eess.SY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09311",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Williams_I/0/1/0/all/0/1\">Ivan Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polizzi_E/0/1/0/all/0/1\">Eric Polizzi</a>",
          "description": "A neural solver and differentiable simulation of the quantum transmitting\nboundary model is presented for the inverse quantum transport problem. The\nneural solver is used to engineer continuous transmission properties and the\ndifferentiable simulation is used to engineer current-voltage characteristics.",
          "link": "http://arxiv.org/abs/2307.09311",
          "publishedOn": "2023-07-19T01:53:28.319Z",
          "wordCount": null,
          "title": "Automatic Differentiation for Inverse Problems with Applications in Quantum Transport. (arXiv:2307.09311v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09182",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pfeiffer_K/0/1/0/all/0/1\">Kilian Pfeiffer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rapp_M/0/1/0/all/0/1\">Martin Rapp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalili_R/0/1/0/all/0/1\">Ramin Khalili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henkel_J/0/1/0/all/0/1\">J&#xf6;rg Henkel</a>",
          "description": "With an increasing number of smart devices like internet of things (IoT)\ndevices deployed in the field, offloadingtraining of neural networks (NNs) to a\ncentral server becomes more and more infeasible. Recent efforts toimprove\nusers' privacy have led to on-device learning emerging as an alternative.\nHowever, a model trainedonly on a single device, using only local data, is\nunlikely to reach a high accuracy. Federated learning (FL)has been introduced\nas a solution, offering a privacy-preserving trade-off between communication\noverheadand model accuracy by sharing knowledge between devices but disclosing\nthe devices' private data. Theapplicability and the benefit of applying\nbaseline FL are, however, limited in many relevant use cases dueto the\nheterogeneity present in such environments. In this survey, we outline the\nheterogeneity challengesFL has to overcome to be widely applicable in\nreal-world applications. We especially focus on the aspect ofcomputation\nheterogeneity among the participating devices and provide a comprehensive\noverview of recentworks on heterogeneity-aware FL. We discuss two groups: works\nthat adapt the NN architecture and worksthat approach heterogeneity on a system\nlevel, covering Federated Averaging (FedAvg), distillation, and\nsplitlearning-based approaches, as well as synchronous and asynchronous\naggregation schemes.",
          "link": "http://arxiv.org/abs/2307.09182",
          "publishedOn": "2023-07-19T01:53:28.308Z",
          "wordCount": null,
          "title": "Federated Learning for Computationally-Constrained Heterogeneous Devices: A Survey. (arXiv:2307.09182v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07357",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Scroccaro_P/0/1/0/all/0/1\">Pedro Zattoni Scroccaro</a>, <a href=\"http://arxiv.org/find/math/1/au:+Beek_P/0/1/0/all/0/1\">Piet van Beek</a>, <a href=\"http://arxiv.org/find/math/1/au:+Esfahani_P/0/1/0/all/0/1\">Peyman Mohajerin Esfahani</a>, <a href=\"http://arxiv.org/find/math/1/au:+Atasoy_B/0/1/0/all/0/1\">Bilge Atasoy</a>",
          "description": "We propose a method for learning decision-makers' behavior in routing\nproblems using Inverse Optimization (IO). The IO framework falls into the\nsupervised learning category and builds on the premise that the target behavior\nis an optimizer of an unknown cost function. This cost function is to be\nlearned through historical data, and in the context of routing problems, can be\ninterpreted as the routing preferences of the decision-makers. In this view,\nthe main contributions of this study are to propose an IO methodology with a\nhypothesis function, loss function, and stochastic first-order algorithm\ntailored to routing problems. We further test our IO approach in the Amazon\nLast Mile Routing Research Challenge, where the goal is to learn models that\nreplicate the routing preferences of human drivers, using thousands of\nreal-world routing examples. Our final IO-learned routing model achieves a\nscore that ranks 2nd compared with the 48 models that qualified for the final\nround of the challenge. Our results showcase the flexibility and real-world\npotential of the proposed IO methodology to learn from decision-makers'\ndecisions in routing problems.",
          "link": "http://arxiv.org/abs/2307.07357",
          "publishedOn": "2023-07-19T01:53:28.298Z",
          "wordCount": null,
          "title": "Inverse Optimization for Routing Problems. (arXiv:2307.07357v1 [math.OC] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yaoyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhongwang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Leyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Z/0/1/0/all/0/1\">Zhiwei Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_T/0/1/0/all/0/1\">Tao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhi-Qin John Xu</a>",
          "description": "We propose an optimistic estimate to evaluate the best possible fitting\nperformance of nonlinear models. It yields an optimistic sample size that\nquantifies the smallest possible sample size to fit/recover a target function\nusing a nonlinear model. We estimate the optimistic sample sizes for matrix\nfactorization models, deep models, and deep neural networks (DNNs) with\nfully-connected or convolutional architecture. For each nonlinear model, our\nestimates predict a specific subset of targets that can be fitted at\noverparameterization, which are confirmed by our experiments. Our optimistic\nestimate reveals two special properties of the DNN models -- free\nexpressiveness in width and costly expressiveness in connection. These\nproperties suggest the following architecture design principles of DNNs: (i)\nfeel free to add neurons/kernels; (ii) restrain from connecting neurons.\nOverall, our optimistic estimate theoretically unveils the vast potential of\nnonlinear models in fitting at overparameterization. Based on this framework,\nwe anticipate gaining a deeper understanding of how and why numerous nonlinear\nmodels such as DNNs can effectively realize their potential in practice in the\nnear future.",
          "link": "http://arxiv.org/abs/2307.08921",
          "publishedOn": "2023-07-19T01:53:28.283Z",
          "wordCount": null,
          "title": "Optimistic Estimate Uncovers the Potential of Nonlinear Models. (arXiv:2307.08921v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09191",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Matteucci_F/0/1/0/all/0/1\">Federico Matteucci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arzamasov_V/0/1/0/all/0/1\">Vadim Arzamasov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boehm_K/0/1/0/all/0/1\">Klemens Boehm</a>",
          "description": "Categorical encoders transform categorical features into numerical\nrepresentations that are indispensable for a wide range of machine learning\nmodels. Existing encoder benchmark studies lack generalizability because of\ntheir limited choice of (1) encoders, (2) experimental factors, and (3)\ndatasets. Additionally, inconsistencies arise from the adoption of varying\naggregation strategies. This paper is the most comprehensive benchmark of\ncategorical encoders to date, including an extensive evaluation of 32\nconfigurations of encoders from diverse families, with 36 combinations of\nexperimental factors, and on 50 datasets. The study shows the profound\ninfluence of dataset selection, experimental factors, and aggregation\nstrategies on the benchmark's conclusions -- aspects disregarded in previous\nencoder benchmarks.",
          "link": "http://arxiv.org/abs/2307.09191",
          "publishedOn": "2023-07-19T01:53:28.261Z",
          "wordCount": null,
          "title": "A benchmark of categorical encoders for binary classification. (arXiv:2307.09191v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2207.00664",
          "author": "<a href=\"http://arxiv.org/find/hep-ph/1/au:+Leigh_M/0/1/0/all/0/1\">Matthew Leigh</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Raine_J/0/1/0/all/0/1\">John Andrew Raine</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Zoch_K/0/1/0/all/0/1\">Knut Zoch</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Golling_T/0/1/0/all/0/1\">Tobias Golling</a>",
          "description": "We present $\\nu$-Flows, a novel method for restricting the likelihood space\nof neutrino kinematics in high energy collider experiments using conditional\nnormalizing flows and deep invertible neural networks. This method allows the\nrecovery of the full neutrino momentum which is usually left as a free\nparameter and permits one to sample neutrino values under a learned conditional\nlikelihood given event observations. We demonstrate the success of $\\nu$-Flows\nin a case study by applying it to simulated semileptonic $t\\bar{t}$ events and\nshow that it can lead to more accurate momentum reconstruction, particularly of\nthe longitudinal coordinate. We also show that this has direct benefits in a\ndownstream task of jet association, leading to an improvement of up to a factor\nof 1.41 compared to conventional methods.",
          "link": "http://arxiv.org/abs/2207.00664",
          "publishedOn": "2023-07-19T01:53:28.249Z",
          "wordCount": null,
          "title": "\\nu-Flows: Conditional Neutrino Regression. (arXiv:2207.00664v7 [hep-ph] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yudong Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guiliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poupart_P/0/1/0/all/0/1\">Pascal Poupart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1\">Yangchen Pan</a>",
          "description": "Restricting the variance of a policy's return is a popular choice in\nrisk-averse Reinforcement Learning (RL) due to its clear mathematical\ndefinition and easy interpretability. Traditional methods directly restrict the\ntotal return variance. Recent methods restrict the per-step reward variance as\na proxy. We thoroughly examine the limitations of these variance-based methods,\nsuch as sensitivity to numerical scale and hindering of policy learning, and\npropose to use an alternative risk measure, Gini deviation, as a substitute. We\nstudy various properties of this new risk measure and derive a policy gradient\nalgorithm to minimize it. Empirical evaluation in domains where risk-aversion\ncan be clearly defined, shows that our algorithm can mitigate the limitations\nof variance-based risk measures and achieves high return with low risk in terms\nof variance and Gini deviation when others fail to learn a reasonable policy.",
          "link": "http://arxiv.org/abs/2307.08873",
          "publishedOn": "2023-07-19T01:53:28.199Z",
          "wordCount": null,
          "title": "An Alternative to Variance: Gini Deviation for Risk-averse Policy Gradient. (arXiv:2307.08873v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08816",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mak_S/0/1/0/all/0/1\">Stephen Mak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mana_K/0/1/0/all/0/1\">Kyle Mana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zehtabi_P/0/1/0/all/0/1\">Parisa Zehtabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cashmore_M/0/1/0/all/0/1\">Michael Cashmore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magazzeni_D/0/1/0/all/0/1\">Daniele Magazzeni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veloso_M/0/1/0/all/0/1\">Manuela Veloso</a>",
          "description": "Stochastic optimization (SO) attempts to offer optimal decisions in the\npresence of uncertainty. Often, the classical formulation of these problems\nbecomes intractable due to (a) the number of scenarios required to capture the\nuncertainty and (b) the discrete nature of real-world planning problems. To\novercome these tractability issues, practitioners turn to decomposition methods\nthat divide the problem into smaller, more tractable sub-problems. The focal\ndecomposition method of this paper is Benders decomposition (BD), which\ndecomposes stochastic optimization problems on the basis of scenario\nindependence. In this paper we propose a method of accelerating BD with the aid\nof a surrogate model in place of an NP-hard integer master problem. Through the\nacceleration method we observe 30% faster average convergence when compared to\nother accelerated BD implementations. We introduce a reinforcement learning\nagent as a surrogate and demonstrate how it can be used to solve a stochastic\ninventory management problem.",
          "link": "http://arxiv.org/abs/2307.08816",
          "publishedOn": "2023-07-19T01:53:28.194Z",
          "wordCount": null,
          "title": "Towards Accelerating Benders Decomposition via Reinforcement Learning Surrogate Models. (arXiv:2307.08816v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08989",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xinxing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Genke Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_J/0/1/0/all/0/1\">Jian Chu</a>",
          "description": "Drug-target binding affinity prediction plays an important role in the early\nstages of drug discovery, which can infer the strength of interactions between\nnew drugs and new targets. However, the performance of previous computational\nmodels is limited by the following drawbacks. The learning of drug\nrepresentation relies only on supervised data, without taking into account the\ninformation contained in the molecular graph itself. Moreover, most previous\nstudies tended to design complicated representation learning module, while\nuniformity, which is used to measure representation quality, is ignored. In\nthis study, we propose GraphCL-DTA, a graph contrastive learning with molecular\nsemantics for drug-target binding affinity prediction. In GraphCL-DTA, we\ndesign a graph contrastive learning framework for molecular graphs to learn\ndrug representations, so that the semantics of molecular graphs are preserved.\nThrough this graph contrastive framework, a more essential and effective drug\nrepresentation can be learned without additional supervised data. Next, we\ndesign a new loss function that can be directly used to smoothly adjust the\nuniformity of drug and target representations. By directly optimizing the\nuniformity of representations, the representation quality of drugs and targets\ncan be improved. The effectiveness of the above innovative elements is verified\non two real datasets, KIBA and Davis. The excellent performance of GraphCL-DTA\non the above datasets suggests its superiority to the state-of-the-art model.",
          "link": "http://arxiv.org/abs/2307.08989",
          "publishedOn": "2023-07-19T01:53:28.145Z",
          "wordCount": null,
          "title": "GraphCL-DTA: a graph contrastive learning with molecular semantics for drug-target binding affinity prediction. (arXiv:2307.08989v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08712",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Regnani_E/0/1/0/all/0/1\">Emanuele Regnani</a>",
          "description": "This work aims to combine these two fields together by presenting a practical\nimplementation of machine learning to the particular form of mental training\nthat is the art of memory, taken in its competitive version called \"Memory\nSports\". Such a fusion, on the one hand, strives to raise awareness about both\nrealms, while on the other it seeks to encourage research in this mixed field\nas a way to, ultimately, drive forward the development of this seemingly\nunderestimated sport.",
          "link": "http://arxiv.org/abs/2307.08712",
          "publishedOn": "2023-07-19T01:53:27.955Z",
          "wordCount": null,
          "title": "Machine Learning Meets Mental Training -- A Proof of Concept Applied to Memory Sports. (arXiv:2307.08712v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08433",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Eddin_A/0/1/0/all/0/1\">Ahmad Naser Eddin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bono_J/0/1/0/all/0/1\">Jacopo Bono</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aparicio_D/0/1/0/all/0/1\">David Apar&#xed;cio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferreira_H/0/1/0/all/0/1\">Hugo Ferreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ascensao_J/0/1/0/all/0/1\">Jo&#xe3;o Ascens&#xe3;o</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_P/0/1/0/all/0/1\">Pedro Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bizarro_P/0/1/0/all/0/1\">Pedro Bizarro</a>",
          "description": "Many real-world datasets have an underlying dynamic graph structure, where\nentities and their interactions evolve over time. Machine learning models\nshould consider these dynamics in order to harness their full potential in\ndownstream tasks. Previous approaches for graph representation learning have\nfocused on either sampling k-hop neighborhoods, akin to breadth-first search,\nor random walks, akin to depth-first search. However, these methods are\ncomputationally expensive and unsuitable for real-time, low-latency inference\non dynamic graphs. To overcome these limitations, we propose graph-sprints a\ngeneral purpose feature extraction framework for continuous-time-dynamic-graphs\n(CTDGs) that has low latency and is competitive with state-of-the-art, higher\nlatency models. To achieve this, a streaming, low latency approximation to the\nrandom-walk based features is proposed. In our framework, time-aware node\nembeddings summarizing multi-hop information are computed using only single-hop\noperations on the incoming edges. We evaluate our proposed approach on three\nopen-source datasets and two in-house datasets, and compare with three\nstate-of-the-art algorithms (TGN-attn, TGN-ID, Jodie). We demonstrate that our\ngraph-sprints features, combined with a machine learning classifier, achieve\ncompetitive performance (outperforming all baselines for the node\nclassification tasks in five datasets). Simultaneously, graph-sprints\nsignificantly reduce inference latencies, achieving close to an order of\nmagnitude speed-up in our experimental setting.",
          "link": "http://arxiv.org/abs/2307.08433",
          "publishedOn": "2023-07-19T01:53:27.871Z",
          "wordCount": null,
          "title": "From random-walks to graph-sprints: a low-latency node embedding framework on continuous-time dynamic graphs. (arXiv:2307.08433v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09306",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bae_I/0/1/0/all/0/1\">Inhwan Bae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1\">Jean Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeon_H/0/1/0/all/0/1\">Hae-Gon Jeon</a>",
          "description": "Capturing high-dimensional social interactions and feasible futures is\nessential for predicting trajectories. To address this complex nature, several\nattempts have been devoted to reducing the dimensionality of the output\nvariables via parametric curve fitting such as the B\\'ezier curve and B-spline\nfunction. However, these functions, which originate in computer graphics\nfields, are not suitable to account for socially acceptable human dynamics. In\nthis paper, we present EigenTrajectory ($\\mathbb{ET}$), a trajectory prediction\napproach that uses a novel trajectory descriptor to form a compact space, known\nhere as $\\mathbb{ET}$ space, in place of Euclidean space, for representing\npedestrian movements. We first reduce the complexity of the trajectory\ndescriptor via a low-rank approximation. We transform the pedestrians' history\npaths into our $\\mathbb{ET}$ space represented by spatio-temporal principle\ncomponents, and feed them into off-the-shelf trajectory forecasting models. The\ninputs and outputs of the models as well as social interactions are all\ngathered and aggregated in the corresponding $\\mathbb{ET}$ space. Lastly, we\npropose a trajectory anchor-based refinement method to cover all possible\nfutures in the proposed $\\mathbb{ET}$ space. Extensive experiments demonstrate\nthat our EigenTrajectory predictor can significantly improve both the\nprediction accuracy and reliability of existing trajectory forecasting models\non public benchmarks, indicating that the proposed descriptor is suited to\nrepresent pedestrian behaviors. Code is publicly available at\nhttps://github.com/inhwanbae/EigenTrajectory .",
          "link": "http://arxiv.org/abs/2307.09306",
          "publishedOn": "2023-07-19T01:53:27.863Z",
          "wordCount": null,
          "title": "EigenTrajectory: Low-Rank Descriptors for Multi-Modal Trajectory Forecasting. (arXiv:2307.09306v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.04965",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Moussa_C/0/1/0/all/0/1\">Charles Moussa</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gordon_M/0/1/0/all/0/1\">Max Hunter Gordon</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Baczyk_M/0/1/0/all/0/1\">Michal Baczyk</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cerezo_M/0/1/0/all/0/1\">M. Cerezo</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cincio_L/0/1/0/all/0/1\">Lukasz Cincio</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Coles_P/0/1/0/all/0/1\">Patrick J. Coles</a>",
          "description": "Quantum-enhanced data science, also known as quantum machine learning (QML),\nis of growing interest as an application of near-term quantum computers.\nVariational QML algorithms have the potential to solve practical problems on\nreal hardware, particularly when involving quantum data. However, training\nthese algorithms can be challenging and calls for tailored optimization\nprocedures. Specifically, QML applications can require a large shot-count\noverhead due to the large datasets involved. In this work, we advocate for\nsimultaneous random sampling over both the dataset as well as the measurement\noperators that define the loss function. We consider a highly general loss\nfunction that encompasses many QML applications, and we show how to construct\nan unbiased estimator of its gradient. This allows us to propose a shot-frugal\ngradient descent optimizer called Refoqus (REsource Frugal Optimizer for\nQUantum Stochastic gradient descent). Our numerics indicate that Refoqus can\nsave several orders of magnitude in shot cost, even relative to optimizers that\nsample over measurement operators alone.",
          "link": "http://arxiv.org/abs/2211.04965",
          "publishedOn": "2023-07-19T01:53:27.861Z",
          "wordCount": null,
          "title": "Resource frugal optimizer for quantum machine learning. (arXiv:2211.04965v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08798",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ilie_Ablachim_D/0/1/0/all/0/1\">Denis C. Ilie-Ablachim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dumitrescu_B/0/1/0/all/0/1\">Bogdan Dumitrescu</a>",
          "description": "In this paper we present new algorithms for training reduced-size nonlinear\nrepresentations in the Kernel Dictionary Learning (KDL) problem. Standard KDL\nhas the drawback of a large size of the kernel matrix when the data set is\nlarge. There are several ways of reducing the kernel size, notably Nystr\\\"om\nsampling. We propose here a method more in the spirit of dictionary learning,\nwhere the kernel vectors are obtained with a trained sparse representation of\nthe input signals. Moreover, we optimize directly the kernel vectors in the KDL\nprocess, using gradient descent steps. We show with three data sets that our\nalgorithms are able to provide better representations, despite using a small\nnumber of kernel vectors, and also decrease the execution time with respect to\nKDL.",
          "link": "http://arxiv.org/abs/2307.08798",
          "publishedOn": "2023-07-19T01:53:27.848Z",
          "wordCount": null,
          "title": "Reduced Kernel Dictionary Learning. (arXiv:2307.08798v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09312",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hebert_L/0/1/0/all/0/1\">Liam Hebert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahu_G/0/1/0/all/0/1\">Gaurav Sahu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sreenivas_N/0/1/0/all/0/1\">Nanda Kishore Sreenivas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golab_L/0/1/0/all/0/1\">Lukasz Golab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_R/0/1/0/all/0/1\">Robin Cohen</a>",
          "description": "We present the Multi-Modal Discussion Transformer (mDT), a novel multi-modal\ngraph-based transformer model for detecting hate speech in online social\nnetworks. In contrast to traditional text-only methods, our approach to\nlabelling a comment as hate speech centers around the holistic analysis of text\nand images. This is done by leveraging graph transformers to capture the\ncontextual relationships in the entire discussion that surrounds a comment,\nwith interwoven fusion layers to combine text and image embeddings instead of\nprocessing different modalities separately. We compare the performance of our\nmodel to baselines that only process text; we also conduct extensive ablation\nstudies. We conclude with future work for multimodal solutions to deliver\nsocial value in online contexts, arguing that capturing a holistic view of a\nconversation greatly advances the effort to detect anti-social behavior.",
          "link": "http://arxiv.org/abs/2307.09312",
          "publishedOn": "2023-07-19T01:53:27.839Z",
          "wordCount": null,
          "title": "Multi-Modal Discussion Transformer: Integrating Text, Images and Graph Transformers to Detect Hate Speech on Social Media. (arXiv:2307.09312v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09483",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kurkin_A/0/1/0/all/0/1\">Andrii Kurkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hegemann_J/0/1/0/all/0/1\">Jonas Hegemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kordzanganeh_M/0/1/0/all/0/1\">Mo Kordzanganeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melnikov_A/0/1/0/all/0/1\">Alexey Melnikov</a>",
          "description": "Efficient and sustainable power generation is a crucial concern in the energy\nsector. In particular, thermal power plants grapple with accurately predicting\nsteam mass flow, which is crucial for operational efficiency and cost\nreduction. In this study, we use a parallel hybrid neural network architecture\nthat combines a parametrized quantum circuit and a conventional feed-forward\nneural network specifically designed for time-series prediction in industrial\nsettings to enhance predictions of steam mass flow 15 minutes into the future.\nOur results show that the parallel hybrid model outperforms standalone\nclassical and quantum models, achieving more than 5.7 and 4.9 times lower mean\nsquared error (MSE) loss on the test set after training compared to pure\nclassical and pure quantum networks, respectively. Furthermore, the hybrid\nmodel demonstrates smaller relative errors between the ground truth and the\nmodel predictions on the test set, up to 2 times better than the pure classical\nmodel. These findings contribute to the broader scientific understanding of how\nintegrating quantum and classical machine learning techniques can be applied to\nreal-world challenges faced by the energy sector, ultimately leading to\noptimized power plant operations.",
          "link": "http://arxiv.org/abs/2307.09483",
          "publishedOn": "2023-07-19T01:53:27.836Z",
          "wordCount": null,
          "title": "Forecasting the steam mass flow in a powerplant using the parallel hybrid network. (arXiv:2307.09483v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.03209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chenyu You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1\">Weicheng Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_Y/0/1/0/all/0/1\">Yifei Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staib_L/0/1/0/all/0/1\">Lawrence Staib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duncan_J/0/1/0/all/0/1\">James S. Duncan</a>",
          "description": "Integrating high-level semantically correlated contents and low-level\nanatomical features is of central importance in medical image segmentation.\nTowards this end, recent deep learning-based medical segmentation methods have\nshown great promise in better modeling such information. However, convolution\noperators for medical segmentation typically operate on regular grids, which\ninherently blur the high-frequency regions, i.e., boundary regions. In this\nwork, we propose MORSE, a generic implicit neural rendering framework designed\nat an anatomical level to assist learning in medical image segmentation. Our\nmethod is motivated by the fact that implicit neural representation has been\nshown to be more effective in fitting complex signals and solving computer\ngraphics problems than discrete grid-based representation. The core of our\napproach is to formulate medical image segmentation as a rendering problem in\nan end-to-end manner. Specifically, we continuously align the coarse\nsegmentation prediction with the ambiguous coordinate-based point\nrepresentations and aggregate these features to adaptively refine the boundary\nregion. To parallelly optimize multi-scale pixel-level features, we leverage\nthe idea from Mixture-of-Expert (MoE) to design and train our MORSE with a\nstochastic gating mechanism. Our experiments demonstrate that MORSE can work\nwell with different medical segmentation backbones, consistently achieving\ncompetitive performance improvements in both 2D and 3D supervised medical\nsegmentation methods. We also theoretically analyze the superiority of MORSE.",
          "link": "http://arxiv.org/abs/2304.03209",
          "publishedOn": "2023-07-19T01:53:27.786Z",
          "wordCount": null,
          "title": "Implicit Anatomical Rendering for Medical Image Segmentation with Stochastic Experts. (arXiv:2304.03209v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09057",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ryner_M/0/1/0/all/0/1\">Martin Ryner</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kronqvist_J/0/1/0/all/0/1\">Jan Kronqvist</a>, <a href=\"http://arxiv.org/find/math/1/au:+Karlsson_J/0/1/0/all/0/1\">Johan Karlsson</a>",
          "description": "This paper presents a framework for computing the Gromov-Wasserstein problem\nbetween two sets of points in low dimensional spaces, where the discrepancy is\nthe squared Euclidean norm. The Gromov-Wasserstein problem is a generalization\nof the optimal transport problem that finds the assignment between two sets\npreserving pairwise distances as much as possible. This can be used to quantify\nthe similarity between two formations or shapes, a common problem in AI and\nmachine learning. The problem can be formulated as a Quadratic Assignment\nProblem (QAP), which is in general computationally intractable even for small\nproblems. Our framework addresses this challenge by reformulating the QAP as an\noptimization problem with a low-dimensional domain, leveraging the fact that\nthe problem can be expressed as a concave quadratic optimization problem with\nlow rank. The method scales well with the number of points, and it can be used\nto find the global solution for large-scale problems with thousands of points.\nWe compare the computational complexity of our approach with state-of-the-art\nmethods on synthetic problems and apply it to a near-symmetrical problem which\nis of particular interest in computational biology.",
          "link": "http://arxiv.org/abs/2307.09057",
          "publishedOn": "2023-07-19T01:53:27.745Z",
          "wordCount": null,
          "title": "Globally solving the Gromov-Wasserstein problem for point clouds in low dimensional Euclidean spaces. (arXiv:2307.09057v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09337",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Scherbela_M/0/1/0/all/0/1\">Michael Scherbela</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gerard_L/0/1/0/all/0/1\">Leon Gerard</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Grohs_P/0/1/0/all/0/1\">Philipp Grohs</a>",
          "description": "Obtaining accurate solutions to the Schr\\\"odinger equation is the key\nchallenge in computational quantum chemistry. Deep-learning-based Variational\nMonte Carlo (DL-VMC) has recently outperformed conventional approaches in terms\nof accuracy, but only at large computational cost. Whereas in many domains\nmodels are trained once and subsequently applied for inference, accurate DL-VMC\nso far requires a full optimization for every new problem instance, consuming\nthousands of GPUhs even for small molecules. We instead propose a DL-VMC model\nwhich has been pre-trained using self-supervised wavefunction optimization on a\nlarge and chemically diverse set of molecules. Applying this model to new\nmolecules without any optimization, yields wavefunctions and absolute energies\nthat outperform established methods such as CCSD(T)-2Z. To obtain accurate\nrelative energies, only few fine-tuning steps of this base model are required.\nWe accomplish this with a fully end-to-end machine-learned model, consisting of\nan improved geometry embedding architecture and an existing SE(3)-equivariant\nmodel to represent molecular orbitals. Combining this architecture with\ncontinuous sampling of geometries, we improve zero-shot accuracy by two orders\nof magnitude compared to the state of the art. We extensively evaluate the\naccuracy, scalability and limitations of our base model on a wide variety of\ntest systems.",
          "link": "http://arxiv.org/abs/2307.09337",
          "publishedOn": "2023-07-19T01:53:27.212Z",
          "wordCount": 711,
          "title": "Variational Monte Carlo on a Budget -- Fine-tuning pre-trained Neural Wavefunctions. (arXiv:2307.09337v1 [physics.chem-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.09205",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1\">Fan Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magliacane_S/0/1/0/all/0/1\">Sara Magliacane</a>",
          "description": "In many reinforcement learning tasks, the agent has to learn to interact with\nmany objects of different types and generalize to unseen combinations and\nnumbers of objects. Often a task is a composition of previously learned tasks\n(e.g. block stacking). These are examples of compositional generalization, in\nwhich we compose object-centric representations to solve complex tasks. Recent\nworks have shown the benefits of object-factored representations and\nhierarchical abstractions for improving sample efficiency in these settings. On\nthe other hand, these methods do not fully exploit the benefits of\nfactorization in terms of object attributes. In this paper, we address this\nopportunity and introduce the Dynamic Attribute FacTored RL (DAFT-RL)\nframework. In DAFT-RL, we leverage object-centric representation learning to\nextract objects from visual inputs. We learn to classify them in classes and\ninfer their latent parameters. For each class of object, we learn a class\ntemplate graph that describes how the dynamics and reward of an object of this\nclass factorize according to its attributes. We also learn an interaction\npattern graph that describes how objects of different classes interact with\neach other at the attribute level. Through these graphs and a dynamic\ninteraction graph that models the interactions between objects, we can learn a\npolicy that can then be directly applied in a new environment by just\nestimating the interactions and latent parameters. We evaluate DAFT-RL in three\nbenchmark datasets and show our framework outperforms the state-of-the-art in\ngeneralizing across unseen objects with varying attributes and latent\nparameters, as well as in the composition of previously learned tasks.",
          "link": "http://arxiv.org/abs/2307.09205",
          "publishedOn": "2023-07-19T01:53:27.207Z",
          "wordCount": 764,
          "title": "Learning Dynamic Attribute-factored World Models for Efficient Multi-object Reinforcement Learning. (arXiv:2307.09205v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.09218",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhenyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1\">Enneng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Heng Huang</a>",
          "description": "Forgetting refers to the loss or deterioration of previously acquired\ninformation or knowledge. While the existing surveys on forgetting have\nprimarily focused on continual learning, forgetting is a prevalent phenomenon\nobserved in various other research domains within deep learning. Forgetting\nmanifests in research fields such as generative models due to generator shifts,\nand federated learning due to heterogeneous data distributions across clients.\nAddressing forgetting encompasses several challenges, including balancing the\nretention of old task knowledge with fast learning of new tasks, managing task\ninterference with conflicting goals, and preventing privacy leakage, etc.\nMoreover, most existing surveys on continual learning implicitly assume that\nforgetting is always harmful. In contrast, our survey argues that forgetting is\na double-edged sword and can be beneficial and desirable in certain cases, such\nas privacy-preserving scenarios. By exploring forgetting in a broader context,\nwe aim to present a more nuanced understanding of this phenomenon and highlight\nits potential advantages. Through this comprehensive survey, we aspire to\nuncover potential solutions by drawing upon ideas and approaches from various\nfields that have dealt with forgetting. By examining forgetting beyond its\nconventional boundaries, in future work, we hope to encourage the development\nof novel strategies for mitigating, harnessing, or even embracing forgetting in\nreal applications. A comprehensive list of papers about forgetting in various\nresearch fields is available at\n\\url{https://github.com/EnnengYang/Awesome-Forgetting-in-Deep-Learning}.",
          "link": "http://arxiv.org/abs/2307.09218",
          "publishedOn": "2023-07-19T01:53:27.088Z",
          "wordCount": 751,
          "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning. (arXiv:2307.09218v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.09080",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Farooq_M/0/1/0/all/0/1\">Muhammad Shoaib Farooq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayat_A/0/1/0/all/0/1\">Azeen Ahmed Hayat</a>",
          "description": "Energy shortfall and electricity load shedding are the main problems for\ndeveloping countries. The main causes are lack of management in the energy\nsector and the use of non-renewable energy sources. The improved energy\nmanagement and use of renewable sources can be significant to resolve energy\ncrisis. It is necessary to increase the use of renewable energy sources (RESs)\nto meet the increasing energy demand due to high prices of fossil-fuel based\nenergy. Federated learning (FL) is the most emerging technique in the field of\nartificial intelligence. Federated learning helps to generate global model at\nserver side by ensemble locally trained models at remote edges sites while\npreserving data privacy. The global model used to predict energy demand to\nsatisfy the needs of consumers. In this article, we have proposed Blockchain\nbased safe distributed ledger technology for transaction of data between\nprosumer and consumer to ensure their transparency, traceability and security.\nFurthermore, we have also proposed a Federated learning model to forecast the\nenergy requirements of consumer and prosumer. Moreover, Blockchain has been\nused to store excess energy data from prosumer for better management of energy\nbetween prosumer and grid. Lastly, the experiment results revealed that\nrenewable energy sources have produced better and comparable results to other\nnon-renewable energy resources.",
          "link": "http://arxiv.org/abs/2307.09080",
          "publishedOn": "2023-07-19T01:53:27.067Z",
          "wordCount": 740,
          "title": "A Federated learning model for Electric Energy management using Blockchain Technology. (arXiv:2307.09080v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08811",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mamun_M/0/1/0/all/0/1\">Md Abdullah Al Mamun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alam_Q/0/1/0/all/0/1\">Quazi Mishkatul Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaigani_E/0/1/0/all/0/1\">Erfan Shaigani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaree_P/0/1/0/all/0/1\">Pedram Zaree</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alouani_I/0/1/0/all/0/1\">Ihsen Alouani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abu_Ghazaleh_N/0/1/0/all/0/1\">Nael Abu-Ghazaleh</a>",
          "description": "Machine learning (ML) models are overparameterized to support generality and\navoid overfitting. Prior works have shown that these additional parameters can\nbe used for both malicious (e.g., hiding a model covertly within a trained\nmodel) and beneficial purposes (e.g., watermarking a model). In this paper, we\npropose a novel information theoretic perspective of the problem; we consider\nthe ML model as a storage channel with a capacity that increases with\noverparameterization. Specifically, we consider a sender that embeds arbitrary\ninformation in the model at training time, which can be extracted by a receiver\nwith a black-box access to the deployed model. We derive an upper bound on the\ncapacity of the channel based on the number of available parameters. We then\nexplore black-box write and read primitives that allow the attacker to: (i)\nstore data in an optimized way within the model by augmenting the training data\nat the transmitter side, and (ii) to read it by querying the model after it is\ndeployed. We also analyze the detectability of the writing primitive and\nconsider a new version of the problem which takes information storage\ncovertness into account. Specifically, to obtain storage covertness, we\nintroduce a new constraint such that the data augmentation used for the write\nprimitives minimizes the distribution shift with the initial (baseline task)\ndistribution. This constraint introduces a level of \"interference\" with the\ninitial task, thereby limiting the channel's effective capacity. Therefore, we\ndevelop optimizations to improve the capacity in this case, including a novel\nML-specific substitution based error correction protocol. We believe that the\nproposed modeling of the problem offers new tools to better understand and\nmitigate potential vulnerabilities of ML, especially in the context of\nincreasingly large models.",
          "link": "http://arxiv.org/abs/2307.08811",
          "publishedOn": "2023-07-19T01:53:27.062Z",
          "wordCount": 811,
          "title": "DeepMem: ML Models as storage channels and their (mis-)applications. (arXiv:2307.08811v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.09165",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shijie Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1\">Fei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1\">Zhen Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xu-Yao Zhang</a>",
          "description": "Efficiency and trustworthiness are two eternal pursuits when applying deep\nlearning in real-world applications. With regard to efficiency, dataset\ndistillation (DD) endeavors to reduce training costs by distilling the large\ndataset into a tiny synthetic dataset. However, existing methods merely\nconcentrate on in-distribution (InD) classification in a closed-world setting,\ndisregarding out-of-distribution (OOD) samples. On the other hand, OOD\ndetection aims to enhance models' trustworthiness, which is always\ninefficiently achieved in full-data settings. For the first time, we\nsimultaneously consider both issues and propose a novel paradigm called\nTrustworthy Dataset Distillation (TrustDD). By distilling both InD samples and\noutliers, the condensed datasets are capable to train models competent in both\nInD classification and OOD detection. To alleviate the requirement of real\noutlier data and make OOD detection more practical, we further propose to\ncorrupt InD samples to generate pseudo-outliers and introduce Pseudo-Outlier\nExposure (POE). Comprehensive experiments on various settings demonstrate the\neffectiveness of TrustDD, and the proposed POE surpasses state-of-the-art\nmethod Outlier Exposure (OE). Compared with the preceding DD, TrustDD is more\ntrustworthy and applicable to real open-world scenarios. Our code will be\npublicly available.",
          "link": "http://arxiv.org/abs/2307.09165",
          "publishedOn": "2023-07-19T01:53:27.057Z",
          "wordCount": 685,
          "title": "Towards Trustworthy Dataset Distillation. (arXiv:2307.09165v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.09025",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Cao_H/0/1/0/all/0/1\">Hanyan Cao</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Pan_F/0/1/0/all/0/1\">Feng Pan</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Wang_Y/0/1/0/all/0/1\">Yijia Wang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Zhang_P/0/1/0/all/0/1\">Pan Zhang</a>",
          "description": "We propose a general framework for decoding quantum error-correcting codes\nwith generative modeling. The model utilizes autoregressive neural networks,\nspecifically Transformers, to learn the joint probability of logical operators\nand syndromes. This training is in an unsupervised way, without the need for\nlabeled training data, and is thus referred to as pre-training. After the\npre-training, the model can efficiently compute the likelihood of logical\noperators for any given syndrome, using maximum likelihood decoding. It can\ndirectly generate the most-likely logical operators with computational\ncomplexity $\\mathcal O(2k)$ in the number of logical qubits $k$, which is\nsignificantly better than the conventional maximum likelihood decoding\nalgorithms that require $\\mathcal O(4^k)$ computation. Based on the pre-trained\nmodel, we further propose refinement to achieve more accurately the likelihood\nof logical operators for a given syndrome by directly sampling the stabilizer\noperators. We perform numerical experiments on stabilizer codes with small code\ndistances, using both depolarizing error models and error models with\ncorrelated noise. The results show that our approach provides significantly\nbetter decoding accuracy than the minimum weight perfect matching and\nbelief-propagation-based algorithms. Our framework is general and can be\napplied to any error model and quantum codes with different topologies such as\nsurface codes and quantum LDPC codes. Furthermore, it leverages the\nparallelization capabilities of GPUs, enabling simultaneous decoding of a large\nnumber of syndromes. Our approach sheds light on the efficient and accurate\ndecoding of quantum error-correcting codes using generative artificial\nintelligence and modern computational power.",
          "link": "http://arxiv.org/abs/2307.09025",
          "publishedOn": "2023-07-19T01:53:27.017Z",
          "wordCount": 761,
          "title": "qecGPT: decoding Quantum Error-correcting Codes with Generative Pre-trained Transformers. (arXiv:2307.09025v1 [quant-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.09019",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingkui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yiqin Zhang</a>",
          "description": "Time series prediction plays a crucial role in various industrial fields. In\nrecent years, neural networks with a transformer backbone have achieved\nremarkable success in many domains, including computer vision and NLP. In time\nseries analysis domain, some studies have suggested that even the simplest MLP\nnetworks outperform advanced transformer-based networks on time series forecast\ntasks. However, we believe these findings indicate there to be low-rank\nproperties in time series sequences. In this paper, we consider the low-pass\ncharacteristics of transformers and try to incorporate the advantages of MLP.\nWe adopt skip-layer connections inspired by Unet into traditional transformer\nbackbone, thus preserving high-frequency context from input to output, namely\nU-shaped Transformer. We introduce patch merge and split operation to extract\nfeatures with different scales and use larger datasets to fully make use of the\ntransformer backbone. Our experiments demonstrate that the model performs at an\nadvanced level across multiple datasets with relatively low cost.",
          "link": "http://arxiv.org/abs/2307.09019",
          "publishedOn": "2023-07-19T01:53:26.949Z",
          "wordCount": 668,
          "title": "U-shaped Transformer: Retain High Frequency Context in Time Series Analysis. (arXiv:2307.09019v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08801",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Runge_F/0/1/0/all/0/1\">Frederic Runge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Franke_J/0/1/0/all/0/1\">J&#xf6;rg K. H. Franke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1\">Frank Hutter</a>",
          "description": "Experimental screening and selection pipelines for the discovery of novel\nriboswitches are expensive, time-consuming, and inefficient. Using\ncomputational methods to reduce the number of candidates for the screen could\ndrastically decrease these costs. However, existing computational approaches do\nnot fully satisfy all requirements for the design of such initial screening\nlibraries. In this work, we present a new method, libLEARNA, capable of\nproviding RNA focus libraries of diverse variable-length qualified candidates.\nOur novel structure-based design approach considers global properties as well\nas desired sequence and structure features. We demonstrate the benefits of our\nmethod by designing theophylline riboswitch libraries, following a previously\npublished protocol, and yielding 30% more unique high-quality candidates.",
          "link": "http://arxiv.org/abs/2307.08801",
          "publishedOn": "2023-07-19T01:53:26.915Z",
          "wordCount": 619,
          "title": "Towards Automated Design of Riboswitches. (arXiv:2307.08801v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08863",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cooijmans_T/0/1/0/all/0/1\">Tim Cooijmans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aghajohari_M/0/1/0/all/0/1\">Milad Aghajohari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1\">Aaron Courville</a>",
          "description": "Gradient-based learning in multi-agent systems is difficult because the\ngradient derives from a first-order model which does not account for the\ninteraction between agents' learning processes. LOLA (arXiv:1709.04326)\naccounts for this by differentiating through one step of optimization. We\nextend the ideas of LOLA and develop a fully-general value-based approach to\noptimization. At the core is a function we call the meta-value, which at each\npoint in joint-policy space gives for each agent a discounted sum of its\nobjective over future optimization steps. We argue that the gradient of the\nmeta-value gives a more reliable improvement direction than the gradient of the\noriginal objective, because the meta-value derives from empirical observations\nof the effects of optimization. We show how the meta-value can be approximated\nby training a neural network to minimize TD error along optimization\ntrajectories in which agents follow the gradient of the meta-value. We analyze\nthe behavior of our method on the Logistic Game and on the Iterated Prisoner's\nDilemma.",
          "link": "http://arxiv.org/abs/2307.08863",
          "publishedOn": "2023-07-19T01:53:26.910Z",
          "wordCount": 681,
          "title": "Meta-Value Learning: a General Framework for Learning with Learning Awareness. (arXiv:2307.08863v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08949",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_T/0/1/0/all/0/1\">Tianyao Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yingxuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yunlong Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xiaofeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1\">Zhen Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yongqiang Yang</a>",
          "description": "Multi-tenancy in public clouds may lead to co-location interference on shared\nresources, which possibly results in performance degradation of cloud\napplications. Cloud providers want to know when such events happen and how\nserious the degradation is, to perform interference-aware migrations and\nalleviate the problem. However, virtual machines (VM) in\nInfrastructure-as-a-Service public clouds are black-boxes to providers, where\napplication-level performance information cannot be acquired. This makes\nperformance monitoring intensely challenging as cloud providers can only rely\non low-level metrics such as CPU usage and hardware counters.\n\nWe propose a novel machine learning framework, Alioth, to monitor the\nperformance degradation of cloud applications. To feed the data-hungry models,\nwe first elaborate interference generators and conduct comprehensive\nco-location experiments on a testbed to build Alioth-dataset which reflects the\ncomplexity and dynamicity in real-world scenarios. Then we construct Alioth by\n(1) augmenting features via recovering low-level metrics under no interference\nusing denoising auto-encoders, (2) devising a transfer learning model based on\ndomain adaptation neural network to make models generalize on test cases unseen\nin offline training, and (3) developing a SHAP explainer to automate feature\nselection and enhance model interpretability. Experiments show that Alioth\nachieves an average mean absolute error of 5.29% offline and 10.8% when testing\non applications unseen in the training stage, outperforming the baseline\nmethods. Alioth is also robust in signaling quality-of-service violation under\ndynamicity. Finally, we demonstrate a possible application of Alioth's\ninterpretability, providing insights to benefit the decision-making of cloud\noperators. The dataset and code of Alioth have been released on GitHub.",
          "link": "http://arxiv.org/abs/2307.08949",
          "publishedOn": "2023-07-19T01:53:26.905Z",
          "wordCount": 803,
          "title": "Alioth: A Machine Learning Based Interference-Aware Performance Monitor for Multi-Tenancy Applications in Public Cloud. (arXiv:2307.08949v1 [cs.DC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08941",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wei_T/0/1/0/all/0/1\">Tianxin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zeming Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yifan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jingrui He</a>",
          "description": "Fine-tuning a pre-trained language model (PLM) emerges as the predominant\nstrategy in many natural language processing applications. However, even\nfine-tuning the PLMs and doing inference are expensive, especially on edge\ndevices with low computing power. Some general approaches (e.g. quantization\nand distillation) have been widely studied to reduce the compute/memory of PLM\nfine-tuning, while very few one-shot compression techniques are explored. In\nthis paper, we investigate the neural tangent kernel (NTK)--which reveals the\ngradient descent dynamics of neural networks--of the multilayer perceptrons\n(MLP) modules in a PLM and propose to coin a lightweight PLM through\nNTK-approximating MLP fusion. To achieve this, we reconsider the MLP as a\nbundle of sub-MLPs, and cluster them into a given number of centroids, which\ncan then be restored as a compressed MLP and surprisingly shown to well\napproximate the NTK of the original PLM. Extensive experiments of PLM\nfine-tuning on both natural language understanding (NLU) and generation (NLG)\ntasks are provided to verify the effectiveness of the proposed method MLP\nfusion. Our code is available at https://github.com/weitianxin/MLP_Fusion.",
          "link": "http://arxiv.org/abs/2307.08941",
          "publishedOn": "2023-07-19T01:53:26.886Z",
          "wordCount": 688,
          "title": "NTK-approximating MLP Fusion for Efficient Language Model Fine-tuning. (arXiv:2307.08941v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08880",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Salem_N/0/1/0/all/0/1\">Nosseiba Ben Salem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bennani_Y/0/1/0/all/0/1\">Younes Bennani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karkazan_J/0/1/0/all/0/1\">Joseph Karkazan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barbara_A/0/1/0/all/0/1\">Abir Barbara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dacheux_C/0/1/0/all/0/1\">Charles Dacheux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gregory_T/0/1/0/all/0/1\">Thomas Gregory</a>",
          "description": "Deep learning-based applications have seen a lot of success in recent years.\nText, audio, image, and video have all been explored with great success using\ndeep learning approaches. The use of convolutional neural networks (CNN) in\ncomputer vision, in particular, has yielded reliable results. In order to\nachieve these results, a large amount of data is required. However, the dataset\ncannot always be accessible. Moreover, annotating data can be difficult and\ntime-consuming. Self-training is a semi-supervised approach that managed to\nalleviate this problem and achieve state-of-the-art performances. Theoretical\nanalysis even proved that it may result in a better generalization than a\nnormal classifier. Another problem neural networks can face is the increasing\ncomplexity of modern problems, requiring a high computational and storage cost.\nOne way to mitigate this issue, a strategy that has been inspired by human\ncognition known as modular learning, can be employed. The principle of the\napproach is to decompose a complex problem into simpler sub-tasks. This\napproach has several advantages, including faster learning, better\ngeneralization, and enables interpretability.\n\nIn the first part of this paper, we introduce and evaluate different\narchitectures of modular learning for Dorsal Capsulo-Scapholunate Septum (DCSS)\ninstability classification. Our experiments have shown that modular learning\nimproves performances compared to non-modular systems. Moreover, we found that\nweighted modular, that is to weight the output using the probabilities from the\ngating module, achieved an almost perfect classification. In the second part,\nwe present our approach for data labeling and segmentation with self-training\napplied on shoulder arthroscopy images.",
          "link": "http://arxiv.org/abs/2307.08880",
          "publishedOn": "2023-07-19T01:53:26.880Z",
          "wordCount": 766,
          "title": "Modular Neural Network Approaches for Surgical Image Recognition. (arXiv:2307.08880v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Quanquan C. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivas_V/0/1/0/all/0/1\">Vaidehi Srinivas</a>",
          "description": "The main bottleneck in designing efficient dynamic algorithms is the unknown\nnature of the update sequence. In particular, there are some problems, like\n3-vertex connectivity, planar digraph all pairs shortest paths, and others,\nwhere the separation in runtime between the best partially dynamic solutions\nand the best fully dynamic solutions is polynomial, sometimes even exponential.\n\nIn this paper, we formulate the predicted-deletion dynamic model, motivated\nby a recent line of empirical work about predicting edge updates in dynamic\ngraphs. In this model, edges are inserted and deleted online, and when an edge\nis inserted, it is accompanied by a \"prediction\" of its deletion time. This\nmodels real world settings where services may have access to historical data or\nother information about an input and can subsequently use such information make\npredictions about user behavior. The model is also of theoretical interest, as\nit interpolates between the partially dynamic and fully dynamic settings, and\nprovides a natural extension of the algorithms with predictions paradigm to the\ndynamic setting.\n\nWe give a novel framework for this model that \"lifts\" partially dynamic\nalgorithms into the fully dynamic setting with little overhead. We use our\nframework to obtain improved efficiency bounds over the state-of-the-art\ndynamic algorithms for a variety of problems. In particular, we design\nalgorithms that have amortized update time that scales with a partially dynamic\nalgorithm, with high probability, when the predictions are of high quality. On\nthe flip side, our algorithms do no worse than existing fully-dynamic\nalgorithms when the predictions are of low quality. Furthermore, our algorithms\nexhibit a graceful trade-off between the two cases. Thus, we are able to take\nadvantage of ML predictions asymptotically \"for free.''",
          "link": "http://arxiv.org/abs/2307.08890",
          "publishedOn": "2023-07-19T01:53:26.874Z",
          "wordCount": 792,
          "title": "The Predicted-Deletion Dynamic Model: Taking Advantage of ML Predictions, for Free. (arXiv:2307.08890v1 [cs.DS])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08796",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ilie_Ablachim_D/0/1/0/all/0/1\">Denis C. Ilie-Ablachim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dumitrescu_B/0/1/0/all/0/1\">Bogdan Dumitrescu</a>",
          "description": "In this paper we present a new classification method based on Dictionary\nLearning (DL). The main contribution consists of a kernel version of incoherent\nDL, derived from its standard linear counterpart. We also propose an\nimprovement of the AK-SVD algorithm concerning the representation update. Our\nalgorithms are tested on several popular databases of classification problems.",
          "link": "http://arxiv.org/abs/2307.08796",
          "publishedOn": "2023-07-19T01:53:26.868Z",
          "wordCount": 573,
          "title": "Classification with Incoherent Kernel Dictionary Learning. (arXiv:2307.08796v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08822",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Loli_R/0/1/0/all/0/1\">Rafael Cerna Loli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Clerckx_B/0/1/0/all/0/1\">Bruno Clerckx</a>",
          "description": "In this letter, we propose the use of a meta-learning based precoder\noptimization framework to directly optimize the Rate-Splitting Multiple Access\n(RSMA) precoders with partial Channel State Information at the Transmitter\n(CSIT). By exploiting the overfitting of the compact neural network to maximize\nthe explicit Average Sum-Rate (ASR) expression, we effectively bypass the need\nfor any other training data while minimizing the total running time. Numerical\nresults reveal that the meta-learning based solution achieves similar ASR\nperformance to conventional precoder optimization in medium-scale scenarios,\nand significantly outperforms sub-optimal low complexity precoder algorithms in\nthe large-scale regime.",
          "link": "http://arxiv.org/abs/2307.08822",
          "publishedOn": "2023-07-19T01:53:26.849Z",
          "wordCount": 615,
          "title": "A Meta-Learning Based Precoder Optimization Framework for Rate-Splitting Multiple Access. (arXiv:2307.08822v1 [eess.SP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1\">Ruida Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1\">Min Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalathil_D/0/1/0/all/0/1\">Dileep Kalathil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1\">P. R. Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_C/0/1/0/all/0/1\">Chao Tian</a>",
          "description": "We study robust reinforcement learning (RL) with the goal of determining a\nwell-performing policy that is robust against model mismatch between the\ntraining simulator and the testing environment. Previous policy-based robust RL\nalgorithms mainly focus on the tabular setting under uncertainty sets that\nfacilitate robust policy evaluation, but are no longer tractable when the\nnumber of states scales up. To this end, we propose two novel uncertainty set\nformulations, one based on double sampling and the other on an integral\nprobability metric. Both make large-scale robust RL tractable even when one\nonly has access to a simulator. We propose a robust natural actor-critic (RNAC)\napproach that incorporates the new uncertainty sets and employs function\napproximation. We provide finite-time convergence guarantees for the proposed\nRNAC algorithm to the optimal robust policy within the function approximation\nerror. Finally, we demonstrate the robust performance of the policy learned by\nour proposed RNAC approach in multiple MuJoCo environments and a real-world\nTurtleBot navigation task.",
          "link": "http://arxiv.org/abs/2307.08875",
          "publishedOn": "2023-07-19T01:53:26.844Z",
          "wordCount": 682,
          "title": "Natural Actor-Critic for Robust Reinforcement Learning with Function Approximation. (arXiv:2307.08875v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08933",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sequeira_P/0/1/0/all/0/1\">Pedro Sequeira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gervasio_M/0/1/0/all/0/1\">Melinda Gervasio</a>",
          "description": "In recent years, advances in deep learning have resulted in a plethora of\nsuccesses in the use of reinforcement learning (RL) to solve complex sequential\ndecision tasks with high-dimensional inputs. However, existing systems lack the\nnecessary mechanisms to provide humans with a holistic view of their\ncompetence, presenting an impediment to their adoption, particularly in\ncritical applications where the decisions an agent makes can have significant\nconsequences. Yet, existing RL-based systems are essentially competency-unaware\nin that they lack the necessary interpretation mechanisms to allow human\noperators to have an insightful, holistic view of their competency. Towards\nmore explainable Deep RL (xDRL), we propose a new framework based on analyses\nof interestingness. Our tool provides various measures of RL agent competence\nstemming from interestingness analysis and is applicable to a wide range of RL\nalgorithms, natively supporting the popular RLLib toolkit. We showcase the use\nof our framework by applying the proposed pipeline in a set of scenarios of\nvarying complexity. We empirically assess the capability of the approach in\nidentifying agent behavior patterns and competency-controlling conditions, and\nthe task elements mostly responsible for an agent's competence, based on global\nand local analyses of interestingness. Overall, we show that our framework can\nprovide agent designers with insights about RL agent competence, both their\ncapabilities and limitations, enabling more informed decisions about\ninterventions, additional training, and other interactions in collaborative\nhuman-machine settings.",
          "link": "http://arxiv.org/abs/2307.08933",
          "publishedOn": "2023-07-19T01:53:26.830Z",
          "wordCount": 775,
          "title": "IxDRL: A Novel Explainable Deep Reinforcement Learning Toolkit based on Analyses of Interestingness. (arXiv:2307.08933v1 [cs.AI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08913",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zeen Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_X/0/1/0/all/0/1\">Xingzhe Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingyao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiang_W/0/1/0/all/0/1\">Wenwen Qiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Changwen Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1\">Fuchun Sun</a>",
          "description": "In recent years, self-supervised learning (SSL) has emerged as a promising\napproach for extracting valuable representations from unlabeled data. One\nsuccessful SSL method is contrastive learning, which aims to bring positive\nexamples closer while pushing negative examples apart. Many current contrastive\nlearning approaches utilize a parameterized projection head. Through a\ncombination of empirical analysis and theoretical investigation, we provide\ninsights into the internal mechanisms of the projection head and its\nrelationship with the phenomenon of dimensional collapse. Our findings\ndemonstrate that the projection head enhances the quality of representations by\nperforming contrastive loss in a projected subspace. Therefore, we propose an\nassumption that only a subset of features is necessary when minimizing the\ncontrastive loss of a mini-batch of data. Theoretical analysis further suggests\nthat a sparse projection head can enhance generalization, leading us to\nintroduce SparseHead - a regularization term that effectively constrains the\nsparsity of the projection head, and can be seamlessly integrated with any\nself-supervised learning (SSL) approaches. Our experimental results validate\nthe effectiveness of SparseHead, demonstrating its ability to improve the\nperformance of existing contrastive methods.",
          "link": "http://arxiv.org/abs/2307.08913",
          "publishedOn": "2023-07-19T01:53:26.825Z",
          "wordCount": 705,
          "title": "Towards the Sparseness of Projection Head in Self-Supervised Learning. (arXiv:2307.08913v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08800",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Lipnitskaya_S/0/1/0/all/0/1\">Sofya Lipnitskaya</a>",
          "description": "The regulAS software package is a bioinformatics tool designed to support\ncomputational biology researchers in investigating regulatory mechanisms of\nsplicing alterations through integrative analysis of large-scale RNA-Seq data\nfrom cancer and healthy human donors, characterized by TCGA and GTEx projects.\nThis technical report provides a comprehensive overview of regulAS, focusing on\nits core functionality, basic modules, experiment configuration, further\nextensibility and customisation.\n\nThe core functionality of regulAS enables the automation of computational\nexperiments, efficient results storage and processing, and streamlined workflow\nmanagement. Integrated basic modules extend regulAS with features such as\nRNA-Seq data retrieval from the public multi-omics UCSC Xena data repository,\npredictive modeling and feature ranking capabilities using the scikit-learn\npackage, and flexible reporting generation for analysing gene expression\nprofiles and relevant modulations of alternative splicing aberrations across\ntissues and cancer types. Experiment configuration is handled through YAML\nfiles with the Hydra and OmegaConf libraries, offering a user-friendly\napproach. Additionally, regulAS allows for the development and integration of\ncustom modules to handle specialized tasks.\n\nIn conclusion, regulAS provides an automated solution for alternative\nsplicing and cancer biology studies, enhancing efficiency, reproducibility, and\ncustomization of experimental design, while the extensibility of the pipeline\nenables researchers to further tailor the software package to their specific\nneeds. Source code is available under the MIT license at\nhttps://github.com/slipnitskaya/regulAS.",
          "link": "http://arxiv.org/abs/2307.08800",
          "publishedOn": "2023-07-19T01:53:26.808Z",
          "wordCount": 745,
          "title": "regulAS: A Bioinformatics Tool for the Integrative Analysis of Alternative Splicing Regulome using RNA-Seq data. (arXiv:2307.08800v1 [q-bio.GN])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08881",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yasir_M/0/1/0/all/0/1\">Mustafa Yasir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palowitch_J/0/1/0/all/0/1\">John Palowitch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsitsulin_A/0/1/0/all/0/1\">Anton Tsitsulin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_Thanh_L/0/1/0/all/0/1\">Long Tran-Thanh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perozzi_B/0/1/0/all/0/1\">Bryan Perozzi</a>",
          "description": "Despite a surge in interest in GNN development, homogeneity in benchmarking\ndatasets still presents a fundamental issue to GNN research. GraphWorld is a\nrecent solution which uses the Stochastic Block Model (SBM) to generate diverse\npopulations of synthetic graphs for benchmarking any GNN task. Despite its\nsuccess, the SBM imposed fundamental limitations on the kinds of graph\nstructure GraphWorld could create.\n\nIn this work we examine how two additional synthetic graph generators can\nimprove GraphWorld's evaluation; LFR, a well-established model in the graph\nclustering literature and CABAM, a recent adaptation of the Barabasi-Albert\nmodel tailored for GNN benchmarking. By integrating these generators, we\nsignificantly expand the coverage of graph space within the GraphWorld\nframework while preserving key graph properties observed in real-world\nnetworks. To demonstrate their effectiveness, we generate 300,000 graphs to\nbenchmark 11 GNN models on a node classification task. We find GNN performance\nvariations in response to homophily, degree distribution and feature signal.\nBased on these findings, we classify models by their sensitivity to the new\ngenerators under these properties. Additionally, we release the extensions made\nto GraphWorld on the GitHub repository, offering further evaluation of GNN\nperformance on new graphs.",
          "link": "http://arxiv.org/abs/2307.08881",
          "publishedOn": "2023-07-19T01:53:26.473Z",
          "wordCount": 726,
          "title": "Examining the Effects of Degree Distribution and Homophily in Graph Learning Models. (arXiv:2307.08881v1 [cs.SI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08910",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huiyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeh_C/0/1/0/all/0/1\">Chin-Chia Michael Yeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yujie Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junpeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_V/0/1/0/all/0/1\">Vivian Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_M/0/1/0/all/0/1\">Mahashweta Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hao Yang</a>",
          "description": "Graph Neural Networks (GNNs) have achieved impressive performance in\ncollaborative filtering. However, GNNs tend to yield inferior performance when\nthe distributions of training and test data are not aligned well. Also,\ntraining GNNs requires optimizing non-convex neural networks with an abundance\nof local and global minima, which may differ widely in their performance at\ntest time. Thus, it is essential to choose the minima carefully. Here we\npropose an effective training schema, called {gSAM}, under the principle that\nthe \\textit{flatter} minima has a better generalization ability than the\n\\textit{sharper} ones. To achieve this goal, gSAM regularizes the flatness of\nthe weight loss landscape by forming a bi-level optimization: the outer problem\nconducts the standard model training while the inner problem helps the model\njump out of the sharp minima. Experimental results show the superiority of our\ngSAM.",
          "link": "http://arxiv.org/abs/2307.08910",
          "publishedOn": "2023-07-19T01:53:26.427Z",
          "wordCount": 638,
          "title": "Sharpness-Aware Graph Collaborative Filtering. (arXiv:2307.08910v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingkai Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1\">Jiaming Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Haotian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_Y/0/1/0/all/0/1\">Yuchen Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prakash_B/0/1/0/all/0/1\">B. Aditya Prakash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>",
          "description": "Diffusion-based graph generative models have recently obtained promising\nresults for graph generation. However, existing diffusion-based graph\ngenerative models are mostly one-shot generative models that apply Gaussian\ndiffusion in the dequantized adjacency matrix space. Such a strategy can suffer\nfrom difficulty in model training, slow sampling speed, and incapability of\nincorporating constraints. We propose an \\emph{autoregressive diffusion} model\nfor graph generation. Unlike existing methods, we define a node-absorbing\ndiffusion process that operates directly in the discrete graph space. For\nforward diffusion, we design a \\emph{diffusion ordering network}, which learns\na data-dependent node absorbing ordering from graph topology. For reverse\ngeneration, we design a \\emph{denoising network} that uses the reverse node\nordering to efficiently reconstruct the graph by predicting the node type of\nthe new node and its edges with previously denoised nodes at a time. Based on\nthe permutation invariance of graph, we show that the two networks can be\njointly trained by optimizing a simple lower bound of data likelihood. Our\nexperiments on six diverse generic graph datasets and two molecule datasets\nshow that our model achieves better or comparable generation performance with\nprevious state-of-the-art, and meanwhile enjoys fast generation speed.",
          "link": "http://arxiv.org/abs/2307.08849",
          "publishedOn": "2023-07-19T01:53:26.421Z",
          "wordCount": 691,
          "title": "Autoregressive Diffusion Model for Graph Generation. (arXiv:2307.08849v1 [cs.AI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08874",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mirjanic_V/0/1/0/all/0/1\">Vladimir V. Mirjani&#x107;</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Pascanu_R/0/1/0/all/0/1\">Razvan Pascanu</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Velickovic_P/0/1/0/all/0/1\">Petar Veli&#x10d;kovi&#x107;</a> (1 and 2) ((1) University of Cambridge, (2) Google DeepMind)",
          "description": "Neural Algorithmic Reasoning (NAR) is a research area focused on designing\nneural architectures that can reliably capture classical computation, usually\nby learning to execute algorithms. A typical approach is to rely on Graph\nNeural Network (GNN) architectures, which encode inputs in high-dimensional\nlatent spaces that are repeatedly transformed during the execution of the\nalgorithm. In this work we perform a detailed analysis of the structure of the\nlatent space induced by the GNN when executing algorithms. We identify two\npossible failure modes: (i) loss of resolution, making it hard to distinguish\nsimilar values; (ii) inability to deal with values outside the range observed\nduring training. We propose to solve the first issue by relying on a softmax\naggregator, and propose to decay the latent space in order to deal with\nout-of-range values. We show that these changes lead to improvements on the\nmajority of algorithms in the standard CLRS-30 benchmark when using the\nstate-of-the-art Triplet-GMPNN processor. Our code is available at\n\\href{https://github.com/mirjanic/nar-latent-spaces}{https://github.com/mirjanic/nar-latent-spaces}.",
          "link": "http://arxiv.org/abs/2307.08874",
          "publishedOn": "2023-07-19T01:53:26.416Z",
          "wordCount": 699,
          "title": "Latent Space Representations of Neural Algorithmic Reasoners. (arXiv:2307.08874v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08925",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chaochao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1\">Xiaohua Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1\">Jianwei Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xiaolin Zheng</a>",
          "description": "Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.",
          "link": "http://arxiv.org/abs/2307.08925",
          "publishedOn": "2023-07-19T01:53:26.394Z",
          "wordCount": 665,
          "title": "Federated Large Language Model: A Position Paper. (arXiv:2307.08925v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08877",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_A/0/1/0/all/0/1\">Ayan Chatterjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walters_R/0/1/0/all/0/1\">Robin Walters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menichetti_G/0/1/0/all/0/1\">Giulia Menichetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eliassi_Rad_T/0/1/0/all/0/1\">Tina Eliassi-Rad</a>",
          "description": "Link prediction is a crucial task in graph machine learning with diverse\napplications. We explore the interplay between node attributes and graph\ntopology and demonstrate that incorporating pre-trained node attributes\nimproves the generalization power of link prediction models. Our proposed\nmethod, UPNA (Unsupervised Pre-training of Node Attributes), solves the\ninductive link prediction problem by learning a function that takes a pair of\nnode attributes and predicts the probability of an edge, as opposed to Graph\nNeural Networks (GNN), which can be prone to topological shortcuts in graphs\nwith power-law degree distribution. In this manner, UPNA learns a significant\npart of the latent graph generation mechanism since the learned function can be\nused to add incoming nodes to a growing graph. By leveraging pre-trained node\nattributes, we overcome observational bias and make meaningful predictions\nabout unobserved nodes, surpassing state-of-the-art performance (3X to 34X\nimprovement on benchmark datasets). UPNA can be applied to various pairwise\nlearning tasks and integrated with existing link prediction models to enhance\ntheir generalizability and bolster graph generative models.",
          "link": "http://arxiv.org/abs/2307.08877",
          "publishedOn": "2023-07-19T01:53:26.388Z",
          "wordCount": 702,
          "title": "Disentangling Node Attributes from Graph Topology for Improved Generalizability in Link Prediction. (arXiv:2307.08877v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongji Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1\">Ching-Yao Lai</a>",
          "description": "Deep learning techniques are increasingly applied to scientific problems,\nwhere the precision of networks is crucial. Despite being deemed as universal\nfunction approximators, neural networks, in practice, struggle to reduce the\nprediction errors below $O(10^{-5})$ even with large network size and extended\ntraining iterations. To address this issue, we developed the multi-stage neural\nnetworks that divides the training process into different stages, with each\nstage using a new network that is optimized to fit the residue from the\nprevious stage. Across successive stages, the residue magnitudes decreases\nsubstantially and follows an inverse power-law relationship with the residue\nfrequencies. The multi-stage neural networks effectively mitigate the spectral\nbiases associated with regular neural networks, enabling them to capture the\nhigh frequency feature of target functions. We demonstrate that the prediction\nerror from the multi-stage training for both regression problems and\nphysics-informed neural networks can nearly reach the machine-precision\n$O(10^{-16})$ of double-floating point within a finite number of iterations.\nSuch levels of accuracy are rarely attainable using single neural networks\nalone.",
          "link": "http://arxiv.org/abs/2307.08934",
          "publishedOn": "2023-07-19T01:53:26.382Z",
          "wordCount": 680,
          "title": "Multi-stage Neural Networks: Function Approximator of Machine Precision. (arXiv:2307.08934v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Gang Chen</a>",
          "description": "When to solve math problems, most language models take a sampling strategy to\npredict next word according conditional probabilities. In the math reasoning\nstep, it may generate wrong answer. Considering math problems are\ndeterministic, we propose a mixed policy exploration approach to solve math\nproblems with reinforcement learning. In peculiar, we propose a two level token\nexploration policy: the abstract level explores next token with probability and\nthe second level is deterministic. Specifically, the abstract level policy will\ndecide whether the token is operator or operand with probability sampling,\nwhile the second level is deterministic to select next token with the highest\nscore in a greedy way. We test our method on GSM8K dataset with GPT-2 model,\nand demonstrate more than $2\\%$ performance gain. Our implementation is\navailable at https://github.com/vividitytech/math_lm_rl.",
          "link": "http://arxiv.org/abs/2307.08767",
          "publishedOn": "2023-07-19T01:53:26.375Z",
          "wordCount": 649,
          "title": "A mixed policy to improve performance of language models on math problems. (arXiv:2307.08767v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08924",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingyao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zeen Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_X/0/1/0/all/0/1\">Xingzhe Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1\">Lingyu Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hongwei Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiang_W/0/1/0/all/0/1\">Wenwen Qiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Changwen Zheng</a>",
          "description": "Through experiments on various meta-learning methods, task samplers, and\nfew-shot learning tasks, this paper arrives at three conclusions. Firstly,\nthere are no universal task sampling strategies to guarantee the performance of\nmeta-learning models. Secondly, task diversity can cause the models to either\nunderfit or overfit during training. Lastly, the generalization performance of\nthe models are influenced by task divergence, task entropy, and task\ndifficulty. In response to these findings, we propose a novel task sampler\ncalled Adaptive Sampler (ASr). ASr is a plug-and-play task sampler that takes\ntask divergence, task entropy, and task difficulty to sample tasks. To optimize\nASr, we rethink and propose a simple and general meta-learning algorithm.\nFinally, a large number of empirical experiments demonstrate the effectiveness\nof the proposed ASr.",
          "link": "http://arxiv.org/abs/2307.08924",
          "publishedOn": "2023-07-19T01:53:26.360Z",
          "wordCount": 645,
          "title": "Learning to Sample Tasks for Meta Learning. (arXiv:2307.08924v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.17375",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Dianbo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bolotta_S/0/1/0/all/0/1\">Samuele Bolotta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">He Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dumas_G/0/1/0/all/0/1\">Guillaume Dumas</a>",
          "description": "Attention has become a common ingredient in deep learning architectures. It\nadds a dynamical selection of information on top of the static selection of\ninformation supported by weights. In the same way, we can imagine a\nhigher-order informational filter built on top of attention: an Attention\nSchema (AS), namely, a descriptive and predictive model of attention. In\ncognitive neuroscience, Attention Schema Theory (AST) supports this idea of\ndistinguishing attention from AS. A strong prediction of this theory is that an\nagent can use its own AS to also infer the states of other agents' attention\nand consequently enhance coordination with other agents. As such, multi-agent\nreinforcement learning would be an ideal setting to experimentally test the\nvalidity of AST. We explore different ways in which attention and AS interact\nwith each other. Our preliminary results indicate that agents that implement\nthe AS as a recurrent internal control achieve the best performance. In\ngeneral, these exploratory experiments suggest that equipping artificial agents\nwith a model of attention can enhance their social intelligence.",
          "link": "http://arxiv.org/abs/2305.17375",
          "publishedOn": "2023-07-17T01:05:36.235Z",
          "wordCount": 689,
          "title": "Attention Schema in Neural Agents. (arXiv:2305.17375v3 [cs.AI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.01946",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shivashankara_K/0/1/0/all/0/1\">Kshama Kodthalu Shivashankara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shervedani_A/0/1/0/all/0/1\">Afagh Mehri Shervedani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sameni_R/0/1/0/all/0/1\">Reza Sameni</a>",
          "description": "The electrocardiogram (ECG) is an accurate and widely available tool for\ndiagnosing cardiovascular diseases. ECGs have been recorded in printed formats\nfor decades and their digitization holds great potential for training machine\nlearning (ML) models in algorithmic ECG diagnosis. Physical ECG archives are at\nrisk of deterioration and scanning printed ECGs alone is insufficient, as ML\nmodels require ECG time-series data. Therefore, the digitization and conversion\nof paper ECG archives into time-series data is of utmost importance. Deep\nlearning models for image processing show promise in this regard. However, the\nscarcity of ECG archives with reference time-series is a challenge. Data\naugmentation techniques utilizing \\textit{digital twins} present a potential\nsolution.\n\nWe introduce a novel method for generating synthetic ECG images on standard\npaper-like ECG backgrounds with realistic artifacts. Distortions including\nhandwritten text artifacts, wrinkles, creases and perspective transforms are\napplied to the generated images, without personally identifiable information.\nAs a use case, we generated an ECG image dataset of 21,801 records from the\n12-lead PhysioNet PTB-XL ECG time-series dataset. A deep ECG image digitization\nmodel was built and trained on the synthetic dataset, and was employed to\nconvert the synthetic images to time-series data for evaluation. The\nsignal-to-noise ratio (SNR) was calculated to assess the image digitization\nquality vs the ground truth ECG time-series. The results show an average signal\nrecovery SNR of 27$\\pm$2.8\\,dB, demonstrating the significance of the proposed\nsynthetic ECG image dataset for training deep learning models. The codebase is\navailable as an open-access toolbox for ECG research.",
          "link": "http://arxiv.org/abs/2307.01946",
          "publishedOn": "2023-07-17T01:05:36.203Z",
          "wordCount": 806,
          "title": "A Synthetic Electrocardiogram (ECG) Image Generation Toolbox to Facilitate Deep Learning-Based Scanned ECG Digitization. (arXiv:2307.01946v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.16464",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lashkari_M/0/1/0/all/0/1\">Mohammad Lashkari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gheibi_A/0/1/0/all/0/1\">Amin Gheibi</a>",
          "description": "The generalization performance of deep neural networks with regard to the\noptimization algorithm is one of the major concerns in machine learning. This\nperformance can be affected by various factors. In this paper, we theoretically\nprove that the Lipschitz constant of a loss function is an important factor to\ndiminish the generalization error of the output model obtained by Adam or\nAdamW. The results can be used as a guideline for choosing the loss function\nwhen the optimization algorithm is Adam or AdamW. In addition, to evaluate the\ntheoretical bound in a practical setting, we choose the human age estimation\nproblem in computer vision. For assessing the generalization better, the\ntraining and test datasets are drawn from different distributions. Our\nexperimental evaluation shows that the loss function with a lower Lipschitz\nconstant and maximum value improves the generalization of the model trained by\nAdam or AdamW.",
          "link": "http://arxiv.org/abs/2303.16464",
          "publishedOn": "2023-07-17T01:05:36.195Z",
          "wordCount": 713,
          "title": "Lipschitzness Effect of a Loss Function on Generalization Performance of Deep Neural Networks Trained by Adam and AdamW Optimizers. (arXiv:2303.16464v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.14863",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nag_S/0/1/0/all/0/1\">Sauradip Nag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiatian Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jiankang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yi-Zhe Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1\">Tao Xiang</a>",
          "description": "We propose a new formulation of temporal action detection (TAD) with\ndenoising diffusion, DiffTAD in short. Taking as input random temporal\nproposals, it can yield action proposals accurately given an untrimmed long\nvideo. This presents a generative modeling perspective, against previous\ndiscriminative learning manners. This capability is achieved by first diffusing\nthe ground-truth proposals to random ones (i.e., the forward/noising process)\nand then learning to reverse the noising process (i.e., the backward/denoising\nprocess). Concretely, we establish the denoising process in the Transformer\ndecoder (e.g., DETR) by introducing a temporal location query design with\nfaster convergence in training. We further propose a cross-step selective\nconditioning algorithm for inference acceleration. Extensive evaluations on\nActivityNet and THUMOS show that our DiffTAD achieves top performance compared\nto previous art alternatives. The code will be made available at\nhttps://github.com/sauradip/DiffusionTAD.",
          "link": "http://arxiv.org/abs/2303.14863",
          "publishedOn": "2023-07-17T01:05:36.160Z",
          "wordCount": 679,
          "title": "DiffTAD: Temporal Action Detection with Proposal Denoising Diffusion. (arXiv:2303.14863v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.00864",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shu_Y/0/1/0/all/0/1\">Yang Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xingzhuo Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jialong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Ximei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianmin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_M/0/1/0/all/0/1\">Mingsheng Long</a>",
          "description": "Out-of-distribution (OOD) generalization, where the model needs to handle\ndistribution shifts from training, is a major challenge of machine learning.\nContrastive language-image pre-training (CLIP) models have shown impressive\nzero-shot ability, but the further adaptation of CLIP on downstream tasks\nundesirably degrades OOD performances. This paper aims at generalizing CLIP to\nout-of-distribution test data on downstream tasks. We propose CLIPood, a\nfine-tuning method that can adapt CLIP models to OOD situations where both\ndomain shifts and open classes may occur on the unseen test data. To exploit\nthe semantic relations between classes from the text modality, CLIPood\nintroduces a new training objective, margin metric softmax (MMS), with class\nadaptive margins for fine-tuning. To incorporate both pre-trained zero-shot\nmodel and fine-tuned task-adaptive model, CLIPood leverages a new optimization\nstrategy, Beta moving average (BMA), to maintain a temporal ensemble weighted\nby Beta distribution. Experiments on diverse datasets with different OOD\nscenarios show that CLIPood consistently outperforms existing generalization\ntechniques.",
          "link": "http://arxiv.org/abs/2302.00864",
          "publishedOn": "2023-07-17T01:05:36.149Z",
          "wordCount": 682,
          "title": "CLIPood: Generalizing CLIP to Out-of-Distributions. (arXiv:2302.00864v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.00543",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dorfman_R/0/1/0/all/0/1\">Ron Dorfman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vargaftik_S/0/1/0/all/0/1\">Shay Vargaftik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_Itzhak_Y/0/1/0/all/0/1\">Yaniv Ben-Itzhak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_K/0/1/0/all/0/1\">Kfir Y. Levy</a>",
          "description": "Many compression techniques have been proposed to reduce the communication\noverhead of Federated Learning training procedures. However, these are\ntypically designed for compressing model updates, which are expected to decay\nthroughout training. As a result, such methods are inapplicable to downlink\n(i.e., from the parameter server to clients) compression in the cross-device\nsetting, where heterogeneous clients $\\textit{may appear only once}$ during\ntraining and thus must download the model parameters. Accordingly, we propose\n$\\textsf{DoCoFL}$ -- a new framework for downlink compression in the\ncross-device setting. Importantly, $\\textsf{DoCoFL}$ can be seamlessly combined\nwith many uplink compression schemes, rendering it suitable for bi-directional\ncompression. Through extensive evaluation, we show that $\\textsf{DoCoFL}$\noffers significant bi-directional bandwidth reduction while achieving\ncompetitive accuracy to that of a baseline without any compression.",
          "link": "http://arxiv.org/abs/2302.00543",
          "publishedOn": "2023-07-17T01:05:36.127Z",
          "wordCount": 657,
          "title": "DoCoFL: Downlink Compression for Cross-Device Federated Learning. (arXiv:2302.00543v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.04188",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_P/0/1/0/all/0/1\">Puyu Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lei_Y/0/1/0/all/0/1\">Yunwen Lei</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ying_Y/0/1/0/all/0/1\">Yiming Ying</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhou_D/0/1/0/all/0/1\">Ding-Xuan Zhou</a>",
          "description": "Modern machine learning algorithms aim to extract fine-grained information\nfrom data to provide accurate predictions, which often conflicts with the goal\nof privacy protection. This paper addresses the practical and theoretical\nimportance of developing privacy-preserving machine learning algorithms that\nensure good performance while preserving privacy. In this paper, we focus on\nthe privacy and utility (measured by excess risk bounds) performances of\ndifferentially private stochastic gradient descent (SGD) algorithms in the\nsetting of stochastic convex optimization. Specifically, we examine the\npointwise problem in the low-noise setting for which we derive sharper excess\nrisk bounds for the differentially private SGD algorithm. In the pairwise\nlearning setting, we propose a simple differentially private SGD algorithm\nbased on gradient perturbation. Furthermore, we develop novel utility bounds\nfor the proposed algorithm, proving that it achieves optimal excess risk rates\neven for non-smooth losses. Notably, we establish fast learning rates for\nprivacy-preserving pairwise learning under the low-noise condition, which is\nthe first of its kind.",
          "link": "http://arxiv.org/abs/2209.04188",
          "publishedOn": "2023-07-17T01:05:36.121Z",
          "wordCount": 680,
          "title": "Differentially Private Stochastic Gradient Descent with Low-Noise. (arXiv:2209.04188v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2207.09874",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cacciarelli_D/0/1/0/all/0/1\">Davide Cacciarelli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kulahci_M/0/1/0/all/0/1\">Murat Kulahci</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tyssedal_J/0/1/0/all/0/1\">John S&#xf8;lve Tyssedal</a>",
          "description": "The proliferation of automated data collection schemes and the advances in\nsensorics are increasing the amount of data we are able to monitor in\nreal-time. However, given the high annotation costs and the time required by\nquality inspections, data is often available in an unlabeled form. This is\nfostering the use of active learning for the development of soft sensors and\npredictive models. In production, instead of performing random inspections to\nobtain product information, labels are collected by evaluating the information\ncontent of the unlabeled data. Several query strategy frameworks for regression\nhave been proposed in the literature but most of the focus has been dedicated\nto the static pool-based scenario. In this work, we propose a new strategy for\nthe stream-based scenario, where instances are sequentially offered to the\nlearner, which must instantaneously decide whether to perform the quality check\nto obtain the label or discard the instance. The approach is inspired by the\noptimal experimental design theory and the iterative aspect of the\ndecision-making process is tackled by setting a threshold on the\ninformativeness of the unlabeled data points. The proposed approach is\nevaluated using numerical simulations and the Tennessee Eastman Process\nsimulator. The results confirm that selecting the examples suggested by the\nproposed algorithm allows for a faster reduction in the prediction error.",
          "link": "http://arxiv.org/abs/2207.09874",
          "publishedOn": "2023-07-17T01:05:36.116Z",
          "wordCount": 770,
          "title": "Stream-based active learning with linear models. (arXiv:2207.09874v5 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.05695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lialin_V/0/1/0/all/0/1\">Vladislav Lialin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shivagunde_N/0/1/0/all/0/1\">Namrata Shivagunde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muckatira_S/0/1/0/all/0/1\">Sherin Muckatira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rumshisky_A/0/1/0/all/0/1\">Anna Rumshisky</a>",
          "description": "Despite the dominance and effectiveness of scaling, resulting in large\nnetworks with hundreds of billions of parameters, the necessity to train\noverparametrized models remains poorly understood, and alternative approaches\ndo not necessarily make it cheaper to train high-performance models. In this\npaper, we explore low-rank training techniques as an alternative approach to\ntraining large neural networks. We introduce a novel method called ReLoRA,\nwhich utilizes low-rank updates to train high-rank networks. We apply ReLoRA to\npre-training transformer language models with up to 350M parameters and\ndemonstrate comparable performance to regular neural network training.\nFurthermore, we observe that the efficiency of ReLoRA increases with model\nsize, making it a promising approach for training multi-billion-parameter\nnetworks efficiently. Our findings shed light on the potential of low-rank\ntraining techniques and their implications for scaling laws.",
          "link": "http://arxiv.org/abs/2307.05695",
          "publishedOn": "2023-07-17T01:05:36.110Z",
          "wordCount": 656,
          "title": "Stack More Layers Differently: High-Rank Training Through Low-Rank Updates. (arXiv:2307.05695v2 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.18405",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yue Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1\">Ke Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_J/0/1/0/all/0/1\">Jun Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Sihang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xihong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xinwang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Stan Z. Li</a>",
          "description": "Deep graph clustering, which aims to group the nodes of a graph into disjoint\nclusters with deep neural networks, has achieved promising progress in recent\nyears. However, the existing methods fail to scale to the large graph with\nmillion nodes. To solve this problem, a scalable deep graph clustering method\n(Dink-Net) is proposed with the idea of dilation and shrink. Firstly, by\ndiscriminating nodes, whether being corrupted by augmentations, representations\nare learned in a self-supervised manner. Meanwhile, the cluster centres are\ninitialized as learnable neural parameters. Subsequently, the clustering\ndistribution is optimized by minimizing the proposed cluster dilation loss and\ncluster shrink loss in an adversarial manner. By these settings, we unify the\ntwo-step clustering, i.e., representation learning and clustering optimization,\ninto an end-to-end framework, guiding the network to learn clustering-friendly\nfeatures. Besides, Dink-Net scales well to large graphs since the designed loss\nfunctions adopt the mini-batch data to optimize the clustering distribution\neven without performance drops. Both experimental results and theoretical\nanalyses demonstrate the superiority of our method. Compared to the runner-up,\nDink-Net achieves 9.62% NMI improvement on the ogbn-papers100M dataset with 111\nmillion nodes and 1.6 billion edges. The source code is released at\nhttps://github.com/yueliu1999/Dink-Net. Besides, a collection (papers, codes,\nand datasets) of deep graph clustering is shared at\nhttps://github.com/yueliu1999/Awesome-Deep-Graph-Clustering.",
          "link": "http://arxiv.org/abs/2305.18405",
          "publishedOn": "2023-07-17T01:05:35.922Z",
          "wordCount": 756,
          "title": "Dink-Net: Neural Clustering on Large Graphs. (arXiv:2305.18405v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.04391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1\">Tong Guo</a>",
          "description": "In industry deep learning application, our manually labeled data has a\ncertain number of noisy data. To solve this problem and achieve more than 90\nscore in dev dataset, we present a simple method to find the noisy data and\nre-label the noisy data by human, given the model predictions as references in\nhuman labeling. In this paper, we illustrate our idea for a broad set of deep\nlearning tasks, includes classification, sequence tagging, object detection,\nsequence generation, click-through rate prediction. The experimental results\nand human evaluation results verify our idea.",
          "link": "http://arxiv.org/abs/2302.04391",
          "publishedOn": "2023-07-17T01:05:35.901Z",
          "wordCount": null,
          "title": "The Re-Label Method For Data-Centric Machine Learning. (arXiv:2302.04391v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.07014",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Langerbein_J/0/1/0/all/0/1\">Janine Langerbein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Massing_T/0/1/0/all/0/1\">Till Massing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klenke_J/0/1/0/all/0/1\">Jens Klenke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reckmann_N/0/1/0/all/0/1\">Natalie Reckmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Striewe_M/0/1/0/all/0/1\">Michael Striewe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goedicke_M/0/1/0/all/0/1\">Michael Goedicke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanck_C/0/1/0/all/0/1\">Christoph Hanck</a>",
          "description": "Due to the precautionary measures during the COVID-19 pandemic many\nuniversities offered unproctored take-home exams. We propose methods to detect\npotential collusion between students and apply our approach on event log data\nfrom take-home exams during the pandemic. We find groups of students with\nsuspiciously similar exams. In addition, we compare our findings to a proctored\ncontrol group. By this, we establish a rule of thumb for evaluating which cases\nare \"outstandingly similar\", i.e., suspicious cases.",
          "link": "http://arxiv.org/abs/2302.07014",
          "publishedOn": "2023-07-17T01:05:35.898Z",
          "wordCount": null,
          "title": "A Data Mining Approach for Detecting Collusion in Unproctored Online Exams. (arXiv:2302.07014v3 [cs.CY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.14460",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marcinkevics_R/0/1/0/all/0/1\">Ri&#x10d;ards Marcinkevi&#x10d;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolfertstetter_P/0/1/0/all/0/1\">Patricia Reis Wolfertstetter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klimiene_U/0/1/0/all/0/1\">Ugne Klimiene</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chin_Cheong_K/0/1/0/all/0/1\">Kieran Chin-Cheong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paschke_A/0/1/0/all/0/1\">Alyssia Paschke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zerres_J/0/1/0/all/0/1\">Julia Zerres</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Denzinger_M/0/1/0/all/0/1\">Markus Denzinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niederberger_D/0/1/0/all/0/1\">David Niederberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wellmann_S/0/1/0/all/0/1\">Sven Wellmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozkan_E/0/1/0/all/0/1\">Ece Ozkan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knorr_C/0/1/0/all/0/1\">Christian Knorr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogt_J/0/1/0/all/0/1\">Julia E. Vogt</a>",
          "description": "Appendicitis is among the most frequent reasons for pediatric abdominal\nsurgeries. With recent advances in machine learning, data-driven decision\nsupport could help clinicians diagnose and manage patients while reducing the\nnumber of non-critical surgeries. Previous decision support systems for\nappendicitis focused on clinical, laboratory, scoring and computed tomography\ndata, mainly ignoring abdominal ultrasound, a noninvasive and readily available\ndiagnostic modality. To this end, we developed and validated interpretable\nmachine learning models for predicting the diagnosis, management and severity\nof suspected appendicitis using ultrasound images. Our models were trained on a\ndataset comprising 579 pediatric patients with 1709 ultrasound images\naccompanied by clinical and laboratory data. Our methodological contribution is\nthe generalization of concept bottleneck models to prediction problems with\nmultiple views and incomplete concept sets. Notably, such models lend\nthemselves to interpretation and interaction via high-level concepts\nunderstandable to clinicians without sacrificing performance or requiring\ntime-consuming image annotation when deployed.",
          "link": "http://arxiv.org/abs/2302.14460",
          "publishedOn": "2023-07-17T01:05:35.897Z",
          "wordCount": null,
          "title": "Interpretable and Intervenable Ultrasonography-based Machine Learning Models for Pediatric Appendicitis. (arXiv:2302.14460v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07320",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ying_M/0/1/0/all/0/1\">Mufang Ying</a>, <a href=\"http://arxiv.org/find/math/1/au:+Khamaru_K/0/1/0/all/0/1\">Koulik Khamaru</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_C/0/1/0/all/0/1\">Cun-Hui Zhang</a>",
          "description": "Sequential data collection has emerged as a widely adopted technique for\nenhancing the efficiency of data gathering processes. Despite its advantages,\nsuch data collection mechanism often introduces complexities to the statistical\ninference procedure. For instance, the ordinary least squares (OLS) estimator\nin an adaptive linear regression model can exhibit non-normal asymptotic\nbehavior, posing challenges for accurate inference and interpretation. In this\npaper, we propose a general method for constructing debiased estimator which\nremedies this issue. It makes use of the idea of adaptive linear estimating\nequations, and we establish theoretical guarantees of asymptotic normality,\nsupplemented by discussions on achieving near-optimal asymptotic variance. A\nsalient feature of our estimator is that in the context of multi-armed bandits,\nour estimator retains the non-asymptotic performance of the least square\nestimator while obtaining asymptotic normality property. Consequently, this\nwork helps connect two fruitful paradigms of adaptive inference: a)\nnon-asymptotic inference using concentration inequalities and b) asymptotic\ninference via asymptotic normality.",
          "link": "http://arxiv.org/abs/2307.07320",
          "publishedOn": "2023-07-17T01:05:35.874Z",
          "wordCount": null,
          "title": "Adaptive Linear Estimating Equations. (arXiv:2307.07320v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.12271",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vardakas_G/0/1/0/all/0/1\">Georgios Vardakas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Likas_A/0/1/0/all/0/1\">Aristidis Likas</a>",
          "description": "The $k$-means algorithm is a prevalent clustering method due to its\nsimplicity, effectiveness, and speed. However, its main disadvantage is its\nhigh sensitivity to the initial positions of the cluster centers. The global\n$k$-means is a deterministic algorithm proposed to tackle the random\ninitialization problem of k-means but its well-known that requires high\ncomputational cost. It partitions the data to $K$ clusters by solving all\n$k$-means sub-problems incrementally for all $k=1,\\ldots, K$. For each $k$\ncluster problem, the method executes the $k$-means algorithm $N$ times, where\n$N$ is the number of datapoints. In this paper, we propose the \\emph{global\n$k$-means\\texttt{++}} clustering algorithm, which is an effective way of\nacquiring quality clustering solutions akin to those of global $k$-means with a\nreduced computational load. This is achieved by exploiting the center selection\nprobability that is effectively used in the $k$-means\\texttt{++} algorithm. The\nproposed method has been tested and compared in various benchmark datasets\nyielding very satisfactory results in terms of clustering quality and execution\nspeed.",
          "link": "http://arxiv.org/abs/2211.12271",
          "publishedOn": "2023-07-17T01:05:35.867Z",
          "wordCount": null,
          "title": "Global $k$-means$++$: an effective relaxation of the global $k$-means clustering algorithm. (arXiv:2211.12271v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2207.08768",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shu Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1\">Siwei Lyu</a>",
          "description": "Recent works have revealed an essential paradigm in designing loss functions\nthat differentiate individual losses vs. aggregate losses. The individual loss\nmeasures the quality of the model on a sample, while the aggregate loss\ncombines individual losses/scores over each training sample. Both have a common\nprocedure that aggregates a set of individual values to a single numerical\nvalue. The ranking order reflects the most fundamental relation among\nindividual values in designing losses. In addition, decomposability, in which a\nloss can be decomposed into an ensemble of individual terms, becomes a\nsignificant property of organizing losses/scores. This survey provides a\nsystematic and comprehensive review of rank-based decomposable losses in\nmachine learning. Specifically, we provide a new taxonomy of loss functions\nthat follows the perspectives of aggregate loss and individual loss. We\nidentify the aggregator to form such losses, which are examples of set\nfunctions. We organize the rank-based decomposable losses into eight\ncategories. Following these categories, we review the literature on rank-based\naggregate losses and rank-based individual losses. We describe general formulas\nfor these losses and connect them with existing research topics. We also\nsuggest future research directions spanning unexplored, remaining, and emerging\nissues in rank-based decomposable losses.",
          "link": "http://arxiv.org/abs/2207.08768",
          "publishedOn": "2023-07-17T01:05:35.865Z",
          "wordCount": null,
          "title": "Rank-based Decomposable Losses in Machine Learning: A Survey. (arXiv:2207.08768v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.10113",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_A/0/1/0/all/0/1\">Alex Tong Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_S/0/1/0/all/0/1\">Samy Wu Fung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wuchen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nurbekyan_L/0/1/0/all/0/1\">Levon Nurbekyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osher_S/0/1/0/all/0/1\">Stanley J. Osher</a>",
          "description": "We present APAC-Net, an alternating population and agent control neural\nnetwork for solving stochastic mean field games (MFGs). Our algorithm is geared\ntoward high-dimensional instances of MFGs that are beyond reach with existing\nsolution methods. We achieve this in two steps. First, we take advantage of the\nunderlying variational primal-dual structure that MFGs exhibit and phrase it as\na convex-concave saddle point problem. Second, we parameterize the value and\ndensity functions by two neural networks, respectively. By phrasing the problem\nin this manner, solving the MFG can be interpreted as a special case of\ntraining a generative adversarial network (GAN). We show the potential of our\nmethod on up to 100-dimensional MFG problems.",
          "link": "http://arxiv.org/abs/2002.10113",
          "publishedOn": "2023-07-17T01:05:35.858Z",
          "wordCount": 722,
          "title": "Alternating the Population and Control Neural Networks to Solve High-Dimensional Stochastic Mean-Field Games. (arXiv:2002.10113v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.00828",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_S/0/1/0/all/0/1\">Shengbo Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_K/0/1/0/all/0/1\">Ke Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Y/0/1/0/all/0/1\">Yin Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cao_Y/0/1/0/all/0/1\">Yuting Cao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_T/0/1/0/all/0/1\">Tingwen Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wen_S/0/1/0/all/0/1\">Shiping Wen</a>",
          "description": "Breaking safety constraints in control systems can lead to potential risks,\nresulting in unexpected costs or catastrophic damage. Nevertheless, uncertainty\nis ubiquitous, even among similar tasks. In this paper, we develop a novel\nadaptive safe control framework that integrates meta learning, Bayesian models,\nand control barrier function (CBF) method. Specifically, with the help of CBF\nmethod, we learn the inherent and external uncertainties by a unified adaptive\nBayesian linear regression (ABLR) model, which consists of a forward neural\nnetwork (NN) and a Bayesian output layer. Meta learning techniques are\nleveraged to pre-train the NN weights and priors of the ABLR model using data\ncollected from historical similar tasks. For a new control task, we refine the\nmeta-learned models using a few samples, and introduce pessimistic confidence\nbounds into CBF constraints to ensure safe control. Moreover, we provide\ntheoretical criteria to guarantee probabilistic safety during the control\nprocesses. To validate our approach, we conduct comparative experiments in\nvarious obstacle avoidance scenarios. The results demonstrate that our\nalgorithm significantly improves the Bayesian model-based CBF method, and is\ncapable for efficient safe exploration even with multiple uncertain\nconstraints.",
          "link": "http://arxiv.org/abs/2307.00828",
          "publishedOn": "2023-07-17T01:05:35.851Z",
          "wordCount": null,
          "title": "Model-Assisted Probabilistic Safe Adaptive Control With Meta-Bayesian Learning. (arXiv:2307.00828v2 [eess.SY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_K/0/1/0/all/0/1\">Ke Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhiyuan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Haohan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Desheng Wang</a>",
          "description": "In future 6G Mobile Edge Computing (MEC), autopilot systems require the\ncapability of processing multimodal data with strong interdependencies.\nHowever, traditional heuristic algorithms are inadequate for real-time\nscheduling due to their requirement for multiple iterations to derive the\noptimal scheme. We propose a novel TSNet-SAC based on Transformer, that\nutilizes heuristic algorithms solely to guide the training of TSNet.\nAdditionally, a Sliding Augment Component (SAC) is introduced to enhance the\nrobustness and resolve algorithm defects. Furthermore, the Extender component\nis designed to handle multi-scale training data and provide network\nscalability, enabling TSNet to adapt to different access scenarios. Simulation\ndemonstrates that TSNet-SAC outperforms existing networks in accuracy and\nrobustness, achieving superior scheduling-making latency compared to heuristic\nalgorithms.",
          "link": "http://arxiv.org/abs/2307.07445",
          "publishedOn": "2023-07-17T01:05:35.850Z",
          "wordCount": 631,
          "title": "TSNet-SAC: Leveraging Transformers for Efficient Task Scheduling. (arXiv:2307.07445v1 [cs.NI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06250",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jiaqi Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Squires_C/0/1/0/all/0/1\">Chandler Squires</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Greenewald_K/0/1/0/all/0/1\">Kristjan Greenewald</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Srivastava_A/0/1/0/all/0/1\">Akash Srivastava</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shanmugam_K/0/1/0/all/0/1\">Karthikeyan Shanmugam</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Uhler_C/0/1/0/all/0/1\">Caroline Uhler</a>",
          "description": "Causal disentanglement aims to uncover a representation of data using latent\nvariables that are interrelated through a causal model. Such a representation\nis identifiable if the latent model that explains the data is unique. In this\npaper, we focus on the scenario where unpaired observational and interventional\ndata are available, with each intervention changing the mechanism of a latent\nvariable. When the causal variables are fully observed, statistically\nconsistent algorithms have been developed to identify the causal model under\nfaithfulness assumptions. We here show that identifiability can still be\nachieved with unobserved causal variables, given a generalized notion of\nfaithfulness. Our results guarantee that we can recover the latent causal model\nup to an equivalence class and predict the effect of unseen combinations of\ninterventions, in the limit of infinite data. We implement our causal\ndisentanglement framework by developing an autoencoding variational Bayes\nalgorithm and apply it to the problem of predicting combinatorial perturbation\neffects in genomics.",
          "link": "http://arxiv.org/abs/2307.06250",
          "publishedOn": "2023-07-17T01:05:35.850Z",
          "wordCount": null,
          "title": "Identifiability Guarantees for Causal Disentanglement from Soft Interventions. (arXiv:2307.06250v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.11267",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Kim_Y/0/1/0/all/0/1\">Yeongjong Kim</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lee_D/0/1/0/all/0/1\">Dabeen Lee</a>",
          "description": "This paper studies online convex optimization with stochastic constraints. We\npropose a variant of the drift-plus-penalty algorithm that guarantees\n$O(\\sqrt{T})$ expected regret and zero constraint violation, after a fixed\nnumber of iterations, which improves the vanilla drift-plus-penalty method with\n$O(\\sqrt{T})$ constraint violation. Our algorithm is oblivious to the length of\nthe time horizon $T$, in contrast to the vanilla drift-plus-penalty method.\nThis is based on our novel drift lemma that provides time-varying bounds on the\nvirtual queue drift and, as a result, leads to time-varying bounds on the\nexpected virtual queue length. Moreover, we extend our framework to\nstochastic-constrained online convex optimization under two-point bandit\nfeedback. We show that by adapting our algorithmic framework to the bandit\nfeedback setting, we may still achieve $O(\\sqrt{T})$ expected regret and zero\nconstraint violation, improving upon the previous work for the case of\nidentical constraint functions. Numerical results demonstrate our theoretical\nresults.",
          "link": "http://arxiv.org/abs/2301.11267",
          "publishedOn": "2023-07-17T01:05:35.836Z",
          "wordCount": null,
          "title": "Online Convex Optimization with Stochastic Constraints: Zero Constraint Violation and Bandit Feedback. (arXiv:2301.11267v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07199",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sasindran_Z/0/1/0/all/0/1\">Zitha Sasindran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yelchuri_H/0/1/0/all/0/1\">Harsha Yelchuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prabhakar_T/0/1/0/all/0/1\">T. V. Prabhakar</a>",
          "description": "Federated learning (FL) has evolved as a prominent method for edge devices to\ncooperatively create a unified prediction model while securing their sensitive\ntraining data local to the device. Despite the existence of numerous research\nframeworks for simulating FL algorithms, they do not facilitate comprehensive\ndeployment for automatic speech recognition tasks on heterogeneous edge\ndevices. This is where Ed-Fed, a comprehensive and generic FL framework, comes\nin as a foundation for future practical FL system research. We also propose a\nnovel resource-aware client selection algorithm to optimise the waiting time in\nthe FL settings. We show that our approach can handle the straggler devices and\ndynamically set the training time for the selected devices in a round. Our\nevaluation has shown that the proposed approach significantly optimises waiting\ntime in FL compared to conventional random client selection methods.",
          "link": "http://arxiv.org/abs/2307.07199",
          "publishedOn": "2023-07-17T01:05:35.827Z",
          "wordCount": 663,
          "title": "Ed-Fed: A generic federated learning framework with resource-aware client selection for edge devices. (arXiv:2307.07199v1 [cs.DC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2110.03443",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Blattner_L/0/1/0/all/0/1\">Laura Blattner</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Nelson_S/0/1/0/all/0/1\">Scott Nelson</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Spiess_J/0/1/0/all/0/1\">Jann Spiess</a>",
          "description": "We show how to optimally regulate prediction algorithms in a world where an\nagent uses complex 'black-box' prediction functions to make decisions such as\nlending, medical testing, or hiring, and where a principal is limited in how\nmuch she can learn about the agent's black-box model. We show that limiting\nagents to prediction functions that are simple enough to be fully transparent\nis inefficient as long as the misalignment is limited and first-best prediction\nfunctions are sufficiently complex. Algorithmic audits can improve welfare, but\nthe gains depend on the design of the audit tools. Tools that focus on\nminimizing overall information loss, the focus of many explainer tools, will\ngenerally be inefficient since they focus on explaining the average behavior of\nthe prediction function. Targeted tools that focus on the source of incentive\nmisalignment, e.g., excess false positives or racial disparities, can provide\nsecond-best solutions. We provide empirical support for our theoretical\nfindings using an application in consumer lending, where we document that\ncomplex models regulated based on context-specific explanation tools outperform\nsimple, fully transparent models. This gain from complex models represents a\nPareto improvement across our empirical applications that are preferred both by\nthe lender and from the perspective of the financial regulator.",
          "link": "http://arxiv.org/abs/2110.03443",
          "publishedOn": "2023-07-17T01:05:35.798Z",
          "wordCount": null,
          "title": "Unpacking the Black Box: Regulating Algorithmic Decisions. (arXiv:2110.03443v2 [econ.GN] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.08349",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hazra_R/0/1/0/all/0/1\">Rishi Hazra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raedt_L/0/1/0/all/0/1\">Luc De Raedt</a>",
          "description": "Despite numerous successes in Deep Reinforcement Learning (DRL), the learned\npolicies are not interpretable. Moreover, since DRL does not exploit symbolic\nrelational representations, it has difficulties in coping with structural\nchanges in its environment (such as increasing the number of objects).\nRelational Reinforcement Learning, on the other hand, inherits the relational\nrepresentations from symbolic planning to learn reusable policies. However, it\nhas so far been unable to scale up and exploit the power of deep neural\nnetworks. We propose Deep Explainable Relational Reinforcement Learning\n(DERRL), a framework that exploits the best of both -- neural and symbolic\nworlds. By resorting to a neuro-symbolic approach, DERRL combines relational\nrepresentations and constraints from symbolic planning with deep learning to\nextract interpretable policies. These policies are in the form of logical rules\nthat explain how each decision (or action) is arrived at. Through several\nexperiments, in setups like the Countdown Game, Blocks World, Gridworld, and\nTraffic, we show that the policies learned by DERRL can be applied to different\nconfigurations and contexts, hence generalizing to environmental modifications.",
          "link": "http://arxiv.org/abs/2304.08349",
          "publishedOn": "2023-07-17T01:05:35.798Z",
          "wordCount": null,
          "title": "Deep Explainable Relational Reinforcement Learning: A Neuro-Symbolic Approach. (arXiv:2304.08349v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.14369",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Masum_M/0/1/0/all/0/1\">Muhammad Anwar Ma&#x27;sum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pratama_M/0/1/0/all/0/1\">Mahardhika Pratama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lughofer_E/0/1/0/all/0/1\">Edwin Lughofer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habibullah/0/1/0/all/0/1\">Habibullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kowalczyk_R/0/1/0/all/0/1\">Ryszard Kowalczyk</a>",
          "description": "Existing approaches on continual learning call for a lot of samples in their\ntraining processes. Such approaches are impractical for many real-world\nproblems having limited samples because of the overfitting problem. This paper\nproposes a few-shot continual learning approach, termed FLat-tO-WidE AppRoach\n(FLOWER), where a flat-to-wide learning process finding the flat-wide minima is\nproposed to address the catastrophic forgetting problem. The issue of data\nscarcity is overcome with a data augmentation approach making use of a ball\ngenerator concept to restrict the sampling space into the smallest enclosing\nball. Our numerical studies demonstrate the advantage of FLOWER achieving\nsignificantly improved performances over prior arts notably in the small base\ntasks. For further study, source codes of FLOWER, competitor algorithms and\nexperimental logs are shared publicly in\n\\url{https://github.com/anwarmaxsum/FLOWER}.",
          "link": "http://arxiv.org/abs/2306.14369",
          "publishedOn": "2023-07-17T01:05:35.783Z",
          "wordCount": null,
          "title": "Few-Shot Continual Learning via Flat-to-Wide Approaches. (arXiv:2306.14369v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.04856",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vadeboncoeur_A/0/1/0/all/0/1\">Arnaud Vadeboncoeur</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Akyildiz_O/0/1/0/all/0/1\">&#xd6;mer Deniz Akyildiz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kazlauskaite_I/0/1/0/all/0/1\">Ieva Kazlauskaite</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Girolami_M/0/1/0/all/0/1\">Mark Girolami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cirak_F/0/1/0/all/0/1\">Fehmi Cirak</a>",
          "description": "We introduce a physics-driven deep latent variable model (PDDLVM) to learn\nsimultaneously parameter-to-solution (forward) and solution-to-parameter\n(inverse) maps of parametric partial differential equations (PDEs). Our\nformulation leverages conventional PDE discretization techniques, deep neural\nnetworks, probabilistic modelling, and variational inference to assemble a\nfully probabilistic coherent framework. In the posited probabilistic model,\nboth the forward and inverse maps are approximated as Gaussian distributions\nwith a mean and covariance parameterized by deep neural networks. The PDE\nresidual is assumed to be an observed random vector of value zero, hence we\nmodel it as a random vector with a zero mean and a user-prescribed covariance.\nThe model is trained by maximizing the probability, that is the evidence or\nmarginal likelihood, of observing a residual of zero by maximizing the evidence\nlower bound (ELBO). Consequently, the proposed methodology does not require any\nindependent PDE solves and is physics-informed at training time, allowing the\nreal-time solution of PDE forward and inverse problems after training. The\nproposed framework can be easily extended to seamlessly integrate observed data\nto solve inverse problems and to build generative models. We demonstrate the\nefficiency and robustness of our method on finite element discretized\nparametric PDE problems such as linear and nonlinear Poisson problems, elastic\nshells with complex 3D geometries, and time-dependent nonlinear and\ninhomogeneous PDEs using a physics-informed neural network (PINN)\ndiscretization. We achieve up to three orders of magnitude speed-up after\ntraining compared to traditional finite element method (FEM), while outputting\ncoherent uncertainty estimates.",
          "link": "http://arxiv.org/abs/2208.04856",
          "publishedOn": "2023-07-17T01:05:35.780Z",
          "wordCount": null,
          "title": "Fully probabilistic deep models for forward and inverse problems in parametric PDEs. (arXiv:2208.04856v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07066",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peihao Li</a>",
          "description": "In the midst of the emerging trend of integrating artificial intelligence\n(AI) with crypto mining, we identify three major challenges that create a gap\nbetween these two fields. To bridge this gap, we introduce the\nproof-of-training (PoT) protocol, an approach that combines the strengths of\nboth AI and blockchain technology. The PoT protocol utilizes the practical\nByzantine fault tolerance (PBFT) consensus mechanism to synchronize global\nstates. To evaluate the performance of the protocol design, we present an\nimplementation of a decentralized training network (DTN) that adopts the PoT\nprotocol. Our results indicate that the protocol exhibits considerable\npotential in terms of task throughput, system robustness, and network security.",
          "link": "http://arxiv.org/abs/2307.07066",
          "publishedOn": "2023-07-17T01:05:35.779Z",
          "wordCount": null,
          "title": "Proof of Training (PoT): Harnessing Crypto Mining Power for Distributed AI Training. (arXiv:2307.07066v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07313",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carlsson_O/0/1/0/all/0/1\">Oscar Carlsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerken_J/0/1/0/all/0/1\">Jan E. Gerken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Linander_H/0/1/0/all/0/1\">Hampus Linander</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spiess_H/0/1/0/all/0/1\">Heiner Spie&#xdf;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ohlsson_F/0/1/0/all/0/1\">Fredrik Ohlsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petersson_C/0/1/0/all/0/1\">Christoffer Petersson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Persson_D/0/1/0/all/0/1\">Daniel Persson</a>",
          "description": "High-resolution wide-angle fisheye images are becoming more and more\nimportant for robotics applications such as autonomous driving. However, using\nordinary convolutional neural networks or vision transformers on this data is\nproblematic due to projection and distortion losses introduced when projecting\nto a rectangular grid on the plane. We introduce the HEAL-SWIN transformer,\nwhich combines the highly uniform Hierarchical Equal Area iso-Latitude\nPixelation (HEALPix) grid used in astrophysics and cosmology with the\nHierarchical Shifted-Window (SWIN) transformer to yield an efficient and\nflexible model capable of training on high-resolution, distortion-free\nspherical data. In HEAL-SWIN, the nested structure of the HEALPix grid is used\nto perform the patching and windowing operations of the SWIN transformer,\nresulting in a one-dimensional representation of the spherical data with\nminimal computational overhead. We demonstrate the superior performance of our\nmodel for semantic segmentation and depth regression tasks on both synthetic\nand real automotive datasets. Our code is available at\nhttps://github.com/JanEGerken/HEAL-SWIN.",
          "link": "http://arxiv.org/abs/2307.07313",
          "publishedOn": "2023-07-17T01:05:35.778Z",
          "wordCount": 677,
          "title": "HEAL-SWIN: A Vision Transformer On The Sphere. (arXiv:2307.07313v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Martelloni_A/0/1/0/all/0/1\">Andrea Martelloni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McPherson_A/0/1/0/all/0/1\">Andrew P McPherson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barthet_M/0/1/0/all/0/1\">Mathieu Barthet</a>",
          "description": "Real-time music information retrieval (RT-MIR) has much potential to augment\nthe capabilities of traditional acoustic instruments. We develop RT-MIR\ntechniques aimed at augmenting percussive fingerstyle, which blends acoustic\nguitar playing with guitar body percussion. We formulate several design\nobjectives for RT-MIR systems for augmented instrument performance: (i) causal\nconstraint, (ii) perceptually negligible action-to-sound latency, (iii) control\nintimacy support, (iv) synthesis control support. We present and evaluate\nreal-time guitar body percussion recognition and embedding learning techniques\nbased on convolutional neural networks (CNNs) and CNNs jointly trained with\nvariational autoencoders (VAEs). We introduce a taxonomy of guitar body\npercussion based on hand part and location. We follow a cross-dataset\nevaluation approach by collecting three datasets labelled according to the\ntaxonomy. The embedding quality of the models is assessed using KL-Divergence\nacross distributions corresponding to different taxonomic classes. Results\nindicate that the networks are strong classifiers especially in a simplified\n2-class recognition task, and the VAEs yield improved class separation compared\nto CNNs as evidenced by increased KL-Divergence across distributions. We argue\nthat the VAE embedding quality could support control intimacy and rich\ninteraction when the latent space's parameters are used to control an external\nsynthesis engine. Further design challenges around generalisation to different\ndatasets have been identified.",
          "link": "http://arxiv.org/abs/2307.07426",
          "publishedOn": "2023-07-17T01:05:35.765Z",
          "wordCount": 740,
          "title": "Real-time Percussive Technique Recognition and Embedding Learning for the Acoustic Guitar. (arXiv:2307.07426v1 [cs.SD])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.19694",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Aghbalou_A/0/1/0/all/0/1\">Anass Aghbalou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Staerman_G/0/1/0/all/0/1\">Guillaume Staerman</a>",
          "description": "Hypothesis transfer learning (HTL) contrasts domain adaptation by allowing\nfor a previous task leverage, named the source, into a new one, the target,\nwithout requiring access to the source data. Indeed, HTL relies only on a\nhypothesis learnt from such source data, relieving the hurdle of expansive data\nstorage and providing great practical benefits. Hence, HTL is highly beneficial\nfor real-world applications relying on big data. The analysis of such a method\nfrom a theoretical perspective faces multiple challenges, particularly in\nclassification tasks. This paper deals with this problem by studying the\nlearning theory of HTL through algorithmic stability, an attractive theoretical\nframework for machine learning algorithms analysis. In particular, we are\ninterested in the statistical behaviour of the regularized empirical risk\nminimizers in the case of binary classification. Our stability analysis\nprovides learning guarantees under mild assumptions. Consequently, we derive\nseveral complexity-free generalization bounds for essential statistical\nquantities like the training error, the excess risk and cross-validation\nestimates. These refined bounds allow understanding the benefits of transfer\nlearning and comparing the behaviour of standard losses in different scenarios,\nleading to valuable insights for practitioners.",
          "link": "http://arxiv.org/abs/2305.19694",
          "publishedOn": "2023-07-17T01:05:35.765Z",
          "wordCount": null,
          "title": "Hypothesis Transfer Learning with Surrogate Classification Losses: Generalization Bounds through Algorithmic Stability. (arXiv:2305.19694v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.12319",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pozas_Kerstjens_A/0/1/0/all/0/1\">Alejandro Pozas-Kerstjens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Santana_S/0/1/0/all/0/1\">Senaida Hern&#xe1;ndez-Santana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monturiol_J/0/1/0/all/0/1\">Jos&#xe9; Ram&#xf3;n Pareja Monturiol</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopez_M/0/1/0/all/0/1\">Marco Castrill&#xf3;n L&#xf3;pez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scarpa_G/0/1/0/all/0/1\">Giannicola Scarpa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_Guillen_C/0/1/0/all/0/1\">Carlos E. Gonz&#xe1;lez-Guill&#xe9;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_Garcia_D/0/1/0/all/0/1\">David P&#xe9;rez-Garc&#xed;a</a>",
          "description": "Tensor networks, widely used for providing efficient representations of\nlow-energy states of local quantum many-body systems, have been recently\nproposed as machine learning architectures which could present advantages with\nrespect to traditional ones. In this work we show that tensor network\narchitectures have especially prospective properties for privacy-preserving\nmachine learning, which is important in tasks such as the processing of medical\nrecords. First, we describe a new privacy vulnerability that is present in\nfeedforward neural networks, illustrating it in synthetic and real-world\ndatasets. Then, we develop well-defined conditions to guarantee robustness to\nsuch vulnerability, which involve the characterization of models equivalent\nunder gauge symmetry. We rigorously prove that such conditions are satisfied by\ntensor-network architectures. In doing so, we define a novel canonical form for\nmatrix product states, which has a high degree of regularity and fixes the\nresidual gauge that is left in the canonical forms based on singular value\ndecompositions. We supplement the analytical findings with practical examples\nwhere matrix product states are trained on datasets of medical records, which\nshow large reductions on the probability of an attacker extracting information\nabout the training dataset from the model's parameters. Given the growing\nexpertise in training tensor-network architectures, these results imply that\none may not have to be forced to make a choice between accuracy in prediction\nand ensuring the privacy of the information processed.",
          "link": "http://arxiv.org/abs/2202.12319",
          "publishedOn": "2023-07-17T01:05:35.760Z",
          "wordCount": null,
          "title": "Privacy-preserving machine learning with tensor networks. (arXiv:2202.12319v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07449",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Epasto_A/0/1/0/all/0/1\">Alessandro Epasto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_T/0/1/0/all/0/1\">Tamalika Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_P/0/1/0/all/0/1\">Peilin Zhong</a>",
          "description": "The streaming model is an abstraction of computing over massive data streams,\nwhich is a popular way of dealing with large-scale modern data analysis. In\nthis model, there is a stream of data points, one after the other. A streaming\nalgorithm is only allowed one pass over the data stream, and the goal is to\nperform some analysis during the stream while using as small space as possible.\n\nClustering problems (such as $k$-means and $k$-median) are fundamental\nunsupervised machine learning primitives, and streaming clustering algorithms\nhave been extensively studied in the past. However, since data privacy becomes\na central concern in many real-world applications, non-private clustering\nalgorithms are not applicable in many scenarios.\n\nIn this work, we provide the first differentially private streaming\nalgorithms for $k$-means and $k$-median clustering of $d$-dimensional Euclidean\ndata points over a stream with length at most $T$ using $poly(k,d,\\log(T))$\nspace to achieve a {\\it constant} multiplicative error and a\n$poly(k,d,\\log(T))$ additive error. In particular, we present a differentially\nprivate streaming clustering framework which only requires an offline DP\ncoreset algorithm as a blackbox. By plugging in existing DP coreset results via\nGhazi, Kumar, Manurangsi 2020 and Kaplan, Stemmer 2018, we achieve (1) a\n$(1+\\gamma)$-multiplicative approximation with\n$\\tilde{O}_\\gamma(poly(k,d,\\log(T)))$ space for any $\\gamma>0$, and the\nadditive error is $poly(k,d,\\log(T))$ or (2) an $O(1)$-multiplicative\napproximation with $\\tilde{O}(k \\cdot poly(d,\\log(T)))$ space and\n$poly(k,d,\\log(T))$ additive error.\n\nIn addition, our algorithmic framework is also differentially private under\nthe continual release setting, i.e., the union of outputs of our algorithms at\nevery timestamp is always differentially private.",
          "link": "http://arxiv.org/abs/2307.07449",
          "publishedOn": "2023-07-17T01:05:35.759Z",
          "wordCount": 755,
          "title": "Differentially Private Clustering in Data Streams. (arXiv:2307.07449v1 [cs.DS])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07489",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1\">Dapeng Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jian Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinchao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foo_C/0/1/0/all/0/1\">Chuan-Sheng Foo</a>",
          "description": "Unsupervised domain adaptation (UDA) has witnessed remarkable advancements in\nimproving the accuracy of models for unlabeled target domains. However, the\ncalibration of predictive uncertainty in the target domain, a crucial aspect of\nthe safe deployment of UDA models, has received limited attention. The\nconventional in-domain calibration method, \\textit{temperature scaling}\n(TempScal), encounters challenges due to domain distribution shifts and the\nabsence of labeled target domain data. Recent approaches have employed\nimportance-weighting techniques to estimate the target-optimal temperature\nbased on re-weighted labeled source data. Nonetheless, these methods require\nsource data and suffer from unreliable density estimates under severe domain\nshifts, rendering them unsuitable for source-free UDA settings. To overcome\nthese limitations, we propose PseudoCal, a source-free calibration method that\nexclusively relies on unlabeled target data. Unlike previous approaches that\ntreat UDA calibration as a \\textit{covariate shift} problem, we consider it as\nan unsupervised calibration problem specific to the target domain. Motivated by\nthe factorization of the negative log-likelihood (NLL) objective in TempScal,\nwe generate a labeled pseudo-target set that captures the structure of the real\ntarget. By doing so, we transform the unsupervised calibration problem into a\nsupervised one, enabling us to effectively address it using widely-used\nin-domain methods like TempScal. Finally, we thoroughly evaluate the\ncalibration performance of PseudoCal by conducting extensive experiments on 10\nUDA methods, considering both traditional UDA settings and recent source-free\nUDA scenarios. The experimental results consistently demonstrate the superior\nperformance of PseudoCal, exhibiting significantly reduced calibration error\ncompared to existing calibration methods.",
          "link": "http://arxiv.org/abs/2307.07489",
          "publishedOn": "2023-07-17T01:05:35.759Z",
          "wordCount": null,
          "title": "PseudoCal: A Source-Free Approach to Unsupervised Uncertainty Calibration in Domain Adaptation. (arXiv:2307.07489v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07508",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cordeiro_E/0/1/0/all/0/1\">Edyvalberty Alenquer Cordeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pitombeira_Neto_A/0/1/0/all/0/1\">Anselmo Ramalho Pitombeira-Neto</a>",
          "description": "The dynamic vehicle dispatching problem corresponds to deciding which\nvehicles to assign to requests that arise stochastically over time and space.\nIt emerges in diverse areas, such as in the assignment of trucks to loads to be\ntransported; in emergency systems; and in ride-hailing services. In this paper,\nwe model the problem as a semi-Markov decision process, which allows us to\ntreat time as continuous. In this setting, decision epochs coincide with\ndiscrete events whose time intervals are random. We argue that an event-based\napproach substantially reduces the combinatorial complexity of the decision\nspace and overcomes other limitations of discrete-time models often proposed in\nthe literature. In order to test our approach, we develop a new discrete-event\nsimulator and use double deep q-learning to train our decision agents.\nNumerical experiments are carried out in realistic scenarios using data from\nNew York City. We compare the policies obtained through our approach with\nheuristic policies often used in practice. Results show that our policies\nexhibit better average waiting times, cancellation rates and total service\ntimes, with reduction in average waiting times of up to 50% relative to the\nother tested heuristic policies.",
          "link": "http://arxiv.org/abs/2307.07508",
          "publishedOn": "2023-07-17T01:05:35.754Z",
          "wordCount": 723,
          "title": "Deep reinforcement learning for the dynamic vehicle dispatching problem: An event-based approach. (arXiv:2307.07508v1 [cs.AI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07167",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fakorede_O/0/1/0/all/0/1\">Olukorede Fakorede</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nirala_A/0/1/0/all/0/1\">Ashutosh Kumar Nirala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atsague_M/0/1/0/all/0/1\">Modeste Atsague</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_J/0/1/0/all/0/1\">Jin Tian</a>",
          "description": "Adversarial Training (AT) has been found to substantially improve the\nrobustness of deep learning classifiers against adversarial attacks. AT\ninvolves obtaining robustness by including adversarial examples in training a\nclassifier. Most variants of AT algorithms treat every training example\nequally. However, recent works have shown that better performance is achievable\nby treating them unequally. In addition, it has been observed that AT exerts an\nuneven influence on different classes in a training set and unfairly hurts\nexamples corresponding to classes that are inherently harder to classify.\nConsequently, various reweighting schemes have been proposed that assign\nunequal weights to robust losses of individual examples in a training set. In\nthis work, we propose a novel instance-wise reweighting scheme. It considers\nthe vulnerability of each natural example and the resulting information loss on\nits adversarial counterpart occasioned by adversarial attacks. Through\nextensive experiments, we show that our proposed method significantly improves\nover existing reweighting schemes, especially against strong white and\nblack-box attacks.",
          "link": "http://arxiv.org/abs/2307.07167",
          "publishedOn": "2023-07-17T01:05:35.749Z",
          "wordCount": 668,
          "title": "Vulnerability-Aware Instance Reweighting For Adversarial Training. (arXiv:2307.07167v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07081",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ilie_Ablachim_D/0/1/0/all/0/1\">Denis C. Ilie-Ablachim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dumitrescu_B/0/1/0/all/0/1\">Bogdan Dumitrescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rusu_C/0/1/0/all/0/1\">Cristian Rusu</a>",
          "description": "This paper presents a kernelized version of the t-SNE algorithm, capable of\nmapping high-dimensional data to a low-dimensional space while preserving the\npairwise distances between the data points in a non-Euclidean metric. This can\nbe achieved using a kernel trick only in the high dimensional space or in both\nspaces, leading to an end-to-end kernelized version. The proposed kernelized\nversion of the t-SNE algorithm can offer new views on the relationships between\ndata points, which can improve performance and accuracy in particular\napplications, such as classification problems involving kernel methods. The\ndifferences between t-SNE and its kernelized version are illustrated for\nseveral datasets, showing a neater clustering of points belonging to different\nclasses.",
          "link": "http://arxiv.org/abs/2307.07081",
          "publishedOn": "2023-07-17T01:05:35.738Z",
          "wordCount": 607,
          "title": "Kernel t-distributed stochastic neighbor embedding. (arXiv:2307.07081v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.15609",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Glyn_Davies_A/0/1/0/all/0/1\">Alex Glyn-Davies</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Duffin_C/0/1/0/all/0/1\">Connor Duffin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Akyildiz_O/0/1/0/all/0/1\">&#xd6;. Deniz Akyildiz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Girolami_M/0/1/0/all/0/1\">Mark Girolami</a>",
          "description": "Incorporating unstructured data into physical models is a challenging problem\nthat is emerging in data assimilation. Traditional approaches focus on\nwell-defined observation operators whose functional forms are typically assumed\nto be known. This prevents these methods from achieving a consistent model-data\nsynthesis in configurations where the mapping from data-space to model-space is\nunknown. To address these shortcomings, in this paper we develop a\nphysics-informed dynamical variational autoencoder ($\\Phi$-DVAE) to embed\ndiverse data streams into time-evolving physical systems described by\ndifferential equations. Our approach combines a standard, possibly nonlinear,\nfilter for the latent state-space model and a VAE, to assimilate the\nunstructured data into the latent dynamical system. Unstructured data, in our\nexample systems, comes in the form of video data and velocity field\nmeasurements, however the methodology is suitably generic to allow for\narbitrary unknown observation operators. A variational Bayesian framework is\nused for the joint estimation of the encoding, latent states, and unknown\nsystem parameters. To demonstrate the method, we provide case studies with the\nLorenz-63 ordinary differential equation, and the advection and Korteweg-de\nVries partial differential equations. Our results, with synthetic data, show\nthat $\\Phi$-DVAE provides a data efficient dynamics encoding methodology which\nis competitive with standard approaches. Unknown parameters are recovered with\nuncertainty quantification, and unseen data are accurately predicted.",
          "link": "http://arxiv.org/abs/2209.15609",
          "publishedOn": "2023-07-17T01:05:35.727Z",
          "wordCount": null,
          "title": "$\\Phi$-DVAE: Physics-Informed Dynamical Variational Autoencoders for Unstructured Data Assimilation. (arXiv:2209.15609v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07322",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Turner_M/0/1/0/all/0/1\">Mark Turner</a>, <a href=\"http://arxiv.org/find/math/1/au:+Berthold_T/0/1/0/all/0/1\">Timo Berthold</a>, <a href=\"http://arxiv.org/find/math/1/au:+Besancon_M/0/1/0/all/0/1\">Mathieu Besan&#xe7;on</a>",
          "description": "The current cut selection algorithm used in mixed-integer programming solvers\nhas remained largely unchanged since its creation. In this paper, we propose a\nset of new cut scoring measures, cut filtering techniques, and stopping\ncriteria, extending the current state-of-the-art algorithm and obtaining a 4\\%\nperformance improvement for SCIP over the MIPLIB 2017 benchmark set.",
          "link": "http://arxiv.org/abs/2307.07322",
          "publishedOn": "2023-07-17T01:05:35.726Z",
          "wordCount": 562,
          "title": "A Context-Aware Cutting Plane Selection Algorithm for Mixed-Integer Programming. (arXiv:2307.07322v1 [math.OC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07191",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhixian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Q/0/1/0/all/0/1\">Qingsong Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chaoli Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Liang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krannichfeldt_L/0/1/0/all/0/1\">Leandro Von Krannichfeldt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yi Wang</a>",
          "description": "Load forecasting is of great significance in the power industry as it can\nprovide a reference for subsequent tasks such as power grid dispatch, thus\nbringing huge economic benefits. However, there are many differences between\nload forecasting and traditional time series forecasting. On the one hand, load\nforecasting aims to minimize the cost of subsequent tasks such as power grid\ndispatch, rather than simply pursuing prediction accuracy. On the other hand,\nthe load is largely influenced by many external factors, such as temperature or\ncalendar variables. In addition, the scale of predictions (such as\nbuilding-level loads and aggregated-level loads) can also significantly impact\nthe predicted results. In this paper, we provide a comprehensive load\nforecasting archive, which includes load domain-specific feature engineering to\nhelp forecasting models better model load data. In addition, different from the\ntraditional loss function which only aims for accuracy, we also provide a\nmethod to customize the loss function based on the forecasting error,\nintegrating it into our forecasting framework. Based on this, we conducted\nextensive experiments on load data at different levels, providing a reference\nfor researchers to compare different load forecasting models.",
          "link": "http://arxiv.org/abs/2307.07191",
          "publishedOn": "2023-07-17T01:05:35.696Z",
          "wordCount": 703,
          "title": "Benchmarks and Custom Package for Electrical Load Forecasting. (arXiv:2307.07191v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07317",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Waterschoot_C/0/1/0/all/0/1\">Cedric Waterschoot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosch_A/0/1/0/all/0/1\">Antal van den Bosch</a>",
          "description": "Online news outlets are grappling with the moderation of user-generated\ncontent within their comment section. We present a recommender system based on\nranking class probabilities to support and empower the moderator in choosing\nfeatured posts, a time-consuming task. By combining user and textual content\nfeatures we obtain an optimal classification F1-score of 0.44 on the test set.\nFurthermore, we observe an optimum mean NDCG@5 of 0.87 on a large set of\nvalidation articles. As an expert evaluation, content moderators assessed the\noutput of a random selection of articles by choosing comments to feature based\non the recommendations, which resulted in a NDCG score of 0.83. We conclude\nthat first, adding text features yields the best score and second, while\nchoosing featured content remains somewhat subjective, content moderators found\nsuitable comments in all but one evaluated recommendations. We end the paper by\nanalyzing our best-performing model, a step towards transparency and\nexplainability in hybrid content moderation.",
          "link": "http://arxiv.org/abs/2307.07317",
          "publishedOn": "2023-07-17T01:05:35.692Z",
          "wordCount": 671,
          "title": "Hybrid moderation in the newsroom: Recommending featured posts to content moderators. (arXiv:2307.07317v1 [cs.IR])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07119",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Goyle_K/0/1/0/all/0/1\">Kartikay Goyle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1\">Quin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyle_V/0/1/0/all/0/1\">Vakul Goyle</a>",
          "description": "Current automated machine learning (ML) tools are model-centric, focusing on\nmodel selection and parameter optimization. However, the majority of the time\nin data analysis is devoted to data cleaning and wrangling, for which limited\ntools are available. Here we present DataAssist, an automated data preparation\nand cleaning platform that enhances dataset quality using ML-informed methods.\nWe show that DataAssist provides a pipeline for exploratory data analysis and\ndata cleaning, including generating visualization for user-selected variables,\nunifying data annotation, suggesting anomaly removal, and preprocessing data.\nThe exported dataset can be readily integrated with other autoML tools or\nuser-specified model for downstream analysis. Our data-centric tool is\napplicable to a variety of fields, including economics, business, and\nforecasting applications saving over 50\\% time of the time spent on data\ncleansing and preparation.",
          "link": "http://arxiv.org/abs/2307.07119",
          "publishedOn": "2023-07-17T01:05:35.668Z",
          "wordCount": 648,
          "title": "DataAssist: A Machine Learning Approach to Data Cleaning and Preparation. (arXiv:2307.07119v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07195",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haluszczynski_A/0/1/0/all/0/1\">Alexander Haluszczynski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koglmayr_D/0/1/0/all/0/1\">Daniel K&#xf6;glmayr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rath_C/0/1/0/all/0/1\">Christoph R&#xe4;th</a>",
          "description": "Controlling nonlinear dynamical systems using machine learning allows to not\nonly drive systems into simple behavior like periodicity but also to more\ncomplex arbitrary dynamics. For this, it is crucial that a machine learning\nsystem can be trained to reproduce the target dynamics sufficiently well. On\nthe example of forcing a chaotic parametrization of the Lorenz system into\nintermittent dynamics, we show first that classical reservoir computing excels\nat this task. In a next step, we compare those results based on different\namounts of training data to an alternative setup, where next-generation\nreservoir computing is used instead. It turns out that while delivering\ncomparable performance for usual amounts of training data, next-generation RC\nsignificantly outperforms in situations where only very limited data is\navailable. This opens even further practical control applications in real world\nproblems where data is restricted.",
          "link": "http://arxiv.org/abs/2307.07195",
          "publishedOn": "2023-07-17T01:05:35.656Z",
          "wordCount": 691,
          "title": "Controlling dynamical systems to complex target states using machine learning: next-generation vs. classical reservoir computing. (arXiv:2307.07195v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07346",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1\">Lianyu Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Junjie Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Mudi Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zengyou He</a>",
          "description": "The objective of clusterability evaluation is to check whether a clustering\nstructure exists within the data set. As a crucial yet often-overlooked issue\nin cluster analysis, it is essential to conduct such a test before applying any\nclustering algorithm. If a data set is unclusterable, any subsequent clustering\nanalysis would not yield valid results. Despite its importance, the majority of\nexisting studies focus on numerical data, leaving the clusterability evaluation\nissue for categorical data as an open problem. Here we present TestCat, a\ntesting-based approach to assess the clusterability of categorical data in\nterms of an analytical $p$-value. The key idea underlying TestCat is that\nclusterable categorical data possess many strongly correlated attribute pairs\nand hence the sum of chi-squared statistics of all attribute pairs is employed\nas the test statistic for $p$-value calculation. We apply our method to a set\nof benchmark categorical data sets, showing that TestCat outperforms those\nsolutions based on existing clusterability evaluation methods for numeric data.\nTo the best of our knowledge, our work provides the first way to effectively\nrecognize the clusterability of categorical data in a statistically sound\nmanner.",
          "link": "http://arxiv.org/abs/2307.07346",
          "publishedOn": "2023-07-17T01:05:35.652Z",
          "wordCount": 710,
          "title": "A testing-based approach to assess the clusterability of categorical data. (arXiv:2307.07346v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07454",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Garcia_Esteban_J/0/1/0/all/0/1\">Juan Jos&#xe9; Garc&#xed;a-Esteban</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Cuevas_J/0/1/0/all/0/1\">Juan Carlos Cuevas</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bravo_Abad_J/0/1/0/all/0/1\">Jorge Bravo-Abad</a>",
          "description": "Generative adversarial networks (GANs) are one of the most robust and\nversatile techniques in the field of generative artificial intelligence. In\nthis work, we report on an application of GANs in the domain of synthetic\nspectral data generation, offering a solution to the scarcity of data found in\nvarious scientific contexts. We demonstrate the proposed approach by applying\nit to an illustrative problem within the realm of near-field radiative heat\ntransfer involving a multilayered hyperbolic metamaterial. We find that a\nsuccessful generation of spectral data requires two modifications to\nconventional GANs: (i) the introduction of Wasserstein GANs (WGANs) to avoid\nmode collapse, and, (ii) the conditioning of WGANs to obtain accurate labels\nfor the generated data. We show that a simple feed-forward neural network\n(FFNN), when augmented with data generated by a CWGAN, enhances significantly\nits performance under conditions of limited data availability, demonstrating\nthe intrinsic value of CWGAN data augmentation beyond simply providing larger\ndatasets. In addition, we show that CWGANs can act as a surrogate model with\nimproved performance in the low-data regime with respect to simple FFNNs.\nOverall, this work highlights the potential of generative machine learning\nalgorithms in scientific applications beyond image generation and optimization.",
          "link": "http://arxiv.org/abs/2307.07454",
          "publishedOn": "2023-07-17T01:05:35.647Z",
          "wordCount": 705,
          "title": "Generative adversarial networks for data-scarce spectral applications. (arXiv:2307.07454v1 [physics.optics])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07050",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Neklyudov_K/0/1/0/all/0/1\">Kirill Neklyudov</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Nys_J/0/1/0/all/0/1\">Jannes Nys</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Thiede_L/0/1/0/all/0/1\">Luca Thiede</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Carrasquilla_J/0/1/0/all/0/1\">Juan Carrasquilla</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Liu_Q/0/1/0/all/0/1\">Qiang Liu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Welling_M/0/1/0/all/0/1\">Max Welling</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Makhzani_A/0/1/0/all/0/1\">Alireza Makhzani</a>",
          "description": "Solving the quantum many-body Schr\\\"odinger equation is a fundamental and\nchallenging problem in the fields of quantum physics, quantum chemistry, and\nmaterial sciences. One of the common computational approaches to this problem\nis Quantum Variational Monte Carlo (QVMC), in which ground-state solutions are\nobtained by minimizing the energy of the system within a restricted family of\nparameterized wave functions. Deep learning methods partially address the\nlimitations of traditional QVMC by representing a rich family of wave functions\nin terms of neural networks. However, the optimization objective in QVMC\nremains notoriously hard to minimize and requires second-order optimization\nmethods such as natural gradient. In this paper, we first reformulate energy\nfunctional minimization in the space of Born distributions corresponding to\nparticle-permutation (anti-)symmetric wave functions, rather than the space of\nwave functions. We then interpret QVMC as the Fisher--Rao gradient flow in this\ndistributional space, followed by a projection step onto the variational\nmanifold. This perspective provides us with a principled framework to derive\nnew QMC algorithms, by endowing the distributional space with better metrics,\nand following the projected gradient flow induced by those metrics. More\nspecifically, we propose \"Wasserstein Quantum Monte Carlo\" (WQMC), which uses\nthe gradient flow induced by the Wasserstein metric, rather than Fisher--Rao\nmetric, and corresponds to transporting the probability mass, rather than\nteleporting it. We demonstrate empirically that the dynamics of WQMC results in\nfaster convergence to the ground state of molecular systems.",
          "link": "http://arxiv.org/abs/2307.07050",
          "publishedOn": "2023-07-17T01:05:35.638Z",
          "wordCount": 771,
          "title": "Wasserstein Quantum Monte Carlo: A Novel Approach for Solving the Quantum Many-Body Schr\\\"odinger Equation. (arXiv:2307.07050v1 [physics.comp-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07423",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bleich_A/0/1/0/all/0/1\">Amnon Bleich</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Linnemann_A/0/1/0/all/0/1\">Antje Linnemann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jaidi_B/0/1/0/all/0/1\">Benjamin Jaidi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Diem_B/0/1/0/all/0/1\">Bj&#xf6;rn H Diem</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Conrad_T/0/1/0/all/0/1\">Tim OF Conrad</a>",
          "description": "Implantable Cardiac Monitor (ICM) devices are demonstrating as of today, the\nfastest-growing market for implantable cardiac devices. As such, they are\nbecoming increasingly common in patients for measuring heart electrical\nactivity. ICMs constantly monitor and record a patient's heart rhythm and when\ntriggered - send it to a secure server where health care professionals (denote\nHCPs from here on) can review it. These devices employ a relatively simplistic\nrule-based algorithm (due to energy consumption constraints) to alert for\nabnormal heart rhythms. This algorithm is usually parameterized to an\nover-sensitive mode in order to not miss a case (resulting in relatively high\nfalse-positive rate) and this, combined with the device's nature of constantly\nmonitoring the heart rhythm and its growing popularity, results in HCPs having\nto analyze and diagnose an increasingly growing amount of data. In order to\nreduce the load on the latter, automated methods for ECG analysis are nowadays\nbecoming a great tool to assist HCPs in their analysis. While state-of-the-art\nalgorithms are data-driven rather than rule-based, training data for ICMs often\nconsist of specific characteristics which make its analysis unique and\nparticularly challenging. This study presents the challenges and solutions in\nautomatically analyzing ICM data and introduces a method for its classification\nthat outperforms existing methods on such data. As such, it could be used in\nnumerous ways such as aiding HCPs in the analysis of ECGs originating from ICMs\nby e.g. suggesting a rhythm type.",
          "link": "http://arxiv.org/abs/2307.07423",
          "publishedOn": "2023-07-17T01:05:35.626Z",
          "wordCount": 781,
          "title": "Enhancing ECG Analysis of Implantable Cardiac Monitor Data: An Efficient Pipeline for Multi-Label Classification. (arXiv:2307.07423v1 [eess.SP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07325",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Krishna_V/0/1/0/all/0/1\">Varun Krishna</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sai_T/0/1/0/all/0/1\">Tarun Sai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ganapathy_S/0/1/0/all/0/1\">Sriram Ganapathy</a>",
          "description": "The representation learning of speech, without textual resources, is an area\nof significant interest for many low resource speech applications. In this\npaper, we describe an approach to self-supervised representation learning from\nraw audio using a hidden unit clustering (HUC) framework. The input to the\nmodel consists of audio samples that are windowed and processed with 1-D\nconvolutional layers. The learned \"time-frequency\" representations from the\nconvolutional neural network (CNN) module are further processed with long short\nterm memory (LSTM) layers which generate a contextual vector representation for\nevery windowed segment. The HUC framework, allowing the categorization of the\nrepresentations into a small number of phoneme-like units, is used to train the\nmodel for learning semantically rich speech representations. The targets\nconsist of phoneme-like pseudo labels for each audio segment and these are\ngenerated with an iterative k-means algorithm. We explore techniques that\nimprove the speaker invariance of the learned representations and illustrate\nthe effectiveness of the proposed approach on two settings, i) completely\nunsupervised speech applications on the sub-tasks described as part of the\nZeroSpeech 2021 challenge and ii) semi-supervised automatic speech recognition\n(ASR) applications on the TIMIT dataset and on the GramVaani challenge Hindi\ndataset. In these experiments, we achieve state-of-art results for various\nZeroSpeech tasks. Further, on the ASR experiments, the HUC representations are\nshown to improve significantly over other established benchmarks based on\nWav2vec, HuBERT and Best-RQ.",
          "link": "http://arxiv.org/abs/2307.07325",
          "publishedOn": "2023-07-17T01:05:35.617Z",
          "wordCount": 752,
          "title": "Representation Learning With Hidden Unit Clustering For Low Resource Speech Applications. (arXiv:2307.07325v1 [eess.AS])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Z/0/1/0/all/0/1\">Zheng Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhenya Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chuanren Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hengshu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1\">Enhong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Hui Xiong</a>",
          "description": "Machine learning algorithms have become ubiquitous in a number of\napplications (e.g. image classification). However, due to the insufficient\nmeasurement of traditional metrics (e.g. the coarse-grained Accuracy of each\nclassifier), substantial gaps are usually observed between the real-world\nperformance of these algorithms and their scores in standardized evaluations.\nIn this paper, inspired by the psychometric theories from human measurement, we\npropose a task-agnostic evaluation framework Camilla, where a multi-dimensional\ndiagnostic metric Ability is defined for collaboratively measuring the\nmultifaceted strength of each machine learning algorithm. Specifically, given\nthe response logs from different algorithms to data samples, we leverage\ncognitive diagnosis assumptions and neural networks to learn the complex\ninteractions among algorithms, samples and the skills (explicitly or implicitly\npre-defined) of each sample. In this way, both the abilities of each algorithm\non multiple skills and some of the sample factors (e.g. sample difficulty) can\nbe simultaneously quantified. We conduct extensive experiments with hundreds of\nmachine learning algorithms on four public datasets, and our experimental\nresults demonstrate that Camilla not only can capture the pros and cons of each\nalgorithm more precisely, but also outperforms state-of-the-art baselines on\nthe metric reliability, rank consistency and rank stability.",
          "link": "http://arxiv.org/abs/2307.07134",
          "publishedOn": "2023-07-17T01:05:35.575Z",
          "wordCount": 708,
          "title": "Multi-Dimensional Ability Diagnosis for Machine Learning Algorithms. (arXiv:2307.07134v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07051",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Hongyi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yixin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Lavender Yao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oermann_E/0/1/0/all/0/1\">Eric Karl Oermann</a>",
          "description": "Recent advances in large language models have led to renewed interest in\nnatural language processing in healthcare using the free text of clinical\nnotes. One distinguishing characteristic of clinical notes is their long time\nspan over multiple long documents. The unique structure of clinical notes\ncreates a new design choice: when the context length for a language model\npredictor is limited, which part of clinical notes should we choose as the\ninput? Existing studies either choose the inputs with domain knowledge or\nsimply truncate them. We propose a framework to analyze the sections with high\npredictive power. Using MIMIC-III, we show that: 1) predictive power\ndistribution is different between nursing notes and discharge notes and 2)\ncombining different types of notes could improve performance when the context\nlength is large. Our findings suggest that a carefully selected sampling\nfunction could enable more efficient information extraction from clinical\nnotes.",
          "link": "http://arxiv.org/abs/2307.07051",
          "publishedOn": "2023-07-17T01:05:35.528Z",
          "wordCount": 726,
          "title": "Making the Most Out of the Limited Context Length: Predictive Power Varies with Clinical Note Type and Note Section. (arXiv:2307.07051v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07172",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1\">Jingjing Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Min Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Sheng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Hui Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xuefeng Jiang</a>",
          "description": "Federated Learning (FL) emerges as a distributed machine learning paradigm\nwithout end-user data transmission, effectively avoiding privacy leakage.\nParticipating devices in FL are usually bandwidth-constrained, and the uplink\nis much slower than the downlink in wireless networks, which causes a severe\nuplink communication bottleneck. A prominent direction to alleviate this\nproblem is federated dropout, which drops fractional weights of local models.\nHowever, existing federated dropout studies focus on random or ordered dropout\nand lack theoretical support, resulting in unguaranteed performance. In this\npaper, we propose Federated learning with Bayesian Inference-based Adaptive\nDropout (FedBIAD), which regards weight rows of local models as probability\ndistributions and adaptively drops partial weight rows based on importance\nindicators correlated with the trend of local training loss. By applying\nFedBIAD, each client adaptively selects a high-quality dropping pattern with\naccurate approximations and only transmits parameters of non-dropped weight\nrows to mitigate uplink costs while improving accuracy. Theoretical analysis\ndemonstrates that the convergence rate of the average generalization error of\nFedBIAD is minimax optimal up to a squared logarithmic factor. Extensive\nexperiments on image classification and next-word prediction show that compared\nwith status quo approaches, FedBIAD provides 2x uplink reduction with an\naccuracy increase of up to 2.41% even on non-Independent and Identically\nDistributed (non-IID) data, which brings up to 72% decrease in training time.",
          "link": "http://arxiv.org/abs/2307.07172",
          "publishedOn": "2023-07-17T01:05:35.474Z",
          "wordCount": 774,
          "title": "FedBIAD: Communication-Efficient and Accuracy-Guaranteed Federated Learning with Bayesian Inference-Based Adaptive Dropout. (arXiv:2307.07172v1 [cs.DC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07160",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Golchin_S/0/1/0/all/0/1\">Shahriar Golchin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Surdeanu_M/0/1/0/all/0/1\">Mihai Surdeanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tavabi_N/0/1/0/all/0/1\">Nazgol Tavabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiapour_A/0/1/0/all/0/1\">Ata Kiapour</a>",
          "description": "We propose a novel task-agnostic in-domain pre-training method that sits\nbetween generic pre-training and fine-tuning. Our approach selectively masks\nin-domain keywords, i.e., words that provide a compact representation of the\ntarget domain. We identify such keywords using KeyBERT (Grootendorst, 2020). We\nevaluate our approach using six different settings: three datasets combined\nwith two distinct pre-trained language models (PLMs). Our results reveal that\nthe fine-tuned PLMs adapted using our in-domain pre-training strategy\noutperform PLMs that used in-domain pre-training with random masking as well as\nthose that followed the common pre-train-then-fine-tune paradigm. Further, the\noverhead of identifying in-domain keywords is reasonable, e.g., 7-15% of the\npre-training time (for two epochs) for BERT Large (Devlin et al., 2019).",
          "link": "http://arxiv.org/abs/2307.07160",
          "publishedOn": "2023-07-17T01:05:35.419Z",
          "wordCount": 643,
          "title": "Do not Mask Randomly: Effective Domain-adaptive Pre-training by Masking In-domain Keywords. (arXiv:2307.07160v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07176",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Weidong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1\">Jiaming Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Borong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_C/0/1/0/all/0/1\">Chunhe Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yaodong Yang</a>",
          "description": "The widespread application of Reinforcement Learning (RL) in real-world\nsituations is yet to come to fruition, largely as a result of its failure to\nsatisfy the essential safety demands of such systems. Existing safe\nreinforcement learning (SafeRL) methods, employing cost functions to enhance\nsafety, fail to achieve zero-cost in complex scenarios, including vision-only\ntasks, even with comprehensive data sampling and training. To address this, we\nintroduce Safe DreamerV3, a novel algorithm that integrates both\nLagrangian-based and planning-based methods within a world model. Our\nmethodology represents a significant advancement in SafeRL as the first\nalgorithm to achieve nearly zero-cost in both low-dimensional and vision-only\ntasks within the Safety-Gymnasium benchmark. Our project website can be found\nin: https://sites.google.com/view/safedreamerv3.",
          "link": "http://arxiv.org/abs/2307.07176",
          "publishedOn": "2023-07-17T01:05:35.228Z",
          "wordCount": null,
          "title": "Safe DreamerV3: Safe Reinforcement Learning with World Models. (arXiv:2307.07176v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07443",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Chen Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Huayi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhirui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1\">Hong Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>",
          "description": "Molecular property prediction has gained significant attention due to its\ntransformative potential in multiple scientific disciplines. Conventionally, a\nmolecule graph can be represented either as a graph-structured data or a SMILES\ntext. Recently, the rapid development of Large Language Models (LLMs) has\nrevolutionized the field of NLP. Although it is natural to utilize LLMs to\nassist in understanding molecules represented by SMILES, the exploration of how\nLLMs will impact molecular property prediction is still in its early stage. In\nthis work, we advance towards this objective through two perspectives:\nzero/few-shot molecular classification, and using the new explanations\ngenerated by LLMs as representations of molecules. To be specific, we first\nprompt LLMs to do in-context molecular classification and evaluate their\nperformance. After that, we employ LLMs to generate semantically enriched\nexplanations for the original SMILES and then leverage that to fine-tune a\nsmall-scale LM model for multiple downstream tasks. The experimental results\nhighlight the superiority of text explanations as molecular representations\nacross multiple benchmark datasets, and confirm the immense potential of LLMs\nin molecular property prediction tasks. Codes are available at\n\\url{https://github.com/ChnQ/LLM4Mol}.",
          "link": "http://arxiv.org/abs/2307.07443",
          "publishedOn": "2023-07-17T01:05:35.228Z",
          "wordCount": null,
          "title": "Can Large Language Models Empower Molecular Property Prediction?. (arXiv:2307.07443v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06978",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hughes_A/0/1/0/all/0/1\">Aidan J. Hughes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poole_J/0/1/0/all/0/1\">Jack Poole</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dervilis_N/0/1/0/all/0/1\">Nikolaos Dervilis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gardner_P/0/1/0/all/0/1\">Paul Gardner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Worden_K/0/1/0/all/0/1\">Keith Worden</a>",
          "description": "Decision-support for the operation and maintenance of structures provides\nsignificant motivation for the development and implementation of structural\nhealth monitoring (SHM) systems. Unfortunately, the limited availability of\nlabelled training data hinders the development of the statistical models on\nwhich these decision-support systems rely. Population-based SHM seeks to\nmitigate the impact of data scarcity by using transfer learning techniques to\nshare information between individual structures within a population. The\ncurrent paper proposes a decision framework for selecting transfer strategies\nbased upon a novel concept -- the expected value of information transfer --\nsuch that negative transfer is avoided. By avoiding negative transfer, and by\noptimising information transfer strategies using the transfer-decision\nframework, one can reduce the costs associated with operating and maintaining\nstructures, and improve safety.",
          "link": "http://arxiv.org/abs/2307.06978",
          "publishedOn": "2023-07-17T01:05:35.227Z",
          "wordCount": null,
          "title": "A decision framework for selecting information-transfer strategies in population-based SHM. (arXiv:2307.06978v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07113",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Mancino_Ball_G/0/1/0/all/0/1\">Gabriel Mancino-Ball</a>, <a href=\"http://arxiv.org/find/math/1/au:+Xu_Y/0/1/0/all/0/1\">Yangyang Xu</a>",
          "description": "In this paper, we consider the decentralized, stochastic nonconvex\nstrongly-concave (NCSC) minimax problem with nonsmooth regularization terms on\nboth primal and dual variables, wherein a network of $m$ computing agents\ncollaborate via peer-to-peer communications. We consider when the coupling\nfunction is in expectation or finite-sum form and the double regularizers are\nconvex functions, applied separately to the primal and dual variables. Our\nalgorithmic framework introduces a Lagrangian multiplier to eliminate the\nconsensus constraint on the dual variable. Coupling this with\nvariance-reduction (VR) techniques, our proposed method, entitled VRLM, by a\nsingle neighbor communication per iteration, is able to achieve an\n$\\mathcal{O}(\\kappa^3\\varepsilon^{-3})$ sample complexity under the general\nstochastic setting, with either a big-batch or small-batch VR option, where\n$\\kappa$ is the condition number of the problem and $\\varepsilon$ is the\ndesired solution accuracy. With a big-batch VR, we can additionally achieve\n$\\mathcal{O}(\\kappa^2\\varepsilon^{-2})$ communication complexity. Under the\nspecial finite-sum setting, our method with a big-batch VR can achieve an\n$\\mathcal{O}(n + \\sqrt{n} \\kappa^2\\varepsilon^{-2})$ sample complexity and\n$\\mathcal{O}(\\kappa^2\\varepsilon^{-2})$ communication complexity, where $n$ is\nthe number of components in the finite sum. All complexity results match the\nbest-known results achieved by a few existing methods for solving special cases\nof the problem we consider. To the best of our knowledge, this is the first\nwork which provides convergence guarantees for NCSC minimax problems with\ngeneral convex nonsmooth regularizers applied to both the primal and dual\nvariables in the decentralized stochastic setting. Numerical experiments are\nconducted on two machine learning problems. Our code is downloadable from\nhttps://github.com/RPI-OPT/VRLM.",
          "link": "http://arxiv.org/abs/2307.07113",
          "publishedOn": "2023-07-17T01:05:35.226Z",
          "wordCount": null,
          "title": "Variance-reduced accelerated methods for decentralized stochastic double-regularized nonconvex strongly-concave minimax problems. (arXiv:2307.07113v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chaszczewicz_A/0/1/0/all/0/1\">Alicja Chaszczewicz</a>",
          "description": "Our work serves as a framework for unifying the challenges of contemporary\nexplainable AI (XAI). We demonstrate that while XAI methods provide\nsupplementary and potentially useful output for machine learning models,\nresearchers and decision-makers should be mindful of their conceptual and\ntechnical limitations, which frequently result in these methods themselves\nbecoming black boxes. We examine three XAI research avenues spanning image,\ntextual, and graph data, covering saliency, attention, and graph-type\nexplainers. Despite the varying contexts and timeframes of the mentioned cases,\nthe same persistent roadblocks emerge, highlighting the need for a conceptual\nbreakthrough in the field to address the challenge of compatibility between XAI\nmethods and application tasks.",
          "link": "http://arxiv.org/abs/2307.06963",
          "publishedOn": "2023-07-17T01:05:35.224Z",
          "wordCount": null,
          "title": "Is Task-Agnostic Explainable AI a Myth?. (arXiv:2307.06963v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07269",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hanif_A/0/1/0/all/0/1\">Asif Hanif</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Naseer_M/0/1/0/all/0/1\">Muzammal Naseer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Khan_S/0/1/0/all/0/1\">Salman Khan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shah_M/0/1/0/all/0/1\">Mubarak Shah</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Khan_F/0/1/0/all/0/1\">Fahad Shahbaz Khan</a>",
          "description": "It is imperative to ensure the robustness of deep learning models in critical\napplications such as, healthcare. While recent advances in deep learning have\nimproved the performance of volumetric medical image segmentation models, these\nmodels cannot be deployed for real-world applications immediately due to their\nvulnerability to adversarial attacks. We present a 3D frequency domain\nadversarial attack for volumetric medical image segmentation models and\ndemonstrate its advantages over conventional input or voxel domain attacks.\nUsing our proposed attack, we introduce a novel frequency domain adversarial\ntraining approach for optimizing a robust model against voxel and frequency\ndomain attacks. Moreover, we propose frequency consistency loss to regulate our\nfrequency domain adversarial training that achieves a better tradeoff between\nmodel's performance on clean and adversarial samples. Code is publicly\navailable at https://github.com/asif-hanif/vafa.",
          "link": "http://arxiv.org/abs/2307.07269",
          "publishedOn": "2023-07-17T01:05:35.224Z",
          "wordCount": null,
          "title": "Frequency Domain Adversarial Training for Robust Volumetric Medical Segmentation. (arXiv:2307.07269v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07302",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Baty_H/0/1/0/all/0/1\">Hubert Baty</a>",
          "description": "In this paper, numerical methods using Physics-Informed Neural Networks\n(PINNs) are presented with the aim to solve higher-order ordinary differential\nequations (ODEs). Indeed, this deep-learning technique is successfully applied\nfor solving different classes of singular ODEs, namely the well known\nsecond-order Lane-Emden equations, third order-order Emden-Fowler equations,\nand fourth-order Lane-Emden-Fowler equations. Two variants of PINNs technique\nare considered and compared. First, a minimization procedure is used to\nconstrain the total loss function of the neural network, in which the equation\nresidual is considered with some weight to form a physics-based loss and added\nto the training data loss that contains the initial/boundary conditions.\nSecond, a specific choice of trial solutions ensuring these conditions as hard\nconstraints is done in order to satisfy the differential equation, contrary to\nthe first variant based on training data where the constraints appear as soft\nones. Advantages and drawbacks of PINNs variants are highlighted.",
          "link": "http://arxiv.org/abs/2307.07302",
          "publishedOn": "2023-07-17T01:05:35.224Z",
          "wordCount": null,
          "title": "Solving higher-order Lane-Emden-Fowler type equations using physics-informed neural networks: benchmark tests comparing soft and hard constraints. (arXiv:2307.07302v1 [physics.comp-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1\">Byung-Kwan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Junho Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ro_Y/0/1/0/all/0/1\">Yong Man Ro</a>",
          "description": "Adversarial examples derived from deliberately crafted perturbations on\nvisual inputs can easily harm decision process of deep neural networks. To\nprevent potential threats, various adversarial training-based defense methods\nhave grown rapidly and become a de facto standard approach for robustness.\nDespite recent competitive achievements, we observe that adversarial\nvulnerability varies across targets and certain vulnerabilities remain\nprevalent. Intriguingly, such peculiar phenomenon cannot be relieved even with\ndeeper architectures and advanced defense methods. To address this issue, in\nthis paper, we introduce a causal approach called Adversarial Double Machine\nLearning (ADML), which allows us to quantify the degree of adversarial\nvulnerability for network predictions and capture the effect of treatments on\noutcome of interests. ADML can directly estimate causal parameter of\nadversarial perturbations per se and mitigate negative effects that can\npotentially damage robustness, bridging a causal perspective into the\nadversarial vulnerability. Through extensive experiments on various CNN and\nTransformer architectures, we corroborate that ADML improves adversarial\nrobustness with large margins and relieve the empirical observation.",
          "link": "http://arxiv.org/abs/2307.07250",
          "publishedOn": "2023-07-17T01:05:35.219Z",
          "wordCount": null,
          "title": "Mitigating Adversarial Vulnerability through Causal Parameter Estimation by Adversarial Double Machine Learning. (arXiv:2307.07250v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07344",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chaoyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Z/0/1/0/all/0/1\">Zhonghua Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1\">Carola-Bibiane Sch&#xf6;nlieb</a>",
          "description": "This paper proposes a novel approach to integrating partial differential\nequation (PDE)-based evolution models into neural networks through a new type\nof regularization. Specifically, we propose inverse evolution layers (IELs)\nbased on evolution equations. These layers can achieve specific regularization\nobjectives and endow neural networks' outputs with corresponding properties of\nthe evolution models. Moreover, IELs are straightforward to construct and\nimplement, and can be easily designed for various physical evolutions and\nneural networks. Additionally, the design process for these layers can provide\nneural networks with intuitive and mathematical interpretability, thus\nenhancing the transparency and explainability of the approach. To demonstrate\nthe effectiveness, efficiency, and simplicity of our approach, we present an\nexample of endowing semantic segmentation models with the smoothness property\nbased on the heat diffusion model. To achieve this goal, we design\nheat-diffusion IELs and apply them to address the challenge of semantic\nsegmentation with noisy labels. The experimental results demonstrate that the\nheat-diffusion IELs can effectively mitigate the overfitting problem caused by\nnoisy labels.",
          "link": "http://arxiv.org/abs/2307.07344",
          "publishedOn": "2023-07-17T01:05:35.219Z",
          "wordCount": null,
          "title": "Inverse Evolution Layers: Physics-informed Regularizers for Deep Neural Networks. (arXiv:2307.07344v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaofei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuting He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_C/0/1/0/all/0/1\">Cheng Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_R/0/1/0/all/0/1\">Rongjun Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Guanyu Yang</a>",
          "description": "The foundation models based on pre-training technology have significantly\nadvanced artificial intelligence from theoretical to practical applications.\nThese models have facilitated the feasibility of computer-aided diagnosis for\nwidespread use. Medical contrastive vision-language pre-training, which does\nnot require human annotations, is an effective approach for guiding\nrepresentation learning using description information in diagnostic reports.\nHowever, the effectiveness of pre-training is limited by the large-scale\nsemantic overlap and shifting problems in medical field. To address these\nissues, we propose the Knowledge-Boosting Contrastive Vision-Language\nPre-training framework (KoBo), which integrates clinical knowledge into the\nlearning of vision-language semantic consistency. The framework uses an\nunbiased, open-set sample-wise knowledge representation to measure negative\nsample noise and supplement the correspondence between vision-language mutual\ninformation and clinical knowledge. Extensive experiments validate the effect\nof our framework on eight tasks including classification, segmentation,\nretrieval, and semantic relatedness, achieving comparable or better performance\nwith the zero-shot or few-shot settings. Our code is open on\nhttps://github.com/ChenXiaoFei-CS/KoBo.",
          "link": "http://arxiv.org/abs/2307.07246",
          "publishedOn": "2023-07-17T01:05:35.218Z",
          "wordCount": null,
          "title": "Knowledge Boosting: Rethinking Medical Contrastive Vision-Language Pre-Training. (arXiv:2307.07246v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07396",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marette_T/0/1/0/all/0/1\">Thibault Marette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miettinen_P/0/1/0/all/0/1\">Pauli Miettinen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neumann_S/0/1/0/all/0/1\">Stefan Neumann</a>",
          "description": "Finding (bi-)clusters in bipartite graphs is a popular data analysis\napproach. Analysts typically want to visualize the clusters, which is simple as\nlong as the clusters are disjoint. However, many modern algorithms find\noverlapping clusters, making visualization more complicated. In this paper, we\nstudy the problem of visualizing \\emph{a given clustering} of overlapping\nclusters in bipartite graphs and the related problem of visualizing Boolean\nMatrix Factorizations. We conceptualize three different objectives that any\ngood visualization should satisfy: (1) proximity of cluster elements, (2) large\nconsecutive areas of elements from the same cluster, and (3) large\nuninterrupted areas in the visualization, regardless of the cluster membership.\nWe provide objective functions that capture these goals and algorithms that\noptimize these objective functions. Interestingly, in experiments on real-world\ndatasets, we find that the best trade-off between these competing goals is\nachieved by a novel heuristic, which locally aims to place rows and columns\nwith similar cluster membership next to each other.",
          "link": "http://arxiv.org/abs/2307.07396",
          "publishedOn": "2023-07-17T01:05:35.161Z",
          "wordCount": null,
          "title": "Visualizing Overlapping Biclusterings and Boolean Matrix Factorizations. (arXiv:2307.07396v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07298",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beetz_M/0/1/0/all/0/1\">Marcel Beetz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yilong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_A/0/1/0/all/0/1\">Abhirup Banerjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grau_V/0/1/0/all/0/1\">Vicente Grau</a>",
          "description": "Myocardial infarction (MI) is one of the most prevalent cardiovascular\ndiseases with associated clinical decision-making typically based on\nsingle-valued imaging biomarkers. However, such metrics only approximate the\ncomplex 3D structure and physiology of the heart and hence hinder a better\nunderstanding and prediction of MI outcomes. In this work, we investigate the\nutility of complete 3D cardiac shapes in the form of point clouds for an\nimproved detection of MI events. To this end, we propose a fully automatic\nmulti-step pipeline consisting of a 3D cardiac surface reconstruction step\nfollowed by a point cloud classification network. Our method utilizes recent\nadvances in geometric deep learning on point clouds to enable direct and\nefficient multi-scale learning on high-resolution surface models of the cardiac\nanatomy. We evaluate our approach on 1068 UK Biobank subjects for the tasks of\nprevalent MI detection and incident MI prediction and find improvements of ~13%\nand ~5% respectively over clinical benchmarks. Furthermore, we analyze the role\nof each ventricle and cardiac phase for 3D shape-based MI detection and conduct\na visual analysis of the morphological and physiological patterns typically\nassociated with MI outcomes.",
          "link": "http://arxiv.org/abs/2307.07298",
          "publishedOn": "2023-07-17T01:05:35.158Z",
          "wordCount": null,
          "title": "3D Shape-Based Myocardial Infarction Prediction Using Point Cloud Classification Networks. (arXiv:2307.07298v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07331",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ozturk_I/0/1/0/all/0/1\">Ibrahim Tolga &#xd6;zt&#xfc;rk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nedelchev_R/0/1/0/all/0/1\">Rostislav Nedelchev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heumann_C/0/1/0/all/0/1\">Christian Heumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arias_E/0/1/0/all/0/1\">Esteban Garces Arias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roger_M/0/1/0/all/0/1\">Marius Roger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bischl_B/0/1/0/all/0/1\">Bernd Bischl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Assenmacher_M/0/1/0/all/0/1\">Matthias A&#xdf;enmacher</a>",
          "description": "Recent studies have demonstrated how to assess the stereotypical bias in\npre-trained English language models. In this work, we extend this branch of\nresearch in multiple different dimensions by systematically investigating (a)\nmono- and multilingual models of (b) different underlying architectures with\nrespect to their bias in (c) multiple different languages. To that end, we make\nuse of the English StereoSet data set (Nadeem et al., 2021), which we\nsemi-automatically translate into German, French, Spanish, and Turkish. We find\nthat it is of major importance to conduct this type of analysis in a\nmultilingual setting, as our experiments show a much more nuanced picture as\nwell as notable differences from the English-only analysis. The main takeaways\nfrom our analysis are that mGPT-2 (partly) shows surprising anti-stereotypical\nbehavior across languages, English (monolingual) models exhibit the strongest\nbias, and the stereotypes reflected in the data set are least present in\nTurkish models. Finally, we release our codebase alongside the translated data\nsets and practical guidelines for the semi-automatic translation to encourage a\nfurther extension of our work to other languages.",
          "link": "http://arxiv.org/abs/2307.07331",
          "publishedOn": "2023-07-17T01:05:35.158Z",
          "wordCount": null,
          "title": "How Different Is Stereotypical Bias Across Languages?. (arXiv:2307.07331v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07055",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Hui Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kaixuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_C/0/1/0/all/0/1\">Chengzhuo Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Minshuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mengdi Wang</a>",
          "description": "We explore the methodology and theory of reward-directed generation via\nconditional diffusion models. Directed generation aims to generate samples with\ndesired properties as measured by a reward function, which has broad\napplications in generative AI, reinforcement learning, and computational\nbiology. We consider the common learning scenario where the data set consists\nof unlabeled data along with a smaller set of data with noisy reward labels.\nOur approach leverages a learned reward function on the smaller data set as a\npseudolabeler. From a theoretical standpoint, we show that this directed\ngenerator can effectively learn and sample from the reward-conditioned data\ndistribution. Additionally, our model is capable of recovering the latent\nsubspace representation of data. Moreover, we establish that the model\ngenerates a new population that moves closer to a user-specified target reward\nvalue, where the optimality gap aligns with the off-policy bandit regret in the\nfeature subspace. The improvement in rewards obtained is influenced by the\ninterplay between the strength of the reward signal, the distribution shift,\nand the cost of off-support extrapolation. We provide empirical results to\nvalidate our theory and highlight the relationship between the strength of\nextrapolation and the quality of generated samples.",
          "link": "http://arxiv.org/abs/2307.07055",
          "publishedOn": "2023-07-17T01:05:35.156Z",
          "wordCount": null,
          "title": "Reward-Directed Conditional Diffusion: Provable Distribution Estimation and Reward Improvement. (arXiv:2307.07055v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07107",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Renming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Canturk_S/0/1/0/all/0/1\">Semih Cant&#xfc;rk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lapointe_Gagne_O/0/1/0/all/0/1\">Olivier Lapointe-Gagn&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Letourneau_V/0/1/0/all/0/1\">Vincent L&#xe9;tourneau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_G/0/1/0/all/0/1\">Guy Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beaini_D/0/1/0/all/0/1\">Dominique Beaini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rampasek_L/0/1/0/all/0/1\">Ladislav Ramp&#xe1;&#x161;ek</a>",
          "description": "Positional and structural encodings (PSE) enable better identifiability of\nnodes within a graph, as in general graphs lack a canonical node ordering. This\nrenders PSEs essential tools for empowering modern GNNs, and in particular\ngraph Transformers. However, designing PSEs that work optimally for a variety\nof graph prediction tasks is a challenging and unsolved problem. Here, we\npresent the graph positional and structural encoder (GPSE), a first-ever\nattempt to train a graph encoder that captures rich PSE representations for\naugmenting any GNN. GPSE can effectively learn a common latent representation\nfor multiple PSEs, and is highly transferable. The encoder trained on a\nparticular graph dataset can be used effectively on datasets drawn from\nsignificantly different distributions and even modalities. We show that across\na wide range of benchmarks, GPSE-enhanced models can significantly improve the\nperformance in certain tasks, while performing on par with those that employ\nexplicitly computed PSEs in other cases. Our results pave the way for the\ndevelopment of large pre-trained models for extracting graph positional and\nstructural information and highlight their potential as a viable alternative to\nexplicitly computed PSEs as well as to existing self-supervised pre-training\napproaches.",
          "link": "http://arxiv.org/abs/2307.07107",
          "publishedOn": "2023-07-17T01:05:35.156Z",
          "wordCount": null,
          "title": "Graph Positional and Structural Encoder. (arXiv:2307.07107v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07405",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Axiotis_K/0/1/0/all/0/1\">Kyriakos Axiotis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yasuda_T/0/1/0/all/0/1\">Taisuke Yasuda</a>",
          "description": "Despite widespread adoption in practice, guarantees for the LASSO and Group\nLASSO are strikingly lacking in settings beyond statistical problems, and these\nalgorithms are usually considered to be a heuristic in the context of sparse\nconvex optimization on deterministic inputs. We give the first recovery\nguarantees for the Group LASSO for sparse convex optimization with\nvector-valued features. We show that if a sufficiently large Group LASSO\nregularization is applied when minimizing a strictly convex function $l$, then\nthe minimizer is a sparse vector supported on vector-valued features with the\nlargest $\\ell_2$ norm of the gradient. Thus, repeating this procedure selects\nthe same set of features as the Orthogonal Matching Pursuit algorithm, which\nadmits recovery guarantees for any function $l$ with restricted strong\nconvexity and smoothness via weak submodularity arguments. This answers open\nquestions of Tibshirani et al. and Yasuda et al. Our result is the first to\ntheoretically explain the empirical success of the Group LASSO for convex\nfunctions under general input instances assuming only restricted strong\nconvexity and smoothness. Our result also generalizes provable guarantees for\nthe Sequential Attention algorithm, which is a feature selection algorithm\ninspired by the attention mechanism proposed by Yasuda et al.\n\nAs an application of our result, we give new results for the column subset\nselection problem, which is well-studied when the loss is the Frobenius norm or\nother entrywise matrix losses. We give the first result for general loss\nfunctions for this problem that requires only restricted strong convexity and\nsmoothness.",
          "link": "http://arxiv.org/abs/2307.07405",
          "publishedOn": "2023-07-17T01:05:35.153Z",
          "wordCount": null,
          "title": "Performance of $\\ell_1$ Regularization for Sparse Convex Optimization. (arXiv:2307.07405v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07512",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kitouni_O/0/1/0/all/0/1\">Ouail Kitouni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nolte_N/0/1/0/all/0/1\">Niklas Nolte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_M/0/1/0/all/0/1\">Michael Williams</a>",
          "description": "The monotonic dependence of the outputs of a neural network on some of its\ninputs is a crucial inductive bias in many scenarios where domain knowledge\ndictates such behavior. This is especially important for interpretability and\nfairness considerations. In a broader context, scenarios in which monotonicity\nis important can be found in finance, medicine, physics, and other disciplines.\nIt is thus desirable to build neural network architectures that implement this\ninductive bias provably. In this work, we propose a weight-constrained\narchitecture with a single residual connection to achieve exact monotonic\ndependence in any subset of the inputs. The weight constraint scheme directly\ncontrols the Lipschitz constant of the neural network and thus provides the\nadditional benefit of robustness. Compared to currently existing techniques\nused for monotonicity, our method is simpler in implementation and in theory\nfoundations, has negligible computational overhead, is guaranteed to produce\nmonotonic dependence, and is highly expressive. We show how the algorithm is\nused to train powerful, robust, and interpretable discriminators that achieve\ncompetitive performance compared to current state-of-the-art methods across\nvarious benchmarks, from social applications to the classification of the\ndecays of subatomic particles produced at the CERN Large Hadron Collider.",
          "link": "http://arxiv.org/abs/2307.07512",
          "publishedOn": "2023-07-17T01:05:35.152Z",
          "wordCount": null,
          "title": "Expressive Monotonic Neural Networks. (arXiv:2307.07512v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1\">Akshansh Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jatti_V/0/1/0/all/0/1\">Vijaykumar S Jatti</a>",
          "description": "In this study, we investigate the application of supervised machine learning\nalgorithms for estimating the Ultimate Tensile Strength (UTS) of Polylactic\nAcid (PLA) specimens fabricated using the Fused Deposition Modeling (FDM)\nprocess. A total of 31 PLA specimens were prepared, with Infill Percentage,\nLayer Height, Print Speed, and Extrusion Temperature serving as input\nparameters. The primary objective was to assess the accuracy and effectiveness\nof four distinct supervised classification algorithms, namely Logistic\nClassification, Gradient Boosting Classification, Decision Tree, and K-Nearest\nNeighbor, in predicting the UTS of the specimens. The results revealed that\nwhile the Decision Tree and K-Nearest Neighbor algorithms both achieved an F1\nscore of 0.71, the KNN algorithm exhibited a higher Area Under the Curve (AUC)\nscore of 0.79, outperforming the other algorithms. This demonstrates the\nsuperior ability of the KNN algorithm in differentiating between the two\nclasses of ultimate tensile strength within the dataset, rendering it the most\nfavorable choice for classification in the context of this research. This study\nrepresents the first attempt to estimate the UTS of PLA specimens using machine\nlearning-based classification algorithms, and the findings offer valuable\ninsights into the potential of these techniques in improving the performance\nand accuracy of predictive models in the domain of additive manufacturing.",
          "link": "http://arxiv.org/abs/2307.06970",
          "publishedOn": "2023-07-17T01:05:35.142Z",
          "wordCount": null,
          "title": "Machine Learning-Assisted Pattern Recognition Algorithms for Estimating Ultimate Tensile Strength in Fused Deposition Modeled Polylactic Acid Specimens. (arXiv:2307.06970v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07264",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Houshuang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuchen He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chihao Zhang</a>",
          "description": "Learning with expert advice and multi-armed bandit are two classic online\ndecision problems which differ on how the information is observed in each round\nof the game. We study a family of problems interpolating the two. For a vector\n$\\mathbf{m}=(m_1,\\dots,m_K)\\in \\mathbb{N}^K$, an instance of $\\mathbf{m}$-MAB\nindicates that the arms are partitioned into $K$ groups and the $i$-th group\ncontains $m_i$ arms. Once an arm is pulled, the losses of all arms in the same\ngroup are observed. We prove tight minimax regret bounds for $\\mathbf{m}$-MAB\nand design an optimal PAC algorithm for its pure exploration version,\n$\\mathbf{m}$-BAI, where the goal is to identify the arm with minimum loss with\nas few rounds as possible. We show that the minimax regret of $\\mathbf{m}$-MAB\nis $\\Theta\\left(\\sqrt{T\\sum_{k=1}^K\\log (m_k+1)}\\right)$ and the minimum number\nof pulls for an $(\\epsilon,0.05)$-PAC algorithm of $\\mathbf{m}$-BAI is\n$\\Theta\\left(\\frac{1}{\\epsilon^2}\\cdot \\sum_{k=1}^K\\log (m_k+1)\\right)$. Both\nour upper bounds and lower bounds for $\\mathbf{m}$-MAB can be extended to a\nmore general setting, namely the bandit with graph feedback, in terms of the\nclique cover and related graph parameters. As consequences, we obtained tight\nminimax regret bounds for several families of feedback graphs.",
          "link": "http://arxiv.org/abs/2307.07264",
          "publishedOn": "2023-07-17T01:05:35.079Z",
          "wordCount": null,
          "title": "On Interpolating Experts and Multi-Armed Bandits. (arXiv:2307.07264v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06950",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xia Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geyer_P/0/1/0/all/0/1\">Philipp Geyer</a>",
          "description": "Despite the digitalization trend and data volume surge, first-principles\nmodels (also known as logic-driven, physics-based, rule-based, or\nknowledge-based models) and data-driven approaches have existed in parallel,\nmirroring the ongoing AI debate on symbolism versus connectionism. Research for\nprocess development to integrate both sides to transfer and utilize domain\nknowledge in the data-driven process is rare. This study emphasizes efforts and\nprevailing trends to integrate multidisciplinary domain professions into\nmachine acknowledgeable, data-driven processes in a two-fold organization:\nexamining information uncertainty sources in knowledge representation and\nexploring knowledge decomposition with a three-tier knowledge-integrated\nmachine learning paradigm. This approach balances holist and reductionist\nperspectives in the engineering domain.",
          "link": "http://arxiv.org/abs/2307.06950",
          "publishedOn": "2023-07-17T01:05:35.077Z",
          "wordCount": null,
          "title": "Pathway toward prior knowledge-integrated machine learning in engineering. (arXiv:2307.06950v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06951",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1\">Prateek Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phade_S/0/1/0/all/0/1\">Soham Phade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasa_S/0/1/0/all/0/1\">Sunil Srinivasa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1\">Andrew Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Stephan Zheng</a>",
          "description": "The international community must collaborate to mitigate climate change and\nsustain economic growth. However, collaboration is hard to achieve, partly\nbecause no global authority can ensure compliance with international climate\nagreements. Combining AI with climate-economic simulations offers a promising\nsolution to design international frameworks, including negotiation protocols\nand climate agreements, that promote and incentivize collaboration. In\naddition, these frameworks should also have policy goals fulfillment, and\nsustained commitment, taking into account climate-economic dynamics and\nstrategic behaviors. These challenges require an interdisciplinary approach\nacross machine learning, economics, climate science, law, policy, ethics, and\nother fields.\n\nTowards this objective, we organized AI for Global Climate Cooperation, a\nMila competition in which teams submitted proposals and analyses of\ninternational frameworks, based on (modifications of) RICE-N, an AI-driven\nintegrated assessment model (IAM). In particular, RICE-N supports modeling\nregional decision-making using AI agents. Furthermore, the IAM then models the\nclimate-economic impact of those decisions into the future.\n\nWhereas the first track focused only on performance metrics, the proposals\nsubmitted to the second track were evaluated both quantitatively and\nqualitatively. The quantitative evaluation focused on a combination of (i) the\ndegree of mitigation of global temperature rise and (ii) the increase in\neconomic productivity. On the other hand, an interdisciplinary panel of human\nexperts in law, policy, sociology, economics and environmental science,\nevaluated the solutions qualitatively. In particular, the panel considered the\neffectiveness, simplicity, feasibility, ethics, and notions of climate justice\nof the protocols. In the third track, the participants were asked to critique\nand improve RICE-N.",
          "link": "http://arxiv.org/abs/2307.06951",
          "publishedOn": "2023-07-17T01:05:35.077Z",
          "wordCount": null,
          "title": "AI For Global Climate Cooperation 2023 Competition Proceedings. (arXiv:2307.06951v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07389",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ni_M/0/1/0/all/0/1\">Mingjian Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guangyao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xiawu Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_P/0/1/0/all/0/1\">Peixi Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Li Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yonghong Tian</a>",
          "description": "The sparsity of Deep Neural Networks is well investigated to maximize the\nperformance and reduce the size of overparameterized networks as possible.\nExisting methods focus on pruning parameters in the training process by using\nthresholds and metrics. Meanwhile, feature similarity between different layers\nhas not been discussed sufficiently before, which could be rigorously proved to\nbe highly correlated to the network sparsity in this paper. Inspired by\ninterlayer feature similarity in overparameterized models, we investigate the\nintrinsic link between network sparsity and interlayer feature similarity.\nSpecifically, we prove that reducing interlayer feature similarity based on\nCentered Kernel Alignment (CKA) improves the sparsity of the network by using\ninformation bottleneck theory. Applying such theory, we propose a plug-and-play\nCKA-based Sparsity Regularization for sparse network training, dubbed CKA-SR,\nwhich utilizes CKA to reduce feature similarity between layers and increase\nnetwork sparsity. In other words, layers of our sparse network tend to have\ntheir own identity compared to each other. Experimentally, we plug the proposed\nCKA-SR into the training process of sparse network training methods and find\nthat CKA-SR consistently improves the performance of several State-Of-The-Art\nsparse training methods, especially at extremely high sparsity. Code is\nincluded in the supplementary materials.",
          "link": "http://arxiv.org/abs/2307.07389",
          "publishedOn": "2023-07-17T01:05:35.076Z",
          "wordCount": null,
          "title": "Learning Sparse Neural Networks with Identity Layers. (arXiv:2307.07389v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07370",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tu_G/0/1/0/all/0/1\">Guoyun Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Ying Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vlassov_V/0/1/0/all/0/1\">Vladimir Vlassov</a>",
          "description": "Image captioning is a significant field across computer vision and natural\nlanguage processing. We propose and present AIC-AB NET, a novel\nAttribute-Information-Combined Attention-Based Network that combines spatial\nattention architecture and text attributes in an encoder-decoder. For caption\ngeneration, adaptive spatial attention determines which image region best\nrepresents the image and whether to attend to the visual features or the visual\nsentinel. Text attribute information is synchronously fed into the decoder to\nhelp image recognition and reduce uncertainty. We have tested and evaluated our\nAICAB NET on the MS COCO dataset and a new proposed Fashion dataset. The\nFashion dataset is employed as a benchmark of single-object images. The results\nshow the superior performance of the proposed model compared to the\nstate-of-the-art baseline and ablated models on both the images from MSCOCO and\nour single-object images. Our AIC-AB NET outperforms the baseline adaptive\nattention network by 0.017 (CIDEr score) on the MS COCO dataset and 0.095\n(CIDEr score) on the Fashion dataset.",
          "link": "http://arxiv.org/abs/2307.07370",
          "publishedOn": "2023-07-17T01:05:35.075Z",
          "wordCount": null,
          "title": "AIC-AB NET: A Neural Network for Image Captioning with Spatial Attention and Text Attributes. (arXiv:2307.07370v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07383",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Incudini_M/0/1/0/all/0/1\">Massimiliano Incudini</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Martini_F/0/1/0/all/0/1\">Francesco Martini</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Pierro_A/0/1/0/all/0/1\">Alessandra Di Pierro</a>",
          "description": "Topological data analysis (TDA) has emerged as a powerful tool for extracting\nmeaningful insights from complex data. TDA enhances the analysis of objects by\nembedding them into a simplicial complex and extracting useful global\nproperties such as the Betti numbers, i.e. the number of multidimensional\nholes, which can be used to define kernel methods that are easily integrated\nwith existing machine-learning algorithms. These kernel methods have found\nbroad applications, as they rely on powerful mathematical frameworks which\nprovide theoretical guarantees on their performance. However, the computation\nof higher-dimensional Betti numbers can be prohibitively expensive on classical\nhardware, while quantum algorithms can approximate them in polynomial time in\nthe instance size. In this work, we propose a quantum approach to defining\ntopological kernels, which is based on constructing Betti curves, i.e.\ntopological fingerprint of filtrations with increasing order. We exhibit a\nworking prototype of our approach implemented on a noiseless simulator and show\nits robustness by means of some empirical results suggesting that topological\napproaches may offer an advantage in quantum machine learning.",
          "link": "http://arxiv.org/abs/2307.07383",
          "publishedOn": "2023-07-17T01:05:35.073Z",
          "wordCount": null,
          "title": "Higher-order topological kernels via quantum computation. (arXiv:2307.07383v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04675",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cobian_E/0/1/0/all/0/1\">Emma R. Cobian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jubilee Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hauenstein_J/0/1/0/all/0/1\">Jonathan D. Hauenstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schiavazzi_D/0/1/0/all/0/1\">Daniele E. Schiavazzi</a>",
          "description": "Variational inference is an increasingly popular method in statistics and\nmachine learning for approximating probability distributions. We developed\nLINFA (Library for Inference with Normalizing Flow and Annealing), a Python\nlibrary for variational inference to accommodate computationally expensive\nmodels and difficult-to-sample distributions with dependent parameters. We\ndiscuss the theoretical background, capabilities, and performance of LINFA in\nvarious benchmarks. LINFA is publicly available on GitHub at\nhttps://github.com/desResLab/LINFA.",
          "link": "http://arxiv.org/abs/2307.04675",
          "publishedOn": "2023-07-17T01:05:35.073Z",
          "wordCount": null,
          "title": "LINFA: a Python library for variational inference with normalizing flow and annealing. (arXiv:2307.04675v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07507",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hao_W/0/1/0/all/0/1\">Wei Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendoza_D/0/1/0/all/0/1\">Daniel Mendoza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1\">Rafael da Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayanan_D/0/1/0/all/0/1\">Deepak Narayanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phanishaye_A/0/1/0/all/0/1\">Amar Phanishaye</a>",
          "description": "Models derived from other models are extremely common in machine learning\n(ML) today. For example, transfer learning is used to create task-specific\nmodels from \"pre-trained\" models through finetuning. This has led to an\necosystem where models are related to each other, sharing structure and often\neven parameter values. However, it is hard to manage these model derivatives:\nthe storage overhead of storing all derived models quickly becomes onerous,\nprompting users to get rid of intermediate models that might be useful for\nfurther analysis. Additionally, undesired behaviors in models are hard to track\ndown (e.g., is a bug inherited from an upstream model?). In this paper, we\npropose a model versioning and management system called MGit that makes it\neasier to store, test, update, and collaborate on model derivatives. MGit\nintroduces a lineage graph that records provenance and versioning information\nbetween models, optimizations to efficiently store model parameters, as well as\nabstractions over this lineage graph that facilitate relevant testing, updating\nand collaboration functionality. MGit is able to reduce the lineage graph's\nstorage footprint by up to 7x and automatically update downstream models in\nresponse to updates to upstream models.",
          "link": "http://arxiv.org/abs/2307.07507",
          "publishedOn": "2023-07-17T01:05:35.072Z",
          "wordCount": null,
          "title": "MGit: A Model Versioning and Management System. (arXiv:2307.07507v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1810.07287",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kumbier_K/0/1/0/all/0/1\">Karl Kumbier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Basu_S/0/1/0/all/0/1\">Sumanta Basu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Frise_E/0/1/0/all/0/1\">Erwin Frise</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Celniker_S/0/1/0/all/0/1\">Susan E. Celniker</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Brown_J/0/1/0/all/0/1\">James B. Brown</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Celniker_S/0/1/0/all/0/1\">Susan Celniker</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yu_B/0/1/0/all/0/1\">Bin Yu</a>",
          "description": "Standard ChIP-seq peak calling pipelines seek to differentiate biochemically\nreproducible signals of individual genomic elements from background noise.\nHowever, reproducibility alone does not imply functional regulation (e.g.,\nenhancer activation, alternative splicing). Here we present a general-purpose,\ninterpretable machine learning method: signed iterative random forests (siRF),\nwhich we use to infer regulatory interactions among transcription factors and\nfunctional binding signatures surrounding enhancer elements in Drosophila\nmelanogaster.",
          "link": "http://arxiv.org/abs/1810.07287",
          "publishedOn": "2023-07-17T01:05:35.072Z",
          "wordCount": null,
          "title": "Signed iterative random forests to identify enhancer-associated transcription factor binding. (arXiv:1810.07287v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07412",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Elgaar_M/0/1/0/all/0/1\">Mohamed Elgaar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amiri_H/0/1/0/all/0/1\">Hadi Amiri</a>",
          "description": "We introduce the problem of curriculum discovery and describe a curriculum\nlearning framework capable of discovering effective curricula in a curriculum\nspace based on prior knowledge about sample difficulty. Using annotation\nentropy and loss as measures of difficulty, we show that (i): the\ntop-performing discovered curricula for a given model and dataset are often\nnon-monotonic as opposed to monotonic curricula in existing literature, (ii):\nthe prevailing easy-to-hard or hard-to-easy transition curricula are often at\nthe risk of underperforming, and (iii): the curricula discovered for smaller\ndatasets and models perform well on larger datasets and models respectively.\nThe proposed framework encompasses some of the existing curriculum learning\napproaches and can discover curricula that outperform them across several NLP\ntasks.",
          "link": "http://arxiv.org/abs/2307.07412",
          "publishedOn": "2023-07-17T01:05:35.059Z",
          "wordCount": null,
          "title": "HuCurl: Human-induced Curriculum Discovery. (arXiv:2307.07412v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07328",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zihao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mingda Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1\">Shaokui Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yanbo Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Baoyuan Wu</a>",
          "description": "Data-poisoning based backdoor attacks aim to insert backdoor into models by\nmanipulating training datasets without controlling the training process of the\ntarget model. Existing attack methods mainly focus on designing triggers or\nfusion strategies between triggers and benign samples. However, they often\nrandomly select samples to be poisoned, disregarding the varying importance of\neach poisoning sample in terms of backdoor injection. A recent selection\nstrategy filters a fixed-size poisoning sample pool by recording forgetting\nevents, but it fails to consider the remaining samples outside the pool from a\nglobal perspective. Moreover, computing forgetting events requires significant\nadditional computing resources. Therefore, how to efficiently and effectively\nselect poisoning samples from the entire dataset is an urgent problem in\nbackdoor attacks.To address it, firstly, we introduce a poisoning mask into the\nregular backdoor training loss. We suppose that a backdoored model training\nwith hard poisoning samples has a more backdoor effect on easy ones, which can\nbe implemented by hindering the normal training process (\\ie, maximizing loss\n\\wrt mask). To further integrate it with normal training process, we then\npropose a learnable poisoning sample selection strategy to learn the mask\ntogether with the model parameters through a min-max optimization.Specifically,\nthe outer loop aims to achieve the backdoor attack goal by minimizing the loss\nbased on the selected samples, while the inner loop selects hard poisoning\nsamples that impede this goal by maximizing the loss. After several rounds of\nadversarial training, we finally select effective poisoning samples with high\ncontribution. Extensive experiments on benchmark datasets demonstrate the\neffectiveness and efficiency of our approach in boosting backdoor attack\nperformance.",
          "link": "http://arxiv.org/abs/2307.07328",
          "publishedOn": "2023-07-17T01:05:35.051Z",
          "wordCount": null,
          "title": "Boosting Backdoor Attack with A Learnable Poisoning Sample Selection Strategy. (arXiv:2307.07328v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07378",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mileo_A/0/1/0/all/0/1\">Alessandra Mileo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smeaton_A/0/1/0/all/0/1\">Alan F. Smeaton</a>",
          "description": "The development of computer vision and in-situ monitoring using visual\nsensors allows the collection of large datasets from the additive manufacturing\n(AM) process. Such datasets could be used with machine learning techniques to\nimprove the quality of AM. This paper examines two scenarios: first, using\nconvolutional neural networks (CNNs) to accurately classify defects in an image\ndataset from AM and second, applying active learning techniques to the\ndeveloped classification model. This allows the construction of a\nhuman-in-the-loop mechanism to reduce the size of the data required to train\nand generate training data.",
          "link": "http://arxiv.org/abs/2307.07378",
          "publishedOn": "2023-07-17T01:05:35.051Z",
          "wordCount": null,
          "title": "Defect Classification in Additive Manufacturing Using CNN-Based Vision Processing. (arXiv:2307.07378v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07062",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Joly_A/0/1/0/all/0/1\">Arnaud Joly</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nicolis_M/0/1/0/all/0/1\">Marco Nicolis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Peterova_E/0/1/0/all/0/1\">Ekaterina Peterova</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lombardi_A/0/1/0/all/0/1\">Alessandro Lombardi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Abbas_A/0/1/0/all/0/1\">Ammar Abbas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Korlaar_A/0/1/0/all/0/1\">Arent van Korlaar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hussain_A/0/1/0/all/0/1\">Aman Hussain</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sharma_P/0/1/0/all/0/1\">Parul Sharma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moinet_A/0/1/0/all/0/1\">Alexis Moinet</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lajszczak_M/0/1/0/all/0/1\">Mateusz Lajszczak</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Karanasou_P/0/1/0/all/0/1\">Penny Karanasou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bonafonte_A/0/1/0/all/0/1\">Antonio Bonafonte</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Drugman_T/0/1/0/all/0/1\">Thomas Drugman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sokolova_E/0/1/0/all/0/1\">Elena Sokolova</a>",
          "description": "We present a scalable method to produce high quality emphasis for\ntext-to-speech (TTS) that does not require recordings or annotations. Many TTS\nmodels include a phoneme duration model. A simple but effective method to\nachieve emphasized speech consists in increasing the predicted duration of the\nemphasised word. We show that this is significantly better than spectrogram\nmodification techniques improving naturalness by $7.3\\%$ and correct testers'\nidentification of the emphasized word in a sentence by $40\\%$ on a reference\nfemale en-US voice. We show that this technique significantly closes the gap to\nmethods that require explicit recordings. The method proved to be scalable and\npreferred in all four languages tested (English, Spanish, Italian, German), for\ndifferent voices and multiple speaking styles.",
          "link": "http://arxiv.org/abs/2307.07062",
          "publishedOn": "2023-07-17T01:05:35.050Z",
          "wordCount": null,
          "title": "Controllable Emphasis with zero data for text-to-speech. (arXiv:2307.07062v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07397",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhengbo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jian Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1\">Ran He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1\">Nan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zilei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_T/0/1/0/all/0/1\">Tieniu Tan</a>",
          "description": "With the growing interest in pretrained vision-language models like CLIP,\nrecent research has focused on adapting these models to downstream tasks.\nDespite achieving promising results, most existing methods require labeled data\nfor all classes, which may not hold in real-world applications due to the long\ntail and Zipf's law. For example, some classes may lack labeled data entirely,\nsuch as emerging concepts. To address this problem, we propose a plug-and-play\ngenerative approach called \\textbf{S}ynt\\textbf{H}es\\textbf{I}zed\n\\textbf{P}rompts~(\\textbf{SHIP}) to improve existing fine-tuning methods.\nSpecifically, we follow variational autoencoders to introduce a generator that\nreconstructs the visual features by inputting the synthesized prompts and the\ncorresponding class names to the textual encoder of CLIP. In this manner, we\neasily obtain the synthesized features for the remaining label-only classes.\nThereafter, we fine-tune CLIP with off-the-shelf methods by combining labeled\nand synthesized features. Extensive experiments on base-to-new generalization,\ncross-dataset transfer learning, and generalized zero-shot learning demonstrate\nthe superiority of our approach. The code is available at\n\\url{https://github.com/mrflogs/SHIP}.",
          "link": "http://arxiv.org/abs/2307.07397",
          "publishedOn": "2023-07-17T01:05:35.047Z",
          "wordCount": null,
          "title": "Improving Zero-Shot Generalization for CLIP with Synthesized Prompts. (arXiv:2307.07397v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07439",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Starck_S/0/1/0/all/0/1\">Sophie Starck</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kini_Y/0/1/0/all/0/1\">Yadunandan Vivekanand Kini</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ritter_J/0/1/0/all/0/1\">Jessica Johanna Maria Ritter</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Braren_R/0/1/0/all/0/1\">Rickmer Braren</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rueckert_D/0/1/0/all/0/1\">Daniel Rueckert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mueller_T/0/1/0/all/0/1\">Tamara Mueller</a>",
          "description": "Age prediction is an important part of medical assessments and research. It\ncan aid in detecting diseases as well as abnormal ageing by highlighting the\ndiscrepancy between chronological and biological age. To gain a comprehensive\nunderstanding of age-related changes observed in various body parts, we\ninvestigate them on a larger scale by using whole-body images. We utilise the\nGrad-CAM interpretability method to determine the body areas most predictive of\na person's age. We expand our analysis beyond individual subjects by employing\nregistration techniques to generate population-wide interpretability maps.\nFurthermore, we set state-of-the-art whole-body age prediction with a model\nthat achieves a mean absolute error of 2.76 years. Our findings reveal three\nprimary areas of interest: the spine, the autochthonous back muscles, and the\ncardiac region, which exhibits the highest importance.",
          "link": "http://arxiv.org/abs/2307.07439",
          "publishedOn": "2023-07-17T01:05:35.046Z",
          "wordCount": null,
          "title": "Atlas-Based Interpretable Age Prediction. (arXiv:2307.07439v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06984",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rio_T/0/1/0/all/0/1\">Tereso del Rio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+England_M/0/1/0/all/0/1\">Matthew England</a>",
          "description": "This paper discusses and evaluates ideas of data balancing and data\naugmentation in the context of mathematical objects: an important topic for\nboth the symbolic computation and satisfiability checking communities, when\nthey are making use of machine learning techniques to optimise their tools. We\nconsider a dataset of non-linear polynomial problems and the problem of\nselecting a variable ordering for cylindrical algebraic decomposition to tackle\nthese with. By swapping the variable names in already labelled problems, we\ngenerate new problem instances that do not require any further labelling when\nviewing the selection as a classification problem. We find this augmentation\nincreases the accuracy of ML models by 63% on average. We study what part of\nthis improvement is due to the balancing of the dataset and what is achieved\nthanks to further increasing the size of the dataset, concluding that both have\na very significant effect. We finish the paper by reflecting on how this idea\ncould be applied in other uses of machine learning in mathematics.",
          "link": "http://arxiv.org/abs/2307.06984",
          "publishedOn": "2023-07-17T01:05:35.045Z",
          "wordCount": null,
          "title": "Data Augmentation for Mathematical Objects. (arXiv:2307.06984v1 [cs.SC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07477",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koga_T/0/1/0/all/0/1\">Tatsuki Koga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1\">Congzheng Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pelikan_M/0/1/0/all/0/1\">Martin Pelikan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chitnis_M/0/1/0/all/0/1\">Mona Chitnis</a>",
          "description": "Federated learning (FL) combined with differential privacy (DP) offers\nmachine learning (ML) training with distributed devices and with a formal\nprivacy guarantee. With a large population of devices, FL with DP produces a\nperformant model in a timely manner. However, for applications with a smaller\npopulation, not only does the model utility degrade as the DP noise is\ninversely proportional to population, but also the training latency increases\nsince waiting for enough clients to become available from a smaller pool is\nslower. In this work, we thus propose expanding the population based on domain\nadaptation techniques to speed up the training and improves the final model\nquality when training with small populations. We empirically demonstrate that\nour techniques can improve the utility by 13% to 30% on real-world language\nmodeling datasets.",
          "link": "http://arxiv.org/abs/2307.07477",
          "publishedOn": "2023-07-17T01:05:35.011Z",
          "wordCount": null,
          "title": "Population Expansion for Training Language Models with Private Federated Learning. (arXiv:2307.07477v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07406",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Upadhyay_A/0/1/0/all/0/1\">Antesh Upadhyay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashemi_A/0/1/0/all/0/1\">Abolfazl Hashemi</a>",
          "description": "We propose an improved convergence analysis technique that characterizes the\ndistributed learning paradigm of federated learning (FL) with imperfect/noisy\nuplink and downlink communications. Such imperfect communication scenarios\narise in the practical deployment of FL in emerging communication systems and\nprotocols. The analysis developed in this paper demonstrates, for the first\ntime, that there is an asymmetry in the detrimental effects of uplink and\ndownlink communications in FL. In particular, the adverse effect of the\ndownlink noise is more severe on the convergence of FL algorithms. Using this\ninsight, we propose improved Signal-to-Noise (SNR) control strategies that,\ndiscarding the negligible higher-order terms, lead to a similar convergence\nrate for FL as in the case of a perfect, noise-free communication channel while\nincurring significantly less power resources compared to existing solutions. In\nparticular, we establish that to maintain the $O(\\frac{1}{\\sqrt{K}})$ rate of\nconvergence like in the case of noise-free FL, we need to scale down the uplink\nand downlink noise by $\\Omega({\\sqrt{k}})$ and $\\Omega({k})$ respectively,\nwhere $k$ denotes the communication round, $k=1,\\dots, K$. Our theoretical\nresult is further characterized by two major benefits: firstly, it does not\nassume the somewhat unrealistic assumption of bounded client dissimilarity, and\nsecondly, it only requires smooth non-convex loss functions, a function class\nbetter suited for modern machine learning and deep learning models. We also\nperform extensive empirical analysis to verify the validity of our theoretical\nfindings.",
          "link": "http://arxiv.org/abs/2307.07406",
          "publishedOn": "2023-07-17T01:05:35.008Z",
          "wordCount": null,
          "title": "Improved Convergence Analysis and SNR Control Strategies for Federated Learning in the Presence of Noise. (arXiv:2307.07406v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06957",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xu_Z/0/1/0/all/0/1\">Zuheng Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Campbell_T/0/1/0/all/0/1\">Trevor Campbell</a>",
          "description": "In this paper, we investigate the impact of numerical instability on the\nreliability of sampling, density evaluation, and evidence lower bound (ELBO)\nestimation in variational flows. We first empirically demonstrate that common\nflows can exhibit a catastrophic accumulation of error: the numerical flow map\ndeviates significantly from the exact map -- which affects sampling -- and the\nnumerical inverse flow map does not accurately recover the initial input --\nwhich affects density and ELBO computations. Surprisingly though, we find that\nresults produced by flows are often accurate enough for applications despite\nthe presence of serious numerical instability. In this work, we treat\nvariational flows as dynamical systems, and leverage shadowing theory to\nelucidate this behavior via theoretical guarantees on the error of sampling,\ndensity evaluation, and ELBO estimation. Finally, we develop and empirically\ntest a diagnostic procedure that can be used to validate results produced by\nnumerically unstable flows in practice.",
          "link": "http://arxiv.org/abs/2307.06957",
          "publishedOn": "2023-07-17T01:05:35.005Z",
          "wordCount": null,
          "title": "Embracing the chaos: analysis and diagnosis of numerical instability in variational flows. (arXiv:2307.06957v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07072",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parker_C/0/1/0/all/0/1\">Christopher S. Parker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schroder_A/0/1/0/all/0/1\">Anna Schroder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Epstein_S/0/1/0/all/0/1\">Sean C. Epstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cole_J/0/1/0/all/0/1\">James Cole</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alexander_D/0/1/0/all/0/1\">Daniel C. Alexander</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hui Zhang</a>",
          "description": "Purpose: Previous quantitative MR imaging studies using self-supervised deep\nlearning have reported biased parameter estimates at low SNR. Such systematic\nerrors arise from the choice of Mean Squared Error (MSE) loss function for\nnetwork training, which is incompatible with Rician-distributed MR magnitude\nsignals. To address this issue, we introduce the negative log Rician likelihood\n(NLR) loss. Methods: A numerically stable and accurate implementation of the\nNLR loss was developed to estimate quantitative parameters of the apparent\ndiffusion coefficient (ADC) model and intra-voxel incoherent motion (IVIM)\nmodel. Parameter estimation accuracy, precision and overall error were\nevaluated in terms of bias, variance and root mean squared error and compared\nagainst the MSE loss over a range of SNRs (5 - 30). Results: Networks trained\nwith NLR loss show higher estimation accuracy than MSE for the ADC and IVIM\ndiffusion coefficients as SNR decreases, with minimal loss of precision or\ntotal error. At high effective SNR (high SNR and small diffusion coefficients),\nboth losses show comparable accuracy and precision for all parameters of both\nmodels. Conclusion: The proposed NLR loss is numerically stable and accurate\nacross the full range of tested SNRs and improves parameter estimation accuracy\nof diffusion coefficients using self-supervised deep learning. We expect the\ndevelopment to benefit quantitative MR imaging techniques broadly, enabling\nmore accurate parameter estimation from noisy data.",
          "link": "http://arxiv.org/abs/2307.07072",
          "publishedOn": "2023-07-17T01:05:35.005Z",
          "wordCount": null,
          "title": "Rician likelihood loss for quantitative MRI using self-supervised deep learning. (arXiv:2307.07072v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.09032",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xutong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1\">Yangchen Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chenjun Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1\">Sarath Chandar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajendran_J/0/1/0/all/0/1\">Janarthanan Rajendran</a>",
          "description": "Efficient exploration is critical in cooperative deep Multi-Agent\nReinforcement Learning (MARL). In this work, we propose an exploration method\nthat effectively encourages cooperative exploration based on the idea of\nsequential action-computation scheme. The high-level intuition is that to\nperform optimism-based exploration, agents would explore cooperative strategies\nif each agent's optimism estimate captures a structured dependency relationship\nwith other agents. Assuming agents compute actions following a sequential order\nat \\textit{each environment timestep}, we provide a perspective to view MARL as\ntree search iterations by considering agents as nodes at different depths of\nthe search tree. Inspired by the theoretically justified tree search algorithm\nUCT (Upper Confidence bounds applied to Trees), we develop a method called\nConditionally Optimistic Exploration (COE). COE augments each agent's\nstate-action value estimate with an action-conditioned optimistic bonus derived\nfrom the visitation count of the global state and joint actions of preceding\nagents. COE is performed during training and disabled at deployment, making it\ncompatible with any value decomposition method for centralized training with\ndecentralized execution. Experiments across various cooperative MARL benchmarks\nshow that COE outperforms current state-of-the-art exploration methods on\nhard-exploration tasks.",
          "link": "http://arxiv.org/abs/2303.09032",
          "publishedOn": "2023-07-17T01:05:35.004Z",
          "wordCount": null,
          "title": "Conditionally Optimistic Exploration for Cooperative Deep Multi-Agent Reinforcement Learning. (arXiv:2303.09032v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07296",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leong_K/0/1/0/all/0/1\">Kenji Leong</a>",
          "description": "Active Simultaneous Localisation and Mapping (SLAM) is a critical problem in\nautonomous robotics, enabling robots to navigate to new regions while building\nan accurate model of their surroundings. Visual SLAM is a popular technique\nthat uses virtual elements to enhance the experience. However, existing\nfrontier-based exploration strategies can lead to a non-optimal path in\nscenarios where there are multiple frontiers with similar distance. This issue\ncan impact the efficiency and accuracy of Visual SLAM, which is crucial for a\nwide range of robotic applications, such as search and rescue, exploration, and\nmapping. To address this issue, this research combines both an existing\nVisual-Graph SLAM known as ExploreORB with reinforcement learning. The proposed\nalgorithm allows the robot to learn and optimize exploration routes through a\nreward-based system to create an accurate map of the environment with proper\nfrontier selection. Frontier-based exploration is used to detect unexplored\nareas, while reinforcement learning optimizes the robot's movement by assigning\nrewards for optimal frontier points. Graph SLAM is then used to integrate the\nrobot's sensory data and build an accurate map of the environment. The proposed\nalgorithm aims to improve the efficiency and accuracy of ExploreORB by\noptimizing the exploration process of frontiers to build a more accurate map.\nTo evaluate the effectiveness of the proposed approach, experiments will be\nconducted in various virtual environments using Gazebo, a robot simulation\nsoftware. Results of these experiments will be compared with existing methods\nto demonstrate the potential of the proposed approach as an optimal solution\nfor SLAM in autonomous robotics.",
          "link": "http://arxiv.org/abs/2307.07296",
          "publishedOn": "2023-07-17T01:05:34.979Z",
          "wordCount": null,
          "title": "Reinforcement Learning with Frontier-Based Exploration via Autonomous Environment. (arXiv:2307.07296v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07503",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hamran_A/0/1/0/all/0/1\">Aupam Hamran</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vaeztourshizi_M/0/1/0/all/0/1\">Marzieh Vaeztourshizi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Esmaili_A/0/1/0/all/0/1\">Amirhossein Esmaili</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pedram_M/0/1/0/all/0/1\">Massoud Pedram</a>",
          "description": "In this paper, we present different architectures of Convolutional Neural\nNetworks (CNN) to analyze and classify the brain tumors into benign and\nmalignant types using the Magnetic Resonance Imaging (MRI) technique. Different\nCNN architecture optimization techniques such as widening and deepening of the\nnetwork and adding skip connections are applied to improve the accuracy of the\nnetwork. Results show that a subset of these techniques can judiciously be used\nto outperform a baseline CNN model used for the same purpose.",
          "link": "http://arxiv.org/abs/2307.07503",
          "publishedOn": "2023-07-17T01:05:34.979Z",
          "wordCount": null,
          "title": "Brain Tumor Detection using Convolutional Neural Networks with Skip Connections. (arXiv:2307.07503v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07171",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guanhua Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_B/0/1/0/all/0/1\">Bairu Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1\">Wenqi Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sijia Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shiyu Chang</a>",
          "description": "Although large language models (LLMs) have achieved great success in vast\nreal-world applications, their vulnerabilities towards noisy inputs have\nsignificantly limited their uses, especially in high-stake environments. In\nthese contexts, it is crucial to ensure that every prediction made by large\nlanguage models is stable, i.e., LLM predictions should be consistent given\nminor differences in the input. This largely falls into the study of certified\nrobust LLMs, i.e., all predictions of LLM are certified to be correct in a\nlocal region around the input. Randomized smoothing has demonstrated great\npotential in certifying the robustness and prediction stability of LLMs.\nHowever, randomized smoothing requires adding noise to the input before model\nprediction, and its certification performance depends largely on the model's\nperformance on corrupted data. As a result, its direct application to LLMs\nremains challenging and often results in a small certification radius. To\naddress this issue, we take advantage of the multitasking nature of LLMs and\npropose to denoise the corrupted inputs with LLMs in a self-denoising manner.\nDifferent from previous works like denoised smoothing, which requires training\na separate model to robustify LLM, our method enjoys far better efficiency and\nflexibility. Our experiment results show that our method outperforms the\nexisting certification methods under both certified robustness and empirical\nrobustness. The codes are available at\nhttps://github.com/UCSB-NLP-Chang/SelfDenoise.",
          "link": "http://arxiv.org/abs/2307.07171",
          "publishedOn": "2023-07-17T01:05:34.929Z",
          "wordCount": null,
          "title": "Certified Robustness for Large Language Models with Self-Denoising. (arXiv:2307.07171v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07343",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1\">Linkai Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qiaoling Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1\">Hong Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yiding Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Ziyang Chen</a>",
          "description": "The selection of model's parameters plays an important role in the\napplication of support vector classification (SVC). The commonly used method of\nselecting model's parameters is the k-fold cross validation with grid search\n(CV). It is extremely time-consuming because it needs to train a large number\nof SVC models. In this paper, a new method is proposed to train SVC with the\nselection of model's parameters. Firstly, training SVC with the selection of\nmodel's parameters is modeled as a minimax optimization problem\n(MaxMin-L2-SVC-NCH), in which the minimization problem is an optimization\nproblem of finding the closest points between two normal convex hulls\n(L2-SVC-NCH) while the maximization problem is an optimization problem of\nfinding the optimal model's parameters. A lower time complexity can be expected\nin MaxMin-L2-SVC-NCH because CV is abandoned. A gradient-based algorithm is\nthen proposed to solve MaxMin-L2-SVC-NCH, in which L2-SVC-NCH is solved by a\nprojected gradient algorithm (PGA) while the maximization problem is solved by\na gradient ascent algorithm with dynamic learning rate. To demonstrate the\nadvantages of the PGA in solving L2-SVC-NCH, we carry out a comparison of the\nPGA and the famous sequential minimal optimization (SMO) algorithm after a SMO\nalgorithm and some KKT conditions for L2-SVC-NCH are provided. It is revealed\nthat the SMO algorithm is a special case of the PGA. Thus, the PGA can provide\nmore flexibility. The comparative experiments between MaxMin-L2-SVC-NCH and the\nclassical parameter selection models on public datasets show that\nMaxMin-L2-SVC-NCH greatly reduces the number of models to be trained and the\ntest accuracy is not lost to the classical models. It indicates that\nMaxMin-L2-SVC-NCH performs better than the other models. We strongly recommend\nMaxMin-L2-SVC-NCH as a preferred model for SVC task.",
          "link": "http://arxiv.org/abs/2307.07343",
          "publishedOn": "2023-07-17T01:05:34.925Z",
          "wordCount": null,
          "title": "MaxMin-L2-SVC-NCH: A New Method to Train Support Vector Classifier with the Selection of Model's Parameters. (arXiv:2307.07343v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Castro_B/0/1/0/all/0/1\">Bernard J. Giron Castro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peucheret_C/0/1/0/all/0/1\">Christophe Peucheret</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zibar_D/0/1/0/all/0/1\">Darko Zibar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ros_F/0/1/0/all/0/1\">Francesco Da Ros</a>",
          "description": "We quantify the impact of thermo-optic and free-carrier effects on time-delay\nreservoir computing using a silicon microring resonator. We identify pump power\nand frequency detuning ranges with NMSE less than 0.05 for the NARMA-10 task\ndepending on the time constants of the two considered effects.",
          "link": "http://arxiv.org/abs/2307.07011",
          "publishedOn": "2023-07-17T01:05:34.887Z",
          "wordCount": null,
          "title": "Impact of Free-carrier Nonlinearities on Silicon Microring-based Reservoir Computing. (arXiv:2307.07011v1 [cs.ET])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07457",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cacciola_M/0/1/0/all/0/1\">Matteo Cacciola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frangioni_A/0/1/0/all/0/1\">Antonio Frangioni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lodi_A/0/1/0/all/0/1\">Andrea Lodi</a>",
          "description": "In recent years, the integration of Machine Learning (ML) models with\nOperation Research (OR) tools has gained popularity across diverse\napplications, including cancer treatment, algorithmic configuration, and\nchemical process optimization. In this domain, the combination of ML and OR\noften relies on representing the ML model output using Mixed Integer\nProgramming (MIP) formulations. Numerous studies in the literature have\ndeveloped such formulations for many ML predictors, with a particular emphasis\non Artificial Neural Networks (ANNs) due to their significant interest in many\napplications. However, ANNs frequently contain a large number of parameters,\nresulting in MIP formulations that are impractical to solve, thereby impeding\nscalability. In fact, the ML community has already introduced several\ntechniques to reduce the parameter count of ANNs without compromising their\nperformance, since the substantial size of modern ANNs presents challenges for\nML applications as it significantly impacts computational efforts during\ntraining and necessitates significant memory resources for storage. In this\npaper, we showcase the effectiveness of pruning, one of these techniques, when\napplied to ANNs prior to their integration into MIPs. By pruning the ANN, we\nachieve significant improvements in the speed of the solution process. We\ndiscuss why pruning is more suitable in this context compared to other ML\ncompression techniques, and we identify the most appropriate pruning\nstrategies. To highlight the potential of this approach, we conduct experiments\nusing feed-forward neural networks with multiple layers to construct\nadversarial examples. Our results demonstrate that pruning offers remarkable\nreductions in solution times without hindering the quality of the final\ndecision, enabling the resolution of previously unsolvable instances.",
          "link": "http://arxiv.org/abs/2307.07457",
          "publishedOn": "2023-07-17T01:05:34.861Z",
          "wordCount": null,
          "title": "Structured Pruning of Neural Networks for Constraints Learning. (arXiv:2307.07457v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07093",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+DSouza_N/0/1/0/all/0/1\">Niharika S. D&#x27;Souza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongzhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giovannini_A/0/1/0/all/0/1\">Andrea Giovannini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foncubierta_Rodriguez_A/0/1/0/all/0/1\">Antonio Foncubierta-Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beck_K/0/1/0/all/0/1\">Kristen L. Beck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boyko_O/0/1/0/all/0/1\">Orest Boyko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Syeda_Mahmood_T/0/1/0/all/0/1\">Tanveer Syeda-Mahmood</a>",
          "description": "With the emergence of multimodal electronic health records, the evidence for\nan outcome may be captured across multiple modalities ranging from clinical to\nimaging and genomic data. Predicting outcomes effectively requires fusion\nframeworks capable of modeling fine-grained and multi-faceted complex\ninteractions between modality features within and across patients. We develop\nan innovative fusion approach called MaxCorr MGNN that models non-linear\nmodality correlations within and across patients through\nHirschfeld-Gebelein-Renyi maximal correlation (MaxCorr) embeddings, resulting\nin a multi-layered graph that preserves the identities of the modalities and\npatients. We then design, for the first time, a generalized multi-layered graph\nneural network (MGNN) for task-informed reasoning in multi-layered graphs, that\nlearns the parameters defining patient-modality graph connectivity and message\npassing in an end-to-end fashion. We evaluate our model an outcome prediction\ntask on a Tuberculosis (TB) dataset consistently outperforming several\nstate-of-the-art neural, graph-based and traditional fusion techniques.",
          "link": "http://arxiv.org/abs/2307.07093",
          "publishedOn": "2023-07-17T01:05:34.853Z",
          "wordCount": null,
          "title": "MaxCorrMGNN: A Multi-Graph Neural Network Framework for Generalized Multimodal Fusion of Medical Data for Outcome Prediction. (arXiv:2307.07093v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07083",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Thi Minh Tam Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benjumea_A/0/1/0/all/0/1\">Aduen Benjumea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bradley_A/0/1/0/all/0/1\">Andrew Bradley</a>",
          "description": "This paper proposes a scenario-based functional testing approach for\nenhancing the performance of machine learning (ML) applications. The proposed\nmethod is an iterative process that starts with testing the ML model on various\nscenarios to identify areas of weakness. It follows by a further testing on the\nsuspected weak scenarios and statistically evaluate the model's performance on\nthe scenarios to confirm the diagnosis. Once the diagnosis of weak scenarios is\nconfirmed by test results, the treatment of the model is performed by\nretraining the model using a transfer learning technique with the original\nmodel as the base and applying a set of training data specifically targeting\nthe treated scenarios plus a subset of training data selected at random from\nthe original train dataset to prevent the so-call catastrophic forgetting\neffect. Finally, after the treatment, the model is assessed and evaluated again\nby testing on the treated scenarios as well as other scenarios to check if the\ntreatment is effective and no side effect caused. The paper reports a case\nstudy with a real ML deep neural network (DNN) model, which is the perception\nsystem of an autonomous racing car. It is demonstrated that the method is\neffective in the sense that DNN model's performance can be improved. It\nprovides an efficient method of enhancing ML model's performance with much less\nhuman and compute resource than retrain from scratch.",
          "link": "http://arxiv.org/abs/2307.07083",
          "publishedOn": "2023-07-17T01:05:34.687Z",
          "wordCount": null,
          "title": "A Scenario-Based Functional Testing Approach to Improving DNN Performance. (arXiv:2307.07083v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06975",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Capogrosso_L/0/1/0/all/0/1\">Luigi Capogrosso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mascolini_A/0/1/0/all/0/1\">Alessio Mascolini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Girella_F/0/1/0/all/0/1\">Federico Girella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skenderi_G/0/1/0/all/0/1\">Geri Skenderi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaiardelli_S/0/1/0/all/0/1\">Sebastiano Gaiardelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DallOra_N/0/1/0/all/0/1\">Nicola Dall&#x27;Ora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponzio_F/0/1/0/all/0/1\">Francesco Ponzio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fraccaroli_E/0/1/0/all/0/1\">Enrico Fraccaroli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cataldo_S/0/1/0/all/0/1\">Santa Di Cataldo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vinco_S/0/1/0/all/0/1\">Sara Vinco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Macii_E/0/1/0/all/0/1\">Enrico Macii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fummi_F/0/1/0/all/0/1\">Franco Fummi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cristani_M/0/1/0/all/0/1\">Marco Cristani</a>",
          "description": "Industry 4.0 involves the integration of digital technologies, such as IoT,\nBig Data, and AI, into manufacturing and industrial processes to increase\nefficiency and productivity. As these technologies become more interconnected\nand interdependent, Industry 4.0 systems become more complex, which brings the\ndifficulty of identifying and stopping anomalies that may cause disturbances in\nthe manufacturing process. This paper aims to propose a diffusion-based model\nfor real-time anomaly prediction in Industry 4.0 processes. Using a\nneuro-symbolic approach, we integrate industrial ontologies in the model,\nthereby adding formal knowledge on smart manufacturing. Finally, we propose a\nsimple yet effective way of distilling diffusion models through Random Fourier\nFeatures for deployment on an embedded system for direct integration into the\nmanufacturing process. To the best of our knowledge, this approach has never\nbeen explored before.",
          "link": "http://arxiv.org/abs/2307.06975",
          "publishedOn": "2023-07-17T01:05:34.593Z",
          "wordCount": null,
          "title": "Neuro-symbolic Empowered Denoising Diffusion Probabilistic Models for Real-time Anomaly Detection in Industry 4.0. (arXiv:2307.06975v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07090",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Singh_A/0/1/0/all/0/1\">Amandeep Singh</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Liu_Y/0/1/0/all/0/1\">Ye Liu</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Yoganarasimhan_H/0/1/0/all/0/1\">Hema Yoganarasimhan</a>",
          "description": "Choice Modeling is at the core of many economics, operations, and marketing\nproblems. In this paper, we propose a fundamental characterization of choice\nfunctions that encompasses a wide variety of extant choice models. We\ndemonstrate how nonparametric estimators like neural nets can easily\napproximate such functionals and overcome the curse of dimensionality that is\ninherent in the non-parametric estimation of choice functions. We demonstrate\nthrough extensive simulations that our proposed functionals can flexibly\ncapture underlying consumer behavior in a completely data-driven fashion and\noutperform traditional parametric models. As demand settings often exhibit\nendogenous features, we extend our framework to incorporate estimation under\nendogenous features. Further, we also describe a formal inference procedure to\nconstruct valid confidence intervals on objects of interest like price\nelasticity. Finally, to assess the practical applicability of our estimator, we\nutilize a real-world dataset from S. Berry, Levinsohn, and Pakes (1995). Our\nempirical analysis confirms that the estimator generates realistic and\ncomparable own- and cross-price elasticities that are consistent with the\nobservations reported in the existing literature.",
          "link": "http://arxiv.org/abs/2307.07090",
          "publishedOn": "2023-07-17T01:05:34.555Z",
          "wordCount": 655,
          "title": "Choice Models and Permutation Invariance. (arXiv:2307.07090v1 [econ.EM])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07014",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rebello_A/0/1/0/all/0/1\">Aaman Rebello</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Shengpu Tang</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Wiens_J/0/1/0/all/0/1\">Jenna Wiens</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Parbhoo_S/0/1/0/all/0/1\">Sonali Parbhoo</a> (1) ((1) Department of Engineering, Imperial College London, (2) Division of Computer Science &amp; Engineering, University of Michigan)",
          "description": "Off-policy evaluation (OPE) aims to estimate the benefit of following a\ncounterfactual sequence of actions, given data collected from executed\nsequences. However, existing OPE estimators often exhibit high bias and high\nvariance in problems involving large, combinatorial action spaces. We\ninvestigate how to mitigate this issue using factored action spaces i.e.\nexpressing each action as a combination of independent sub-actions from smaller\naction spaces. This approach facilitates a finer-grained analysis of how\nactions differ in their effects. In this work, we propose a new family of\n\"decomposed\" importance sampling (IS) estimators based on factored action\nspaces. Given certain assumptions on the underlying problem structure, we prove\nthat the decomposed IS estimators have less variance than their original\nnon-decomposed versions, while preserving the property of zero bias. Through\nsimulations, we empirically verify our theoretical results, probing the\nvalidity of various assumptions. Provided with a technique that can derive the\naction space factorisation for a given problem, our work shows that OPE can be\nimproved \"for free\" by utilising this inherent problem structure.",
          "link": "http://arxiv.org/abs/2307.07014",
          "publishedOn": "2023-07-17T01:05:34.549Z",
          "wordCount": 748,
          "title": "Leveraging Factored Action Spaces for Off-Policy Evaluation. (arXiv:2307.07014v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07084",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boyle_D/0/1/0/all/0/1\">David Boyle</a>",
          "description": "Reinforcement Learning or optimal control can provide effective reasoning for\nsequential decision-making problems with variable dynamics. Such reasoning in\npractical implementation, however, poses a persistent challenge in interpreting\nthe reward function and corresponding optimal policy. Consequently, formalizing\nthe sequential decision-making problems as inference has a considerable value,\nas probabilistic inference in principle offers diverse and powerful\nmathematical tools to infer the stochastic dynamics whilst suggesting a\nprobabilistic interpretation of the reward design and policy convergence. In\nthis study, we propose a novel Adaptive Wasserstein Variational Optimization\n(AWaVO) to tackle these challenges in sequential decision-making. Our approach\nutilizes formal methods to provide interpretations of reward design,\ntransparency of training convergence, and probabilistic interpretation of\nsequential decisions. To demonstrate practicality, we show convergent training\nwith guaranteed global convergence rates not only in simulation but also in\nreal robot tasks, and empirically verify a reasonable tradeoff between high\nperformance and conservative interpretability.",
          "link": "http://arxiv.org/abs/2307.07084",
          "publishedOn": "2023-07-17T01:05:34.538Z",
          "wordCount": 683,
          "title": "Safe Reinforcement Learning as Wasserstein Variational Inference: Formal Methods for Interpretability. (arXiv:2307.07084v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07030",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Dixit_R/0/1/0/all/0/1\">Rishabh Dixit</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gurbuzbalaban_M/0/1/0/all/0/1\">Mert Gurbuzbalaban</a>, <a href=\"http://arxiv.org/find/math/1/au:+Bajwa_W/0/1/0/all/0/1\">Waheed U. Bajwa</a>",
          "description": "This paper considers the problem of understanding the behavior of a general\nclass of accelerated gradient methods on smooth nonconvex functions. Motivated\nby some recent works that have proposed effective algorithms, based on Polyak's\nheavy ball method and the Nesterov accelerated gradient method, to achieve\nconvergence to a local minimum of nonconvex functions, this work proposes a\nbroad class of Nesterov-type accelerated methods and puts forth a rigorous\nstudy of these methods encompassing the escape from saddle-points and\nconvergence to local minima through a both asymptotic and a non-asymptotic\nanalysis. In the asymptotic regime, this paper answers an open question of\nwhether Nesterov's accelerated gradient method (NAG) with variable momentum\nparameter avoids strict saddle points almost surely. This work also develops\ntwo metrics of asymptotic rate of convergence and divergence, and evaluates\nthese two metrics for several popular standard accelerated methods such as the\nNAG, and Nesterov's accelerated gradient with constant momentum (NCM) near\nstrict saddle points. In the local regime, this work provides an analysis that\nleads to the \"linear\" exit time estimates from strict saddle neighborhoods for\ntrajectories of these accelerated methods as well the necessary conditions for\nthe existence of such trajectories. Finally, this work studies a sub-class of\naccelerated methods that can converge in convex neighborhoods of nonconvex\nfunctions with a near optimal rate to a local minima and at the same time this\nsub-class offers superior saddle-escape behavior compared to that of NAG.",
          "link": "http://arxiv.org/abs/2307.07030",
          "publishedOn": "2023-07-17T01:05:34.533Z",
          "wordCount": 793,
          "title": "Accelerated gradient methods for nonconvex optimization: Escape trajectories from strict saddle points and convergence to local minima. (arXiv:2307.07030v1 [math.OC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06971",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jaakkola_R/0/1/0/all/0/1\">Reijo Jaakkola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Janhunen_T/0/1/0/all/0/1\">Tomi Janhunen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuusisto_A/0/1/0/all/0/1\">Antti Kuusisto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rankooh_M/0/1/0/all/0/1\">Masood Feyzbakhsh Rankooh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vilander_M/0/1/0/all/0/1\">Miikka Vilander</a>",
          "description": "We investigate explainability via short Boolean formulas in the data model\nbased on unary relations. As an explanation of length k, we take a Boolean\nformula of length k that minimizes the error with respect to the target\nattribute to be explained. We first provide novel quantitative bounds for the\nexpected error in this scenario. We then also demonstrate how the setting works\nin practice by studying three concrete data sets. In each case, we calculate\nexplanation formulas of different lengths using an encoding in Answer Set\nProgramming. The most accurate formulas we obtain achieve errors similar to\nother methods on the same data sets. However, due to overfitting, these\nformulas are not necessarily ideal explanations, so we use cross validation to\nidentify a suitable length for explanations. By limiting to shorter formulas,\nwe obtain explanations that avoid overfitting but are still reasonably accurate\nand also, importantly, human interpretable.",
          "link": "http://arxiv.org/abs/2307.06971",
          "publishedOn": "2023-07-17T01:05:34.527Z",
          "wordCount": 674,
          "title": "Short Boolean Formulas as Explanations in Practice. (arXiv:2307.06971v1 [cs.LO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adilova_L/0/1/0/all/0/1\">Linara Adilova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischer_A/0/1/0/all/0/1\">Asja Fischer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1\">Martin Jaggi</a>",
          "description": "In the federated setup one performs an aggregation of separate local models\nmultiple times during training in order to obtain a stronger global model; most\noften aggregation is a simple averaging of the parameters. Understanding when\nand why averaging works in a non-convex setup, such as federated deep learning,\nis an open challenge that hinders obtaining highly performant global models. On\ni.i.d.~datasets federated deep learning with frequent averaging is successful.\nThe common understanding, however, is that during the independent training\nmodels are drifting away from each other and thus averaging may not work\nanymore after many local parameter updates. The problem can be seen from the\nperspective of the loss surface: for points on a non-convex surface the average\ncan become arbitrarily bad. The assumption of local convexity, often used to\nexplain the success of federated averaging, contradicts to the empirical\nevidence showing that high loss barriers exist between models from the very\nbeginning of the learning, even when training on the same data. Based on the\nobservation that the learning process evolves differently in different layers,\nwe investigate the barrier between models in a layerwise fashion. Our\nconjecture is that barriers preventing from successful federated training are\ncaused by a particular layer or group of layers.",
          "link": "http://arxiv.org/abs/2307.06966",
          "publishedOn": "2023-07-17T01:05:34.522Z",
          "wordCount": 707,
          "title": "Layerwise Linear Mode Connectivity. (arXiv:2307.06966v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wind_J/0/1/0/all/0/1\">Johan S. Wind</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antun_V/0/1/0/all/0/1\">Vegard Antun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hansen_A/0/1/0/all/0/1\">Anders C. Hansen</a>",
          "description": "Understanding the implicit regularization imposed by neural network\narchitectures and gradient based optimization methods is a key challenge in\ndeep learning and AI. In this work we provide sharp results for the implicit\nregularization imposed by the gradient flow of Diagonal Linear Networks (DLNs)\nin the over-parameterized regression setting and, potentially surprisingly,\nlink this to the phenomenon of phase transitions in generalized hardness of\napproximation (GHA). GHA generalizes the phenomenon of hardness of\napproximation from computer science to, among others, continuous and robust\noptimization. It is well-known that the $\\ell^1$-norm of the gradient flow of\nDLNs with tiny initialization converges to the objective function of basis\npursuit. We improve upon these results by showing that the gradient flow of\nDLNs with tiny initialization approximates minimizers of the basis pursuit\noptimization problem (as opposed to just the objective function), and we obtain\nnew and sharp convergence bounds w.r.t.\\ the initialization size. Non-sharpness\nof our results would imply that the GHA phenomenon would not occur for the\nbasis pursuit optimization problem -- which is a contradiction -- thus implying\nsharpness. Moreover, we characterize $\\textit{which}$ $\\ell_1$ minimizer of the\nbasis pursuit problem is chosen by the gradient flow whenever the minimizer is\nnot unique. Interestingly, this depends on the depth of the DLN.",
          "link": "http://arxiv.org/abs/2307.07410",
          "publishedOn": "2023-07-17T01:05:34.488Z",
          "wordCount": null,
          "title": "Implicit regularization in AI meets generalized hardness of approximation in optimization -- Sharp results for diagonal linear networks. (arXiv:2307.07410v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07181",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1\">Chia-Yuan Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1\">Yu-Neng Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guanchu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1\">Mengnan Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Na_Z/0/1/0/all/0/1\">Zou Na</a>",
          "description": "Domain generalization aims to learn a generalization model that can perform\nwell on unseen test domains by only training on limited source domains.\nHowever, existing domain generalization approaches often bring in\nprediction-irrelevant noise or require the collection of domain labels. To\naddress these challenges, we consider the domain generalization problem from a\ndifferent perspective by categorizing underlying feature groups into\ndomain-shared and domain-specific features. Nevertheless, the domain-specific\nfeatures are difficult to be identified and distinguished from the input data.\nIn this work, we propose DomaIn-SPEcific Liberating (DISPEL), a post-processing\nfine-grained masking approach that can filter out undefined and\nindistinguishable domain-specific features in the embedding space.\nSpecifically, DISPEL utilizes a mask generator that produces a unique mask for\neach input data to filter domain-specific features. The DISPEL framework is\nhighly flexible to be applied to any fine-tuned models. We derive a\ngeneralization error bound to guarantee the generalization performance by\noptimizing a designed objective loss. The experimental results on five\nbenchmarks demonstrate DISPEL outperforms existing methods and can further\ngeneralize various algorithms.",
          "link": "http://arxiv.org/abs/2307.07181",
          "publishedOn": "2023-07-17T01:05:34.484Z",
          "wordCount": 672,
          "title": "DISPEL: Domain Generalization via Domain-Specific Liberating. (arXiv:2307.07181v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07091",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hussing_M/0/1/0/all/0/1\">Marcel Hussing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendez_J/0/1/0/all/0/1\">Jorge A. Mendez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singrodia_A/0/1/0/all/0/1\">Anisha Singrodia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kent_C/0/1/0/all/0/1\">Cassandra Kent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eaton_E/0/1/0/all/0/1\">Eric Eaton</a>",
          "description": "Offline reinforcement learning (RL) is a promising direction that allows RL\nagents to pre-train on large datasets, avoiding the recurrence of expensive\ndata collection. To advance the field, it is crucial to generate large-scale\ndatasets. Compositional RL is particularly appealing for generating such large\ndatasets, since 1) it permits creating many tasks from few components, 2) the\ntask structure may enable trained agents to solve new tasks by combining\nrelevant learned components, and 3) the compositional dimensions provide a\nnotion of task relatedness. This paper provides four offline RL datasets for\nsimulated robotic manipulation created using the 256 tasks from CompoSuite\n[Mendez et al., 2022a]. Each dataset is collected from an agent with a\ndifferent degree of performance, and consists of 256 million transitions. We\nprovide training and evaluation settings for assessing an agent's ability to\nlearn compositional task policies. Our benchmarking experiments on each setting\nshow that current offline RL methods can learn the training tasks to some\nextent and that compositional methods significantly outperform\nnon-compositional methods. However, current methods are still unable to extract\nthe tasks' compositional structure to generalize to unseen tasks, showing a\nneed for further research in offline compositional RL.",
          "link": "http://arxiv.org/abs/2307.07091",
          "publishedOn": "2023-07-17T01:05:34.469Z",
          "wordCount": 709,
          "title": "Robotic Manipulation Datasets for Offline Compositional Reinforcement Learning. (arXiv:2307.07091v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07413",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1\">Yunjie Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1\">Lei Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_Z/0/1/0/all/0/1\">Zhongwen Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jieming Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalander_M/0/1/0/all/0/1\">Marcus Kalander</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chen Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1\">Jianye Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>",
          "description": "This paper studies a new problem, \\emph{active learning with partial labels}\n(ALPL). In this setting, an oracle annotates the query samples with partial\nlabels, relaxing the oracle from the demanding accurate labeling process. To\naddress ALPL, we first build an intuitive baseline that can be seamlessly\nincorporated into existing AL frameworks. Though effective, this baseline is\nstill susceptible to the \\emph{overfitting}, and falls short of the\nrepresentative partial-label-based samples during the query process. Drawing\ninspiration from human inference in cognitive science, where accurate\ninferences can be explicitly derived from \\emph{counter-examples} (CEs), our\nobjective is to leverage this human-like learning pattern to tackle the\n\\emph{overfitting} while enhancing the process of selecting representative\nsamples in ALPL. Specifically, we construct CEs by reversing the partial labels\nfor each instance, and then we propose a simple but effective WorseNet to\ndirectly learn from this complementary pattern. By leveraging the distribution\ngap between WorseNet and the predictor, this adversarial evaluation manner\ncould enhance both the performance of the predictor itself and the sample\nselection process, allowing the predictor to capture more accurate patterns in\nthe data. Experimental results on five real-world datasets and four benchmark\ndatasets show that our proposed method achieves comprehensive improvements over\nten representative AL frameworks, highlighting the superiority of WorseNet. The\nsource code will be available at \\url{https://github.com/Ferenas/APLL}.",
          "link": "http://arxiv.org/abs/2307.07413",
          "publishedOn": "2023-07-17T01:05:34.449Z",
          "wordCount": null,
          "title": "Exploiting Counter-Examples for Active Learning with Partial labels. (arXiv:2307.07413v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07189",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kirtas_M/0/1/0/all/0/1\">Manos Kirtas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Passalis_N/0/1/0/all/0/1\">Nikolaos Passalis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tefas_A/0/1/0/all/0/1\">Anastasios Tefas</a>",
          "description": "Even nowadays, where Deep Learning (DL) has achieved state-of-the-art\nperformance in a wide range of research domains, accelerating training and\nbuilding robust DL models remains a challenging task. To this end, generations\nof researchers have pursued to develop robust methods for training DL\narchitectures that can be less sensitive to weight distributions, model\narchitectures and loss landscapes. However, such methods are limited to\nadaptive learning rate optimizers, initialization schemes, and clipping\ngradients without investigating the fundamental rule of parameters update.\nAlthough multiplicative updates have contributed significantly to the early\ndevelopment of machine learning and hold strong theoretical claims, to best of\nour knowledge, this is the first work that investigate them in context of DL\ntraining acceleration and robustness. In this work, we propose an optimization\nframework that fits to a wide range of optimization algorithms and enables one\nto apply alternative update rules. To this end, we propose a novel\nmultiplicative update rule and we extend their capabilities by combining it\nwith a traditional additive update term, under a novel hybrid update method. We\nclaim that the proposed framework accelerates training, while leading to more\nrobust models in contrast to traditionally used additive update rule and we\nexperimentally demonstrate their effectiveness in a wide range of task and\noptimization methods. Such tasks ranging from convex and non-convex\noptimization to difficult image classification benchmarks applying a wide range\nof traditionally used optimization methods and Deep Neural Network (DNN)\narchitectures.",
          "link": "http://arxiv.org/abs/2307.07189",
          "publishedOn": "2023-07-17T01:05:34.443Z",
          "wordCount": null,
          "title": "Multiplicative update rules for accelerating deep learning training and increasing robustness. (arXiv:2307.07189v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dey_N/0/1/0/all/0/1\">Neel Dey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abulnaga_S/0/1/0/all/0/1\">S. Mazdak Abulnaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Billot_B/0/1/0/all/0/1\">Benjamin Billot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turk_E/0/1/0/all/0/1\">Esra Abaci Turk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grant_P/0/1/0/all/0/1\">P. Ellen Grant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalca_A/0/1/0/all/0/1\">Adrian V. Dalca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golland_P/0/1/0/all/0/1\">Polina Golland</a>",
          "description": "Star-convex shapes arise across bio-microscopy and radiology in the form of\nnuclei, nodules, metastases, and other units. Existing instance segmentation\nnetworks for such structures train on densely labeled instances for each\ndataset, which requires substantial and often impractical manual annotation\neffort. Further, significant reengineering or finetuning is needed when\npresented with new datasets and imaging modalities due to changes in contrast,\nshape, orientation, resolution, and density. We present AnyStar, a\ndomain-randomized generative model that simulates synthetic training data of\nblob-like objects with randomized appearance, environments, and imaging physics\nto train general-purpose star-convex instance segmentation networks. As a\nresult, networks trained using our generative model do not require annotated\nimages from unseen datasets. A single network trained on our synthesized data\naccurately 3D segments C. elegans and P. dumerilii nuclei in fluorescence\nmicroscopy, mouse cortical nuclei in micro-CT, zebrafish brain nuclei in EM,\nand placental cotyledons in human fetal MRI, all without any retraining,\nfinetuning, transfer learning, or domain adaptation. Code is available at\nhttps://github.com/neel-dey/AnyStar.",
          "link": "http://arxiv.org/abs/2307.07044",
          "publishedOn": "2023-07-17T01:05:34.412Z",
          "wordCount": 690,
          "title": "AnyStar: Domain randomized universal star-convex 3D instance segmentation. (arXiv:2307.07044v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Daiqing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_H/0/1/0/all/0/1\">Huan Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kar_A/0/1/0/all/0/1\">Amlan Kar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Acuna_D/0/1/0/all/0/1\">David Acuna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seung Wook Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreis_K/0/1/0/all/0/1\">Karsten Kreis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1\">Antonio Torralba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fidler_S/0/1/0/all/0/1\">Sanja Fidler</a>",
          "description": "In this work, we introduce a self-supervised feature representation learning\nframework DreamTeacher that utilizes generative networks for pre-training\ndownstream image backbones. We propose to distill knowledge from a trained\ngenerative model into standard image backbones that have been well engineered\nfor specific perception tasks. We investigate two types of knowledge\ndistillation: 1) distilling learned generative features onto target image\nbackbones as an alternative to pretraining these backbones on large labeled\ndatasets such as ImageNet, and 2) distilling labels obtained from generative\nnetworks with task heads onto logits of target backbones. We perform extensive\nanalyses on multiple generative models, dense prediction benchmarks, and\nseveral pre-training regimes. We empirically find that our DreamTeacher\nsignificantly outperforms existing self-supervised representation learning\napproaches across the board. Unsupervised ImageNet pre-training with\nDreamTeacher leads to significant improvements over ImageNet classification\npre-training on downstream datasets, showcasing generative models, and\ndiffusion generative models specifically, as a promising approach to\nrepresentation learning on large, diverse datasets without requiring manual\nannotation.",
          "link": "http://arxiv.org/abs/2307.07487",
          "publishedOn": "2023-07-17T01:05:34.386Z",
          "wordCount": null,
          "title": "DreamTeacher: Pretraining Image Backbones with Deep Generative Models. (arXiv:2307.07487v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07178",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Kang_W/0/1/0/all/0/1\">Wei Kang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Xu_L/0/1/0/all/0/1\">Liang Xu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhou_H/0/1/0/all/0/1\">Hong Zhou</a>",
          "description": "We propose a novel learning-based surrogate data assimilation (DA) model for\nefficient state estimation in a limited area. Our model employs a feedforward\nneural network for online computation, eliminating the need for integrating\nhigh-dimensional limited-area models. This approach offers significant\ncomputational advantages over traditional DA algorithms. Furthermore, our\nmethod avoids the requirement of lateral boundary conditions for the\nlimited-area model in both online and offline computations. The design of our\nsurrogate DA model is built upon a robust theoretical framework that leverages\ntwo fundamental concepts: observability and effective region. The concept of\nobservability enables us to quantitatively determine the optimal amount of\nobservation data necessary for accurate DA. Meanwhile, the concept of effective\nregion substantially reduces the computational burden associated with computing\nobservability and generating training data.",
          "link": "http://arxiv.org/abs/2307.07178",
          "publishedOn": "2023-07-17T01:05:34.380Z",
          "wordCount": null,
          "title": "A Surrogate Data Assimilation Model for the Estimation of Dynamical System in a Limited Area. (arXiv:2307.07178v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07380",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chanchani_S/0/1/0/all/0/1\">Sachin J. Chanchani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_R/0/1/0/all/0/1\">Ruihong Huang</a>",
          "description": "Vector representations of natural language are ubiquitous in search\napplications. Recently, various methods based on contrastive learning have been\nproposed to learn textual representations from unlabelled data; by maximizing\nalignment between minimally-perturbed embeddings of the same text, and\nencouraging a uniform distribution of embeddings across a broader corpus.\nDifferently, we propose maximizing alignment between texts and a composition of\ntheir phrasal constituents. We consider several realizations of this objective\nand elaborate the impact on representations in each case. Experimental results\non semantic textual similarity tasks show improvements over baselines that are\ncomparable with state-of-the-art approaches. Moreover, this work is the first\nto do so without incurring costs in auxiliary training objectives or additional\nnetwork parameters.",
          "link": "http://arxiv.org/abs/2307.07380",
          "publishedOn": "2023-07-17T01:05:34.049Z",
          "wordCount": null,
          "title": "Composition-contrastive Learning for Sentence Embeddings. (arXiv:2307.07380v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07063",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jian_Y/0/1/0/all/0/1\">Yiren Jian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chongyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vosoughi_S/0/1/0/all/0/1\">Soroush Vosoughi</a>",
          "description": "We present a novel methodology aimed at optimizing the application of frozen\nlarge language models (LLMs) for resource-intensive vision-language (VL)\npre-training. The current paradigm uses visual features as prompts to guide\nlanguage models, with a focus on determining the most relevant visual features\nfor corresponding text. Our approach diverges by concentrating on the language\ncomponent, specifically identifying the optimal prompts to align with visual\nfeatures. We introduce the Prompt-Transformer (P-Former), a model that predicts\nthese ideal prompts, which is trained exclusively on linguistic data, bypassing\nthe need for image-text pairings. This strategy subtly bifurcates the\nend-to-end VL training process into an additional, separate stage. Our\nexperiments reveal that our framework significantly enhances the performance of\na robust image-to-text baseline (BLIP-2), and effectively narrows the\nperformance gap between models trained with either 4M or 129M image-text pairs.\nImportantly, our framework is modality-agnostic and flexible in terms of\narchitectural design, as validated by its successful application in a video\nlearning task using varied base modules. The code is available at\nhttps://github.com/yiren-jian/BLIText",
          "link": "http://arxiv.org/abs/2307.07063",
          "publishedOn": "2023-07-17T01:05:33.512Z",
          "wordCount": 680,
          "title": "Bootstrapping Vision-Language Learning with Decoupled Language Pre-training. (arXiv:2307.07063v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.06283",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Jablonka_K/0/1/0/all/0/1\">Kevin Maik Jablonka</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Ai_Q/0/1/0/all/0/1\">Qianxiang Ai</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Al_Feghali_A/0/1/0/all/0/1\">Alexander Al-Feghali</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Badhwar_S/0/1/0/all/0/1\">Shruti Badhwar</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Bocarsly_J/0/1/0/all/0/1\">Joshua D. Bocarsly</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Bran_A/0/1/0/all/0/1\">Andres M Bran</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Bringuier_S/0/1/0/all/0/1\">Stefan Bringuier</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Brinson_L/0/1/0/all/0/1\">L. Catherine Brinson</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Choudhary_K/0/1/0/all/0/1\">Kamal Choudhary</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Circi_D/0/1/0/all/0/1\">Defne Circi</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Cox_S/0/1/0/all/0/1\">Sam Cox</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Jong_W/0/1/0/all/0/1\">Wibe A. de Jong</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Evans_M/0/1/0/all/0/1\">Matthew L. Evans</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Gastellu_N/0/1/0/all/0/1\">Nicolas Gastellu</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Genzling_J/0/1/0/all/0/1\">Jerome Genzling</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Gil_M/0/1/0/all/0/1\">Mar&#xed;a Victoria Gil</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Gupta_A/0/1/0/all/0/1\">Ankur K. Gupta</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Hong_Z/0/1/0/all/0/1\">Zhi Hong</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Imran_A/0/1/0/all/0/1\">Alishba Imran</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Kruschwitz_S/0/1/0/all/0/1\">Sabine Kruschwitz</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Labarre_A/0/1/0/all/0/1\">Anne Labarre</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Lala_J/0/1/0/all/0/1\">Jakub L&#xe1;la</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Liu_T/0/1/0/all/0/1\">Tao Liu</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Ma_S/0/1/0/all/0/1\">Steven Ma</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Majumdar_S/0/1/0/all/0/1\">Sauradeep Majumdar</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Merz_G/0/1/0/all/0/1\">Garrett W. Merz</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Moitessier_N/0/1/0/all/0/1\">Nicolas Moitessier</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Moubarak_E/0/1/0/all/0/1\">Elias Moubarak</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Mourino_B/0/1/0/all/0/1\">Beatriz Mouri&#xf1;o</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Pelkie_B/0/1/0/all/0/1\">Brenden Pelkie</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Pieler_M/0/1/0/all/0/1\">Michael Pieler</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Ramos_M/0/1/0/all/0/1\">Mayk Caldas Ramos</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Rankovic_B/0/1/0/all/0/1\">Bojana Rankovi&#x107;</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Rodriques_S/0/1/0/all/0/1\">Samuel G. Rodriques</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Sanders_J/0/1/0/all/0/1\">Jacob N. Sanders</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Schwaller_P/0/1/0/all/0/1\">Philippe Schwaller</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Schwarting_M/0/1/0/all/0/1\">Marcus Schwarting</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Shi_J/0/1/0/all/0/1\">Jiale Shi</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Smit_B/0/1/0/all/0/1\">Berend Smit</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Smith_B/0/1/0/all/0/1\">Ben E. Smith</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Herck_J/0/1/0/all/0/1\">Joren Van Herck</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Volker_C/0/1/0/all/0/1\">Christoph V&#xf6;lker</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Ward_L/0/1/0/all/0/1\">Logan Ward</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Warren_S/0/1/0/all/0/1\">Sean Warren</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Weiser_B/0/1/0/all/0/1\">Benjamin Weiser</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Zhang_S/0/1/0/all/0/1\">Sylvester Zhang</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaoqi Zhang</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Zia_G/0/1/0/all/0/1\">Ghezal Ahmad Zia</a>, et al. (5 additional authors not shown)",
          "description": "Large-language models (LLMs) such as GPT-4 caught the interest of many\nscientists. Recent studies suggested that these models could be useful in\nchemistry and materials science. To explore these possibilities, we organized a\nhackathon.\n\nThis article chronicles the projects built as part of this hackathon.\nParticipants employed LLMs for various applications, including predicting\nproperties of molecules and materials, designing novel interfaces for tools,\nextracting knowledge from unstructured data, and developing new educational\napplications.\n\nThe diverse topics and the fact that working prototypes could be generated in\nless than two days highlight that LLMs will profoundly impact the future of our\nfields. The rich collection of ideas and projects also indicates that the\napplications of LLMs are not limited to materials science and chemistry but\noffer potential benefits to a wide range of scientific disciplines.",
          "link": "http://arxiv.org/abs/2306.06283",
          "publishedOn": "2023-07-15T01:02:14.617Z",
          "wordCount": 837,
          "title": "14 Examples of How LLMs Can Transform Materials Science and Chemistry: A Reflection on a Large Language Model Hackathon. (arXiv:2306.06283v3 [cond-mat.mtrl-sci] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2201.07372",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Silva_A/0/1/0/all/0/1\">Ashwin De Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramesh_R/0/1/0/all/0/1\">Rahul Ramesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ungar_L/0/1/0/all/0/1\">Lyle Ungar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shuler_M/0/1/0/all/0/1\">Marshall Hussain Shuler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cowan_N/0/1/0/all/0/1\">Noah J. Cowan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Platt_M/0/1/0/all/0/1\">Michael Platt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isik_L/0/1/0/all/0/1\">Leyla Isik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roh_S/0/1/0/all/0/1\">Seung-Eon Roh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charles_A/0/1/0/all/0/1\">Adam Charles</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venkataraman_A/0/1/0/all/0/1\">Archana Venkataraman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caffo_B/0/1/0/all/0/1\">Brian Caffo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+How_J/0/1/0/all/0/1\">Javier J. How</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kebschull_J/0/1/0/all/0/1\">Justus M Kebschull</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krakauer_J/0/1/0/all/0/1\">John W. Krakauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bichuch_M/0/1/0/all/0/1\">Maxim Bichuch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kinfu_K/0/1/0/all/0/1\">Kaleab Alemayehu Kinfu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yezerets_E/0/1/0/all/0/1\">Eva Yezerets</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jayaraman_D/0/1/0/all/0/1\">Dinesh Jayaraman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jong M. Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Villar_S/0/1/0/all/0/1\">Soledad Villar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phillips_I/0/1/0/all/0/1\">Ian Phillips</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Priebe_C/0/1/0/all/0/1\">Carey E. Priebe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hartung_T/0/1/0/all/0/1\">Thomas Hartung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_M/0/1/0/all/0/1\">Michael I. Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dey_J/0/1/0/all/0/1\">Jayanta Dey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ningyuan/0/1/0/all/0/1\">Ningyuan</a> (Teresa) <a href=\"http://arxiv.org/find/cs/1/au:+Huang/0/1/0/all/0/1\">Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eaton_E/0/1/0/all/0/1\">Eric Eaton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Etienne_Cummings_R/0/1/0/all/0/1\">Ralph Etienne-Cummings</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ogburn_E/0/1/0/all/0/1\">Elizabeth L. Ogburn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burns_R/0/1/0/all/0/1\">Randal Burns</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osuagwu_O/0/1/0/all/0/1\">Onyema Osuagwu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mensh_B/0/1/0/all/0/1\">Brett Mensh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muotri_A/0/1/0/all/0/1\">Alysson R. Muotri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_J/0/1/0/all/0/1\">Julia Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_C/0/1/0/all/0/1\">Chris White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Weiwei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rusu_A/0/1/0/all/0/1\">Andrei A. Rusu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verstynen_T/0/1/0/all/0/1\">Timothy Verstynen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kording_K/0/1/0/all/0/1\">Konrad P. Kording</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhari_P/0/1/0/all/0/1\">Pratik Chaudhari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogelstein_J/0/1/0/all/0/1\">Joshua T. Vogelstein</a>",
          "description": "Learning is a process which can update decision rules, based on past\nexperience, such that future performance improves. Traditionally, machine\nlearning is often evaluated under the assumption that the future will be\nidentical to the past in distribution or change adversarially. But these\nassumptions can be either too optimistic or pessimistic for many problems in\nthe real world. Real world scenarios evolve over multiple spatiotemporal scales\nwith partially predictable dynamics. Here we reformulate the learning problem\nto one that centers around this idea of dynamic futures that are partially\nlearnable. We conjecture that certain sequences of tasks are not\nretrospectively learnable (in which the data distribution is fixed), but are\nprospectively learnable (in which distributions may be dynamic), suggesting\nthat prospective learning is more difficult in kind than retrospective\nlearning. We argue that prospective learning more accurately characterizes many\nreal world problems that (1) currently stymie existing artificial intelligence\nsolutions and/or (2) lack adequate explanations for how natural intelligences\nsolve them. Thus, studying prospective learning will lead to deeper insights\nand solutions to currently vexing challenges in both natural and artificial\nintelligences.",
          "link": "http://arxiv.org/abs/2201.07372",
          "publishedOn": "2023-07-14T01:03:53.248Z",
          "wordCount": 831,
          "title": "Prospective Learning: Principled Extrapolation to the Future. (arXiv:2201.07372v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06324",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Grimmer_B/0/1/0/all/0/1\">Benjamin Grimmer</a>",
          "description": "This work establishes provably faster convergence rates for gradient descent\nvia a computer-assisted analysis technique. Our theory allows nonconstant\nstepsize policies with frequent long steps potentially violating descent by\nanalyzing the overall effect of many iterations at once rather than the typical\none-iteration inductions used in most first-order method analyses. We show that\nlong steps, which may increase the objective value in the short term, lead to\nprovably faster convergence in the long term. A conjecture towards proving a\nfaster $O(1/T\\log T)$ rate for gradient descent is also motivated along with\nsimple numerical validation.",
          "link": "http://arxiv.org/abs/2307.06324",
          "publishedOn": "2023-07-14T01:03:53.238Z",
          "wordCount": null,
          "title": "Provably Faster Gradient Descent via Long Steps. (arXiv:2307.06324v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.10081",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Haibin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zichuan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyou Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Q/0/1/0/all/0/1\">Qiang Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_D/0/1/0/all/0/1\">Deheng Ye</a>",
          "description": "We study the adaption of soft actor-critic (SAC) from continuous action space\nto discrete action space. We revisit vanilla SAC and provide an in-depth\nunderstanding of its Q value underestimation and performance instability issues\nwhen applied to discrete settings. We thereby propose entropy-penalty and\ndouble average Q-learning with Q-clip to address these issues. Extensive\nexperiments on typical benchmarks with discrete action space, including Atari\ngames and a large-scale MOBA game, show the efficacy of our proposed method.\nOur code is at:https://github.com/coldsummerday/Revisiting-Discrete-SAC.",
          "link": "http://arxiv.org/abs/2209.10081",
          "publishedOn": "2023-07-14T01:03:53.237Z",
          "wordCount": 607,
          "title": "Revisiting Discrete Soft Actor-Critic. (arXiv:2209.10081v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06380",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghorbani_R/0/1/0/all/0/1\">Ramin Ghorbani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reinders_M/0/1/0/all/0/1\">Marcel J.T. Reinders</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tax_D/0/1/0/all/0/1\">David M.J. Tax</a>",
          "description": "Photoplethysmography (PPG) signals, typically acquired from wearable devices,\nhold significant potential for continuous fitness-health monitoring. In\nparticular, heart conditions that manifest in rare and subtle deviating heart\npatterns may be interesting. However, robust and reliable anomaly detection\nwithin these data remains a challenge due to the scarcity of labeled data and\nhigh inter-subject variability. This paper introduces a two-stage framework\nleveraging representation learning and personalization to improve anomaly\ndetection performance in PPG data. The proposed framework first employs\nrepresentation learning to transform the original PPG signals into a more\ndiscriminative and compact representation. We then apply three different\nunsupervised anomaly detection methods for movement detection and biometric\nidentification. We validate our approach using two different datasets in both\ngeneralized and personalized scenarios. The results show that representation\nlearning significantly improves anomaly detection performance while reducing\nthe high inter-subject variability. Personalized models further enhance anomaly\ndetection performance, underscoring the role of personalization in PPG-based\nfitness-health monitoring systems. The results from biometric identification\nshow that it's easier to distinguish a new user from one intended authorized\nuser than from a group of users. Overall, this study provides evidence of the\neffectiveness of representation learning and personalization for anomaly\ndetection in PPG data.",
          "link": "http://arxiv.org/abs/2307.06380",
          "publishedOn": "2023-07-14T01:03:53.231Z",
          "wordCount": 725,
          "title": "Personalized Anomaly Detection in PPG Data using Representation Learning and Biometric Identification. (arXiv:2307.06380v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06941",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Albini_E/0/1/0/all/0/1\">Emanuele Albini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Shubham Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Saumitra Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dervovic_D/0/1/0/all/0/1\">Danial Dervovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magazzeni_D/0/1/0/all/0/1\">Daniele Magazzeni</a>",
          "description": "Explainable Artificial Intelligence (XAI) has received widespread interest in\nrecent years, and two of the most popular types of explanations are feature\nattributions, and counterfactual explanations. These classes of approaches have\nbeen largely studied independently and the few attempts at reconciling them\nhave been primarily empirical. This work establishes a clear theoretical\nconnection between game-theoretic feature attributions, focusing on but not\nlimited to SHAP, and counterfactuals explanations. After motivating operative\nchanges to Shapley values based feature attributions and counterfactual\nexplanations, we prove that, under conditions, they are in fact equivalent. We\nthen extend the equivalency result to game-theoretic solution concepts beyond\nShapley values. Moreover, through the analysis of the conditions of such\nequivalence, we shed light on the limitations of naively using counterfactual\nexplanations to provide feature importances. Experiments on three datasets\nquantitatively show the difference in explanations at every stage of the\nconnection between the two approaches and corroborate the theoretical findings.",
          "link": "http://arxiv.org/abs/2307.06941",
          "publishedOn": "2023-07-14T01:03:53.231Z",
          "wordCount": null,
          "title": "On the Connection between Game-Theoretic Feature Attributions and Counterfactual Explanations. (arXiv:2307.06941v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.06407",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lawson_D/0/1/0/all/0/1\">Daniel Lawson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qureshi_A/0/1/0/all/0/1\">Ahmed H. Qureshi</a>",
          "description": "Learning long-horizon tasks such as navigation has presented difficult\nchallenges for successfully applying reinforcement learning to robotics. From\nanother perspective, under known environments, sampling-based planning can\nrobustly find collision-free paths in environments without learning. In this\nwork, we propose Control Transformer that models return-conditioned sequences\nfrom low-level policies guided by a sampling-based Probabilistic Roadmap (PRM)\nplanner. We demonstrate that our framework can solve long-horizon navigation\ntasks using only local information. We evaluate our approach on\npartially-observed maze navigation with MuJoCo robots, including Ant, Point,\nand Humanoid. We show that Control Transformer can successfully navigate\nthrough mazes and transfer to unknown environments. Additionally, we apply our\nmethod to a differential drive robot (Turtlebot3) and show zero-shot sim2real\ntransfer under noisy observations.",
          "link": "http://arxiv.org/abs/2211.06407",
          "publishedOn": "2023-07-14T01:03:53.213Z",
          "wordCount": null,
          "title": "Control Transformer: Robot Navigation in Unknown Environments through PRM-Guided Return-Conditioned Sequence Modeling. (arXiv:2211.06407v3 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06501",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lv_W/0/1/0/all/0/1\">Wenzhou Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tianyu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1\">Luolin Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Liang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jian Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1\">Feng Qi</a>",
          "description": "Objective: The artificial pancreas (AP) has shown promising potential in\nachieving closed-loop glucose control for individuals with type 1 diabetes\nmellitus (T1DM). However, designing an effective control policy for the AP\nremains challenging due to the complex physiological processes, delayed insulin\nresponse, and inaccurate glucose measurements. While model predictive control\n(MPC) offers safety and stability through the dynamic model and safety\nconstraints, it lacks individualization and is adversely affected by\nunannounced meals. Conversely, deep reinforcement learning (DRL) provides\npersonalized and adaptive strategies but faces challenges with distribution\nshifts and substantial data requirements. Methods: We propose a hybrid control\npolicy for the artificial pancreas (HyCPAP) to address the above challenges.\nHyCPAP combines an MPC policy with an ensemble DRL policy, leveraging the\nstrengths of both policies while compensating for their respective limitations.\nTo facilitate faster deployment of AP systems in real-world settings, we\nfurther incorporate meta-learning techniques into HyCPAP, leveraging previous\nexperience and patient-shared knowledge to enable fast adaptation to new\npatients with limited available data. Results: We conduct extensive experiments\nusing the FDA-accepted UVA/Padova T1DM simulator across three scenarios. Our\napproaches achieve the highest percentage of time spent in the desired\neuglycemic range and the lowest occurrences of hypoglycemia. Conclusion: The\nresults clearly demonstrate the superiority of our methods for closed-loop\nglucose management in individuals with T1DM. Significance: The study presents\nnovel control policies for AP systems, affirming the great potential of\nproposed methods for efficient closed-loop glucose control.",
          "link": "http://arxiv.org/abs/2307.06501",
          "publishedOn": "2023-07-14T01:03:53.182Z",
          "wordCount": 761,
          "title": "Hybrid Control Policy for Artificial Pancreas via Ensemble Deep Reinforcement Learning. (arXiv:2307.06501v1 [cs.AI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brandenburger_A/0/1/0/all/0/1\">Andr&#xe9; Brandenburger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoffmann_F/0/1/0/all/0/1\">Folker Hoffmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charlish_A/0/1/0/all/0/1\">Alexander Charlish</a>",
          "description": "The performance of data fusion and tracking algorithms often depends on\nparameters that not only describe the sensor system, but can also be\ntask-specific. While for the sensor system tuning these variables is\ntime-consuming and mostly requires expert knowledge, intrinsic parameters of\ntargets under track can even be completely unobservable until the system is\ndeployed. With state-of-the-art sensor systems growing more and more complex,\nthe number of parameters naturally increases, necessitating the automatic\noptimization of the model variables. In this paper, the parameters of an\ninteracting multiple model (IMM) filter are optimized solely using\nmeasurements, thus without necessity for any ground-truth data. The resulting\nmethod is evaluated through an ablation study on simulated data, where the\ntrained model manages to match the performance of a filter parametrized with\nground-truth values.",
          "link": "http://arxiv.org/abs/2307.06618",
          "publishedOn": "2023-07-14T01:03:53.177Z",
          "wordCount": null,
          "title": "Learning IMM Filter Parameters from Measurements using Gradient Descent. (arXiv:2307.06618v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05926",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Chun Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quintana_M/0/1/0/all/0/1\">Matias Quintana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagy_Z/0/1/0/all/0/1\">Zoltan Nagy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_C/0/1/0/all/0/1\">Clayton Miller</a>",
          "description": "Building energy prediction and management has become increasingly important\nin recent decades, driven by the growth of Internet of Things (IoT) devices and\nthe availability of more energy data. However, energy data is often collected\nfrom multiple sources and can be incomplete or inconsistent, which can hinder\naccurate predictions and management of energy systems and limit the usefulness\nof the data for decision-making and research. To address this issue, past\nstudies have focused on imputing missing gaps in energy data, including random\nand continuous gaps. One of the main challenges in this area is the lack of\nvalidation on a benchmark dataset with various building and meter types, making\nit difficult to accurately evaluate the performance of different imputation\nmethods. Another challenge is the lack of application of state-of-the-art\nimputation methods for missing gaps in energy data. Contemporary\nimage-inpainting methods, such as Partial Convolution (PConv), have been widely\nused in the computer vision domain and have demonstrated their effectiveness in\ndealing with complex missing patterns. To study whether energy data imputation\ncan benefit from the image-based deep learning method, this study compared\nPConv, Convolutional neural networks (CNNs), and weekly persistence method\nusing one of the biggest publicly available whole building energy datasets,\nconsisting of 1479 power meters worldwide, as the benchmark. The results show\nthat, compared to the CNN with the raw time series (1D-CNN) and the weekly\npersistence method, neural network models with reshaped energy data with two\ndimensions reduced the Mean Squared Error (MSE) by 10% to 30%. The advanced\ndeep learning method, Partial convolution (PConv), has further reduced the MSE\nby 20-30% than 2D-CNN and stands out among all models.",
          "link": "http://arxiv.org/abs/2307.05926",
          "publishedOn": "2023-07-14T01:03:53.176Z",
          "wordCount": null,
          "title": "Filling time-series gaps using image techniques: Multidimensional context autoencoder approach for building energy data imputation. (arXiv:2307.05926v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06565",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_L/0/1/0/all/0/1\">Lianke Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuanyuan Yang</a>",
          "description": "Deep learning has been widely used in many fields, but the model training\nprocess usually consumes massive computational resources and time. Therefore,\ndesigning an efficient neural network training method with a provable\nconvergence guarantee is a fundamental and important research question. In this\npaper, we present a static half-space report data structure that consists of a\nfully connected two-layer neural network for shifted ReLU activation to enable\nactivated neuron identification in sublinear time via geometric search. We also\nprove that our algorithm can converge in $O(M^2/\\epsilon^2)$ time with network\nsize quadratic in the coefficient norm upper bound $M$ and error term\n$\\epsilon$.",
          "link": "http://arxiv.org/abs/2307.06565",
          "publishedOn": "2023-07-14T01:03:53.175Z",
          "wordCount": null,
          "title": "Efficient SGD Neural Network Training via Sublinear Activated Neuron Identification. (arXiv:2307.06565v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.07501",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhicheng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jiaxuan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_L/0/1/0/all/0/1\">Licheng Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xu Liu</a>",
          "description": "We propose a balanced coarsening scheme for multilevel hypergraph\npartitioning. In addition, an initial partitioning algorithm is designed to\nimprove the quality of k-way hypergraph partitioning. By assigning vertex\nweights through the LPT algorithm, we generate a prior hypergraph under a\nrelaxed balance constraint. With the prior hypergraph, we have defined the\nWasserstein discrepancy to coordinate the optimal transport of coarsening\nprocess. And the optimal transport matrix is solved by Sinkhorn algorithm. Our\ncoarsening scheme fully takes into account the minimization of connectivity\nmetric (objective function). For the initial partitioning stage, we define a\nnormalized cut function induced by Fiedler vector, which is theoretically\nproved to be a concave function. Thereby, a three-point algorithm is designed\nto find the best cut under the balance constraint.",
          "link": "http://arxiv.org/abs/2106.07501",
          "publishedOn": "2023-07-14T01:03:53.175Z",
          "wordCount": null,
          "title": "Balanced Coarsening for Multilevel Hypergraph Partitioning via Wasserstein Discrepancy. (arXiv:2106.07501v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.08715",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Samir_R/0/1/0/all/0/1\">Romario Sameh Samir</a>",
          "description": "Accurate and efficient classification of different types of cancer is\ncritical for early detection and effective treatment. In this paper, we present\nthe results of our experiments using the EfficientNet algorithm for\nclassification of brain tumor, breast cancer mammography, chest cancer, and\nskin cancer. We used publicly available datasets and preprocessed the images to\nensure consistency and comparability. Our experiments show that the\nEfficientNet algorithm achieved high accuracy, precision, recall, and F1 scores\non each of the cancer datasets, outperforming other state-of-the-art algorithms\nin the literature. We also discuss the strengths and weaknesses of the\nEfficientNet algorithm and its potential applications in clinical practice. Our\nresults suggest that the EfficientNet algorithm is well-suited for\nclassification of different types of cancer and can be used to improve the\naccuracy and efficiency of cancer diagnosis.",
          "link": "http://arxiv.org/abs/2304.08715",
          "publishedOn": "2023-07-14T01:03:53.175Z",
          "wordCount": null,
          "title": "EfficientNet Algorithm for Classification of Different Types of Cancer. (arXiv:2304.08715v3 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.11336",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gross_B/0/1/0/all/0/1\">Benedikt Gro&#xdf;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wunder_G/0/1/0/all/0/1\">Gerhard Wunder</a>",
          "description": "Synthetic data has been hailed as the silver bullet for privacy preserving\ndata analysis. If a record is not real, then how could it violate a person's\nprivacy? In addition, deep-learning based generative models are employed\nsuccessfully to approximate complex high-dimensional distributions from data\nand draw realistic samples from this learned distribution. It is often\noverlooked though that generative models are prone to memorising many details\nof individual training records and often generate synthetic data that too\nclosely resembles the underlying sensitive training data, hence violating\nstrong privacy regulations as, e.g., encountered in health care. Differential\nprivacy is the well-known state-of-the-art framework for guaranteeing\nprotection of sensitive individuals' data, allowing aggregate statistics and\neven machine learning models to be released publicly without compromising\nprivacy. The training mechanisms however often add too much noise during the\ntraining process, and thus severely compromise the utility of these private\nmodels. Even worse, the tight privacy budgets do not allow for many training\nepochs so that model quality cannot be properly controlled in practice. In this\npaper we explore an alternative approach for privately generating data that\nmakes direct use of the inherent stochasticity in generative models, e.g.,\nvariational autoencoders. The main idea is to appropriately constrain the\ncontinuity modulus of the deep models instead of adding another noise mechanism\non top. For this approach, we derive mathematically rigorous privacy guarantees\nand illustrate its effectiveness with practical experiments.",
          "link": "http://arxiv.org/abs/2304.11336",
          "publishedOn": "2023-07-14T01:03:53.175Z",
          "wordCount": null,
          "title": "Differentially Private Synthetic Data Generation via Lipschitz-Regularised Variational Autoencoders. (arXiv:2304.11336v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.03875",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Beibin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mellou_K/0/1/0/all/0/1\">Konstantina Mellou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pathuri_J/0/1/0/all/0/1\">Jeevan Pathuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menache_I/0/1/0/all/0/1\">Ishai Menache</a>",
          "description": "Supply chain operations traditionally involve a variety of complex decision\nmaking problems. Over the last few decades, supply chains greatly benefited\nfrom advances in computation, which allowed the transition from manual\nprocessing to automation and cost-effective optimization. Nonetheless, business\noperators still need to spend substantial efforts in explaining and\ninterpreting the optimization outcomes to stakeholders. Motivated by the recent\nadvances in Large Language Models (LLMs), we study how this disruptive\ntechnology can help bridge the gap between supply chain automation and human\ncomprehension and trust thereof. We design OptiGuide -- a framework that\naccepts as input queries in plain text, and outputs insights about the\nunderlying optimization outcomes. Our framework does not forgo the\nstate-of-the-art combinatorial optimization technology, but rather leverages it\nto quantitatively answer what-if scenarios (e.g., how would the cost change if\nwe used supplier B instead of supplier A for a given demand?). Importantly, our\ndesign does not require sending proprietary data over to LLMs, which can be a\nprivacy concern in some circumstances. We demonstrate the effectiveness of our\nframework on a real server placement scenario within Microsoft's cloud supply\nchain. Along the way, we develop a general evaluation benchmark, which can be\nused to evaluate the accuracy of the LLM output in other scenarios.",
          "link": "http://arxiv.org/abs/2307.03875",
          "publishedOn": "2023-07-14T01:03:53.175Z",
          "wordCount": null,
          "title": "Large Language Models for Supply Chain Optimization. (arXiv:2307.03875v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06855",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akbiyik_M/0/1/0/all/0/1\">M. Eren Akbiyik</a>",
          "description": "Noise injection is a fundamental tool for data augmentation, and yet there is\nno widely accepted procedure to incorporate it with learning frameworks. This\nstudy analyzes the effects of adding or applying different noise models of\nvarying magnitudes to Convolutional Neural Network (CNN) architectures. Noise\nmodels that are distributed with different density functions are given common\nmagnitude levels via Structural Similarity (SSIM) metric in order to create an\nappropriate ground for comparison. The basic results are conforming with the\nmost of the common notions in machine learning, and also introduce some novel\nheuristics and recommendations on noise injection. The new approaches will\nprovide better understanding on optimal learning procedures for image\nclassification.",
          "link": "http://arxiv.org/abs/2307.06855",
          "publishedOn": "2023-07-14T01:03:53.174Z",
          "wordCount": null,
          "title": "Data Augmentation in Training CNNs: Injecting Noise to Images. (arXiv:2307.06855v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.01316",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharifi_I/0/1/0/all/0/1\">Iman Sharifi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yildirim_M/0/1/0/all/0/1\">Mustafa Yildirim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fallah_S/0/1/0/all/0/1\">Saber Fallah</a>",
          "description": "The dynamic nature of driving environments and the presence of diverse road\nusers pose significant challenges for decision-making in autonomous driving.\nDeep reinforcement learning (DRL) has emerged as a popular approach to tackle\nthis problem. However, the application of existing DRL solutions is mainly\nconfined to simulated environments due to safety concerns, impeding their\ndeployment in real-world. To overcome this limitation, this paper introduces a\nnovel neuro-symbolic model-free DRL approach, called DRL with Symbolic Logics\n(DRLSL) that combines the strengths of DRL (learning from experience) and\nsymbolic first-order logics (knowledge-driven reasoning) to enable safe\nlearning in real-time interactions of autonomous driving within real\nenvironments. This innovative approach provides a means to learn autonomous\ndriving policies by actively engaging with the physical environment while\nensuring safety. We have implemented the DRLSL framework in autonomous driving\nusing the highD dataset and demonstrated that our method successfully avoids\nunsafe actions during both the training and testing phases. Furthermore, our\nresults indicate that DRLSL achieves faster convergence during training and\nexhibits better generalizability to new driving scenarios compared to\ntraditional DRL methods.",
          "link": "http://arxiv.org/abs/2307.01316",
          "publishedOn": "2023-07-14T01:03:53.174Z",
          "wordCount": null,
          "title": "Towards Safe Autonomous Driving Policies using a Neuro-Symbolic Deep Reinforcement Learning Approach. (arXiv:2307.01316v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05845",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haas_L/0/1/0/all/0/1\">Lukas Haas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skreta_M/0/1/0/all/0/1\">Michal Skreta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alberti_S/0/1/0/all/0/1\">Silas Alberti</a>",
          "description": "We introduce PIGEON, a multi-task end-to-end system for planet-scale image\ngeolocalization that achieves state-of-the-art performance on both external\nbenchmarks and in human evaluation. Our work incorporates semantic geocell\ncreation with label smoothing, conducts pretraining of a vision transformer on\nimages with geographic information, and refines location predictions with\nProtoNets across a candidate set of geocells. The contributions of PIGEON are\nthree-fold: first, we design a semantic geocells creation and splitting\nalgorithm based on open-source data which can be adapted to any geospatial\ndataset. Second, we show the effectiveness of intra-geocell refinement and the\napplicability of unsupervised clustering and ProtNets to the task. Finally, we\nmake our pre-trained CLIP transformer model, StreetCLIP, publicly available for\nuse in adjacent domains with applications to fighting climate change and urban\nand rural scene understanding.",
          "link": "http://arxiv.org/abs/2307.05845",
          "publishedOn": "2023-07-14T01:03:53.174Z",
          "wordCount": null,
          "title": "PIGEON: Predicting Image Geolocations. (arXiv:2307.05845v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06422",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chien_E/0/1/0/all/0/1\">Eli Chien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei-Ning Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_C/0/1/0/all/0/1\">Chao Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Pan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozgur_A/0/1/0/all/0/1\">Ayfer &#xd6;zg&#xfc;r</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milenkovic_O/0/1/0/all/0/1\">Olgica Milenkovic</a>",
          "description": "Graph learning methods, such as Graph Neural Networks (GNNs) based on graph\nconvolutions, are highly successful in solving real-world learning problems\ninvolving graph-structured data. However, graph learning methods expose\nsensitive user information and interactions not only through their model\nparameters but also through their model predictions. Consequently, standard\nDifferential Privacy (DP) techniques that merely offer model weight privacy are\ninadequate. This is especially the case for node predictions that leverage\nneighboring node attributes directly via graph convolutions that create\nadditional risks of privacy leakage. To address this problem, we introduce\nGraph Differential Privacy (GDP), a new formal DP framework tailored to graph\nlearning settings that ensures both provably private model parameters and\npredictions. Furthermore, since there may be different privacy requirements for\nthe node attributes and graph structure, we introduce a novel notion of relaxed\nnode-level data adjacency. This relaxation can be used for establishing\nguarantees for different degrees of graph topology privacy while maintaining\nnode attribute privacy. Importantly, this relaxation reveals a useful trade-off\nbetween utility and topology privacy for graph learning methods. In addition,\nour analysis of GDP reveals that existing DP-GNNs fail to exploit this\ntrade-off due to the complex interplay between graph topology and attribute\ndata in standard graph convolution designs. To mitigate this problem, we\nintroduce the Differentially Private Decoupled Graph Convolution (DPDGC) model,\nwhich benefits from decoupled graph convolution while providing GDP guarantees.\nExtensive experiments on seven node classification benchmarking datasets\ndemonstrate the superior privacy-utility trade-off of DPDGC over existing\nDP-GNNs based on standard graph convolution design.",
          "link": "http://arxiv.org/abs/2307.06422",
          "publishedOn": "2023-07-14T01:03:53.173Z",
          "wordCount": 765,
          "title": "Differentially Private Decoupled Graph Convolutions for Multigranular Topology Protection. (arXiv:2307.06422v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06825",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Nevin L. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Kaican Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1\">Han Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1\">Weiyan Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenguo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Luning Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongxiang Huang</a>",
          "description": "Domain generalization (DG) is about learning models that generalize well to\nnew domains that are related to, but different from, the training domain(s). It\nis a fundamental problem in machine learning and has attracted much attention\nin recent years. A large number of approaches have been proposed. Different\napproaches are motivated from different perspectives, making it difficult to\ngain an overall understanding of the area. In this paper, we propose a causal\nframework for domain generalization and present an understanding of common DG\napproaches in the framework. Our work sheds new lights on the following\nquestions: (1) What are the key ideas behind each DG method? (2) Why is it\nexpected to improve generalization to new domains theoretically? (3) How are\ndifferent DG methods related to each other and what are relative advantages and\nlimitations? By providing a unified perspective on DG, we hope to help\nresearchers better understand the underlying principles and develop more\neffective approaches for this critical problem in machine learning.",
          "link": "http://arxiv.org/abs/2307.06825",
          "publishedOn": "2023-07-14T01:03:53.168Z",
          "wordCount": null,
          "title": "A Causal Framework to Unify Common Domain Generalization Approaches. (arXiv:2307.06825v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06547",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Horry_M/0/1/0/all/0/1\">Michael James Horry</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chakraborty_S/0/1/0/all/0/1\">Subrata Chakraborty</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pradhan_B/0/1/0/all/0/1\">Biswajeet Pradhan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Paul_M/0/1/0/all/0/1\">Manoranjan Paul</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_J/0/1/0/all/0/1\">Jing Zhu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Barua_P/0/1/0/all/0/1\">Prabal Datta Barua</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Acharya_U/0/1/0/all/0/1\">U. Rajendra Acharya</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_F/0/1/0/all/0/1\">Fang Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_J/0/1/0/all/0/1\">Jianlong Zhou</a>",
          "description": "Lung cancer is the leading cause of cancer death and early diagnosis is\nassociated with a positive prognosis. Chest X-ray (CXR) provides an inexpensive\nimaging mode for lung cancer diagnosis. Suspicious nodules are difficult to\ndistinguish from vascular and bone structures using CXR. Computer vision has\npreviously been proposed to assist human radiologists in this task, however,\nleading studies use down-sampled images and computationally expensive methods\nwith unproven generalization. Instead, this study localizes lung nodules using\nefficient encoder-decoder neural networks that process full resolution images\nto avoid any signal loss resulting from down-sampling. Encoder-decoder networks\nare trained and tested using the JSRT lung nodule dataset. The networks are\nused to localize lung nodules from an independent external CXR dataset.\nSensitivity and false positive rates are measured using an automated framework\nto eliminate any observer subjectivity. These experiments allow for the\ndetermination of the optimal network depth, image resolution and pre-processing\npipeline for generalized lung nodule localization. We find that nodule\nlocalization is influenced by subtlety, with more subtle nodules being detected\nin earlier training epochs. Therefore, we propose a novel self-ensemble model\nfrom three consecutive epochs centered on the validation optimum. This ensemble\nachieved a sensitivity of 85% in 10-fold internal testing with false positives\nof 8 per image. A sensitivity of 81% is achieved at a false positive rate of 6\nfollowing morphological false positive reduction. This result is comparable to\nmore computationally complex systems based on linear and spatial filtering, but\nwith a sub-second inference time that is faster than other methods. The\nproposed algorithm achieved excellent generalization results against an\nexternal dataset with sensitivity of 77% at a false positive rate of 7.6.",
          "link": "http://arxiv.org/abs/2307.06547",
          "publishedOn": "2023-07-14T01:03:53.166Z",
          "wordCount": 824,
          "title": "Full-resolution Lung Nodule Segmentation from Chest X-ray Images using Residual Encoder-Decoder Networks. (arXiv:2307.06547v1 [eess.IV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.12330",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Viquerat_J/0/1/0/all/0/1\">J. Viquerat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hachem_E/0/1/0/all/0/1\">E. Hachem</a>",
          "description": "The coupling of deep reinforcement learning to numerical flow control\nproblems has recently received a considerable attention, leading to\ngroundbreaking results and opening new perspectives for the domain. Due to the\nusually high computational cost of fluid dynamics solvers, the use of parallel\nenvironments during the learning process represents an essential ingredient to\nattain efficient control in a reasonable time. Yet, most of the deep\nreinforcement learning literature for flow control relies on on-policy\nalgorithms, for which the massively parallel transition collection may break\ntheoretical assumptions and lead to suboptimal control models. To overcome this\nissue, we propose a parallelism pattern relying on partial-trajectory buffers\nterminated by a return bootstrapping step, allowing a flexible use of parallel\nenvironments while preserving the on-policiness of the updates. This approach\nis illustrated on a CPU-intensive continuous flow control problem from the\nliterature.",
          "link": "http://arxiv.org/abs/2304.12330",
          "publishedOn": "2023-07-14T01:03:53.160Z",
          "wordCount": 686,
          "title": "Parallel bootstrap-based on-policy deep reinforcement learning for continuous flow control applications. (arXiv:2304.12330v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06442",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yu-Zhen Janice Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menasche_D/0/1/0/all/0/1\">Daniel S. Menasch&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Towsley_D/0/1/0/all/0/1\">Don Towsley</a>",
          "description": "We study sensor/agent data collection and collaboration policies for\nparameter estimation, accounting for resource constraints and correlation\nbetween observations collected by distinct sensors/agents. Specifically, we\nconsider a group of sensors/agents each samples from different variables of a\nmultivariate Gaussian distribution and has different estimation objectives, and\nwe formulate a sensor/agent's data collection and collaboration policy design\nproblem as a Fisher information maximization (or Cramer-Rao bound minimization)\nproblem. When the knowledge of correlation between variables is available, we\nanalytically identify two particular scenarios: (1) where the knowledge of the\ncorrelation between samples cannot be leveraged for collaborative estimation\npurposes and (2) where the optimal data collection policy involves investing\nscarce resources to collaboratively sample and transfer information that is not\nof immediate interest and whose statistics are already known, with the sole\ngoal of increasing the confidence on the estimate of the parameter of interest.\nWhen the knowledge of certain correlation is unavailable but collaboration may\nstill be worthwhile, we propose novel ways to apply multi-armed bandit\nalgorithms to learn the optimal data collection and collaboration policy in our\ndistributed parameter estimation problem and demonstrate that the proposed\nalgorithms, DOUBLE-F, DOUBLE-Z, UCB-F, UCB-Z, are effective through\nsimulations.",
          "link": "http://arxiv.org/abs/2307.06442",
          "publishedOn": "2023-07-14T01:03:53.142Z",
          "wordCount": null,
          "title": "On Collaboration in Distributed Parameter Estimation with Resource Constraints. (arXiv:2307.06442v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziru Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuling Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_G/0/1/0/all/0/1\">Guangzhi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hui_P/0/1/0/all/0/1\">Pan Hui</a>",
          "description": "In the era of Internet of Things (IoT), Digital Twin (DT) is envisioned to\nempower various areas as a bridge between physical objects and the digital\nworld. Through virtualization and simulation techniques, multiple functions can\nbe achieved by leveraging computing resources. In this process, Mobile Cloud\nComputing (MCC) and Mobile Edge Computing (MEC) have become two of the key\nfactors to achieve real-time feedback. However, current works only considered\nedge servers or cloud servers in the DT system models. Besides, The models\nignore the DT with not only one data resource. In this paper, we propose a new\nDT system model considering a heterogeneous MEC/MCC environment. Each DT in the\nmodel is maintained in one of the servers via multiple data collection devices.\nThe offloading decision-making problem is also considered and a new offloading\nscheme is proposed based on Distributed Deep Learning (DDL). Simulation results\ndemonstrate that our proposed algorithm can effectively and efficiently\ndecrease the system's average latency and energy consumption. Significant\nimprovement is achieved compared with the baselines under the dynamic\nenvironment of DTs.",
          "link": "http://arxiv.org/abs/2307.05888",
          "publishedOn": "2023-07-14T01:03:53.142Z",
          "wordCount": null,
          "title": "Efficient Task Offloading Algorithm for Digital Twin in Edge/Cloud Computing Environment. (arXiv:2307.05888v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vekinis_A/0/1/0/all/0/1\">Andrew Alexander Vekinis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perantonis_S/0/1/0/all/0/1\">Stavros Perantonis</a>",
          "description": "Heading towards navigational autonomy in unmanned surface vehicles (USVs) in\nthe maritime sector can fundamentally lead towards safer waters as well as\nreduced operating costs, while also providing a range of exciting new\ncapabilities for oceanic research, exploration and monitoring. However,\nachieving such a goal is challenging. USV control systems must, safely and\nreliably, be able to adhere to the international regulations for preventing\ncollisions at sea (COLREGs) in encounters with other vessels as they navigate\nto a given waypoint while being affected by realistic weather conditions,\neither during the day or at night. To deal with the multitude of possible\nscenarios, it is critical to have a virtual environment that is able to\nreplicate the realistic operating conditions USVs will encounter, before they\ncan be implemented in the real world. Such \"digital twins\" form the foundations\nupon which Deep Reinforcement Learning (DRL) and Computer Vision (CV)\nalgorithms can be used to develop and guide USV control systems. In this paper\nwe describe the novel development of a COLREG-compliant DRL-based collision\navoidant navigational system with CV-based awareness in a realistic ocean\nsimulation environment. The performance of the trained autonomous Agents\nresulting from this approach is evaluated in several successful navigations to\nset waypoints in both open sea and coastal encounters with other vessels. A\nbinary executable version of the simulator with trained agents is available at\nhttps://github.com/aavek/Aeolus-Ocean",
          "link": "http://arxiv.org/abs/2307.06688",
          "publishedOn": "2023-07-14T01:03:53.141Z",
          "wordCount": null,
          "title": "Aeolus Ocean -- A simulation environment for the autonomous COLREG-compliant navigation of Unmanned Surface Vehicles using Deep Reinforcement Learning and Maritime Object Detection. (arXiv:2307.06688v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.14905",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xiaojuan Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Song-Chun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yitao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Muhan Zhang</a>",
          "description": "Knowledge graph (KG) reasoning is an important problem for knowledge graphs.\nIn this paper, we propose a novel and principled framework called \\textbf{RulE}\n(stands for {Rul}e {E}mbedding) to effectively leverage logical rules to\nenhance KG reasoning. Unlike knowledge graph embedding (KGE) methods, RulE\nlearns rule embeddings from existing triplets and first-order {rules} by\njointly representing \\textbf{entities}, \\textbf{relations} and \\textbf{logical\nrules} in a unified embedding space. Based on the learned rule embeddings, a\nconfidence score can be calculated for each rule, reflecting its consistency\nwith the observed triplets. This allows us to perform logical rule inference in\na soft way, thus alleviating the brittleness of logic. On the other hand, RulE\ninjects prior logical rule information into the embedding space, enriching and\nregularizing the entity/relation embeddings. This makes KGE alone perform\nbetter too. RulE is conceptually simple and empirically effective. We conduct\nextensive experiments to verify each component of RulE. Results on multiple\nbenchmarks reveal that our model outperforms the majority of existing\nembedding-based and rule-based approaches.",
          "link": "http://arxiv.org/abs/2210.14905",
          "publishedOn": "2023-07-14T01:03:53.141Z",
          "wordCount": null,
          "title": "RulE: Neural-Symbolic Knowledge Graph Reasoning with Rule Embedding. (arXiv:2210.14905v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.08128",
          "author": "<a href=\"http://arxiv.org/find/hep-ph/1/au:+Buhmann_E/0/1/0/all/0/1\">Erik Buhmann</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Kasieczka_G/0/1/0/all/0/1\">Gregor Kasieczka</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Thaler_J/0/1/0/all/0/1\">Jesse Thaler</a>",
          "description": "With the vast data-collecting capabilities of current and future high-energy\ncollider experiments, there is an increasing demand for computationally\nefficient simulations. Generative machine learning models enable fast event\ngeneration, yet so far these approaches are largely constrained to fixed data\nstructures and rigid detector geometries. In this paper, we introduce EPiC-GAN\n- equivariant point cloud generative adversarial network - which can produce\npoint clouds of variable multiplicity. This flexible framework is based on deep\nsets and is well suited for simulating sprays of particles called jets. The\ngenerator and discriminator utilize multiple EPiC layers with an interpretable\nglobal latent vector. Crucially, the EPiC layers do not rely on pairwise\ninformation sharing between particles, which leads to a significant speed-up\nover graph- and transformer-based approaches with more complex relation\ndiagrams. We demonstrate that EPiC-GAN scales well to large particle\nmultiplicities and achieves high generation fidelity on benchmark jet\ngeneration tasks.",
          "link": "http://arxiv.org/abs/2301.08128",
          "publishedOn": "2023-07-14T01:03:53.140Z",
          "wordCount": 720,
          "title": "EPiC-GAN: Equivariant Point Cloud Generation for Particle Jets. (arXiv:2301.08128v3 [hep-ph] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.00482",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tong_A/0/1/0/all/0/1\">Alexander Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malkin_N/0/1/0/all/0/1\">Nikolay Malkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huguet_G/0/1/0/all/0/1\">Guillaume Huguet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yanlei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rector_Brooks_J/0/1/0/all/0/1\">Jarrid Rector-Brooks</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fatras_K/0/1/0/all/0/1\">Kilian Fatras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_G/0/1/0/all/0/1\">Guy Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>",
          "description": "Continuous normalizing flows (CNFs) are an attractive generative modeling\ntechnique, but they have been held back by limitations in their\nsimulation-based maximum likelihood training. We introduce the generalized\nconditional flow matching (CFM) technique, a family of simulation-free training\nobjectives for CNFs. CFM features a stable regression objective like that used\nto train the stochastic flow in diffusion models but enjoys the efficient\ninference of deterministic flow models. In contrast to both diffusion models\nand prior CNF training algorithms, CFM does not require the source distribution\nto be Gaussian or require evaluation of its density. A variant of our objective\nis optimal transport CFM (OT-CFM), which creates simpler flows that are more\nstable to train and lead to faster inference, as evaluated in our experiments.\nFurthermore, OT-CFM is the first method to compute dynamic OT in a\nsimulation-free way. Training CNFs with CFM improves results on a variety of\nconditional and unconditional generation tasks, such as inferring single cell\ndynamics, unsupervised image translation, and Schr\\\"odinger bridge inference.",
          "link": "http://arxiv.org/abs/2302.00482",
          "publishedOn": "2023-07-14T01:03:53.135Z",
          "wordCount": 734,
          "title": "Improving and generalizing flow-based generative models with minibatch optimal transport. (arXiv:2302.00482v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2106.06613",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Treutlein_J/0/1/0/all/0/1\">Johannes Treutlein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dennis_M/0/1/0/all/0/1\">Michael Dennis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oesterheld_C/0/1/0/all/0/1\">Caspar Oesterheld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foerster_J/0/1/0/all/0/1\">Jakob Foerster</a>",
          "description": "In many coordination problems, independently reasoning humans are able to\ndiscover mutually compatible policies. In contrast, independently trained\nself-play policies are often mutually incompatible. Zero-shot coordination\n(ZSC) has recently been proposed as a new frontier in multi-agent reinforcement\nlearning to address this fundamental issue. Prior work approaches the ZSC\nproblem by assuming players can agree on a shared learning algorithm but not on\nlabels for actions and observations, and proposes other-play as an optimal\nsolution. However, until now, this \"label-free\" problem has only been\ninformally defined. We formalize this setting as the label-free coordination\n(LFC) problem by defining the label-free coordination game. We show that\nother-play is not an optimal solution to the LFC problem as it fails to\nconsistently break ties between incompatible maximizers of the other-play\nobjective. We introduce an extension of the algorithm, other-play with\ntie-breaking, and prove that it is optimal in the LFC problem and an\nequilibrium in the LFC game. Since arbitrary tie-breaking is precisely what the\nZSC setting aims to prevent, we conclude that the LFC problem does not reflect\nthe aims of ZSC. To address this, we introduce an alternative informal\noperationalization of ZSC as a starting point for future work.",
          "link": "http://arxiv.org/abs/2106.06613",
          "publishedOn": "2023-07-14T01:03:53.129Z",
          "wordCount": 745,
          "title": "A New Formalism, Method and Open Issues for Zero-Shot Coordination. (arXiv:2106.06613v3 [cs.AI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2207.11290",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhaskhar_N/0/1/0/all/0/1\">Nandita Bhaskhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel L. Rubin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Messer_C/0/1/0/all/0/1\">Christopher Lee-Messer</a>",
          "description": "Continuous monitoring of trained ML models to determine when their\npredictions should and should not be trusted is essential for their safe\ndeployment. Such a framework ought to be high-performing, explainable, post-hoc\nand actionable. We propose TRUST-LAPSE, a \"mistrust\" scoring framework for\ncontinuous model monitoring. We assess the trustworthiness of each input\nsample's model prediction using a sequence of latent-space embeddings.\nSpecifically, (a) our latent-space mistrust score estimates mistrust using\ndistance metrics (Mahalanobis distance) and similarity metrics (cosine\nsimilarity) in the latent-space and (b) our sequential mistrust score\ndetermines deviations in correlations over the sequence of past input\nrepresentations in a non-parametric, sliding-window based algorithm for\nactionable continuous monitoring. We evaluate TRUST-LAPSE via two downstream\ntasks: (1) distributionally shifted input detection, and (2) data drift\ndetection. We evaluate across diverse domains - audio and vision using public\ndatasets and further benchmark our approach on challenging, real-world\nelectroencephalograms (EEG) datasets for seizure detection. Our latent-space\nmistrust scores achieve state-of-the-art results with AUROCs of 84.1 (vision),\n73.9 (audio), and 77.1 (clinical EEGs), outperforming baselines by over 10\npoints. We expose critical failures in popular baselines that remain\ninsensitive to input semantic content, rendering them unfit for real-world\nmodel monitoring. We show that our sequential mistrust scores achieve high\ndrift detection rates; over 90% of the streams show < 20% error for all\ndomains. Through extensive qualitative and quantitative evaluations, we show\nthat our mistrust scores are more robust and provide explainability for easy\nadoption into practice.",
          "link": "http://arxiv.org/abs/2207.11290",
          "publishedOn": "2023-07-14T01:03:53.124Z",
          "wordCount": 814,
          "title": "TRUST-LAPSE: An Explainable and Actionable Mistrust Scoring Framework for Model Monitoring. (arXiv:2207.11290v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.03044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenzhe Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Hao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zichuan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chongjie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zongqing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_D/0/1/0/all/0/1\">Deheng Ye</a>",
          "description": "Transformer has been considered the dominating neural architecture in NLP and\nCV, mostly under supervised settings. Recently, a similar surge of using\nTransformers has appeared in the domain of reinforcement learning (RL), but it\nis faced with unique design choices and challenges brought by the nature of RL.\nHowever, the evolution of Transformers in RL has not yet been well unraveled.\nIn this paper, we seek to systematically review motivations and progress on\nusing Transformers in RL, provide a taxonomy on existing works, discuss each\nsub-field, and summarize future prospects.",
          "link": "http://arxiv.org/abs/2301.03044",
          "publishedOn": "2023-07-14T01:03:53.114Z",
          "wordCount": null,
          "title": "A Survey on Transformers in Reinforcement Learning. (arXiv:2301.03044v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.00268",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1\">Md Tamjid Hossain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+La_H/0/1/0/all/0/1\">Hung La</a>",
          "description": "Lately, differential privacy (DP) has been introduced in cooperative\nmultiagent reinforcement learning (CMARL) to safeguard the agents' privacy\nagainst adversarial inference during knowledge sharing. Nevertheless, we argue\nthat the noise introduced by DP mechanisms may inadvertently give rise to a\nnovel poisoning threat, specifically in the context of private knowledge\nsharing during CMARL, which remains unexplored in the literature. To address\nthis shortcoming, we present an adaptive, privacy-exploiting, and\nevasion-resilient localized poisoning attack (PeLPA) that capitalizes on the\ninherent DP-noise to circumvent anomaly detection systems and hinder the\noptimal convergence of the CMARL model. We rigorously evaluate our proposed\nPeLPA attack in diverse environments, encompassing both non-adversarial and\nmultiple-adversarial contexts. Our findings reveal that, in a medium-scale\nenvironment, the PeLPA attack with attacker ratios of 20% and 40% can lead to\nan increase in average steps to goal by 50.69% and 64.41%, respectively.\nFurthermore, under similar conditions, PeLPA can result in a 1.4x and 1.6x\ncomputational time increase in optimal reward attainment and a 1.18x and 1.38x\nslower convergence for attacker ratios of 20% and 40%, respectively.",
          "link": "http://arxiv.org/abs/2307.00268",
          "publishedOn": "2023-07-14T01:03:53.111Z",
          "wordCount": null,
          "title": "Hiding in Plain Sight: Differential Privacy Noise Exploitation for Evasion-resilient Localized Poisoning Attacks in Multiagent Reinforcement Learning. (arXiv:2307.00268v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.01856",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shihan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clarke_A/0/1/0/all/0/1\">Alexander Kenneth Clarke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maksymenko_K/0/1/0/all/0/1\">Kostiantyn Maksymenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deslauriers_Gauthier_S/0/1/0/all/0/1\">Samuel Deslauriers-Gauthier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_X/0/1/0/all/0/1\">Xinjun Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiangyang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farina_D/0/1/0/all/0/1\">Dario Farina</a>",
          "description": "Simulations of biophysical systems are fundamental for studying physiological\nmechanisms and developing human machine interfaces. Whilst advanced numerical\nmethods, such as finite element models, can excel in this task, they are\nextremely computationally expensive to use when generating a large number of\nsimulations or simulating dynamic events with continuously changing structural\nparameters. We propose an architecture that uses a conditional generative model\nto interpolate between the numerical model states, dramatically lowering the\nmodeling time while maintaining a high generation accuracy. As a demonstration\nof this concept, we present BioMime, a hybrid-structured generative model that\nenables an accurate, ultra-fast, and arbitrarily high temporal-resolution\nsimulation of a specific biophysical system during dynamic changes. This\nmethodology has wide applications in physiological and clinical research as\nwell as in supporting data augmentation strategies for signal analysis,\nrepresenting a computationally efficient and highly accurate model for\nbiophysical simulations.",
          "link": "http://arxiv.org/abs/2211.01856",
          "publishedOn": "2023-07-14T01:03:53.110Z",
          "wordCount": null,
          "title": "Human Biophysics as Network Weights: Conditional Generative Models for Dynamic Simulation. (arXiv:2211.01856v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.00422",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cacciarelli_D/0/1/0/all/0/1\">Davide Cacciarelli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kulahci_M/0/1/0/all/0/1\">Murat Kulahci</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tyssedal_J/0/1/0/all/0/1\">John S&#xf8;lve Tyssedal</a>",
          "description": "In many industrial applications, obtaining labeled observations is not\nstraightforward as it often requires the intervention of human experts or the\nuse of expensive testing equipment. In these circumstances, active learning can\nbe highly beneficial in suggesting the most informative data points to be used\nwhen fitting a model. Reducing the number of observations needed for model\ndevelopment alleviates both the computational burden required for training and\nthe operational expenses related to labeling. Online active learning, in\nparticular, is useful in high-volume production processes where the decision\nabout the acquisition of the label for a data point needs to be taken within an\nextremely short time frame. However, despite the recent efforts to develop\nonline active learning strategies, the behavior of these methods in the\npresence of outliers has not been thoroughly examined. In this work, we\ninvestigate the performance of online active linear regression in contaminated\ndata streams. Our study shows that the currently available query strategies are\nprone to sample outliers, whose inclusion in the training set eventually\ndegrades the predictive performance of the models. To address this issue, we\npropose a solution that bounds the search area of a conditional D-optimal\nalgorithm and uses a robust estimator. Our approach strikes a balance between\nexploring unseen regions of the input space and protecting against outliers.\nThrough numerical simulations, we show that the proposed method is effective in\nimproving the performance of online active learning in the presence of\noutliers, thus expanding the potential applications of this powerful tool.",
          "link": "http://arxiv.org/abs/2302.00422",
          "publishedOn": "2023-07-14T01:03:53.110Z",
          "wordCount": null,
          "title": "Robust online active learning. (arXiv:2302.00422v5 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.06887",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Guneyi_E/0/1/0/all/0/1\">Eylem Tugce Guneyi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yaldiz_B/0/1/0/all/0/1\">Berkay Yaldiz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Canbolat_A/0/1/0/all/0/1\">Abdullah Canbolat</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vural_E/0/1/0/all/0/1\">Elif Vural</a>",
          "description": "The modeling of time-varying graph signals as stationary time-vertex\nstochastic processes permits the inference of missing signal values by\nefficiently employing the correlation patterns of the process across different\ngraph nodes and time instants. In this study, we propose an algorithm for\ncomputing graph autoregressive moving average (graph ARMA) processes based on\nlearning the joint time-vertex power spectral density of the process from its\nincomplete realizations for the task of signal interpolation. Our solution\nrelies on first roughly estimating the joint spectrum of the process from\npartially observed realizations and then refining this estimate by projecting\nit onto the spectrum manifold of the graph ARMA process through convex\nrelaxations. The initially missing signal values are then estimated based on\nthe learnt model. Experimental results show that the proposed approach achieves\nhigh accuracy in time-vertex signal estimation problems.",
          "link": "http://arxiv.org/abs/2302.06887",
          "publishedOn": "2023-07-14T01:03:53.109Z",
          "wordCount": null,
          "title": "Learning Graph ARMA Processes from Time-Vertex Spectra. (arXiv:2302.06887v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.03570",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_P/0/1/0/all/0/1\">Peng Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_G/0/1/0/all/0/1\">Guodong Long</a>",
          "description": "Personalized federated learning (PFL) jointly trains a variety of local\nmodels through balancing between knowledge sharing across clients and model\npersonalization per client. This paper addresses PFL via explicit disentangling\nlatent representations into two parts to capture the shared knowledge and\nclient-specific personalization, which leads to more reliable and effective\nPFL. The disentanglement is achieved by a novel Federated Dual Variational\nAutoencoder (FedDVA), which employs two encoders to infer the two types of\nrepresentations. FedDVA can produce a better understanding of the trade-off\nbetween global knowledge sharing and local personalization in PFL. Moreover, it\ncan be integrated with existing FL methods and turn them into personalized\nmodels for heterogeneous downstream tasks. Extensive experiments validate the\nadvantages caused by disentanglement and show that models trained with\ndisentangled representations substantially outperform those vanilla methods.",
          "link": "http://arxiv.org/abs/2306.03570",
          "publishedOn": "2023-07-14T01:03:53.109Z",
          "wordCount": null,
          "title": "Personalization Disentanglement for Federated Learning: An explainable perspective. (arXiv:2306.03570v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15639",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1\">Dai Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1\">Zhiqi Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qibin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Junbin Gao</a>",
          "description": "This paper presents a comprehensive theoretical analysis of the graph\np-Laplacian regularized framelet network (pL-UFG) to establish a solid\nunderstanding of its properties. We conduct a convergence analysis on pL-UFG,\naddressing the gap in the understanding of its asymptotic behaviors. Further by\ninvestigating the generalized Dirichlet energy of pL-UFG, we demonstrate that\nthe Dirichlet energy remains non-zero throughout convergence, ensuring the\navoidance of over-smoothing issues. Additionally, we elucidate the energy\ndynamic perspective, highlighting the synergistic relationship between the\nimplicit layer in pL-UFG and graph framelets. This synergy enhances the model's\nadaptability to both homophilic and heterophilic data. Notably, we reveal that\npL-UFG can be interpreted as a generalized non-linear diffusion process,\nthereby bridging the gap between pL-UFG and differential equations on the\ngraph. Importantly, these multifaceted analyses lead to unified conclusions\nthat offer novel insights for understanding and implementing pL-UFG, as well as\nother graph neural network (GNN) models. Finally, based on our dynamic\nanalysis, we propose two novel pL-UFG models with manually controlled energy\ndynamics. We demonstrate empirically and theoretically that our proposed models\nnot only inherit the advantages of pL-UFG but also significantly reduce\ncomputational costs for training on large-scale graph datasets.",
          "link": "http://arxiv.org/abs/2305.15639",
          "publishedOn": "2023-07-14T01:03:53.108Z",
          "wordCount": null,
          "title": "Revisiting Generalized p-Laplacian Regularized Framelet GCNs: Convergence, Energy Dynamic and Training with Non-Linear Diffusion. (arXiv:2305.15639v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.00241",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tony T. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gleave_A/0/1/0/all/0/1\">Adam Gleave</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tseng_T/0/1/0/all/0/1\">Tom Tseng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pelrine_K/0/1/0/all/0/1\">Kellin Pelrine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belrose_N/0/1/0/all/0/1\">Nora Belrose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1\">Joseph Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dennis_M/0/1/0/all/0/1\">Michael D. Dennis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1\">Yawen Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pogrebniak_V/0/1/0/all/0/1\">Viktor Pogrebniak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russell_S/0/1/0/all/0/1\">Stuart Russell</a>",
          "description": "We attack the state-of-the-art Go-playing AI system KataGo by training\nadversarial policies against it, achieving a >97% win rate against KataGo\nrunning at superhuman settings. Our adversaries do not win by playing Go well.\nInstead, they trick KataGo into making serious blunders. Our attack transfers\nzero-shot to other superhuman Go-playing AIs, and is comprehensible to the\nextent that human experts can implement it without algorithmic assistance to\nconsistently beat superhuman AIs. The core vulnerability uncovered by our\nattack persists even in KataGo agents adversarially trained to defend against\nour attack. Our results demonstrate that even superhuman AI systems may harbor\nsurprising failure modes. Example games are available https://goattack.far.ai/.",
          "link": "http://arxiv.org/abs/2211.00241",
          "publishedOn": "2023-07-14T01:03:53.107Z",
          "wordCount": null,
          "title": "Adversarial Policies Beat Superhuman Go AIs. (arXiv:2211.00241v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.11873",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Elsemuller_L/0/1/0/all/0/1\">Lasse Elsem&#xfc;ller</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schnuerch_M/0/1/0/all/0/1\">Martin Schnuerch</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Burkner_P/0/1/0/all/0/1\">Paul-Christian B&#xfc;rkner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Radev_S/0/1/0/all/0/1\">Stefan T. Radev</a>",
          "description": "Bayesian model comparison (BMC) offers a principled approach for assessing\nthe relative merits of competing computational models and propagating\nuncertainty into model selection decisions. However, BMC is often intractable\nfor the popular class of hierarchical models due to their high-dimensional\nnested parameter structure. To address this intractability, we propose a deep\nlearning method for performing BMC on any set of hierarchical models which can\nbe instantiated as probabilistic programs. Since our method enables amortized\ninference, it allows efficient re-estimation of posterior model probabilities\nand fast performance validation prior to any real-data application. In a series\nof extensive validation studies, we benchmark the performance of our method\nagainst the state-of-the-art bridge sampling method and demonstrate excellent\namortized inference across all BMC settings. We then showcase our method by\ncomparing four hierarchical evidence accumulation models that have previously\nbeen deemed intractable for BMC due to partly implicit likelihoods. In this\napplication, we corroborate evidence for the recently proposed L\\'evy flight\nmodel of decision-making and show how transfer learning can be leveraged to\nenhance training efficiency. We provide reproducible code for all analyses and\nan open-source implementation of our method.",
          "link": "http://arxiv.org/abs/2301.11873",
          "publishedOn": "2023-07-14T01:03:53.107Z",
          "wordCount": null,
          "title": "A Deep Learning Method for Comparing Bayesian Hierarchical Models. (arXiv:2301.11873v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.10741",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Baum_J/0/1/0/all/0/1\">Jerome Baum</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kanagawa_H/0/1/0/all/0/1\">Heishiro Kanagawa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1\">Arthur Gretton</a>",
          "description": "We propose a goodness-of-fit measure for probability densities modeling\nobservations with varying dimensionality, such as text documents of differing\nlengths or variable-length sequences. The proposed measure is an instance of\nthe kernel Stein discrepancy (KSD), which has been used to construct\ngoodness-of-fit tests for unnormalized densities. The KSD is defined by its\nStein operator: current operators used in testing apply to fixed-dimensional\nspaces. As our main contribution, we extend the KSD to the variable-dimension\nsetting by identifying appropriate Stein operators, and propose a novel KSD\ngoodness-of-fit test. As with the previous variants, the proposed KSD does not\nrequire the density to be normalized, allowing the evaluation of a large class\nof models. Our test is shown to perform well in practice on discrete sequential\ndata benchmarks.",
          "link": "http://arxiv.org/abs/2210.10741",
          "publishedOn": "2023-07-14T01:03:53.106Z",
          "wordCount": null,
          "title": "A kernel Stein test of goodness of fit for sequential models. (arXiv:2210.10741v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.00858",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Dong_Z/0/1/0/all/0/1\">Zijian Dong</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wu_Y/0/1/0/all/0/1\">Yilei Wu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Xiao_Y/0/1/0/all/0/1\">Yu Xiao</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chong_J/0/1/0/all/0/1\">Joanna Su Xian Chong</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Jin_Y/0/1/0/all/0/1\">Yueming Jin</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhou_J/0/1/0/all/0/1\">Juan Helen Zhou</a>",
          "description": "Under the framework of network-based neurodegeneration, brain functional\nconnectome (FC)-based Graph Neural Networks (GNN) have emerged as a valuable\ntool for the diagnosis and prognosis of neurodegenerative diseases such as\nAlzheimer's disease (AD). However, these models are tailored for brain FC at a\nsingle time point instead of characterizing FC trajectory. Discerning how FC\nevolves with disease progression, particularly at the predementia stages such\nas cognitively normal individuals with amyloid deposition or individuals with\nmild cognitive impairment (MCI), is crucial for delineating disease spreading\npatterns and developing effective strategies to slow down or even halt disease\nadvancement. In this work, we proposed the first interpretable framework for\nbrain FC trajectory embedding with application to neurodegenerative disease\ndiagnosis and prognosis, namely Brain Tokenized Graph Transformer (Brain\nTokenGT). It consists of two modules: 1) Graph Invariant and Variant Embedding\n(GIVE) for generation of node and spatio-temporal edge embeddings, which were\ntokenized for downstream processing; 2) Brain Informed Graph Transformer\nReadout (BIGTR) which augments previous tokens with trainable type identifiers\nand non-trainable node identifiers and feeds them into a standard transformer\nencoder to readout. We conducted extensive experiments on two public\nlongitudinal fMRI datasets of the AD continuum for three tasks, including\ndifferentiating MCI from controls, predicting dementia conversion in MCI, and\nclassification of amyloid positive or negative cognitively normal individuals.\nBased on brain FC trajectory, the proposed Brain TokenGT approach outperformed\nall the other benchmark models and at the same time provided excellent\ninterpretability. The code is available at\nhttps://github.com/ZijianD/Brain-TokenGT.git",
          "link": "http://arxiv.org/abs/2307.00858",
          "publishedOn": "2023-07-14T01:03:53.106Z",
          "wordCount": null,
          "title": "Beyond the Snapshot: Brain Tokenized Graph Transformer for Longitudinal Brain Functional Connectome Embedding. (arXiv:2307.00858v2 [q-bio.NC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.07804",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhen Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peiqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Shangdi Yu</a>",
          "description": "Large Language Models (LLMs) have made remarkable advancements in the field\nof natural language processing. However, their increasing size poses challenges\nin terms of computational cost. On the other hand, Small Language Models (SLMs)\nare known for their efficiency, but they often struggle with limited capacity\nand training data, especially in specific domains. In this paper, we introduce\na novel method aimed at improving SLMs in the medical domain using LLM-based\ngenerative data augmentation. The objective of our approach is to develop more\nefficient and capable models that are specifically tailored for specialized\napplications. Through experiments conducted on the PubMedQA dataset, we\ndemonstrate the effectiveness of LLMs in refining and diversifying existing\nquestion-answer pairs. This refinement process leads to improved performance in\na significantly smaller model after fine-tuning. Notably, our best SLM, with\nunder 1.6 billion parameters, outperforms the few-shot GPT-4 on the PubMedQA\ndataset. Our code and generated data are publicly available to facilitate\nfurther explorations.",
          "link": "http://arxiv.org/abs/2305.07804",
          "publishedOn": "2023-07-14T01:03:53.105Z",
          "wordCount": null,
          "title": "Improving Small Language Models on PubMedQA via Generative Data Augmentation. (arXiv:2305.07804v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06945",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1\">Tao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jing Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Si-Qing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>",
          "description": "We propose the In-context Autoencoder (ICAE) for context compression in a\nlarge language model (LLM). The ICAE has two modules: a learnable encoder\nadapted with LoRA from an LLM for compressing a long context into a limited\nnumber of memory slots, and a fixed decoder which is the target LLM that can\ncondition on the memory slots for various purposes. We first pretrain the ICAE\nusing both autoencoding and language modeling objectives on massive text data,\nenabling it to generate memory slots that accurately and comprehensively\nrepresent the original context. Then, we fine-tune the pretrained ICAE on a\nsmall amount of instruct data to enhance its interaction with various prompts\nfor producing desirable responses. Our experimental results demonstrate that\nthe ICAE learned with our proposed pretraining and fine-tuning paradigm can\neffectively produce memory slots with $4\\times$ context compression, which can\nbe well conditioned on by the target LLM to respond to various prompts. The\npromising results demonstrate significant implications of the ICAE for its\nnovel approach to the long context problem and its potential to reduce\ncomputation and memory overheads for LLM inference in practice, suggesting\nfurther research effort in context management for an LLM. Our code and data\nwill be released shortly.",
          "link": "http://arxiv.org/abs/2307.06945",
          "publishedOn": "2023-07-14T01:03:53.104Z",
          "wordCount": null,
          "title": "In-context Autoencoder for Context Compression in a Large Language Model. (arXiv:2307.06945v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.12811",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Takida_Y/0/1/0/all/0/1\">Yuhta Takida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imaizumi_M/0/1/0/all/0/1\">Masaaki Imaizumi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shibuya_T/0/1/0/all/0/1\">Takashi Shibuya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1\">Chieh-Hsin Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uesaka_T/0/1/0/all/0/1\">Toshimitsu Uesaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murata_N/0/1/0/all/0/1\">Naoki Murata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitsufuji_Y/0/1/0/all/0/1\">Yuki Mitsufuji</a>",
          "description": "Generative adversarial networks (GANs) learn a target probability\ndistribution by optimizing a generator and a discriminator with minimax\nobjectives. This paper addresses the question of whether such optimization\nactually provides the generator with gradients that make its distribution close\nto the target distribution. We derive metrizable conditions, sufficient\nconditions for the discriminator to serve as the distance between the\ndistributions by connecting the GAN formulation with the concept of sliced\noptimal transport. Furthermore, by leveraging these theoretical results, we\npropose a novel GAN training scheme, called slicing adversarial network (SAN).\nWith only simple modifications, a broad class of existing GANs can be converted\nto SANs. Experiments on synthetic and image datasets support our theoretical\nresults and the SAN's effectiveness as compared to usual GANs. Furthermore, we\nalso apply SAN to StyleGAN-XL, which leads to state-of-the-art FID score\namongst GANs for class conditional generation on ImageNet 256$\\times$256.",
          "link": "http://arxiv.org/abs/2301.12811",
          "publishedOn": "2023-07-14T01:03:53.104Z",
          "wordCount": null,
          "title": "SAN: Inducing Metrizability of GAN with Discriminative Normalized Linear Layer. (arXiv:2301.12811v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.11986",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Savic_M/0/1/0/all/0/1\">Milo&#x161; Savi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurbalija_V/0/1/0/all/0/1\">Vladimir Kurbalija</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radovanovic_M/0/1/0/all/0/1\">Milo&#x161; Radovanovi&#x107;</a>",
          "description": "The notion of local intrinsic dimensionality (LID) is an important\nadvancement in data dimensionality analysis, with applications in data mining,\nmachine learning and similarity search problems. Existing distance-based LID\nestimators were designed for tabular datasets encompassing data points\nrepresented as vectors in a Euclidean space. After discussing their limitations\nfor graph-structured data considering graph embeddings and graph distances, we\npropose NC-LID, a novel LID-related measure for quantifying the discriminatory\npower of the shortest-path distance with respect to natural communities of\nnodes as their intrinsic localities. It is shown how this measure can be used\nto design LID-aware graph embedding algorithms by formulating two LID-elastic\nvariants of node2vec with personalized hyperparameters that are adjusted\naccording to NC-LID values. Our empirical analysis of NC-LID on a large number\nof real-world graphs shows that this measure is able to point to nodes with\nhigh link reconstruction errors in node2vec embeddings better than node\ncentrality metrics. The experimental evaluation also shows that the proposed\nLID-elastic node2vec extensions improve node2vec by better preserving graph\nstructure in generated embeddings.",
          "link": "http://arxiv.org/abs/2208.11986",
          "publishedOn": "2023-07-14T01:03:53.102Z",
          "wordCount": null,
          "title": "Local Intrinsic Dimensionality Measures for Graphs, with Applications to Graph Embeddings. (arXiv:2208.11986v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.08440",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beucler_T/0/1/0/all/0/1\">Tom Beucler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gentine_P/0/1/0/all/0/1\">Pierre Gentine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuval_J/0/1/0/all/0/1\">Janni Yuval</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Ankitesh Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_L/0/1/0/all/0/1\">Liran Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jerry Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Sungduk Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rasp_S/0/1/0/all/0/1\">Stephan Rasp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_F/0/1/0/all/0/1\">Fiaz Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+OGorman_P/0/1/0/all/0/1\">Paul A. O&#x27;Gorman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neelin_J/0/1/0/all/0/1\">J. David Neelin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lutsko_N/0/1/0/all/0/1\">Nicholas J. Lutsko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pritchard_M/0/1/0/all/0/1\">Michael Pritchard</a>",
          "description": "Projecting climate change is a generalization problem: we extrapolate the\nrecent past using physical models across past, present, and future climates.\nCurrent climate models require representations of processes that occur at\nscales smaller than model grid size, which have been the main source of model\nprojection uncertainty. Recent machine learning (ML) algorithms hold promise to\nimprove such process representations, but tend to extrapolate poorly to climate\nregimes they were not trained on. To get the best of the physical and\nstatistical worlds, we propose a new framework -- termed \"climate-invariant\" ML\n-- incorporating knowledge of climate processes into ML algorithms, and show\nthat it can maintain high accuracy across a wide range of climate and\ngeographic conditions in three distinct atmospheric models. Our results suggest\nthat explicitly incorporating physical knowledge into data-driven models of\nEarth system processes can improve their consistency, data efficiency, and\ngeneralizability across climate regimes.",
          "link": "http://arxiv.org/abs/2112.08440",
          "publishedOn": "2023-07-14T01:03:53.100Z",
          "wordCount": null,
          "title": "Climate-Invariant Machine Learning. (arXiv:2112.08440v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1\">Jun Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Ji-Qian Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jing-Qi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_A/0/1/0/all/0/1\">An-Bao Xu</a>",
          "description": "In this paper, we consider the network latency estimation, which has been an\nimportant metric for network performance. However, a large scale of network\nlatency estimation requires a lot of computing time. Therefore, we propose a\nnew method that is much faster and maintains high accuracy. The data structure\nof network nodes can form a matrix, and the tensor model can be formed by\nintroducing the time dimension. Thus, the entire problem can be be summarized\nas a tensor completion problem. The main idea of our method is improving the\ntensor leverage sampling strategy and introduce tensor QR decomposition into\ntensor completion. To achieve faster tensor leverage sampling, we replace\ntensor singular decomposition (t-SVD) with tensor CSVD-QR to appoximate t-SVD.\nTo achieve faster completion for incomplete tensor, we use the tensor\n$L_{2,1}$-norm rather than traditional tensor nuclear norm. Furthermore, we\nintroduce tensor QR decomposition into alternating direction method of\nmultipliers (ADMM) framework. Numerical experiments witness that our method is\nfaster than state-of-art algorithms with satisfactory accuracy.",
          "link": "http://arxiv.org/abs/2307.06848",
          "publishedOn": "2023-07-14T01:03:53.098Z",
          "wordCount": null,
          "title": "Tensor Completion via Leverage Sampling and Tensor QR Decomposition for Network Latency Estimation. (arXiv:2307.06848v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.06392",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Khan_S/0/1/0/all/0/1\">Saud Khan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Durrani_S/0/1/0/all/0/1\">Salman Durrani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shahab_M/0/1/0/all/0/1\">Muhammad Basit Shahab</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Johnson_S/0/1/0/all/0/1\">Sarah J. Johnson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Camtepe_S/0/1/0/all/0/1\">Seyit Camtepe</a>",
          "description": "We consider the multi-user detection (MUD) problem in uplink grant-free\nnon-orthogonal multiple access (NOMA), where the access point has to identify\nthe total number and correct identity of the active Internet of Things (IoT)\ndevices and decode their transmitted data. We assume that IoT devices use\ncomplex spreading sequences and transmit information in a random-access manner\nfollowing the burst-sparsity model, where some IoT devices transmit their data\nin multiple adjacent time slots with a high probability, while others transmit\nonly once during a frame. Exploiting the temporal correlation, we propose an\nattention-based bidirectional long short-term memory (BiLSTM) network to solve\nthe MUD problem. The BiLSTM network creates a pattern of the device activation\nhistory using forward and reverse pass LSTMs, whereas the attention mechanism\nprovides essential context to the device activation points. By doing so, a\nhierarchical pathway is followed for detecting active devices in a grant-free\nscenario. Then, by utilising the complex spreading sequences, blind data\ndetection for the estimated active devices is performed. The proposed framework\ndoes not require prior knowledge of device sparsity levels and channels for\nperforming MUD. The results show that the proposed network achieves better\nperformance compared to existing benchmark schemes.",
          "link": "http://arxiv.org/abs/2209.06392",
          "publishedOn": "2023-07-14T01:03:53.097Z",
          "wordCount": null,
          "title": "Joint User and Data Detection in Grant-Free NOMA with Attention-based BiLSTM Network. (arXiv:2209.06392v2 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.10369",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deutel_M/0/1/0/all/0/1\">Mark Deutel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woller_P/0/1/0/all/0/1\">Philipp Woller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mutschler_C/0/1/0/all/0/1\">Christopher Mutschler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teich_J/0/1/0/all/0/1\">J&#xfc;rgen Teich</a>",
          "description": "Large Deep Neural Networks (DNNs) are the backbone of today's artificial\nintelligence due to their ability to make accurate predictions when being\ntrained on huge datasets. With advancing technologies, such as the Internet of\nThings, interpreting large quantities of data generated by sensors is becoming\nan increasingly important task. However, in many applications not only the\npredictive performance but also the energy consumption of deep learning models\nis of major interest. This paper investigates the efficient deployment of deep\nlearning models on resource-constrained microcontroller architectures via\nnetwork compression. We present a methodology for the systematic exploration of\ndifferent DNN pruning, quantization, and deployment strategies, targeting\ndifferent ARM Cortex-M based low-power systems. The exploration allows to\nanalyze trade-offs between key metrics such as accuracy, memory consumption,\nexecution time, and power consumption. We discuss experimental results on three\ndifferent DNN architectures and show that we can compress them to below 10\\% of\ntheir original parameter count before their predictive quality decreases. This\nalso allows us to deploy and evaluate them on Cortex-M based microcontrollers.",
          "link": "http://arxiv.org/abs/2205.10369",
          "publishedOn": "2023-07-14T01:03:53.096Z",
          "wordCount": null,
          "title": "Energy-efficient Deployment of Deep Learning Applications on Cortex-M based Microcontrollers using Deep Compression. (arXiv:2205.10369v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.15092",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1\">Zhiqi Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_A/0/1/0/all/0/1\">Andi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1\">Dai Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasnev_A/0/1/0/all/0/1\">Andrey Vasnev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Junbin Gao</a>",
          "description": "This paper introduces a novel Framelet Graph approach based on p-Laplacian\nGNN. The proposed two models, named p-Laplacian undecimated framelet graph\nconvolution (pL-UFG) and generalized p-Laplacian undecimated framelet graph\nconvolution (pL-fUFG) inherit the nature of p-Laplacian with the expressive\npower of multi-resolution decomposition of graph signals. The empirical study\nhighlights the excellent performance of the pL-UFG and pL-fUFG in different\ngraph learning tasks including node classification and signal denoising.",
          "link": "http://arxiv.org/abs/2210.15092",
          "publishedOn": "2023-07-14T01:03:53.094Z",
          "wordCount": null,
          "title": "Generalized Laplacian Regularized Framelet Graph Neural Networks. (arXiv:2210.15092v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1912.13122",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garcia_Camino_A/0/1/0/all/0/1\">Andr&#xe9;s Garc&#xed;a-Camino</a>",
          "description": "Regulation of Multi-Agent Systems (MAS) and Declarative Electronic\nInstitutions (DEIs) was a multidisciplinary research topic of the past decade\ninvolving (Physical and Software) Agents and Law since the beginning, but\nrecently evolved towards News-claimed Robot Lawyer since 2016. One of these\nfirst proposals of restricting the behaviour of Software Agentswas Electronic\nInstitutions.However, with the recent reformulation of Artificial Neural\nNetworks (ANNs) as Deep Learning (DL), Security, Privacy,Ethical and Legal\nissues regarding the use of DL has raised concerns in the Artificial\nIntelligence (AI) Community. Now that the Regulation of MAS is almost correctly\naddressed, we propose the Regulation of Artificial Neural Networks as\nAgent-based Training of a special type of regulated Artificial Neural Network\nthat we call Institutional Neural Network (INN).The main purpose of this paper\nis to bring attention to Artificial Teaching (AT) and to give a tentative\nanswer showing a proof-of-concept implementation of Regulated Deep Learning\n(RDL). This paper introduces the former concept and provide sI, a language\npreviously used to model declaratively and extend Electronic Institutions, as a\nmeans to regulate the execution of Artificial Neural Networks and their\ninteractions with Artificial Teachers (ATs)",
          "link": "http://arxiv.org/abs/1912.13122",
          "publishedOn": "2023-07-14T01:03:53.092Z",
          "wordCount": null,
          "title": "Declarative Mechanism Design. (arXiv:1912.13122v4 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.07729",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jinmei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chunlin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_D/0/1/0/all/0/1\">Daoyi Dong</a>",
          "description": "Bayesian policy reuse (BPR) is a general policy transfer framework for\nselecting a source policy from an offline library by inferring the task belief\nbased on some observation signals and a trained observation model. In this\npaper, we propose an improved BPR method to achieve more efficient policy\ntransfer in deep reinforcement learning (DRL). First, most BPR algorithms use\nthe episodic return as the observation signal that contains limited information\nand cannot be obtained until the end of an episode. Instead, we employ the\nstate transition sample, which is informative and instantaneous, as the\nobservation signal for faster and more accurate task inference. Second, BPR\nalgorithms usually require numerous samples to estimate the probability\ndistribution of the tabular-based observation model, which may be expensive and\neven infeasible to learn and maintain, especially when using the state\ntransition sample as the signal. Hence, we propose a scalable observation model\nbased on fitting state transition functions of source tasks from only a small\nnumber of samples, which can generalize to any signals observed in the target\ntask. Moreover, we extend the offline-mode BPR to the continual learning\nsetting by expanding the scalable observation model in a plug-and-play fashion,\nwhich can avoid negative transfer when faced with new unknown tasks.\nExperimental results show that our method can consistently facilitate faster\nand more efficient policy transfer.",
          "link": "http://arxiv.org/abs/2204.07729",
          "publishedOn": "2023-07-14T01:03:53.091Z",
          "wordCount": null,
          "title": "Efficient Bayesian Policy Reuse with a Scalable Observation Model in Deep Reinforcement Learning. (arXiv:2204.07729v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.06984",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_H/0/1/0/all/0/1\">Hanbaek Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kureh_Y/0/1/0/all/0/1\">Yacoub H. Kureh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vendrow_J/0/1/0/all/0/1\">Joshua Vendrow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Porter_M/0/1/0/all/0/1\">Mason A. Porter</a>",
          "description": "It is common to use networks to encode the architecture of interactions\nbetween entities in complex systems in the physical, biological, social, and\ninformation sciences. To study the large-scale behavior of complex systems, it\nis useful to examine mesoscale structures in networks as building blocks that\ninfluence such behavior. We present a new approach for describing low-rank\nmesoscale structures in networks, and we illustrate our approach using several\nsynthetic network models and empirical friendship, collaboration, and\nprotein--protein interaction (PPI) networks. We find that these networks\npossess a relatively small number of `latent motifs' that together can\nsuccessfully approximate most subgraphs of a network at a fixed mesoscale. We\nuse an algorithm for `network dictionary learning' (NDL), which combines a\nnetwork-sampling method and nonnegative matrix factorization, to learn the\nlatent motifs of a given network. The ability to encode a network using a set\nof latent motifs has a wide variety of applications to network-analysis tasks,\nsuch as comparison, denoising, and edge inference. Additionally, using a new\nnetwork denoising and reconstruction (NDR) algorithm, we demonstrate how to\ndenoise a corrupted network by using only the latent motifs that one learns\ndirectly from the corrupted network.",
          "link": "http://arxiv.org/abs/2102.06984",
          "publishedOn": "2023-07-14T01:03:53.090Z",
          "wordCount": null,
          "title": "Learning low-rank latent mesoscale structures in networks. (arXiv:2102.06984v5 [cs.SI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.01497",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ilandarideva_S/0/1/0/all/0/1\">Sasila Ilandarideva</a>, <a href=\"http://arxiv.org/find/math/1/au:+Juditsky_A/0/1/0/all/0/1\">Anatoli Juditsky</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lan_G/0/1/0/all/0/1\">Guanghui Lan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Li_T/0/1/0/all/0/1\">Tianjiao Li</a>",
          "description": "We consider a class of stochastic smooth convex optimization problems under\nrather general assumptions on the noise in the stochastic gradient observation.\nAs opposed to the classical problem setting in which the variance of noise is\nassumed to be uniformly bounded, herein we assume that the variance of\nstochastic gradients is related to the \"sub-optimality\" of the approximate\nsolutions delivered by the algorithm. Such problems naturally arise in a\nvariety of applications, in particular, in the well-known generalized linear\nregression problem in statistics. However, to the best of our knowledge, none\nof the existing stochastic approximation algorithms for solving this class of\nproblems attain optimality in terms of the dependence on accuracy, problem\nparameters, and mini-batch size.\n\nWe discuss two non-Euclidean accelerated stochastic approximation\nroutines--stochastic accelerated gradient descent (SAGD) and stochastic\ngradient extrapolation (SGE)--which carry a particular duality relationship. We\nshow that both SAGD and SGE, under appropriate conditions, achieve the optimal\nconvergence rate, attaining the optimal iteration and sample complexities\nsimultaneously. However, corresponding assumptions for the SGE algorithm are\nmore general; they allow, for instance, for efficient application of the SGE to\nstatistical estimation problems under heavy tail noises and discontinuous score\nfunctions. We also discuss the application of the SGE to problems satisfying\nquadratic growth conditions, and show how it can be used to recover sparse\nsolutions. Finally, we report on some simulation experiments to illustrate\nnumerical performance of our proposed algorithms in high-dimensional settings.",
          "link": "http://arxiv.org/abs/2307.01497",
          "publishedOn": "2023-07-14T01:03:53.088Z",
          "wordCount": null,
          "title": "Accelerated stochastic approximation with state-dependent noise. (arXiv:2307.01497v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.09522",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Magesh_A/0/1/0/all/0/1\">Akshayaa Magesh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Veeravalli_V/0/1/0/all/0/1\">Venugopal V. Veeravalli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Roy_A/0/1/0/all/0/1\">Anirban Roy</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jha_S/0/1/0/all/0/1\">Susmit Jha</a>",
          "description": "We study the problem of Out-of-Distribution (OOD) detection, that is,\ndetecting whether a learning algorithm's output can be trusted at inference\ntime. While a number of tests for OOD detection have been proposed in prior\nwork, a formal framework for studying this problem is lacking. We propose a\ndefinition for the notion of OOD that includes both the input distribution and\nthe learning algorithm, which provides insights for the construction of\npowerful tests for OOD detection. We propose a multiple hypothesis testing\ninspired procedure to systematically combine any number of different statistics\nfrom the learning algorithm using conformal p-values. We further provide strong\nguarantees on the probability of incorrectly classifying an in-distribution\nsample as OOD. In our experiments, we find that threshold-based tests proposed\nin prior work perform well in specific settings, but not uniformly well across\ndifferent types of OOD instances. In contrast, our proposed method that\ncombines multiple statistics performs uniformly well across different datasets\nand neural networks.",
          "link": "http://arxiv.org/abs/2206.09522",
          "publishedOn": "2023-07-14T01:03:53.087Z",
          "wordCount": null,
          "title": "Multiple Testing Framework for Out-of-Distribution Detection. (arXiv:2206.09522v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.15944",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kessler_S/0/1/0/all/0/1\">Samuel Kessler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ostaszewski_M/0/1/0/all/0/1\">Mateusz Ostaszewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bortkiewicz_M/0/1/0/all/0/1\">Micha&#x142; Bortkiewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zarski_M/0/1/0/all/0/1\">Mateusz &#x17b;arski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolczyk_M/0/1/0/all/0/1\">Maciej Wo&#x142;czyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parker_Holder_J/0/1/0/all/0/1\">Jack Parker-Holder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1\">Stephen J. Roberts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milos_P/0/1/0/all/0/1\">Piotr Mi&#x142;o&#x15b;</a>",
          "description": "World models power some of the most efficient reinforcement learning\nalgorithms. In this work, we showcase that they can be harnessed for continual\nlearning - a situation when the agent faces changing environments. World models\ntypically employ a replay buffer for training, which can be naturally extended\nto continual learning. We systematically study how different selective\nexperience replay methods affect performance, forgetting, and transfer. We also\nprovide recommendations regarding various modeling options for using world\nmodels. The best set of choices is called Continual-Dreamer, it is\ntask-agnostic and utilizes the world model for continual exploration.\nContinual-Dreamer is sample efficient and outperforms state-of-the-art\ntask-agnostic continual reinforcement learning methods on Minigrid and Minihack\nbenchmarks.",
          "link": "http://arxiv.org/abs/2211.15944",
          "publishedOn": "2023-07-14T01:03:53.085Z",
          "wordCount": null,
          "title": "The Effectiveness of World Models for Continual Reinforcement Learning. (arXiv:2211.15944v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2207.04827",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Simas_R/0/1/0/all/0/1\">Rodrigo Simas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_Couto_L/0/1/0/all/0/1\">Luis Sa-Couto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wichert_A/0/1/0/all/0/1\">Andreas Wichert</a>",
          "description": "Drawing from memory the face of a friend you have not seen in years is a\ndifficult task. However, if you happen to cross paths, you would easily\nrecognize each other. The biological memory is equipped with an impressive\ncompression algorithm that can store the essential, and then infer the details\nto match perception. The Willshaw Memory is a simple abstract model for\ncortical computations which implements mechanisms of biological memories. Using\nour recently proposed sparse coding prescription for visual patterns, this\nmodel can store and retrieve an impressive amount of real-world data in a\nfault-tolerant manner. In this paper, we extend the capabilities of the basic\nAssociative Memory Model by using a Multiple-Modality framework. In this\nsetting, the memory stores several modalities (e.g., visual, or textual) of\neach pattern simultaneously. After training, the memory can be used to infer\nmissing modalities when just a subset is perceived. Using a simple\nencoder-memory-decoder architecture, and a newly proposed iterative retrieval\nalgorithm for the Willshaw Model, we perform experiments on the MNIST dataset.\nBy storing both the images and labels as modalities, a single Memory can be\nused not only to retrieve and complete patterns but also to classify and\ngenerate new ones. We further discuss how this model could be used for other\nlearning tasks, thus serving as a biologically-inspired framework for learning.",
          "link": "http://arxiv.org/abs/2207.04827",
          "publishedOn": "2023-07-14T01:03:53.083Z",
          "wordCount": null,
          "title": "Classification and Generation of real-world data with an Associative Memory Model. (arXiv:2207.04827v4 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.04428",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dorfman_R/0/1/0/all/0/1\">Ron Dorfman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_K/0/1/0/all/0/1\">Kfir Y. Levy</a>",
          "description": "We consider stochastic optimization problems where data is drawn from a\nMarkov chain. Existing methods for this setting crucially rely on knowing the\nmixing time of the chain, which in real-world applications is usually unknown.\nWe propose the first optimization method that does not require the knowledge of\nthe mixing time, yet obtains the optimal asymptotic convergence rate when\napplied to convex problems. We further show that our approach can be extended\nto: (i) finding stationary points in non-convex optimization with Markovian\ndata, and (ii) obtaining better dependence on the mixing time in temporal\ndifference (TD) learning; in both cases, our method is completely oblivious to\nthe mixing time. Our method relies on a novel combination of multi-level Monte\nCarlo (MLMC) gradient estimation together with an adaptive learning method.",
          "link": "http://arxiv.org/abs/2202.04428",
          "publishedOn": "2023-07-14T01:03:53.081Z",
          "wordCount": null,
          "title": "Adapting to Mixing Time in Stochastic Optimization with Markovian Data. (arXiv:2202.04428v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06877",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Papadimitriou_C/0/1/0/all/0/1\">Christos Papadimitriou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Binghui Peng</a>",
          "description": "The problem of continual learning in the domain of reinforcement learning,\noften called non-stationary reinforcement learning, has been identified as an\nimportant challenge to the application of reinforcement learning. We prove a\nworst-case complexity result, which we believe captures this challenge:\nModifying the probabilities or the reward of a single state-action pair in a\nreinforcement learning problem requires an amount of time almost as large as\nthe number of states in order to keep the value function up to date, unless the\nstrong exponential time hypothesis (SETH) is false; SETH is a widely accepted\nstrengthening of the P $\\neq$ NP conjecture. Recall that the number of states\nin current applications of reinforcement learning is typically astronomical. In\ncontrast, we show that just $\\textit{adding}$ a new state-action pair is\nconsiderably easier to implement.",
          "link": "http://arxiv.org/abs/2307.06877",
          "publishedOn": "2023-07-14T01:03:53.080Z",
          "wordCount": null,
          "title": "The complexity of non-stationary reinforcement learning. (arXiv:2307.06877v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06913",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Graziani_M/0/1/0/all/0/1\">Mara Graziani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahony_L/0/1/0/all/0/1\">Laura O&#x27; Mahony</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">An-Phi Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_H/0/1/0/all/0/1\">Henning M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andrearczyk_V/0/1/0/all/0/1\">Vincent Andrearczyk</a>",
          "description": "Interpreting the inner workings of deep learning models is crucial for\nestablishing trust and ensuring model safety. Concept-based explanations have\nemerged as a superior approach that is more interpretable than feature\nattribution estimates such as pixel saliency. However, defining the concepts\nfor the interpretability analysis biases the explanations by the user's\nexpectations on the concepts. To address this, we propose a novel post-hoc\nunsupervised method that automatically uncovers the concepts learned by deep\nmodels during training. By decomposing the latent space of a layer in singular\nvectors and refining them by unsupervised clustering, we uncover concept\nvectors aligned with directions of high variance that are relevant to the model\nprediction, and that point to semantically distinct concepts. Our extensive\nexperiments reveal that the majority of our concepts are readily understandable\nto humans, exhibit coherency, and bear relevance to the task at hand. Moreover,\nwe showcase the practical utility of our method in dataset exploration, where\nour concept vectors successfully identify outlier training samples affected by\nvarious confounding factors. This novel exploration technique has remarkable\nversatility to data types and model architectures and it will facilitate the\nidentification of biases and the discovery of sources of error within training\ndata.",
          "link": "http://arxiv.org/abs/2307.06913",
          "publishedOn": "2023-07-14T01:03:53.062Z",
          "wordCount": null,
          "title": "Uncovering Unique Concept Vectors through Latent Space Decomposition. (arXiv:2307.06913v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06871",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Neto_E/0/1/0/all/0/1\">Eufr&#xe1;sio de A. Lima Neto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bailiss_J/0/1/0/all/0/1\">Jonathan Bailiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finke_A/0/1/0/all/0/1\">Axel Finke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1\">Jo Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cosma_G/0/1/0/all/0/1\">Georgina Cosma</a>",
          "description": "Local authorities in England, such as Leicestershire County Council (LCC),\nprovide Early Help services that can be offered at any point in a young\nperson's life when they experience difficulties that cannot be supported by\nuniversal services alone, such as schools. This paper investigates the\nutilisation of machine learning (ML) to assist experts in identifying families\nthat may need to be referred for Early Help assessment and support. LCC\nprovided an anonymised dataset comprising 14360 records of young people under\nthe age of 18. The dataset was pre-processed, machine learning models were\nbuild, and experiments were conducted to validate and test the performance of\nthe models. Bias mitigation techniques were applied to improve the fairness of\nthese models. During testing, while the models demonstrated the capability to\nidentify young people requiring intervention or early help, they also produced\na significant number of false positives, especially when constructed with\nimbalanced data, incorrectly identifying individuals who most likely did not\nneed an Early Help referral. This paper empirically explores the suitability of\ndata-driven ML models for identifying young people who may require Early Help\nservices and discusses their appropriateness and limitations for this task.",
          "link": "http://arxiv.org/abs/2307.06871",
          "publishedOn": "2023-07-14T01:03:53.058Z",
          "wordCount": null,
          "title": "Identifying Early Help Referrals For Local Authorities With Machine Learning And Bias Analysis. (arXiv:2307.06871v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06915",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wei_Z/0/1/0/all/0/1\">Ziyang Wei</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhu_W/0/1/0/all/0/1\">Wanrong Zhu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wu_W/0/1/0/all/0/1\">Wei Biao Wu</a>",
          "description": "Stochastic Gradient Descent (SGD) is one of the simplest and most popular\nalgorithms in modern statistical and machine learning due to its computational\nand memory efficiency. Various averaging schemes have been proposed to\naccelerate the convergence of SGD in different settings. In this paper, we\nexplore a general averaging scheme for SGD. Specifically, we establish the\nasymptotic normality of a broad range of weighted averaged SGD solutions and\nprovide asymptotically valid online inference approaches. Furthermore, we\npropose an adaptive averaging scheme that exhibits both optimal statistical\nrate and favorable non-asymptotic convergence, drawing insights from the\noptimal weight for the linear model in terms of non-asymptotic mean squared\nerror (MSE).",
          "link": "http://arxiv.org/abs/2307.06915",
          "publishedOn": "2023-07-14T01:03:53.058Z",
          "wordCount": null,
          "title": "Weighted Averaged Stochastic Gradient Descent: Asymptotic Normality and Optimality. (arXiv:2307.06915v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06840",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Papacharalampous_G/0/1/0/all/0/1\">Georgia Papacharalampous</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tyralis_H/0/1/0/all/0/1\">Hristos Tyralis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doulamis_N/0/1/0/all/0/1\">Nikolaos Doulamis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doulamis_A/0/1/0/all/0/1\">Anastasios Doulamis</a>",
          "description": "Regression algorithms are regularly used for improving the accuracy of\nsatellite precipitation products. In this context, ground-based measurements\nare the dependent variable and the satellite data are the predictor variables,\ntogether with topography factors. Alongside this, it is increasingly recognised\nin many fields that combinations of algorithms through ensemble learning can\nlead to substantial predictive performance improvements. Still, a sufficient\nnumber of ensemble learners for improving the accuracy of satellite\nprecipitation products and their large-scale comparison are currently missing\nfrom the literature. In this work, we fill this specific gap by proposing 11\nnew ensemble learners in the field and by extensively comparing them for the\nentire contiguous United States and for a 15-year period. We use monthly data\nfrom the PERSIANN (Precipitation Estimation from Remotely Sensed Information\nusing Artificial Neural Networks) and IMERG (Integrated Multi-satellitE\nRetrievals for GPM) gridded datasets. We also use gauge-measured precipitation\ndata from the Global Historical Climatology Network monthly database, version 2\n(GHCNm). The ensemble learners combine the predictions by six regression\nalgorithms (base learners), namely the multivariate adaptive regression splines\n(MARS), multivariate adaptive polynomial splines (poly-MARS), random forests\n(RF), gradient boosting machines (GBM), extreme gradient boosting (XGBoost) and\nBayesian regularized neural networks (BRNN), and each of them is based on a\ndifferent combiner. The combiners include the equal-weight combiner, the median\ncombiner, two best learners and seven variants of a sophisticated stacking\nmethod. The latter stacks a regression algorithm on the top of the base\nlearners to combine their independent predictions...",
          "link": "http://arxiv.org/abs/2307.06840",
          "publishedOn": "2023-07-14T01:03:53.057Z",
          "wordCount": null,
          "title": "Ensemble learning for blending gridded satellite and gauge-measured precipitation data. (arXiv:2307.06840v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06860",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Canas_J/0/1/0/all/0/1\">Juan Sebasti&#xe1;n Ca&#xf1;as</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toro_Gomez_M/0/1/0/all/0/1\">Maria Paula Toro-G&#xf3;mez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugai_L/0/1/0/all/0/1\">Larissa Sayuri Moreira Sugai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Restrepo_H/0/1/0/all/0/1\">Hern&#xe1;n Dar&#xed;o Ben&#xed;tez Restrepo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudas_J/0/1/0/all/0/1\">Jorge Rudas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bautista_B/0/1/0/all/0/1\">Breyner Posso Bautista</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toledo_L/0/1/0/all/0/1\">Lu&#xed;s Felipe Toledo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dena_S/0/1/0/all/0/1\">Simone Dena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Domingos_A/0/1/0/all/0/1\">Ad&#xe3;o Henrique Rosa Domingos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Souza_F/0/1/0/all/0/1\">Franco Leandro de Souza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neckel_Oliveira_S/0/1/0/all/0/1\">Selvino Neckel-Oliveira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosa_A/0/1/0/all/0/1\">Anderson da Rosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_Rocha_V/0/1/0/all/0/1\">V&#xed;tor Carvalho-Rocha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernardy_J/0/1/0/all/0/1\">Jos&#xe9; Vin&#xed;cius Bernardy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugai_J/0/1/0/all/0/1\">Jos&#xe9; Luiz Massao Moreira Sugai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_C/0/1/0/all/0/1\">Carolina Em&#xed;lia dos Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastos_R/0/1/0/all/0/1\">Rog&#xe9;rio Pereira Bastos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Llusia_D/0/1/0/all/0/1\">Diego Llusia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ulloa_J/0/1/0/all/0/1\">Juan Sebasti&#xe1;n Ulloa</a>",
          "description": "Global change is predicted to induce shifts in anuran acoustic behavior,\nwhich can be studied through passive acoustic monitoring (PAM). Understanding\nchanges in calling behavior requires the identification of anuran species,\nwhich is challenging due to the particular characteristics of neotropical\nsoundscapes. In this paper, we introduce a large-scale multi-species dataset of\nanuran amphibians calls recorded by PAM, that comprises 27 hours of expert\nannotations for 42 different species from two Brazilian biomes. We provide open\naccess to the dataset, including the raw recordings, experimental setup code,\nand a benchmark with a baseline model of the fine-grained categorization\nproblem. Additionally, we highlight the challenges of the dataset to encourage\nmachine learning researchers to solve the problem of anuran call identification\ntowards conservation policy. All our experiments and resources can be found on\nour GitHub repository https://github.com/soundclim/anuraset.",
          "link": "http://arxiv.org/abs/2307.06860",
          "publishedOn": "2023-07-14T01:03:53.057Z",
          "wordCount": null,
          "title": "AnuraSet: A dataset for benchmarking Neotropical anuran calls identification in passive acoustic monitoring. (arXiv:2307.06860v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1901.07186",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Berseth_G/0/1/0/all/0/1\">Glen Berseth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golemo_F/0/1/0/all/0/1\">Florian Golemo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1\">Christopher Pal</a>",
          "description": "Agents that can learn to imitate given video observation -- \\emph{without\ndirect access to state or action information} are more applicable to learning\nin the natural world. However, formulating a reinforcement learning (RL) agent\nthat facilitates this goal remains a significant challenge. We approach this\nchallenge using contrastive training to learn a reward function comparing an\nagent's behaviour with a single demonstration. We use a Siamese recurrent\nneural network architecture to learn rewards in space and time between motion\nclips while training an RL policy to minimize this distance. Through\nexperimentation, we also find that the inclusion of multi-task data and\nadditional image encoding losses improve the temporal consistency of the\nlearned rewards and, as a result, significantly improves policy learning. We\ndemonstrate our approach on simulated humanoid, dog, and raptor agents in 2D\nand a quadruped and a humanoid in 3D. We show that our method outperforms\ncurrent state-of-the-art techniques in these environments and can learn to\nimitate from a single video demonstration.",
          "link": "http://arxiv.org/abs/1901.07186",
          "publishedOn": "2023-07-14T01:03:53.057Z",
          "wordCount": null,
          "title": "Towards Learning to Imitate from a Single Video Demonstration. (arXiv:1901.07186v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.13445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cooper_A/0/1/0/all/0/1\">Avi Cooper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boix_X/0/1/0/all/0/1\">Xavier Boix</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harari_D/0/1/0/all/0/1\">Daniel Harari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madan_S/0/1/0/all/0/1\">Spandan Madan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_H/0/1/0/all/0/1\">Hanspeter Pfister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sasaki_T/0/1/0/all/0/1\">Tomotake Sasaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_P/0/1/0/all/0/1\">Pawan Sinha</a>",
          "description": "The capability of Deep Neural Networks (DNNs) to recognize objects in\norientations outside the distribution of the training data is not well\nunderstood. We present evidence that DNNs are capable of generalizing to\nobjects in novel orientations by disseminating orientation-invariance obtained\nfrom familiar objects seen from many viewpoints. This capability strengthens\nwhen training the DNN with an increasing number of familiar objects, but only\nin orientations that involve 2D rotations of familiar orientations. We show\nthat this dissemination is achieved via neurons tuned to common features\nbetween familiar and unfamiliar objects. These results implicate brain-like\nneural mechanisms for generalization.",
          "link": "http://arxiv.org/abs/2109.13445",
          "publishedOn": "2023-07-14T01:03:53.057Z",
          "wordCount": null,
          "title": "Emergent Neural Network Mechanisms for Generalization to Objects in Novel Orientations. (arXiv:2109.13445v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carbone_A/0/1/0/all/0/1\">Alessandra Carbone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Decelle_A/0/1/0/all/0/1\">Aur&#xe9;lien Decelle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosset_L/0/1/0/all/0/1\">Lorenzo Rosset</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seoane_B/0/1/0/all/0/1\">Beatriz Seoane</a>",
          "description": "In this study, we address the challenge of using energy-based models to\nproduce high-quality, label-specific data in complex structured datasets, such\nas population genetics, RNA or protein sequences data. Traditional training\nmethods encounter difficulties due to inefficient Markov chain Monte Carlo\nmixing, which affects the diversity of synthetic data and increases generation\ntimes. To address these issues, we use a novel training algorithm that exploits\nnon-equilibrium effects. This approach, applied on the Restricted Boltzmann\nMachine, improves the model's ability to correctly classify samples and\ngenerate high-quality synthetic data in only a few sampling steps. The\neffectiveness of this method is demonstrated by its successful application to\nfour different types of data: handwritten digits, mutations of human genomes\nclassified by continental origin, functionally characterized sequences of an\nenzyme protein family, and homologous RNA sequences from specific taxonomies.",
          "link": "http://arxiv.org/abs/2307.06797",
          "publishedOn": "2023-07-14T01:03:53.056Z",
          "wordCount": null,
          "title": "Fast and Functional Structured Data Generators Rooted in Out-of-Equilibrium Physics. (arXiv:2307.06797v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1\">Haoyu Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anicic_D/0/1/0/all/0/1\">Darko Anicic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Runkler_T/0/1/0/all/0/1\">Thomas A. Runkler</a>",
          "description": "The field of Tiny Machine Learning (TinyML) has made substantial advancements\nin democratizing machine learning on low-footprint devices, such as\nmicrocontrollers. The prevalence of these miniature devices raises the question\nof whether aggregating their knowledge can benefit TinyML applications.\nFederated meta-learning is a promising answer to this question, as it addresses\nthe scarcity of labeled data and heterogeneous data distribution across devices\nin the real world. However, deploying TinyML hardware faces unique resource\nconstraints, making existing methods impractical due to energy, privacy, and\ncommunication limitations. We introduce TinyMetaFed, a model-agnostic\nmeta-learning framework suitable for TinyML. TinyMetaFed facilitates\ncollaborative training of a neural network initialization that can be quickly\nfine-tuned on new devices. It offers communication savings and privacy\nprotection through partial local reconstruction and Top-P% selective\ncommunication, computational efficiency via online learning, and robustness to\nclient heterogeneity through few-shot learning. The evaluations on three TinyML\nuse cases demonstrate that TinyMetaFed can significantly reduce energy\nconsumption and communication overhead, accelerate convergence, and stabilize\nthe training process.",
          "link": "http://arxiv.org/abs/2307.06822",
          "publishedOn": "2023-07-14T01:03:53.056Z",
          "wordCount": null,
          "title": "TinyMetaFed: Efficient Federated Meta-Learning for TinyML. (arXiv:2307.06822v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06834",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Al_Quraan_M/0/1/0/all/0/1\">Mohammad Al-Quraan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zoha_A/0/1/0/all/0/1\">Ahmed Zoha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Centeno_A/0/1/0/all/0/1\">Anthony Centeno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salameh_H/0/1/0/all/0/1\">Haythem Bany Salameh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muhaidat_S/0/1/0/all/0/1\">Sami Muhaidat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imran_M/0/1/0/all/0/1\">Muhammad Ali Imran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohjazi_L/0/1/0/all/0/1\">Lina Mohjazi</a>",
          "description": "This article introduces a new method to improve the dependability of\nmillimeter-wave (mmWave) and terahertz (THz) network services in dynamic\noutdoor environments. In these settings, line-of-sight (LoS) connections are\neasily interrupted by moving obstacles like humans and vehicles. The proposed\napproach, coined as Radar-aided Dynamic blockage Recognition (RaDaR), leverages\nradar measurements and federated learning (FL) to train a dual-output neural\nnetwork (NN) model capable of simultaneously predicting blockage status and\ntime. This enables determining the optimal point for proactive handover (PHO)\nor beam switching, thereby reducing the latency introduced by 5G new radio\nprocedures and ensuring high quality of experience (QoE). The framework employs\nradar sensors to monitor and track objects movement, generating range-angle and\nrange-velocity maps that are useful for scene analysis and predictions.\nMoreover, FL provides additional benefits such as privacy protection,\nscalability, and knowledge sharing. The framework is assessed using an\nextensive real-world dataset comprising mmWave channel information and radar\ndata. The evaluation results show that RaDaR substantially enhances network\nreliability, achieving an average success rate of 94% for PHO compared to\nexisting reactive HO procedures that lack proactive blockage prediction.\nAdditionally, RaDaR maintains a superior QoE by ensuring sustained high\nthroughput levels and minimising PHO latency.",
          "link": "http://arxiv.org/abs/2307.06834",
          "publishedOn": "2023-07-14T01:03:53.056Z",
          "wordCount": null,
          "title": "Enhancing Reliability in Federated mmWave Networks: A Practical and Scalable Solution using Radar-Aided Dynamic Blockage Recognition. (arXiv:2307.06834v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06887",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Collins_L/0/1/0/all/0/1\">Liam Collins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassani_H/0/1/0/all/0/1\">Hamed Hassani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soltanolkotabi_M/0/1/0/all/0/1\">Mahdi Soltanolkotabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mokhtari_A/0/1/0/all/0/1\">Aryan Mokhtari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shakkottai_S/0/1/0/all/0/1\">Sanjay Shakkottai</a>",
          "description": "Feature learning, i.e. extracting meaningful representations of data, is\nquintessential to the practical success of neural networks trained with\ngradient descent, yet it is notoriously difficult to explain how and why it\noccurs. Recent theoretical studies have shown that shallow neural networks\noptimized on a single task with gradient-based methods can learn meaningful\nfeatures, extending our understanding beyond the neural tangent kernel or\nrandom feature regime in which negligible feature learning occurs. But in\npractice, neural networks are increasingly often trained on {\\em many} tasks\nsimultaneously with differing loss functions, and these prior analyses do not\ngeneralize to such settings. In the multi-task learning setting, a variety of\nstudies have shown effective feature learning by simple linear models. However,\nmulti-task learning via {\\em nonlinear} models, arguably the most common\nlearning paradigm in practice, remains largely mysterious. In this work, we\npresent the first results proving feature learning occurs in a multi-task\nsetting with a nonlinear model. We show that when the tasks are binary\nclassification problems with labels depending on only $r$ directions within the\nambient $d\\gg r$-dimensional input space, executing a simple gradient-based\nmultitask learning algorithm on a two-layer ReLU neural network learns the\nground-truth $r$ directions. In particular, any downstream task on the $r$\nground-truth coordinates can be solved by learning a linear classifier with\nsample and neuron complexity independent of the ambient dimension $d$, while a\nrandom feature model requires exponential complexity in $d$ for such a\nguarantee.",
          "link": "http://arxiv.org/abs/2307.06887",
          "publishedOn": "2023-07-14T01:03:53.056Z",
          "wordCount": null,
          "title": "Provable Multi-Task Representation Learning by Two-Layer ReLU Neural Networks. (arXiv:2307.06887v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06925",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arar_M/0/1/0/all/0/1\">Moab Arar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_R/0/1/0/all/0/1\">Rinon Gal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atzmon_Y/0/1/0/all/0/1\">Yuval Atzmon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1\">Gal Chechik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_Or_D/0/1/0/all/0/1\">Daniel Cohen-Or</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shamir_A/0/1/0/all/0/1\">Ariel Shamir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bermano_A/0/1/0/all/0/1\">Amit H. Bermano</a>",
          "description": "Text-to-image (T2I) personalization allows users to guide the creative image\ngeneration process by combining their own visual concepts in natural language\nprompts. Recently, encoder-based techniques have emerged as a new effective\napproach for T2I personalization, reducing the need for multiple images and\nlong training times. However, most existing encoders are limited to a\nsingle-class domain, which hinders their ability to handle diverse concepts. In\nthis work, we propose a domain-agnostic method that does not require any\nspecialized dataset or prior information about the personalized concepts. We\nintroduce a novel contrastive-based regularization technique to maintain high\nfidelity to the target concept characteristics while keeping the predicted\nembeddings close to editable regions of the latent space, by pushing the\npredicted tokens toward their nearest existing CLIP tokens. Our experimental\nresults demonstrate the effectiveness of our approach and show how the learned\ntokens are more semantic than tokens predicted by unregularized models. This\nleads to a better representation that achieves state-of-the-art performance\nwhile being more flexible than previous methods.",
          "link": "http://arxiv.org/abs/2307.06925",
          "publishedOn": "2023-07-14T01:03:53.056Z",
          "wordCount": null,
          "title": "Domain-Agnostic Tuning-Encoder for Fast Personalization of Text-To-Image Models. (arXiv:2307.06925v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06933",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Lekang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Svoboda_F/0/1/0/all/0/1\">Filip Svoboda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lane_N/0/1/0/all/0/1\">Nicholas D. Lane</a>",
          "description": "Combining Domain-adaptive Pre-training (DAPT) with Federated Learning (FL)\ncan enhance model adaptation by leveraging more sensitive and distributed data\nwhile preserving data privacy. However, few studies have focused on this\nmethod. Therefore, we conduct the first comprehensive empirical study to\nevaluate the performance of Federated Domain-adaptive Pre-training (FDAPT). We\ndemonstrate that FDAPT can maintain competitive downstream task performance to\nthe centralized baseline in both IID and non-IID situations. Furthermore, we\npropose a novel algorithm, Frozen Federated Domain-adaptive Pre-training\n(FFDAPT). FFDAPT improves the computational efficiency by 12.1% on average and\nexhibits similar downstream task performance to standard FDAPT, with general\nperformance fluctuations remaining less than 1%. Finally, through a critical\nevaluation of our work, we identify promising future research directions for\nthis new research area.",
          "link": "http://arxiv.org/abs/2307.06933",
          "publishedOn": "2023-07-14T01:03:53.053Z",
          "wordCount": null,
          "title": "FDAPT: Federated Domain-adaptive Pre-training for Language Models. (arXiv:2307.06933v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06824",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kienzler_R/0/1/0/all/0/1\">Romeo Kienzler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_R/0/1/0/all/0/1\">Rafflesia Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nilmeier_J/0/1/0/all/0/1\">Jerome Nilmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nesic_I/0/1/0/all/0/1\">Ivan Nesic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haddad_I/0/1/0/all/0/1\">Ibrahim Haddad</a>",
          "description": "In modern data-driven science, reproducibility and reusability are key\nchallenges. Scientists are well skilled in the process from data to\npublication. Although some publication channels require source code and data to\nbe made accessible, rerunning and verifying experiments is usually hard due to\na lack of standards. Therefore, reusing existing scientific data processing\ncode from state-of-the-art research is hard as well. This is why we introduce\nCLAIMED, which has a proven track record in scientific research for addressing\nthe repeatability and reusability issues in modern data-driven science. CLAIMED\nis a framework to build reusable operators and scalable scientific workflows by\nsupporting the scientist to draw from previous work by re-composing workflows\nfrom existing libraries of coarse-grained scientific operators. Although\nvarious implementations exist, CLAIMED is programming language, scientific\nlibrary, and execution environment agnostic.",
          "link": "http://arxiv.org/abs/2307.06824",
          "publishedOn": "2023-07-14T01:03:53.051Z",
          "wordCount": null,
          "title": "CLAIMED -- the open source framework for building coarse-grained operators for accelerated discovery in science. (arXiv:2307.06824v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06886",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adibi_A/0/1/0/all/0/1\">Arman Adibi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_A/0/1/0/all/0/1\">Aritra Mitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassani_H/0/1/0/all/0/1\">Hamed Hassani</a>",
          "description": "Delays and asynchrony are inevitable in large-scale machine-learning problems\nwhere communication plays a key role. As such, several works have extensively\nanalyzed stochastic optimization with delayed gradients. However, as far as we\nare aware, no analogous theory is available for min-max optimization, a topic\nthat has gained recent popularity due to applications in adversarial\nrobustness, game theory, and reinforcement learning. Motivated by this gap, we\nexamine the performance of standard min-max optimization algorithms with\ndelayed gradient updates. First, we show (empirically) that even small delays\ncan cause prominent algorithms like Extra-gradient (\\texttt{EG}) to diverge on\nsimple instances for which \\texttt{EG} guarantees convergence in the absence of\ndelays. Our empirical study thus suggests the need for a careful analysis of\ndelayed versions of min-max optimization algorithms. Accordingly, under\nsuitable technical assumptions, we prove that Gradient Descent-Ascent\n(\\texttt{GDA}) and \\texttt{EG} with delayed updates continue to guarantee\nconvergence to saddle points for convex-concave and strongly convex-strongly\nconcave settings. Our complexity bounds reveal, in a transparent manner, the\nslow-down in convergence caused by delays.",
          "link": "http://arxiv.org/abs/2307.06886",
          "publishedOn": "2023-07-14T01:03:53.051Z",
          "wordCount": null,
          "title": "Min-Max Optimization under Delays. (arXiv:2307.06886v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06760",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mueller_T/0/1/0/all/0/1\">Tamara T. Mueller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chevli_M/0/1/0/all/0/1\">Maulik Chevli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daigavane_A/0/1/0/all/0/1\">Ameya Daigavane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1\">Daniel Rueckert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaissis_G/0/1/0/all/0/1\">Georgios Kaissis</a>",
          "description": "We initiate an empirical investigation into differentially private graph\nneural networks on population graphs from the medical domain by examining\nprivacy-utility trade-offs at different privacy levels on both real-world and\nsynthetic datasets and performing auditing through membership inference\nattacks. Our findings highlight the potential and the challenges of this\nspecific DP application area. Moreover, we find evidence that the underlying\ngraph structure constitutes a potential factor for larger performance gaps by\nshowing a correlation between the degree of graph homophily and the accuracy of\nthe trained model.",
          "link": "http://arxiv.org/abs/2307.06760",
          "publishedOn": "2023-07-14T01:03:53.050Z",
          "wordCount": null,
          "title": "Privacy-Utility Trade-offs in Neural Networks for Medical Population Graphs: Insights from Differential Privacy and Graph Structure. (arXiv:2307.06760v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06816",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">SiHun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sangmin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_K/0/1/0/all/0/1\">Kijoo Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1\">Haeseong Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1\">SangJoon Shin</a>",
          "description": "A data-driven parametric model order reduction (MOR) method using a deep\nartificial neural network is proposed. The present network, which is the\nleast-squares hierarchical variational autoencoder (LSH-VAE), is capable of\nperforming nonlinear MOR for the parametric interpolation of a nonlinear\ndynamic system with a significant number of degrees of freedom. LSH-VAE\nexploits two major changes to the existing networks: a hierarchical deep\nstructure and a hybrid weighted, probabilistic loss function. The enhancements\nresult in a significantly improved accuracy and stability compared against the\nconventional nonlinear MOR methods, autoencoder, and variational autoencoder.\nUpon LSH-VAE, a parametric MOR framework is presented based on the spherically\nlinear interpolation of the latent manifold. The present framework is validated\nand evaluated on three nonlinear and multiphysics dynamic systems. First, the\npresent framework is evaluated on the fluid-structure interaction benchmark\nproblem to assess its efficiency and accuracy. Then, a highly nonlinear\naeroelastic phenomenon, limit cycle oscillation, is analyzed. Finally, the\npresent framework is applied to a three-dimensional fluid flow to demonstrate\nits capability of efficiently analyzing a significantly large number of degrees\nof freedom. The performance of LSH-VAE is emphasized by comparing its results\nagainst that of the widely used nonlinear MOR methods, convolutional\nautoencoder, and $\\beta$-VAE. The present framework exhibits a significantly\nenhanced accuracy to the conventional methods while still exhibiting a large\nspeed-up factor.",
          "link": "http://arxiv.org/abs/2307.06816",
          "publishedOn": "2023-07-14T01:03:53.050Z",
          "wordCount": null,
          "title": "Data-driven Nonlinear Parametric Model Order Reduction Framework using Deep Hierarchical Variational Autoencoder. (arXiv:2307.06816v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06836",
          "author": "<a href=\"http://arxiv.org/find/hep-ex/1/au:+Leigh_M/0/1/0/all/0/1\">Matthew Leigh</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Sengupta_D/0/1/0/all/0/1\">Debajyoti Sengupta</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Raine_J/0/1/0/all/0/1\">John Andrew Raine</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Quetant_G/0/1/0/all/0/1\">Guillaume Qu&#xe9;tant</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Golling_T/0/1/0/all/0/1\">Tobias Golling</a>",
          "description": "Building on the success of PC-JeDi we introduce PC-Droid, a substantially\nimproved diffusion model for the generation of jet particle clouds. By\nleveraging a new diffusion formulation, studying more recent integration\nsolvers, and training on all jet types simultaneously, we are able to achieve\nstate-of-the-art performance for all types of jets across all evaluation\nmetrics. We study the trade-off between generation speed and quality by\ncomparing two attention based architectures, as well as the potential of\nconsistency distillation to reduce the number of diffusion steps. Both the\nfaster architecture and consistency models demonstrate performance surpassing\nmany competing models, with generation time up to two orders of magnitude\nfaster than PC-JeDi.",
          "link": "http://arxiv.org/abs/2307.06836",
          "publishedOn": "2023-07-14T01:03:53.049Z",
          "wordCount": null,
          "title": "PC-Droid: Faster diffusion and improved quality for particle cloud generation. (arXiv:2307.06836v1 [hep-ex])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06771",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ramanarayanan_S/0/1/0/all/0/1\">Sriprabha Ramanarayanan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Palla_A/0/1/0/all/0/1\">Arun Palla</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ram_K/0/1/0/all/0/1\">Keerthi Ram</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sivaprakasam_M/0/1/0/all/0/1\">Mohanasankar Sivaprakasam</a>",
          "description": "Meta-learning has recently been an emerging data-efficient learning technique\nfor various medical imaging operations and has helped advance contemporary deep\nlearning models. Furthermore, meta-learning enhances the knowledge\ngeneralization of the imaging tasks by learning both shared and discriminative\nweights for various configurations of imaging tasks. However, existing\nmeta-learning models attempt to learn a single set of weight initializations of\na neural network that might be restrictive for multimodal data. This work aims\nto develop a multimodal meta-learning model for image reconstruction, which\naugments meta-learning with evolutionary capabilities to encompass diverse\nacquisition settings of multimodal data. Our proposed model called KM-MAML\n(Kernel Modulation-based Multimodal Meta-Learning), has hypernetworks that\nevolve to generate mode-specific weights. These weights provide the\nmode-specific inductive bias for multiple modes by re-calibrating each kernel\nof the base network for image reconstruction via a low-rank kernel modulation\noperation. We incorporate gradient-based meta-learning (GBML) in the contextual\nspace to update the weights of the hypernetworks for different modes. The\nhypernetworks and the reconstruction network in the GBML setting provide\ndiscriminative mode-specific features and low-level image features,\nrespectively. Experiments on multi-contrast MRI reconstruction show that our\nmodel, (i) exhibits superior reconstruction performance over joint training,\nother meta-learning methods, and context-specific MRI reconstruction methods,\nand (ii) better adaptation capabilities with improvement margins of 0.5 dB in\nPSNR and 0.01 in SSIM. Besides, a representation analysis with U-Net shows that\nkernel modulation infuses 80% of mode-specific representation changes in the\nhigh-resolution layers. Our source code is available at\nhttps://github.com/sriprabhar/KM-MAML/.",
          "link": "http://arxiv.org/abs/2307.06771",
          "publishedOn": "2023-07-14T01:03:53.048Z",
          "wordCount": null,
          "title": "Generalizing Supervised Deep Learning MRI Reconstruction to Multiple and Unseen Contrasts using Meta-Learning Hypernetworks. (arXiv:2307.06771v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06784",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Palermo_F/0/1/0/all/0/1\">Francesca Palermo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Omarali_B/0/1/0/all/0/1\">Bukeikhan Omarali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_C/0/1/0/all/0/1\">Changae Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Althoefer_K/0/1/0/all/0/1\">Kaspar Althoefer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farkhatdinov_I/0/1/0/all/0/1\">Ildar Farkhatdinov</a>",
          "description": "This paper presents a novel algorithm for crack localisation and detection\nbased on visual and tactile analysis via fibre-optics. A finger-shaped sensor\nbased on fibre-optics is employed for the data acquisition to collect data for\nthe analysis and the experiments. To detect the possible locations of cracks a\ncamera is used to scan an environment while running an object detection\nalgorithm. Once the crack is detected, a fully-connected graph is created from\na skeletonised version of the crack. A minimum spanning tree is then employed\nfor calculating the shortest path to explore the crack which is then used to\ndevelop the motion planner for the robotic manipulator. The motion planner\ndivides the crack into multiple nodes which are then explored individually.\nThen, the manipulator starts the exploration and performs the tactile data\nclassification to confirm if there is indeed a crack in that location or just a\nfalse positive from the vision algorithm. If a crack is detected, also the\nlength, width, orientation and number of branches are calculated. This is\nrepeated until all the nodes of the crack are explored.\n\nIn order to validate the complete algorithm, various experiments are\nperformed: comparison of exploration of cracks through full scan and motion\nplanning algorithm, implementation of frequency-based features for crack\nclassification and geometry analysis using a combination of vision and tactile\ndata. From the results of the experiments, it is shown that the proposed\nalgorithm is able to detect cracks and improve the results obtained from vision\nto correctly classify cracks and their geometry with minimal cost thanks to the\nmotion planning algorithm.",
          "link": "http://arxiv.org/abs/2307.06784",
          "publishedOn": "2023-07-14T01:03:53.048Z",
          "wordCount": null,
          "title": "Robotic surface exploration with vision and tactile sensing for cracks detection and characterisation. (arXiv:2307.06784v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06842",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Catte_E/0/1/0/all/0/1\">Esteban Catt&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sana_M/0/1/0/all/0/1\">Mohamed Sana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maman_M/0/1/0/all/0/1\">Mickael Maman</a>",
          "description": "This paper addresses the efficient management of Mobile Access Points (MAPs),\nwhich are Unmanned Aerial Vehicles (UAV), in 5G networks. We propose a\ntwo-level hierarchical architecture, which dynamically reconfigures the network\nwhile considering Integrated Access-Backhaul (IAB) constraints. The high-layer\ndecision process determines the number of MAPs through consensus, and we\ndevelop a joint optimization process to account for co-dependence in network\nself-management. In the low-layer, MAPs manage their placement using a\ndouble-attention based Deep Reinforcement Learning (DRL) model that encourages\ncooperation without retraining. To improve generalization and reduce\ncomplexity, we propose a federated mechanism for training and sharing one\nplacement model for every MAP in the low-layer. Additionally, we jointly\noptimize the placement and backhaul connectivity of MAPs using a\nmulti-objective reward function, considering the impact of varying MAP\nplacement on wireless backhaul connectivity.",
          "link": "http://arxiv.org/abs/2307.06842",
          "publishedOn": "2023-07-14T01:03:53.048Z",
          "wordCount": null,
          "title": "Federated Multi-Agent Deep Reinforcement Learning for Dynamic and Flexible 3D Operation of 5G Multi-MAP Networks. (arXiv:2307.06842v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06857",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1\">Siddhartha Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaofei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deoras_A/0/1/0/all/0/1\">Anoop Deoras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_B/0/1/0/all/0/1\">Bing Xiang</a>",
          "description": "In this paper, we present a novel approach for improving the quality and\nconsistency of generated outputs from large-scale pre-trained language models\n(LLMs). Self-consistency has emerged as an effective approach for prompts with\nfixed answers, selecting the answer with the highest number of votes. In this\npaper, we introduce a generalized framework for self-consistency that extends\nits applicability beyond problems that have fixed-answer answers. Through\nextensive simulations, we demonstrate that our approach consistently recovers\nthe optimal or near-optimal generation from a set of candidates. We also\npropose lightweight parameter-free similarity functions that show significant\nand consistent improvements across code generation, autoformalization, and\nsummarization tasks, even without access to token log probabilities. Our method\nincurs minimal computational overhead, requiring no auxiliary reranker models\nor modifications to the existing model.",
          "link": "http://arxiv.org/abs/2307.06857",
          "publishedOn": "2023-07-14T01:03:53.047Z",
          "wordCount": null,
          "title": "Self-consistency for open-ended generations. (arXiv:2307.06857v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06434",
          "author": "<a href=\"http://arxiv.org/find/hep-ex/1/au:+Yu_B/0/1/0/all/0/1\">Boyang Yu</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Hartmann_N/0/1/0/all/0/1\">Nikolai Hartmann</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Schinnerl_L/0/1/0/all/0/1\">Luca Schinnerl</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Kuhr_T/0/1/0/all/0/1\">Thomas Kuhr</a>",
          "description": "When measuring rare processes at Belle II, a huge luminosity is required,\nwhich means a large number of simulations are necessary to determine signal\nefficiencies and background contributions. However, this process demands high\ncomputation costs while most of the simulated data, in particular in case of\nbackground, are discarded by the event selection. Thus, filters using graph\nneural networks are introduced at an early stage to save the resources for the\ndetector simulation and reconstruction of events discarded at analysis level.\nIn our work, we improved the performance of the filters using graph attention\nand investigated statistical methods including sampling and reweighting to deal\nwith the biases introduced by the filtering.",
          "link": "http://arxiv.org/abs/2307.06434",
          "publishedOn": "2023-07-14T01:03:53.046Z",
          "wordCount": 663,
          "title": "Improved selective background Monte Carlo simulation at Belle II with graph attention networks and weighted events. (arXiv:2307.06434v1 [hep-ex])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06721",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shimoyama_S/0/1/0/all/0/1\">Sho Shimoyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morimura_T/0/1/0/all/0/1\">Tetsuro Morimura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abe_K/0/1/0/all/0/1\">Kenshi Abe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takamichi_T/0/1/0/all/0/1\">Toda Takamichi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomomatsu_Y/0/1/0/all/0/1\">Yuta Tomomatsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masakazu Sugiyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hentona_A/0/1/0/all/0/1\">Asahi Hentona</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azuma_Y/0/1/0/all/0/1\">Yuuki Azuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ninomiya_H/0/1/0/all/0/1\">Hirotaka Ninomiya</a>",
          "description": "Dialog policies, which determine a system's action based on the current state\nat each dialog turn, are crucial to the success of the dialog. In recent years,\nreinforcement learning (RL) has emerged as a promising option for dialog policy\nlearning (DPL). In RL-based DPL, dialog policies are updated according to\nrewards. The manual construction of fine-grained rewards, such as\nstate-action-based ones, to effectively guide the dialog policy is challenging\nin multi-domain task-oriented dialog scenarios with numerous state-action pair\ncombinations. One way to estimate rewards from collected data is to train the\nreward estimator and dialog policy simultaneously using adversarial learning\n(AL). Although this method has demonstrated superior performance\nexperimentally, it is fraught with the inherent problems of AL, such as mode\ncollapse. This paper first identifies the role of AL in DPL through detailed\nanalyses of the objective functions of dialog policy and reward estimator.\nNext, based on these analyses, we propose a method that eliminates AL from\nreward estimation and DPL while retaining its advantages. We evaluate our\nmethod using MultiWOZ, a multi-domain task-oriented dialog corpus.",
          "link": "http://arxiv.org/abs/2307.06721",
          "publishedOn": "2023-07-14T01:03:53.041Z",
          "wordCount": null,
          "title": "Why Guided Dialog Policy Learning performs well? Understanding the role of adversarial learning and its alternative. (arXiv:2307.06721v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06723",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_N/0/1/0/all/0/1\">Nairen Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shang-En Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hsin-Hao Su</a>",
          "description": "In this paper, we study parallel algorithms for the correlation clustering\nproblem, where every pair of two different entities is labeled with similar or\ndissimilar. The goal is to partition the entities into clusters to minimize the\nnumber of disagreements with the labels. Currently, all efficient parallel\nalgorithms have an approximation ratio of at least 3. In comparison with the\n$1.994+\\epsilon$ ratio achieved by polynomial-time sequential algorithms\n[CLN22], a significant gap exists.\n\nWe propose the first poly-logarithmic depth parallel algorithm that achieves\na better approximation ratio than 3. Specifically, our algorithm computes a\n$(2.4+\\epsilon)$-approximate solution and uses $\\tilde{O}(m^{1.5})$ work.\nAdditionally, it can be translated into a $\\tilde{O}(m^{1.5})$-time sequential\nalgorithm and a poly-logarithmic rounds sublinear-memory MPC algorithm with\n$\\tilde{O}(m^{1.5})$ total memory.\n\nOur approach is inspired by Awerbuch, Khandekar, and Rao's [AKR12]\nlength-constrained multi-commodity flow algorithm, where we develop an\nefficient parallel algorithm to solve a truncated correlation clustering linear\nprogram of Charikar, Guruswami, and Wirth [CGW05]. Then we show the solution of\nthe truncated linear program can be rounded with a factor of at most 2.4 loss\nby using the framework of [CMSY15]. Such a rounding framework can then be\nimplemented using parallel pivot-based approaches.",
          "link": "http://arxiv.org/abs/2307.06723",
          "publishedOn": "2023-07-14T01:03:53.041Z",
          "wordCount": null,
          "title": "Breaking 3-Factor Approximation for Correlation Clustering in Polylogarithmic Rounds. (arXiv:2307.06723v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06870",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mendez_J/0/1/0/all/0/1\">Jorge A. Mendez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaelbling_L/0/1/0/all/0/1\">Leslie Pack Kaelbling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lozano_Perez_T/0/1/0/all/0/1\">Tom&#xe1;s Lozano-P&#xe9;rez</a>",
          "description": "A robot deployed in a home over long stretches of time faces a true lifelong\nlearning problem. As it seeks to provide assistance to its users, the robot\nshould leverage any accumulated experience to improve its own knowledge to\nbecome a more proficient assistant. We formalize this setting with a novel\nlifelong learning problem formulation in the context of learning for task and\nmotion planning (TAMP). Exploiting the modularity of TAMP systems, we develop a\ngenerative mixture model that produces candidate continuous parameters for a\nplanner. Whereas most existing lifelong learning approaches determine a priori\nhow data is shared across task models, our approach learns shared and\nnon-shared models and determines which to use online during planning based on\nauxiliary tasks that serve as a proxy for each model's understanding of a\nstate. Our method exhibits substantial improvements in planning success on\nsimulated 2D domains and on several problems from the BEHAVIOR benchmark.",
          "link": "http://arxiv.org/abs/2307.06870",
          "publishedOn": "2023-07-14T01:03:53.041Z",
          "wordCount": null,
          "title": "Embodied Lifelong Learning for Task and Motion Planning. (arXiv:2307.06870v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.11740",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Likang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Caifa Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1\">Xiya Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yue Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lei Chen</a>",
          "description": "The perception module of self-driving vehicles relies on a multi-sensor\nsystem to understand its environment. Recent advancements in deep learning have\nled to the rapid development of approaches that integrate multi-sensory\nmeasurements to enhance perception capabilities. This paper surveys the latest\ndeep learning integration techniques applied to the perception module in\nautonomous driving systems, categorizing integration approaches based on \"what,\nhow, and when to integrate\". A new taxonomy of integration is proposed, based\non three dimensions: multi-view, multi-modality, and multi-frame. The\nintegration operations and their pros and cons are summarized, providing new\ninsights into the properties of an \"ideal\" data integration approach that can\nalleviate the limitations of existing methods. After reviewing hundreds of\nrelevant papers, this survey concludes with a discussion of the key features of\nan optimal data integration approach.",
          "link": "http://arxiv.org/abs/2306.11740",
          "publishedOn": "2023-07-14T01:03:52.995Z",
          "wordCount": null,
          "title": "A survey on deep learning approaches for data integration in autonomous driving system. (arXiv:2306.11740v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06742",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Si_J/0/1/0/all/0/1\">Jinhua Si</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_F/0/1/0/all/0/1\">Fang He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lin_X/0/1/0/all/0/1\">Xi Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tang_X/0/1/0/all/0/1\">Xindi Tang</a>",
          "description": "The integrated development of city clusters has given rise to an increasing\ndemand for intercity travel. Intercity ride-pooling service exhibits\nconsiderable potential in upgrading traditional intercity bus services by\nimplementing demand-responsive enhancements. Nevertheless, its online\noperations suffer the inherent complexities due to the coupling of vehicle\nresource allocation among cities and pooled-ride vehicle routing. To tackle\nthese challenges, this study proposes a two-level framework designed to\nfacilitate online fleet management. Specifically, a novel multi-agent feudal\nreinforcement learning model is proposed at the upper level of the framework to\ncooperatively assign idle vehicles to different intercity lines, while the\nlower level updates the routes of vehicles using an adaptive large neighborhood\nsearch heuristic. Numerical studies based on the realistic dataset of Xiamen\nand its surrounding cities in China show that the proposed framework\neffectively mitigates the supply and demand imbalances, and achieves\nsignificant improvement in both the average daily system profit and order\nfulfillment ratio.",
          "link": "http://arxiv.org/abs/2307.06742",
          "publishedOn": "2023-07-14T01:03:52.991Z",
          "wordCount": null,
          "title": "Vehicle Dispatching and Routing of On-Demand Intercity Ride-Pooling Services: A Multi-Agent Hierarchical Reinforcement Learning Approach. (arXiv:2307.06742v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06949",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_N/0/1/0/all/0/1\">Nataniel Ruiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jampani_V/0/1/0/all/0/1\">Varun Jampani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1\">Wei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_T/0/1/0/all/0/1\">Tingbo Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pritch_Y/0/1/0/all/0/1\">Yael Pritch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wadhwa_N/0/1/0/all/0/1\">Neal Wadhwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubinstein_M/0/1/0/all/0/1\">Michael Rubinstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aberman_K/0/1/0/all/0/1\">Kfir Aberman</a>",
          "description": "Personalization has emerged as a prominent aspect within the field of\ngenerative AI, enabling the synthesis of individuals in diverse contexts and\nstyles, while retaining high-fidelity to their identities. However, the process\nof personalization presents inherent challenges in terms of time and memory\nrequirements. Fine-tuning each personalized model needs considerable GPU time\ninvestment, and storing a personalized model per subject can be demanding in\nterms of storage capacity. To overcome these challenges, we propose\nHyperDreamBooth-a hypernetwork capable of efficiently generating a small set of\npersonalized weights from a single image of a person. By composing these\nweights into the diffusion model, coupled with fast finetuning, HyperDreamBooth\ncan generate a person's face in various contexts and styles, with high subject\ndetails while also preserving the model's crucial knowledge of diverse styles\nand semantic modifications. Our method achieves personalization on faces in\nroughly 20 seconds, 25x faster than DreamBooth and 125x faster than Textual\nInversion, using as few as one reference image, with the same quality and style\ndiversity as DreamBooth. Also our method yields a model that is 10000x smaller\nthan a normal DreamBooth model. Project page: https://hyperdreambooth.github.io",
          "link": "http://arxiv.org/abs/2307.06949",
          "publishedOn": "2023-07-14T01:03:52.991Z",
          "wordCount": null,
          "title": "HyperDreamBooth: HyperNetworks for Fast Personalization of Text-to-Image Models. (arXiv:2307.06949v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06701",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adiban_M/0/1/0/all/0/1\">Mohammad Adiban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stefanov_K/0/1/0/all/0/1\">Kalin Stefanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siniscalchi_S/0/1/0/all/0/1\">Sabato Marco Siniscalchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salvi_G/0/1/0/all/0/1\">Giampiero Salvi</a>",
          "description": "We address the video prediction task by putting forth a novel model that\ncombines (i) our recently proposed hierarchical residual vector quantized\nvariational autoencoder (HR-VQVAE), and (ii) a novel spatiotemporal PixelCNN\n(ST-PixelCNN). We refer to this approach as a sequential hierarchical residual\nlearning vector quantized variational autoencoder (S-HR-VQVAE). By leveraging\nthe intrinsic capabilities of HR-VQVAE at modeling still images with a\nparsimonious representation, combined with the ST-PixelCNN's ability at\nhandling spatiotemporal information, S-HR-VQVAE can better deal with chief\nchallenges in video prediction. These include learning spatiotemporal\ninformation, handling high dimensional data, combating blurry prediction, and\nimplicit modeling of physical characteristics. Extensive experimental results\non the KTH Human Action and Moving-MNIST tasks demonstrate that our model\ncompares favorably against top video prediction techniques both in quantitative\nand qualitative evaluations despite a much smaller model size. Finally, we\nboost S-HR-VQVAE by proposing a novel training method to jointly estimate the\nHR-VQVAE and ST-PixelCNN parameters.",
          "link": "http://arxiv.org/abs/2307.06701",
          "publishedOn": "2023-07-14T01:03:52.990Z",
          "wordCount": null,
          "title": "S-HR-VQVAE: Sequential Hierarchical Residual Learning Vector Quantized Variational Autoencoder for Video Prediction. (arXiv:2307.06701v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06713",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Estienne_L/0/1/0/all/0/1\">Lautaro Estienne</a>",
          "description": "A wide variety of natural language tasks are currently being addressed with\nlarge-scale language models (LLMs). These models are usually trained with a\nvery large amount of unsupervised text data and adapted to perform a downstream\nnatural language task using methods like fine-tuning, calibration or in-context\nlearning. In this work, we propose an approach to adapt the prior class\ndistribution to perform text classification tasks without the need for labelled\nsamples and only few in-domain sample queries. The proposed approach treats the\nLLM as a black box, adding a stage where the model posteriors are calibrated to\nthe task. Results show that these methods outperform the un-adapted model for\ndifferent number of training shots in the prompt and a previous approach were\ncalibration is performed without using any adaptation data.",
          "link": "http://arxiv.org/abs/2307.06713",
          "publishedOn": "2023-07-14T01:03:52.987Z",
          "wordCount": null,
          "title": "Unsupervised Calibration through Prior Adaptation for Text Classification using Large Language Models. (arXiv:2307.06713v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruichong Zhang</a>",
          "description": "The learning of Gaussian Mixture Models (also referred to simply as GMMs)\nplays an important role in machine learning. Known for their expressiveness and\ninterpretability, Gaussian mixture models have a wide range of applications,\nfrom statistics, computer vision to distributional reinforcement learning.\nHowever, as of today, few known algorithms can fit or learn these models, some\nof which include Expectation-Maximization algorithms and Sliced Wasserstein\nDistance. Even fewer algorithms are compatible with gradient descent, the\ncommon learning process for neural networks.\n\nIn this paper, we derive a closed formula of two GMMs in the univariate,\none-dimensional case, then propose a distance function called Sliced Cram\\'er\n2-distance for learning general multivariate GMMs. Our approach has several\nadvantages over many previous methods. First, it has a closed-form expression\nfor the univariate case and is easy to compute and implement using common\nmachine learning libraries (e.g., PyTorch and TensorFlow). Second, it is\ncompatible with gradient descent, which enables us to integrate GMMs with\nneural networks seamlessly. Third, it can fit a GMM not only to a set of data\npoints, but also to another GMM directly, without sampling from the target\nmodel. And fourth, it has some theoretical guarantees like global gradient\nboundedness and unbiased sampling gradient. These features are especially\nuseful for distributional reinforcement learning and Deep Q Networks, where the\ngoal is to learn a distribution over future rewards. We will also construct a\nGaussian Mixture Distributional Deep Q Network as a toy example to demonstrate\nits effectiveness. Compared with previous models, this model is parameter\nefficient in terms of representing a distribution and possesses better\ninterpretability.",
          "link": "http://arxiv.org/abs/2307.06753",
          "publishedOn": "2023-07-14T01:03:52.987Z",
          "wordCount": null,
          "title": "Cramer Type Distances for Learning Gaussian Mixture Models by Gradient Descent. (arXiv:2307.06753v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06831",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Caprio_M/0/1/0/all/0/1\">Michele Caprio</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sale_Y/0/1/0/all/0/1\">Yusuf Sale</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hullermeier_E/0/1/0/all/0/1\">Eyke H&#xfc;llermeier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_I/0/1/0/all/0/1\">Insup Lee</a>",
          "description": "In their seminal 1990 paper, Wasserman and Kadane establish an upper bound\nfor the Bayes' posterior probability of a measurable set $A$, when the prior\nlies in a class of probability measures $\\mathcal{P}$ and the likelihood is\nprecise. They also give a sufficient condition for such upper bound to hold\nwith equality. In this paper, we introduce a generalization of their result by\nadditionally addressing uncertainty related to the likelihood. We give an upper\nbound for the posterior probability when both the prior and the likelihood\nbelong to a set of probabilities. Furthermore, we give a sufficient condition\nfor this upper bound to become an equality. This result is interesting on its\nown, and has the potential of being applied to various fields of engineering\n(e.g. model predictive control), machine learning, and artificial intelligence.",
          "link": "http://arxiv.org/abs/2307.06831",
          "publishedOn": "2023-07-14T01:03:52.987Z",
          "wordCount": null,
          "title": "A Novel Bayes' Theorem for Upper Probabilities. (arXiv:2307.06831v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06631",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1\">Dai Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1\">Zhiqi Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Junbin Gao</a>",
          "description": "Knowledge distillation (KD) has shown great potential for transferring\nknowledge from a complex teacher model to a simple student model in which the\nheavy learning task can be accomplished efficiently and without losing too much\nprediction accuracy. Recently, many attempts have been made by applying the KD\nmechanism to the graph representation learning models such as graph neural\nnetworks (GNNs) to accelerate the model's inference speed via student models.\nHowever, many existing KD-based GNNs utilize MLP as a universal approximator in\nthe student model to imitate the teacher model's process without considering\nthe graph knowledge from the teacher model. In this work, we provide a KD-based\nframework on multi-scaled GNNs, known as graph framelet, and prove that by\nadequately utilizing the graph knowledge in a multi-scaled manner provided by\ngraph framelet decomposition, the student model is capable of adapting both\nhomophilic and heterophilic graphs and has the potential of alleviating the\nover-squashing issue with a simple yet effectively graph surgery. Furthermore,\nwe show how the graph knowledge supplied by the teacher is learned and digested\nby the student model via both algebra and geometry. Comprehensive experiments\nshow that our proposed model can generate learning accuracy identical to or\neven surpass the teacher model while maintaining the high speed of inference.",
          "link": "http://arxiv.org/abs/2307.06631",
          "publishedOn": "2023-07-14T01:03:52.986Z",
          "wordCount": null,
          "title": "Frameless Graph Knowledge Distillation. (arXiv:2307.06631v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06406",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Duttweiler_L/0/1/0/all/0/1\">Luke Duttweiler</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Thurston_S/0/1/0/all/0/1\">Sally W. Thurston</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Almudevar_A/0/1/0/all/0/1\">Anthony Almudevar</a>",
          "description": "Bayesian network (BN) structure discovery algorithms typically either make\nassumptions about the sparsity of the true underlying network, or are limited\nby computational constraints to networks with a small number of variables.\nWhile these sparsity assumptions can take various forms, frequently the\nassumptions focus on an upper bound for the maximum in-degree of the underlying\ngraph $\\nabla_G$. Theorem 2 in Duttweiler et. al. (2023) demonstrates that the\nlargest eigenvalue of the normalized inverse covariance matrix ($\\Omega$) of a\nlinear BN is a lower bound for $\\nabla_G$. Building on this result, this paper\nprovides the asymptotic properties of, and a debiasing procedure for, the\nsample eigenvalues of $\\Omega$, leading to a hypothesis test that may be used\nto determine if the BN has max in-degree greater than 1. A linear BN structure\ndiscovery workflow is suggested in which the investigator uses this hypothesis\ntest to aid in selecting an appropriate structure discovery algorithm. The\nhypothesis test performance is evaluated through simulations and the workflow\nis demonstrated on data from a human psoriasis study.",
          "link": "http://arxiv.org/abs/2307.06406",
          "publishedOn": "2023-07-14T01:03:52.984Z",
          "wordCount": null,
          "title": "Testing Sparsity Assumptions in Bayesian Networks. (arXiv:2307.06406v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06518",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Berman_G/0/1/0/all/0/1\">Glen Berman</a>",
          "description": "Machine Learning (ML) systems, particularly when deployed in high-stakes\ndomains, are deeply consequential. They can exacerbate existing inequities,\ncreate new modes of discrimination, and reify outdated social constructs.\nAccordingly, the social context (i.e. organisations, teams, cultures) in which\nML systems are developed is a site of active research for the field of AI\nethics, and intervention for policymakers. This paper focuses on one aspect of\nsocial context that is often overlooked: interactions between practitioners and\nthe tools they rely on, and the role these interactions play in shaping ML\npractices and the development of ML systems. In particular, through an\nempirical study of questions asked on the Stack Exchange forums, the use of\ninteractive computing platforms (e.g. Jupyter Notebook and Google Colab) in ML\npractices is explored. I find that interactive computing platforms are used in\na host of learning and coordination practices, which constitutes an\ninfrastructural relationship between interactive computing platforms and ML\npractitioners. I describe how ML practices are co-evolving alongside the\ndevelopment of interactive computing platforms, and highlight how this risks\nmaking invisible aspects of the ML life cycle that AI ethics researchers' have\ndemonstrated to be particularly salient for the societal impact of deployed ML\nsystems.",
          "link": "http://arxiv.org/abs/2307.06518",
          "publishedOn": "2023-07-14T01:03:52.980Z",
          "wordCount": null,
          "title": "Machine Learning practices and infrastructures. (arXiv:2307.06518v1 [cs.CY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tianlong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiang Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuemei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Caiming Zhang</a>",
          "description": "Time series forecasting has received wide interest from existing research due\nto its broad applications and inherent challenging. The research challenge lies\nin identifying effective patterns in historical series and applying them to\nfuture forecasting. Advanced models based on point-wise connected MLP and\nTransformer architectures have strong fitting power, but their secondary\ncomputational complexity limits practicality. Additionally, those structures\ninherently disrupt the temporal order, reducing the information utilization and\nmaking the forecasting process uninterpretable. To solve these problems, this\npaper proposes a forecasting model, MPR-Net. It first adaptively decomposes\nmulti-scale historical series patterns using convolution operation, then\nconstructs a pattern extension forecasting method based on the prior knowledge\nof pattern reproduction, and finally reconstructs future patterns into future\nseries using deconvolution operation. By leveraging the temporal dependencies\npresent in the time series, MPR-Net not only achieves linear time complexity,\nbut also makes the forecasting process interpretable. By carrying out\nsufficient experiments on more than ten real data sets of both short and long\nterm forecasting tasks, MPR-Net achieves the state of the art forecasting\nperformance, as well as good generalization and robustness performance.",
          "link": "http://arxiv.org/abs/2307.06736",
          "publishedOn": "2023-07-14T01:03:52.979Z",
          "wordCount": null,
          "title": "MPR-Net:Multi-Scale Pattern Reproduction Guided Universality Time Series Interpretable Forecasting. (arXiv:2307.06736v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06775",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feldman_J/0/1/0/all/0/1\">Jonathan Feldman</a>",
          "description": "Over the last decade, there has been a vast increase in eating disorder\ndiagnoses and eating disorder-attributed deaths, reaching their zenith during\nthe Covid-19 pandemic. This immense growth derived in part from the stressors\nof the pandemic but also from increased exposure to social media, which is rife\nwith content that promotes eating disorders. Such content can induce eating\ndisorders in viewers. This study aimed to create a multimodal deep learning\nmodel capable of determining whether a given social media post promotes eating\ndisorders based on a combination of visual and textual data. A labeled dataset\nof Tweets was collected from Twitter, upon which twelve deep learning models\nwere trained and tested. Based on model performance, the most effective deep\nlearning model was the multimodal fusion of the RoBERTa natural language\nprocessing model and the MaxViT image classification model, attaining accuracy\nand F1 scores of 95.9% and 0.959 respectively. The RoBERTa and MaxViT fusion\nmodel, deployed to classify an unlabeled dataset of posts from the social media\nsites Tumblr and Reddit, generated similar classifications as previous research\nstudies that did not employ artificial intelligence, showing that artificial\nintelligence can develop insights congruent to those of researchers.\nAdditionally, the model was used to conduct a time-series analysis of yet\nunseen Tweets from eight Twitter hashtags, uncovering that the relative\nabundance of pro-eating disorder content has decreased drastically. However,\nsince approximately 2018, pro-eating disorder content has either stopped its\ndecline or risen once more in ampleness.",
          "link": "http://arxiv.org/abs/2307.06775",
          "publishedOn": "2023-07-14T01:03:52.979Z",
          "wordCount": null,
          "title": "A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media. (arXiv:2307.06775v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.03854",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Anik_B/0/1/0/all/0/1\">B.M. Tazbiul Hassan Anik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islam_Z/0/1/0/all/0/1\">Zubayer Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdel_Aty_M/0/1/0/all/0/1\">Mohamed Abdel-Aty</a>",
          "description": "The real-time crash likelihood prediction model is an essential component of\nthe proactive traffic safety management system. Over the years, numerous\nstudies have attempted to construct a crash likelihood prediction model in\norder to enhance traffic safety, but mostly on freeways. In the majority of the\nexisting studies, researchers have primarily employed a deep learning-based\nframework to identify crash potential. Lately, Transformer has emerged as a\npotential deep neural network that fundamentally operates through\nattention-based mechanisms. Transformer has several functional benefits over\nextant deep learning models such as Long Short-Term Memory (LSTM), Convolution\nNeural Network (CNN), etc. Firstly, Transformer can readily handle long-term\ndependencies in a data sequence. Secondly, Transformers can parallelly process\nall elements in a data sequence during training. Finally, a Transformer does\nnot have the vanishing gradient issue. Realizing the immense possibility of\nTransformers, this paper proposes inTersection-Transformer (inTformer), a\ntime-embedded attention-based Transformer model that can effectively predict\nintersection crash likelihood in real-time. The proposed model was evaluated\nusing connected vehicle data extracted from INRIX and Center for Advanced\nTransportation Technology (CATT) Lab's Signal Analytics Platform. The data was\nparallelly formatted and stacked at different timesteps to develop nine\ninTformer models. The best inTformer model achieved a sensitivity of 73%. This\nmodel was also compared to earlier studies on crash likelihood prediction at\nintersections and with several established deep learning models trained on the\nsame connected vehicle dataset. In every scenario, this inTformer outperformed\nthe benchmark models confirming the viability of the proposed inTformer\narchitecture.",
          "link": "http://arxiv.org/abs/2307.03854",
          "publishedOn": "2023-07-14T01:03:52.978Z",
          "wordCount": null,
          "title": "inTformer: A Time-Embedded Attention-Based Transformer for Crash Likelihood Prediction at Intersections Using Connected Vehicle Data. (arXiv:2307.03854v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06644",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Colomboni_R/0/1/0/all/0/1\">Roberto Colomboni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esposito_E/0/1/0/all/0/1\">Emmanuel Esposito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paudice_A/0/1/0/all/0/1\">Andrea Paudice</a>",
          "description": "The fat-shattering dimension characterizes the uniform convergence property\nof real-valued functions. The state-of-the-art upper bounds feature a\nmultiplicative squared logarithmic factor on the sample complexity, leaving an\nopen gap with the existing lower bound. We provide an improved uniform\nconvergence bound that closes this gap.",
          "link": "http://arxiv.org/abs/2307.06644",
          "publishedOn": "2023-07-14T01:03:52.976Z",
          "wordCount": null,
          "title": "An Improved Uniform Convergence Bound with Fat-Shattering Dimension. (arXiv:2307.06644v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06709",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Touat_O/0/1/0/all/0/1\">Ousmane Touat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stier_J/0/1/0/all/0/1\">Julian Stier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Portier_P/0/1/0/all/0/1\">Pierre-Edouard Portier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Granitzer_M/0/1/0/all/0/1\">Michael Granitzer</a>",
          "description": "A wide variety of generative models for graphs have been proposed. They are\nused in drug discovery, road networks, neural architecture search, and program\nsynthesis. Generating graphs has theoretical challenges, such as isomorphic\nrepresentations -- evaluating how well a generative model performs is\ndifficult. Which model to choose depending on the application domain?\n\nWe extensively study kernel-based metrics on distributions of graph\ninvariants and manifold-based and kernel-based metrics in graph embedding\nspace. Manifold-based metrics outperform kernel-based metrics in embedding\nspace. We use these metrics to compare GraphRNN and GRAN, two well-known\ngenerative models for graphs, and unveil the influence of node orderings. It\nshows the superiority of GRAN over GraphRNN - further, our proposed adaptation\nof GraphRNN with a depth-first search ordering is effective for small-sized\ngraphs.\n\nA guideline on good practices regarding dataset selection and node feature\ninitialization is provided. Our work is accompanied by open-source code and\nreproducible experiments.",
          "link": "http://arxiv.org/abs/2307.06709",
          "publishedOn": "2023-07-14T01:03:52.974Z",
          "wordCount": null,
          "title": "GRAN is superior to GraphRNN: node orderings, kernel- and graph embeddings-based metrics for graph generators. (arXiv:2307.06709v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06385",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ramakrishnan_K/0/1/0/all/0/1\">Kalyan Ramakrishnan</a>",
          "description": "Audio-Visual Event Localization (AVEL) is the task of temporally localizing\nand classifying \\emph{audio-visual events}, i.e., events simultaneously visible\nand audible in a video. In this paper, we solve AVEL in a weakly-supervised\nsetting, where only video-level event labels (their presence/absence, but not\ntheir locations in time) are available as supervision for training. Our idea is\nto use a base model to estimate labels on the training data at a finer temporal\nresolution than at the video level and re-train the model with these labels.\nI.e., we determine the subset of labels for each \\emph{slice} of frames in a\ntraining video by (i) replacing the frames outside the slice with those from a\nsecond video having no overlap in video-level labels, and (ii) feeding this\nsynthetic video into the base model to extract labels for just the slice in\nquestion. To handle the out-of-distribution nature of our synthetic videos, we\npropose an auxiliary objective for the base model that induces more reliable\npredictions of the localized event labels as desired. Our three-stage pipeline\noutperforms several existing AVEL methods with no architectural changes and\nimproves performance on a related weakly-supervised task as well.",
          "link": "http://arxiv.org/abs/2307.06385",
          "publishedOn": "2023-07-14T01:03:52.970Z",
          "wordCount": null,
          "title": "Temporal Label-Refinement for Weakly-Supervised Audio-Visual Event Localization. (arXiv:2307.06385v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06457",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Simchowitz_M/0/1/0/all/0/1\">Max Simchowitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaiqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Abhishek Gupta</a>",
          "description": "Obtaining rigorous statistical guarantees for generalization under\ndistribution shift remains an open and active research area. We study a setting\nwe call combinatorial distribution shift, where (a) under the test- and\ntraining-distributions, the labels $z$ are determined by pairs of features\n$(x,y)$, (b) the training distribution has coverage of certain marginal\ndistributions over $x$ and $y$ separately, but (c) the test distribution\ninvolves examples from a product distribution over $(x,y)$ that is {not}\ncovered by the training distribution. Focusing on the special case where the\nlabels are given by bilinear embeddings into a Hilbert space $H$: $\\mathbb{E}[z\n\\mid x,y ]=\\langle f_{\\star}(x),g_{\\star}(y)\\rangle_{{H}}$, we aim to\nextrapolate to a test distribution domain that is $not$ covered in training,\ni.e., achieving bilinear combinatorial extrapolation.\n\nOur setting generalizes a special case of matrix completion from\nmissing-not-at-random data, for which all existing results require the\nground-truth matrices to be either exactly low-rank, or to exhibit very sharp\nspectral cutoffs. In this work, we develop a series of theoretical results that\nenable bilinear combinatorial extrapolation under gradual spectral decay as\nobserved in typical high-dimensional data, including novel algorithms,\ngeneralization guarantees, and linear-algebraic results. A key tool is a novel\nperturbation bound for the rank-$k$ singular value decomposition approximations\nbetween two matrices that depends on the relative spectral gap rather than the\nabsolute spectral gap, a result that may be of broader independent interest.",
          "link": "http://arxiv.org/abs/2307.06457",
          "publishedOn": "2023-07-14T01:03:52.970Z",
          "wordCount": null,
          "title": "Tackling Combinatorial Distribution Shift: A Matrix Completion Perspective. (arXiv:2307.06457v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06640",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sakos_I/0/1/0/all/0/1\">Iosif Sakos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varvitsiotis_A/0/1/0/all/0/1\">Antonios Varvitsiotis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piliouras_G/0/1/0/all/0/1\">Georgios Piliouras</a>",
          "description": "Decentralized learning algorithms are an essential tool for designing\nmulti-agent systems, as they enable agents to autonomously learn from their\nexperience and past interactions. In this work, we propose a theoretical and\nalgorithmic framework for real-time identification of the learning dynamics\nthat govern agent behavior using a short burst of a single system trajectory.\nOur method identifies agent dynamics through polynomial regression, where we\ncompensate for limited data by incorporating side-information constraints that\ncapture fundamental assumptions or expectations about agent behavior. These\nconstraints are enforced computationally using sum-of-squares optimization,\nleading to a hierarchy of increasingly better approximations of the true agent\ndynamics. Extensive experiments demonstrated that our approach, using only 5\nsamples from a short run of a single trajectory, accurately recovers the true\ndynamics across various benchmarks, including equilibrium selection and\nprediction of chaotic systems up to 10 Lyapunov times. These findings suggest\nthat our approach has significant potential to support effective policy and\ndecision-making in strategic multi-agent systems.",
          "link": "http://arxiv.org/abs/2307.06640",
          "publishedOn": "2023-07-14T01:03:52.970Z",
          "wordCount": null,
          "title": "Discovering How Agents Learn Using Few Data. (arXiv:2307.06640v1 [cs.GT])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06622",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Rathi_L/0/1/0/all/0/1\">Lakshika Rathi</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+DiAdamo_S/0/1/0/all/0/1\">Stephen DiAdamo</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Shabani_A/0/1/0/all/0/1\">Alireza Shabani</a>",
          "description": "This work investigates the application of quantum machine learning techniques\nfor classical and quantum communication across different qubit channel models.\nBy employing parameterized quantum circuits and a flexible channel noise model,\nwe develop a machine learning framework to generate quantum channel codes and\nevaluate their effectiveness. We explore classical, entanglement-assisted, and\nquantum communication scenarios within our framework. Applying it to various\nquantum channel models as proof of concept, we demonstrate strong performance\nin each case. Our results highlight the potential of quantum machine learning\nin advancing research on quantum communication systems, enabling a better\nunderstanding of capacity bounds under modulation constraints, various\ncommunication settings, and diverse channel models.",
          "link": "http://arxiv.org/abs/2307.06622",
          "publishedOn": "2023-07-14T01:03:52.969Z",
          "wordCount": null,
          "title": "Quantum Autoencoders for Learning Quantum Channel Codes. (arXiv:2307.06622v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.07734",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoo_J/0/1/0/all/0/1\">Jaemin Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tiancheng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akoglu_L/0/1/0/all/0/1\">Leman Akoglu</a>",
          "description": "Self-supervised learning (SSL) has emerged as a promising alternative to\ncreate supervisory signals to real-world problems, avoiding the extensive cost\nof manual labeling. SSL is particularly attractive for unsupervised tasks such\nas anomaly detection (AD), where labeled anomalies are rare or often\nnonexistent. A large catalog of augmentation functions has been used for\nSSL-based AD (SSAD) on image data, and recent works have reported that the type\nof augmentation has a significant impact on accuracy. Motivated by those, this\nwork sets out to put image-based SSAD under a larger lens and investigate the\nrole of data augmentation in SSAD. Through extensive experiments on 3 different\ndetector models and across 420 AD tasks, we provide comprehensive numerical and\nvisual evidences that the alignment between data augmentation and\nanomaly-generating mechanism is the key to the success of SSAD, and in the lack\nthereof, SSL may even impair accuracy. To the best of our knowledge, this is\nthe first meta-analysis on the role of data augmentation in SSAD.",
          "link": "http://arxiv.org/abs/2208.07734",
          "publishedOn": "2023-07-14T01:03:52.969Z",
          "wordCount": null,
          "title": "Data Augmentation is a Hyperparameter: Cherry-picked Self-Supervision for Unsupervised Anomaly Detection is Creating the Illusion of Success. (arXiv:2208.07734v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06924",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shuijing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_A/0/1/0/all/0/1\">Aamir Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_K/0/1/0/all/0/1\">Kaiwen Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Runxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_P/0/1/0/all/0/1\">Peixin Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mizrachi_Z/0/1/0/all/0/1\">Zachary Mizrachi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Justin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McPherson_D/0/1/0/all/0/1\">D. Livingston McPherson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rogers_W/0/1/0/all/0/1\">Wendy A. Rogers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Driggs_Campbell_K/0/1/0/all/0/1\">Katherine Driggs-Campbell</a>",
          "description": "Persons with visual impairments (PwVI) have difficulties understanding and\nnavigating spaces around them. Current wayfinding technologies either focus\nsolely on navigation or provide limited communication about the environment.\nMotivated by recent advances in visual-language grounding and semantic\nnavigation, we propose DRAGON, a guiding robot powered by a dialogue system and\nthe ability to associate the environment with natural language. By\nunderstanding the commands from the user, DRAGON is able to guide the user to\nthe desired landmarks on the map, describe the environment, and answer\nquestions from visual observations. Through effective utilization of dialogue,\nthe robot can ground the user's free-form descriptions to landmarks in the\nenvironment, and give the user semantic information through spoken language. We\nconduct a user study with blindfolded participants in an everyday indoor\nenvironment. Our results demonstrate that DRAGON is able to communicate with\nthe user smoothly, provide a good guiding experience, and connect users with\ntheir surrounding environment in an intuitive manner.",
          "link": "http://arxiv.org/abs/2307.06924",
          "publishedOn": "2023-07-14T01:03:52.964Z",
          "wordCount": null,
          "title": "DRAGON: A Dialogue-Based Robot for Assistive Navigation with Visual Language Grounding. (arXiv:2307.06924v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06343",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_T/0/1/0/all/0/1\">Tianyuan Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lucka_F/0/1/0/all/0/1\">Felix Lucka</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Leeuwen_T/0/1/0/all/0/1\">Tristan van Leeuwen</a>",
          "description": "In X-ray Computed Tomography (CT), projections from many angles are acquired\nand used for 3D reconstruction. To make CT suitable for in-line quality\ncontrol, reducing the number of angles while maintaining reconstruction quality\nis necessary. Sparse-angle tomography is a popular approach for obtaining 3D\nreconstructions from limited data. To optimize its performance, one can adapt\nscan angles sequentially to select the most informative angles for each scanned\nobject. Mathematically, this corresponds to solving and optimal experimental\ndesign (OED) problem. OED problems are high-dimensional, non-convex, bi-level\noptimization problems that cannot be solved online, i.e., during the scan. To\naddress these challenges, we pose the OED problem as a partially observable\nMarkov decision process in a Bayesian framework, and solve it through deep\nreinforcement learning. The approach learns efficient non-greedy policies to\nsolve a given class of OED problems through extensive offline training rather\nthan solving a given OED problem directly via numerical optimization. As such,\nthe trained policy can successfully find the most informative scan angles\nonline. We use a policy training method based on the Actor-Critic approach and\nevaluate its performance on 2D tomography with synthetic data.",
          "link": "http://arxiv.org/abs/2307.06343",
          "publishedOn": "2023-07-14T01:03:52.963Z",
          "wordCount": null,
          "title": "Sequential Experimental Design for X-Ray CT Using Deep Reinforcement Learning. (arXiv:2307.06343v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06645",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mauro_M/0/1/0/all/0/1\">Mario Di Mauro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galatro_G/0/1/0/all/0/1\">Giovanni Galatro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Postiglione_F/0/1/0/all/0/1\">Fabio Postiglione</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_W/0/1/0/all/0/1\">Wei Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liotta_A/0/1/0/all/0/1\">Antonio Liotta</a>",
          "description": "Predicting the behavior of real-time traffic (e.g., VoIP) in mobility\nscenarios could help the operators to better plan their network infrastructures\nand to optimize the allocation of resources. Accordingly, in this work the\nauthors propose a forecasting analysis of crucial QoS/QoE descriptors (some of\nwhich neglected in the technical literature) of VoIP traffic in a real mobile\nenvironment. The problem is formulated in terms of a multivariate time series\nanalysis. Such a formalization allows to discover and model the temporal\nrelationships among various descriptors and to forecast their behaviors for\nfuture periods. Techniques such as Vector Autoregressive models and machine\nlearning (deep-based and tree-based) approaches are employed and compared in\nterms of performance and time complexity, by reframing the multivariate time\nseries problem into a supervised learning one. Moreover, a series of auxiliary\nanalyses (stationarity, orthogonal impulse responses, etc.) are performed to\ndiscover the analytical structure of the time series and to provide deep\ninsights about their relationships. The whole theoretical analysis has an\nexperimental counterpart since a set of trials across a real-world LTE-Advanced\nenvironment has been performed to collect, post-process and analyze about\n600,000 voice packets, organized per flow and differentiated per codec.",
          "link": "http://arxiv.org/abs/2307.06645",
          "publishedOn": "2023-07-14T01:03:52.961Z",
          "wordCount": null,
          "title": "Multivariate Time Series characterization and forecasting of VoIP traffic in real mobile networks. (arXiv:2307.06645v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06341",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Morer_F/0/1/0/all/0/1\">Fidae El Morer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wittek_S/0/1/0/all/0/1\">Stefan Wittek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rausch_A/0/1/0/all/0/1\">Andreas Rausch</a>",
          "description": "The degradation of sewer pipes poses significant economical, environmental\nand health concerns. The maintenance of such assets requires structured plans\nto perform inspections, which are more efficient when structural and\nenvironmental features are considered along with the results of previous\ninspection reports. The development of such plans requires degradation models\nthat can be based on statistical and machine learning methods. This work\nproposes a methodology to assess their suitability to plan inspections\nconsidering three dimensions: accuracy metrics, ability to produce long-term\ndegradation curves and explainability. Results suggest that although ensemble\nmodels yield the highest accuracy, they are unable to infer the long-term\ndegradation of the pipes, whereas the Logistic Regression offers a slightly\nless accurate model that is able to produce consistent degradation curves with\na high explainability. A use case is presented to demonstrate this methodology\nand the efficiency of model-based planning compared to the current inspection\nplan.",
          "link": "http://arxiv.org/abs/2307.06341",
          "publishedOn": "2023-07-14T01:03:52.959Z",
          "wordCount": null,
          "title": "Assessment of the suitability of degradation models for the planning of CCTV inspections of sewer pipes. (arXiv:2307.06341v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06450",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Balkin_R/0/1/0/all/0/1\">Robert Balkin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ceniceros_H/0/1/0/all/0/1\">Hector D. Ceniceros</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hu_R/0/1/0/all/0/1\">Ruimeng Hu</a>",
          "description": "In this paper, we propose a numerical methodology for finding the closed-loop\nNash equilibrium of stochastic delay differential games through deep learning.\nThese games are prevalent in finance and economics where multi-agent\ninteraction and delayed effects are often desired features in a model, but are\nintroduced at the expense of increased dimensionality of the problem. This\nincreased dimensionality is especially significant as that arising from the\nnumber of players is coupled with the potential infinite dimensionality caused\nby the delay. Our approach involves parameterizing the controls of each player\nusing distinct recurrent neural networks. These recurrent neural network-based\ncontrols are then trained using a modified version of Brown's fictitious play,\nincorporating deep learning techniques. To evaluate the effectiveness of our\nmethodology, we test it on finance-related problems with known solutions.\nFurthermore, we also develop new problems and derive their analytical Nash\nequilibrium solutions, which serve as additional benchmarks for assessing the\nperformance of our proposed deep learning approach.",
          "link": "http://arxiv.org/abs/2307.06450",
          "publishedOn": "2023-07-14T01:03:52.954Z",
          "wordCount": 683,
          "title": "Stochastic Delay Differential Games: Financial Modeling and Machine Learning Algorithms. (arXiv:2307.06450v1 [math.OC])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06398",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Timothy Doyeon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Can_T/0/1/0/all/0/1\">Tankut Can</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_K/0/1/0/all/0/1\">Kamesh Krishnamurthy</a>",
          "description": "Understanding how the dynamics in biological and artificial neural networks\nimplement the computations required for a task is a salient open question in\nmachine learning and neuroscience. In particular, computations requiring\ncomplex memory storage and retrieval pose a significant challenge for these\nnetworks to implement or learn. Recently, a family of models described by\nneural ordinary differential equations (nODEs) has emerged as powerful\ndynamical neural network models capable of capturing complex dynamics. Here, we\nextend nODEs by endowing them with adaptive timescales using gating\ninteractions. We refer to these as gated neural ODEs (gnODEs). Using a task\nthat requires memory of continuous quantities, we demonstrate the inductive\nbias of the gnODEs to learn (approximate) continuous attractors. We further\nshow how reduced-dimensional gnODEs retain their modeling power while greatly\nimproving interpretability, even allowing explicit visualization of the\nstructure of learned attractors. We introduce a novel measure of expressivity\nwhich probes the capacity of a neural network to generate complex trajectories.\nUsing this measure, we explore how the phase-space dimension of the nODEs and\nthe complexity of the function modeling the flow field contribute to\nexpressivity. We see that a more complex function for modeling the flow field\nallows a lower-dimensional nODE to capture a given target dynamics. Finally, we\ndemonstrate the benefit of gating in nODEs on several real-world tasks.",
          "link": "http://arxiv.org/abs/2307.06398",
          "publishedOn": "2023-07-14T01:03:52.931Z",
          "wordCount": 730,
          "title": "Trainability, Expressivity and Interpretability in Gated Neural ODEs. (arXiv:2307.06398v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06521",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hasselgren_C/0/1/0/all/0/1\">Catrin Hasselgren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oprea_T/0/1/0/all/0/1\">Tudor I. Oprea</a>",
          "description": "Drug discovery is adapting to novel technologies such as data science,\ninformatics, and artificial intelligence (AI) to accelerate effective treatment\ndevelopment while reducing costs and animal experiments. AI is transforming\ndrug discovery, as indicated by increasing interest from investors, industrial\nand academic scientists, and legislators. Successful drug discovery requires\noptimizing properties related to pharmacodynamics, pharmacokinetics, and\nclinical outcomes. This review discusses the use of AI in the three pillars of\ndrug discovery: diseases, targets, and therapeutic modalities, with a focus on\nsmall molecule drugs. AI technologies, such as generative chemistry, machine\nlearning, and multi-property optimization, have enabled several compounds to\nenter clinical trials. The scientific community must carefully vet known\ninformation to address the reproducibility crisis. The full potential of AI in\ndrug discovery can only be realized with sufficient ground truth and\nappropriate human intervention at later pipeline stages.",
          "link": "http://arxiv.org/abs/2307.06521",
          "publishedOn": "2023-07-14T01:03:52.915Z",
          "wordCount": null,
          "title": "Artificial Intelligence for Drug Discovery: Are We There Yet?. (arXiv:2307.06521v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06556",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Singh_S/0/1/0/all/0/1\">Shivam Singh</a>, <a href=\"http://arxiv.org/find/physics/1/au:+S_S/0/1/0/all/0/1\">Sajana S</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Poornima/0/1/0/all/0/1\">Poornima</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sreelekha_G/0/1/0/all/0/1\">Gajje Sreelekha</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Adak_C/0/1/0/all/0/1\">Chandranath Adak</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Shukla_R/0/1/0/all/0/1\">Rajendra P. Shukla</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kamble_V/0/1/0/all/0/1\">Vinayak Kamble</a>",
          "description": "Detection of Volatile Organic Compounds (VOCs) from the breath is becoming a\nviable route for the early detection of diseases non-invasively. This paper\npresents a sensor array with three metal oxide electrodes that can use machine\nlearning methods to identify four distinct VOCs in a mixture. The metal oxide\nsensor array was subjected to various VOC concentrations, including ethanol,\nacetone, toluene and chloroform. The dataset obtained from individual gases and\ntheir mixtures were analyzed using multiple machine learning algorithms, such\nas Random Forest (RF), K-Nearest Neighbor (KNN), Decision Tree, Linear\nRegression, Logistic Regression, Naive Bayes, Linear Discriminant Analysis,\nArtificial Neural Network, and Support Vector Machine. KNN and RF have shown\nmore than 99% accuracy in classifying different varying chemicals in the gas\nmixtures. In regression analysis, KNN has delivered the best results with R2\nvalue of more than 0.99 and LOD of 0.012, 0.015, 0.014 and 0.025 PPM for\npredicting the concentrations of varying chemicals Acetone, Toluene, Ethanol,\nand Chloroform, respectively in complex mixtures. Therefore, it is demonstrated\nthat the array utilizing the provided algorithms can classify and predict the\nconcentrations of the four gases simultaneously for disease diagnosis and\ntreatment monitoring.",
          "link": "http://arxiv.org/abs/2307.06556",
          "publishedOn": "2023-07-14T01:03:52.913Z",
          "wordCount": 731,
          "title": "Metal Oxide-based Gas Sensor Array for the VOCs Analysis in Complex Mixtures using Machine Learning. (arXiv:2307.06556v1 [physics.app-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06496",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdukhamidov_E/0/1/0/all/0/1\">Eldor Abdukhamidov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abuhamad_M/0/1/0/all/0/1\">Mohammed Abuhamad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woo_S/0/1/0/all/0/1\">Simon S. Woo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_Tin_E/0/1/0/all/0/1\">Eric Chan-Tin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abuhmed_T/0/1/0/all/0/1\">Tamer Abuhmed</a>",
          "description": "Deep learning models are susceptible to adversarial samples in white and\nblack-box environments. Although previous studies have shown high attack\nsuccess rates, coupling DNN models with interpretation models could offer a\nsense of security when a human expert is involved, who can identify whether a\ngiven sample is benign or malicious. However, in white-box environments,\ninterpretable deep learning systems (IDLSes) have been shown to be vulnerable\nto malicious manipulations. In black-box settings, as access to the components\nof IDLSes is limited, it becomes more challenging for the adversary to fool the\nsystem. In this work, we propose a Query-efficient Score-based black-box attack\nagainst IDLSes, QuScore, which requires no knowledge of the target model and\nits coupled interpretation model. QuScore is based on transfer-based and\nscore-based methods by employing an effective microbial genetic algorithm. Our\nmethod is designed to reduce the number of queries necessary to carry out\nsuccessful attacks, resulting in a more efficient process. By continuously\nrefining the adversarial samples created based on feedback scores from the\nIDLS, our approach effectively navigates the search space to identify\nperturbations that can fool the system. We evaluate the attack's effectiveness\non four CNN models (Inception, ResNet, VGG, DenseNet) and two interpretation\nmodels (CAM, Grad), using both ImageNet and CIFAR datasets. Our results show\nthat the proposed approach is query-efficient with a high attack success rate\nthat can reach between 95% and 100% and transferability with an average success\nrate of 69% in the ImageNet and CIFAR datasets. Our attack method generates\nadversarial examples with attribution maps that resemble benign samples. We\nhave also demonstrated that our attack is resilient against various\npreprocessing defense techniques and can easily be transferred to different DNN\nmodels.",
          "link": "http://arxiv.org/abs/2307.06496",
          "publishedOn": "2023-07-14T01:03:52.907Z",
          "wordCount": 808,
          "title": "Microbial Genetic Algorithm-based Black-box Attack against Interpretable Deep Learning Systems. (arXiv:2307.06496v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.11140",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cordonnier_M/0/1/0/all/0/1\">Matthieu Cordonnier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Keriven_N/0/1/0/all/0/1\">Nicolas Keriven</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tremblay_N/0/1/0/all/0/1\">Nicolas Tremblay</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vaiter_S/0/1/0/all/0/1\">Samuel Vaiter</a>",
          "description": "We study the convergence of message passing graph neural networks on random\ngraph models to their continuous counterpart as the number of nodes tends to\ninfinity. Until now, this convergence was only known for architectures with\naggregation functions in the form of normalized means, or, equivalently, of an\napplication of classical operators like the adjacency matrix or the graph\nLaplacian. We extend such results to a large class of aggregation functions,\nthat encompasses all classically used message passing graph neural networks,\nsuch as attention-based message passing, max convolutional message passing or\n(degree-normalized) convolutional message passing. Under mild assumptions, we\ngive non-asymptotic bounds with high probability to quantify this convergence.\nOur main result is based on the McDiarmid inequality. Interestingly, this\nresult does not apply to the case where the aggregation is a coordinate-wise\nmaximum. We treat this case separately and obtain a different convergence rate.",
          "link": "http://arxiv.org/abs/2304.11140",
          "publishedOn": "2023-07-14T01:03:52.890Z",
          "wordCount": null,
          "title": "Convergence of Message Passing Graph Neural Networks with Generic Aggregation On Large Random Graphs. (arXiv:2304.11140v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06555",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shijun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jianfeng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hongkai Zhao</a>",
          "description": "This paper explores the expressive power of deep neural networks for a\ndiverse range of activation functions. An activation function set $\\mathscr{A}$\nis defined to encompass the majority of commonly used activation functions,\nsuch as $\\mathtt{ReLU}$, $\\mathtt{LeakyReLU}$, $\\mathtt{ReLU}^2$,\n$\\mathtt{ELU}$, $\\mathtt{SELU}$, $\\mathtt{Softplus}$, $\\mathtt{GELU}$,\n$\\mathtt{SiLU}$, $\\mathtt{Swish}$, $\\mathtt{Mish}$, $\\mathtt{Sigmoid}$,\n$\\mathtt{Tanh}$, $\\mathtt{Arctan}$, $\\mathtt{Softsign}$, $\\mathtt{dSiLU}$, and\n$\\mathtt{SRS}$. We demonstrate that for any activation function $\\varrho\\in\n\\mathscr{A}$, a $\\mathtt{ReLU}$ network of width $N$ and depth $L$ can be\napproximated to arbitrary precision by a $\\varrho$-activated network of width\n$6N$ and depth $2L$ on any bounded set. This finding enables the extension of\nmost approximation results achieved with $\\mathtt{ReLU}$ networks to a wide\nvariety of other activation functions, at the cost of slightly larger\nconstants.",
          "link": "http://arxiv.org/abs/2307.06555",
          "publishedOn": "2023-07-14T01:03:52.882Z",
          "wordCount": 630,
          "title": "Deep Network Approximation: Beyond ReLU to Diverse Activation Functions. (arXiv:2307.06555v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06540",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yufei Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raga_R/0/1/0/all/0/1\">Rodolfo C. Raga Jr</a>",
          "description": "This study addressed the complex task of sentiment analysis on a dataset of\n119,988 original tweets from Weibo using a Convolutional Neural Network (CNN),\noffering a new approach to Natural Language Processing (NLP). The data, sourced\nfrom Baidu's PaddlePaddle AI platform, were meticulously preprocessed,\ntokenized, and categorized based on sentiment labels. A CNN-based model was\nutilized, leveraging word embeddings for feature extraction, and trained to\nperform sentiment classification. The model achieved a macro-average F1-score\nof approximately 0.73 on the test set, showing balanced performance across\npositive, neutral, and negative sentiments. The findings underscore the\neffectiveness of CNNs for sentiment analysis tasks, with implications for\npractical applications in social media analysis, market research, and policy\nstudies. The complete experimental content and code have been made publicly\navailable on the Kaggle data platform for further research and development.\nFuture work may involve exploring different architectures, such as Recurrent\nNeural Networks (RNN) or transformers, or using more complex pre-trained models\nlike BERT, to further improve the model's ability to understand linguistic\nnuances and context.",
          "link": "http://arxiv.org/abs/2307.06540",
          "publishedOn": "2023-07-14T01:03:52.877Z",
          "wordCount": 699,
          "title": "Convolutional Neural Networks for Sentiment Analysis on Weibo Data: A Natural Language Processing Approach. (arXiv:2307.06540v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06608",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiaming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sang_J/0/1/0/all/0/1\">Jitao Sang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_Q/0/1/0/all/0/1\">Qi Yi</a>",
          "description": "Recently, the no-box adversarial attack, in which the attacker lacks access\nto the model's architecture, weights, and training data, become the most\npractical and challenging attack setup. However, there is an unawareness of the\npotential and flexibility inherent in the surrogate model selection process on\nno-box setting. Inspired by the burgeoning interest in utilizing foundational\nmodels to address downstream tasks, this paper adopts an innovative idea that\n1) recasting adversarial attack as a downstream task. Specifically, image noise\ngeneration to meet the emerging trend and 2) introducing foundational models as\nsurrogate models. Harnessing the concept of non-robust features, we elaborate\non two guiding principles for surrogate model selection to explain why the\nfoundational model is an optimal choice for this role. However, paradoxically,\nwe observe that these foundational models underperform. Analyzing this\nunexpected behavior within the feature space, we attribute the lackluster\nperformance of foundational models (e.g., CLIP) to their significant\nrepresentational capacity and, conversely, their lack of discriminative\nprowess. To mitigate this issue, we propose the use of a margin-based loss\nstrategy for the fine-tuning of foundational models on target images. The\nexperimental results verify that our approach, which employs the basic Fast\nGradient Sign Method (FGSM) attack algorithm, outstrips the performance of\nother, more convoluted algorithms. We conclude by advocating for the research\ncommunity to consider surrogate models as crucial determinants in the\neffectiveness of adversarial attacks in no-box settings. The implications of\nour work bear relevance for improving the efficacy of such adversarial attacks\nand the overall robustness of AI systems.",
          "link": "http://arxiv.org/abs/2307.06608",
          "publishedOn": "2023-07-14T01:03:52.844Z",
          "wordCount": 782,
          "title": "Introducing Foundation Models as Surrogate Models: Advancing Towards More Practical Adversarial Attacks. (arXiv:2307.06608v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06821",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abu_Romoh_M/0/1/0/all/0/1\">Mohannad Abu-Romoh</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Costa_N/0/1/0/all/0/1\">Nelson Costa</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Jaouen_Y/0/1/0/all/0/1\">Yves Jaou&#xeb;n</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Napoli_A/0/1/0/all/0/1\">Antonio Napoli</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Pedro_J/0/1/0/all/0/1\">Jo&#xe3;o Pedro</a> (2,4), <a href=\"http://arxiv.org/find/cs/1/au:+Spinnler_B/0/1/0/all/0/1\">Bernhard Spinnler</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Yousefi_M/0/1/0/all/0/1\">Mansoor Yousefi</a> (1) ((1) Institut Polytechnique de Paris, T&#xe9;l&#xe9;com Paris, Palaiseau, France, (2) Infinera Unipessoal Lda, Carnaxide, Portugal, (3) Infinera, Munich, Germany, (4) Instituto de Telecomunica&#xe7;&#xf5;es, Instituto Superior T&#xe9;cnico, Lisboa, Portugal)",
          "description": "In this paper, we investigate the use of the learned digital back-propagation\n(LDBP) for equalizing dual-polarization fiber-optic transmission in\ndispersion-managed (DM) links. LDBP is a deep neural network that optimizes the\nparameters of DBP using the stochastic gradient descent. We evaluate DBP and\nLDBP in a simulated WDM dual-polarization fiber transmission system operating\nat the bitrate of 256 Gbit/s per channel, with a dispersion map designed for a\n2016 km link with 15% residual dispersion. Our results show that in\nsingle-channel transmission, LDBP achieves an effective signal-to-noise ratio\nimprovement of 6.3 dB and 2.5 dB, respectively, over linear equalization and\nDBP. In WDM transmission, the corresponding $Q$-factor gains are 1.1 dB and 0.4\ndB, respectively. Additionally, we conduct a complexity analysis, which reveals\nthat a frequency-domain implementation of LDBP and DBP is more favorable in\nterms of complexity than the time-domain implementation. These findings\ndemonstrate the effectiveness of LDBP in mitigating the nonlinear effects in DM\nfiber-optic transmission systems.",
          "link": "http://arxiv.org/abs/2307.06821",
          "publishedOn": "2023-07-14T01:03:52.826Z",
          "wordCount": null,
          "title": "Equalization in Dispersion-Managed Systems Using Learned Digital Back-Propagation. (arXiv:2307.06821v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06483",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+TeBlunthuis_N/0/1/0/all/0/1\">Nathan TeBlunthuis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hase_V/0/1/0/all/0/1\">Valerie Hase</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_C/0/1/0/all/0/1\">Chung-Hong Chan</a>",
          "description": "Automated classifiers (ACs), often built via supervised machine learning\n(SML), can categorize large, statistically powerful samples of data ranging\nfrom text to images and video, and have become widely popular measurement\ndevices in communication science and related fields. Despite this popularity,\neven highly accurate classifiers make errors that cause misclassification bias\nand misleading results in downstream analyses-unless such analyses account for\nthese errors. As we show in a systematic literature review of SML applications,\ncommunication scholars largely ignore misclassification bias. In principle,\nexisting statistical methods can use \"gold standard\" validation data, such as\nthat created by human annotators, to correct misclassification bias and produce\nconsistent estimates. We introduce and test such methods, including a new\nmethod we design and implement in the R package misclassificationmodels, via\nMonte Carlo simulations designed to reveal each method's limitations, which we\nalso release. Based on our results, we recommend our new error correction\nmethod as it is versatile and efficient. In sum, automated classifiers, even\nthose below common accuracy standards or making systematic misclassifications,\ncan be useful for measurement with careful study design and appropriate error\ncorrection methods.",
          "link": "http://arxiv.org/abs/2307.06483",
          "publishedOn": "2023-07-14T01:03:52.824Z",
          "wordCount": null,
          "title": "Misclassification in Automated Content Analysis Causes Bias in Regression. Can We Fix It? Yes We Can!. (arXiv:2307.06483v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06431",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Schroder_T/0/1/0/all/0/1\">Tobias Schr&#xf6;der</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ou_Z/0/1/0/all/0/1\">Zijing Ou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lim_J/0/1/0/all/0/1\">Jen Ning Lim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1\">Yingzhen Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vollmer_S/0/1/0/all/0/1\">Sebastian J. Vollmer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Duncan_A/0/1/0/all/0/1\">Andrew B. Duncan</a>",
          "description": "Energy-based models are a simple yet powerful class of probabilistic models,\nbut their widespread adoption has been limited by the computational burden of\ntraining them. We propose a novel loss function called Energy Discrepancy (ED)\nwhich does not rely on the computation of scores or expensive Markov chain\nMonte Carlo. We show that ED approaches the explicit score matching and\nnegative log-likelihood loss under different limits, effectively interpolating\nbetween both. Consequently, minimum ED estimation overcomes the problem of\nnearsightedness encountered in score-based estimation methods, while also\nenjoying theoretical guarantees. Through numerical experiments, we demonstrate\nthat ED learns low-dimensional data distributions faster and more accurately\nthan explicit score matching or contrastive divergence. For high-dimensional\nimage data, we describe how the manifold hypothesis puts limitations on our\napproach and demonstrate the effectiveness of energy discrepancy by training\nthe energy-based model as a prior of a variational decoder model.",
          "link": "http://arxiv.org/abs/2307.06431",
          "publishedOn": "2023-07-14T01:03:52.822Z",
          "wordCount": 654,
          "title": "Energy Discrepancies: A Score-Independent Loss for Energy-Based Models. (arXiv:2307.06431v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06513",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qiuyi/0/1/0/all/0/1\">Qiuyi</a> (Richard) <a href=\"http://arxiv.org/find/cs/1/au:+Zhang/0/1/0/all/0/1\">Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Michael S. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sherol Chen</a>",
          "description": "Beliefs and values are increasingly being incorporated into our AI systems\nthrough alignment processes, such as carefully curating data collection\nprinciples or regularizing the loss function used for training. However, the\nmeta-alignment problem is that these human beliefs are diverse and not aligned\nacross populations; furthermore, the implicit strength of each belief may not\nbe well calibrated even among humans, especially when trying to generalize\nacross contexts. Specifically, in high regret situations, we observe that\ncontextual counterfactuals and recourse costs are particularly important in\nupdating a decision maker's beliefs and the strengths to which such beliefs are\nheld. Therefore, we argue that including counterfactuals is key to an accurate\ncalibration of beliefs during alignment. To do this, we first segment belief\ndiversity into two categories: subjectivity (across individuals within a\npopulation) and epistemic uncertainty (within an individual across different\ncontexts). By leveraging our notion of epistemic uncertainty, we introduce `the\nbelief calibration cycle' framework to more holistically calibrate this\ndiversity of beliefs with context-driven counterfactual reasoning by using a\nmulti-objective optimization. We empirically apply our framework for finding a\nPareto frontier of clustered optimal belief strengths that generalize across\ndifferent contexts, demonstrating its efficacy on a toy dataset for credit\ndecisions.",
          "link": "http://arxiv.org/abs/2307.06513",
          "publishedOn": "2023-07-14T01:03:52.815Z",
          "wordCount": null,
          "title": "Leveraging Contextual Counterfactuals Toward Belief Calibration. (arXiv:2307.06513v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06541",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yiqing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1\">Finale Doshi-Velez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_D/0/1/0/all/0/1\">David Hsu</a>",
          "description": "Inverse reinforcement learning (IRL) algorithms often rely on (forward)\nreinforcement learning or planning over a given time horizon to compute an\napproximately optimal policy for a hypothesized reward function and then match\nthis policy with expert demonstrations. The time horizon plays a critical role\nin determining both the accuracy of reward estimate and the computational\nefficiency of IRL algorithms. Interestingly, an effective time horizon shorter\nthan the ground-truth value often produces better results faster. This work\nformally analyzes this phenomenon and provides an explanation: the time horizon\ncontrols the complexity of an induced policy class and mitigates overfitting\nwith limited data. This analysis leads to a principled choice of the effective\nhorizon for IRL. It also prompts us to reexamine the classic IRL formulation:\nit is more natural to learn jointly the reward and the effective horizon\ntogether rather than the reward alone with a given horizon. Our experimental\nresults confirm the theoretical analysis.",
          "link": "http://arxiv.org/abs/2307.06541",
          "publishedOn": "2023-07-14T01:03:52.773Z",
          "wordCount": 665,
          "title": "On the Effective Horizon of Inverse Reinforcement Learning. (arXiv:2307.06541v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06620",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bastianello_N/0/1/0/all/0/1\">Nicola Bastianello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rikos_A/0/1/0/all/0/1\">Apostolos I. Rikos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johansson_K/0/1/0/all/0/1\">Karl H. Johansson</a>",
          "description": "In this paper we consider online distributed learning problems. Online\ndistributed learning refers to the process of training learning models on\ndistributed data sources. In our setting a set of agents need to cooperatively\ntrain a learning model from streaming data. Differently from federated\nlearning, the proposed approach does not rely on a central server but only on\npeer-to-peer communications among the agents. This approach is often used in\nscenarios where data cannot be moved to a centralized location due to privacy,\nsecurity, or cost reasons. In order to overcome the absence of a central\nserver, we propose a distributed algorithm that relies on a quantized,\nfinite-time coordination protocol to aggregate the locally trained models.\nFurthermore, our algorithm allows for the use of stochastic gradients during\nlocal training. Stochastic gradients are computed using a randomly sampled\nsubset of the local training data, which makes the proposed algorithm more\nefficient and scalable than traditional gradient descent. In our paper, we\nanalyze the performance of the proposed algorithm in terms of the mean distance\nfrom the online solution. Finally, we present numerical results for a logistic\nregression task.",
          "link": "http://arxiv.org/abs/2307.06620",
          "publishedOn": "2023-07-14T01:03:52.750Z",
          "wordCount": 707,
          "title": "Online Distributed Learning with Quantized Finite-Time Coordination. (arXiv:2307.06620v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06581",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lee_H/0/1/0/all/0/1\">Hangbin Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+HA_I/0/1/0/all/0/1\">IL DO HA</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_Y/0/1/0/all/0/1\">Youngjo Lee</a>",
          "description": "For prediction of clustered time-to-event data, we propose a new deep neural\nnetwork based gamma frailty model (DNN-FM). An advantage of the proposed model\nis that the joint maximization of the new h-likelihood provides maximum\nlikelihood estimators for fixed parameters and best unbiased predictors for\nrandom frailties. Thus, the proposed DNN-FM is trained by using a negative\nprofiled h-likelihood as a loss function, constructed by profiling out the\nnon-parametric baseline hazard. Experimental studies show that the proposed\nmethod enhances the prediction performance of the existing methods. A real data\nanalysis shows that the inclusion of subject-specific frailties helps to\nimprove prediction of the DNN based Cox model (DNN-Cox).",
          "link": "http://arxiv.org/abs/2307.06581",
          "publishedOn": "2023-07-14T01:03:52.741Z",
          "wordCount": 615,
          "title": "Deep Neural Networks for Semiparametric Frailty Models via H-likelihood. (arXiv:2307.06581v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06564",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shoush_M/0/1/0/all/0/1\">Mahmoud Shoush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dumas_M/0/1/0/all/0/1\">Marlon Dumas</a>",
          "description": "Prescriptive process monitoring methods seek to optimize the performance of\nbusiness processes by triggering interventions at runtime, thereby increasing\nthe probability of positive case outcomes. These interventions are triggered\naccording to an intervention policy. Reinforcement learning has been put\nforward as an approach to learning intervention policies through trial and\nerror. Existing approaches in this space assume that the number of resources\navailable to perform interventions in a process is unlimited, an unrealistic\nassumption in practice. This paper argues that, in the presence of resource\nconstraints, a key dilemma in the field of prescriptive process monitoring is\nto trigger interventions based not only on predictions of their necessity,\ntimeliness, or effect but also on the uncertainty of these predictions and the\nlevel of resource utilization. Indeed, committing scarce resources to an\nintervention when the necessity or effects of this intervention are highly\nuncertain may intuitively lead to suboptimal intervention effects. Accordingly,\nthe paper proposes a reinforcement learning approach for prescriptive process\nmonitoring that leverages conformal prediction techniques to consider the\nuncertainty of the predictions upon which an intervention decision is based. An\nevaluation using real-life datasets demonstrates that explicitly modeling\nuncertainty using conformal predictions helps reinforcement learning agents\nconverge towards policies with higher net intervention gain",
          "link": "http://arxiv.org/abs/2307.06564",
          "publishedOn": "2023-07-14T01:03:52.731Z",
          "wordCount": 708,
          "title": "Prescriptive Process Monitoring Under Resource Constraints: A Reinforcement Learning Approach. (arXiv:2307.06564v1 [cs.AI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06440",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kaddour_J/0/1/0/all/0/1\">Jean Kaddour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Key_O/0/1/0/all/0/1\">Oscar Key</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nawrot_P/0/1/0/all/0/1\">Piotr Nawrot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minervini_P/0/1/0/all/0/1\">Pasquale Minervini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kusner_M/0/1/0/all/0/1\">Matt J. Kusner</a>",
          "description": "The computation necessary for training Transformer-based language models has\nskyrocketed in recent years. This trend has motivated research on efficient\ntraining algorithms designed to improve training, validation, and downstream\nperformance faster than standard training. In this work, we revisit three\ncategories of such algorithms: dynamic architectures (layer stacking, layer\ndropping), batch selection (selective backprop, RHO loss), and efficient\noptimizers (Lion, Sophia). When pre-training BERT and T5 with a fixed\ncomputation budget using such methods, we find that their training, validation,\nand downstream gains vanish compared to a baseline with a fully-decayed\nlearning rate. We define an evaluation protocol that enables computation to be\ndone on arbitrary machines by mapping all computation time to a reference\nmachine which we call reference system time. We discuss the limitations of our\nproposed protocol and release our code to encourage rigorous research in\nefficient training procedures: https://github.com/JeanKaddour/NoTrainNoGain.",
          "link": "http://arxiv.org/abs/2307.06440",
          "publishedOn": "2023-07-14T01:03:52.720Z",
          "wordCount": 687,
          "title": "No Train No Gain: Revisiting Efficient Training Algorithms For Transformer-based Language Models. (arXiv:2307.06440v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06538",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bakshi_A/0/1/0/all/0/1\">Ainesh Bakshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Allen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1\">Ankur Moitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yau_M/0/1/0/all/0/1\">Morris Yau</a>",
          "description": "Recently Chen and Poor initiated the study of learning mixtures of linear\ndynamical systems. While linear dynamical systems already have wide-ranging\napplications in modeling time-series data, using mixture models can lead to a\nbetter fit or even a richer understanding of underlying subpopulations\nrepresented in the data. In this work we give a new approach to learning\nmixtures of linear dynamical systems that is based on tensor decompositions. As\na result, our algorithm succeeds without strong separation conditions on the\ncomponents, and can be used to compete with the Bayes optimal clustering of the\ntrajectories. Moreover our algorithm works in the challenging\npartially-observed setting. Our starting point is the simple but powerful\nobservation that the classic Ho-Kalman algorithm is a close relative of modern\ntensor decomposition methods for learning latent variable models. This gives us\na playbook for how to extend it to work with more complicated generative\nmodels.",
          "link": "http://arxiv.org/abs/2307.06538",
          "publishedOn": "2023-07-14T01:03:52.697Z",
          "wordCount": 691,
          "title": "Tensor Decompositions Meet Control Theory: Learning General Mixtures of Linear Dynamical Systems. (arXiv:2307.06538v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06534",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yoo_J/0/1/0/all/0/1\">Jaemin Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yue Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Lingxiao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akoglu_L/0/1/0/all/0/1\">Leman Akoglu</a>",
          "description": "Self-supervised learning (SSL) has proven effective in solving various\nproblems by generating internal supervisory signals. Unsupervised anomaly\ndetection, which faces the high cost of obtaining true labels, is an area that\ncan greatly benefit from SSL. However, recent literature suggests that tuning\nthe hyperparameters (HP) of data augmentation functions is crucial to the\nsuccess of SSL-based anomaly detection (SSAD), yet a systematic method for\ndoing so remains unknown. In this work, we propose DSV (Discordance and\nSeparability Validation), an unsupervised validation loss to select\nhigh-performing detection models with effective augmentation HPs. DSV captures\nthe alignment between an augmentation function and the anomaly-generating\nmechanism with surrogate losses, which approximate the discordance and\nseparability of test data, respectively. As a result, the evaluation via DSV\nleads to selecting an effective SSAD model exhibiting better alignment, which\nresults in high detection accuracy. We theoretically derive the degree of\napproximation conducted by the surrogate losses and empirically show that DSV\noutperforms a wide range of baselines on 21 real-world tasks.",
          "link": "http://arxiv.org/abs/2307.06534",
          "publishedOn": "2023-07-14T01:03:52.691Z",
          "wordCount": 684,
          "title": "DSV: An Alignment Validation Loss for Self-supervised Outlier Model Selection. (arXiv:2307.06534v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06693",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lanzieri_L/0/1/0/all/0/1\">Leandro Lanzieri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kietzmann_P/0/1/0/all/0/1\">Peter Kietzmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fey_G/0/1/0/all/0/1\">Goerschwin Fey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schlarb_H/0/1/0/all/0/1\">Holger Schlarb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_T/0/1/0/all/0/1\">Thomas C. Schmidt</a>",
          "description": "Ageing detection and failure prediction are essential in many Internet of\nThings (IoT) deployments, which operate huge quantities of embedded devices\nunattended in the field for years. In this paper, we present a large-scale\nempirical analysis of natural SRAM wear-out using 154 boards from a\ngeneral-purpose testbed. Starting from SRAM initialization bias, which each\nnode can easily collect at startup, we apply various metrics for feature\nextraction and experiment with common machine learning methods to predict the\nage of operation for this node. Our findings indicate that even though ageing\nimpacts are subtle, our indicators can well estimate usage times with an $R^2$\nscore of 0.77 and a mean error of 24% using regressors, and with an F1 score\nabove 0.6 for classifiers applying a six-months resolution.",
          "link": "http://arxiv.org/abs/2307.06693",
          "publishedOn": "2023-07-14T01:03:52.662Z",
          "wordCount": null,
          "title": "Ageing Analysis of Embedded SRAM on a Large-Scale Testbed Using Machine Learning. (arXiv:2307.06693v1 [cs.AR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06698",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thanapalasingam_T/0/1/0/all/0/1\">Thiviyan Thanapalasingam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krieken_E/0/1/0/all/0/1\">Emile van Krieken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bloem_P/0/1/0/all/0/1\">Peter Bloem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Groth_P/0/1/0/all/0/1\">Paul Groth</a>",
          "description": "Knowledge Graph Embedding (KGE) models are used to learn continuous\nrepresentations of entities and relations. A key task in the literature is\npredicting missing links between entities. However, Knowledge Graphs are not\njust sets of links but also have semantics underlying their structure.\nSemantics is crucial in several downstream tasks, such as query answering or\nreasoning. We introduce the subgraph inference task, where a model has to\ngenerate likely and semantically valid subgraphs. We propose IntelliGraphs, a\nset of five new Knowledge Graph datasets. The IntelliGraphs datasets contain\nsubgraphs with semantics expressed in logical rules for evaluating subgraph\ninference. We also present the dataset generator that produced the synthetic\ndatasets. We designed four novel baseline models, which include three models\nbased on traditional KGEs. We evaluate their expressiveness and show that these\nmodels cannot capture the semantics. We believe this benchmark will encourage\nthe development of machine learning models that emphasize semantic\nunderstanding.",
          "link": "http://arxiv.org/abs/2307.06698",
          "publishedOn": "2023-07-14T01:03:52.662Z",
          "wordCount": null,
          "title": "IntelliGraphs: Datasets for Benchmarking Knowledge Graph Generation. (arXiv:2307.06698v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.07306",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1\">Sayak Ray Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saux_P/0/1/0/all/0/1\">Patrick Saux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maillard_O/0/1/0/all/0/1\">Odalric-Ambrym Maillard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopalan_A/0/1/0/all/0/1\">Aditya Gopalan</a>",
          "description": "We revisit the method of mixture technique, also known as the Laplace method,\nto study the concentration phenomenon in generic exponential families.\nCombining the properties of Bregman divergence associated with log-partition\nfunction of the family with the method of mixtures for super-martingales, we\nestablish a generic bound controlling the Bregman divergence between the\nparameter of the family and a finite sample estimate of the parameter. Our\nbound is time-uniform and makes appear a quantity extending the classical\ninformation gain to exponential families, which we call the Bregman information\ngain. For the practitioner, we instantiate this novel bound to several\nclassical families, e.g., Gaussian, Bernoulli, Exponential, Weibull, Pareto,\nPoisson and Chi-square yielding explicit forms of the confidence sets and the\nBregman information gain. We further numerically compare the resulting\nconfidence bounds to state-of-the-art alternatives for time-uniform\nconcentration and show that this novel method yields competitive results.\nFinally, we highlight the benefit of our concentration bounds on some\nillustrative applications.",
          "link": "http://arxiv.org/abs/2201.07306",
          "publishedOn": "2023-07-14T01:03:52.652Z",
          "wordCount": null,
          "title": "Bregman Deviations of Generic Exponential Families. (arXiv:2201.07306v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06362",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Seroussi_I/0/1/0/all/0/1\">Inbar Seroussi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Miron_A/0/1/0/all/0/1\">Asaf Miron</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ringel_Z/0/1/0/all/0/1\">Zohar Ringel</a>",
          "description": "Physically informed neural networks (PINNs) are a promising emerging method\nfor solving differential equations. As in many other deep learning approaches,\nthe choice of PINN design and training protocol requires careful craftsmanship.\nHere, we suggest a comprehensive theoretical framework that sheds light on this\nimportant problem. Leveraging an equivalence between infinitely\nover-parameterized neural networks and Gaussian process regression (GPR), we\nderive an integro-differential equation that governs PINN prediction in the\nlarge data-set limit -- the Neurally-Informed Equation (NIE). This equation\naugments the original one by a kernel term reflecting architecture choices and\nallows quantifying implicit bias induced by the network via a spectral\ndecomposition of the source term in the original differential equation.",
          "link": "http://arxiv.org/abs/2307.06362",
          "publishedOn": "2023-07-14T01:03:52.608Z",
          "wordCount": null,
          "title": "Spectral-Bias and Kernel-Task Alignment in Physically Informed Neural Networks. (arXiv:2307.06362v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06337",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yunshan Chen</a>",
          "description": "The task of incomplete utterance rewriting has recently gotten much\nattention. Previous models struggled to extract information from the dialogue\ncontext, as evidenced by the low restoration scores. To address this issue, we\npropose a novel sequence tagging-based model, which is more adept at extracting\ninformation from context. Meanwhile, we introduce speaker-aware embedding to\nmodel speaker variation. Experiments on multiple public datasets show that our\nmodel achieves optimal results on all nine restoration scores while having\nother metric scores comparable to previous state-of-the-art models.\nFurthermore, benefitting from the model's simplicity, our approach outperforms\nmost previous models on inference speed.",
          "link": "http://arxiv.org/abs/2307.06337",
          "publishedOn": "2023-07-14T01:03:52.593Z",
          "wordCount": null,
          "title": "Incomplete Utterance Rewriting as Sequential Greedy Tagging. (arXiv:2307.06337v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.14586",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Orseau_L/0/1/0/all/0/1\">Laurent Orseau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutter_M/0/1/0/all/0/1\">Marcus Hutter</a>",
          "description": "We extend and combine several tools of the literature to design fast,\nadaptive, anytime and scale-free online learning algorithms. Scale-free regret\nbounds must scale linearly with the maximum loss, both toward large losses and\ntoward very small losses. Adaptive regret bounds demonstrate that an algorithm\ncan take advantage of easy data and potentially have constant regret. We seek\nto develop fast algorithms that depend on as few parameters as possible, in\nparticular they should be anytime and thus not depend on the time horizon. Our\nfirst and main tool, isotuning, is a generalization of the idea of balancing\nthe trade-off of the regret. We develop a set of tools to design and analyze\nsuch learning rates easily and show that they adapts automatically to the rate\nof the regret (whether constant, $O(\\log T)$, $O(\\sqrt{T})$, etc.) within a\nfactor 2 of the optimal learning rate in hindsight for the same observed\nquantities. The second tool is an online correction, which allows us to obtain\ncentered bounds for many algorithms, to prevent the regret bounds from being\nvacuous when the domain is overly large or only partially constrained. The last\ntool, null updates, prevents the algorithm from performing overly large\nupdates, which could result in unbounded regret, or even invalid updates. We\ndevelop a general theory using these tools and apply it to several standard\nalgorithms. In particular, we (almost entirely) restore the adaptivity to small\nlosses of FTRL for unbounded domains, design and prove scale-free adaptive\nguarantees for a variant of Mirror Descent (at least when the Bregman\ndivergence is convex in its second argument), extend Adapt-ML-Prod to\nscale-free guarantees, and provide several other minor contributions about\nProd, AdaHedge, BOA and Soft-Bayes.",
          "link": "http://arxiv.org/abs/2112.14586",
          "publishedOn": "2023-07-12T01:02:47.878Z",
          "wordCount": 810,
          "title": "Isotuning With Applications To Scale-Free Online Learning. (arXiv:2112.14586v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2112.13934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Habib_S/0/1/0/all/0/1\">Salman Habib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beemer_A/0/1/0/all/0/1\">Allison Beemer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kliewer_J/0/1/0/all/0/1\">Joerg Kliewer</a>",
          "description": "In this work we propose RELDEC, a novel approach for sequential decoding of\nmoderate length low-density parity-check (LDPC) codes. The main idea behind\nRELDEC is that an optimized decoding policy is subsequently obtained via\nreinforcement learning based on a Markov decision process (MDP). In contrast to\nour previous work, where an agent learns to schedule only a single check node\n(CN) within a group (cluster) of CNs per iteration, in this work we train the\nagent to schedule all CNs in a cluster, and all clusters in every iteration.\nThat is, in each learning step of RELDEC an agent learns to schedule CN\nclusters sequentially depending on a reward associated with the outcome of\nscheduling a particular cluster. We also modify the state space representation\nof the MDP, enabling RELDEC to be suitable for larger block length LDPC codes\nthan those studied in our previous work. Furthermore, to address decoding under\nvarying channel conditions, we propose agile meta-RELDEC (AM-RELDEC) that\nemploys meta-reinforcement learning. The proposed RELDEC scheme significantly\noutperforms standard flooding and random sequential decoding for a variety of\nLDPC codes, including codes designed for 5G new radio.",
          "link": "http://arxiv.org/abs/2112.13934",
          "publishedOn": "2023-07-12T01:02:47.871Z",
          "wordCount": 731,
          "title": "RELDEC: Reinforcement Learning-Based Decoding of Moderate Length LDPC Codes. (arXiv:2112.13934v2 [cs.IT] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04390",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hu_Y/0/1/0/all/0/1\">Yuqi Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_X/0/1/0/all/0/1\">Xiangyu Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Qing_G/0/1/0/all/0/1\">Gaowei Qing</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xie_K/0/1/0/all/0/1\">Kai Xie</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_C/0/1/0/all/0/1\">Chenglei Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_L/0/1/0/all/0/1\">Lichi Zhang</a>",
          "description": "Background: MR-based subchondral bone effectively predicts knee\nosteoarthritis. However, its clinical application is limited by the cost and\ntime of MR. Purpose: We aim to develop a novel distillation-learning-based\nmethod named SRRD for subchondral bone microstructural analysis using\neasily-acquired CT images, which leverages paired MR images to enhance the\nCT-based analysis model during training. Materials and Methods: Knee joint\nimages of both CT and MR modalities were collected from October 2020 to May\n2021. Firstly, we developed a GAN-based generative model to transform MR images\ninto CT images, which was used to establish the anatomical correspondence\nbetween the two modalities. Next, we obtained numerous patches of subchondral\nbone regions of MR images, together with their trabecular parameters (BV / TV,\nTb. Th, Tb. Sp, Tb. N) from the corresponding CT image patches via regression.\nThe distillation-learning technique was used to train the regression model and\ntransfer MR structural information to the CT-based model. The regressed\ntrabecular parameters were further used for knee osteoarthritis classification.\nResults: A total of 80 participants were evaluated. CT-based regression results\nof trabecular parameters achieved intra-class correlation coefficients (ICCs)\nof 0.804, 0.773, 0.711, and 0.622 for BV / TV, Tb. Th, Tb. Sp, and Tb. N,\nrespectively. The use of distillation learning significantly improved the\nperformance of the CT-based knee osteoarthritis classification method using the\nCNN approach, yielding an AUC score of 0.767 (95% CI, 0.681-0.853) instead of\n0.658 (95% CI, 0.574-0.742) (p<.001). Conclusions: The proposed SRRD method\nshowed high reliability and validity in MR-CT registration, regression, and\nknee osteoarthritis classification, indicating the feasibility of subchondral\nbone microstructural analysis based on CT images.",
          "link": "http://arxiv.org/abs/2307.04390",
          "publishedOn": "2023-07-12T01:02:47.852Z",
          "wordCount": 824,
          "title": "CT-based Subchondral Bone Microstructural Analysis in Knee Osteoarthritis via MR-Guided Distillation Learning. (arXiv:2307.04390v2 [eess.IV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.02497",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mendes_P/0/1/0/all/0/1\">Pedro Mendes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romano_P/0/1/0/all/0/1\">Paolo Romano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garlan_D/0/1/0/all/0/1\">David Garlan</a>",
          "description": "This work focuses on the problem of hyper-parameter tuning (HPT) for robust\n(i.e., adversarially trained) models, shedding light on the new challenges and\nopportunities arising during the HPT process for robust models. To this end, we\nconduct an extensive experimental study based on 3 popular deep models, in\nwhich we explore exhaustively 9 (discretized) HPs, 2 fidelity dimensions, and 2\nattack bounds, for a total of 19208 configurations (corresponding to 50\nthousand GPU hours). Through this study, we show that the complexity of the HPT\nproblem is further exacerbated in adversarial settings due to the need to\nindependently tune the HPs used during standard and adversarial training:\nsucceeding in doing so (i.e., adopting different HP settings in both phases)\ncan lead to a reduction of up to 80% and 43% of the error for clean and\nadversarial inputs, respectively. On the other hand, we also identify new\nopportunities to reduce the cost of HPT for robust models. Specifically, we\npropose to leverage cheap adversarial training methods to obtain inexpensive,\nyet highly correlated, estimations of the quality achievable using\nstate-of-the-art methods. We show that, by exploiting this novel idea in\nconjunction with a recent multi-fidelity optimizer (taKG), the efficiency of\nthe HPT process can be enhanced by up to 2.1x.",
          "link": "http://arxiv.org/abs/2304.02497",
          "publishedOn": "2023-07-12T01:02:47.845Z",
          "wordCount": 721,
          "title": "Hyper-parameter Tuning for Adversarially Robust Models. (arXiv:2304.02497v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2105.06295",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ramli_A/0/1/0/all/0/1\">Albara Ah Ramli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1\">Xin Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Berndt_K/0/1/0/all/0/1\">Kelly Berndt</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Goude_E/0/1/0/all/0/1\">Erica Goude</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hou_J/0/1/0/all/0/1\">Jiahui Hou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kaethler_L/0/1/0/all/0/1\">Lynea B. Kaethler</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_R/0/1/0/all/0/1\">Rex Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lopez_A/0/1/0/all/0/1\">Amanda Lopez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nicorici_A/0/1/0/all/0/1\">Alina Nicorici</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Owens_C/0/1/0/all/0/1\">Corey Owens</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rodriguez_D/0/1/0/all/0/1\">David Rodriguez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1\">Jane Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_H/0/1/0/all/0/1\">Huanle Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Aranki_D/0/1/0/all/0/1\">Daniel Aranki</a>, <a href=\"http://arxiv.org/find/eess/1/au:+McDonald_C/0/1/0/all/0/1\">Craig M. McDonald</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Henricson_E/0/1/0/all/0/1\">Erik K. Henricson</a>",
          "description": "Differences in gait patterns of children with Duchenne muscular dystrophy\n(DMD) and typically-developing (TD) peers are visible to the eye, but\nquantifications of those differences outside of the gait laboratory have been\nelusive. In this work, we measured vertical, mediolateral, and anteroposterior\nacceleration using a waist-worn iPhone accelerometer during ambulation across a\ntypical range of velocities. Fifteen TD and fifteen DMD children from 3-16\nyears of age underwent eight walking/running activities, including five 25\nmeters walk/run speed-calibration tests at a slow walk to running speeds (SC-L1\nto SC-L5), a 6-minute walk test (6MWT), a 100 meters fast-walk/jog/run\n(100MRW), and a free walk (FW). For clinical anchoring purposes, participants\ncompleted a Northstar Ambulatory Assessment (NSAA). We extracted temporospatial\ngait clinical features (CFs) and applied multiple machine learning (ML)\napproaches to differentiate between DMD and TD children using extracted\ntemporospatial gait CFs and raw data. Extracted temporospatial gait CFs showed\nreduced step length and a greater mediolateral component of total power (TP)\nconsistent with shorter strides and Trendelenberg-like gait commonly observed\nin DMD. ML approaches using temporospatial gait CFs and raw data varied in\neffectiveness at differentiating between DMD and TD controls at different\nspeeds, with an accuracy of up to 100%. We demonstrate that by using ML with\naccelerometer data from a consumer-grade smartphone, we can capture\nDMD-associated gait characteristics in toddlers to teens.",
          "link": "http://arxiv.org/abs/2105.06295",
          "publishedOn": "2023-07-12T01:02:47.815Z",
          "wordCount": 825,
          "title": "Gait Characterization in Duchenne Muscular Dystrophy (DMD) Using a Single-Sensor Accelerometer: Classical Machine Learning and Deep Learning Approaches. (arXiv:2105.06295v3 [eess.SP] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.13153",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Wan-Duo Kurt Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_J/0/1/0/all/0/1\">J.P. Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lahiri_A/0/1/0/all/0/1\">Avisek Lahiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leung_T/0/1/0/all/0/1\">Thomas Leung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleijn_W/0/1/0/all/0/1\">W. Bastiaan Kleijn</a>",
          "description": "Text-guided diffusion models such as DALLE-2, Imagen, and Stable Diffusion\nare able to generate an effectively endless variety of images given only a\nshort text prompt describing the desired image content. In many cases the\nimages are of very high quality. However, these models often struggle to\ncompose scenes containing several key objects such as characters in specified\npositional relationships. The missing capability to \"direct\" the placement of\ncharacters and objects both within and across images is crucial in\nstorytelling, as recognized in the literature on film and animation theory. In\nthis work, we take a particularly straightforward approach to providing the\nneeded direction. Drawing on the observation that the cross-attention maps for\nprompt words reflect the spatial layout of objects denoted by those words, we\nintroduce an optimization objective that produces ``activation'' at desired\npositions in these cross-attention maps. The resulting approach is a step\ntoward generalizing the applicability of text-guided diffusion models beyond\nsingle images to collections of related images, as in storybooks. To the best\nof our knowledge, our Directed Diffusion method is the first diffusion\ntechnique that provides positional control over multiple objects, while making\nuse of an existing pre-trained model and maintaining a coherent blend between\nthe positioned objects and the background. Moreover, it requires only a few\nlines to implement.",
          "link": "http://arxiv.org/abs/2302.13153",
          "publishedOn": "2023-07-12T01:02:47.795Z",
          "wordCount": 764,
          "title": "Directed Diffusion: Direct Control of Object Placement through Attention Guidance. (arXiv:2302.13153v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.06210",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Laszkiewicz_M/0/1/0/all/0/1\">Mike Laszkiewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ricker_J/0/1/0/all/0/1\">Jonas Ricker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lederer_J/0/1/0/all/0/1\">Johannes Lederer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischer_A/0/1/0/all/0/1\">Asja Fischer</a>",
          "description": "Recent groundbreaking developments on generative modeling have sparked\ninterest in practical single-model attribution. Such methods predict whether a\nsample was generated by a specific generator or not, for instance, to prove\nintellectual property theft. However, previous works are either limited to the\nclosed-world setting or require undesirable changes of the generative model. We\naddress these shortcomings by proposing FLIPAD, a new approach for single-model\nattribution in the open-world setting based on final-layer inversion and\nanomaly detection. We show that the utilized final-layer inversion can be\nreduced to a convex lasso optimization problem, making our approach\ntheoretically sound and computationally efficient. The theoretical findings are\naccompanied by an experimental study demonstrating the effectiveness of our\napproach, outperforming the existing methods.",
          "link": "http://arxiv.org/abs/2306.06210",
          "publishedOn": "2023-07-12T01:02:47.753Z",
          "wordCount": 643,
          "title": "Single-Model Attribution of Generative Models Through Final-Layer Inversion. (arXiv:2306.06210v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.17303",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Shantanu Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1\">Ke Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batmanghelich_K/0/1/0/all/0/1\">Kayhan Batmanghelich</a>",
          "description": "Building generalizable AI models is one of the primary challenges in the\nhealthcare domain. While radiologists rely on generalizable descriptive rules\nof abnormality, Neural Network (NN) models suffer even with a slight shift in\ninput distribution (e.g., scanner type). Fine-tuning a model to transfer\nknowledge from one domain to another requires a significant amount of labeled\ndata in the target domain. In this paper, we develop an interpretable model\nthat can be efficiently fine-tuned to an unseen target domain with minimal\ncomputational cost. We assume the interpretable component of NN to be\napproximately domain-invariant. However, interpretable models typically\nunderperform compared to their Blackbox (BB) variants. We start with a BB in\nthe source domain and distill it into a \\emph{mixture} of shallow interpretable\nmodels using human-understandable concepts. As each interpretable model covers\na subset of data, a mixture of interpretable models achieves comparable\nperformance as BB. Further, we use the pseudo-labeling technique from\nsemi-supervised learning (SSL) to learn the concept classifier in the target\ndomain, followed by fine-tuning the interpretable models in the target domain.\nWe evaluate our model using a real-life large-scale chest-X-ray (CXR)\nclassification dataset. The code is available at:\n\\url{https://github.com/batmanlab/MICCAI-2023-Route-interpret-repeat-CXRs}.",
          "link": "http://arxiv.org/abs/2305.17303",
          "publishedOn": "2023-07-12T01:02:47.732Z",
          "wordCount": 782,
          "title": "Distilling BlackBox to Interpretable models for Efficient Transfer Learning. (arXiv:2305.17303v7 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.03017",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahmani_S/0/1/0/all/0/1\">Sajjad Rahmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naghshzan_A/0/1/0/all/0/1\">AmirHossein Naghshzan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerrouj_L/0/1/0/all/0/1\">Latifa Guerrouj</a>",
          "description": "Our research investigates the recommendation of code examples to aid software\ndevelopers, a practice that saves developers significant time by providing\nready-to-use code snippets. The focus of our study is Stack Overflow, a\ncommonly used resource for coding discussions and solutions, particularly in\nthe context of the Java programming language.\n\nWe applied BERT, a powerful Large Language Model (LLM) that enables us to\ntransform code examples into numerical vectors by extracting their semantic\ninformation. Once these numerical representations are prepared, we identify\nApproximate Nearest Neighbors (ANN) using Locality-Sensitive Hashing (LSH). Our\nresearch employed two variants of LSH: Random Hyperplane-based LSH and\nQuery-Aware LSH. We rigorously compared these two approaches across four\nparameters: HitRate, Mean Reciprocal Rank (MRR), Average Execution Time, and\nRelevance.\n\nOur study revealed that the Query-Aware (QA) approach showed superior\nperformance over the Random Hyperplane-based (RH) method. Specifically, it\nexhibited a notable improvement of 20% to 35% in HitRate for query pairs\ncompared to the RH approach. Furthermore, the QA approach proved significantly\nmore time-efficient, with its speed in creating hashing tables and assigning\ndata samples to buckets being at least four times faster. It can return code\nexamples within milliseconds, whereas the RH approach typically requires\nseveral seconds to recommend code examples. Due to the superior performance of\nthe QA approach, we tested it against PostFinder and FaCoY, the\nstate-of-the-art baselines. Our QA method showed comparable efficiency proving\nits potential for effective code recommendation.",
          "link": "http://arxiv.org/abs/2305.03017",
          "publishedOn": "2023-07-12T01:02:47.724Z",
          "wordCount": 785,
          "title": "Improving Code Example Recommendations on Informal Documentation Using BERT and Query-Aware LSH: A Comparative Study. (arXiv:2305.03017v2 [cs.SE] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.06959",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuxuan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leeuwen_M/0/1/0/all/0/1\">Matthijs van Leeuwen</a>",
          "description": "In the past two decades, most research on anomaly detection has focused on\nimproving the accuracy of the detection, while largely ignoring the\nexplainability of the corresponding methods and thus leaving the explanation of\noutcomes to practitioners. As anomaly detection algorithms are increasingly\nused in safety-critical domains, providing explanations for the high-stakes\ndecisions made in those domains has become an ethical and regulatory\nrequirement. Therefore, this work provides a comprehensive and structured\nsurvey on state-of-the-art explainable anomaly detection techniques. We propose\na taxonomy based on the main aspects that characterize each explainable anomaly\ndetection technique, aiming to help practitioners and researchers find the\nexplainable anomaly detection method that best suits their needs.",
          "link": "http://arxiv.org/abs/2210.06959",
          "publishedOn": "2023-07-12T01:02:47.718Z",
          "wordCount": 642,
          "title": "A Survey on Explainable Anomaly Detection. (arXiv:2210.06959v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.07996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yuesheng Xu</a>",
          "description": "This paper introduces a successive affine learning (SAL) model for\nconstructing deep neural networks (DNNs). Traditionally, a DNN is built by\nsolving a non-convex optimization problem. It is often challenging to solve\nsuch a problem numerically due to its non-convexity and having a large number\nof layers. To address this challenge, inspired by the human education system,\nthe multi-grade deep learning (MGDL) model was recently initiated by the author\nof this paper. The MGDL model learns a DNN in several grades, in each of which\none constructs a shallow DNN consisting of a relatively small number of layers.\nThe MGDL model still requires solving several non-convex optimization problems.\nThe proposed SAL model mutates from the MGDL model. Noting that each layer of a\nDNN consists of an affine map followed by an activation function, we propose to\nlearn the affine map by solving a quadratic/convex optimization problem which\ninvolves the activation function only {\\it after} the weight matrix and the\nbias vector for the current layer have been trained. In the context of function\napproximation, for a given function the SAL model generates an expansion of the\nfunction with adaptive basis functions in the form of DNNs. We establish the\nPythagorean identity and the Parseval identity for the system generated by the\nSAL model. Moreover, we provide a convergence theorem of the SAL process in the\nsense that either it terminates after a finite number of grades or the norms of\nits optimal error functions strictly decrease to a limit as the grade number\nincreases to infinity. Furthermore, we present numerical examples of proof of\nconcept which demonstrate that the proposed SAL model significantly outperforms\nthe traditional deep learning model.",
          "link": "http://arxiv.org/abs/2305.07996",
          "publishedOn": "2023-07-12T01:02:47.712Z",
          "wordCount": 795,
          "title": "Successive Affine Learning for Deep Neural Networks. (arXiv:2305.07996v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.12636",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sluijs_R/0/1/0/all/0/1\">Rogier van der Sluijs</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bhaskhar_N/0/1/0/all/0/1\">Nandita Bhaskhar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel Rubin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Langlotz_C/0/1/0/all/0/1\">Curtis Langlotz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chaudhari_A/0/1/0/all/0/1\">Akshay Chaudhari</a>",
          "description": "Image augmentations are quintessential for effective visual representation\nlearning across self-supervised learning techniques. While augmentation\nstrategies for natural imaging have been studied extensively, medical images\nare vastly different from their natural counterparts. Thus, it is unknown\nwhether common augmentation strategies employed in Siamese representation\nlearning generalize to medical images and to what extent. To address this\nchallenge, in this study, we systematically assess the effect of various\naugmentations on the quality and robustness of the learned representations. We\ntrain and evaluate Siamese Networks for abnormality detection on chest X-Rays\nacross three large datasets (MIMIC-CXR, CheXpert and VinDR-CXR). We investigate\nthe efficacy of the learned representations through experiments involving\nlinear probing, fine-tuning, zero-shot transfer, and data efficiency. Finally,\nwe identify a set of augmentations that yield robust representations that\ngeneralize well to both out-of-distribution data and diseases, while\noutperforming supervised baselines using just zero-shot transfer and linear\nprobes by up to 20%. Our code is available at\nhttps://github.com/StanfordMIMI/siaug.",
          "link": "http://arxiv.org/abs/2301.12636",
          "publishedOn": "2023-07-12T01:02:47.691Z",
          "wordCount": 747,
          "title": "Exploring Image Augmentations for Siamese Representation Learning with Chest X-Rays. (arXiv:2301.12636v2 [eess.IV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.04934",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Buehler_M/0/1/0/all/0/1\">Markus J. Buehler</a>",
          "description": "We report a flexible language-model based deep learning strategy, applied\nhere to solve complex forward and inverse problems in protein modeling, based\non an attention neural network that integrates transformer and graph\nconvolutional architectures in a causal multi-headed graph mechanism, to\nrealize a generative pretrained model. The model is applied to predict\nsecondary structure content (per-residue level and overall content), protein\nsolubility, and sequencing tasks. Further trained on inverse tasks, the model\nis rendered capable of designing proteins with these properties as target\nfeatures. The model is formulated as a general framework, completely\nprompt-based, and can be adapted for a variety of downstream tasks. We find\nthat adding additional tasks yields emergent synergies that the model exploits\nin improving overall performance, beyond what would be possible by training a\nmodel on each dataset alone. Case studies are presented to validate the method,\nyielding protein designs specifically focused on structural proteins, but also\nexploring the applicability in the design of soluble, antimicrobial\nbiomaterials. While our model is trained to ultimately perform 8 distinct\ntasks, with available datasets it can be extended to solve additional problems.\nIn a broader sense, this work illustrates a form of multiscale modeling that\nrelates a set of ultimate building blocks (here, byte-level utf8 characters\nthat define the nature of the physical system at hand) to complex output. This\nmateriomic scheme captures complex emergent relationships between universal\nbuilding block and resulting properties via a synergizing learning capacity to\nexpress a set of potentialities embedded in the knowledge used in training, via\nthe interplay of universality and diversity.",
          "link": "http://arxiv.org/abs/2305.04934",
          "publishedOn": "2023-07-12T01:02:47.684Z",
          "wordCount": 810,
          "title": "Generative Pretrained Autoregressive Transformer Graph Neural Network applied to the Analysis and Discovery of Novel Proteins. (arXiv:2305.04934v2 [q-bio.BM] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.04318",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Grillo_M/0/1/0/all/0/1\">Milo Grillo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Han_Y/0/1/0/all/0/1\">Yunpeng Han</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Werpachowska_A/0/1/0/all/0/1\">Agnieszka Werpachowska</a>",
          "description": "We propose a simple and efficient approach to generate a prediction intervals\n(PI) for approximated and forecasted trends. Our method leverages a weighted\nasymmetric loss function to estimate the lower and upper bounds of the PI, with\nthe weights determined by its coverage probability. We provide a concise\nmathematical proof of the method, show how it can be extended to derive PIs for\nparametrised functions and argue why the method works for predicting PIs of\ndependent variables. The presented tests of the method on a real-world\nforecasting task using a neural network-based model show that it can produce\nreliable PIs in complex machine learning scenarios.",
          "link": "http://arxiv.org/abs/2210.04318",
          "publishedOn": "2023-07-12T01:02:47.666Z",
          "wordCount": 656,
          "title": "Prediction intervals for neural network models using weighted asymmetric loss functions. (arXiv:2210.04318v4 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.03419",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geerkens_S/0/1/0/all/0/1\">Simon Geerkens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sieberichs_C/0/1/0/all/0/1\">Christian Sieberichs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Braun_A/0/1/0/all/0/1\">Alexander Braun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waschulzik_T/0/1/0/all/0/1\">Thomas Waschulzik</a>",
          "description": "The importance of high data quality is increasing with the growing impact and\ndistribution of ML systems and big data. Also the planned AI Act from the\nEuropean commission defines challenging legal requirements for data quality\nespecially for the market introduction of safety relevant ML systems. In this\npaper we introduce a novel approach that supports the data quality assurance\nprocess of multiple data quality aspects. This approach enables the\nverification of quantitative data quality requirements. The concept and\nbenefits are introduced and explained on small example data sets. How the\nmethod is applied is demonstrated on the well known MNIST data set based an\nhandwritten digits.",
          "link": "http://arxiv.org/abs/2307.03419",
          "publishedOn": "2023-07-12T01:02:47.659Z",
          "wordCount": 642,
          "title": "QI2 -- an Interactive Tool for Data Quality Assurance. (arXiv:2307.03419v2 [cs.CY] CROSS LISTED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2108.11644",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Gircha_A/0/1/0/all/0/1\">A.I. Gircha</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Boev_A/0/1/0/all/0/1\">A.S. Boev</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Avchaciov_K/0/1/0/all/0/1\">K. Avchaciov</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Fedichev_P/0/1/0/all/0/1\">P.O. Fedichev</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Fedorov_A/0/1/0/all/0/1\">A.K. Fedorov</a>",
          "description": "Deep generative chemistry models emerge as powerful tools to expedite drug\ndiscovery. However, the immense size and complexity of the structural space of\nall possible drug-like molecules pose significant obstacles, which could be\novercome with hybrid architectures combining quantum computers with deep\nclassical networks. As the first step toward this goal, we built a compact\ndiscrete variational autoencoder (DVAE) with a Restricted Boltzmann Machine\n(RBM) of reduced size in its latent layer. The size of the proposed model was\nsmall enough to fit on a state-of-the-art D-Wave quantum annealer and allowed\ntraining on a subset of the ChEMBL dataset of biologically active compounds.\nFinally, we generated 2331 novel chemical structures with medicinal chemistry\nand synthetic accessibility properties in the ranges typical for molecules from\nChEMBL. The presented results demonstrate the feasibility of using already\nexisting or soon-to-be-available quantum computing devices as testbeds for\nfuture drug discovery applications.",
          "link": "http://arxiv.org/abs/2108.11644",
          "publishedOn": "2023-07-12T01:02:47.643Z",
          "wordCount": 709,
          "title": "Hybrid quantum-classical machine learning for generative chemistry and drug design. (arXiv:2108.11644v2 [quant-ph] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.08618",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1\">Aina Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_P/0/1/0/all/0/1\">Pan Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xi-Ming Sun</a>",
          "description": "Partial differential equations (PDEs) are a model candidate for soft sensors\nin industrial processes with spatiotemporal dependence. Although\nphysics-informed neural networks (PINNs) are a promising machine learning\nmethod for solving PDEs, they are infeasible for the nonhomogeneous PDEs with\nunmeasurable source terms. To this end, a coupled PINN (CPINN) with a recurrent\nprediction (RP) learning strategy (CPINN- RP) is proposed. First, CPINN\ncomposed of NetU and NetG is proposed. NetU is for approximating PDEs solutions\nand NetG is for regularizing the training of NetU. The two networks are\nintegrated into a data-physics-hybrid loss function. Then, we theoretically\nprove that the proposed CPINN has a satisfying approximation capability for\nsolutions to nonhomogeneous PDEs with unmeasurable source terms. Besides the\ntheoretical aspects, we propose a hierarchical training strategy to optimize\nand couple NetU and NetG. Secondly, NetU-RP is proposed for compensating\ninformation loss in data sampling to improve the prediction performance, in\nwhich RP is the recurrently delayed outputs of well-trained CPINN and hard\nsensors. Finally, the artificial and practical datasets are used to verify the\nfeasibility and effectiveness of CPINN-RP for soft sensors.",
          "link": "http://arxiv.org/abs/2301.08618",
          "publishedOn": "2023-07-12T01:02:47.473Z",
          "wordCount": 754,
          "title": "Solving PDEs with Unmeasurable Source Terms Using Coupled Physics-Informed Neural Network with Recurrent Prediction for Soft Sensors. (arXiv:2301.08618v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04679",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scaman_K/0/1/0/all/0/1\">Kevin Scaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Even_M/0/1/0/all/0/1\">Mathieu Even</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Massoulie_L/0/1/0/all/0/1\">Laurent Massouli&#xe9;</a>",
          "description": "In this paper, we provide a novel framework for the analysis of\ngeneralization error of first-order optimization algorithms for statistical\nlearning when the gradient can only be accessed through partial observations\ngiven by an oracle. Our analysis relies on the regularity of the gradient\nw.r.t. the data samples, and allows to derive near matching upper and lower\nbounds for the generalization error of multiple learning problems, including\nsupervised learning, transfer learning, robust learning, distributed learning\nand communication efficient learning using gradient quantization. These results\nhold for smooth and strongly-convex optimization problems, as well as smooth\nnon-convex optimization problems verifying a Polyak-Lojasiewicz assumption. In\nparticular, our upper and lower bounds depend on a novel quantity that extends\nthe notion of conditional standard deviation, and is a measure of the extent to\nwhich the gradient can be approximated by having access to the oracle. As a\nconsequence, our analysis provides a precise meaning to the intuition that\noptimization of the statistical learning objective is as hard as the estimation\nof its gradient. Finally, we show that, in the case of standard supervised\nlearning, mini-batch gradient descent with increasing batch sizes and a warm\nstart can reach a generalization error that is optimal up to a multiplicative\nfactor, thus motivating the use of this optimization scheme in practical\napplications.",
          "link": "http://arxiv.org/abs/2307.04679",
          "publishedOn": "2023-07-12T01:02:47.466Z",
          "wordCount": 761,
          "title": "Generalization Error of First-Order Methods for Statistical Learning with Generic Oracles. (arXiv:2307.04679v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.12045",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Ma_G/0/1/0/all/0/1\">Gehua Ma</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Jiang_R/0/1/0/all/0/1\">Runhao Jiang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Yan_R/0/1/0/all/0/1\">Rui Yan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Tang_H/0/1/0/all/0/1\">Huajin Tang</a>",
          "description": "Developing computational models of neural response is crucial for\nunderstanding sensory processing and neural computations. Current\nstate-of-the-art neural network methods use temporal filters to handle temporal\ndependencies, resulting in an unrealistic and inflexible processing flow.\nMeanwhile, these methods target trial-averaged firing rates and fail to capture\nimportant features in spike trains. This work presents the temporal\nconditioning spiking latent variable models (TeCoS-LVM) to simulate the neural\nresponse to natural visual stimuli. We use spiking neurons to produce spike\noutputs that directly match the recorded trains. This approach helps to avoid\nlosing information embedded in the original spike trains. We exclude the\ntemporal dimension from the model parameter space and introduce a temporal\nconditioning operation to allow the model to adaptively explore and exploit\ntemporal dependencies in stimuli sequences in a natural paradigm. We show that\nTeCoS-LVM models can produce more realistic spike activities and accurately fit\nspike statistics than powerful alternatives. Additionally, learned TeCoS-LVM\nmodels can generalize well to longer time scales. Overall, while remaining\ncomputationally tractable, our model effectively captures key features of\nneural coding systems. It thus provides a useful tool for building accurate\npredictive computational accounts for various sensory perception circuits.",
          "link": "http://arxiv.org/abs/2306.12045",
          "publishedOn": "2023-07-12T01:02:47.459Z",
          "wordCount": 771,
          "title": "Temporal Conditioning Spiking Latent Variable Models of the Neural Response to Natural Visual Scenes. (arXiv:2306.12045v2 [q-bio.NC] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.02168",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_T/0/1/0/all/0/1\">Tejas Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_F/0/1/0/all/0/1\">Furong Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rostami_M/0/1/0/all/0/1\">Mohammad Rostami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thomason_J/0/1/0/all/0/1\">Jesse Thomason</a>",
          "description": "Adapters present a promising solution to the catastrophic forgetting problem\nin continual learning. However, training independent Adapter modules for every\nnew task misses an opportunity for cross-task knowledge transfer. We propose\nImprovise to Initialize (I2I), a continual learning algorithm that initializes\nAdapters for incoming tasks by distilling knowledge from previously-learned\ntasks' Adapters. We evaluate I2I on CLiMB, a multimodal continual learning\nbenchmark, by conducting experiments on sequences of visual question answering\ntasks. Adapters trained with I2I consistently achieve better task accuracy than\nindependently-trained Adapters, demonstrating that our algorithm facilitates\nknowledge transfer between task Adapters. I2I also results in better cross-task\nknowledge transfer than the state-of-the-art AdapterFusion without incurring\nthe associated parametric cost.",
          "link": "http://arxiv.org/abs/2304.02168",
          "publishedOn": "2023-07-12T01:02:47.453Z",
          "wordCount": 646,
          "title": "I2I: Initializing Adapters with Improvised Knowledge. (arXiv:2304.02168v2 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2203.13739",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Marshall_S/0/1/0/all/0/1\">Simon C. Marshall</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gyurik_C/0/1/0/all/0/1\">Casper Gyurik</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Dunjko_V/0/1/0/all/0/1\">Vedran Dunjko</a>",
          "description": "Quantum computers hold great promise to enhance machine learning, but their\ncurrent qubit counts restrict the realisation of this promise. In an attempt to\nplacate this limitation techniques can be applied for evaluating a quantum\ncircuit using a machine with fewer qubits than the circuit naively requires.\nThese techniques work by evaluating many smaller circuits on the smaller\nmachine, that are then combined in a polynomial to replicate the output of the\nlarger machine. This scheme requires more circuit evaluations than are\npractical for general circuits. However, we investigate the possibility that\nfor certain applications many of these subcircuits are superfluous, and that a\nmuch smaller sum is sufficient to estimate the full circuit. We construct a\nmachine learning model that may be capable of approximating the outputs of the\nlarger circuit with much fewer circuit evaluations. We successfully apply our\nmodel to the task of digit recognition, using simulated quantum computers much\nsmaller than the data dimension. The model is also applied to the task of\napproximating a random 10 qubit PQC with simulated access to a 5 qubit\ncomputer, even with only relatively modest number of circuits our model\nprovides an accurate approximation of the 10 qubit PQCs output, superior to a\nneural network attempt. The developed method might be useful for implementing\nquantum models on larger data throughout the NISQ era.",
          "link": "http://arxiv.org/abs/2203.13739",
          "publishedOn": "2023-07-12T01:02:47.426Z",
          "wordCount": null,
          "title": "High Dimensional Quantum Machine Learning With Small Quantum Computers. (arXiv:2203.13739v3 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05382",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Li_Z/0/1/0/all/0/1\">Ziyue Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fang_Y/0/1/0/all/0/1\">Yuchen Fang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">You Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ren_K/0/1/0/all/0/1\">Kan Ren</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1\">Yansen Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Luo_X/0/1/0/all/0/1\">Xufang Luo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Duan_J/0/1/0/all/0/1\">Juanyong Duan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_C/0/1/0/all/0/1\">Congrui Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_D/0/1/0/all/0/1\">Dongsheng Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Qiu_L/0/1/0/all/0/1\">Lili Qiu</a>",
          "description": "A timely detection of seizures for newborn infants with electroencephalogram\n(EEG) has been a common yet life-saving practice in the Neonatal Intensive Care\nUnit (NICU). However, it requires great human efforts for real-time monitoring,\nwhich calls for automated solutions to neonatal seizure detection. Moreover,\nthe current automated methods focusing on adult epilepsy monitoring often fail\ndue to (i) dynamic seizure onset location in human brains; (ii) different\nmontages on neonates and (iii) huge distribution shift among different\nsubjects. In this paper, we propose a deep learning framework, namely STATENet,\nto address the exclusive challenges with exquisite designs at the temporal,\nspatial and model levels. The experiments over the real-world large-scale\nneonatal EEG dataset illustrate that our framework achieves significantly\nbetter seizure detection performance.",
          "link": "http://arxiv.org/abs/2307.05382",
          "publishedOn": "2023-07-12T01:02:46.982Z",
          "wordCount": null,
          "title": "Protecting the Future: Neonatal Seizure Detection with Spatial-Temporal Modeling. (arXiv:2307.05382v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.08933",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Verma_N/0/1/0/all/0/1\">Nikhil Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prasad_K/0/1/0/all/0/1\">Krishna Prasad</a>",
          "description": "Recruiters can easily shortlist candidates for jobs via viewing their\ncurriculum vitae (CV) document. Unstructured document CV beholds candidate's\nportfolio and named entities listing details. The main aim of this study is to\ndesign and propose a web oriented, highly responsive, computational pipeline\nthat systematically predicts CV entities using hierarchically-refined label\nattention networks. Deep learning models specialized for named entity\nrecognition were trained on large dataset to predict relevant fields. The\narticle suggests an optimal strategy to use a number of deep learning models in\nparallel and predict in real time. We demonstrate selection of light weight\nmicro web framework using Analytical Hierarchy Processing algorithm and focus\non an approach useful to deploy large deep learning model-based pipelines in\nproduction ready environments using microservices. Deployed models and\narchitecture proposed helped in parsing normal CV in less than 700 milliseconds\nfor sequential flow of requests.",
          "link": "http://arxiv.org/abs/2112.08933",
          "publishedOn": "2023-07-12T01:02:46.982Z",
          "wordCount": null,
          "title": "Responsive parallelized architecture for deploying deep learning models in production environments. (arXiv:2112.08933v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jeon_J/0/1/0/all/0/1\">Jaeheyoung Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryu_J/0/1/0/all/0/1\">Jung Hyun Ryu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1\">Jewoong Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1\">Myungjoo Kang</a>",
          "description": "This paper presents a solution to the challenges faced by contrastive\nlearning in sequential recommendation systems. In particular, it addresses the\nissue of false negative, which limits the effectiveness of recommendation\nalgorithms. By introducing an advanced approach to contrastive learning, the\nproposed method improves the quality of item embeddings and mitigates the\nproblem of falsely categorizing similar instances as dissimilar. Experimental\nresults demonstrate performance enhancements compared to existing systems. The\nflexibility and applicability of the proposed approach across various\nrecommendation scenarios further highlight its value in enhancing sequential\nrecommendation systems.",
          "link": "http://arxiv.org/abs/2307.05469",
          "publishedOn": "2023-07-12T01:02:46.981Z",
          "wordCount": null,
          "title": "AdaptiveRec: Adaptively Construct Pairs for Contrastive Learning in Sequential Recommendation. (arXiv:2307.05469v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.16170",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shiji Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xizhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xingxing Wei</a>",
          "description": "Adversarial training is a practical approach for improving the robustness of\ndeep neural networks against adversarial attacks. Although bringing reliable\nrobustness, the performance toward clean examples is negatively affected after\nadversarial training, which means a trade-off exists between accuracy and\nrobustness. Recently, some studies have tried to use knowledge distillation\nmethods in adversarial training, achieving competitive performance in improving\nthe robustness but the accuracy for clean samples is still limited. In this\npaper, to mitigate the accuracy-robustness trade-off, we introduce the\nMulti-Teacher Adversarial Robustness Distillation (MTARD) to guide the model's\nadversarial training process by applying a strong clean teacher and a strong\nrobust teacher to handle the clean examples and adversarial examples,\nrespectively. During the optimization process, to ensure that different\nteachers show similar knowledge scales, we design the Entropy-Based Balance\nalgorithm to adjust the teacher's temperature and keep the teachers'\ninformation entropy consistent. Besides, to ensure that the student has a\nrelatively consistent learning speed from multiple teachers, we propose the\nNormalization Loss Balance algorithm to adjust the learning weights of\ndifferent types of knowledge. A series of experiments conducted on public\ndatasets demonstrate that MTARD outperforms the state-of-the-art adversarial\ntraining and distillation methods against various adversarial attacks.",
          "link": "http://arxiv.org/abs/2306.16170",
          "publishedOn": "2023-07-12T01:02:46.981Z",
          "wordCount": null,
          "title": "Mitigating the Accuracy-Robustness Trade-off via Multi-Teacher Adversarial Distillation. (arXiv:2306.16170v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.13825",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Peiyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yuchen Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chaozhuo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Senzhang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_G/0/1/0/all/0/1\">Guojie Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sunghun Kim</a>",
          "description": "Many real-world graph learning tasks require handling dynamic graphs where\nnew nodes and edges emerge. Dynamic graph learning methods commonly suffer from\nthe catastrophic forgetting problem, where knowledge learned for previous\ngraphs is overwritten by updates for new graphs. To alleviate the problem,\ncontinual graph learning methods are proposed. However, existing continual\ngraph learning methods aim to learn new patterns and maintain old ones with the\nsame set of parameters of fixed size, and thus face a fundamental tradeoff\nbetween both goals. In this paper, we propose Parameter Isolation GNN (PI-GNN)\nfor continual learning on dynamic graphs that circumvents the tradeoff via\nparameter isolation and expansion. Our motivation lies in that different\nparameters contribute to learning different graph patterns. Based on the idea,\nwe expand model parameters to continually learn emerging graph patterns.\nMeanwhile, to effectively preserve knowledge for unaffected patterns, we find\nparameters that correspond to them via optimization and freeze them to prevent\nthem from being rewritten. Experiments on eight real-world datasets corroborate\nthe effectiveness of PI-GNN compared to state-of-the-art baselines.",
          "link": "http://arxiv.org/abs/2305.13825",
          "publishedOn": "2023-07-12T01:02:46.979Z",
          "wordCount": null,
          "title": "Continual Learning on Dynamic Graphs via Parameter Isolation. (arXiv:2305.13825v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.16177",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brodie_M/0/1/0/all/0/1\">Michael L Brodie</a>",
          "description": "Data science is not a science. It is a research paradigm. Its power, scope,\nand scale will surpass science, our most powerful research paradigm, to enable\nknowledge discovery and change our world. We have yet to understand and define\nit, vital to realizing its potential and managing its risks. Modern data\nscience is in its infancy. Emerging slowly since 1962 and rapidly since 2000,\nit is a fundamentally new field of inquiry, one of the most active, powerful,\nand rapidly evolving 21st century innovations. Due to its value, power, and\napplicability, it is emerging in 40+ disciplines, hundreds of research areas,\nand thousands of applications. Millions of data science publications contain\nmyriad definitions of data science and data science problem solving. Due to its\ninfancy, many definitions are independent, application-specific, mutually\nincomplete, redundant, or inconsistent, hence so is data science. This research\naddresses this data science multiple definitions challenge by proposing the\ndevelopment of coherent, unified definition based on a data science reference\nframework using a data science journal for the data science community to\nachieve such a definition. This paper provides candidate definitions for\nessential data science artifacts that are required to discuss such a\ndefinition. They are based on the classical research paradigm concept\nconsisting of a philosophy of data science, the data science problem solving\nparadigm, and the six component data science reference framework (axiology,\nontology, epistemology, methodology, methods, technology) that is a frequently\ncalled for unifying framework with which to define, unify, and evolve data\nscience. It presents challenges for defining data science, solution approaches,\ni.e., means for defining data science, and their requirements and benefits as\nthe basis of a comprehensive solution.",
          "link": "http://arxiv.org/abs/2306.16177",
          "publishedOn": "2023-07-12T01:02:46.977Z",
          "wordCount": null,
          "title": "Defining data science: a new field of inquiry. (arXiv:2306.16177v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1906.08947",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1\">Branislav Kveton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1\">Manzil Zaheer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1\">Csaba Szepesvari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lihong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1\">Mohammad Ghavamzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boutilier_C/0/1/0/all/0/1\">Craig Boutilier</a>",
          "description": "We study two randomized algorithms for generalized linear bandits. The first,\nGLM-TSL, samples a generalized linear model (GLM) from the Laplace\napproximation to the posterior distribution. The second, GLM-FPL, fits a GLM to\na randomly perturbed history of past rewards. We analyze both algorithms and\nderive $\\tilde{O}(d \\sqrt{n \\log K})$ upper bounds on their $n$-round regret,\nwhere $d$ is the number of features and $K$ is the number of arms. The former\nimproves on prior work while the latter is the first for Gaussian noise\nperturbations in non-linear models. We empirically evaluate both GLM-TSL and\nGLM-FPL in logistic bandits, and apply GLM-FPL to neural network bandits. Our\nwork showcases the role of randomization, beyond posterior sampling, in\nexploration.",
          "link": "http://arxiv.org/abs/1906.08947",
          "publishedOn": "2023-07-12T01:02:46.975Z",
          "wordCount": null,
          "title": "Randomized Exploration in Generalized Linear Bandits. (arXiv:1906.08947v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.08756",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xiaomeng Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potter_M/0/1/0/all/0/1\">Michael Potter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_G/0/1/0/all/0/1\">Gaurav Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1\">Yun-Chan Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saripalli_V/0/1/0/all/0/1\">V. Ratna Saripalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trafalis_T/0/1/0/all/0/1\">Theodore Trafalis</a>",
          "description": "It is no secret amongst deep learning researchers that finding the optimal\ndata augmentation strategy during training can mean the difference between\nstate-of-the-art performance and a run-of-the-mill result. To that end, the\ncommunity has seen many efforts to automate the process of finding the perfect\naugmentation procedure for any task at hand. Unfortunately, even recent\ncutting-edge methods bring massive computational overhead, requiring as many as\n100 full model trainings to settle on an ideal configuration. We show how to\nachieve equivalent performance using just 6 trainings with Random\nUnidimensional Augmentation. Source code is available at\nhttps://github.com/fastestimator/RUA/tree/v1.0",
          "link": "http://arxiv.org/abs/2106.08756",
          "publishedOn": "2023-07-12T01:02:46.975Z",
          "wordCount": null,
          "title": "Automating Augmentation Through Random Unidimensional Search. (arXiv:2106.08756v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.13487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1\">Dylan J. Foster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1\">Sham M. Kakade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1\">Jian Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rakhlin_A/0/1/0/all/0/1\">Alexander Rakhlin</a>",
          "description": "A fundamental challenge in interactive learning and decision making, ranging\nfrom bandit problems to reinforcement learning, is to provide sample-efficient,\nadaptive learning algorithms that achieve near-optimal regret. This question is\nanalogous to the classical problem of optimal (supervised) statistical\nlearning, where there are well-known complexity measures (e.g., VC dimension\nand Rademacher complexity) that govern the statistical complexity of learning.\nHowever, characterizing the statistical complexity of interactive learning is\nsubstantially more challenging due to the adaptive nature of the problem. The\nmain result of this work provides a complexity measure, the Decision-Estimation\nCoefficient, that is proven to be both necessary and sufficient for\nsample-efficient interactive learning. In particular, we provide:\n\n1. a lower bound on the optimal regret for any interactive decision making\nproblem, establishing the Decision-Estimation Coefficient as a fundamental\nlimit.\n\n2. a unified algorithm design principle, Estimation-to-Decisions (E2D), which\ntransforms any algorithm for supervised estimation into an online algorithm for\ndecision making. E2D attains a regret bound that matches our lower bound up to\ndependence on a notion of estimation performance, thereby achieving optimal\nsample-efficient learning as characterized by the Decision-Estimation\nCoefficient.\n\nTaken together, these results constitute a theory of learnability for\ninteractive decision making. When applied to reinforcement learning settings,\nthe Decision-Estimation Coefficient recovers essentially all existing hardness\nresults and lower bounds. More broadly, the approach can be viewed as a\ndecision-theoretic analogue of the classical Le Cam theory of statistical\nestimation; it also unifies a number of existing approaches -- both Bayesian\nand frequentist.",
          "link": "http://arxiv.org/abs/2112.13487",
          "publishedOn": "2023-07-12T01:02:46.975Z",
          "wordCount": null,
          "title": "The Statistical Complexity of Interactive Decision Making. (arXiv:2112.13487v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.11680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yuan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_D/0/1/0/all/0/1\">Difan Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1\">Quanquan Gu</a>",
          "description": "We study the implicit bias of batch normalization trained by gradient\ndescent. We show that when learning a linear model with batch normalization for\nbinary classification, gradient descent converges to a uniform margin\nclassifier on the training data with an $\\exp(-\\Omega(\\log^2 t))$ convergence\nrate. This distinguishes linear models with batch normalization from those\nwithout batch normalization in terms of both the type of implicit bias and the\nconvergence rate. We further extend our result to a class of two-layer,\nsingle-filter linear convolutional neural networks, and show that batch\nnormalization has an implicit bias towards a patch-wise uniform margin. Based\non two examples, we demonstrate that patch-wise uniform margin classifiers can\noutperform the maximum margin classifiers in certain learning problems. Our\nresults contribute to a better theoretical understanding of batch\nnormalization.",
          "link": "http://arxiv.org/abs/2306.11680",
          "publishedOn": "2023-07-12T01:02:46.973Z",
          "wordCount": null,
          "title": "The Implicit Bias of Batch Normalization in Linear Models and Two-layer Linear Convolutional Neural Networks. (arXiv:2306.11680v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05399",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wojcik_M/0/1/0/all/0/1\">Mateusz W&#xf3;jcik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kosciukiewicz_W/0/1/0/all/0/1\">Witold Ko&#x15b;ciukiewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baran_M/0/1/0/all/0/1\">Mateusz Baran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kajdanowicz_T/0/1/0/all/0/1\">Tomasz Kajdanowicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonczarek_A/0/1/0/all/0/1\">Adam Gonczarek</a>",
          "description": "Production deployments in complex systems require ML architectures to be\nhighly efficient and usable against multiple tasks. Particularly demanding are\nclassification problems in which data arrives in a streaming fashion and each\nclass is presented separately. Recent methods with stochastic gradient learning\nhave been shown to struggle in such setups or have limitations like memory\nbuffers, and being restricted to specific domains that disable its usage in\nreal-world scenarios. For this reason, we present a fully differentiable\narchitecture based on the Mixture of Experts model, that enables the training\nof high-performance classifiers when examples from each class are presented\nseparately. We conducted exhaustive experiments that proved its applicability\nin various domains and ability to learn online in production environments. The\nproposed technique achieves SOTA results without a memory buffer and clearly\noutperforms the reference methods.",
          "link": "http://arxiv.org/abs/2307.05399",
          "publishedOn": "2023-07-12T01:02:46.972Z",
          "wordCount": null,
          "title": "Domain-Agnostic Neural Architecture for Class Incremental Continual Learning in Document Processing Platform. (arXiv:2307.05399v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05426",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Addeh_A/0/1/0/all/0/1\">Abdoljalil Addeh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vega_F/0/1/0/all/0/1\">Fernando Vega</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Williams_R/0/1/0/all/0/1\">Rebecca J Williams</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Golestani_A/0/1/0/all/0/1\">Ali Golestani</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pike_G/0/1/0/all/0/1\">G. Bruce Pike</a>, <a href=\"http://arxiv.org/find/eess/1/au:+MacDonald_M/0/1/0/all/0/1\">M. Ethan MacDonald</a>",
          "description": "In many fMRI studies, respiratory signals are unavailable or do not have\nacceptable quality. Consequently, the direct removal of low-frequency\nrespiratory variations from BOLD signals is not possible. This study proposes a\none-dimensional CNN model for reconstruction of two respiratory measures, RV\nand RVT. Results show that a CNN can capture informative features from resting\nBOLD signals and reconstruct realistic RV and RVT timeseries. It is expected\nthat application of the proposed method will lower the cost of fMRI studies,\nreduce complexity, and decrease the burden on participants as they will not be\nrequired to wear a respiratory bellows.",
          "link": "http://arxiv.org/abs/2307.05426",
          "publishedOn": "2023-07-12T01:02:46.972Z",
          "wordCount": null,
          "title": "Using BOLD-fMRI to Compute the Respiration Volume per Time (RTV) and Respiration Variation (RV) with Convolutional Neural Networks (CNN) in the Human Connectome Development Cohort. (arXiv:2307.05426v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05440",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Joshi_A/0/1/0/all/0/1\">Abhinav Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_S/0/1/0/all/0/1\">Susmit Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Modi_A/0/1/0/all/0/1\">Ashutosh Modi</a>",
          "description": "Sign languages are the primary means of communication for many\nhard-of-hearing people worldwide. Recently, to bridge the communication gap\nbetween the hard-of-hearing community and the rest of the population, several\nsign language translation datasets have been proposed to enable the development\nof statistical sign language translation systems. However, there is a dearth of\nsign language resources for the Indian sign language. This resource paper\nintroduces ISLTranslate, a translation dataset for continuous Indian Sign\nLanguage (ISL) consisting of 31k ISL-English sentence/phrase pairs. To the best\nof our knowledge, it is the largest translation dataset for continuous Indian\nSign Language. We provide a detailed analysis of the dataset. To validate the\nperformance of existing end-to-end Sign language to spoken language translation\nsystems, we benchmark the created dataset with a transformer-based model for\nISL translation.",
          "link": "http://arxiv.org/abs/2307.05440",
          "publishedOn": "2023-07-12T01:02:46.972Z",
          "wordCount": null,
          "title": "ISLTranslate: Dataset for Translating Indian Sign Language. (arXiv:2307.05440v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fishman_N/0/1/0/all/0/1\">Nic Fishman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klarner_L/0/1/0/all/0/1\">Leo Klarner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathieu_E/0/1/0/all/0/1\">Emile Mathieu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutchinson_M/0/1/0/all/0/1\">Michael Hutchinson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bortoli_V/0/1/0/all/0/1\">Valentin de Bortoli</a>",
          "description": "Denoising diffusion models have recently emerged as the predominant paradigm\nfor generative modelling. Their extension to Riemannian manifolds has\nfacilitated their application to an array of problems in the natural sciences.\nYet, in many practical settings, such manifolds are defined by a set of\nconstraints and are not covered by the existing (Riemannian) diffusion model\nmethodology. Recent work has attempted to address this issue by employing novel\nnoising processes based on logarithmic barrier methods or reflected Brownian\nmotions. However, the associated samplers are computationally burdensome as the\ncomplexity of the constraints increases. In this paper, we introduce an\nalternative simple noising scheme based on Metropolis sampling that affords\nsubstantial gains in computational efficiency and empirical performance\ncompared to the earlier samplers. Of independent interest, we prove that this\nnew process corresponds to a valid discretisation of the reflected Brownian\nmotion. We demonstrate the scalability and flexibility of our approach on a\nrange of problem settings with convex and non-convex constraints, including\napplications from geospatial modelling, robotics and protein design.",
          "link": "http://arxiv.org/abs/2307.05439",
          "publishedOn": "2023-07-12T01:02:46.970Z",
          "wordCount": null,
          "title": "Metropolis Sampling for Constrained Diffusion Models. (arXiv:2307.05439v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05339",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Jain_P/0/1/0/all/0/1\">Pranay Jain</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ding_C/0/1/0/all/0/1\">Cheng Ding</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rudin_C/0/1/0/all/0/1\">Cynthia Rudin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hu_X/0/1/0/all/0/1\">Xiao Hu</a>",
          "description": "Smart watches and other wearable devices are equipped with\nphotoplethysmography (PPG) sensors for monitoring heart rate and other aspects\nof cardiovascular health. However, PPG signals collected from such devices are\nsusceptible to corruption from noise and motion artifacts, which cause errors\nin heart rate estimation. Typical denoising approaches filter or reconstruct\nthe signal in ways that eliminate much of the morphological information, even\nfrom the clean parts of the signal that would be useful to preserve. In this\nwork, we develop an algorithm for denoising PPG signals that reconstructs the\ncorrupted parts of the signal, while preserving the clean parts of the PPG\nsignal. Our novel framework relies on self-supervised training, where we\nleverage a large database of clean PPG signals to train a denoising\nautoencoder. As we show, our reconstructed signals provide better estimates of\nheart rate from PPG signals than the leading heart rate estimation methods.\nFurther experiments show significant improvement in Heart Rate Variability\n(HRV) estimation from PPG signals using our algorithm. We conclude that our\nalgorithm denoises PPG signals in a way that can improve downstream analysis of\nmany different health metrics from wearable devices.",
          "link": "http://arxiv.org/abs/2307.05339",
          "publishedOn": "2023-07-12T01:02:46.968Z",
          "wordCount": null,
          "title": "A Self-Supervised Algorithm for Denoising Photoplethysmography Signals for Heart Rate Estimation from Wearables. (arXiv:2307.05339v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.05379",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rani_A/0/1/0/all/0/1\">Asha Rani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_P/0/1/0/all/0/1\">Pankaj Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_Y/0/1/0/all/0/1\">Yashaswi Verma</a>",
          "description": "Autism, also known as Autism Spectrum Disorder (or ASD), is a neurological\ndisorder. Its main symptoms include difficulty in (verbal and/or non-verbal)\ncommunication, and rigid/repetitive behavior. These symptoms are often\nindistinguishable from a normal (control) individual, due to which this\ndisorder remains undiagnosed in early childhood leading to delayed treatment.\nSince the learning curve is steep during the initial age, an early diagnosis of\nautism could allow to take adequate interventions at the right time, which\nmight positively affect the growth of an autistic child. Further, the\ntraditional methods of autism diagnosis require multiple visits to a\nspecialized psychiatrist, however this process can be time-consuming. In this\npaper, we present a learning based approach to automate autism diagnosis using\nsimple and small action video clips of subjects. This task is particularly\nchallenging because the amount of annotated data available is small, and the\nvariations among samples from the two categories (ASD and control) are\ngenerally indistinguishable. This is also evident from poor performance of a\nbinary classifier learned using the cross-entropy loss on top of a baseline\nencoder. To address this, we adopt contrastive feature learning in both self\nsupervised and supervised learning frameworks, and show that these can lead to\na significant increase in the prediction accuracy of a binary classifier on\nthis task. We further validate this by conducting thorough experimental\nanalyses under different set-ups on two publicly available datasets.",
          "link": "http://arxiv.org/abs/2209.05379",
          "publishedOn": "2023-07-12T01:02:46.968Z",
          "wordCount": null,
          "title": "Action-based Early Autism Diagnosis Using Contrastive Feature Learning. (arXiv:2209.05379v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Webber_G/0/1/0/all/0/1\">George Webber</a>",
          "description": "Making contactless payments using a smartwatch is increasingly popular, but\nthis payment medium lacks traditional biometric security measures such as\nfacial or fingerprint recognition. In 2022, Sturgess et al. proposed WatchAuth,\na system for authenticating smartwatch payments using the physical gesture of\nreaching towards a payment terminal. While effective, the system requires the\nuser to undergo a burdensome enrolment period to achieve acceptable error\nlevels. In this dissertation, we explore whether applications of deep learning\ncan reduce the number of gestures a user must provide to enrol into an\nauthentication system for smartwatch payment. We firstly construct a\ndeep-learned authentication system that outperforms the current\nstate-of-the-art, including in a scenario where the target user has provided a\nlimited number of gestures. We then develop a regularised autoencoder model for\ngenerating synthetic user-specific gestures. We show that using these gestures\nin training improves classification ability for an authentication system.\nThrough this technique we can reduce the number of gestures required to enrol a\nuser into a WatchAuth-like system without negatively impacting its error rates.",
          "link": "http://arxiv.org/abs/2307.05437",
          "publishedOn": "2023-07-12T01:02:46.945Z",
          "wordCount": null,
          "title": "Improving the Security of Smartwatch Payment with Deep Learning. (arXiv:2307.05437v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05361",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Shi_Y/0/1/0/all/0/1\">Yue Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ma_S/0/1/0/all/0/1\">Shuhao Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_Y/0/1/0/all/0/1\">Yihui Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiqiang Zhang</a>",
          "description": "Muscle force and joint kinematics estimation from surface electromyography\n(sEMG) are essential for real-time biomechanical analysis of the dynamic\ninterplay among neural muscle stimulation, muscle dynamics, and kinetics.\nRecent advances in deep neural networks (DNNs) have shown the potential to\nimprove biomechanical analysis in a fully automated and reproducible manner.\nHowever, the small sample nature and physical interpretability of biomechanical\nanalysis limit the applications of DNNs. This paper presents a novel\nphysics-informed low-shot learning method for sEMG-based estimation of muscle\nforce and joint kinematics. This method seamlessly integrates Lagrange's\nequation of motion and inverse dynamic muscle model into the generative\nadversarial network (GAN) framework for structured feature decoding and\nextrapolated estimation from the small sample data. Specifically, Lagrange's\nequation of motion is introduced into the generative model to restrain the\nstructured decoding of the high-level features following the laws of physics.\nAnd a physics-informed policy gradient is designed to improve the adversarial\nlearning efficiency by rewarding the consistent physical representation of the\nextrapolated estimations and the physical references. Experimental validations\nare conducted on two scenarios (i.e. the walking trials and wrist motion\ntrials). Results indicate that the estimations of the muscle forces and joint\nkinematics are unbiased compared to the physics-based inverse dynamics, which\noutperforms the selected benchmark methods, including physics-informed\nconvolution neural network (PI-CNN), vallina generative adversarial network\n(GAN), and multi-layer extreme learning machine (ML-ELM).",
          "link": "http://arxiv.org/abs/2307.05361",
          "publishedOn": "2023-07-12T01:02:46.898Z",
          "wordCount": null,
          "title": "A Physics-Informed Low-Shot Learning For sEMG-Based Estimation of Muscle Force and Joint Kinematics. (arXiv:2307.05361v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05260",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Joshi_A/0/1/0/all/0/1\">Abhinav Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Akshat Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanikella_S/0/1/0/all/0/1\">Sai Kiran Tanikella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Modi_A/0/1/0/all/0/1\">Ashutosh Modi</a>",
          "description": "The task of Prior Case Retrieval (PCR) in the legal domain is about\nautomatically citing relevant (based on facts and precedence) prior legal cases\nin a given query case. To further promote research in PCR, in this paper, we\npropose a new large benchmark (in English) for the PCR task: IL-PCR (Indian\nLegal Prior Case Retrieval) corpus. Given the complex nature of case relevance\nand the long size of legal documents, BM25 remains a strong baseline for\nranking the cited prior documents. In this work, we explore the role of events\nin legal case retrieval and propose an unsupervised retrieval method-based\npipeline U-CREAT (Unsupervised Case Retrieval using Events Extraction). We find\nthat the proposed unsupervised retrieval method significantly increases\nperformance compared to BM25 and makes retrieval faster by a considerable\nmargin, making it applicable to real-time case retrieval systems. Our proposed\nsystem is generic, we show that it generalizes across two different legal\nsystems (Indian and Canadian), and it shows state-of-the-art performance on the\nbenchmarks for both the legal systems (IL-PCR and COLIEE corpora).",
          "link": "http://arxiv.org/abs/2307.05260",
          "publishedOn": "2023-07-12T01:02:46.897Z",
          "wordCount": null,
          "title": "U-CREAT: Unsupervised Case Retrieval using Events extrAcTion. (arXiv:2307.05260v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05405",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shukai Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chenming Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Ying Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Liangjun Zhang</a>",
          "description": "Interactive reinforcement learning has shown promise in learning complex\nrobotic tasks. However, the process can be human-intensive due to the\nrequirement of large amount of interactive feedback. This paper presents a new\nmethod that uses scores provided by humans, instead of pairwise preferences, to\nimprove the feedback efficiency of interactive reinforcement learning. Our key\ninsight is that scores can yield significantly more data than pairwise\npreferences. Specifically, we require a teacher to interactively score the full\ntrajectories of an agent to train a behavioral policy in a sparse reward\nenvironment. To avoid unstable scores given by human negatively impact the\ntraining process, we propose an adaptive learning scheme. This enables the\nlearning paradigm to be insensitive to imperfect or unreliable scores. We\nextensively evaluate our method on robotic locomotion and manipulation tasks.\nThe results show that the proposed method can efficiently learn near-optimal\npolicies by adaptive learning from scores, while requiring less feedback\ncompared to pairwise preference learning methods. The source codes are publicly\navailable at https://github.com/SSKKai/Interactive-Scoring-IRL.",
          "link": "http://arxiv.org/abs/2307.05405",
          "publishedOn": "2023-07-12T01:02:46.894Z",
          "wordCount": null,
          "title": "Boosting Feedback Efficiency of Interactive Reinforcement Learning by Adaptive Learning from Scores. (arXiv:2307.05405v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05232",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1\">Mohammad Dehghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yazdanparast_Z/0/1/0/all/0/1\">Zahra Yazdanparast</a>",
          "description": "Artificial intelligence has achieved significant success in handling complex\ntasks in recent years. This success is due to advances in machine learning\nalgorithms and hardware acceleration. In order to obtain more accurate results\nand solve more complex problems, algorithms must be trained with more data.\nThis huge amount of data could be time-consuming to process and require a great\ndeal of computation. This solution could be achieved by distributing the data\nand algorithm across several machines, which is known as distributed machine\nlearning. There has been considerable effort put into distributed machine\nlearning algorithms, and different methods have been proposed so far. In this\narticle, we present a comprehensive summary of the current state-of-the-art in\nthe field through the review of these algorithms. We divide this algorithms in\nclassification and clustering (traditional machine learning), deep learning and\ndeep reinforcement learning groups. Distributed deep learning has gained more\nattention in recent years and most of studies worked on this algorithms. As a\nresult, most of the articles we discussed here belong to this category. Based\non our investigation of algorithms, we highlight limitations that should be\naddressed in future research.",
          "link": "http://arxiv.org/abs/2307.05232",
          "publishedOn": "2023-07-12T01:02:46.891Z",
          "wordCount": null,
          "title": "A Survey From Distributed Machine Learning to Distributed Deep Learning. (arXiv:2307.05232v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05025",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kang_H/0/1/0/all/0/1\">Hui Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Huaxi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jun Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Bo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dadong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>",
          "description": "In recent years, research on learning with noisy labels has focused on\ndevising novel algorithms that can achieve robustness to noisy training labels\nwhile generalizing to clean data. These algorithms often incorporate\nsophisticated techniques, such as noise modeling, label correction, and\nco-training. In this study, we demonstrate that a simple baseline using\ncross-entropy loss, combined with widely used regularization strategies like\nlearning rate decay, model weights average, and data augmentations, can\noutperform state-of-the-art methods. Our findings suggest that employing a\ncombination of regularization strategies can be more effective than intricate\nalgorithms in tackling the challenges of learning with noisy labels. While some\nof these regularization strategies have been utilized in previous noisy label\nlearning research, their full potential has not been thoroughly explored. Our\nresults encourage a reevaluation of benchmarks for learning with noisy labels\nand prompt reconsideration of the role of specialized learning algorithms\ndesigned for training with noisy labels.",
          "link": "http://arxiv.org/abs/2307.05025",
          "publishedOn": "2023-07-12T01:02:46.866Z",
          "wordCount": null,
          "title": "Unleashing the Potential of Regularization Strategies in Learning with Noisy Labels. (arXiv:2307.05025v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05228",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Runcheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rashid_A/0/1/0/all/0/1\">Ahmad Rashid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kobyzev_I/0/1/0/all/0/1\">Ivan Kobyzev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezagholizadeh_M/0/1/0/all/0/1\">Mehdi Rezagholizadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poupart_P/0/1/0/all/0/1\">Pascal Poupart</a>",
          "description": "Prompt-tuning has become an increasingly popular parameter-efficient method\nfor adapting large pretrained language models to downstream tasks. However,\nboth discrete prompting and continuous prompting assume fixed prompts for all\ndata samples within a task, neglecting the fact that inputs vary greatly in\nsome tasks such as open-domain dialogue generation. In this paper, we present a\nnovel, instance-specific prompt-tuning algorithm for dialogue generation.\nSpecifically, we generate prompts based on instance-level control code, rather\nthan the conversation history, to explore their impact on controlled dialogue\ngeneration. Experiments on popular open-domain dialogue datasets, evaluated on\nboth automated metrics and human evaluation, demonstrate that our method is\nsuperior to prompting baselines and comparable to fine-tuning with only 5%-6%\nof total parameters.",
          "link": "http://arxiv.org/abs/2307.05228",
          "publishedOn": "2023-07-12T01:02:46.856Z",
          "wordCount": null,
          "title": "Attribute Controlled Dialogue Prompting. (arXiv:2307.05228v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05432",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mialon_G/0/1/0/all/0/1\">Gr&#xe9;goire Mialon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garrido_Q/0/1/0/all/0/1\">Quentin Garrido</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawrence_H/0/1/0/all/0/1\">Hannah Lawrence</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rehman_D/0/1/0/all/0/1\">Danyal Rehman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1\">Yann LeCun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiani_B/0/1/0/all/0/1\">Bobak T. Kiani</a>",
          "description": "Machine learning for differential equations paves the way for computationally\nefficient alternatives to numerical solvers, with potentially broad impacts in\nscience and engineering. Though current algorithms typically require simulated\ntraining data tailored to a given setting, one may instead wish to learn useful\ninformation from heterogeneous sources, or from real dynamical systems\nobservations that are messy or incomplete. In this work, we learn\ngeneral-purpose representations of PDEs from heterogeneous data by implementing\njoint embedding methods for self-supervised learning (SSL), a framework for\nunsupervised representation learning that has had notable success in computer\nvision. Our representation outperforms baseline approaches to invariant tasks,\nsuch as regressing the coefficients of a PDE, while also improving the\ntime-stepping performance of neural solvers. We hope that our proposed\nmethodology will prove useful in the eventual development of general-purpose\nfoundation models for PDEs.",
          "link": "http://arxiv.org/abs/2307.05432",
          "publishedOn": "2023-07-12T01:02:46.856Z",
          "wordCount": null,
          "title": "Self-Supervised Learning with Lie Symmetries for Partial Differential Equations. (arXiv:2307.05432v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05330",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Aditya Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maharaj_S/0/1/0/all/0/1\">Shiva Maharaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polson_N/0/1/0/all/0/1\">Nicholas Polson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sokolov_V/0/1/0/all/0/1\">Vadim Sokolov</a>",
          "description": "Valuing chess squares and determining the placement of pieces on the board\nare the main objectives of our study. With the emergence of chess AI, it has\nbecome possible to accurately assess the worth of positions in a game of chess.\nThe conventional approach assigns fixed values to pieces $(\\symking=\\infty,\n\\symqueen=9, \\symrook=5, \\symbishop=3, \\symknight=3, \\sympawn=1)$. We enhance\nthis analysis by introducing marginal valuations for both pieces and squares.\nWe demonstrate our method by examining the positioning of Knights and Bishops,\nand also provide valuable insights into the valuation of pawns. Notably,\nNimzowitsch was among the pioneers in advocating for the significance of Pawn\nstructure and valuation. Finally, we conclude by suggesting potential avenues\nfor future research.",
          "link": "http://arxiv.org/abs/2307.05330",
          "publishedOn": "2023-07-12T01:02:46.838Z",
          "wordCount": null,
          "title": "The Value of Chess Squares. (arXiv:2307.05330v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05193",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ali_H/0/1/0/all/0/1\">Hassan Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qayyum_A/0/1/0/all/0/1\">Adnan Qayyum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Fuqaha_A/0/1/0/all/0/1\">Ala Al-Fuqaha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qadir_J/0/1/0/all/0/1\">Junaid Qadir</a>",
          "description": "Several membership inference (MI) attacks have been proposed to audit a\ntarget DNN. Given a set of subjects, MI attacks tell which subjects the target\nDNN has seen during training. This work focuses on the post-training MI attacks\nemphasizing high confidence membership detection -- True Positive Rates (TPR)\nat low False Positive Rates (FPR). Current works in this category -- likelihood\nratio attack (LiRA) and enhanced MI attack (EMIA) -- only perform well on\ncomplex datasets (e.g., CIFAR-10 and Imagenet) where the target DNN overfits\nits train set, but perform poorly on simpler datasets (0% TPR by both attacks\non Fashion-MNIST, 2% and 0% TPR respectively by LiRA and EMIA on MNIST at 1%\nFPR). To address this, firstly, we unify current MI attacks by presenting a\nframework divided into three stages -- preparation, indication and decision.\nSecondly, we utilize the framework to propose two novel attacks: (1)\nAdversarial Membership Inference Attack (AMIA) efficiently utilizes the\nmembership and the non-membership information of the subjects while\nadversarially minimizing a novel loss function, achieving 6% TPR on both\nFashion-MNIST and MNIST datasets; and (2) Enhanced AMIA (E-AMIA) combines EMIA\nand AMIA to achieve 8% and 4% TPRs on Fashion-MNIST and MNIST datasets\nrespectively, at 1% FPR. Thirdly, we introduce two novel augmented indicators\nthat positively leverage the loss information in the Gaussian neighborhood of a\nsubject. This improves TPR of all four attacks on average by 2.5% and 0.25%\nrespectively on Fashion-MNIST and MNIST datasets at 1% FPR. Finally, we propose\nsimple, yet novel, evaluation metric, the running TPR average (RTA) at a given\nFPR, that better distinguishes different MI attacks in the low FPR region. We\nalso show that AMIA and E-AMIA are more transferable to the unknown DNNs (other\nthan the target DNN) and are more robust to DP-SGD training as compared to LiRA\nand EMIA.",
          "link": "http://arxiv.org/abs/2307.05193",
          "publishedOn": "2023-07-12T01:02:46.837Z",
          "wordCount": null,
          "title": "Membership Inference Attacks on DNNs using Adversarial Perturbations. (arXiv:2307.05193v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05333",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sultana_S/0/1/0/all/0/1\">Sharmin Sultana</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rahman_M/0/1/0/all/0/1\">Md Mahmudur Rahman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mahi_A/0/1/0/all/0/1\">Atqiya Munawara Mahi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_S/0/1/0/all/0/1\">Shao-Hsien Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Alam_M/0/1/0/all/0/1\">Mohammad Arif Ul Alam</a>",
          "description": "The combination of diverse health data (IoT, EHR, and clinical surveys) and\nscalable-adaptable Artificial Intelligence (AI), has enabled the discovery of\nphysical, behavioral, and psycho-social indicators of pain status. Despite the\nhype and promise to fundamentally alter the healthcare system with\ntechnological advancements, much AI adoption in clinical pain evaluation has\nbeen hampered by the heterogeneity of the problem itself and other challenges,\nsuch as personalization and fairness. Studies have revealed that many AI (i.e.,\nmachine learning or deep learning) models display biases and discriminate\nagainst specific population segments (such as those based on gender or\nethnicity), which breeds skepticism among medical professionals about AI\nadaptability. In this paper, we propose a Multi-attribute Fairness Loss (MAFL)\nbased CNN model that aims to account for any sensitive attributes included in\nthe data and fairly predict patients' pain status while attempting to minimize\nthe discrepancies between privileged and unprivileged groups. In order to\ndetermine whether the trade-off between accuracy and fairness can be satisfied,\nwe compare the proposed model with well-known existing mitigation procedures,\nand studies reveal that the implemented model performs favorably in contrast to\nstate-of-the-art methods. Utilizing NIH All-Of-US data, where a cohort of 868\ndistinct individuals with wearables and EHR data gathered over 1500 days has\nbeen taken into consideration to analyze our suggested fair pain assessment\nsystem.",
          "link": "http://arxiv.org/abs/2307.05333",
          "publishedOn": "2023-07-12T01:02:46.832Z",
          "wordCount": null,
          "title": "Unbiased Pain Assessment through Wearables and EHR Data: Multi-attribute Fairness Loss-based CNN Approach. (arXiv:2307.05333v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05104",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schlegel_U/0/1/0/all/0/1\">Udo Schlegel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keim_D/0/1/0/all/0/1\">Daniel A. Keim</a>",
          "description": "Explainable Artificial Intelligence (XAI) has gained significant attention\nrecently as the demand for transparency and interpretability of machine\nlearning models has increased. In particular, XAI for time series data has\nbecome increasingly important in finance, healthcare, and climate science.\nHowever, evaluating the quality of explanations, such as attributions provided\nby XAI techniques, remains challenging. This paper provides an in-depth\nanalysis of using perturbations to evaluate attributions extracted from time\nseries models. A perturbation analysis involves systematically modifying the\ninput data and evaluating the impact on the attributions generated by the XAI\nmethod. We apply this approach to several state-of-the-art XAI techniques and\nevaluate their performance on three time series classification datasets. Our\nresults demonstrate that the perturbation analysis approach can effectively\nevaluate the quality of attributions and provide insights into the strengths\nand limitations of XAI techniques. Such an approach can guide the selection of\nXAI methods for time series data, e.g., focusing on return time rather than\nprecision, and facilitate the development of more reliable and interpretable\nmachine learning models for time series analysis.",
          "link": "http://arxiv.org/abs/2307.05104",
          "publishedOn": "2023-07-12T01:02:46.805Z",
          "wordCount": null,
          "title": "A Deep Dive into Perturbations as Evaluation Technique for Time Series XAI. (arXiv:2307.05104v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.00033",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Thombre_I/0/1/0/all/0/1\">Isha Thombre</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Perepu_P/0/1/0/all/0/1\">Pavan Kumar Perepu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sudhakar_S/0/1/0/all/0/1\">Shyam Kumar Sudhakar</a>",
          "description": "The human gut microbiota is known to contribute to numerous physiological\nfunctions of the body and also implicated in a myriad of pathological\nconditions. Prolific research work in the past few decades have yielded\nvaluable information regarding the relative taxonomic distribution of gut\nmicrobiota. Unfortunately, the microbiome data suffers from class imbalance and\nhigh dimensionality issues that must be addressed. In this study, we have\nimplemented data engineering algorithms to address the above-mentioned issues\ninherent to microbiome data. Four standard machine learning classifiers\n(logistic regression (LR), support vector machines (SVM), random forests (RF),\nand extreme gradient boosting (XGB) decision trees) were implemented on a\npreviously published dataset. The issue of class imbalance and high\ndimensionality of the data was addressed through synthetic minority\noversampling technique (SMOTE) and principal component analysis (PCA). Our\nresults indicate that ensemble classifiers (RF and XGB decision trees) exhibit\nsuperior classification accuracy in predicting the host phenotype. The\napplication of PCA significantly reduced testing time while maintaining high\nclassification accuracy. The highest classification accuracy was obtained at\nthe levels of species for most classifiers. The prototype employed in the study\naddresses the issues inherent to microbiome datasets and could be highly\nbeneficial for providing personalized medicine.",
          "link": "http://arxiv.org/abs/2307.00033",
          "publishedOn": "2023-07-12T01:02:46.798Z",
          "wordCount": null,
          "title": "Application of data engineering approaches to address challenges in microbiome data for optimal medical decision-making. (arXiv:2307.00033v2 [q-bio.QM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05121",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yue Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guanjun Liu</a>",
          "description": "How to obtain informative representations of transactions and then perform\nthe identification of fraudulent transactions is a crucial part of ensuring\nfinancial security. Recent studies apply Graph Neural Networks (GNNs) to the\ntransaction fraud detection problem. Nevertheless, they encounter challenges in\neffectively learning spatial-temporal information due to structural\nlimitations. Moreover, few prior GNN-based detectors have recognized the\nsignificance of incorporating global information, which encompasses similar\nbehavioral patterns and offers valuable insights for discriminative\nrepresentation learning. Therefore, we propose a novel heterogeneous graph\nneural network called Spatial-Temporal-Aware Graph Transformer (STA-GT) for\ntransaction fraud detection problems. Specifically, we design a temporal\nencoding strategy to capture temporal dependencies and incorporate it into the\ngraph neural network framework, enhancing spatial-temporal information modeling\nand improving expressive ability. Furthermore, we introduce a transformer\nmodule to learn local and global information. Pairwise node-node interactions\novercome the limitation of the GNN structure and build up the interactions with\nthe target node and long-distance ones. Experimental results on two financial\ndatasets compared to general GNN models and GNN-based fraud detectors\ndemonstrate that our proposed method STA-GT is effective on the transaction\nfraud detection task.",
          "link": "http://arxiv.org/abs/2307.05121",
          "publishedOn": "2023-07-12T01:02:46.796Z",
          "wordCount": null,
          "title": "Transaction Fraud Detection via Spatial-Temporal-Aware Graph Transformer. (arXiv:2307.05121v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05373",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Almutairi_H/0/1/0/all/0/1\">Haifa Almutairi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hassan_G/0/1/0/all/0/1\">Ghulam Mubashar Hassan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Datta_A/0/1/0/all/0/1\">Amitava Datta</a>",
          "description": "Classification of sleep stages plays an essential role in diagnosing\nsleep-related diseases including Sleep Disorder Breathing (SDB) disease. In\nthis study, we propose an end-to-end deep learning architecture, named SSNet,\nwhich comprises of two deep learning networks based on Convolutional Neuron\nNetworks (CNN) and Long Short Term Memory (LSTM). Both deep learning networks\nextract features from the combination of Electrooculogram (EOG),\nElectroencephalogram (EEG), and Electromyogram (EMG) signals, as each signal\nhas distinct features that help in the classification of sleep stages. The\nfeatures produced by the two-deep learning networks are concatenated to pass to\nthe fully connected layer for the classification. The performance of our\nproposed model is evaluated by using two public datasets Sleep-EDF Expanded\ndataset and ISRUC-Sleep dataset. The accuracy and Kappa coefficient are 96.36%\nand 93.40% respectively, for classifying three classes of sleep stages using\nSleep-EDF Expanded dataset. Whereas, the accuracy and Kappa coefficient are\n96.57% and 83.05% respectively for five classes of sleep stages using Sleep-EDF\nExpanded dataset. Our model achieves the best performance in classifying sleep\nstages when compared with the state-of-the-art techniques.",
          "link": "http://arxiv.org/abs/2307.05373",
          "publishedOn": "2023-07-12T01:02:46.795Z",
          "wordCount": null,
          "title": "Classification of sleep stages from EEG, EOG and EMG signals by SSNet. (arXiv:2307.05373v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05374",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Srivallapanondh_S/0/1/0/all/0/1\">Sasipim Srivallapanondh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Freire_P/0/1/0/all/0/1\">Pedro J. Freire</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Alam_A/0/1/0/all/0/1\">Ashraful Alam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Costa_N/0/1/0/all/0/1\">Nelson Costa</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Spinnler_B/0/1/0/all/0/1\">Bernhard Spinnler</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Napoli_A/0/1/0/all/0/1\">Antonio Napoli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sedov_E/0/1/0/all/0/1\">Egor Sedov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Turitsyn_S/0/1/0/all/0/1\">Sergei K. Turitsyn</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prilepsky_J/0/1/0/all/0/1\">Jaroslaw E. Prilepsky</a>",
          "description": "For the first time, multi-task learning is proposed to improve the\nflexibility of NN-based equalizers in coherent systems. A \"single\" NN-based\nequalizer improves Q-factor by up to 4 dB compared to CDC, without re-training,\neven with variations in launch power, symbol rate, or transmission distance.",
          "link": "http://arxiv.org/abs/2307.05374",
          "publishedOn": "2023-07-12T01:02:46.793Z",
          "wordCount": null,
          "title": "Multi-Task Learning to Enhance Generazability of Neural Network Equalizers in Coherent Optical Systems. (arXiv:2307.05374v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05152",
          "author": "<a href=\"http://arxiv.org/find/hep-ex/1/au:+Coccaro_A/0/1/0/all/0/1\">Andrea Coccaro</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Bello_F/0/1/0/all/0/1\">Francesco Armando Di Bello</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Giagu_S/0/1/0/all/0/1\">Stefano Giagu</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Rambelli_L/0/1/0/all/0/1\">Lucrezia Rambelli</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Stocchetti_N/0/1/0/all/0/1\">Nicola Stocchetti</a>",
          "description": "Experimental particle physics demands a sophisticated trigger and acquisition\nsystem capable to efficiently retain the collisions of interest for further\ninvestigation. Heterogeneous computing with the employment of FPGA cards may\nemerge as a trending technology for the triggering strategy of the upcoming\nhigh-luminosity program of the Large Hadron Collider at CERN. In this context,\nwe present two machine-learning algorithms for selecting events where neutral\nlong-lived particles decay within the detector volume studying their accuracy\nand inference time when accelerated on commercially available Xilinx FPGA\naccelerator cards. The inference time is also confronted with a CPU- and\nGPU-based hardware setup. The proposed new algorithms are proven efficient for\nthe considered benchmark physics scenario and their accuracy is found to not\ndegrade when accelerated on the FPGA cards. The results indicate that all\ntested architectures fit within the latency requirements of a second-level\ntrigger farm and that exploiting accelerator technologies for real-time\nprocessing of particle-physics collisions is a promising research field that\ndeserves additional investigations, in particular with machine-learning models\nwith a large number of trainable parameters.",
          "link": "http://arxiv.org/abs/2307.05152",
          "publishedOn": "2023-07-12T01:02:46.787Z",
          "wordCount": null,
          "title": "Fast Neural Network Inference on FPGAs for Triggering on Long-Lived Particles at Colliders. (arXiv:2307.05152v1 [hep-ex])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05187",
          "author": "<a href=\"http://arxiv.org/find/hep-ph/1/au:+Algren_M/0/1/0/all/0/1\">Malte Algren</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Raine_J/0/1/0/all/0/1\">John Andrew Raine</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Golling_T/0/1/0/all/0/1\">Tobias Golling</a>",
          "description": "Being able to decorrelate a feature space from protected attributes is an\narea of active research and study in ethics, fairness, and also natural\nsciences. We introduce a novel decorrelation method using Convex Neural Optimal\nTransport Solvers (Cnots), that is able to decorrelate continuous feature space\nagainst protected attributes with optimal transport. We demonstrate how well it\nperforms in the context of jet classification in high energy physics, where\nclassifier scores are desired to be decorrelated from the mass of a jet. The\ndecorrelation achieved in binary classification approaches the levels achieved\nby the state-of-the-art using conditional normalising flows. When moving to\nmulticlass outputs the optimal transport approach performs significantly better\nthan the state-of-the-art, suggesting substantial gains at decorrelating\nmultidimensional feature spaces.",
          "link": "http://arxiv.org/abs/2307.05187",
          "publishedOn": "2023-07-12T01:02:46.785Z",
          "wordCount": null,
          "title": "Decorrelation using Optimal Transport. (arXiv:2307.05187v1 [hep-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05117",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Honghao Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1\">David P. Woodruff</a>",
          "description": "We consider the randomized communication complexity of the distributed\n$\\ell_p$-regression problem in the coordinator model, for $p\\in (0,2]$. In this\nproblem, there is a coordinator and $s$ servers. The $i$-th server receives\n$A^i\\in\\{-M, -M+1, \\ldots, M\\}^{n\\times d}$ and $b^i\\in\\{-M, -M+1, \\ldots,\nM\\}^n$ and the coordinator would like to find a $(1+\\epsilon)$-approximate\nsolution to $\\min_{x\\in\\mathbb{R}^n} \\|(\\sum_i A^i)x - (\\sum_i b^i)\\|_p$. Here\n$M \\leq \\mathrm{poly}(nd)$ for convenience. This model, where the data is\nadditively shared across servers, is commonly referred to as the arbitrary\npartition model.\n\nWe obtain significantly improved bounds for this problem. For $p = 2$, i.e.,\nleast squares regression, we give the first optimal bound of\n$\\tilde{\\Theta}(sd^2 + sd/\\epsilon)$ bits.\n\nFor $p \\in (1,2)$,we obtain an $\\tilde{O}(sd^2/\\epsilon +\nsd/\\mathrm{poly}(\\epsilon))$ upper bound. Notably, for $d$ sufficiently large,\nour leading order term only depends linearly on $1/\\epsilon$ rather than\nquadratically. We also show communication lower bounds of $\\Omega(sd^2 +\nsd/\\epsilon^2)$ for $p\\in (0,1]$ and $\\Omega(sd^2 + sd/\\epsilon)$ for $p\\in\n(1,2]$. Our bounds considerably improve previous bounds due to (Woodruff et al.\nCOLT, 2013) and (Vempala et al., SODA, 2020).",
          "link": "http://arxiv.org/abs/2307.05117",
          "publishedOn": "2023-07-12T01:02:46.784Z",
          "wordCount": null,
          "title": "$\\ell_p$-Regression in the Arbitrary Partition Model of Communication. (arXiv:2307.05117v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Azran_G/0/1/0/all/0/1\">Guy Azran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Danesh_M/0/1/0/all/0/1\">Mohamad H. Danesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albrecht_S/0/1/0/all/0/1\">Stefano V. Albrecht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keren_S/0/1/0/all/0/1\">Sarah Keren</a>",
          "description": "Recent studies show that deep reinforcement learning (DRL) agents tend to\noverfit to the task on which they were trained and fail to adapt to minor\nenvironment changes. To expedite learning when transferring to unseen tasks, we\npropose a novel approach to representing the current task using reward machines\n(RM), state machine abstractions that induce subtasks based on the current\ntask's rewards and dynamics. Our method provides agents with symbolic\nrepresentations of optimal transitions from their current abstract state and\nrewards them for achieving these transitions. These representations are shared\nacross tasks, allowing agents to exploit knowledge of previously encountered\nsymbols and transitions, thus enhancing transfer. Our empirical evaluation\nshows that our representations improve sample efficiency and few-shot transfer\nin a variety of domains.",
          "link": "http://arxiv.org/abs/2307.05209",
          "publishedOn": "2023-07-12T01:02:46.784Z",
          "wordCount": null,
          "title": "Contextual Pre-Planning on Reward Machine Abstractions for Enhanced Transfer in Deep Reinforcement Learning. (arXiv:2307.05209v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04907",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hemanthage_B/0/1/0/all/0/1\">Bhathiya Hemanthage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dondrup_C/0/1/0/all/0/1\">Christian Dondrup</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartie_P/0/1/0/all/0/1\">Phil Bartie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lemon_O/0/1/0/all/0/1\">Oliver Lemon</a>",
          "description": "SimpleMTOD is a simple language model which recasts several sub-tasks in\nmultimodal task-oriented dialogues as sequence prediction tasks. SimpleMTOD is\nbuilt on a large-scale transformer-based auto-regressive architecture, which\nhas already proven to be successful in uni-modal task-oriented dialogues, and\neffectively leverages transfer learning from pre-trained GPT-2. In-order to\ncapture the semantics of visual scenes, we introduce both local and\nde-localized tokens for objects within a scene. De-localized tokens represent\nthe type of an object rather than the specific object itself and so possess a\nconsistent meaning across the dataset. SimpleMTOD achieves a state-of-the-art\nBLEU score (0.327) in the Response Generation sub-task of the SIMMC 2.0\ntest-std dataset while performing on par in other multimodal sub-tasks:\nDisambiguation, Coreference Resolution, and Dialog State Tracking. This is\ndespite taking a minimalist approach for extracting visual (and non-visual)\ninformation. In addition the model does not rely on task-specific architectural\nchanges such as classification heads.",
          "link": "http://arxiv.org/abs/2307.04907",
          "publishedOn": "2023-07-12T01:02:46.775Z",
          "wordCount": null,
          "title": "SimpleMTOD: A Simple Language Model for Multimodal Task-Oriented Dialogue with Symbolic Scene Representation. (arXiv:2307.04907v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05004",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nakamura_T/0/1/0/all/0/1\">Tomoaki Nakamura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taniguchi_A/0/1/0/all/0/1\">Akira Taniguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taniguchi_T/0/1/0/all/0/1\">Tadahiro Taniguchi</a>",
          "description": "This paper proposes a generative probabilistic model integrating emergent\ncommunication and multi-agent reinforcement learning. The agents plan their\nactions by probabilistic inference, called control as inference, and\ncommunicate using messages that are latent variables and estimated based on the\nplanned actions. Through these messages, each agent can send information about\nits actions and know information about the actions of another agent. Therefore,\nthe agents change their actions according to the estimated messages to achieve\ncooperative tasks. This inference of messages can be considered as\ncommunication, and this procedure can be formulated by the Metropolis-Hasting\nnaming game. Through experiments in the grid world environment, we show that\nthe proposed PGM can infer meaningful messages to achieve the cooperative task.",
          "link": "http://arxiv.org/abs/2307.05004",
          "publishedOn": "2023-07-12T01:02:46.775Z",
          "wordCount": null,
          "title": "Control as Probabilistic Inference as an Emergent Communication Mechanism in Multi-Agent Reinforcement Learning. (arXiv:2307.05004v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05132",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Wang_S/0/1/0/all/0/1\">Siyang Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Henter_G/0/1/0/all/0/1\">Gustav Eje Henter</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gustafson_J/0/1/0/all/0/1\">Joakim Gustafson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Szekely_E/0/1/0/all/0/1\">&#xc9;va Sz&#xe9;kely</a>",
          "description": "Self-supervised learning (SSL) speech representations learned from large\namounts of diverse, mixed-quality speech data without transcriptions are\ngaining ground in many speech technology applications. Prior work has shown\nthat SSL is an effective intermediate representation in two-stage\ntext-to-speech (TTS) for both read and spontaneous speech. However, it is still\nnot clear which SSL and which layer from each SSL model is most suited for\nspontaneous TTS. We address this shortcoming by extending the scope of\ncomparison for SSL in spontaneous TTS to 6 different SSLs and 3 layers within\neach SSL. Furthermore, SSL has also shown potential in predicting the mean\nopinion scores (MOS) of synthesized speech, but this has only been done in\nread-speech MOS prediction. We extend an SSL-based MOS prediction framework\npreviously developed for scoring read speech synthesis and evaluate its\nperformance on synthesized spontaneous speech. All experiments are conducted\ntwice on two different spontaneous corpora in order to find generalizable\ntrends. Overall, we present comprehensive experimental results on the use of\nSSL in spontaneous TTS and MOS prediction to further quantify and understand\nhow SSL can be used in spontaneous TTS. Audios samples:\nhttps://www.speech.kth.se/tts-demos/sp_ssl_tts",
          "link": "http://arxiv.org/abs/2307.05132",
          "publishedOn": "2023-07-12T01:02:46.775Z",
          "wordCount": null,
          "title": "On the Use of Self-Supervised Speech Representations in Spontaneous Speech Synthesis. (arXiv:2307.05132v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05189",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khadilkar_H/0/1/0/all/0/1\">Harshad Khadilkar</a>",
          "description": "We present a simple linear regression based approach for learning the weights\nand biases of a neural network, as an alternative to standard gradient based\nbackpropagation. The present work is exploratory in nature, and we restrict the\ndescription and experiments to (i) simple feedforward neural networks, (ii)\nscalar (single output) regression problems, and (iii) invertible activation\nfunctions. However, the approach is intended to be extensible to larger, more\ncomplex architectures. The key idea is the observation that the input to every\nneuron in a neural network is a linear combination of the activations of\nneurons in the previous layer, as well as the parameters (weights and biases)\nof the layer. If we are able to compute the ideal total input values to every\nneuron by working backwards from the output, we can formulate the learning\nproblem as a linear least squares problem which iterates between updating the\nparameters and the activation values. We present an explicit algorithm that\nimplements this idea, and we show that (at least for simple problems) the\napproach is more stable and faster than gradient-based backpropagation.",
          "link": "http://arxiv.org/abs/2307.05189",
          "publishedOn": "2023-07-12T01:02:46.775Z",
          "wordCount": null,
          "title": "Using Linear Regression for Iteratively Training Neural Networks. (arXiv:2307.05189v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05017",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1\">Yi Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yongsheng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weichuan Zhang</a>",
          "description": "Decisions made by convolutional neural networks(CNN) can be understood and\nexplained by visualizing discriminative regions on images. To this end, Class\nActivation Map (CAM) based methods were proposed as powerful interpretation\ntools, making the prediction of deep learning models more explainable,\ntransparent, and trustworthy. However, all the CAM-based methods (e.g., CAM,\nGrad-CAM, and Relevance-CAM) can only be used for interpreting CNN models with\nfully-connected (FC) layers as a classifier. It is worth noting that many deep\nlearning models classify images without FC layers, e.g., few-shot learning\nimage classification, contrastive learning image classification, and image\nretrieval tasks. In this work, a post-hoc interpretation tool named feature\nactivation map (FAM) is proposed, which can interpret deep learning models\nwithout FC layers as a classifier. In the proposed FAM algorithm, the\nchannel-wise contribution weights are derived from the similarity scores\nbetween two image embeddings. The activation maps are linearly combined with\nthe corresponding normalized contribution weights, forming the explanation map\nfor visualization. The quantitative and qualitative experiments conducted on\nten deep learning models for few-shot image classification, contrastive\nlearning image classification and image retrieval tasks demonstrate the\neffectiveness of the proposed FAM algorithm.",
          "link": "http://arxiv.org/abs/2307.05017",
          "publishedOn": "2023-07-12T01:02:46.774Z",
          "wordCount": null,
          "title": "Feature Activation Map: Visual Explanation of Deep Learning Models for Image Classification. (arXiv:2307.05017v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05161",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yinghao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_R/0/1/0/all/0/1\">Ruibin Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yizhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Ge Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xingran Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Hanzhi Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenghua Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benetos_E/0/1/0/all/0/1\">Emmanouil Benetos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ragni_A/0/1/0/all/0/1\">Anton Ragni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gyenge_N/0/1/0/all/0/1\">Norbert Gyenge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Ruibo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_G/0/1/0/all/0/1\">Gus Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dannenberg_R/0/1/0/all/0/1\">Roger Dannenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yike Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jie Fu</a>",
          "description": "Self-supervised learning (SSL) has shown promising results in various speech\nand natural language processing applications. However, its efficacy in music\ninformation retrieval (MIR) still remains largely unexplored. While previous\nSSL models pre-trained on music recordings may have been mostly closed-sourced,\nrecent speech models such as wav2vec2.0 have shown promise in music modelling.\nNevertheless, research exploring the effectiveness of applying speech SSL\nmodels to music recordings has been limited. We explore the music adaption of\nSSL with two distinctive speech-related models, data2vec1.0 and Hubert, and\nrefer to them as music2vec and musicHuBERT, respectively. We train $12$ SSL\nmodels with 95M parameters under various pre-training configurations and\nsystematically evaluate the MIR task performances with 13 different MIR tasks.\nOur findings suggest that training with music data can generally improve\nperformance on MIR tasks, even when models are trained using paradigms designed\nfor speech. However, we identify the limitations of such existing\nspeech-oriented designs, especially in modelling polyphonic information. Based\non the experimental results, empirical suggestions are also given for designing\nfuture musical SSL strategies and paradigms.",
          "link": "http://arxiv.org/abs/2307.05161",
          "publishedOn": "2023-07-12T01:02:46.774Z",
          "wordCount": null,
          "title": "On the Effectiveness of Speech Self-supervised Learning for Music. (arXiv:2307.05161v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04838",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Subramanyam_R/0/1/0/all/0/1\">Rakshith Subramanyam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jayram_T/0/1/0/all/0/1\">T. S. Jayram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anirudh_R/0/1/0/all/0/1\">Rushil Anirudh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thiagarajan_J/0/1/0/all/0/1\">Jayaraman J. Thiagarajan</a>",
          "description": "In this paper, we explore the potential of Vision-Language Models (VLMs),\nspecifically CLIP, in predicting visual object relationships, which involves\ninterpreting visual features from images into language-based relations. Current\nstate-of-the-art methods use complex graphical models that utilize language\ncues and visual features to address this challenge. We hypothesize that the\nstrong language priors in CLIP embeddings can simplify these graphical models\npaving for a simpler approach. We adopt the UVTransE relation prediction\nframework, which learns the relation as a translational embedding with subject,\nobject, and union box embeddings from a scene. We systematically explore the\ndesign of CLIP-based subject, object, and union-box representations within the\nUVTransE framework and propose CREPE (CLIP Representation Enhanced Predicate\nEstimation). CREPE utilizes text-based representations for all three bounding\nboxes and introduces a novel contrastive training strategy to automatically\ninfer the text prompt for union-box. Our approach achieves state-of-the-art\nperformance in predicate estimation, mR@5 27.79, and mR@20 31.95 on the Visual\nGenome benchmark, achieving a 15.3\\% gain in performance over recent\nstate-of-the-art at mR@20. This work demonstrates CLIP's effectiveness in\nobject relation prediction and encourages further research on VLMs in this\nchallenging domain.",
          "link": "http://arxiv.org/abs/2307.04838",
          "publishedOn": "2023-07-12T01:02:46.773Z",
          "wordCount": null,
          "title": "CREPE: Learnable Prompting With CLIP Improves Visual Relationship Prediction. (arXiv:2307.04838v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05068",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oesterheld_C/0/1/0/all/0/1\">Caspar Oesterheld</a> (Carnegie Mellon University), <a href=\"http://arxiv.org/find/cs/1/au:+Demski_A/0/1/0/all/0/1\">Abram Demski</a> (Machine Intelligence Research Institute), <a href=\"http://arxiv.org/find/cs/1/au:+Conitzer_V/0/1/0/all/0/1\">Vincent Conitzer</a> (Carnegie Mellon University)",
          "description": "The dominant theories of rational choice assume logical omniscience. That is,\nthey assume that when facing a decision problem, an agent can perform all\nrelevant computations and determine the truth value of all relevant\nlogical/mathematical claims. This assumption is unrealistic when, for example,\nwe offer bets on remote digits of pi or when an agent faces a computationally\nintractable planning problem. Furthermore, the assumption of logical\nomniscience creates contradictions in cases where the environment can contain\ndescriptions of the agent itself. Importantly, strategic interactions as\nstudied in game theory are decision problems in which a rational agent is\npredicted by its environment (the other players). In this paper, we develop a\ntheory of rational decision making that does not assume logical omniscience. We\nconsider agents who repeatedly face decision problems (including ones like\nbetting on digits of pi or games against other agents). The main contribution\nof this paper is to provide a sensible theory of rationality for such agents.\nRoughly, we require that a boundedly rational inductive agent tests each\nefficiently computable hypothesis infinitely often and follows those hypotheses\nthat keep their promises of high rewards. We then prove that agents that are\nrational in this sense have other desirable properties. For example, they learn\nto value random and pseudo-random lotteries at their expected reward. Finally,\nwe consider strategic interactions between different agents and prove a folk\ntheorem for what strategies bounded rational inductive agents can converge to.",
          "link": "http://arxiv.org/abs/2307.05068",
          "publishedOn": "2023-07-12T01:02:46.773Z",
          "wordCount": null,
          "title": "A Theory of Bounded Inductive Rationality. (arXiv:2307.05068v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05126",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Coelho_C/0/1/0/all/0/1\">C. Coelho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_M/0/1/0/all/0/1\">M. Fernanda P. Costa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferras_L/0/1/0/all/0/1\">L.L. Ferr&#xe1;s</a>",
          "description": "Due to their dynamic properties such as irregular sampling rate and\nhigh-frequency sampling, Continuous Time Series (CTS) are found in many\napplications. Since CTS with irregular sampling rate are difficult to model\nwith standard Recurrent Neural Networks (RNNs), RNNs have been generalised to\nhave continuous-time hidden dynamics defined by a Neural Ordinary Differential\nEquation (Neural ODE), leading to the ODE-RNN model. Another approach that\nprovides a better modelling is that of the Latent ODE model, which constructs a\ncontinuous-time model where a latent state is defined at all times. The Latent\nODE model uses a standard RNN as the encoder and a Neural ODE as the decoder.\nHowever, since the RNN encoder leads to difficulties with missing data and\nill-defined latent variables, a Latent ODE-RNN model has recently been proposed\nthat uses a ODE-RNN model as the encoder instead. Both the Latent ODE and\nLatent ODE-RNN models are difficult to train due to the vanishing and exploding\ngradients problem. To overcome this problem, the main contribution of this\npaper is to propose and illustrate a new model based on a new Latent ODE using\nan ODE-LSTM (Long Short-Term Memory) network as an encoder -- the Latent\nODE-LSTM model. To limit the growth of the gradients the Norm Gradient Clipping\nstrategy was embedded on the Latent ODE-LSTM model. The performance evaluation\nof the new Latent ODE-LSTM (with and without Norm Gradient Clipping) for\nmodelling CTS with regular and irregular sampling rates is then demonstrated.\nNumerical experiments show that the new Latent ODE-LSTM performs better than\nLatent ODE-RNNs and can avoid the vanishing and exploding gradients during\ntraining.",
          "link": "http://arxiv.org/abs/2307.05126",
          "publishedOn": "2023-07-12T01:02:46.773Z",
          "wordCount": null,
          "title": "Enhancing Continuous Time Series Modelling with a Latent ODE-LSTM Approach. (arXiv:2307.05126v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Grimal_P/0/1/0/all/0/1\">Paul Grimal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borgne_H/0/1/0/all/0/1\">Herv&#xe9; Le Borgne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferret_O/0/1/0/all/0/1\">Olivier Ferret</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tourille_J/0/1/0/all/0/1\">Julien Tourille</a>",
          "description": "The progress in the generation of synthetic images has made it crucial to\nassess their quality. While several metrics have been proposed to assess the\nrendering of images, it is crucial for Text-to-Image (T2I) models, which\ngenerate images based on a prompt, to consider additional aspects such as to\nwhich extent the generated image matches the important content of the prompt.\nMoreover, although the generated images usually result from a random starting\npoint, the influence of this one is generally not considered. In this article,\nwe propose a new metric based on prompt templates to study the alignment\nbetween the content specified in the prompt and the corresponding generated\nimages. It allows us to better characterize the alignment in terms of the type\nof the specified objects, their number, and their color. We conducted a study\non several recent T2I models about various aspects. An additional interesting\nresult we obtained with our approach is that image quality can vary drastically\ndepending on the latent noise used as a seed for the images. We also quantify\nthe influence of the number of concepts in the prompt, their order as well as\ntheir (color) attributes. Finally, our method allows us to identify some latent\nseeds that produce better images than others, opening novel directions of\nresearch on this understudied topic.",
          "link": "http://arxiv.org/abs/2307.05134",
          "publishedOn": "2023-07-12T01:02:46.773Z",
          "wordCount": null,
          "title": "TIAM -- A Metric for Evaluating Alignment in Text-to-Image Generation. (arXiv:2307.05134v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.02011",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cai_T/0/1/0/all/0/1\">Tiffany Tianhui Cai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Namkoong_H/0/1/0/all/0/1\">Hongseok Namkoong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yadlowsky_S/0/1/0/all/0/1\">Steve Yadlowsky</a>",
          "description": "Prediction models can perform poorly when deployed to target distributions\ndifferent from the training distribution. To understand these operational\nfailure modes, we develop a method, called DIstribution Shift DEcomposition\n(DISDE), to attribute a drop in performance to different types of distribution\nshifts. Our approach decomposes the performance drop into terms for 1) an\nincrease in harder but frequently seen examples from training, 2) changes in\nthe relationship between features and outcomes, and 3) poor performance on\nexamples infrequent or unseen during training. These terms are defined by\nfixing a distribution on $X$ while varying the conditional distribution of $Y\n\\mid X$ between training and target, or by fixing the conditional distribution\nof $Y \\mid X$ while varying the distribution on $X$. In order to do this, we\ndefine a hypothetical distribution on $X$ consisting of values common in both\ntraining and target, over which it is easy to compare $Y \\mid X$ and thus\npredictive performance. We estimate performance on this hypothetical\ndistribution via reweighting methods. Empirically, we show how our method can\n1) inform potential modeling improvements across distribution shifts for\nemployment prediction on tabular census data, and 2) help to explain why\ncertain domain adaptation methods fail to improve model performance for\nsatellite image classification.",
          "link": "http://arxiv.org/abs/2303.02011",
          "publishedOn": "2023-07-12T01:02:46.772Z",
          "wordCount": null,
          "title": "Diagnosing Model Performance Under Distribution Shift. (arXiv:2303.02011v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04942",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bai_R/0/1/0/all/0/1\">Ruqi Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagchi_S/0/1/0/all/0/1\">Saurabh Bagchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inouye_D/0/1/0/all/0/1\">David I. Inouye</a>",
          "description": "While prior domain generalization (DG) benchmarks consider train-test dataset\nheterogeneity, we evaluate Federated DG which introduces federated learning\n(FL) specific challenges. Additionally, we explore domain-based heterogeneity\nin clients' local datasets - a realistic Federated DG scenario. Prior Federated\nDG evaluations are limited in terms of the number or heterogeneity of clients\nand dataset diversity. To address this gap, we propose an Federated DG\nbenchmark methodology that enables control of the number and heterogeneity of\nclients and provides metrics for dataset difficulty. We then apply our\nmethodology to evaluate 13 Federated DG methods, which include centralized DG\nmethods adapted to the FL context, FL methods that handle client heterogeneity,\nand methods designed specifically for Federated DG. Our results suggest that\ndespite some progress, there remain significant performance gaps in Federated\nDG particularly when evaluating with a large number of clients, high client\nheterogeneity, or more realistic datasets. Please check our extendable\nbenchmark code here: https://github.com/inouye-lab/FedDG_Benchmark.",
          "link": "http://arxiv.org/abs/2307.04942",
          "publishedOn": "2023-07-12T01:02:46.771Z",
          "wordCount": null,
          "title": "Benchmarking Algorithms for Federated Domain Generalization. (arXiv:2307.04942v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Emezue_C/0/1/0/all/0/1\">Chris Chinenye Emezue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drouin_A/0/1/0/all/0/1\">Alexandre Drouin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deleu_T/0/1/0/all/0/1\">Tristan Deleu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bauer_S/0/1/0/all/0/1\">Stefan Bauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>",
          "description": "The practical utility of causality in decision-making is widely recognized,\nwith causal discovery and inference being inherently intertwined. Nevertheless,\na notable gap exists in the evaluation of causal discovery methods, where\ninsufficient emphasis is placed on downstream inference. To address this gap,\nwe evaluate six established baseline causal discovery methods and a newly\nproposed method based on GFlowNets, on the downstream task of treatment effect\nestimation. Through the implementation of a robust evaluation procedure, we\noffer valuable insights into the efficacy of these causal discovery methods for\ntreatment effect estimation, considering both synthetic and real-world\nscenarios, as well as low-data scenarios. Furthermore, the results of our study\ndemonstrate that GFlowNets possess the capability to effectively capture a wide\nrange of useful and diverse ATE modes.",
          "link": "http://arxiv.org/abs/2307.04988",
          "publishedOn": "2023-07-12T01:02:46.771Z",
          "wordCount": null,
          "title": "Benchmarking Bayesian Causal Discovery Methods for Downstream Treatment Effect Estimation. (arXiv:2307.04988v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04870",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Na_W/0/1/0/all/0/1\">Woojoo Na</a>",
          "description": "We introduce Onion Universe Algorithm (OUA), a novel classification method in\nensemble learning. In particular, we show its applicability as a label model\nfor weakly supervised learning. OUA offers simplicity in implementation,\ncomputational efficiency, and does not rely on any assumptions regarding the\ndata or weak signals. The model is well suited for scenarios where fully\nlabeled data is not available. Our method is built upon geometrical\ninterpretation of the space spanned by weak signals. Empirical results support\nour analysis of the hidden geometric structure underlying general set of weak\nsignals and also illustrates that OUA works well in practice. We show empirical\nevidence that OUA performs favorably on common benchmark datasets compared to\nexisting label models for weakly supervised learning.",
          "link": "http://arxiv.org/abs/2307.04870",
          "publishedOn": "2023-07-12T01:02:46.770Z",
          "wordCount": null,
          "title": "Onion Universe Algorithm: Applications in Weakly Supervised Learning. (arXiv:2307.04870v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04957",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_W/0/1/0/all/0/1\">Wei Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wei Yu</a>",
          "description": "In reinforcement learning, the objective is almost always defined as a\n\\emph{cumulative} function over the rewards along the process. However, there\nare many optimal control and reinforcement learning problems in various\napplication fields, especially in communications and networking, where the\nobjectives are not naturally expressed as summations of the rewards. In this\npaper, we recognize the prevalence of non-cumulative objectives in various\nproblems, and propose a modification to existing algorithms for optimizing such\nobjectives. Specifically, we dive into the fundamental building block for many\noptimal control and reinforcement learning algorithms: the Bellman optimality\nequation. To optimize a non-cumulative objective, we replace the original\nsummation operation in the Bellman update rule with a generalized operation\ncorresponding to the objective. Furthermore, we provide sufficient conditions\non the form of the generalized operation as well as assumptions on the Markov\ndecision process under which the globally optimal convergence of the\ngeneralized Bellman updates can be guaranteed. We demonstrate the idea\nexperimentally with the bottleneck objective, i.e., the objectives determined\nby the minimum reward along the process, on classical optimal control and\nreinforcement learning tasks, as well as on two network routing problems on\nmaximizing the flow rates.",
          "link": "http://arxiv.org/abs/2307.04957",
          "publishedOn": "2023-07-12T01:02:46.754Z",
          "wordCount": null,
          "title": "Reinforcement Learning with Non-Cumulative Objective. (arXiv:2307.04957v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04937",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhimeng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jialiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1\">Teng Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Suhang Wang</a>",
          "description": "Graph neural networks have shown great ability in representation (GNNs)\nlearning on graphs, facilitating various tasks. Despite their great performance\nin modeling graphs, recent works show that GNNs tend to inherit and amplify the\nbias from training data, causing concerns of the adoption of GNNs in high-stake\nscenarios. Hence, many efforts have been taken for fairness-aware GNNs.\nHowever, most existing fair GNNs learn fair node representations by adopting\nstatistical fairness notions, which may fail to alleviate bias in the presence\nof statistical anomalies. Motivated by causal theory, there are several\nattempts utilizing graph counterfactual fairness to mitigate root causes of\nunfairness. However, these methods suffer from non-realistic counterfactuals\nobtained by perturbation or generation. In this paper, we take a causal view on\nfair graph learning problem. Guided by the casual analysis, we propose a novel\nframework CAF, which can select counterfactuals from training data to avoid\nnon-realistic counterfactuals and adopt selected counterfactuals to learn fair\nnode representations for node classification task. Extensive experiments on\nsynthetic and real-world datasets show the effectiveness of CAF.",
          "link": "http://arxiv.org/abs/2307.04937",
          "publishedOn": "2023-07-12T01:02:46.753Z",
          "wordCount": null,
          "title": "Improving Fairness of Graph Neural Networks: A Graph Counterfactual Perspective. (arXiv:2307.04937v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04946",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luther_K/0/1/0/all/0/1\">Kyle Luther</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seung_H/0/1/0/all/0/1\">H. Sebastian Seung</a>",
          "description": "Inverse problems generally require a regularizer or prior for a good\nsolution. A recent trend is to train a convolutional net to denoise images, and\nuse this net as a prior when solving the inverse problem. Several proposals\ndepend on a singular value decomposition of the forward operator, and several\nothers backpropagate through the denoising net at runtime. Here we propose a\nsimpler approach that combines the traditional gradient-based minimization of\nreconstruction error with denoising. Noise is also added at each step, so the\niterative dynamics resembles a Langevin or diffusion process. Both the level of\nadded noise and the size of the denoising step decay exponentially with time.\nWe apply our method to the problem of tomographic reconstruction from electron\nmicrographs acquired at multiple tilt angles. With empirical studies using\nsimulated tilt views, we find parameter settings for our method that produce\ngood results. We show that high accuracy can be achieved with as few as 50\ndenoising steps. We also compare with DDRM and DPS, more complex diffusion\nmethods of the kinds mentioned above. These methods are less accurate (as\nmeasured by MSE and SSIM) for our tomography problem, even after the generation\nhyperparameters are optimized. Finally we extend our method to reconstruction\nof arbitrary-sized images and show results on 128 $\\times$ 1568 pixel images",
          "link": "http://arxiv.org/abs/2307.04946",
          "publishedOn": "2023-07-12T01:02:46.752Z",
          "wordCount": null,
          "title": "DDGM: Solving inverse problems by Diffusive Denoising of Gradient-based Minimization. (arXiv:2307.04946v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04849",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sorokin_A/0/1/0/all/0/1\">Aleksei Sorokin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xinran Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_E/0/1/0/all/0/1\">Eric Hans Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_B/0/1/0/all/0/1\">Bolong Cheng</a>",
          "description": "Gradient boosted trees (GBTs) are ubiquitous models used by researchers,\nmachine learning (ML) practitioners, and data scientists because of their\nrobust performance, interpretable behavior, and ease-of-use. One critical\nchallenge in training GBTs is the tuning of their hyperparameters. In practice,\nselecting these hyperparameters is often done manually. Recently, the ML\ncommunity has advocated for tuning hyperparameters through black-box\noptimization and developed state-of-the-art systems to do so. However, applying\nsuch systems to tune GBTs suffers from two drawbacks. First, these systems are\nnot \\textit{model-aware}, rather they are designed to apply to a\n\\textit{generic} model; this leaves significant optimization performance on the\ntable. Second, using these systems requires \\textit{domain knowledge} such as\nthe choice of hyperparameter search space, which is an antithesis to the\nautomatic experimentation that black-box optimization aims to provide. In this\npaper, we present SigOpt Mulch, a model-aware hyperparameter tuning system\nspecifically designed for automated tuning of GBTs that provides two\nimprovements over existing systems. First, Mulch leverages powerful techniques\nin metalearning and multifidelity optimization to perform model-aware\nhyperparameter optimization. Second, it automates the process of learning\nperformant hyperparameters by making intelligent decisions about the\noptimization search space, thus reducing the need for user domain knowledge.\nThese innovations allow Mulch to identify good GBT hyperparameters far more\nefficiently -- and in a more seamless and user-friendly way -- than existing\nblack-box hyperparameter tuning systems.",
          "link": "http://arxiv.org/abs/2307.04849",
          "publishedOn": "2023-07-12T01:02:46.751Z",
          "wordCount": null,
          "title": "SigOpt Mulch: An Intelligent System for AutoML of Gradient Boosted Trees. (arXiv:2307.04849v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04841",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bordelon_B/0/1/0/all/0/1\">Blake Bordelon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Masset_P/0/1/0/all/0/1\">Paul Masset</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kuo_H/0/1/0/all/0/1\">Henry Kuo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pehlevan_C/0/1/0/all/0/1\">Cengiz Pehlevan</a>",
          "description": "Reinforcement learning has been successful across several applications in\nwhich agents have to learn to act in environments with sparse feedback.\nHowever, despite this empirical success there is still a lack of theoretical\nunderstanding of how the parameters of reinforcement learning models and the\nfeatures used to represent states interact to control the dynamics of learning.\nIn this work, we use concepts from statistical physics, to study the typical\ncase learning curves for temporal difference learning of a value function with\nlinear function approximators. Our theory is derived under a Gaussian\nequivalence hypothesis where averages over the random trajectories are replaced\nwith temporally correlated Gaussian feature averages and we validate our\nassumptions on small scale Markov Decision Processes. We find that the\nstochastic semi-gradient noise due to subsampling the space of possible\nepisodes leads to significant plateaus in the value error, unlike in\ntraditional gradient descent dynamics. We study how learning dynamics and\nplateaus depend on feature structure, learning rate, discount factor, and\nreward function. We then analyze how strategies like learning rate annealing\nand reward shaping can favorably alter learning dynamics and plateaus. To\nconclude, our work introduces new tools to open a new direction towards\ndeveloping a theory of learning dynamics in reinforcement learning.",
          "link": "http://arxiv.org/abs/2307.04841",
          "publishedOn": "2023-07-12T01:02:46.714Z",
          "wordCount": null,
          "title": "Dynamics of Temporal Difference Reinforcement Learning. (arXiv:2307.04841v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04895",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishay_A/0/1/0/all/0/1\">Adam Ishay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Joohyung Lee</a>",
          "description": "Constraint satisfaction problems (CSPs) are about finding values of variables\nthat satisfy the given constraints. We show that Transformer extended with\nrecurrence is a viable approach to learning to solve CSPs in an end-to-end\nmanner, having clear advantages over state-of-the-art methods such as Graph\nNeural Networks, SATNet, and some neuro-symbolic models. With the ability of\nTransformer to handle visual input, the proposed Recurrent Transformer can\nstraightforwardly be applied to visual constraint reasoning problems while\nsuccessfully addressing the symbol grounding problem. We also show how to\nleverage deductive knowledge of discrete constraints in the Transformer's\ninductive learning to achieve sample-efficient learning and semi-supervised\nlearning for CSPs.",
          "link": "http://arxiv.org/abs/2307.04895",
          "publishedOn": "2023-07-12T01:02:46.714Z",
          "wordCount": null,
          "title": "Learning to Solve Constraint Satisfaction Problems with Recurrent Transformer. (arXiv:2307.04895v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05350",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Shantanu Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1\">Ke Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arabshahi_F/0/1/0/all/0/1\">Forough Arabshahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batmanghelich_K/0/1/0/all/0/1\">Kayhan Batmanghelich</a>",
          "description": "The current approach to ML model design is either to choose a flexible\nBlackbox model and explain it post hoc or to start with an interpretable model.\nBlackbox models are flexible but difficult to explain, whereas interpretable\nmodels are designed to be explainable. However, developing interpretable models\nnecessitates extensive ML knowledge, and the resulting models tend to be less\nflexible, offering potentially subpar performance compared to their Blackbox\nequivalents. This paper aims to blur the distinction between a post hoc\nexplanation of a BlackBox and constructing interpretable models. We propose\nbeginning with a flexible BlackBox model and gradually \\emph{carving out} a\nmixture of interpretable models and a \\emph{residual network}. Our design\nidentifies a subset of samples and \\emph{routes} them through the interpretable\nmodels. The remaining samples are routed through a flexible residual network.\nWe adopt First Order Logic (FOL) as the interpretable model's backbone, which\nprovides basic reasoning on concepts retrieved from the BlackBox model. On the\nresidual network, we repeat the method until the proportion of data explained\nby the residual network falls below a desired threshold. Our approach offers\nseveral advantages. First, the mixture of interpretable and flexible residual\nnetworks results in almost no compromise in performance. Second, the route,\ninterpret, and repeat approach yields a highly flexible interpretable model.\nOur extensive experiment demonstrates the performance of the model on various\ndatasets. We show that by editing the FOL model, we can fix the shortcut\nlearned by the original BlackBox model. Finally, our method provides a\nframework for a hybrid symbolic-connectionist network that is simple to train\nand adaptable to many applications.",
          "link": "http://arxiv.org/abs/2307.05350",
          "publishedOn": "2023-07-12T01:02:46.714Z",
          "wordCount": null,
          "title": "Route, Interpret, Repeat: Blurring the line between post hoc explainability and interpretable models. (arXiv:2307.05350v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04850",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kariyappa_S/0/1/0/all/0/1\">Sanjay Kariyappa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsepenekas_L/0/1/0/all/0/1\">Leonidas Tsepenekas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lecue_F/0/1/0/all/0/1\">Freddy L&#xe9;cu&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magazzeni_D/0/1/0/all/0/1\">Daniele Magazzeni</a>",
          "description": "The SHAP framework provides a principled method to explain the predictions of\na model by computing feature importance. Motivated by applications in finance,\nwe introduce the Top-k Identification Problem (TkIP), where the objective is to\nidentify the k features with the highest SHAP values. While any method to\ncompute SHAP values with uncertainty estimates (such as KernelSHAP and\nSamplingSHAP) can be trivially adapted to solve TkIP, doing so is highly sample\ninefficient. The goal of our work is to improve the sample efficiency of\nexisting methods in the context of solving TkIP. Our key insight is that TkIP\ncan be framed as an Explore-m problem--a well-studied problem related to\nmulti-armed bandits (MAB). This connection enables us to improve sample\nefficiency by leveraging two techniques from the MAB literature: (1) a better\nstopping-condition (to stop sampling) that identifies when PAC (Probably\nApproximately Correct) guarantees have been met and (2) a greedy sampling\nscheme that judiciously allocates samples between different features. By\nadopting these methods we develop KernelSHAP@k and SamplingSHAP@k to\nefficiently solve TkIP, offering an average improvement of $5\\times$ in\nsample-efficiency and runtime across most common credit related datasets.",
          "link": "http://arxiv.org/abs/2307.04850",
          "publishedOn": "2023-07-12T01:02:46.713Z",
          "wordCount": null,
          "title": "SHAP@k:Efficient and Probably Approximately Correct (PAC) Identification of Top-k Features. (arXiv:2307.04850v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04869",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bagwe_G/0/1/0/all/0/1\">Gaurav Bagwe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1\">Xiaoyong Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_M/0/1/0/all/0/1\">Miao Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lan Zhang</a>",
          "description": "Federated continual learning (FCL) learns incremental tasks over time from\nconfidential datasets distributed across clients. This paper focuses on\nrehearsal-free FCL, which has severe forgetting issues when learning new tasks\ndue to the lack of access to historical task data. To address this issue, we\npropose Fed-CPrompt based on prompt learning techniques to obtain task-specific\nprompts in a communication-efficient way. Fed-CPrompt introduces two key\ncomponents, asynchronous prompt learning, and contrastive continual loss, to\nhandle asynchronous task arrival and heterogeneous data distributions in FCL,\nrespectively. Extensive experiments demonstrate the effectiveness of\nFed-CPrompt in achieving SOTA rehearsal-free FCL performance.",
          "link": "http://arxiv.org/abs/2307.04869",
          "publishedOn": "2023-07-12T01:02:46.704Z",
          "wordCount": null,
          "title": "Fed-CPrompt: Contrastive Prompt for Rehearsal-Free Federated Continual Learning. (arXiv:2307.04869v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05356",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_B/0/1/0/all/0/1\">Benny J. Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boggust_A/0/1/0/all/0/1\">Angie Boggust</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Satyanarayan_A/0/1/0/all/0/1\">Arvind Satyanarayan</a>",
          "description": "Captions that describe or explain charts help improve recall and\ncomprehension of the depicted data and provide a more accessible medium for\npeople with visual disabilities. However, current approaches for automatically\ngenerating such captions struggle to articulate the perceptual or cognitive\nfeatures that are the hallmark of charts (e.g., complex trends and patterns).\nIn response, we introduce VisText: a dataset of 12,441 pairs of charts and\ncaptions that describe the charts' construction, report key statistics, and\nidentify perceptual and cognitive phenomena. In VisText, a chart is available\nas three representations: a rasterized image, a backing data table, and a scene\ngraph -- a hierarchical representation of a chart's visual elements akin to a\nweb page's Document Object Model (DOM). To evaluate the impact of VisText, we\nfine-tune state-of-the-art language models on our chart captioning task and\napply prefix-tuning to produce captions that vary the semantic content they\nconvey. Our models generate coherent, semantically rich captions and perform on\npar with state-of-the-art chart captioning models across machine translation\nand text generation metrics. Through qualitative analysis, we identify six\nbroad categories of errors that our models make that can inform future work.",
          "link": "http://arxiv.org/abs/2307.05356",
          "publishedOn": "2023-07-12T01:02:46.704Z",
          "wordCount": null,
          "title": "VisText: A Benchmark for Semantically Rich Chart Captioning. (arXiv:2307.05356v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2207.06960",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patel_N/0/1/0/all/0/1\">Nilay Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flanigan_J/0/1/0/all/0/1\">Jeffrey Flanigan</a>",
          "description": "Human language is known to exhibit a nested, hierarchical structure, allowing\nus to form complex sentences out of smaller pieces. However, many\nstate-of-the-art neural networks models such as Transformers have no explicit\nhierarchical structure in its architecture -- that is, they don't have an\ninductive bias toward hierarchical structure. Additionally, Transformers are\nknown to perform poorly on compositional generalization tasks which require\nsuch structures. In this paper, we introduce Treeformer, a general-purpose\nencoder module inspired by the CKY algorithm which learns a composition\noperator and pooling function to construct hierarchical encodings for phrases\nand sentences. Our extensive experiments demonstrate the benefits of\nincorporating hierarchical structure into the Transformer and show significant\nimprovements in compositional generalization as well as in downstream tasks\nsuch as machine translation, abstractive summarization, and various natural\nlanguage understanding tasks.",
          "link": "http://arxiv.org/abs/2207.06960",
          "publishedOn": "2023-07-12T01:02:46.704Z",
          "wordCount": null,
          "title": "Forming Trees with Treeformers. (arXiv:2207.06960v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.08413",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beltran_E/0/1/0/all/0/1\">Enrique Tom&#xe1;s Mart&#xed;nez Beltr&#xe1;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_M/0/1/0/all/0/1\">Mario Quiles P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchez_P/0/1/0/all/0/1\">Pedro Miguel S&#xe1;nchez S&#xe1;nchez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernal_S/0/1/0/all/0/1\">Sergio L&#xf3;pez Bernal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bovet_G/0/1/0/all/0/1\">G&#xe9;r&#xf4;me Bovet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_M/0/1/0/all/0/1\">Manuel Gil P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_G/0/1/0/all/0/1\">Gregorio Mart&#xed;nez P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celdran_A/0/1/0/all/0/1\">Alberto Huertas Celdr&#xe1;n</a>",
          "description": "In the last decade, Federated Learning (FL) has gained relevance in training\ncollaborative models without sharing sensitive data. Since its birth,\nCentralized FL (CFL) has been the most common approach in the literature, where\na central entity creates a global model. However, a centralized approach leads\nto increased latency due to bottlenecks, heightened vulnerability to system\nfailures, and trustworthiness concerns affecting the entity responsible for the\nglobal model creation. Decentralized Federated Learning (DFL) emerged to\naddress these concerns by promoting decentralized model aggregation and\nminimizing reliance on centralized architectures. However, despite the work\ndone in DFL, the literature has not (i) studied the main aspects\ndifferentiating DFL and CFL; (ii) analyzed DFL frameworks to create and\nevaluate new solutions; and (iii) reviewed application scenarios using DFL.\nThus, this article identifies and analyzes the main fundamentals of DFL in\nterms of federation architectures, topologies, communication mechanisms,\nsecurity approaches, and key performance indicators. Additionally, the paper at\nhand explores existing mechanisms to optimize critical DFL fundamentals. Then,\nthe most relevant features of the current DFL frameworks are reviewed and\ncompared. After that, it analyzes the most used DFL application scenarios,\nidentifying solutions based on the fundamentals and frameworks previously\ndefined. Finally, the evolution of existing DFL solutions is studied to provide\na list of trends, lessons learned, and open challenges.",
          "link": "http://arxiv.org/abs/2211.08413",
          "publishedOn": "2023-07-12T01:02:46.704Z",
          "wordCount": null,
          "title": "Decentralized Federated Learning: Fundamentals, State of the Art, Frameworks, Trends, and Challenges. (arXiv:2211.08413v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05249",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yang_Z/0/1/0/all/0/1\">Zhiwen Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_Y/0/1/0/all/0/1\">Yang Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_H/0/1/0/all/0/1\">Hui Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wei_B/0/1/0/all/0/1\">Bingzheng Wei</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fan_Y/0/1/0/all/0/1\">Yubo Fan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1\">Yan Xu</a>",
          "description": "Multi-center positron emission tomography (PET) image synthesis aims at\nrecovering low-dose PET images from multiple different centers. The\ngeneralizability of existing methods can still be suboptimal for a multi-center\nstudy due to domain shifts, which result from non-identical data distribution\namong centers with different imaging systems/protocols. While some approaches\naddress domain shifts by training specialized models for each center, they are\nparameter inefficient and do not well exploit the shared knowledge across\ncenters. To address this, we develop a generalist model that shares\narchitecture and parameters across centers to utilize the shared knowledge.\nHowever, the generalist model can suffer from the center interference issue,\n\\textit{i.e.} the gradient directions of different centers can be inconsistent\nor even opposite owing to the non-identical data distribution. To mitigate such\ninterference, we introduce a novel dynamic routing strategy with cross-layer\nconnections that routes data from different centers to different experts.\nExperiments show that our generalist model with dynamic routing (DRMC) exhibits\nexcellent generalizability across centers. Code and data are available at:\nhttps://github.com/Yaziwel/Multi-Center-PET-Image-Synthesis.",
          "link": "http://arxiv.org/abs/2307.05249",
          "publishedOn": "2023-07-12T01:02:46.703Z",
          "wordCount": null,
          "title": "DRMC: A Generalist Model with Dynamic Routing for Multi-Center PET Image Synthesis. (arXiv:2307.05249v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05358",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bai_S/0/1/0/all/0/1\">Sikai Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuaicheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_W/0/1/0/all/0/1\">Weiming Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kunlin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1\">Jun Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1\">Shuai Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Junyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Song Guo</a>",
          "description": "Federated learning has become a popular method to learn from decentralized\nheterogeneous data. Federated semi-supervised learning (FSSL) emerges to train\nmodels from a small fraction of labeled data due to label scarcity on\ndecentralized clients. Existing FSSL methods assume independent and identically\ndistributed (IID) labeled data across clients and consistent class distribution\nbetween labeled and unlabeled data within a client. This work studies a more\npractical and challenging scenario of FSSL, where data distribution is\ndifferent not only across clients but also within a client between labeled and\nunlabeled data. To address this challenge, we propose a novel FSSL framework\nwith dual regulators, FedDure.} FedDure lifts the previous assumption with a\ncoarse-grained regulator (C-reg) and a fine-grained regulator (F-reg): C-reg\nregularizes the updating of the local model by tracking the learning effect on\nlabeled data distribution; F-reg learns an adaptive weighting scheme tailored\nfor unlabeled instances in each client. We further formulate the client model\ntraining as bi-level optimization that adaptively optimizes the model in the\nclient with two regulators. Theoretically, we show the convergence guarantee of\nthe dual regulators. Empirically, we demonstrate that FedDure is superior to\nthe existing methods across a wide range of settings, notably by more than 11%\non CIFAR-10 and CINIC-10 datasets.",
          "link": "http://arxiv.org/abs/2307.05358",
          "publishedOn": "2023-07-12T01:02:46.703Z",
          "wordCount": null,
          "title": "Combating Data Imbalances in Federated Semi-supervised Learning with Dual Regulators. (arXiv:2307.05358v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05284",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiashuo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_P/0/1/0/all/0/1\">Peng Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Namkoong_H/0/1/0/all/0/1\">Hongseok Namkoong</a>",
          "description": "Different distribution shifts require different algorithmic and operational\ninterventions. Methodological research must be grounded by the specific shifts\nthey address. Although nascent benchmarks provide a promising empirical\nfoundation, they implicitly focus on covariate shifts, and the validity of\nempirical findings depends on the type of shift, e.g., previous observations on\nalgorithmic performance can fail to be valid when the $Y|X$ distribution\nchanges. We conduct a thorough investigation of natural shifts in 5 tabular\ndatasets over 86,000 model configurations, and find that $Y|X$-shifts are most\nprevalent. To encourage researchers to develop a refined language for\ndistribution shifts, we build WhyShift, an empirical testbed of curated\nreal-world shifts where we characterize the type of shift we benchmark\nperformance over. Since $Y|X$-shifts are prevalent in tabular settings, we\nidentify covariate regions that suffer the biggest $Y|X$-shifts and discuss\nimplications for algorithmic and data-based interventions. Our testbed\nhighlights the importance of future research that builds an understanding of\nhow distributions differ.",
          "link": "http://arxiv.org/abs/2307.05284",
          "publishedOn": "2023-07-12T01:02:46.702Z",
          "wordCount": null,
          "title": "On the Need for a Language Describing Distribution Shifts: Illustrations on Tabular Datasets. (arXiv:2307.05284v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05217",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chatzianastasis_M/0/1/0/all/0/1\">Michail Chatzianastasis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikolentzos_G/0/1/0/all/0/1\">Giannis Nikolentzos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vazirgiannis_M/0/1/0/all/0/1\">Michalis Vazirgiannis</a>",
          "description": "Graph neural networks have become the standard approach for dealing with\nlearning problems on graphs. Among the different variants of graph neural\nnetworks, graph attention networks (GATs) have been applied with great success\nto different tasks. In the GAT model, each node assigns an importance score to\nits neighbors using an attention mechanism. However, similar to other graph\nneural networks, GATs aggregate messages from nodes that belong to different\nclasses, and therefore produce node representations that are not well separated\nwith respect to the different classes, which might hurt their performance. In\nthis work, to alleviate this problem, we propose a new technique that can be\nincorporated into any graph attention model to encourage higher attention\nscores between nodes that share the same class label. We evaluate the proposed\nmethod on several node classification datasets demonstrating increased\nperformance over standard baseline models.",
          "link": "http://arxiv.org/abs/2307.05217",
          "publishedOn": "2023-07-12T01:02:46.700Z",
          "wordCount": null,
          "title": "Supervised Attention Using Homophily in Graph Neural Networks. (arXiv:2307.05217v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05431",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Mathieu_E/0/1/0/all/0/1\">Emile Mathieu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dutordoir_V/0/1/0/all/0/1\">Vincent Dutordoir</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hutchinson_M/0/1/0/all/0/1\">Michael J. Hutchinson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bortoli_V/0/1/0/all/0/1\">Valentin De Bortoli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Teh_Y/0/1/0/all/0/1\">Yee Whye Teh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1\">Richard E. Turner</a>",
          "description": "Denoising diffusion models have proven to be a flexible and effective\nparadigm for generative modelling. Their recent extension to infinite\ndimensional Euclidean spaces has allowed for the modelling of stochastic\nprocesses. However, many problems in the natural sciences incorporate\nsymmetries and involve data living in non-Euclidean spaces. In this work, we\nextend the framework of diffusion models to incorporate a series of geometric\npriors in infinite-dimension modelling. We do so by a) constructing a noising\nprocess which admits, as limiting distribution, a geometric Gaussian process\nthat transforms under the symmetry group of interest, and b) approximating the\nscore with a neural network that is equivariant w.r.t. this group. We show that\nwith these conditions, the generative functional model admits the same\nsymmetry. We demonstrate scalability and capacity of the model, using a novel\nLangevin-based conditional sampler, to fit complex scalar and vector fields,\nwith Euclidean and spherical codomain, on synthetic and real-world weather\ndata.",
          "link": "http://arxiv.org/abs/2307.05431",
          "publishedOn": "2023-07-12T01:02:46.700Z",
          "wordCount": null,
          "title": "Geometric Neural Diffusion Processes. (arXiv:2307.05431v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04868",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tjandra_D/0/1/0/all/0/1\">Donna Tjandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiens_J/0/1/0/all/0/1\">Jenna Wiens</a>",
          "description": "Noisy training labels can hurt model performance. Most approaches that aim to\naddress label noise assume label noise is independent from the input features.\nIn practice, however, label noise is often feature or\n\\textit{instance-dependent}, and therefore biased (i.e., some instances are\nmore likely to be mislabeled than others). E.g., in clinical care, female\npatients are more likely to be under-diagnosed for cardiovascular disease\ncompared to male patients. Approaches that ignore this dependence can produce\nmodels with poor discriminative performance, and in many healthcare settings,\ncan exacerbate issues around health disparities. In light of these limitations,\nwe propose a two-stage approach to learn in the presence instance-dependent\nlabel noise. Our approach utilizes \\textit{\\anchor points}, a small subset of\ndata for which we know the observed and ground truth labels. On several tasks,\nour approach leads to consistent improvements over the state-of-the-art in\ndiscriminative performance (AUROC) while mitigating bias (area under the\nequalized odds curve, AUEOC). For example, when predicting acute respiratory\nfailure onset on the MIMIC-III dataset, our approach achieves a harmonic mean\n(AUROC and AUEOC) of 0.84 (SD [standard deviation] 0.01) while that of the next\nbest baseline is 0.81 (SD 0.01). Overall, our approach improves accuracy while\nmitigating potential bias compared to existing approaches in the presence of\ninstance-dependent label noise.",
          "link": "http://arxiv.org/abs/2307.04868",
          "publishedOn": "2023-07-12T01:02:46.676Z",
          "wordCount": null,
          "title": "Leveraging an Alignment Set in Tackling Instance-Dependent Label Noise. (arXiv:2307.04868v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04995",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zixuan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haojie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_J/0/1/0/all/0/1\">Jingze Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Liyan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_H/0/1/0/all/0/1\">Huanqi Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kezhao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Shizhi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Penghan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_J/0/1/0/all/0/1\">Jidong Zhai</a>",
          "description": "Deep neural networks (DNNs) are of critical use in different domains. To\naccelerate DNN computation, tensor compilers are proposed to generate efficient\ncode on different domain-specific accelerators. Existing tensor compilers\nmainly focus on optimizing computation efficiency. However, memory access is\nbecoming a key performance bottleneck because the computational performance of\naccelerators is increasing much faster than memory performance. The lack of\ndirect description of memory access and data dependence in current tensor\ncompilers' intermediate representation (IR) brings significant challenges to\ngenerate memory-efficient code.\n\nIn this paper, we propose IntelliGen, a tensor compiler that can generate\nhigh-performance code for memory-intensive operators by considering both\ncomputation and data movement optimizations. IntelliGen represent a DNN program\nusing GIR, which includes primitives indicating its computation, data movement,\nand parallel strategies. This information will be further composed as an\ninstruction-level dataflow graph to perform holistic optimizations by searching\ndifferent memory access patterns and computation operations, and generating\nmemory-efficient code on different hardware. We evaluate IntelliGen on NVIDIA\nGPU, AMD GPU, and Cambricon MLU, showing speedup up to 1.97x, 2.93x, and\n16.91x(1.28x, 1.23x, and 2.31x on average), respectively, compared to current\nmost performant frameworks.",
          "link": "http://arxiv.org/abs/2307.04995",
          "publishedOn": "2023-07-12T01:02:46.676Z",
          "wordCount": null,
          "title": "PowerFusion: A Tensor Compiler with Explicit Data Movement Description and Instruction-level Graph IR. (arXiv:2307.04995v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05080",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lad_V/0/1/0/all/0/1\">Vedang Lad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mueller_J/0/1/0/all/0/1\">Jonas Mueller</a>",
          "description": "The labor-intensive annotation process of semantic segmentation datasets is\noften prone to errors, since humans struggle to label every pixel correctly. We\nstudy algorithms to automatically detect such annotation errors, in particular\nmethods to score label quality, such that the images with the lowest scores are\nleast likely to be correctly labeled. This helps prioritize what data to review\nin order to ensure a high-quality training/evaluation dataset, which is\ncritical in sensitive applications such as medical imaging and autonomous\nvehicles. Widely applicable, our label quality scores rely on probabilistic\npredictions from a trained segmentation model -- any model architecture and\ntraining procedure can be utilized. Here we study 7 different label quality\nscoring methods used in conjunction with a DeepLabV3+ or a FPN segmentation\nmodel to detect annotation errors in a version of the SYNTHIA dataset.\nPrecision-recall evaluations reveal a score -- the soft-minimum of the\nmodel-estimated likelihoods of each pixel's annotated class -- that is\nparticularly effective to identify images that are mislabeled, across multiple\ntypes of annotation error.",
          "link": "http://arxiv.org/abs/2307.05080",
          "publishedOn": "2023-07-12T01:02:46.676Z",
          "wordCount": null,
          "title": "Estimating label quality and errors in semantic segmentation data via any model. (arXiv:2307.05080v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04905",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuechen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mingchen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1\">Xiangyu Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiasi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_Chowdhury_A/0/1/0/all/0/1\">Amit K. Roy-Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suresh_A/0/1/0/all/0/1\">Ananda Theertha Suresh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oymak_S/0/1/0/all/0/1\">Samet Oymak</a>",
          "description": "The growth and diversity of machine learning applications motivate a\nrethinking of learning with mobile and edge devices. How can we address diverse\nclient goals and learn with scarce heterogeneous data? While federated learning\naims to address these issues, it has challenges hindering a unified solution.\nLarge transformer models have been shown to work across a variety of tasks\nachieving remarkable few-shot adaptation. This raises the question: Can clients\nuse a single general-purpose model, rather than custom models for each task,\nwhile obeying device and network constraints? In this work, we investigate\npretrained transformers (PTF) to achieve these on-device learning goals and\nthoroughly explore the roles of model size and modularity, where the latter\nrefers to adaptation through modules such as prompts or adapters. Focusing on\nfederated learning, we demonstrate that: (1) Larger scale shrinks the accuracy\ngaps between alternative approaches and improves heterogeneity robustness.\nScale allows clients to run more local SGD epochs which can significantly\nreduce the number of communication rounds. At the extreme, clients can achieve\nrespectable accuracy locally highlighting the potential of fully-local\nlearning. (2) Modularity, by design, enables $>$100$\\times$ less communication\nin bits. Surprisingly, it also boosts the generalization capability of local\nadaptation methods and the robustness of smaller PTFs. Finally, it enables\nclients to solve multiple unrelated tasks simultaneously using a single PTF,\nwhereas full updates are prone to catastrophic forgetting. These insights on\nscale and modularity motivate a new federated learning approach we call \"You\nOnly Load Once\" (FedYolo): The clients load a full PTF model once and all\nfuture updates are accomplished through communication-efficient modules with\nlimited catastrophic-forgetting, where each task is assigned to its own module.",
          "link": "http://arxiv.org/abs/2307.04905",
          "publishedOn": "2023-07-12T01:02:46.675Z",
          "wordCount": null,
          "title": "FedYolo: Augmenting Federated Learning with Pretrained Transformers. (arXiv:2307.04905v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.10343",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Tung Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brandstetter_J/0/1/0/all/0/1\">Johannes Brandstetter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kapoor_A/0/1/0/all/0/1\">Ashish Kapoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_J/0/1/0/all/0/1\">Jayesh K. Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grover_A/0/1/0/all/0/1\">Aditya Grover</a>",
          "description": "Most state-of-the-art approaches for weather and climate modeling are based\non physics-informed numerical models of the atmosphere. These approaches aim to\nmodel the non-linear dynamics and complex interactions between multiple\nvariables, which are challenging to approximate. Additionally, many such\nnumerical models are computationally intensive, especially when modeling the\natmospheric phenomenon at a fine-grained spatial and temporal resolution.\nRecent data-driven approaches based on machine learning instead aim to directly\nsolve a downstream forecasting or projection task by learning a data-driven\nfunctional mapping using deep neural networks. However, these networks are\ntrained using curated and homogeneous climate datasets for specific\nspatiotemporal tasks, and thus lack the generality of numerical models. We\ndevelop and demonstrate ClimaX, a flexible and generalizable deep learning\nmodel for weather and climate science that can be trained using heterogeneous\ndatasets spanning different variables, spatio-temporal coverage, and physical\ngroundings. ClimaX extends the Transformer architecture with novel encoding and\naggregation blocks that allow effective use of available compute while\nmaintaining general utility. ClimaX is pre-trained with a self-supervised\nlearning objective on climate datasets derived from CMIP6. The pre-trained\nClimaX can then be fine-tuned to address a breadth of climate and weather\ntasks, including those that involve atmospheric variables and spatio-temporal\nscales unseen during pretraining. Compared to existing data-driven baselines,\nwe show that this generality in ClimaX results in superior performance on\nbenchmarks for weather forecasting and climate projections, even when\npretrained at lower resolutions and compute budgets. The source code is\navailable at https://github.com/microsoft/ClimaX.",
          "link": "http://arxiv.org/abs/2301.10343",
          "publishedOn": "2023-07-12T01:02:46.674Z",
          "wordCount": null,
          "title": "ClimaX: A foundation model for weather and climate. (arXiv:2301.10343v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05199",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Franc_V/0/1/0/all/0/1\">Vojtech Franc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prusa_D/0/1/0/all/0/1\">Daniel Prusa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paplham_J/0/1/0/all/0/1\">Jakub Paplham</a>",
          "description": "The optimal prediction strategy for out-of-distribution (OOD) setups is a\nfundamental question in machine learning. In this paper, we address this\nquestion and present several contributions. We propose three reject option\nmodels for OOD setups: the Cost-based model, the Bounded TPR-FPR model, and the\nBounded Precision-Recall model. These models extend the standard reject option\nmodels used in non-OOD setups and define the notion of an optimal OOD selective\nclassifier. We establish that all the proposed models, despite their different\nformulations, share a common class of optimal strategies. Motivated by the\noptimal strategy, we introduce double-score OOD methods that leverage\nuncertainty scores from two chosen OOD detectors: one focused on OOD/ID\ndiscrimination and the other on misclassification detection. The experimental\nresults consistently demonstrate the superior performance of this simple\nstrategy compared to state-of-the-art methods. Additionally, we propose novel\nevaluation metrics derived from the definition of the optimal strategy under\nthe proposed OOD rejection models. These new metrics provide a comprehensive\nand reliable assessment of OOD methods without the deficiencies observed in\nexisting evaluation approaches.",
          "link": "http://arxiv.org/abs/2307.05199",
          "publishedOn": "2023-07-12T01:02:46.673Z",
          "wordCount": null,
          "title": "Reject option models comprising out-of-distribution detection. (arXiv:2307.05199v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05252",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Simon_H/0/1/0/all/0/1\">Hans Ulrich Simon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Telle_J/0/1/0/all/0/1\">Jan Arne Telle</a>",
          "description": "Imagine a learner L who tries to infer a hidden concept from a collection of\nobservations. Building on the work [4] of Ferri et al., we assume the learner\nto be parameterized by priors P(c) and by c-conditional likelihoods P(z|c)\nwhere c ranges over all concepts in a given class C and z ranges over all\nobservations in an observation set Z. L is called a MAP-learner (resp. an\nMLE-learner) if it thinks of a collection S of observations as a random sample\nand returns the concept with the maximum a-posteriori probability (resp. the\nconcept which maximizes the c-conditional likelihood of S). Depending on\nwhether L assumes that S is obtained from ordered or unordered sampling resp.\nfrom sampling with or without replacement, we can distinguish four different\nsampling modes. Given a target concept c in C, a teacher for a MAP-learner L\naims at finding a smallest collection of observations that causes L to return\nc. This approach leads in a natural manner to various notions of a MAP- or\nMLE-teaching dimension of a concept class C. Our main results are: We show that\nthis teaching model has some desirable monotonicity properties. We clarify how\nthe four sampling modes are related to each other. As for the (important!)\nspecial case, where concepts are subsets of a domain and observations are\n0,1-labeled examples, we obtain some additional results. First of all, we\ncharacterize the MAP- and MLE-teaching dimension associated with an optimally\nparameterized MAP-learner graph-theoretically. From this central result, some\nother ones are easy to derive. It is shown, for instance, that the MLE-teaching\ndimension is either equal to the MAP-teaching dimension or exceeds the latter\nby 1. It is shown furthermore that these dimensions can be bounded from above\nby the so-called antichain number, the VC-dimension and related combinatorial\nparameters. Moreover they can be computed in polynomial time.",
          "link": "http://arxiv.org/abs/2307.05252",
          "publishedOn": "2023-07-12T01:02:46.673Z",
          "wordCount": null,
          "title": "MAP- and MLE-Based Teaching. (arXiv:2307.05252v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sengupta_A/0/1/0/all/0/1\">Agnimitra Sengupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Adway Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guler_S/0/1/0/all/0/1\">S. Ilgin Guler</a>",
          "description": "Deep learning (DL) methods have outperformed parametric models such as\nhistorical average, ARIMA and variants in predicting traffic variables into\nshort and near-short future, that are critical for traffic management.\nSpecifically, recurrent neural network (RNN) and its variants (e.g. long\nshort-term memory) are designed to retain long-term temporal correlations and\ntherefore are suitable for modeling sequences. However, multi-regime models\nassume the traffic system to evolve through multiple states (say, free-flow,\ncongestion in traffic) with distinct characteristics, and hence, separate\nmodels are trained to characterize the traffic dynamics within each regime. For\ninstance, Markov-switching models with a hidden Markov model (HMM) for regime\nidentification is capable of capturing complex dynamic patterns and\nnon-stationarity. Interestingly, both HMM and LSTM can be used for modeling an\nobservation sequence from a set of latent or, hidden state variables. In LSTM,\nthe latent variable is computed in a deterministic manner from the current\nobservation and the previous latent variable, while, in HMM, the set of latent\nvariables is a Markov chain. Inspired by research in natural language\nprocessing, a hybrid hidden Markov-LSTM model that is capable of learning\ncomplementary features in traffic data is proposed for traffic flow prediction.\nResults indicate significant performance gains in using hybrid architecture\ncompared to conventional methods such as Markov switching ARIMA and LSTM.",
          "link": "http://arxiv.org/abs/2307.04954",
          "publishedOn": "2023-07-12T01:02:46.602Z",
          "wordCount": null,
          "title": "Hybrid hidden Markov LSTM for short-term traffic flow prediction. (arXiv:2307.04954v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04887",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_V/0/1/0/all/0/1\">Vincent Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Han Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_R/0/1/0/all/0/1\">Ruo Yu Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Javed_K/0/1/0/all/0/1\">Khurram Javed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_A/0/1/0/all/0/1\">Adam White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_M/0/1/0/all/0/1\">Martha White</a>",
          "description": "Catastrophic interference is common in many network-based learning systems,\nand many proposals exist for mitigating it. Before overcoming interference we\nmust understand it better. In this work, we provide a definition and novel\nmeasure of interference for value-based reinforcement learning methods such as\nFitted Q-Iteration and DQN. We systematically evaluate our measure of\ninterference, showing that it correlates with instability in control\nperformance, across a variety of network architectures. Our new interference\nmeasure allows us to ask novel scientific questions about commonly used deep\nlearning architectures and study learning algorithms which mitigate\ninterference. Lastly, we outline a class of algorithms which we call\nonline-aware that are designed to mitigate interference, and show they do\nreduce interference according to our measure and that they improve stability\nand performance in several classic control environments.",
          "link": "http://arxiv.org/abs/2307.04887",
          "publishedOn": "2023-07-12T01:02:46.600Z",
          "wordCount": null,
          "title": "Measuring and Mitigating Interference in Reinforcement Learning. (arXiv:2307.04887v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05318",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Ramos_M/0/1/0/all/0/1\">Mayk Caldas Ramos</a>, <a href=\"http://arxiv.org/find/physics/1/au:+White_A/0/1/0/all/0/1\">Andrew D. White</a>",
          "description": "Aqueous solubility is a valuable yet challenging property to predict.\nComputing solubility using first-principles methods requires accounting for the\ncompeting effects of entropy and enthalpy, resulting in long computations for\nrelatively poor accuracy. Data-driven approaches, such as deep learning, offer\nimproved accuracy and computational efficiency but typically lack uncertainty\nquantification. Additionally, ease of use remains a concern for any\ncomputational technique, resulting in the sustained popularity of group-based\ncontribution methods. In this work, we addressed these problems with a deep\nlearning model with predictive uncertainty that runs on a static website\n(without a server). This approach moves computing needs onto the website\nvisitor without requiring installation, removing the need to pay for and\nmaintain servers. Our model achieves satisfactory results in solubility\nprediction. Furthermore, we demonstrate how to create molecular property\nprediction models that balance uncertainty and ease of use. The code is\navailable at \\url{https://github.com/ur-whitelab/mol.dev}, and the model is\nusable at \\url{https://mol.dev}.",
          "link": "http://arxiv.org/abs/2307.05318",
          "publishedOn": "2023-07-12T01:02:46.599Z",
          "wordCount": null,
          "title": "Predicting small molecules solubilities on endpoint devices using deep ensemble neural networks. (arXiv:2307.05318v1 [physics.chem-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04952",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yachuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zongmin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+P%2E_X/0/1/0/all/0/1\">Xavier Soria P.</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chaozhi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Q/0/1/0/all/0/1\">Qian Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yun Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hua Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiangdong Wang</a>",
          "description": "The significance of multi-scale features has been gradually recognized by the\nedge detection community. However, the fusion of multi-scale features increases\nthe complexity of the model, which is not friendly to practical application. In\nthis work, we propose a Compact Twice Fusion Network (CTFN) to fully integrate\nmulti-scale features while maintaining the compactness of the model. CTFN\nincludes two lightweight multi-scale feature fusion modules: a Semantic\nEnhancement Module (SEM) that can utilize the semantic information contained in\ncoarse-scale features to guide the learning of fine-scale features, and a\nPseudo Pixel-level Weighting (PPW) module that aggregate the complementary\nmerits of multi-scale features by assigning weights to all features.\nNotwithstanding all this, the interference of texture noise makes the correct\nclassification of some pixels still a challenge. For these hard samples, we\npropose a novel loss function, coined Dynamic Focal Loss, which reshapes the\nstandard cross-entropy loss and dynamically adjusts the weights to correct the\ndistribution of hard samples. We evaluate our method on three datasets, i.e.,\nBSDS500, NYUDv2, and BIPEDv2. Compared with state-of-the-art methods, CTFN\nachieves competitive accuracy with less parameters and computational cost.\nApart from the backbone, CTFN requires only 0.1M additional parameters, which\nreduces its computation cost to just 60% of other state-of-the-art methods. The\ncodes are available at https://github.com/Li-yachuan/CTFN-pytorch-master.",
          "link": "http://arxiv.org/abs/2307.04952",
          "publishedOn": "2023-07-12T01:02:46.597Z",
          "wordCount": null,
          "title": "Compact Twice Fusion Network for Edge Detection. (arXiv:2307.04952v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04962",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patankar_S/0/1/0/all/0/1\">Shubhankar P. Patankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouellet_M/0/1/0/all/0/1\">Mathieu Ouellet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cervino_J/0/1/0/all/0/1\">Juan Cervino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1\">Alejandro Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murphy_K/0/1/0/all/0/1\">Kieran A. Murphy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bassett_D/0/1/0/all/0/1\">Dani S. Bassett</a>",
          "description": "Intrinsically motivated exploration has proven useful for reinforcement\nlearning, even without additional extrinsic rewards. When the environment is\nnaturally represented as a graph, how to guide exploration best remains an open\nquestion. In this work, we propose a novel approach for exploring\ngraph-structured data motivated by two theories of human curiosity: the\ninformation gap theory and the compression progress theory. The theories view\ncuriosity as an intrinsic motivation to optimize for topological features of\nsubgraphs induced by the visited nodes in the environment. We use these\nproposed features as rewards for graph neural-network-based reinforcement\nlearning. On multiple classes of synthetically generated graphs, we find that\ntrained agents generalize to larger environments and to longer exploratory\nwalks than are seen during training. Our method computes more efficiently than\nthe greedy evaluation of the relevant topological properties. The proposed\nintrinsic motivations bear particular relevance for recommender systems. We\ndemonstrate that curiosity-based recommendations are more predictive of human\nbehavior than PageRank centrality for several real-world graph datasets,\nincluding MovieLens, Amazon Books, and Wikispeedia.",
          "link": "http://arxiv.org/abs/2307.04962",
          "publishedOn": "2023-07-12T01:02:46.595Z",
          "wordCount": null,
          "title": "Intrinsically motivated graph exploration using network theories of human curiosity. (arXiv:2307.04962v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Verma_G/0/1/0/all/0/1\">Ghanshyam Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sengupta_S/0/1/0/all/0/1\">Shovon Sengupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simanta_S/0/1/0/all/0/1\">Simon Simanta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perge_J/0/1/0/all/0/1\">Janos A. Perge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pillai_D/0/1/0/all/0/1\">Devishree Pillai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCrae_J/0/1/0/all/0/1\">John P. McCrae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buitelaar_P/0/1/0/all/0/1\">Paul Buitelaar</a>",
          "description": "Personalized recommendations have a growing importance in direct marketing,\nwhich motivates research to enhance customer experiences by knowledge graph\n(KG) applications. For example, in financial services, companies may benefit\nfrom providing relevant financial articles to their customers to cultivate\nrelationships, foster client engagement and promote informed financial\ndecisions. While several approaches center on KG-based recommender systems for\nimproved content, in this study we focus on interpretable KG-based recommender\nsystems for decision making.To this end, we present two knowledge graph-based\napproaches for personalized article recommendations for a set of customers of a\nlarge multinational financial services company. The first approach employs\nReinforcement Learning and the second approach uses the XGBoost algorithm for\nrecommending articles to the customers. Both approaches make use of a KG\ngenerated from both structured (tabular data) and unstructured data (a large\nbody of text data).Using the Reinforcement Learning-based recommender system we\ncould leverage the graph traversal path leading to the recommendation as a way\nto generate interpretations (Path Directed Reasoning (PDR)). In the\nXGBoost-based approach, one can also provide explainable results using post-hoc\nmethods such as SHAP (SHapley Additive exPlanations) and ELI5 (Explain Like I\nam Five).Importantly, our approach offers explainable results, promoting better\ndecision-making. This study underscores the potential of combining advanced\nmachine learning techniques with KG-driven insights to bolster experience in\ncustomer relationship management.",
          "link": "http://arxiv.org/abs/2307.04996",
          "publishedOn": "2023-07-12T01:02:46.595Z",
          "wordCount": null,
          "title": "Empowering recommender systems using automatically generated Knowledge Graphs and Reinforcement Learning. (arXiv:2307.04996v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.16015",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Radev_S/0/1/0/all/0/1\">Stefan T Radev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmitt_M/0/1/0/all/0/1\">Marvin Schmitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schumacher_L/0/1/0/all/0/1\">Lukas Schumacher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elsemuller_L/0/1/0/all/0/1\">Lasse Elsem&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pratz_V/0/1/0/all/0/1\">Valentin Pratz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schalte_Y/0/1/0/all/0/1\">Yannik Sch&#xe4;lte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kothe_U/0/1/0/all/0/1\">Ullrich K&#xf6;the</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burkner_P/0/1/0/all/0/1\">Paul-Christian B&#xfc;rkner</a>",
          "description": "Modern Bayesian inference involves a mixture of computational techniques for\nestimating, validating, and drawing conclusions from probabilistic models as\npart of principled workflows for data analysis. Typical problems in Bayesian\nworkflows are the approximation of intractable posterior distributions for\ndiverse model types and the comparison of competing models of the same process\nin terms of their complexity and predictive performance. This manuscript\nintroduces the Python library BayesFlow for simulation-based training of\nestablished neural network architectures for amortized data compression and\ninference. Amortized Bayesian inference, as implemented in BayesFlow, enables\nusers to train custom neural networks on model simulations and re-use these\nnetworks for any subsequent application of the models. Since the trained\nnetworks can perform inference almost instantaneously, the upfront neural\nnetwork training is quickly amortized.",
          "link": "http://arxiv.org/abs/2306.16015",
          "publishedOn": "2023-07-12T01:02:46.594Z",
          "wordCount": null,
          "title": "BayesFlow: Amortized Bayesian Workflows With Neural Networks. (arXiv:2306.16015v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_R/0/1/0/all/0/1\">Rupert Mitchell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mundt_M/0/1/0/all/0/1\">Martin Mundt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1\">Kristian Kersting</a>",
          "description": "The results of training a neural network are heavily dependent on the\narchitecture chosen; and even a modification of only the size of the network,\nhowever small, typically involves restarting the training process. In contrast\nto this, we begin training with a small architecture, only increase its\ncapacity as necessary for the problem, and avoid interfering with previous\noptimization while doing so. We thereby introduce a natural gradient based\napproach which intuitively expands both the width and depth of a neural network\nwhen this is likely to substantially reduce the hypothetical converged training\nloss. We prove an upper bound on the \"rate\" at which neurons are added, and a\ncomputationally cheap lower bound on the expansion score. We illustrate the\nbenefits of such Self-Expanding Neural Networks in both classification and\nregression problems, including those where the appropriate architecture size is\nsubstantially uncertain a priori.",
          "link": "http://arxiv.org/abs/2307.04526",
          "publishedOn": "2023-07-12T01:02:46.548Z",
          "wordCount": null,
          "title": "Self Expanding Neural Networks. (arXiv:2307.04526v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15542",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1\">Baifeng Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gai_S/0/1/0/all/0/1\">Siyu Gai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1\">Trevor Darrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>",
          "description": "Transfer learning involves adapting a pre-trained model to novel downstream\ntasks. However, we observe that current transfer learning methods often fail to\nfocus on task-relevant features. In this work, we explore refocusing model\nattention for transfer learning. We introduce Top-Down Attention Steering\n(TOAST), a novel transfer learning algorithm that keeps the pre-trained\nbackbone frozen, selects task-relevant features in the output, and feeds those\nfeatures back to the model to steer the attention to the task-specific\nfeatures. By refocusing the attention only, TOAST achieves state-of-the-art\nresults on a number of transfer learning benchmarks, while having a small\nnumber of tunable parameters. Compared to fully fine-tuning, LoRA, and prompt\ntuning, TOAST substantially improves performance across a range of fine-grained\nvisual classification datasets (e.g., 81.1% -> 86.2% on FGVC). TOAST also\noutperforms the fully fine-tuned Alpaca and Vicuna models on\ninstruction-following language generation. Code is available at\nhttps://github.com/bfshi/TOAST.",
          "link": "http://arxiv.org/abs/2305.15542",
          "publishedOn": "2023-07-12T01:02:46.542Z",
          "wordCount": null,
          "title": "TOAST: Transfer Learning via Attention Steering. (arXiv:2305.15542v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05454",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hlavnova_E/0/1/0/all/0/1\">Ester Hlavnova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1\">Sebastian Ruder</a>",
          "description": "A challenge towards developing NLP systems for the world's languages is\nunderstanding how they generalize to typological differences relevant for\nreal-world applications. To this end, we propose M2C, a morphologically-aware\nframework for behavioral testing of NLP models. We use M2C to generate tests\nthat probe models' behavior in light of specific linguistic features in 12\ntypologically diverse languages. We evaluate state-of-the-art language models\non the generated tests. While models excel at most tests in English, we\nhighlight generalization failures to specific typological characteristics such\nas temporal expressions in Swahili and compounding possessives in Finish. Our\nfindings motivate the development of models that address these blind spots.",
          "link": "http://arxiv.org/abs/2307.05454",
          "publishedOn": "2023-07-12T01:02:46.541Z",
          "wordCount": null,
          "title": "Empowering Cross-lingual Behavioral Testing of NLP Models with Typological Features. (arXiv:2307.05454v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.01147",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Igel_C/0/1/0/all/0/1\">Christian Igel</a>",
          "description": "Monotonicity constraints are powerful regularizers in statistical modelling.\nThey can support fairness in computer supported decision making and increase\nplausibility in data-driven scientific models. The seminal min-max (MM) neural\nnetwork architecture ensures monotonicity, but often gets stuck in undesired\nlocal optima during training because of vanishing gradients. We propose a\nsimple modification of the MM network using strictly-increasing smooth\nnon-linearities that alleviates this problem. The resulting smooth min-max\n(SMM) network module inherits the asymptotic approximation properties from the\nMM architecture. It can be used within larger deep learning systems trained\nend-to-end. The SMM module is considerably simpler and less computationally\ndemanding than state-of-the-art neural networks for monotonic modelling. Still,\nin our experiments, it compared favorably to alternative neural and non-neural\napproaches in terms of generalization performance.",
          "link": "http://arxiv.org/abs/2306.01147",
          "publishedOn": "2023-07-12T01:02:46.527Z",
          "wordCount": null,
          "title": "Smooth Monotonic Networks. (arXiv:2306.01147v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.00890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Santoni_M/0/1/0/all/0/1\">Maria Laura Santoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raponi_E/0/1/0/all/0/1\">Elena Raponi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leone_R/0/1/0/all/0/1\">Renato De Leone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doerr_C/0/1/0/all/0/1\">Carola Doerr</a>",
          "description": "Bayesian Optimization (BO) is a class of black-box, surrogate-based\nheuristics that can efficiently optimize problems that are expensive to\nevaluate, and hence admit only small evaluation budgets. BO is particularly\npopular for solving numerical optimization problems in industry, where the\nevaluation of objective functions often relies on time-consuming simulations or\nphysical experiments. However, many industrial problems depend on a large\nnumber of parameters. This poses a challenge for BO algorithms, whose\nperformance is often reported to suffer when the dimension grows beyond 15\nvariables. Although many new algorithms have been proposed to address this\nproblem, it is not well understood which one is the best for which optimization\nscenario.\n\nIn this work, we compare five state-of-the-art high-dimensional BO\nalgorithms, with vanilla BO and CMA-ES on the 24 BBOB functions of the COCO\nenvironment at increasing dimensionality, ranging from 10 to 60 variables. Our\nresults confirm the superiority of BO over CMA-ES for limited evaluation\nbudgets and suggest that the most promising approach to improve BO is the use\nof trust regions. However, we also observe significant performance differences\nfor different function landscapes and budget exploitation phases, indicating\nimprovement potential, e.g., through hybridization of algorithmic components.",
          "link": "http://arxiv.org/abs/2303.00890",
          "publishedOn": "2023-07-12T01:02:46.526Z",
          "wordCount": null,
          "title": "Comparison of High-Dimensional Bayesian Optimization Algorithms on BBOB. (arXiv:2303.00890v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05370",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ray_L/0/1/0/all/0/1\">Lala Shakti Swarup Ray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geissler_D/0/1/0/all/0/1\">Daniel Gei&#xdf;ler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1\">Bo Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukowicz_P/0/1/0/all/0/1\">Paul Lukowicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greinke_B/0/1/0/all/0/1\">Berit Greinke</a>",
          "description": "Folding is an unique structural technique to enable planer materials with\nmotion or 3D mechanical properties. Textile-based capacitive sensing has shown\nto be sensitive to the geometry deformation and relative motion of conductive\ntextiles. In this work, we propose a novel self-tracking foldable smart textile\nby combining folded fabric structures and capacitive sensing to detect the\nstructural motions using state-of-the-art sensing circuits and deep learning\ntechnologies. We created two folding patterns, Accordion and Chevron, each with\ntwo layouts of capacitive sensors in the form of thermobonded conductive\ntextile patches. In an experiment of manually moving patches of the folding\npatterns, we developed deep neural network to learn and reconstruct the\nvision-tracked shape of the patches. Through our approach, the geometry\nprimitives defining the patch shape can be reconstructed from the capacitive\nsignals with R-squared value of up to 95\\% and tracking error of 1cm for 22.5cm\nlong patches. With mechanical, electrical and sensing properties, Capafoldable\ncould enable a new range of smart textile applications.",
          "link": "http://arxiv.org/abs/2307.05370",
          "publishedOn": "2023-07-12T01:02:46.525Z",
          "wordCount": null,
          "title": "Capafoldable: self-tracking foldable smart textiles with capacitive sensing. (arXiv:2307.05370v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05422",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1\">Hao Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_P/0/1/0/all/0/1\">Prashanth Krishnamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1\">Siddharth Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khorrami_F/0/1/0/all/0/1\">Farshad Khorrami</a>",
          "description": "This paper proposes a data-efficient detection method for deep neural\nnetworks against backdoor attacks under a black-box scenario. The proposed\napproach is motivated by the intuition that features corresponding to triggers\nhave a higher influence in determining the backdoored network output than any\nother benign features. To quantitatively measure the effects of triggers and\nbenign features on determining the backdoored network output, we introduce five\nmetrics. To calculate the five-metric values for a given input, we first\ngenerate several synthetic samples by injecting the input's partial contents\ninto clean validation samples. Then, the five metrics are computed by using the\noutput labels of the corresponding synthetic samples. One contribution of this\nwork is the use of a tiny clean validation dataset. Having the computed five\nmetrics, five novelty detectors are trained from the validation dataset. A meta\nnovelty detector fuses the output of the five trained novelty detectors to\ngenerate a meta confidence score. During online testing, our method determines\nif online samples are poisoned or not via assessing their meta confidence\nscores output by the meta novelty detector. We show the efficacy of our\nmethodology through a broad range of backdoor attacks, including ablation\nstudies and comparison to existing approaches. Our methodology is promising\nsince the proposed five metrics quantify the inherent differences between clean\nand poisoned samples. Additionally, our detection method can be incrementally\nimproved by appending more metrics that may be proposed to address future\nadvanced attacks.",
          "link": "http://arxiv.org/abs/2307.05422",
          "publishedOn": "2023-07-12T01:02:46.520Z",
          "wordCount": null,
          "title": "Differential Analysis of Triggers and Benign Features for Black-Box DNN Backdoor Detection. (arXiv:2307.05422v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04998",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sekhari_A/0/1/0/all/0/1\">Ayush Sekhari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sridharan_K/0/1/0/all/0/1\">Karthik Sridharan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wen Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1\">Runzhe Wu</a>",
          "description": "We consider the problem of Imitation Learning (IL) by actively querying noisy\nexpert for feedback. While imitation learning has been empirically successful,\nmuch of prior work assumes access to noiseless expert feedback which is not\npractical in many applications. In fact, when one only has access to noisy\nexpert feedback, algorithms that rely on purely offline data (non-interactive\nIL) can be shown to need a prohibitively large number of samples to be\nsuccessful. In contrast, in this work, we provide an interactive algorithm for\nIL that uses selective sampling to actively query the noisy expert for\nfeedback. Our contributions are twofold: First, we provide a new selective\nsampling algorithm that works with general function classes and multiple\nactions, and obtains the best-known bounds for the regret and the number of\nqueries. Next, we extend this analysis to the problem of IL with noisy expert\nfeedback and provide a new IL algorithm that makes limited queries.\n\nOur algorithm for selective sampling leverages function approximation, and\nrelies on an online regression oracle w.r.t.~the given model class to predict\nactions, and to decide whether to query the expert for its label. On the\ntheoretical side, the regret bound of our algorithm is upper bounded by the\nregret of the online regression oracle, while the query complexity additionally\ndepends on the eluder dimension of the model class. We complement this with a\nlower bound that demonstrates that our results are tight. We extend our\nselective sampling algorithm for IL with general function approximation and\nprovide bounds on both the regret and the number of queries made to the noisy\nexpert. A key novelty here is that our regret and query complexity bounds only\ndepend on the number of times the optimal policy (and not the noisy expert, or\nthe learner) go to states that have a small margin.",
          "link": "http://arxiv.org/abs/2307.04998",
          "publishedOn": "2023-07-12T01:02:46.511Z",
          "wordCount": null,
          "title": "Selective Sampling and Imitation Learning via Online Regression. (arXiv:2307.04998v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.07040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pal_S/0/1/0/all/0/1\">Soumyabrata Pal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suggala_A/0/1/0/all/0/1\">Arun Sai Suggala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shanmugam_K/0/1/0/all/0/1\">Karthikeyan Shanmugam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1\">Prateek Jain</a>",
          "description": "We consider the problem of latent bandits with cluster structure where there\nare multiple users, each with an associated multi-armed bandit problem. These\nusers are grouped into \\emph{latent} clusters such that the mean reward vectors\nof users within the same cluster are identical. At each round, a user, selected\nuniformly at random, pulls an arm and observes a corresponding noisy reward.\nThe goal of the users is to maximize their cumulative rewards. This problem is\ncentral to practical recommendation systems and has received wide attention of\nlate \\cite{gentile2014online, maillard2014latent}. Now, if each user acts\nindependently, then they would have to explore each arm independently and a\nregret of $\\Omega(\\sqrt{\\mathsf{MNT}})$ is unavoidable, where $\\mathsf{M},\n\\mathsf{N}$ are the number of arms and users, respectively. Instead, we propose\nLATTICE (Latent bAndiTs via maTrIx ComplEtion) which allows exploitation of the\nlatent cluster structure to provide the minimax optimal regret of\n$\\widetilde{O}(\\sqrt{(\\mathsf{M}+\\mathsf{N})\\mathsf{T}})$, when the number of\nclusters is $\\widetilde{O}(1)$. This is the first algorithm to guarantee such\nstrong regret bound. LATTICE is based on a careful exploitation of arm\ninformation within a cluster while simultaneously clustering users.\nFurthermore, it is computationally efficient and requires only\n$O(\\log{\\mathsf{T}})$ calls to an offline matrix completion oracle across all\n$\\mathsf{T}$ rounds.",
          "link": "http://arxiv.org/abs/2301.07040",
          "publishedOn": "2023-07-12T01:02:46.510Z",
          "wordCount": null,
          "title": "Optimal Algorithms for Latent Bandits with Cluster Structure. (arXiv:2301.07040v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05390",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Das_K/0/1/0/all/0/1\">Kishalay Das</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Goyal_P/0/1/0/all/0/1\">Pawan Goyal</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Lee_S/0/1/0/all/0/1\">Seung-Cheol Lee</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Bhattacharjee_S/0/1/0/all/0/1\">Satadeep Bhattacharjee</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Ganguly_N/0/1/0/all/0/1\">Niloy Ganguly</a>",
          "description": "Machine Learning models have emerged as a powerful tool for fast and accurate\nprediction of different crystalline properties. Exiting state-of-the-art models\nrely on a single modality of crystal data i.e. crystal graph structure, where\nthey construct multi-graph by establishing edges between nearby atoms in 3D\nspace and apply GNN to learn materials representation. Thereby, they encode\nlocal chemical semantics around the atoms successfully but fail to capture\nimportant global periodic structural information like space group number,\ncrystal symmetry, rotational information, etc, which influence different\ncrystal properties. In this work, we leverage textual descriptions of materials\nto model global structural information into graph structure and learn a more\nrobust and enriched representation of crystalline materials. To this effect, we\nfirst curate a textual dataset for crystalline material databases containing\ndescriptions of each material. Further, we propose CrysMMNet, a simple\nmulti-modal framework, which fuses both structural and textual representation\ntogether to generate a joint multimodal representation of crystalline\nmaterials. We conduct extensive experiments on two benchmark datasets across\nten different properties to show that CrysMMNet outperforms existing\nstate-of-the-art baseline methods with a good margin. We also observe that\nfusing the textual representation with crystal graph structure provides\nconsistent improvement for all the SOTA GNN models compared to their own\nvanilla versions. We have shared the textual dataset, that we have curated for\nboth the benchmark material databases, with the community for future use.",
          "link": "http://arxiv.org/abs/2307.05390",
          "publishedOn": "2023-07-12T01:02:46.509Z",
          "wordCount": null,
          "title": "CrysMMNet: Multimodal Representation for Crystal Property Prediction. (arXiv:2307.05390v1 [cond-mat.mtrl-sci])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.08767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xiaomeng Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_T/0/1/0/all/0/1\">Tao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potter_M/0/1/0/all/0/1\">Michael Potter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1\">Yun-Chan Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_G/0/1/0/all/0/1\">Gaurav Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saripalli_V/0/1/0/all/0/1\">V. Ratna Saripalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trafalis_T/0/1/0/all/0/1\">Theodore Trafalis</a>",
          "description": "There is a parameter ubiquitous throughout the deep learning world: learning\nrate. There is likewise a ubiquitous question: what should that learning rate\nbe? The true answer to this question is often tedious and time consuming to\nobtain, and a great deal of arcane knowledge has accumulated in recent years\nover how to pick and modify learning rates to achieve optimal training\nperformance. Moreover, the long hours spent carefully crafting the perfect\nlearning rate can come to nothing the moment your network architecture,\noptimizer, dataset, or initial conditions change ever so slightly. But it need\nnot be this way. We propose a new answer to the great learning rate question:\nthe Autonomous Learning Rate Controller. Find it at\nhttps://github.com/fastestimator/ARC/tree/v2.0",
          "link": "http://arxiv.org/abs/2106.08767",
          "publishedOn": "2023-07-12T01:02:46.508Z",
          "wordCount": null,
          "title": "To Raise or Not To Raise: The Autonomous Learning Rate Question. (arXiv:2106.08767v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Rui Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_S/0/1/0/all/0/1\">Shihan Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Songyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Wei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Binghai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_S/0/1/0/all/0/1\">Senjie Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1\">Limao Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xi_Z/0/1/0/all/0/1\">Zhiheng Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuhao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1\">Nuo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_W/0/1/0/all/0/1\">Wenbin Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Minghao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_R/0/1/0/all/0/1\">Rongxiang Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wensen Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1\">Cheng Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1\">Zhangyue Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1\">Yuan Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haoran Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1\">Tianxiang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1\">Hang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1\">Tao Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>",
          "description": "Large language models (LLMs) have formulated a blueprint for the advancement\nof artificial general intelligence. Its primary objective is to function as a\nhuman-centric (helpful, honest, and harmless) assistant. Alignment with humans\nassumes paramount significance, and reinforcement learning with human feedback\n(RLHF) emerges as the pivotal technological paradigm underpinning this pursuit.\nCurrent technical routes usually include \\textbf{reward models} to measure\nhuman preferences, \\textbf{Proximal Policy Optimization} (PPO) to optimize\npolicy model outputs, and \\textbf{process supervision} to improve step-by-step\nreasoning capabilities. However, due to the challenges of reward design,\nenvironment interaction, and agent training, coupled with huge trial and error\ncost of large language models, there is a significant barrier for AI\nresearchers to motivate the development of technical alignment and safe landing\nof LLMs. The stable training of RLHF has still been a puzzle. In the first\nreport, we dissect the framework of RLHF, re-evaluate the inner workings of\nPPO, and explore how the parts comprising PPO algorithms impact policy agent\ntraining. We identify policy constraints being the key factor for the effective\nimplementation of the PPO algorithm. Therefore, we explore the PPO-max, an\nadvanced version of PPO algorithm, to efficiently improve the training\nstability of the policy model. Based on our main results, we perform a\ncomprehensive analysis of RLHF abilities compared with SFT models and ChatGPT.\nThe absence of open-source implementations has posed significant challenges to\nthe investigation of LLMs alignment. Therefore, we are eager to release\ntechnical reports, reward models and PPO codes",
          "link": "http://arxiv.org/abs/2307.04964",
          "publishedOn": "2023-07-12T01:02:46.507Z",
          "wordCount": null,
          "title": "Secrets of RLHF in Large Language Models Part I: PPO. (arXiv:2307.04964v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2011.12177",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Bhattacharya_A/0/1/0/all/0/1\">Anwesh Bhattacharya</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+P%2E_N/0/1/0/all/0/1\">Nehal C. P.</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Das_M/0/1/0/all/0/1\">Mousumi Das</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Paswan_A/0/1/0/all/0/1\">Abhishek Paswan</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Saha_S/0/1/0/all/0/1\">Snehanshu Saha</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Combes_F/0/1/0/all/0/1\">Francoise Combes</a>",
          "description": "We present a novel algorithm to detect double nuclei galaxies (DNG) called\nGOTHIC (Graph BOosted iterated HIll Climbing) - that detects whether a given\nimage of a galaxy has two or more closely separated nuclei. Our aim is to\ndetect samples of dual or multiple active galactic nuclei (AGN) in galaxies.\nAlthough galaxy mergers are common, the detection of dual AGN is rare. Their\ndetection is very important as they help us understand the formation of\nsupermassive black hole (SMBH) binaries, SMBH growth and AGN feedback effects\nin multiple nuclei systems. There is thus a need for an algorithm to do a\nsystematic survey of existing imaging data for the discovery of DNGs and dual\nAGN. We have tested GOTHIC on a known sample of DNGs and subsequently applied\nit to a sample of a million SDSS DR16 galaxies lying in the redshift range of 0\nto 0.75 approximately, and have available spectroscopic data. We have detected\n159 dual AGN in this sample, of which 2 are triple AGN systems. Our results\nshow that dual AGN are not common, and triple AGN even rarer. The color (u-r)\nmagnitude plots of the DNGs indicate that star formation is quenched as the\nnuclei come closer and as the AGN fraction increases. The quenching is\nespecially prominent for dual/triple AGN galaxies that lie in the extreme end\nof the red sequence.",
          "link": "http://arxiv.org/abs/2011.12177",
          "publishedOn": "2023-07-12T01:02:46.507Z",
          "wordCount": null,
          "title": "Automated Detection of Double Nuclei Galaxies using GOTHIC and the Discovery of a Large Sample of Dual AGN. (arXiv:2011.12177v4 [astro-ph.GA] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.10200",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sihua Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingzhe Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brinton_C/0/1/0/all/0/1\">Christopher G. Brinton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_C/0/1/0/all/0/1\">Changchuan Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saad_W/0/1/0/all/0/1\">Walid Saad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1\">Shuguang Cui</a>",
          "description": "This paper considers improving wireless communication and computation\nefficiency in federated learning (FL) via model quantization. In the proposed\nbitwidth FL scheme, edge devices train and transmit quantized versions of their\nlocal FL model parameters to a coordinating server, which aggregates them into\na quantized global model and synchronizes the devices. The goal is to jointly\ndetermine the bitwidths employed for local FL model quantization and the set of\ndevices participating in FL training at each iteration. We pose this as an\noptimization problem that aims to minimize the training loss of quantized FL\nunder a per-iteration device sampling budget and delay requirement. However,\nthe formulated problem is difficult to solve without (i) a concrete\nunderstanding of how quantization impacts global ML performance and (ii) the\nability of the server to construct estimates of this process efficiently. To\naddress the first challenge, we analytically characterize how limited wireless\nresources and induced quantization errors affect the performance of the\nproposed FL method. Our results quantify how the improvement of FL training\nloss between two consecutive iterations depends on the device selection and\nquantization scheme as well as on several parameters inherent to the model\nbeing learned. Then, we show that the FL training process can be described as a\nMarkov decision process and propose a model-based reinforcement learning (RL)\nmethod to optimize action selection over iterations. Compared to model-free RL,\nthis model-based RL approach leverages the derived mathematical\ncharacterization of the FL training process to discover an effective device\nselection and quantization scheme without imposing additional device\ncommunication overhead. Simulation results show that the proposed FL algorithm\ncan reduce the convergence time.",
          "link": "http://arxiv.org/abs/2209.10200",
          "publishedOn": "2023-07-12T01:02:46.505Z",
          "wordCount": null,
          "title": "Performance Optimization for Variable Bitwidth Federated Learning in Wireless Networks. (arXiv:2209.10200v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05006",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Unni_V/0/1/0/all/0/1\">Vinit S. Unni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_A/0/1/0/all/0/1\">Ashish Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jyothi_P/0/1/0/all/0/1\">Preethi Jyothi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarawagi_S/0/1/0/all/0/1\">Sunita Sarawagi</a>",
          "description": "RNN-Transducers (RNN-Ts) have gained widespread acceptance as an end-to-end\nmodel for speech to text conversion because of their high accuracy and\nstreaming capabilities. A typical RNN-T independently encodes the input audio\nand the text context, and combines the two encodings by a thin joint network.\nWhile this architecture provides SOTA streaming accuracy, it also makes the\nmodel vulnerable to strong LM biasing which manifests as multi-step\nhallucination of text without acoustic evidence. In this paper we propose\nLookAhead that makes text representations more acoustically grounded by looking\nahead into the future within the audio input. This technique yields a\nsignificant 5%-20% relative reduction in word error rate on both in-domain and\nout-of-domain evaluation sets.",
          "link": "http://arxiv.org/abs/2307.05006",
          "publishedOn": "2023-07-12T01:02:46.504Z",
          "wordCount": null,
          "title": "Improving RNN-Transducers with Acoustic LookAhead. (arXiv:2307.05006v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05035",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alsuhli_G/0/1/0/all/0/1\">Ghada Alsuhli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakellariou_V/0/1/0/all/0/1\">Vasileios Sakellariou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saleh_H/0/1/0/all/0/1\">Hani Saleh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Qutayri_M/0/1/0/all/0/1\">Mahmoud Al-Qutayri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammad_B/0/1/0/all/0/1\">Baker Mohammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stouraitis_T/0/1/0/all/0/1\">Thanos Stouraitis</a>",
          "description": "Deep neural networks (DNNs) have become an enabling component for a myriad of\nartificial intelligence applications. DNNs have shown sometimes superior\nperformance, even compared to humans, in cases such as self-driving, health\napplications, etc. Because of their computational complexity, deploying DNNs in\nresource-constrained devices still faces many challenges related to computing\ncomplexity, energy efficiency, latency, and cost. To this end, several research\ndirections are being pursued by both academia and industry to accelerate and\nefficiently implement DNNs. One important direction is determining the\nappropriate data representation for the massive amount of data involved in DNN\nprocessing. Using conventional number systems has been found to be sub-optimal\nfor DNNs. Alternatively, a great body of research focuses on exploring suitable\nnumber systems. This article aims to provide a comprehensive survey and\ndiscussion about alternative number systems for more efficient representations\nof DNN data. Various number systems (conventional/unconventional) exploited for\nDNNs are discussed. The impact of these number systems on the performance and\nhardware design of DNNs is considered. In addition, this paper highlights the\nchallenges associated with each number system and various solutions that are\nproposed for addressing them. The reader will be able to understand the\nimportance of an efficient number system for DNN, learn about the widely used\nnumber systems for DNN, understand the trade-offs between various number\nsystems, and consider various design aspects that affect the impact of number\nsystems on DNN performance. In addition, the recent trends and related research\nopportunities will be highlighted",
          "link": "http://arxiv.org/abs/2307.05035",
          "publishedOn": "2023-07-12T01:02:46.504Z",
          "wordCount": null,
          "title": "Number Systems for Deep Neural Network Architectures: A Survey. (arXiv:2307.05035v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05385",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_S/0/1/0/all/0/1\">Sully F. Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Guo_Z/0/1/0/all/0/1\">Zhicheng Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ding_C/0/1/0/all/0/1\">Cheng Ding</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hu_X/0/1/0/all/0/1\">Xiao Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rudin_C/0/1/0/all/0/1\">Cynthia Rudin</a>",
          "description": "Photoplethysmography (PPG) provides a low-cost, non-invasive method to\ncontinuously monitor various cardiovascular parameters. PPG signals are\ngenerated by wearable devices and frequently contain large artifacts caused by\nexternal factors, such as motion of the human subject. In order to ensure\nrobust and accurate extraction of physiological parameters, corrupted areas of\nthe signal need to be identified and handled appropriately. Previous\nmethodology relied either on handcrafted feature detectors or signal metrics\nwhich yield sub-optimal performance, or relied on machine learning techniques\nsuch as deep neural networks (DNN) which lack interpretability and are\ncomputationally and memory intensive. In this work, we present a novel method\nto learn a small set of interpretable convolutional kernels that has\nperformance similar to -- and often better than -- the state-of-the-art DNN\napproach with several orders of magnitude fewer parameters. This work allows\nfor efficient, robust, and interpretable signal quality assessment and artifact\nsegmentation on low-power devices.",
          "link": "http://arxiv.org/abs/2307.05385",
          "publishedOn": "2023-07-12T01:02:46.503Z",
          "wordCount": null,
          "title": "Learned Kernels for Interpretable and Efficient PPG Signal Quality Assessment and Artifact Segmentation. (arXiv:2307.05385v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05476",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ryu_J/0/1/0/all/0/1\">Jung Hyun Ryu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeon_J/0/1/0/all/0/1\">Jaeheyoung Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1\">Jewoong Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+1_M/0/1/0/all/0/1\">Myungjoo Kang 1</a>",
          "description": "Along with the exponential growth of online platforms and services,\nrecommendation systems have become essential for identifying relevant items\nbased on user preferences. The domain of sequential recommendation aims to\ncapture evolving user preferences over time. To address dynamic preference,\nvarious contrastive learning methods have been proposed to target data\nsparsity, a challenge in recommendation systems due to the limited user-item\ninteractions. In this paper, we are the first to apply the Fisher-Merging\nmethod to Sequential Recommendation, addressing and resolving practical\nchallenges associated with it. This approach ensures robust fine-tuning by\nmerging the parameters of multiple models, resulting in improved overall\nperformance. Through extensive experiments, we demonstrate the effectiveness of\nour proposed methods, highlighting their potential to advance the\nstate-of-the-art in sequential learning and recommendation systems.",
          "link": "http://arxiv.org/abs/2307.05476",
          "publishedOn": "2023-07-12T01:02:46.495Z",
          "wordCount": null,
          "title": "Fisher-Weighted Merge of Contrastive Learning Models in Sequential Recommendation. (arXiv:2307.05476v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05364",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Munteanu_V/0/1/0/all/0/1\">Valentin Munteanu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Starostin_V/0/1/0/all/0/1\">Vladimir Starostin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Greco_A/0/1/0/all/0/1\">Alessandro Greco</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pithan_L/0/1/0/all/0/1\">Linus Pithan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gerlach_A/0/1/0/all/0/1\">Alexander Gerlach</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hinderhofer_A/0/1/0/all/0/1\">Alexander Hinderhofer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kowarik_S/0/1/0/all/0/1\">Stefan Kowarik</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schreiber_F/0/1/0/all/0/1\">Frank Schreiber</a>",
          "description": "Due to the lack of phase information, determining the physical parameters of\nmultilayer thin films from measured neutron and X-ray reflectivity curves is,\non a fundamental level, an underdetermined inverse problem. This so-called\nphase problem poses limitations on standard neural networks, constraining the\nrange and number of considered parameters in previous machine learning\nsolutions. To overcome this, we present an approach that utilizes prior\nknowledge to regularize the training process over larger parameter spaces. We\ndemonstrate the effectiveness of our method in various scenarios, including\nmultilayer structures with box model parameterization and a physics-inspired\nspecial parameterization of the scattering length density profile for a\nmultilayer structure. By leveraging the input of prior knowledge, we can\nimprove the training dynamics and address the underdetermined (\"ill-posed\")\nnature of the problem. In contrast to previous methods, our approach scales\nfavorably when increasing the complexity of the inverse problem, working\nproperly even for a 5-layer multilayer model and an N-layer periodic multilayer\nmodel with up to 17 open parameters.",
          "link": "http://arxiv.org/abs/2307.05364",
          "publishedOn": "2023-07-12T01:02:46.494Z",
          "wordCount": null,
          "title": "Neural network analysis of neutron and X-ray reflectivity data: Incorporating prior knowledge for tackling the phase problem. (arXiv:2307.05364v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04993",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Yong_S/0/1/0/all/0/1\">Suk Yee Yong</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ong_C/0/1/0/all/0/1\">Cheng Soon Ong</a>",
          "description": "Precise measurements of the black hole mass are essential to gain insight on\nthe black hole and host galaxy co-evolution. A direct measure of the black hole\nmass is often restricted to nearest galaxies and instead, an indirect method\nusing the single-epoch virial black hole mass estimation is used for objects at\nhigh redshifts. However, this method is subjected to biases and uncertainties\nas it is reliant on the scaling relation from a small sample of local active\ngalactic nuclei. In this study, we propose the application of conformalised\nquantile regression (CQR) to quantify the uncertainties of the black hole\npredictions in a machine learning setting. We compare CQR with various\nprediction interval techniques and demonstrated that CQR can provide a more\nuseful prediction interval indicator. In contrast to baseline approaches for\nprediction interval estimation, we show that the CQR method provides prediction\nintervals that adjust to the black hole mass and its related properties. That\nis it yields a tighter constraint on the prediction interval (hence more\ncertain) for a larger black hole mass, and accordingly, bright and broad\nspectral line width source. Using a combination of neural network model and CQR\nframework, the recovered virial black hole mass predictions and uncertainties\nare comparable to those measured from the Sloan Digital Sky Survey. The code is\npublicly available at https://github.com/yongsukyee/uncertain_blackholemass.",
          "link": "http://arxiv.org/abs/2307.04993",
          "publishedOn": "2023-07-12T01:02:46.493Z",
          "wordCount": null,
          "title": "Uncertainty Quantification of the Virial Black Hole Mass with Conformal Prediction. (arXiv:2307.04993v1 [astro-ph.CO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05275",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_Garcia_J/0/1/0/all/0/1\">Juan Carlos Ruiz-Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tolosana_R/0/1/0/all/0/1\">Ruben Tolosana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vera_Rodriguez_R/0/1/0/all/0/1\">Ruben Vera-Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moro_C/0/1/0/all/0/1\">Carlos Moro</a>",
          "description": "The aging population has led to a growing number of falls in our society,\naffecting global public health worldwide. This paper presents CareFall, an\nautomatic Fall Detection System (FDS) based on wearable devices and Artificial\nIntelligence (AI) methods. CareFall considers the accelerometer and gyroscope\ntime signals extracted from a smartwatch. Two different approaches are used for\nfeature extraction and classification: i) threshold-based, and ii) machine\nlearning-based. Experimental results on two public databases show that the\nmachine learning-based approach, which combines accelerometer and gyroscope\ninformation, outperforms the threshold-based approach in terms of accuracy,\nsensitivity, and specificity. This research contributes to the design of smart\nand user-friendly solutions to mitigate the negative consequences of falls\namong older people.",
          "link": "http://arxiv.org/abs/2307.05275",
          "publishedOn": "2023-07-12T01:02:46.492Z",
          "wordCount": null,
          "title": "CareFall: Automatic Fall Detection through Wearable Devices and AI Methods. (arXiv:2307.05275v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04904",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kumtepeli_V/0/1/0/all/0/1\">Volkan Kumtepeli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Perriment_R/0/1/0/all/0/1\">Rebecca Perriment</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Howey_D/0/1/0/all/0/1\">David A. Howey</a>",
          "description": "We present an approach for computationally efficient dynamic time warping\n(DTW) and clustering of time-series data. The method frames the dynamic warping\nof time series datasets as an optimisation problem solved using dynamic\nprogramming, and then clusters time series data by solving a second\noptimisation problem using mixed-integer programming (MIP). There is also an\noption to use k-medoids clustering for increased speed, when a certificate for\nglobal optimality is not essential. The improved efficiency of our approach is\ndue to task-level parallelisation of the clustering alongside DTW. Our approach\nwas tested using the UCR Time Series Archive, and was found to be, on average,\n33% faster than the next fastest option when using the same clustering method.\nThis increases to 64% faster when considering only larger datasets (with more\nthan 1000 time series). The MIP clustering is most effective on small numbers\nof longer time series, because the DTW computation is faster than other\napproaches, but the clustering problem becomes increasingly computationally\nexpensive as the number of time series to be clustered increases.",
          "link": "http://arxiv.org/abs/2307.04904",
          "publishedOn": "2023-07-12T01:02:46.490Z",
          "wordCount": null,
          "title": "Fast dynamic time warping and clustering in C++. (arXiv:2307.04904v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.08004",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Landa_B/0/1/0/all/0/1\">Boris Landa</a>, <a href=\"http://arxiv.org/find/math/1/au:+Cheng_X/0/1/0/all/0/1\">Xiuyuan Cheng</a>",
          "description": "The Gaussian kernel and its traditional normalizations (e.g., row-stochastic)\nare popular approaches for assessing similarities between data points. Yet,\nthey can be inaccurate under high-dimensional noise, especially if the noise\nmagnitude varies considerably across the data, e.g., under heteroskedasticity\nor outliers. In this work, we investigate a more robust alternative -- the\ndoubly stochastic normalization of the Gaussian kernel. We consider a setting\nwhere points are sampled from an unknown density on a low-dimensional manifold\nembedded in high-dimensional space and corrupted by possibly strong,\nnon-identically distributed, sub-Gaussian noise. We establish that the doubly\nstochastic affinity matrix and its scaling factors concentrate around certain\npopulation forms, and provide corresponding finite-sample probabilistic error\nbounds. We then utilize these results to develop several tools for robust\ninference under general high-dimensional noise. First, we derive a robust\ndensity estimator that reliably infers the underlying sampling density and can\nsubstantially outperform the standard kernel density estimator under\nheteroskedasticity and outliers. Second, we obtain estimators for the pointwise\nnoise magnitudes, the pointwise signal magnitudes, and the pairwise Euclidean\ndistances between clean data points. Lastly, we derive robust graph Laplacian\nnormalizations that accurately approximate various manifold Laplacians,\nincluding the Laplace Beltrami operator, improving over traditional\nnormalizations in noisy settings. We exemplify our results in simulations and\non real single-cell RNA-sequencing data. For the latter, we show that in\ncontrast to traditional methods, our approach is robust to variability in\ntechnical noise levels across cell types.",
          "link": "http://arxiv.org/abs/2209.08004",
          "publishedOn": "2023-07-12T01:02:46.470Z",
          "wordCount": null,
          "title": "Robust Inference of Manifold Density and Geometry by Doubly Stochastic Scaling. (arXiv:2209.08004v2 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05213",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Silvestri_M/0/1/0/all/0/1\">Mattia Silvestri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berden_S/0/1/0/all/0/1\">Senne Berden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandi_J/0/1/0/all/0/1\">Jayanta Mandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmutogullari_A/0/1/0/all/0/1\">Ali &#x130;rfan Mahmuto&#x11f;ullar&#x131;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mulamba_M/0/1/0/all/0/1\">Maxime Mulamba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Filippo_A/0/1/0/all/0/1\">Allegra De Filippo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guns_T/0/1/0/all/0/1\">Tias Guns</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lombardi_M/0/1/0/all/0/1\">Michele Lombardi</a>",
          "description": "Many real-world optimization problems contain unknown parameters that must be\npredicted prior to solving. To train the predictive machine learning (ML)\nmodels involved, the commonly adopted approach focuses on maximizing predictive\naccuracy. However, this approach does not always lead to the minimization of\nthe downstream task loss. Decision-focused learning (DFL) is a recently\nproposed paradigm whose goal is to train the ML model by directly minimizing\nthe task loss. However, state-of-the-art DFL methods are limited by the\nassumptions they make about the structure of the optimization problem (e.g.,\nthat the problem is linear) and by the fact that can only predict parameters\nthat appear in the objective function. In this work, we address these\nlimitations by instead predicting \\textit{distributions} over parameters and\nadopting score function gradient estimation (SFGE) to compute decision-focused\nupdates to the predictive model, thereby widening the applicability of DFL. Our\nexperiments show that by using SFGE we can: (1) deal with predictions that\noccur both in the objective function and in the constraints; and (2)\neffectively tackle two-stage stochastic optimization problems.",
          "link": "http://arxiv.org/abs/2307.05213",
          "publishedOn": "2023-07-12T01:02:46.469Z",
          "wordCount": null,
          "title": "Score Function Gradient Estimation to Widen the Applicability of Decision-Focused Learning. (arXiv:2307.05213v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05029",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_N/0/1/0/all/0/1\">Normen Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_G/0/1/0/all/0/1\">Gang Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tizpaz_Niari_S/0/1/0/all/0/1\">Saeid Tizpaz-Niari</a>",
          "description": "This thesis explores open-sourced machine learning (ML) model explanation\ntools to understand whether these tools can allow a layman to visualize,\nunderstand, and suggest intuitive remedies to unfairness in ML-based\ndecision-support systems. Machine learning models trained on datasets biased\nagainst minority groups are increasingly used to guide life-altering social\ndecisions, prompting the urgent need to study their logic for unfairness. Due\nto this problem's impact on vast populations of the general public, it is\ncritical for the layperson -- not just subject matter experts in social justice\nor machine learning experts -- to understand the nature of unfairness within\nthese algorithms and the potential trade-offs. Existing research on fairness in\nmachine learning focuses mostly on the mathematical definitions and tools to\nunderstand and remedy unfair models, with some directly citing user-interactive\ntools as necessary for future work. This thesis presents FairLay-ML, a\nproof-of-concept GUI integrating some of the most promising tools to provide\nintuitive explanations for unfair logic in ML models by integrating existing\nresearch tools (e.g. Local Interpretable Model-Agnostic Explanations) with\nexisting ML-focused GUI (e.g. Python Streamlit). We test FairLay-ML using\nmodels of various accuracy and fairness generated by an unfairness detector\ntool, Parfait-ML, and validate our results using Themis. Our study finds that\nthe technology stack used for FairLay-ML makes it easy to install and provides\nreal-time black-box explanations of pre-trained models to users. Furthermore,\nthe explanations provided translate to actionable remedies.",
          "link": "http://arxiv.org/abs/2307.05029",
          "publishedOn": "2023-07-12T01:02:46.466Z",
          "wordCount": null,
          "title": "FairLay-ML: Intuitive Remedies for Unfairness in Data-Driven Social-Critical Algorithms. (arXiv:2307.05029v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05378",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Du_Y/0/1/0/all/0/1\">Yuanqi Du</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Wang_Y/0/1/0/all/0/1\">Yingheng Wang</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Huang_Y/0/1/0/all/0/1\">Yining Huang</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Li_J/0/1/0/all/0/1\">Jianan Canal Li</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanqiao Zhu</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Xie_T/0/1/0/all/0/1\">Tian Xie</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Duan_C/0/1/0/all/0/1\">Chenru Duan</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Gregoire_J/0/1/0/all/0/1\">John M. Gregoire</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Gomes_C/0/1/0/all/0/1\">Carla P. Gomes</a>",
          "description": "We introduce M$^2$Hub, a toolkit for advancing machine learning in materials\ndiscovery. Machine learning has achieved remarkable progress in modeling\nmolecular structures, especially biomolecules for drug discovery. However, the\ndevelopment of machine learning approaches for modeling materials structures\nlag behind, which is partly due to the lack of an integrated platform that\nenables access to diverse tasks for materials discovery. To bridge this gap,\nM$^2$Hub will enable easy access to materials discovery tasks, datasets,\nmachine learning methods, evaluations, and benchmark results that cover the\nentire workflow. Specifically, the first release of M$^2$Hub focuses on three\nkey stages in materials discovery: virtual screening, inverse design, and\nmolecular simulation, including 9 datasets that covers 6 types of materials\nwith 56 tasks across 8 types of material properties. We further provide 2\nsynthetic datasets for the purpose of generative tasks on materials. In\naddition to random data splits, we also provide 3 additional data partitions to\nreflect the real-world materials discovery scenarios. State-of-the-art machine\nlearning methods (including those are suitable for materials structures but\nnever compared in the literature) are benchmarked on representative tasks. Our\ncodes and library are publicly available at https://github.com/yuanqidu/M2Hub.",
          "link": "http://arxiv.org/abs/2307.05378",
          "publishedOn": "2023-07-12T01:02:46.465Z",
          "wordCount": null,
          "title": "M$^2$Hub: Unlocking the Potential of Machine Learning for Materials Discovery. (arXiv:2307.05378v1 [cond-mat.mtrl-sci])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05109",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guha_E/0/1/0/all/0/1\">Etash Kumar Guha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ndiaye_E/0/1/0/all/0/1\">Eugene Ndiaye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huo_X/0/1/0/all/0/1\">Xiaoming Huo</a>",
          "description": "Given a sequence of observable variables $\\{(x_1, y_1), \\ldots, (x_n,\ny_n)\\}$, the conformal prediction method estimates a confidence set for\n$y_{n+1}$ given $x_{n+1}$ that is valid for any finite sample size by merely\nassuming that the joint distribution of the data is permutation invariant.\nAlthough attractive, computing such a set is computationally infeasible in most\nregression problems. Indeed, in these cases, the unknown variable $y_{n+1}$ can\ntake an infinite number of possible candidate values, and generating conformal\nsets requires retraining a predictive model for each candidate. In this paper,\nwe focus on a sparse linear model with only a subset of variables for\nprediction and use numerical continuation techniques to approximate the\nsolution path efficiently. The critical property we exploit is that the set of\nselected variables is invariant under a small perturbation of the input data.\nTherefore, it is sufficient to enumerate and refit the model only at the change\npoints of the set of active features and smoothly interpolate the rest of the\nsolution via a Predictor-Corrector mechanism. We show how our path-following\nalgorithm accurately approximates conformal prediction sets and illustrate its\nperformance using synthetic and real data examples.",
          "link": "http://arxiv.org/abs/2307.05109",
          "publishedOn": "2023-07-12T01:02:46.403Z",
          "wordCount": null,
          "title": "Conformalization of Sparse Generalized Linear Models. (arXiv:2307.05109v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05162",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suri_K/0/1/0/all/0/1\">Kunal Suri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_P/0/1/0/all/0/1\">Prakhar Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1\">Saumajit Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Atul Singh</a>",
          "description": "Finetuning Large Language Models helps improve the results for\ndomain-specific use cases. End-to-end finetuning of large language models is\ntime and resource intensive and has high storage requirements to store the\nfinetuned version of the large language model. Parameter Efficient Fine Tuning\n(PEFT) methods address the time and resource challenges by keeping the large\nlanguage model as a fixed base and add additional layers, which the PEFT\nmethods finetune. This paper demonstrates the evaluation results for one such\nPEFT method Low Rank Adaptation (LoRA), for Clinical Dialogue Summarization.\nThe evaluation results show that LoRA works at par with end-to-end finetuning\nfor a large language model. The paper presents the evaluations done for solving\nboth the Subtask A and B from ImageCLEFmedical\n{https://www.imageclef.org/2023/medical}",
          "link": "http://arxiv.org/abs/2307.05162",
          "publishedOn": "2023-07-12T01:02:46.400Z",
          "wordCount": null,
          "title": "SuryaKiran at MEDIQA-Sum 2023: Leveraging LoRA for Clinical Dialogue Summarization. (arXiv:2307.05162v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05048",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Sen_J/0/1/0/all/0/1\">Jaydip Sen</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Dasgupta_S/0/1/0/all/0/1\">Subhasis Dasgupta</a>",
          "description": "Portfolio optimization has been an area that has attracted considerable\nattention from the financial research community. Designing a profitable\nportfolio is a challenging task involving precise forecasting of future stock\nreturns and risks. This chapter presents a comparative study of three portfolio\ndesign approaches, the mean-variance portfolio (MVP), hierarchical risk parity\n(HRP)-based portfolio, and autoencoder-based portfolio. These three approaches\nto portfolio design are applied to the historical prices of stocks chosen from\nten thematic sectors listed on the National Stock Exchange (NSE) of India. The\nportfolios are designed using the stock price data from January 1, 2018, to\nDecember 31, 2021, and their performances are tested on the out-of-sample data\nfrom January 1, 2022, to December 31, 2022. Extensive results are analyzed on\nthe performance of the portfolios. It is observed that the performance of the\nMVP portfolio is the best on the out-of-sample data for the risk-adjusted\nreturns. However, the autoencoder portfolios outperformed their counterparts on\nannual returns.",
          "link": "http://arxiv.org/abs/2307.05048",
          "publishedOn": "2023-07-12T01:02:46.387Z",
          "wordCount": null,
          "title": "Portfolio Optimization: A Comparative Study. (arXiv:2307.05048v1 [q-fin.PM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05194",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Jewson_J/0/1/0/all/0/1\">Jack Jewson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ghalebikesabi_S/0/1/0/all/0/1\">Sahra Ghalebikesabi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Holmes_C/0/1/0/all/0/1\">Chris Holmes</a>",
          "description": "Differential privacy guarantees allow the results of a statistical analysis\ninvolving sensitive data to be released without compromising the privacy of any\nindividual taking part. Achieving such guarantees generally requires the\ninjection of noise, either directly into parameter estimates or into the\nestimation process. Instead of artificially introducing perturbations, sampling\nfrom Bayesian posterior distributions has been shown to be a special case of\nthe exponential mechanism, producing consistent, and efficient private\nestimates without altering the data generative process. The application of\ncurrent approaches has, however, been limited by their strong bounding\nassumptions which do not hold for basic models, such as simple linear\nregressors. To ameliorate this, we propose $\\beta$D-Bayes, a posterior sampling\nscheme from a generalised posterior targeting the minimisation of the\n$\\beta$-divergence between the model and the data generating process. This\nprovides private estimation that is generally applicable without requiring\nchanges to the underlying model and consistently learns the data generating\nparameter. We show that $\\beta$D-Bayes produces more precise inference\nestimation for the same privacy guarantees, and further facilitates\ndifferentially private estimation via posterior sampling for complex\nclassifiers and continuous regression models such as neural networks for the\nfirst time.",
          "link": "http://arxiv.org/abs/2307.05194",
          "publishedOn": "2023-07-12T01:02:46.387Z",
          "wordCount": null,
          "title": "Differentially Private Statistical Inference through $\\beta$-Divergence One Posterior Sampling. (arXiv:2307.05194v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05163",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chevtchenko_S/0/1/0/all/0/1\">S&#xe9;rgio F Chevtchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rocha_E/0/1/0/all/0/1\">Elisson da Silva Rocha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cruz_B/0/1/0/all/0/1\">Bruna Cruz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andrade_E/0/1/0/all/0/1\">Ermeson Carneiro de Andrade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Araujo_D/0/1/0/all/0/1\">Danilo Ricardo Barbosa de Ara&#xfa;jo</a>",
          "description": "Energy storage solutions play an increasingly important role in modern\ninfrastructure and lead-acid batteries are among the most commonly used in the\nrechargeable category. Due to normal degradation over time, correctly\ndetermining the battery's State of Health (SoH) and Remaining Useful Life (RUL)\ncontributes to enhancing predictive maintenance, reliability, and longevity of\nbattery systems. Besides improving the cost savings, correct estimation of the\nSoH can lead to reduced pollution though reuse of retired batteries. This paper\npresents a mapping study of the state-of-the-art in machine learning methods\nfor estimating the SoH and RUL of lead-acid batteries. These two indicators are\ncritical in the battery management systems of electric vehicles, renewable\nenergy systems, and other applications that rely heavily on this battery\ntechnology. In this study, we analyzed the types of machine learning algorithms\nemployed for estimating SoH and RUL, and evaluated their performance in terms\nof accuracy and inference time. Additionally, this mapping identifies and\nanalyzes the most commonly used combinations of sensors in specific\napplications, such as vehicular batteries. The mapping concludes by\nhighlighting potential gaps and opportunities for future research, which lays\nthe foundation for further advancements in the field.",
          "link": "http://arxiv.org/abs/2307.05163",
          "publishedOn": "2023-07-12T01:02:46.386Z",
          "wordCount": null,
          "title": "A Mapping Study of Machine Learning Methods for Remaining Useful Life Estimation of Lead-Acid Batteries. (arXiv:2307.05163v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05341",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Suk_J/0/1/0/all/0/1\">Joe Suk</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kpotufe_S/0/1/0/all/0/1\">Samory Kpotufe</a>",
          "description": "We study nonparametric contextual bandits where Lipschitz mean reward\nfunctions may change over time. We first establish the minimax dynamic regret\nrate in this less understood setting in terms of number of changes $L$ and\ntotal-variation $V$, both capturing all changes in distribution over context\nspace, and argue that state-of-the-art procedures are suboptimal in this\nsetting.\n\nNext, we tend to the question of an adaptivity for this setting, i.e.\nachieving the minimax rate without knowledge of $L$ or $V$. Quite importantly,\nwe posit that the bandit problem, viewed locally at a given context $X_t$,\nshould not be affected by reward changes in other parts of context space $\\cal\nX$. We therefore propose a notion of change, which we term experienced\nsignificant shifts, that better accounts for locality, and thus counts\nconsiderably less changes than $L$ and $V$. Furthermore, similar to recent work\non non-stationary MAB (Suk & Kpotufe, 2022), experienced significant shifts\nonly count the most significant changes in mean rewards, e.g., severe best-arm\nchanges relevant to observed contexts.\n\nOur main result is to show that this more tolerant notion of change can in\nfact be adapted to.",
          "link": "http://arxiv.org/abs/2307.05341",
          "publishedOn": "2023-07-12T01:02:46.376Z",
          "wordCount": null,
          "title": "Tracking Most Significant Shifts in Nonparametric Contextual Bandits. (arXiv:2307.05341v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.01977",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Hong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Chaoyue Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_R/0/1/0/all/0/1\">Ruogu Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1\">Xiaoyong Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Dapeng Wu</a>",
          "description": "Neural network pruning is an essential technique for reducing the size and\ncomplexity of deep neural networks, enabling large-scale models on devices with\nlimited resources. However, existing pruning approaches heavily rely on\ntraining data for guiding the pruning strategies, making them ineffective for\nfederated learning over distributed and confidential datasets. Additionally,\nthe memory- and computation-intensive pruning process becomes infeasible for\nrecourse-constrained devices in federated learning. To address these\nchallenges, we propose FedTiny, a distributed pruning framework for federated\nlearning that generates specialized tiny models for memory- and\ncomputing-constrained devices. We introduce two key modules in FedTiny to\nadaptively search coarse- and finer-pruned specialized models to fit deployment\nscenarios with sparse and cheap local computation. First, an adaptive batch\nnormalization selection module is designed to mitigate biases in pruning caused\nby the heterogeneity of local data. Second, a lightweight progressive pruning\nmodule aims to finer prune the models under strict memory and computational\nbudgets, allowing the pruning policy for each layer to be gradually determined\nrather than evaluating the overall model structure. The experimental results\ndemonstrate the effectiveness of FedTiny, which outperforms state-of-the-art\napproaches, particularly when compressing deep models to extremely sparse tiny\nmodels. FedTiny achieves an accuracy improvement of 2.61% while significantly\nreducing the computational cost by 95.91% and the memory footprint by 94.01%\ncompared to state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2212.01977",
          "publishedOn": "2023-07-12T01:02:46.307Z",
          "wordCount": null,
          "title": "Distributed Pruning Towards Tiny Neural Networks in Federated Learning. (arXiv:2212.01977v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.03829",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Durso_Finley_J/0/1/0/all/0/1\">Joshua Durso-Finley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Falet_J/0/1/0/all/0/1\">Jean-Pierre Falet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_R/0/1/0/all/0/1\">Raghav Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arnold_D/0/1/0/all/0/1\">Douglas L. Arnold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pawlowski_N/0/1/0/all/0/1\">Nick Pawlowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arbel_T/0/1/0/all/0/1\">Tal Arbel</a>",
          "description": "Image-based precision medicine aims to personalize treatment decisions based\non an individual's unique imaging features so as to improve their clinical\noutcome. Machine learning frameworks that integrate uncertainty estimation as\npart of their treatment recommendations would be safer and more reliable.\nHowever, little work has been done in adapting uncertainty estimation\ntechniques and validation metrics for precision medicine. In this paper, we use\nBayesian deep learning for estimating the posterior distribution over factual\nand counterfactual outcomes on several treatments. This allows for estimating\nthe uncertainty for each treatment option and for the individual treatment\neffects (ITE) between any two treatments. We train and evaluate this model to\npredict future new and enlarging T2 lesion counts on a large, multi-center\ndataset of MR brain images of patients with multiple sclerosis, exposed to\nseveral treatments during randomized controlled trials. We evaluate the\ncorrelation of the uncertainty estimate with the factual error, and, given the\nlack of ground truth counterfactual outcomes, demonstrate how uncertainty for\nthe ITE prediction relates to bounds on the ITE error. Lastly, we demonstrate\nhow knowledge of uncertainty could modify clinical decision-making to improve\nindividual patient and clinical trial outcomes.",
          "link": "http://arxiv.org/abs/2305.03829",
          "publishedOn": "2023-07-12T01:02:46.306Z",
          "wordCount": null,
          "title": "Improving Image-Based Precision Medicine with Uncertainty-Aware Causal Models. (arXiv:2305.03829v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05141",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Przystupa_M/0/1/0/all/0/1\">Michael Przystupa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haghverd_F/0/1/0/all/0/1\">Faezeh Haghverd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jagersand_M/0/1/0/all/0/1\">Martin Jagersand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tosatto_S/0/1/0/all/0/1\">Samuele Tosatto</a>",
          "description": "Movement primitives are trainable parametric models that reproduce robotic\nmovements starting from a limited set of demonstrations. Previous works\nproposed simple linear models that exhibited high sample efficiency and\ngeneralization power by allowing temporal modulation of movements (reproducing\nmovements faster or slower), blending (merging two movements into one),\nvia-point conditioning (constraining a movement to meet some particular\nvia-points) and context conditioning (generation of movements based on an\nobserved variable, e.g., position of an object). Previous works have proposed\nneural network-based motor primitive models, having demonstrated their capacity\nto perform tasks with some forms of input conditioning or time-modulation\nrepresentations. However, there has not been a single unified deep motor\nprimitive's model proposed that is capable of all previous operations, limiting\nneural motor primitive's potential applications. This paper proposes a deep\nmovement primitive architecture that encodes all the operations above and uses\na Bayesian context aggregator that allows a more sound context conditioning and\nblending. Our results demonstrate our approach can scale to reproduce complex\nmotions on a larger variety of input choices compared to baselines while\nmaintaining operations of linear movement primitives provide.",
          "link": "http://arxiv.org/abs/2307.05141",
          "publishedOn": "2023-07-12T01:02:46.301Z",
          "wordCount": null,
          "title": "Deep Probabilistic Movement Primitives with a Bayesian Aggregator. (arXiv:2307.05141v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04927",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1\">Xiaotong Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Filieri_A/0/1/0/all/0/1\">Antonio Filieri</a>",
          "description": "Safe exploration aims at addressing the limitations of Reinforcement Learning\n(RL) in safety-critical scenarios, where failures during trial-and-error\nlearning may incur high costs. Several methods exist to incorporate external\nknowledge or to use proximal sensor data to limit the exploration of unsafe\nstates. However, reducing exploration risks in unknown environments, where an\nagent must discover safety threats during exploration, remains challenging. In\nthis paper, we target the problem of safe exploration by guiding the training\nwith counterexamples of the safety requirement. Our method abstracts both\ncontinuous and discrete state-space systems into compact abstract models\nrepresenting the safety-relevant knowledge acquired by the agent during\nexploration. We then exploit probabilistic counterexample generation to\nconstruct minimal simulation submodels eliciting safety requirement violations,\nwhere the agent can efficiently train offline to refine its policy towards\nminimising the risk of safety violations during the subsequent online\nexploration. We demonstrate our method's effectiveness in reducing safety\nviolations during online exploration in preliminary experiments by an average\nof 40.3% compared with QL and DQN standard algorithms and 29.1% compared with\nprevious related work, while achieving comparable cumulative rewards with\nrespect to unrestricted exploration and alternative approaches.",
          "link": "http://arxiv.org/abs/2307.04927",
          "publishedOn": "2023-07-12T01:02:46.140Z",
          "wordCount": null,
          "title": "Probabilistic Counterexample Guidance for Safer Reinforcement Learning. (arXiv:2307.04927v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05435",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Golovanevsky_M/0/1/0/all/0/1\">Michal Golovanevsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schiller_E/0/1/0/all/0/1\">Eva Schiller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1\">Akira Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Ritambhara Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eickhoff_C/0/1/0/all/0/1\">Carsten Eickhoff</a>",
          "description": "Multimodal learning models have become increasingly important as they surpass\nsingle-modality approaches on diverse tasks ranging from question-answering to\nautonomous driving. Despite the importance of multimodal learning, existing\nefforts focus on NLP applications, where the number of modalities is typically\nless than four (audio, video, text, images). However, data inputs in other\ndomains, such as the medical field, may include X-rays, PET scans, MRIs,\ngenetic screening, clinical notes, and more, creating a need for both efficient\nand accurate information fusion. Many state-of-the-art models rely on pairwise\ncross-modal attention, which does not scale well for applications with more\nthan three modalities. For $n$ modalities, computing attention will result in\n$n \\choose 2$ operations, potentially requiring considerable amounts of\ncomputational resources. To address this, we propose a new domain-neutral\nattention mechanism, One-Versus-Others (OvO) attention, that scales linearly\nwith the number of modalities and requires only $n$ attention operations, thus\noffering a significant reduction in computational complexity compared to\nexisting cross-modal attention algorithms. Using three diverse real-world\ndatasets as well as an additional simulation experiment, we show that our\nmethod improves performance compared to popular fusion techniques while\ndecreasing computation costs.",
          "link": "http://arxiv.org/abs/2307.05435",
          "publishedOn": "2023-07-12T01:02:46.013Z",
          "wordCount": null,
          "title": "One-Versus-Others Attention: Scalable Multimodal Integration. (arXiv:2307.05435v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.06170",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Lee_H/0/1/0/all/0/1\">Hyun-Gi Lee</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Park_J/0/1/0/all/0/1\">Jungsic Park</a>",
          "description": "The linear response of a photomultiplier tube (PMT) is a required property\nfor photon counting and reconstruction of the neutrino energy. The linearity\nvalid region and the saturation response of PMT were investigated using a\nlinear-alkyl-benzene (LAB)-based liquid scintillator. A correlation was\nobserved between the two different saturation responses, with pulse-shape\ndistortion and pulse-area decrease. The observed pulse-shape provides useful\ninformation for the estimation of the linearity region relative to the\npulse-area. This correlation-based diagnosis allows an ${in}$-${situ}$\nestimation of the linearity range, which was previously challenging. The\nmeasured correlation between the two saturation responses was employed to train\nan artificial-neural-network (ANN) to predict the decrease in pulse-area from\nthe observed pulse-shape. The ANN-predicted pulse-area decrease enables the\nprediction of the ideal number of photoelectrons irrelevant to the saturation\nbehavior. This pulse-shape-based machine learning technique offers a novel\nmethod for restoring the saturation response of PMTs.",
          "link": "http://arxiv.org/abs/2302.06170",
          "publishedOn": "2023-07-12T01:02:46.009Z",
          "wordCount": null,
          "title": "Restoring the saturation response of a PMT using pulse-shape and artificial-neural-networks. (arXiv:2302.06170v3 [physics.ins-det] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.00390",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rao_S/0/1/0/all/0/1\">Susie Xi Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Egger_P/0/1/0/all/0/1\">Peter H. Egger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Ce Zhang</a>",
          "description": "This paper presents a hierarchical classification system that automatically\ncategorizes a scholarly publication using its abstract into a three-tier\nhierarchical label set (discipline, field, subfield) in a multi-class setting.\nThis system enables a holistic categorization of research activities in the\nmentioned hierarchy in terms of knowledge production through articles and\nimpact through citations, permitting those activities to fall into multiple\ncategories. The classification system distinguishes 44 disciplines, 718 fields\nand 1,485 subfields among 160 million abstract snippets in Microsoft Academic\nGraph (version 2018-05-17). We used batch training in a modularized and\ndistributed fashion to address and allow for interdisciplinary and interfield\nclassifications in single-label and multi-label settings. In total, we have\nconducted 3,140 experiments in all considered models (Convolutional Neural\nNetworks, Recurrent Neural Networks, Transformers). The classification accuracy\nis > 90% in 77.13% and 78.19% of the single-label and multi-label\nclassifications, respectively. We examine the advantages of our classification\nby its ability to better align research texts and output with disciplines, to\nadequately classify them in an automated way, and to capture the degree of\ninterdisciplinarity. The proposed system (a set of pre-trained models) can\nserve as a backbone to an interactive system for indexing scientific\npublications in the future.",
          "link": "http://arxiv.org/abs/2302.00390",
          "publishedOn": "2023-07-12T01:02:45.948Z",
          "wordCount": null,
          "title": "Hierarchical Classification of Research Fields in the \"Web of Science\" Using Deep Learning. (arXiv:2302.00390v2 [cs.DL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05392",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Lan_H/0/1/0/all/0/1\">Hai Lan</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Wei_X/0/1/0/all/0/1\">Xian Wei</a>",
          "description": "Recently, message-passing Neural networks (MPNN) provide a promising tool for\ndealing with molecular graphs and have achieved remarkable success in\nfacilitating the discovery and materials design with desired properties.\nHowever, the classical MPNN methods also suffer from a limitation in capturing\nthe strong topological information hidden in molecular structures, such as\nnonisomorphic graphs. To address this problem, this work proposes a Simplicial\nMessage Passing (SMP) framework to better capture the topological information\nfrom molecules, which can break through the limitation within the vanilla\nmessage-passing paradigm. In SMP, a generalized message-passing framework is\nestablished for aggregating the information from arbitrary-order simplicial\ncomplex, and a hierarchical structure is elaborated to allow information\nexchange between different order simplices. We apply the SMP framework within\ndeep learning architectures for quantum-chemical properties prediction and\nachieve state-of-the-art results. The results show that compared to traditional\nMPNN, involving higher-order simplex can better capture the complex structure\nof molecules and substantially enhance the performance of tasks. The SMP-based\nmodel can provide a generalized framework for GNNs and aid in the discovery and\ndesign of materials with tailored properties for various applications.",
          "link": "http://arxiv.org/abs/2307.05392",
          "publishedOn": "2023-07-12T01:02:45.920Z",
          "wordCount": null,
          "title": "Simplicial Message Passing for Chemical Property Prediction. (arXiv:2307.05392v1 [cond-mat.mtrl-sci])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05362",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Cheng_X/0/1/0/all/0/1\">Xuewei Cheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_K/0/1/0/all/0/1\">Ke Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zou_Y/0/1/0/all/0/1\">Yi Zou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ma_S/0/1/0/all/0/1\">Shujie Ma</a>",
          "description": "Deep neural networks have played an important role in automatic sleep stage\nclassification because of their strong representation and in-model feature\ntransformation abilities. However, class imbalance and individual heterogeneity\nwhich typically exist in raw EEG signals of sleep data can significantly affect\nthe classification performance of any machine learning algorithms. To solve\nthese two problems, this paper develops a generative adversarial network\n(GAN)-powered ensemble deep learning model, named SleepEGAN, for the imbalanced\nclassification of sleep stages. To alleviate class imbalance, we propose a new\nGAN (called EGAN) architecture adapted to the features of EEG signals for data\naugmentation. The generated samples for the minority classes are used in the\ntraining process. In addition, we design a cost-free ensemble learning strategy\nto reduce the model estimation variance caused by the heterogeneity between the\nvalidation and test sets, so as to enhance the accuracy and robustness of\nprediction performance. We show that the proposed method can improve\nclassification accuracy compared to several existing state-of-the-art methods\nusing three public sleep datasets.",
          "link": "http://arxiv.org/abs/2307.05362",
          "publishedOn": "2023-07-12T01:02:45.862Z",
          "wordCount": null,
          "title": "SleepEGAN: A GAN-enhanced Ensemble Deep Learning Model for Imbalanced Classification of Sleep Stages. (arXiv:2307.05362v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05384",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chen_X/0/1/0/all/0/1\">Xuxing Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Balasubramanian_K/0/1/0/all/0/1\">Krishnakumar Balasubramanian</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ghadimi_S/0/1/0/all/0/1\">Saeed Ghadimi</a>",
          "description": "We develop and analyze stochastic approximation algorithms for solving nested\ncompositional bi-level optimization problems. These problems involve a nested\ncomposition of $T$ potentially non-convex smooth functions in the upper-level,\nand a smooth and strongly convex function in the lower-level. Our proposed\nalgorithm does not rely on matrix inversions or mini-batches and can achieve an\n$\\epsilon$-stationary solution with an oracle complexity of approximately\n$\\tilde{O}_T(1/\\epsilon^{2})$, assuming the availability of stochastic\nfirst-order oracles for the individual functions in the composition and the\nlower-level, which are unbiased and have bounded moments. Here, $\\tilde{O}_T$\nhides polylog factors and constants that depend on $T$. The key challenge we\naddress in establishing this result relates to handling three distinct sources\nof bias in the stochastic gradients. The first source arises from the\ncompositional nature of the upper-level, the second stems from the bi-level\nstructure, and the third emerges due to the utilization of Neumann series\napproximations to avoid matrix inversion. To demonstrate the effectiveness of\nour approach, we apply it to the problem of robust feature learning for deep\nneural networks under covariate shift, showcasing the benefits and advantages\nof our methodology in that context.",
          "link": "http://arxiv.org/abs/2307.05384",
          "publishedOn": "2023-07-12T01:02:45.572Z",
          "wordCount": null,
          "title": "Stochastic Nested Compositional Bi-level Optimization for Robust Feature Learning. (arXiv:2307.05384v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04893",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moraes_R/0/1/0/all/0/1\">Rubens O. Moraes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aleixo_D/0/1/0/all/0/1\">David S. Aleixo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferreira_L/0/1/0/all/0/1\">Lucas N. Ferreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lelis_L/0/1/0/all/0/1\">Levi H. S. Lelis</a>",
          "description": "This paper introduces Local Learner (2L), an algorithm for providing a set of\nreference strategies to guide the search for programmatic strategies in\ntwo-player zero-sum games. Previous learning algorithms, such as Iterated Best\nResponse (IBR), Fictitious Play (FP), and Double-Oracle (DO), can be\ncomputationally expensive or miss important information for guiding search\nalgorithms. 2L actively selects a set of reference strategies to improve the\nsearch signal. We empirically demonstrate the advantages of our approach while\nguiding a local search algorithm for synthesizing strategies in three games,\nincluding MicroRTS, a challenging real-time strategy game. Results show that 2L\nlearns reference strategies that provide a stronger search signal than IBR, FP,\nand DO. We also simulate a tournament of MicroRTS, where a synthesizer using 2L\noutperformed the winners of the two latest MicroRTS competitions, which were\nprogrammatic strategies written by human programmers.",
          "link": "http://arxiv.org/abs/2307.04893",
          "publishedOn": "2023-07-12T01:02:45.198Z",
          "wordCount": 681,
          "title": "Choosing Well Your Opponents: How to Guide the Synthesis of Programmatic Strategies. (arXiv:2307.04893v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.05380",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Klipfel_A/0/1/0/all/0/1\">Astrid Klipfel</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Fregier_Y/0/1/0/all/0/1\">Ya&#xeb;l Fr&#xe9;gier</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Sayede_A/0/1/0/all/0/1\">Adlane Sayede</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Bouraoui_Z/0/1/0/all/0/1\">Zied Bouraoui</a>",
          "description": "Graph neural networks are widely used in machine learning applied to\nchemistry, and in particular for material science discovery. For crystalline\nmaterials, however, generating graph-based representation from geometrical\ninformation for neural networks is not a trivial task. The periodicity of\ncrystalline needs efficient implementations to be processed in real-time under\na massively parallel environment. With the aim of training graph-based\ngenerative models of new material discovery, we propose an efficient tool to\ngenerate cutoff graphs and k-nearest-neighbours graphs of periodic structures\nwithin GPU optimization. We provide pyMatGraph a Pytorch-compatible framework\nto generate graphs in real-time during the training of neural network\narchitecture. Our tool can update a graph of a structure, making generative\nmodels able to update the geometry and process the updated graph during the\nforward propagation on the GPU side. Our code is publicly available at\nhttps://github.com/aklipf/mat-graph.",
          "link": "http://arxiv.org/abs/2307.05380",
          "publishedOn": "2023-07-12T01:02:45.173Z",
          "wordCount": 647,
          "title": "Optimized Crystallographic Graph Generation for Material Science. (arXiv:2307.05380v1 [cond-mat.mtrl-sci])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.05299",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bishnoi_S/0/1/0/all/0/1\">Suresh Bishnoi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattoo_R/0/1/0/all/0/1\">Ravinder Bhattoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jayadeva/0/1/0/all/0/1\">Jayadeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranu_S/0/1/0/all/0/1\">Sayan Ranu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnan_N/0/1/0/all/0/1\">N M Anoop Krishnan</a>",
          "description": "The time evolution of physical systems is described by differential\nequations, which depend on abstract quantities like energy and force.\nTraditionally, these quantities are derived as functionals based on observables\nsuch as positions and velocities. Discovering these governing symbolic laws is\nthe key to comprehending the interactions in nature. Here, we present a\nHamiltonian graph neural network (HGNN), a physics-enforced GNN that learns the\ndynamics of systems directly from their trajectory. We demonstrate the\nperformance of HGNN on n-springs, n-pendulums, gravitational systems, and\nbinary Lennard Jones systems; HGNN learns the dynamics in excellent agreement\nwith the ground truth from small amounts of data. We also evaluate the ability\nof HGNN to generalize to larger system sizes, and to hybrid spring-pendulum\nsystem that is a combination of two original systems (spring and pendulum) on\nwhich the models are trained independently. Finally, employing symbolic\nregression on the learned HGNN, we infer the underlying equations relating the\nenergy functionals, even for complex systems such as the binary Lennard-Jones\nliquid. Our framework facilitates the interpretable discovery of interaction\nlaws directly from physical system trajectories. Furthermore, this approach can\nbe extended to other systems with topology-dependent dynamics, such as cells,\npolydisperse gels, or deformable bodies.",
          "link": "http://arxiv.org/abs/2307.05299",
          "publishedOn": "2023-07-12T01:02:45.161Z",
          "wordCount": 729,
          "title": "Discovering Symbolic Laws Directly from Trajectories with Hamiltonian Graph Neural Networks. (arXiv:2307.05299v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04866",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ramli_A/0/1/0/all/0/1\">Albara Ah Ramli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1\">Xin Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Berndt_K/0/1/0/all/0/1\">Kelly Berndt</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chuah_C/0/1/0/all/0/1\">Chen-Nee Chuah</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Goude_E/0/1/0/all/0/1\">Erica Goude</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kaethler_L/0/1/0/all/0/1\">Lynea B. Kaethler</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lopez_A/0/1/0/all/0/1\">Amanda Lopez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nicorici_A/0/1/0/all/0/1\">Alina Nicorici</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Owens_C/0/1/0/all/0/1\">Corey Owens</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rodriguez_D/0/1/0/all/0/1\">David Rodriguez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1\">Jane Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Aranki_D/0/1/0/all/0/1\">Daniel Aranki</a>, <a href=\"http://arxiv.org/find/eess/1/au:+McDonald_C/0/1/0/all/0/1\">Craig M. McDonald</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Henricson_E/0/1/0/all/0/1\">Erik K. Henricson</a>",
          "description": "Background: Estimation of temporospatial clinical features of gait (CFs),\nsuch as step count and length, step duration, step frequency, gait speed and\ndistance traveled is an important component of community-based mobility\nevaluation using wearable accelerometers. However, challenges arising from\ndevice complexity and availability, cost and analytical methodology have\nlimited widespread application of such tools. Research Question: Can\naccelerometer data from commercially-available smartphones be used to extract\ngait CFs across a broad range of attainable gait velocities in children with\nDuchenne muscular dystrophy (DMD) and typically developing controls (TDs) using\nmachine learning (ML)-based methods Methods: Fifteen children with DMD and 15\nTDs underwent supervised clinical testing across a range of gait speeds using\n10 or 25m run/walk (10MRW, 25MRW), 100m run/walk (100MRW), 6-minute walk (6MWT)\nand free-walk (FW) evaluations while wearing a mobile phone-based accelerometer\nat the waist near the body's center of mass. Gait CFs were extracted from the\naccelerometer data using a multi-step machine learning-based process and\nresults were compared to ground-truth observation data. Results: Model\npredictions vs. observed values for step counts, distance traveled, and step\nlength showed a strong correlation (Pearson's r = -0.9929 to 0.9986, p<0.0001).\nThe estimates demonstrated a mean (SD) percentage error of 1.49% (7.04%) for\nstep counts, 1.18% (9.91%) for distance traveled, and 0.37% (7.52%) for step\nlength compared to ground truth observations for the combined 6MWT, 100MRW, and\nFW tasks. Significance: The study findings indicate that a single accelerometer\nplaced near the body's center of mass can accurately measure CFs across\ndifferent gait speeds in both TD and DMD peers, suggesting that there is\npotential for accurately measuring CFs in the community with consumer-level\nsmartphones.",
          "link": "http://arxiv.org/abs/2307.04866",
          "publishedOn": "2023-07-12T01:02:45.154Z",
          "wordCount": 856,
          "title": "Automated Detection of Gait Events and Travel Distance Using Waist-worn Accelerometers Across a Typical Range of Walking and Running Speeds. (arXiv:2307.04866v1 [eess.SP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04859",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bergman_A/0/1/0/all/0/1\">Alexander W. Bergman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yifan_W/0/1/0/all/0/1\">Wang Yifan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wetzstein_G/0/1/0/all/0/1\">Gordon Wetzstein</a>",
          "description": "The ability to generate diverse 3D articulated head avatars is vital to a\nplethora of applications, including augmented reality, cinematography, and\neducation. Recent work on text-guided 3D object generation has shown great\npromise in addressing these needs. These methods directly leverage pre-trained\n2D text-to-image diffusion models to generate 3D-multi-view-consistent radiance\nfields of generic objects. However, due to the lack of geometry and texture\npriors, these methods have limited control over the generated 3D objects,\nmaking it difficult to operate inside a specific domain, e.g., human heads. In\nthis work, we develop a new approach to text-guided 3D head avatar generation\nto address this limitation. Our framework directly operates on the geometry and\ntexture of an articulable 3D morphable model (3DMM) of a head, and introduces\nnovel optimization procedures to update the geometry and texture while keeping\nthe 2D and 3D facial features aligned. The result is a 3D head avatar that is\nconsistent with the text description and can be readily articulated using the\ndeformation model of the 3DMM. We show that our diffusion-based articulated\nhead avatars outperform state-of-the-art approaches for this task. The latter\nare typically based on CLIP, which is known to provide limited diversity of\ngeneration and accuracy for 3D object generation.",
          "link": "http://arxiv.org/abs/2307.04859",
          "publishedOn": "2023-07-12T01:02:45.123Z",
          "wordCount": 726,
          "title": "Articulated 3D Head Avatar Generation using Text-to-Image Diffusion Models. (arXiv:2307.04859v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.02733",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Laar_T/0/1/0/all/0/1\">Thijs van de Laar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Koudahl_M/0/1/0/all/0/1\">Magnus Koudahl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vries_B/0/1/0/all/0/1\">Bert de Vries</a>",
          "description": "The Free Energy Principle (FEP) describes (biological) agents as minimising a\nvariational Free Energy (FE) with respect to a generative model of their\nenvironment. Active Inference (AIF) is a corollary of the FEP that describes\nhow agents explore and exploit their environment by minimising an expected FE\nobjective. In two related papers, we describe a scalable, epistemic approach to\nsynthetic AIF agents, by message passing on free-form Forney-style Factor\nGraphs (FFGs). A companion paper (part I) introduces a Constrained FFG (CFFG)\nnotation that visually represents (generalised) FE objectives for AIF. The\ncurrent paper (part II) derives message passing algorithms that minimise\n(generalised) FE objectives on a CFFG by variational calculus. A comparison\nbetween simulated Bethe and generalised FE agents illustrates how synthetic AIF\ninduces epistemic behaviour on a T-maze navigation task. With a full message\npassing account of synthetic AIF agents, it becomes possible to derive and\nreuse message updates across models and move closer to industrial applications\nof synthetic AIF.",
          "link": "http://arxiv.org/abs/2306.02733",
          "publishedOn": "2023-07-12T01:02:45.104Z",
          "wordCount": 696,
          "title": "Realising Synthetic Active Inference Agents, Part II: Variational Message Updates. (arXiv:2306.02733v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04963",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Simin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1\">Shiyi Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Cong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wei Yang</a>",
          "description": "DL compiler's primary function is to translate DNN programs written in\nhigh-level DL frameworks such as PyTorch and TensorFlow into portable\nexecutables. These executables can then be flexibly executed by the deployed\nhost programs. However, existing DL compilers rely on a tracing mechanism,\nwhich involves feeding a runtime input to a neural network program and tracing\nthe program execution paths to generate the computational graph necessary for\ncompilation. Unfortunately, this mechanism falls short when dealing with modern\ndynamic neural networks (DyNNs) that possess varying computational graphs\ndepending on the inputs. Consequently, conventional DL compilers struggle to\naccurately compile DyNNs into executable code. To address this limitation, we\npropose \\tool, a general approach that enables any existing DL compiler to\nsuccessfully compile DyNNs. \\tool tackles the dynamic nature of DyNNs by\nintroducing a compilation mechanism that redistributes the control and data\nflow of the original DNN programs during the compilation process. Specifically,\n\\tool develops program analysis and program transformation techniques to\nconvert a dynamic neural network into multiple sub-neural networks. Each\nsub-neural network is devoid of conditional statements and is compiled\nindependently. Furthermore, \\tool synthesizes a host module that models the\ncontrol flow of the DyNNs and facilitates the invocation of the sub-neural\nnetworks. Our evaluation demonstrates the effectiveness of \\tool, achieving a\n100\\% success rate in compiling all dynamic neural networks. Moreover, the\ncompiled executables generated by \\tool exhibit significantly improved\nperformance, running between $1.12\\times$ and $20.21\\times$ faster than the\noriginal DyNNs executed on general-purpose DL frameworks.",
          "link": "http://arxiv.org/abs/2307.04963",
          "publishedOn": "2023-07-12T01:02:45.098Z",
          "wordCount": 775,
          "title": "DyCL: Dynamic Neural Network Compilation Via Program Rewriting and Graph Optimization. (arXiv:2307.04963v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/1903.09132",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1\">Branislav Kveton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1\">Csaba Szepesvari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1\">Mohammad Ghavamzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boutilier_C/0/1/0/all/0/1\">Craig Boutilier</a>",
          "description": "We propose a new online algorithm for cumulative regret minimization in a\nstochastic linear bandit. The algorithm pulls the arm with the highest\nestimated reward in a linear model trained on its perturbed history. Therefore,\nwe call it perturbed-history exploration in a linear bandit (LinPHE). The\nperturbed history is a mixture of observed rewards and randomly generated\ni.i.d. pseudo-rewards. We derive a $\\tilde{O}(d \\sqrt{n})$ gap-free bound on\nthe $n$-round regret of LinPHE, where $d$ is the number of features. The key\nsteps in our analysis are new concentration and anti-concentration bounds on\nthe weighted sum of Bernoulli random variables. To show the generality of our\ndesign, we generalize LinPHE to a logistic model. We evaluate our algorithms\nempirically and show that they are practical.",
          "link": "http://arxiv.org/abs/1903.09132",
          "publishedOn": "2023-07-12T01:02:45.083Z",
          "wordCount": 667,
          "title": "Perturbed-History Exploration in Stochastic Linear Bandits. (arXiv:1903.09132v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.05014",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Renhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gandelsman_Y/0/1/0/all/0/1\">Yossi Gandelsman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinlei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Efros_A/0/1/0/all/0/1\">Alexei A. Efros</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolong Wang</a>",
          "description": "Prior work has established test-time training (TTT) as a general framework to\nfurther improve a trained model at test time. Before making a prediction on\neach test instance, the model is trained on the same instance using a\nself-supervised task, such as image reconstruction with masked autoencoders. We\nextend TTT to the streaming setting, where multiple test instances - video\nframes in our case - arrive in temporal order. Our extension is online TTT: The\ncurrent model is initialized from the previous model, then trained on the\ncurrent frame and a small window of frames immediately before. Online TTT\nsignificantly outperforms the fixed-model baseline for four tasks, on three\nreal-world datasets. The relative improvement is 45% and 66% for instance and\npanoptic segmentation. Surprisingly, online TTT also outperforms its offline\nvariant that accesses more information, training on all frames from the entire\ntest video regardless of temporal order. This differs from previous findings\nusing synthetic videos. We conceptualize locality as the advantage of online\nover offline TTT. We analyze the role of locality with ablations and a theory\nbased on bias-variance trade-off.",
          "link": "http://arxiv.org/abs/2307.05014",
          "publishedOn": "2023-07-12T01:02:45.042Z",
          "wordCount": 684,
          "title": "Test-Time Training on Video Streams. (arXiv:2307.05014v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04891",
          "author": "<a href=\"http://arxiv.org/find/hep-th/1/au:+Forestano_R/0/1/0/all/0/1\">Roy T. Forestano</a>, <a href=\"http://arxiv.org/find/hep-th/1/au:+Matchev_K/0/1/0/all/0/1\">Konstantin T. Matchev</a>, <a href=\"http://arxiv.org/find/hep-th/1/au:+Matcheva_K/0/1/0/all/0/1\">Katia Matcheva</a>, <a href=\"http://arxiv.org/find/hep-th/1/au:+Roman_A/0/1/0/all/0/1\">Alexander Roman</a>, <a href=\"http://arxiv.org/find/hep-th/1/au:+Unlu_E/0/1/0/all/0/1\">Eyup B. Unlu</a>, <a href=\"http://arxiv.org/find/hep-th/1/au:+Verner_S/0/1/0/all/0/1\">Sarunas Verner</a>",
          "description": "Recent work has applied supervised deep learning to derive continuous\nsymmetry transformations that preserve the data labels and to obtain the\ncorresponding algebras of symmetry generators. This letter introduces two\nimproved algorithms that significantly speed up the discovery of these symmetry\ntransformations. The new methods are demonstrated by deriving the complete set\nof generators for the unitary groups U(n) and the exceptional Lie groups $G_2$,\n$F_4$, and $E_6$. A third post-processing algorithm renders the found\ngenerators in sparse form. We benchmark the performance improvement of the new\nalgorithms relative to the standard approach. Given the significant complexity\nof the exceptional Lie groups, our results demonstrate that this\nmachine-learning method for discovering symmetries is completely general and\ncan be applied to a wide variety of labeled datasets.",
          "link": "http://arxiv.org/abs/2307.04891",
          "publishedOn": "2023-07-12T01:02:45.012Z",
          "wordCount": 695,
          "title": "Accelerated Discovery of Machine-Learned Symmetries: Deriving the Exceptional Lie Groups G2, F4 and E6. (arXiv:2307.04891v1 [hep-th])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04990",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zhili Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winston_E/0/1/0/all/0/1\">Ezra Winston</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1\">J. Zico Kolter</a>",
          "description": "Deep Boltzmann machines (DBMs), one of the first ``deep'' learning methods\never studied, are multi-layered probabilistic models governed by a pairwise\nenergy function that describes the likelihood of all variables/nodes in the\nnetwork. In practice, DBMs are often constrained, i.e., via the\n\\emph{restricted} Boltzmann machine (RBM) architecture (which does not permit\nintra-layer connections), in order to allow for more efficient inference. In\nthis work, we revisit the generic DBM approach, and ask the question: are there\nother possible restrictions to their design that would enable efficient\n(approximate) inference? In particular, we develop a new class of restricted\nmodel, the monotone DBM, which allows for arbitrary self-connection in each\nlayer, but restricts the \\emph{weights} in a manner that guarantees the\nexistence and global uniqueness of a mean-field fixed point. To do this, we\nleverage tools from the recently-proposed monotone Deep Equilibrium model and\nshow that a particular choice of activation results in a fixed-point iteration\nthat gives a variational mean-field solution. While this approach is still\nlargely conceptual, it is the first architecture that allows for efficient\napproximate inference in fully-general weight structures for DBMs. We apply\nthis approach to simple deep convolutional Boltzmann architectures and\ndemonstrate that it allows for tasks such as the joint completion and\nclassification of images, within a single deep probabilistic setting, while\navoiding the pitfalls of mean-field inference in traditional RBMs.",
          "link": "http://arxiv.org/abs/2307.04990",
          "publishedOn": "2023-07-12T01:02:45.005Z",
          "wordCount": 709,
          "title": "Monotone deep Boltzmann machines. (arXiv:2307.04990v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.05383",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Fan_D/0/1/0/all/0/1\">Di Fan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_M/0/1/0/all/0/1\">Mingyang Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaohan Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gong_X/0/1/0/all/0/1\">Xiaopeng Gong</a>",
          "description": "A novel human emotion recognition method based on automatically selected\nGalvanic Skin Response (GSR) signal features and SVM is proposed in this paper.\nGSR signals were acquired by e-Health Sensor Platform V2.0. Then, the data is\nde-noised by wavelet function and normalized to get rid of the individual\ndifference. 30 features are extracted from the normalized data, however,\ndirectly using of these features will lead to a low recognition rate. In order\nto gain the optimized features, a covariance based feature selection is\nemployed in our method. Finally, a SVM with input of the optimized features is\nutilized to achieve the human emotion recognition. The experimental results\nindicate that the proposed method leads to good human emotion recognition, and\nthe recognition accuracy is more than 66.67%.",
          "link": "http://arxiv.org/abs/2307.05383",
          "publishedOn": "2023-07-12T01:02:44.952Z",
          "wordCount": 644,
          "title": "Human Emotion Recognition Based On Galvanic Skin Response signal Feature Selection and SVM. (arXiv:2307.05383v1 [eess.SP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04817",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Ma_J/0/1/0/all/0/1\">Jun Ma</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Shen_H/0/1/0/all/0/1\">Huanfeng Shen</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Jiang_M/0/1/0/all/0/1\">Menghui Jiang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lin_L/0/1/0/all/0/1\">Liupeng Lin</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Meng_C/0/1/0/all/0/1\">Chunlei Meng</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zeng_C/0/1/0/all/0/1\">Chao Zeng</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Li_H/0/1/0/all/0/1\">Huifang Li</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wu_P/0/1/0/all/0/1\">Penghai Wu</a>",
          "description": "More accurate, spatio-temporally, and physically consistent LST estimation\nhas been a main interest in Earth system research. Developing physics-driven\nmechanism models and data-driven machine learning (ML) models are two major\nparadigms for gapless LST estimation, which have their respective advantages\nand disadvantages. In this paper, a physics-constrained ML model, which\ncombines the strengths in the mechanism model and ML model, is proposed to\ngenerate gapless LST with physical meanings and high accuracy. The hybrid model\nemploys ML as the primary architecture, under which the input variable physical\nconstraints are incorporated to enhance the interpretability and extrapolation\nability of the model. Specifically, the light gradient-boosting machine (LGBM)\nmodel, which uses only remote sensing data as input, serves as the pure ML\nmodel. Physical constraints (PCs) are coupled by further incorporating key\nCommunity Land Model (CLM) forcing data (cause) and CLM simulation data\n(effect) as inputs into the LGBM model. This integration forms the PC-LGBM\nmodel, which incorporates surface energy balance (SEB) constraints underlying\nthe data in CLM-LST modeling within a biophysical framework. Compared with a\npure physical method and pure ML methods, the PC-LGBM model improves the\nprediction accuracy and physical interpretability of LST. It also demonstrates\na good extrapolation ability for the responses to extreme weather cases,\nsuggesting that the PC-LGBM model enables not only empirical learning from data\nbut also rationally derived from theory. The proposed method represents an\ninnovative way to map accurate and physically interpretable gapless LST, and\ncould provide insights to accelerate knowledge discovery in land surface\nprocesses and data mining in geographical parameter estimation.",
          "link": "http://arxiv.org/abs/2307.04817",
          "publishedOn": "2023-07-12T01:02:44.847Z",
          "wordCount": 783,
          "title": "A physics-constrained machine learning method for mapping gapless land surface temperature. (arXiv:2307.04817v1 [physics.ao-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04770",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hao_D/0/1/0/all/0/1\">Degan Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Negahdar_M/0/1/0/all/0/1\">Mohammadreza Negahdar</a>",
          "description": "Long COVID is a general term of post-acute sequelae of COVID-19. Patients\nwith long COVID can endure long-lasting symptoms including fatigue, headache,\ndyspnea and anosmia, etc. Identifying the cohorts with severe long-term\ncomplications in COVID-19 could benefit the treatment planning and resource\narrangement. However, due to the heterogeneous phenotype presented in long\nCOVID patients, it is difficult to predict their outcomes from their\nlongitudinal data. In this study, we proposed a spatiotemporal attention\nmechanism to weigh feature importance jointly from the temporal dimension and\nfeature space. Considering that medical examinations can have interchangeable\norders in adjacent time points, we restricted the learning of short-term\ndependency with a Local-LSTM and the learning of long-term dependency with the\njoint spatiotemporal attention. We also compared the proposed method with\nseveral state-of-the-art methods and a method in clinical practice. The methods\nare evaluated on a hard-to-acquire clinical dataset of patients with long\nCOVID. Experimental results show the Local-LSTM with joint spatiotemporal\nattention outperformed related methods in outcome prediction. The proposed\nmethod provides a clinical tool for the severity assessment of long COVID.",
          "link": "http://arxiv.org/abs/2307.04770",
          "publishedOn": "2023-07-12T01:02:44.824Z",
          "wordCount": 725,
          "title": "Predicting Outcomes in Long COVID Patients with Spatiotemporal Attention. (arXiv:2307.04770v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Subin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kyungmin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">June Suk Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_J/0/1/0/all/0/1\">Jongheon Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1\">Kihyuk Sohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jinwoo Shin</a>",
          "description": "Generative priors of large-scale text-to-image diffusion models enable a wide\nrange of new generation and editing applications on diverse visual modalities.\nHowever, when adapting these priors to complex visual modalities, often\nrepresented as multiple images (e.g., video), achieving consistency across a\nset of images is challenging. In this paper, we address this challenge with a\nnovel method, Collaborative Score Distillation (CSD). CSD is based on the Stein\nVariational Gradient Descent (SVGD). Specifically, we propose to consider\nmultiple samples as \"particles\" in the SVGD update and combine their score\nfunctions to distill generative priors over a set of images synchronously.\nThus, CSD facilitates seamless integration of information across 2D images,\nleading to a consistent visual synthesis across multiple samples. We show the\neffectiveness of CSD in a variety of tasks, encompassing the visual editing of\npanorama images, videos, and 3D scenes. Our results underline the competency of\nCSD as a versatile method for enhancing inter-sample consistency, thereby\nbroadening the applicability of text-to-image diffusion models.",
          "link": "http://arxiv.org/abs/2307.04787",
          "publishedOn": "2023-07-12T01:02:44.816Z",
          "wordCount": 679,
          "title": "Collaborative Score Distillation for Consistent Visual Synthesis. (arXiv:2307.04787v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bshouty_N/0/1/0/all/0/1\">Nader H. Bshouty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haddad_Zaknoon_C/0/1/0/all/0/1\">Catherine A. Haddad-Zaknoon</a>",
          "description": "Group testing is an approach aimed at identifying up to $d$ defective items\namong a total of $n$ elements. This is accomplished by examining subsets to\ndetermine if at least one defective item is present. In our study, we focus on\nthe problem of identifying a subset of $\\ell\\leq d$ defective items. We develop\nupper and lower bounds on the number of tests required to detect $\\ell$\ndefective items in both the adaptive and non-adaptive settings while\nconsidering scenarios where no prior knowledge of $d$ is available, and\nsituations where an estimate of $d$ or at least some non-trivial upper bound on\n$d$ is available.\n\nWhen no prior knowledge on $d$ is available, we prove a lower bound of $\n\\Omega(\\frac{\\ell \\log^2n}{\\log \\ell +\\log\\log n})$ tests in the randomized\nnon-adaptive settings and an upper bound of $O(\\ell \\log^2 n)$ for the same\nsettings. Furthermore, we demonstrate that any non-adaptive deterministic\nalgorithm must ask $\\Theta(n)$ tests, signifying a fundamental limitation in\nthis scenario. For adaptive algorithms, we establish tight bounds in different\nscenarios. In the deterministic case, we prove a tight bound of\n$\\Theta(\\ell\\log{(n/\\ell)})$. Moreover, in the randomized settings, we derive a\ntight bound of $\\Theta(\\ell\\log{(n/d)})$.\n\nWhen $d$, or at least some non-trivial estimate of $d$, is known, we prove a\ntight bound of $\\Theta(d\\log (n/d))$ for the deterministic non-adaptive\nsettings, and $\\Theta(\\ell\\log(n/d))$ for the randomized non-adaptive settings.\nIn the adaptive case, we present an upper bound of $O(\\ell \\log (n/\\ell))$ for\nthe deterministic settings, and a lower bound of $\\Omega(\\ell\\log(n/d)+\\log\nn)$. Additionally, we establish a tight bound of $\\Theta(\\ell \\log(n/d))$ for\nthe randomized adaptive settings.",
          "link": "http://arxiv.org/abs/2307.04822",
          "publishedOn": "2023-07-12T01:02:44.808Z",
          "wordCount": 770,
          "title": "On Detecting Some Defective Items in Group Testing. (arXiv:2307.04822v1 [cs.DS])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04780",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Acosta_F/0/1/0/all/0/1\">Fernando Torales Acosta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mikuni_V/0/1/0/all/0/1\">Vinicius Mikuni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nachman_B/0/1/0/all/0/1\">Benjamin Nachman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arratia_M/0/1/0/all/0/1\">Miguel Arratia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barish_K/0/1/0/all/0/1\">Kenneth Barish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karki_B/0/1/0/all/0/1\">Bishnu Karki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milton_R/0/1/0/all/0/1\">Ryan Milton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karande_P/0/1/0/all/0/1\">Piyush Karande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Angerami_A/0/1/0/all/0/1\">Aaron Angerami</a>",
          "description": "Score based generative models are a new class of generative models that have\nbeen shown to accurately generate high dimensional calorimeter datasets. Recent\nadvances in generative models have used images with 3D voxels to represent and\nmodel complex calorimeter showers. Point clouds, however, are likely a more\nnatural representation of calorimeter showers, particularly in calorimeters\nwith high granularity. Point clouds preserve all of the information of the\noriginal simulation, more naturally deal with sparse datasets, and can be\nimplemented with more compact models and data files. In this work, two\nstate-of-the-art score based models are trained on the same set of calorimeter\nsimulation and directly compared.",
          "link": "http://arxiv.org/abs/2307.04780",
          "publishedOn": "2023-07-12T01:02:44.801Z",
          "wordCount": 649,
          "title": "Comparison of Point Cloud and Image-based Models for Calorimeter Fast Simulation. (arXiv:2307.04780v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04778",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sarraf_S/0/1/0/all/0/1\">Saman Sarraf</a>",
          "description": "Business statistics play a crucial role in implementing a data-driven\nstrategic plan at the enterprise level to employ various analytics where the\noutcomes of such a plan enable an enterprise to enhance the decision-making\nprocess or to mitigate risks to the organization. In this work, a strategic\nplan informed by the statistical analysis is introduced for a financial company\ncalled LendingClub, where the plan is comprised of exploring the possibility of\nonboarding a big data platform along with advanced feature selection\ncapacities. The main objectives of such a plan are to increase the company's\nrevenue while reducing the risks of granting loans to borrowers who cannot\nreturn their loans. In this study, different hypotheses formulated to address\nthe company's concerns are studied, where the results reveal that the amount of\nloans profoundly impacts the number of borrowers charging off their loans.\nAlso, the proposed strategic plan includes onboarding advanced analytics such\nas machine learning technologies that allow the company to build better\ngeneralized data-driven predictive models.",
          "link": "http://arxiv.org/abs/2307.04778",
          "publishedOn": "2023-07-12T01:02:44.794Z",
          "wordCount": 703,
          "title": "Formulating A Strategic Plan Based On Statistical Analyses And Applications For Financial Companies Through A Real-World Use Case. (arXiv:2307.04778v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04777",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shukla_M/0/1/0/all/0/1\">Manan Shukla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seneviratne_O/0/1/0/all/0/1\">Oshani Seneviratne</a>",
          "description": "Mental health disorders remain a significant challenge in modern healthcare,\nwith diagnosis and treatment often relying on subjective patient descriptions\nand past medical history. To address this issue, we propose a personalized\nmental health tracking and mood prediction system that utilizes patient\nphysiological data collected through personal health devices. Our system\nleverages a decentralized learning mechanism that combines transfer and\nfederated machine learning concepts using smart contracts, allowing data to\nremain on users' devices and enabling effective tracking of mental health\nconditions for psychiatric treatment and management in a privacy-aware and\naccountable manner. We evaluate our model using a popular mental health dataset\nthat demonstrates promising results. By utilizing connected health systems and\nmachine learning models, our approach offers a novel solution to the challenge\nof providing psychiatrists with further insight into their patients' mental\nhealth outside of traditional office visits.",
          "link": "http://arxiv.org/abs/2307.04777",
          "publishedOn": "2023-07-12T01:02:44.776Z",
          "wordCount": 659,
          "title": "MentalHealthAI: Utilizing Personal Health Device Data to Optimize Psychiatry Treatment. (arXiv:2307.04777v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04772",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nye_L/0/1/0/all/0/1\">Logan Nye</a>",
          "description": "Digital twin technology has is anticipated to transform healthcare, enabling\npersonalized medicines and support, earlier diagnoses, simulated treatment\noutcomes, and optimized surgical plans. Digital twins are readily gaining\ntraction in industries like manufacturing, supply chain logistics, and civil\ninfrastructure. Not in patient care, however. The challenge of modeling complex\ndiseases with multimodal patient data and the computational complexities of\nanalyzing it have stifled digital twin adoption in the biomedical vertical.\nYet, these major obstacles can potentially be handled by approaching these\nmodels in a different way. This paper proposes a novel framework for addressing\nthe barriers to clinical twin modeling created by computational costs and\nmodeling complexities. We propose structuring patient health data as a\nknowledge graph and using closed-form continuous-time liquid neural networks,\nfor real-time analytics. By synthesizing multimodal patient data and leveraging\nthe flexibility and efficiency of closed form continuous time networks and\nknowledge graph ontologies, our approach enables real time insights,\npersonalized medicine, early diagnosis and intervention, and optimal surgical\nplanning. This novel approach provides a comprehensive and adaptable view of\npatient health along with real-time analytics, paving the way for digital twin\nsimulations and other anticipated benefits in healthcare.",
          "link": "http://arxiv.org/abs/2307.04772",
          "publishedOn": "2023-07-12T01:02:44.768Z",
          "wordCount": 709,
          "title": "Digital Twins for Patient Care via Knowledge Graphs and Closed-Form Continuous-Time Liquid Neural Networks. (arXiv:2307.04772v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        }
      ]
    },
    {
      "title": "stat.ML updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/stat.ML",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2308.01729",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Duval_F/0/1/0/all/0/1\">Francis Duval</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Boucher_J/0/1/0/all/0/1\">Jean-Philippe Boucher</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pigeon_M/0/1/0/all/0/1\">Mathieu Pigeon</a>",
          "description": "We present novel cross-sectional and longitudinal claim count models for\nvehicle insurance built upon the Combined Actuarial Neural Network (CANN)\nframework proposed by Mario W\\\"uthrich and Michael Merz. The CANN approach\ncombines a classical actuarial model, such as a generalized linear model, with\na neural network. This blending of models results in a two-component model\ncomprising a classical regression model and a neural network part. The CANN\nmodel leverages the strengths of both components, providing a solid foundation\nand interpretability from the classical model while harnessing the flexibility\nand capacity to capture intricate relationships and interactions offered by the\nneural network. In our proposed models, we use well-known log-linear claim\ncount regression models for the classical regression part and a multilayer\nperceptron (MLP) for the neural network part. The MLP part is used to process\ntelematics car driving data given as a vector characterizing the driving\nbehavior of each insured driver. In addition to the Poisson and negative\nbinomial distributions for cross-sectional data, we propose a procedure for\ntraining our CANN model with a multivariate negative binomial (MVNB)\nspecification. By doing so, we introduce a longitudinal model that accounts for\nthe dependence between contracts from the same insured. Our results reveal that\nthe CANN models exhibit superior performance compared to log-linear models that\nrely on manually engineered telematics features.",
          "link": "http://arxiv.org/abs/2308.01729",
          "publishedOn": "2023-08-05T00:48:26.674Z",
          "wordCount": null,
          "title": "Telematics Combined Actuarial Neural Networks for Cross-Sectional and Longitudinal Claim Count Data. (arXiv:2308.01729v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01839",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Ma_R/0/1/0/all/0/1\">Rong Ma</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sun_E/0/1/0/all/0/1\">Eric D. Sun</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Donoho_D/0/1/0/all/0/1\">David Donoho</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>",
          "description": "Single-cell data integration can provide a comprehensive molecular view of\ncells, and many algorithms have been developed to remove unwanted technical or\nbiological variations and integrate heterogeneous single-cell datasets. Despite\ntheir wide usage, existing methods suffer from several fundamental limitations.\nIn particular, we lack a rigorous statistical test for whether two\nhigh-dimensional single-cell datasets are alignable (and therefore should even\nbe aligned). Moreover, popular methods can substantially distort the data\nduring alignment, making the aligned data and downstream analysis difficult to\ninterpret. To overcome these limitations, we present a spectral manifold\nalignment and inference (SMAI) framework, which enables principled and\ninterpretable alignability testing and structure-preserving integration of\nsingle-cell data. SMAI provides a statistical test to robustly determine the\nalignability between datasets to avoid misleading inference, and is justified\nby high-dimensional statistical theory. On a diverse range of real and\nsimulated benchmark datasets, it outperforms commonly used alignment methods.\nMoreover, we show that SMAI improves various downstream analyses such as\nidentification of differentially expressed genes and imputation of single-cell\nspatial transcriptomics, providing further biological insights. SMAI's\ninterpretability also enables quantification and a deeper understanding of the\nsources of technical confounders in single-cell data.",
          "link": "http://arxiv.org/abs/2308.01839",
          "publishedOn": "2023-08-05T00:48:26.668Z",
          "wordCount": null,
          "title": "Is your data alignable? Principled and interpretable alignability testing and integration of single-cell data. (arXiv:2308.01839v1 [q-bio.QM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.08875",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sluijterman_L/0/1/0/all/0/1\">Laurens Sluijterman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cator_E/0/1/0/all/0/1\">Eric Cator</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Heskes_T/0/1/0/all/0/1\">Tom Heskes</a>",
          "description": "This paper focusses on the optimal implementation of a Mean Variance\nEstimation network (MVE network) (Nix and Weigend, 1994). This type of network\nis often used as a building block for uncertainty estimation methods in a\nregression setting, for instance Concrete dropout (Gal et al., 2017) and Deep\nEnsembles (Lakshminarayanan et al., 2017). Specifically, an MVE network assumes\nthat the data is produced from a normal distribution with a mean function and\nvariance function. The MVE network outputs a mean and variance estimate and\noptimizes the network parameters by minimizing the negative loglikelihood. In\nour paper, we present two significant insights. Firstly, the convergence\ndifficulties reported in recent work can be relatively easily prevented by\nfollowing the simple yet often overlooked recommendation from the original\nauthors that a warm-up period should be used. During this period, only the mean\nis optimized with a fixed variance. We demonstrate the effectiveness of this\nstep through experimentation, highlighting that it should be standard practice.\nAs a sidenote, we examine whether, after the warm-up, it is beneficial to fix\nthe mean while optimizing the variance or to optimize both simultaneously.\nHere, we do not observe a substantial difference. Secondly, we introduce a\nnovel improvement of the MVE network: separate regularization of the mean and\nthe variance estimate. We demonstrate, both on toy examples and on a number of\nbenchmark UCI regression data sets, that following the original recommendations\nand the novel separate regularization can lead to significant improvements.",
          "link": "http://arxiv.org/abs/2302.08875",
          "publishedOn": "2023-08-05T00:48:26.658Z",
          "wordCount": null,
          "title": "Optimal Training of Mean Variance Estimation Neural Networks. (arXiv:2302.08875v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.10051",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Lipshutz_D/0/1/0/all/0/1\">David Lipshutz</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bahroun_Y/0/1/0/all/0/1\">Yanis Bahroun</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Golkar_S/0/1/0/all/0/1\">Siavash Golkar</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sengupta_A/0/1/0/all/0/1\">Anirvan M. Sengupta</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chklovskii_D/0/1/0/all/0/1\">Dmitri B. Chklovskii</a>",
          "description": "An established normative approach for understanding the algorithmic basis of\nneural computation is to derive online algorithms from principled computational\nobjectives and evaluate their compatibility with anatomical and physiological\nobservations. Similarity matching objectives have served as successful starting\npoints for deriving online algorithms that map onto neural networks (NNs) with\npoint neurons and Hebbian/anti-Hebbian plasticity. These NN models account for\nmany anatomical and physiological observations; however, the objectives have\nlimited computational power and the derived NNs do not explain\nmulti-compartmental neuronal structures and non-Hebbian forms of plasticity\nthat are prevalent throughout the brain. In this article, we unify and\ngeneralize recent extensions of the similarity matching approach to address\nmore complex objectives, including a large class of unsupervised and\nself-supervised learning tasks that can be formulated as symmetric generalized\neigenvalue problems or nonnegative matrix factorization problems.\nInterestingly, the online algorithms derived from these objectives naturally\nmap onto NNs with multi-compartmental neurons and local, non-Hebbian learning\nrules. Therefore, this unified extension of the similarity matching approach\nprovides a normative framework that facilitates understanding\nmulti-compartmental neuronal structures and non-Hebbian plasticity found\nthroughout the brain.",
          "link": "http://arxiv.org/abs/2302.10051",
          "publishedOn": "2023-08-05T00:48:26.658Z",
          "wordCount": null,
          "title": "Normative framework for deriving neural networks with multi-compartmental neurons and non-Hebbian plasticity. (arXiv:2302.10051v2 [q-bio.NC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01481",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Roy_A/0/1/0/all/0/1\">Abhishek Roy</a>, <a href=\"http://arxiv.org/find/math/1/au:+Balasubramanian_K/0/1/0/all/0/1\">Krishnakumar Balasubramanian</a>",
          "description": "We study the online overlapping batch-means covariance estimator for\nStochastic Gradient Descent (SGD) under Markovian sampling. We show that the\nconvergence rates of the covariance estimator are\n$O\\big(\\sqrt{d}\\,n^{-1/8}(\\log n)^{1/4}\\big)$ and\n$O\\big(\\sqrt{d}\\,n^{-1/8}\\big)$ under state-dependent and state-independent\nMarkovian sampling, respectively, with $d$ representing dimensionality and $n$\ndenoting the number of observations or SGD iterations. Remarkably, these rates\nmatch the best-known convergence rate previously established for the\nindependent and identically distributed ($\\iid$) case by \\cite{zhu2021online},\nup to logarithmic factors. Our analysis overcomes significant challenges that\narise due to Markovian sampling, leading to the introduction of additional\nerror terms and complex dependencies between the blocks of the batch-means\ncovariance estimator. Moreover, we establish the convergence rate for the first\nfour moments of the $\\ell_2$ norm of the error of SGD dynamics under\nstate-dependent Markovian data, which holds potential interest as an\nindependent result. To validate our theoretical findings, we provide numerical\nillustrations to derive confidence intervals for SGD when training linear and\nlogistic regression models under Markovian sampling. Additionally, we apply our\napproach to tackle the intriguing problem of strategic classification with\nlogistic regression, where adversaries can adaptively modify features during\nthe training process to increase their chances of being classified in a\nspecific target class.",
          "link": "http://arxiv.org/abs/2308.01481",
          "publishedOn": "2023-08-05T00:48:26.656Z",
          "wordCount": null,
          "title": "Online covariance estimation for stochastic gradient descent under Markovian sampling. (arXiv:2308.01481v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01490",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Puning Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_L/0/1/0/all/0/1\">Lifeng Lai</a>",
          "description": "$Q$ learning is a popular model free reinforcement learning method. Most of\nexisting works focus on analyzing $Q$ learning for finite state and action\nspaces. If the state space is continuous, then the original $Q$ learning method\ncan not be directly used. A modification of the original $Q$ learning method\nwas proposed in (Shah and Xie, 2018), which estimates $Q$ values with nearest\nneighbors. Such modification makes $Q$ learning suitable for continuous state\nspace. (Shah and Xie, 2018) shows that the convergence rate of estimated $Q$\nfunction is $\\tilde{O}(T^{-1/(d+3)})$, which is slower than the minimax lower\nbound $\\tilde{\\Omega}(T^{-1/(d+2)})$, indicating that this method is not\nefficient. This paper proposes two new $Q$ learning methods to bridge the gap\nof convergence rates in (Shah and Xie, 2018), with one of them being offline,\nwhile the other is online. Despite that we still use nearest neighbor approach\nto estimate $Q$ function, the algorithms are crucially different from (Shah and\nXie, 2018). In particular, we replace the kernel nearest neighbor in\ndiscretized region with a direct nearest neighbor approach. Consequently, our\napproach significantly improves the convergence rate. Moreover, the time\ncomplexity is also significantly improved in high dimensional state spaces. Our\nanalysis shows that both offline and online methods are minimax rate optimal.",
          "link": "http://arxiv.org/abs/2308.01490",
          "publishedOn": "2023-08-05T00:48:26.655Z",
          "wordCount": null,
          "title": "Minimax Optimal $Q$ Learning with Nearest Neighbors. (arXiv:2308.01490v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2012.14563",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hiabu_M/0/1/0/all/0/1\">Munir Hiabu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mammen_E/0/1/0/all/0/1\">Enno Mammen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Meyer_J/0/1/0/all/0/1\">Joseph T. Meyer</a>",
          "description": "We introduce a novel interpretable tree based algorithm for prediction in a\nregression setting. Our motivation is to estimate the unknown regression\nfunction from a functional decomposition perspective in which the functional\ncomponents correspond to lower order interaction terms. The idea is to modify\nthe random forest algorithm by keeping certain leaves after they are split\ninstead of deleting them. This leads to non-binary trees which we refer to as\nplanted trees. An extension to a forest leads to our random planted forest\nalgorithm. Additionally, the maximum number of covariates which can interact\nwithin a leaf can be bounded. If we set this interaction bound to one, the\nresulting estimator is a sum of one-dimensional functions. In the other extreme\ncase, if we do not set a limit, the resulting estimator and corresponding model\nplace no restrictions on the form of the regression function. In a simulation\nstudy we find encouraging prediction and visualisation properties of our random\nplanted forest method. We also develop theory for an idealized version of\nrandom planted forests in cases where the interaction bound is low. We show\nthat if it is smaller than three, the idealized version achieves asymptotically\noptimal convergence rates up to a logarithmic factor. Code is available on\nGitHub https://github.com/PlantedML/randomPlantedForest.",
          "link": "http://arxiv.org/abs/2012.14563",
          "publishedOn": "2023-08-05T00:48:26.641Z",
          "wordCount": null,
          "title": "Random Planted Forest: a directly interpretable tree ensemble. (arXiv:2012.14563v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01538",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Zhong_W/0/1/0/all/0/1\">Weishun Zhong</a>",
          "description": "Disordered many-body systems exhibit a wide range of emergent phenomena\nacross different scales. These complex behaviors can be utilized for various\ninformation processing tasks such as error correction, learning, and\noptimization. Despite the empirical success of utilizing these systems for\nintelligent tasks, the underlying principles that govern their emergent\nintelligent behaviors remain largely unknown. In this thesis, we aim to\ncharacterize such emergent intelligence in disordered systems through\nstatistical physics. We chart a roadmap for our efforts in this thesis based on\ntwo axes: learning mechanisms (long-term memory vs. working memory) and\nlearning dynamics (artificial vs. natural). Throughout our journey, we uncover\nrelationships between learning mechanisms and physical dynamics that could\nserve as guiding principles for designing intelligent systems. We hope that our\ninvestigation into the emergent intelligence of seemingly disparate learning\nsystems can expand our current understanding of intelligence beyond neural\nsystems and uncover a wider range of computational substrates suitable for AI\napplications.",
          "link": "http://arxiv.org/abs/2308.01538",
          "publishedOn": "2023-08-05T00:48:26.631Z",
          "wordCount": null,
          "title": "Non-equilibrium physics: from spin glasses to machine and neural learning. (arXiv:2308.01538v1 [cond-mat.dis-nn])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2003.08904",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weber_M/0/1/0/all/0/1\">Maurice Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaojun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karlas_B/0/1/0/all/0/1\">Bojan Karla&#x161;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Ce Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>",
          "description": "Recent studies have shown that deep neural networks (DNNs) are vulnerable to\nadversarial attacks, including evasion and backdoor (poisoning) attacks. On the\ndefense side, there have been intensive efforts on improving both empirical and\nprovable robustness against evasion attacks; however, the provable robustness\nagainst backdoor attacks still remains largely unexplored. In this paper, we\nfocus on certifying the machine learning model robustness against general\nthreat models, especially backdoor attacks. We first provide a unified\nframework via randomized smoothing techniques and show how it can be\ninstantiated to certify the robustness against both evasion and backdoor\nattacks. We then propose the first robust training process, RAB, to smooth the\ntrained model and certify its robustness against backdoor attacks. We prove the\nrobustness bound for machine learning models trained with RAB and prove that\nour robustness bound is tight. In addition, we theoretically show that it is\npossible to train the robust smoothed models efficiently for simple models such\nas K-nearest neighbor classifiers, and we propose an exact smooth-training\nalgorithm that eliminates the need to sample from a noise distribution for such\nmodels. Empirically, we conduct comprehensive experiments for different machine\nlearning (ML) models such as DNNs, support vector machines, and K-NN models on\nMNIST, CIFAR-10, and ImageNette datasets and provide the first benchmark for\ncertified robustness against backdoor attacks. In addition, we evaluate K-NN\nmodels on a spambase tabular dataset to demonstrate the advantages of the\nproposed exact algorithm. Both the theoretic analysis and the comprehensive\nevaluation on diverse ML models and datasets shed light on further robust\nlearning strategies against general training time attacks.",
          "link": "http://arxiv.org/abs/2003.08904",
          "publishedOn": "2023-08-05T00:48:26.628Z",
          "wordCount": null,
          "title": "RAB: Provable Robustness Against Backdoor Attacks. (arXiv:2003.08904v8 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.03395",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sluijterman_L/0/1/0/all/0/1\">Laurens Sluijterman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cator_E/0/1/0/all/0/1\">Eric Cator</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Heskes_T/0/1/0/all/0/1\">Tom Heskes</a>",
          "description": "As neural networks become more popular, the need for accompanying uncertainty\nestimates increases. There are currently two main approaches to test the\nquality of these estimates. Most methods output a density. They can be compared\nby evaluating their loglikelihood on a test set. Other methods output a\nprediction interval directly. These methods are often tested by examining the\nfraction of test points that fall inside the corresponding prediction\nintervals. Intuitively both approaches seem logical. However, we demonstrate\nthrough both theoretical arguments and simulations that both ways of evaluating\nthe quality of uncertainty estimates have serious flaws. Firstly, both\napproaches cannot disentangle the separate components that jointly create the\npredictive uncertainty, making it difficult to evaluate the quality of the\nestimates of these components. Secondly, a better loglikelihood does not\nguarantee better prediction intervals, which is what the methods are often used\nfor in practice. Moreover, the current approach to test prediction intervals\ndirectly has additional flaws. We show why it is fundamentally flawed to test a\nprediction or confidence interval on a single test set. At best, marginal\ncoverage is measured, implicitly averaging out overconfident and underconfident\npredictions. A much more desirable property is pointwise coverage, requiring\nthe correct coverage for each prediction. We demonstrate through practical\nexamples that these effects can result in favoring a method, based on the\npredictive uncertainty, that has undesirable behaviour of the confidence or\nprediction intervals. Finally, we propose a simulation-based testing approach\nthat addresses these problems while still allowing easy comparison between\ndifferent methods.",
          "link": "http://arxiv.org/abs/2106.03395",
          "publishedOn": "2023-08-05T00:48:26.621Z",
          "wordCount": null,
          "title": "How to Evaluate Uncertainty Estimates in Machine Learning for Regression?. (arXiv:2106.03395v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01605",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Doutreligne_M/0/1/0/all/0/1\">Matthieu Doutreligne</a> (SODA), <a href=\"http://arxiv.org/find/stat/1/au:+Struja_T/0/1/0/all/0/1\">Tristan Struja</a> (MIT, SODA), <a href=\"http://arxiv.org/find/stat/1/au:+Abecassis_J/0/1/0/all/0/1\">Judith Abecassis</a> (SODA), <a href=\"http://arxiv.org/find/stat/1/au:+Morgand_C/0/1/0/all/0/1\">Claire Morgand</a> (ARS IDF), <a href=\"http://arxiv.org/find/stat/1/au:+Celi_L/0/1/0/all/0/1\">Leo Anthony Celi</a> (MIT), <a href=\"http://arxiv.org/find/stat/1/au:+Varoquaux_G/0/1/0/all/0/1\">Ga&#xeb;l Varoquaux</a> (SODA)",
          "description": "Accurate predictions, as with machine learning, may not suffice to provide\noptimal healthcare for every patient. Indeed, prediction can be driven by\nshortcuts in the data, such as racial biases. Causal thinking is needed for\ndata-driven decisions. Here, we give an introduction to the key elements,\nfocusing on routinely-collected data, electronic health records (EHRs) and\nclaims data. Using such data to assess the value of an intervention requires\ncare: temporal dependencies and existing practices easily confound the causal\neffect. We present a step-by-step framework to help build valid decision making\nfrom real-life patient records by emulating a randomized trial before\nindividualizing decisions, eg with machine learning. Our framework highlights\nthe most important pitfalls and considerations in analysing EHRs or claims data\nto draw causal conclusions. We illustrate the various choices in studying the\neffect of albumin on sepsis mortality in the Medical Information Mart for\nIntensive Care database (MIMIC-IV). We study the impact of various choices at\nevery step, from feature extraction to causal-estimator selection. In a\ntutorial spirit, the code and the data are openly available.",
          "link": "http://arxiv.org/abs/2308.01605",
          "publishedOn": "2023-08-05T00:48:26.442Z",
          "wordCount": null,
          "title": "Causal thinking for decision making on Electronic Health Records: why and how. (arXiv:2308.01605v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01358",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Philippenko_C/0/1/0/all/0/1\">Constantin Philippenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dieuleveut_A/0/1/0/all/0/1\">Aymeric Dieuleveut</a>",
          "description": "In this paper, we investigate the impact of compression on stochastic\ngradient algorithms for machine learning, a technique widely used in\ndistributed and federated learning. We underline differences in terms of\nconvergence rates between several unbiased compression operators, that all\nsatisfy the same condition on their variance, thus going beyond the classical\nworst-case analysis. To do so, we focus on the case of least-squares regression\n(LSR) and analyze a general stochastic approximation algorithm for minimizing\nquadratic functions relying on a random field. We consider weak assumptions on\nthe random field, tailored to the analysis (specifically, expected H\\\"older\nregularity), and on the noise covariance, enabling the analysis of various\nrandomizing mechanisms, including compression. We then extend our results to\nthe case of federated learning.\n\nMore formally, we highlight the impact on the convergence of the covariance\n$\\mathfrak{C}_{\\mathrm{ania}}$ of the additive noise induced by the algorithm.\nWe demonstrate despite the non-regularity of the stochastic field, that the\nlimit variance term scales with $\\mathrm{Tr}(\\mathfrak{C}_{\\mathrm{ania}}\nH^{-1})/K$ (where $H$ is the Hessian of the optimization problem and $K$ the\nnumber of iterations) generalizing the rate for the vanilla LSR case where it\nis $\\sigma^2 \\mathrm{Tr}(H H^{-1}) / K = \\sigma^2 d / K$ (Bach and Moulines,\n2013). Then, we analyze the dependency of $\\mathfrak{C}_{\\mathrm{ania}}$ on the\ncompression strategy and ultimately its impact on convergence, first in the\ncentralized case, then in two heterogeneous FL frameworks.",
          "link": "http://arxiv.org/abs/2308.01358",
          "publishedOn": "2023-08-05T00:48:26.424Z",
          "wordCount": null,
          "title": "Compressed and distributed least-squares regression: convergence rates with applications to Federated Learning. (arXiv:2308.01358v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.02096",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Cindy Y. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cen_S/0/1/0/all/0/1\">Sarah H. Cen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_D/0/1/0/all/0/1\">Devavrat Shah</a>",
          "description": "In recent years, multiple notions of algorithmic fairness have arisen. One\nsuch notion is individual fairness (IF), which requires that individuals who\nare similar receive similar treatment. In parallel, matrix estimation (ME) has\nemerged as a natural paradigm for handling noisy data with missing values. In\nthis work, we connect the two concepts. We show that pre-processing data using\nME can improve an algorithm's IF without sacrificing performance. Specifically,\nwe show that using a popular ME method known as singular value thresholding\n(SVT) to pre-process the data provides a strong IF guarantee under appropriate\nconditions. We then show that, under analogous conditions, SVT pre-processing\nalso yields estimates that are consistent and approximately minimax optimal. As\nsuch, the ME pre-processing step does not, under the stated conditions,\nincrease the prediction error of the base algorithm, i.e., does not impose a\nfairness-performance trade-off. We verify these results on synthetic and real\ndata.",
          "link": "http://arxiv.org/abs/2302.02096",
          "publishedOn": "2023-08-05T00:48:26.394Z",
          "wordCount": null,
          "title": "Matrix Estimation for Individual Fairness. (arXiv:2302.02096v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2005.09048",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Rolle_A/0/1/0/all/0/1\">Alexander Rolle</a>, <a href=\"http://arxiv.org/find/math/1/au:+Scoccola_L/0/1/0/all/0/1\">Luis Scoccola</a>",
          "description": "We consider the degree-Rips construction from topological data analysis,\nwhich provides a density-sensitive, multiparameter hierarchical clustering\nalgorithm. We analyze its stability to perturbations of the input data using\nthe correspondence-interleaving distance, a metric for hierarchical clusterings\nthat we introduce. Taking certain one-parameter slices of degree-Rips recovers\nwell-known methods for density-based clustering, but we show that these methods\nare unstable. However, we prove that degree-Rips, as a multiparameter object,\nis stable, and we propose an alternative approach for taking slices of\ndegree-Rips, which yields a one-parameter hierarchical clustering algorithm\nwith better stability properties. We prove that this algorithm is consistent,\nusing the correspondence-interleaving distance. We provide an algorithm for\nextracting a single clustering from one-parameter hierarchical clusterings,\nwhich is stable with respect to the correspondence-interleaving distance. And,\nwe integrate these methods into a pipeline for density-based clustering, which\nwe call Persistable. Adapting tools from multiparameter persistent homology, we\npropose visualization tools that guide the selection of all parameters of the\npipeline. We demonstrate Persistable on benchmark datasets, showing that it\nidentifies multi-scale cluster structure in data.",
          "link": "http://arxiv.org/abs/2005.09048",
          "publishedOn": "2023-08-05T00:48:26.364Z",
          "wordCount": null,
          "title": "Stable and consistent density-based clustering via multiparameter persistence. (arXiv:2005.09048v3 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01677",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Garber_D/0/1/0/all/0/1\">Dan Garber</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kaplan_A/0/1/0/all/0/1\">Atara Kaplan</a>",
          "description": "We consider convex relaxations for recovering low-rank tensors based on\nconstrained minimization over a ball induced by the tensor nuclear norm,\nrecently introduced in \\cite{tensor_tSVD}. We build on a recent line of results\nthat considered convex relaxations for the recovery of low-rank matrices and\nestablished that under a strict complementarity condition (SC), both the\nconvergence rate and per-iteration runtime of standard gradient methods may\nimprove dramatically. We develop the appropriate strict complementarity\ncondition for the tensor nuclear norm ball and obtain the following main\nresults under this condition: 1. When the objective to minimize is of the form\n$f(\\mX)=g(\\mA\\mX)+\\langle{\\mC,\\mX}\\rangle$ , where $g$ is strongly convex and\n$\\mA$ is a linear map (e.g., least squares), a quadratic growth bound holds,\nwhich implies linear convergence rates for standard projected gradient methods,\ndespite the fact that $f$ need not be strongly convex. 2. For a smooth\nobjective function, when initialized in certain proximity of an optimal\nsolution which satisfies SC, standard projected gradient methods only require\nSVD computations (for projecting onto the tensor nuclear norm ball) of rank\nthat matches the tubal rank of the optimal solution. In particular, when the\ntubal rank is constant, this implies nearly linear (in the size of the tensor)\nruntime per iteration, as opposed to super linear without further assumptions.\n3. For a nonsmooth objective function which admits a popular smooth\nsaddle-point formulation, we derive similar results to the latter for the well\nknown extragradient method. An additional contribution which may be of\nindependent interest, is the rigorous extension of many basic results regarding\ntensors of arbitrary order, which were previously obtained only for third-order\ntensors.",
          "link": "http://arxiv.org/abs/2308.01677",
          "publishedOn": "2023-08-05T00:48:26.322Z",
          "wordCount": null,
          "title": "Efficiency of First-Order Methods for Low-Rank Tensor Recovery with the Tensor Nuclear Norm Under Strict Complementarity. (arXiv:2308.01677v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.12344",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xi He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahman_W/0/1/0/all/0/1\">Waheed Ul Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Little_M/0/1/0/all/0/1\">Max A. Little</a>",
          "description": "Algorithms for solving the linear classification problem have a long history,\ndating back at least to 1936 with linear discriminant analysis. For linearly\nseparable data, many algorithms can obtain the exact solution to the\ncorresponding 0-1 loss classification problem efficiently, but for data which\nis not linearly separable, it has been shown that this problem, in full\ngenerality, is NP-hard. Alternative approaches all involve approximations of\nsome kind, including the use of surrogates for the 0-1 loss (for example, the\nhinge or logistic loss) or approximate combinatorial search, none of which can\nbe guaranteed to solve the problem exactly. Finding efficient algorithms to\nobtain an exact i.e. globally optimal solution for the 0-1 loss linear\nclassification problem with fixed dimension, remains an open problem. In\nresearch we report here, we detail the rigorous construction of a new\nalgorithm, incremental cell enumeration (ICE), that can solve the 0-1 loss\nclassification problem exactly in polynomial time. We prove correctness using\nconcepts from the theory of hyperplane arrangements and oriented matroids. We\ndemonstrate the effectiveness of this algorithm on synthetic and real-world\ndatasets, showing optimal accuracy both in and out-of-sample, in practical\ncomputational time. We also empirically demonstrate how the use of approximate\nupper bound leads to polynomial time run-time improvements to the algorithm\nwhilst retaining exactness. To our knowledge, this is the first,\nrigorously-proven polynomial time, practical algorithm for this long-standing\nproblem.",
          "link": "http://arxiv.org/abs/2306.12344",
          "publishedOn": "2023-08-05T00:48:26.321Z",
          "wordCount": null,
          "title": "An efficient, provably exact, practical algorithm for the 0-1 loss linear classification problem. (arXiv:2306.12344v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.12465",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Diaz_M/0/1/0/all/0/1\">Mateo D&#xed;az</a>, <a href=\"http://arxiv.org/find/math/1/au:+Epperly_E/0/1/0/all/0/1\">Ethan N. Epperly</a>, <a href=\"http://arxiv.org/find/math/1/au:+Frangella_Z/0/1/0/all/0/1\">Zachary Frangella</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tropp_J/0/1/0/all/0/1\">Joel A. Tropp</a>, <a href=\"http://arxiv.org/find/math/1/au:+Webber_R/0/1/0/all/0/1\">Robert J. Webber</a>",
          "description": "This paper introduces two randomized preconditioning techniques for robustly\nsolving kernel ridge regression (KRR) problems with a medium to large number of\ndata points ($10^4 \\leq N \\leq 10^7$). The first method, RPCholesky\npreconditioning, is capable of accurately solving the full-data KRR problem in\n$O(N^2)$ arithmetic operations, assuming sufficiently rapid polynomial decay of\nthe kernel matrix eigenvalues. The second method, KRILL preconditioning, offers\nan accurate solution to a restricted version of the KRR problem involving $k\n\\ll N$ selected data centers at a cost of $O((N + k^2) k \\log k)$ operations.\nThe proposed methods solve a broad range of KRR problems and overcome the\nfailure modes of previous KRR preconditioners, making them ideal for practical\napplications.",
          "link": "http://arxiv.org/abs/2304.12465",
          "publishedOn": "2023-08-05T00:48:25.211Z",
          "wordCount": 655,
          "title": "Robust, randomized preconditioning for kernel ridge regression. (arXiv:2304.12465v3 [math.NA] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01835",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tamas_A/0/1/0/all/0/1\">Ambrus Tam&#xe1;s</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Csaji_B/0/1/0/all/0/1\">Bal&#xe1;zs Csan&#xe1;d Cs&#xe1;ji</a>",
          "description": "One of the key objects of binary classification is the regression function,\ni.e., the conditional expectation of the class labels given the inputs. With\nthe regression function not only a Bayes optimal classifier can be defined, but\nit also encodes the corresponding misclassification probabilities. The paper\npresents a resampling framework to construct exact, distribution-free and\nnon-asymptotically guaranteed confidence regions for the true regression\nfunction for any user-chosen confidence level. Then, specific algorithms are\nsuggested to demonstrate the framework. It is proved that the constructed\nconfidence regions are strongly consistent, that is, any false model is\nexcluded in the long run with probability one. The exclusion is quantified with\nprobably approximately correct type bounds, as well. Finally, the algorithms\nare validated via numerical experiments, and the methods are compared to\napproximate asymptotic confidence ellipsoids.",
          "link": "http://arxiv.org/abs/2308.01835",
          "publishedOn": "2023-08-05T00:48:25.203Z",
          "wordCount": 633,
          "title": "Distribution-Free Inference for the Regression Function of Binary Classification. (arXiv:2308.01835v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01853",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chao_P/0/1/0/all/0/1\">Patrick Chao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dobriban_E/0/1/0/all/0/1\">Edgar Dobriban</a>",
          "description": "Distribution shifts are a serious concern in modern statistical learning as\nthey can systematically change the properties of the data away from the truth.\nWe focus on Wasserstein distribution shifts, where every data point may undergo\na slight perturbation, as opposed to the Huber contamination model where a\nfraction of observations are outliers. We formulate and study shifts beyond\nindependent perturbations, exploring Joint Distribution Shifts, where the\nper-observation perturbations can be coordinated. We analyze several important\nstatistical problems, including location estimation, linear regression, and\nnon-parametric density estimation. Under a squared loss for mean estimation and\nprediction error in linear regression, we find the exact minimax risk, a least\nfavorable perturbation, and show that the sample mean and least squares\nestimators are respectively optimal. This holds for both independent and joint\nshifts, but the least favorable perturbations and minimax risks differ. For\nother problems, we provide nearly optimal estimators and precise finite-sample\nbounds. We also introduce several tools for bounding the minimax risk under\ndistribution shift, such as a smoothing technique for location families, and\ngeneralizations of classical tools including least favorable sequences of\npriors, the modulus of continuity, Le Cam's, Fano's, and Assouad's methods.",
          "link": "http://arxiv.org/abs/2308.01853",
          "publishedOn": "2023-08-05T00:48:25.171Z",
          "wordCount": 706,
          "title": "Statistical Estimation Under Distribution Shift: Wasserstein Perturbations and Minimax Theory. (arXiv:2308.01853v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2012.05465",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Qiu_H/0/1/0/all/0/1\">Hongxiang Qiu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Luedtke_A/0/1/0/all/0/1\">Alex Luedtke</a>",
          "description": "Bayes estimators are well known to provide a means to incorporate prior\nknowledge that can be expressed in terms of a single prior distribution.\nHowever, when this knowledge is too vague to express with a single prior, an\nalternative approach is needed. Gamma-minimax estimators provide such an\napproach. These estimators minimize the worst-case Bayes risk over a set\n$\\Gamma$ of prior distributions that are compatible with the available\nknowledge. Traditionally, Gamma-minimaxity is defined for parametric models. In\nthis work, we define Gamma-minimax estimators for general models and propose\nadversarial meta-learning algorithms to compute them when the set of prior\ndistributions is constrained by generalized moments. Accompanying convergence\nguarantees are also provided. We also introduce a neural network class that\nprovides a rich, but finite-dimensional, class of estimators from which a\nGamma-minimax estimator can be selected. We illustrate our method in two\nsettings, namely entropy estimation and a prediction problem that arises in\nbiodiversity studies.",
          "link": "http://arxiv.org/abs/2012.05465",
          "publishedOn": "2023-08-05T00:48:25.144Z",
          "wordCount": 705,
          "title": "Adversarial Meta-Learning of Gamma-Minimax Estimators That Leverage Prior Knowledge. (arXiv:2012.05465v5 [stat.ME] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01475",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Allen_G/0/1/0/all/0/1\">Genevera I. Allen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gan_L/0/1/0/all/0/1\">Luqin Gan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zheng_L/0/1/0/all/0/1\">Lili Zheng</a>",
          "description": "New technologies have led to vast troves of large and complex datasets across\nmany scientific domains and industries. People routinely use machine learning\ntechniques to not only process, visualize, and make predictions from this big\ndata, but also to make data-driven discoveries. These discoveries are often\nmade using Interpretable Machine Learning, or machine learning models and\ntechniques that yield human understandable insights. In this paper, we discuss\nand review the field of interpretable machine learning, focusing especially on\nthe techniques as they are often employed to generate new knowledge or make\ndiscoveries from large data sets. We outline the types of discoveries that can\nbe made using Interpretable Machine Learning in both supervised and\nunsupervised settings. Additionally, we focus on the grand challenge of how to\nvalidate these discoveries in a data-driven manner, which promotes trust in\nmachine learning systems and reproducibility in science. We discuss validation\nfrom both a practical perspective, reviewing approaches based on data-splitting\nand stability, as well as from a theoretical perspective, reviewing statistical\nresults on model selection consistency and uncertainty quantification via\nstatistical inference. Finally, we conclude by highlighting open challenges in\nusing interpretable machine learning techniques to make discoveries, including\ngaps between theory and practice for validating data-driven-discoveries.",
          "link": "http://arxiv.org/abs/2308.01475",
          "publishedOn": "2023-08-05T00:48:25.117Z",
          "wordCount": 709,
          "title": "Interpretable Machine Learning for Discovery: Statistical Challenges \\& Opportunities. (arXiv:2308.01475v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2202.10903",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sluijterman_L/0/1/0/all/0/1\">Laurens Sluijterman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cator_E/0/1/0/all/0/1\">Eric Cator</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Heskes_T/0/1/0/all/0/1\">Tom Heskes</a>",
          "description": "With the rise of the popularity and usage of neural networks, trustworthy\nuncertainty estimation is becoming increasingly essential. One of the most\nprominent uncertainty estimation methods is Deep Ensembles (Lakshminarayanan et\nal., 2017) . A classical parametric model has uncertainty in the parameters due\nto the fact that the data on which the model is build is a random sample. A\nmodern neural network has an additional uncertainty component since the\noptimization of the network is random. Lakshminarayanan et al. (2017) noted\nthat Deep Ensembles do not incorporate the classical uncertainty induced by the\neffect of finite data. In this paper, we present a computationally cheap\nextension of Deep Ensembles for the regression setting, called Bootstrapped\nDeep Ensembles, that explicitly takes this classical effect of finite data into\naccount using a modified version of the parametric bootstrap. We demonstrate\nthrough an experimental study that our method significantly improves upon\nstandard Deep Ensembles",
          "link": "http://arxiv.org/abs/2202.10903",
          "publishedOn": "2023-08-05T00:48:25.108Z",
          "wordCount": 674,
          "title": "Confident Neural Network Regression with Bootstrapped Deep Ensembles. (arXiv:2202.10903v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sakhi_O/0/1/0/all/0/1\">Otmane Sakhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rohde_D/0/1/0/all/0/1\">David Rohde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chopin_N/0/1/0/all/0/1\">Nicolas Chopin</a>",
          "description": "An increasingly important building block of large scale machine learning\nsystems is based on returning slates; an ordered lists of items given a query.\nApplications of this technology include: search, information retrieval and\nrecommender systems. When the action space is large, decision systems are\nrestricted to a particular structure to complete online queries quickly. This\npaper addresses the optimization of these large scale decision systems given an\narbitrary reward function. We cast this learning problem in a policy\noptimization framework and propose a new class of policies, born from a novel\nrelaxation of decision functions. This results in a simple, yet efficient\nlearning algorithm that scales to massive action spaces. We compare our method\nto the commonly adopted Plackett-Luce policy class and demonstrate the\neffectiveness of our approach on problems with action space sizes in the order\nof millions.",
          "link": "http://arxiv.org/abs/2308.01566",
          "publishedOn": "2023-08-05T00:48:24.864Z",
          "wordCount": 645,
          "title": "Fast Slate Policy Optimization: Going Beyond Plackett-Luce. (arXiv:2308.01566v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.05946",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sengupta_A/0/1/0/all/0/1\">Agnimitra Sengupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mondal_S/0/1/0/all/0/1\">Sudeepta Mondal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Adway Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guler_S/0/1/0/all/0/1\">S. Ilgin Guler</a>",
          "description": "Deep-learning models for traffic data prediction can have superior\nperformance in modeling complex functions using a multi-layer architecture.\nHowever, a major drawback of these approaches is that most of these approaches\ndo not offer forecasts with uncertainty estimates, which are essential for\ntraffic operations and control. Without uncertainty estimates, it is difficult\nto place any level of trust to the model predictions, and operational\nstrategies relying on overconfident predictions can lead to worsening traffic\nconditions. In this study, we propose a Bayesian recurrent neural network\nframework for uncertainty quantification in traffic prediction with higher\ngeneralizability by introducing spectral normalization to its hidden layers. In\nour paper, we have shown that normalization alters the training process of deep\nneural networks by controlling the model's complexity and reducing the risk of\noverfitting to the training data. This, in turn, helps improve the\ngeneralization performance of the model on out-of-distribution datasets.\nResults demonstrate that spectral normalization improves uncertainty estimates\nand significantly outperforms both the layer normalization and model without\nnormalization in single-step prediction horizons. This improved performance can\nbe attributed to the ability of spectral normalization to better localize the\nfeature space of the data under perturbations. Our findings are especially\nrelevant to traffic management applications, where predicting traffic\nconditions across multiple locations is the goal, but the availability of\ntraining data from multiple locations is limited. Spectral normalization,\ntherefore, provides a more generalizable approach that can effectively capture\nthe underlying patterns in traffic data without requiring location-specific\nmodels.",
          "link": "http://arxiv.org/abs/2307.05946",
          "publishedOn": "2023-07-29T00:48:57.359Z",
          "wordCount": null,
          "title": "A Bayesian approach to quantifying uncertainties and improving generalizability in traffic prediction models. (arXiv:2307.05946v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.05965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Erp_B/0/1/0/all/0/1\">Bart van Erp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nuijten_W/0/1/0/all/0/1\">Wouter W. L. Nuijten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laar_T/0/1/0/all/0/1\">Thijs van de Laar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vries_B/0/1/0/all/0/1\">Bert de Vries</a>",
          "description": "Bayesian state and parameter estimation have been automated effectively in a\nvariety of probabilistic programming languages. The process of model comparison\non the other hand, which still requires error-prone and time-consuming manual\nderivations, is often overlooked despite its importance. This paper efficiently\nautomates Bayesian model averaging, selection, and combination by message\npassing on a Forney-style factor graph with a custom mixture node. Parameter\nand state inference, and model comparison can then be executed simultaneously\nusing message passing with scale factors. This approach shortens the model\ndesign cycle and allows for the straightforward extension to hierarchical and\ntemporal model priors to accommodate for modeling complicated time-varying\nprocesses.",
          "link": "http://arxiv.org/abs/2306.05965",
          "publishedOn": "2023-07-29T00:48:57.333Z",
          "wordCount": null,
          "title": "Automating Model Comparison in Factor Graphs. (arXiv:2306.05965v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.10291",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Derezinski_M/0/1/0/all/0/1\">Micha&#x142; Derezi&#x144;ski</a>",
          "description": "Algorithmic Gaussianization is a phenomenon that can arise when using\nrandomized sketching or sampling methods to produce smaller representations of\nlarge datasets: For certain tasks, these sketched representations have been\nobserved to exhibit many robust performance characteristics that are known to\noccur when a data sample comes from a sub-gaussian random design, which is a\npowerful statistical model of data distributions. However, this phenomenon has\nonly been studied for specific tasks and metrics, or by relying on\ncomputationally expensive methods. We address this by providing an algorithmic\nframework for gaussianizing data distributions via averaging, proving that it\nis possible to efficiently construct data sketches that are nearly\nindistinguishable (in terms of total variation distance) from sub-gaussian\nrandom designs. In particular, relying on a recently introduced sketching\ntechnique called Leverage Score Sparsified (LESS) embeddings, we show that one\ncan construct an $n\\times d$ sketch of an $N\\times d$ matrix $A$, where $n\\ll\nN$, that is nearly indistinguishable from a sub-gaussian design, in time\n$O(\\text{nnz}(A)\\log N + nd^2)$, where $\\text{nnz}(A)$ is the number of\nnon-zero entries in $A$. As a consequence, strong statistical guarantees and\nprecise asymptotics available for the estimators produced from sub-gaussian\ndesigns (e.g., for least squares and Lasso regression, covariance estimation,\nlow-rank approximation, etc.) can be straightforwardly adapted to our sketching\nframework. We illustrate this with a new approximation guarantee for sketched\nleast squares, among other examples.",
          "link": "http://arxiv.org/abs/2206.10291",
          "publishedOn": "2023-07-29T00:48:55.771Z",
          "wordCount": 761,
          "title": "Algorithmic Gaussianization through Sketching: Converting Data into Sub-gaussian Random Designs. (arXiv:2206.10291v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2208.12942",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sainsbury_Dale_M/0/1/0/all/0/1\">Matthew Sainsbury-Dale</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zammit_Mangion_A/0/1/0/all/0/1\">Andrew Zammit-Mangion</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huser_R/0/1/0/all/0/1\">Rapha&#xeb;l Huser</a>",
          "description": "Neural point estimators are neural networks that map data to parameter point\nestimates. They are fast, likelihood free and, due to their amortised nature,\namenable to fast bootstrap-based uncertainty quantification. In this paper, we\naim to increase the awareness of statisticians to this relatively new\ninferential tool, and to facilitate its adoption by providing user-friendly\nopen-source software. We also give attention to the ubiquitous problem of\nmaking inference from replicated data, which we address in the neural setting\nusing permutation-invariant neural networks. Through extensive simulation\nstudies we show that these neural point estimators can quickly and optimally\n(in a Bayes sense) estimate parameters in weakly-identified and\nhighly-parameterised models with relative ease. We demonstrate their\napplicability through an analysis of extreme sea-surface temperature in the Red\nSea where, after training, we obtain parameter estimates and bootstrap-based\nconfidence intervals from hundreds of spatial fields in a fraction of a second.",
          "link": "http://arxiv.org/abs/2208.12942",
          "publishedOn": "2023-07-29T00:48:55.765Z",
          "wordCount": 676,
          "title": "Likelihood-Free Parameter Estimation with Neural Bayes Estimators. (arXiv:2208.12942v4 [stat.ME] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2005.00695",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Sen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyang R. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valiant_G/0/1/0/all/0/1\">Gregory Valiant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Re_C/0/1/0/all/0/1\">Christopher R&#xe9;</a>",
          "description": "Data augmentation is a powerful technique to improve performance in\napplications such as image and text classification tasks. Yet, there is little\nrigorous understanding of why and how various augmentations work. In this work,\nwe consider a family of linear transformations and study their effects on the\nridge estimator in an over-parametrized linear regression setting. First, we\nshow that transformations that preserve the labels of the data can improve\nestimation by enlarging the span of the training data. Second, we show that\ntransformations that mix data can improve estimation by playing a\nregularization effect. Finally, we validate our theoretical insights on MNIST.\nBased on the insights, we propose an augmentation scheme that searches over the\nspace of transformations by how uncertain the model is about the transformed\ndata. We validate our proposed scheme on image and text datasets. For example,\nour method outperforms random sampling methods by 1.24% on CIFAR-100 using\nWide-ResNet-28-10. Furthermore, we achieve comparable accuracy to the SoTA\nAdversarial AutoAugment on CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets.",
          "link": "http://arxiv.org/abs/2005.00695",
          "publishedOn": "2023-07-29T00:48:55.758Z",
          "wordCount": 743,
          "title": "On the Generalization Effects of Linear Transformations in Data Augmentation. (arXiv:2005.00695v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14839",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+English_E/0/1/0/all/0/1\">Eshant English</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kirchler_M/0/1/0/all/0/1\">Matthias Kirchler</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lippert_C/0/1/0/all/0/1\">Christoph Lippert</a>",
          "description": "Normalising Flows are generative models characterised by their invertible\narchitecture. However, the requirement of invertibility imposes constraints on\ntheir expressiveness, necessitating a large number of parameters and innovative\narchitectural designs to achieve satisfactory outcomes. Whilst flow-based\nmodels predominantly rely on neural-network-based transformations for\nexpressive designs, alternative transformation methods have received limited\nattention. In this work, we present Ferumal flow, a novel kernelised\nnormalising flow paradigm that integrates kernels into the framework. Our\nresults demonstrate that a kernelised flow can yield competitive or superior\nresults compared to neural network-based flows whilst maintaining parameter\nefficiency. Kernelised flows excel especially in the low-data regime, enabling\nflexible non-parametric density estimation in applications with sparse data\navailability.",
          "link": "http://arxiv.org/abs/2307.14839",
          "publishedOn": "2023-07-29T00:48:55.734Z",
          "wordCount": 591,
          "title": "Kernelised Normalising Flows. (arXiv:2307.14839v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14953",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Montesuma_E/0/1/0/all/0/1\">Eduardo Fernandes Montesuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mboula_F/0/1/0/all/0/1\">Fred Ngol&#xe8; Mboula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Souloumiac_A/0/1/0/all/0/1\">Antoine Souloumiac</a>",
          "description": "This paper seeks to solve Multi-Source Domain Adaptation (MSDA), which aims\nto mitigate data distribution shifts when transferring knowledge from multiple\nlabeled source domains to an unlabeled target domain. We propose a novel MSDA\nframework based on dictionary learning and optimal transport. We interpret each\ndomain in MSDA as an empirical distribution. As such, we express each domain as\na Wasserstein barycenter of dictionary atoms, which are empirical\ndistributions. We propose a novel algorithm, DaDiL, for learning via\nmini-batches: (i) atom distributions; (ii) a matrix of barycentric coordinates.\nBased on our dictionary, we propose two novel methods for MSDA: DaDil-R, based\non the reconstruction of labeled samples in the target domain, and DaDiL-E,\nbased on the ensembling of classifiers learned on atom distributions. We\nevaluate our methods in 3 benchmarks: Caltech-Office, Office 31, and CRWU,\nwhere we improved previous state-of-the-art by 3.15%, 2.29%, and 7.71% in\nclassification performance. Finally, we show that interpolations in the\nWasserstein hull of learned atoms provide data that can generalize to the\ntarget domain.",
          "link": "http://arxiv.org/abs/2307.14953",
          "publishedOn": "2023-07-29T00:48:55.728Z",
          "wordCount": 710,
          "title": "Multi-Source Domain Adaptation through Dataset Dictionary Learning in Wasserstein Space. (arXiv:2307.14953v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14642",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kim_K/0/1/0/all/0/1\">Kyurae Kim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ma_Y/0/1/0/all/0/1\">Yian Ma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gardner_J/0/1/0/all/0/1\">Jacob R. Gardner</a>",
          "description": "We prove that black-box variational inference (BBVI) with control variates,\nparticularly the sticking-the-landing (STL) estimator, converges at a geometric\n(traditionally called \"linear\") rate under perfect variational family\nspecification. In particular, we prove a quadratic bound on the gradient\nvariance of the STL estimator, one which encompasses misspecified variational\nfamilies. Combined with previous works on the quadratic variance condition,\nthis directly implies convergence of BBVI with the use of projected stochastic\ngradient descent. We also improve existing analysis on the regular closed-form\nentropy gradient estimators, which enables comparison against the STL estimator\nand provides explicit non-asymptotic complexity guarantees for both.",
          "link": "http://arxiv.org/abs/2307.14642",
          "publishedOn": "2023-07-29T00:48:55.721Z",
          "wordCount": 606,
          "title": "Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?. (arXiv:2307.14642v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.01198",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cotta_L/0/1/0/all/0/1\">Leonardo Cotta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bevilacqua_B/0/1/0/all/0/1\">Beatrice Bevilacqua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_N/0/1/0/all/0/1\">Nesreen Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_B/0/1/0/all/0/1\">Bruno Ribeiro</a>",
          "description": "Existing causal models for link prediction assume an underlying set of\ninherent node factors -- an innate characteristic defined at the node's birth\n-- that governs the causal evolution of links in the graph. In some causal\ntasks, however, link formation is path-dependent: The outcome of link\ninterventions depends on existing links. Unfortunately, these existing causal\nmethods are not designed for path-dependent link formation, as the cascading\nfunctional dependencies between links (arising from path dependence) are either\nunidentifiable or require an impractical number of control variables. To\novercome this, we develop the first causal model capable of dealing with path\ndependencies in link prediction. In this work we introduce the concept of\ncausal lifting, an invariance in causal models of independent interest that, on\ngraphs, allows the identification of causal link prediction queries using\nlimited interventional data. Further, we show how structural pairwise\nembeddings exhibit lower bias and correctly represent the task's causal\nstructure, as opposed to existing node embeddings, e.g., graph neural network\nnode embeddings and matrix factorization. Finally, we validate our theoretical\nfindings on three scenarios for causal link prediction tasks: knowledge base\ncompletion, covariance matrix estimation and consumer-product recommendations.",
          "link": "http://arxiv.org/abs/2302.01198",
          "publishedOn": "2023-07-29T00:48:55.714Z",
          "wordCount": 715,
          "title": "Causal Lifting and Link Prediction. (arXiv:2302.01198v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.07436",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Malinovskaya_A/0/1/0/all/0/1\">Anna Malinovskaya</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mozharovskyi_P/0/1/0/all/0/1\">Pavlo Mozharovskyi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Otto_P/0/1/0/all/0/1\">Philipp Otto</a>",
          "description": "The rapid advancement of models based on artificial intelligence demands\ninnovative monitoring techniques which can operate in real time with low\ncomputational costs. In machine learning, especially if we consider artificial\nneural networks (ANNs), the models are often trained in a supervised manner.\nConsequently, the learned relationship between the input and the output must\nremain valid during the model's deployment. If this stationarity assumption\nholds, we can conclude that the ANN provides accurate predictions. Otherwise,\nthe retraining or rebuilding of the model is required. We propose considering\nthe latent feature representation of the data (called \"embedding\") generated by\nthe ANN to determine the time when the data stream starts being nonstationary.\nIn particular, we monitor embeddings by applying multivariate control charts\nbased on the data depth calculation and normalized ranks. The performance of\nthe introduced method is compared with benchmark approaches for various ANN\narchitectures and different underlying data formats.",
          "link": "http://arxiv.org/abs/2209.07436",
          "publishedOn": "2023-07-29T00:48:55.696Z",
          "wordCount": 683,
          "title": "Statistical process monitoring of artificial neural networks. (arXiv:2209.07436v2 [stat.ME] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14619",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Block_A/0/1/0/all/0/1\">Adam Block</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfrommer_D/0/1/0/all/0/1\">Daniel Pfrommer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simchowitz_M/0/1/0/all/0/1\">Max Simchowitz</a>",
          "description": "We propose a theoretical framework for studying the imitation of stochastic,\nnon-Markovian, potentially multi-modal (i.e. \"complex\" ) expert demonstrations\nin nonlinear dynamical systems. Our framework invokes low-level controllers -\neither learned or implicit in position-command control - to stabilize imitation\npolicies around expert demonstrations. We show that with (a) a suitable\nlow-level stability guarantee and (b) a stochastic continuity property of the\nlearned policy we call \"total variation continuity\" (TVC), an imitator that\naccurately estimates actions on the demonstrator's state distribution closely\nmatches the demonstrator's distribution over entire trajectories. We then show\nthat TVC can be ensured with minimal degradation of accuracy by combining a\npopular data-augmentation regimen with a novel algorithmic trick: adding\naugmentation noise at execution time. We instantiate our guarantees for\npolicies parameterized by diffusion models and prove that if the learner\naccurately estimates the score of the (noise-augmented) expert policy, then the\ndistribution of imitator trajectories is close to the demonstrator distribution\nin a natural optimal transport distance. Our analysis constructs intricate\ncouplings between noise-augmented trajectories, a technique that may be of\nindependent interest. We conclude by empirically validating our algorithmic\nrecommendations.",
          "link": "http://arxiv.org/abs/2307.14619",
          "publishedOn": "2023-07-29T00:48:55.688Z",
          "wordCount": 700,
          "title": "Imitating Complex Trajectories: Bridging Low-Level Stability and High-Level Behavior. (arXiv:2307.14619v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14653",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Seroussi_I/0/1/0/all/0/1\">Inbar Seroussi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Alemi_A/0/1/0/all/0/1\">Alexander A. Alemi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Helias_M/0/1/0/all/0/1\">Moritz Helias</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ringel_Z/0/1/0/all/0/1\">Zohar Ringel</a>",
          "description": "State-of-the-art neural networks require extreme computational power to\ntrain. It is therefore natural to wonder whether they are optimally trained.\nHere we apply a recent advancement in stochastic thermodynamics which allows\nbounding the speed at which one can go from the initial weight distribution to\nthe final distribution of the fully trained network, based on the ratio of\ntheir Wasserstein-2 distance and the entropy production rate of the dynamical\nprocess connecting them. Considering both gradient-flow and Langevin training\ndynamics, we provide analytical expressions for these speed limits for linear\nand linearizable neural networks e.g. Neural Tangent Kernel (NTK). Remarkably,\ngiven some plausible scaling assumptions on the NTK spectra and spectral\ndecomposition of the labels -- learning is optimal in a scaling sense. Our\nresults are consistent with small-scale experiments with Convolutional Neural\nNetworks (CNNs) and Fully Connected Neural networks (FCNs) on CIFAR-10, showing\na short highly non-optimal regime followed by a longer optimal regime.",
          "link": "http://arxiv.org/abs/2307.14653",
          "publishedOn": "2023-07-29T00:48:55.680Z",
          "wordCount": 642,
          "title": "Speed Limits for Deep Learning. (arXiv:2307.14653v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2208.05776",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wu_S/0/1/0/all/0/1\">Sidi Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Beaulac_C/0/1/0/all/0/1\">C&#xe9;dric Beaulac</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cao_J/0/1/0/all/0/1\">Jiguo Cao</a>",
          "description": "The regression of a functional response on a set of scalar predictors can be\na challenging task, especially if there is a large number of predictors, or the\nrelationship between those predictors and the response is nonlinear. In this\nwork, we propose a solution to this problem: a feed-forward neural network (NN)\ndesigned to predict a functional response using scalar inputs. First, we\ntransform the functional response to a finite-dimensional representation and\nconstruct an NN that outputs this representation. Then, we propose to modify\nthe output of an NN via the objective function and introduce different\nobjective functions for network training. The proposed models are suited for\nboth regularly and irregularly spaced data, and a roughness penalty can be\nfurther applied to control the smoothness of the predicted curve. The\ndifficulty in implementing both those features lies in the definition of\nobjective functions that can be back-propagated. In our experiments, we\ndemonstrate that our model outperforms the conventional function-on-scalar\nregression model in multiple scenarios while computationally scaling better\nwith the dimension of the predictors.",
          "link": "http://arxiv.org/abs/2208.05776",
          "publishedOn": "2023-07-29T00:48:55.673Z",
          "wordCount": 693,
          "title": "Neural Networks for Scalar Input and Functional Output. (arXiv:2208.05776v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.02060",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Stone_I/0/1/0/all/0/1\">Iris R. Stone</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sagiv_Y/0/1/0/all/0/1\">Yotam Sagiv</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Park_I/0/1/0/all/0/1\">Il Memming Park</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pillow_J/0/1/0/all/0/1\">Jonathan W. Pillow</a>",
          "description": "Latent linear dynamical systems with Bernoulli observations provide a\npowerful modeling framework for identifying the temporal dynamics underlying\nbinary time series data, which arise in a variety of contexts such as binary\ndecision-making and discrete stochastic processes (e.g., binned neural spike\ntrains). Here we develop a spectral learning method for fast, efficient fitting\nof probit-Bernoulli latent linear dynamical system (LDS) models. Our approach\nextends traditional subspace identification methods to the Bernoulli setting\nvia a transformation of the first and second sample moments. This results in a\nrobust, fixed-cost estimator that avoids the hazards of local optima and the\nlong computation time of iterative fitting procedures like the\nexpectation-maximization (EM) algorithm. In regimes where data is limited or\nassumptions about the statistical structure of the data are not met, we\ndemonstrate that the spectral estimate provides a good initialization for\nLaplace-EM fitting. Finally, we show that the estimator provides substantial\nbenefits to real world settings by analyzing data from mice performing a\nsensory decision-making task.",
          "link": "http://arxiv.org/abs/2303.02060",
          "publishedOn": "2023-07-29T00:48:55.665Z",
          "wordCount": 707,
          "title": "Spectral learning of Bernoulli linear dynamical systems models. (arXiv:2303.02060v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.13813",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Busbridge_D/0/1/0/all/0/1\">Dan Busbridge</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramapuram_J/0/1/0/all/0/1\">Jason Ramapuram</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ablin_P/0/1/0/all/0/1\">Pierre Ablin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Likhomanenko_T/0/1/0/all/0/1\">Tatiana Likhomanenko</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dhekane_E/0/1/0/all/0/1\">Eeshan Gunesh Dhekane</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Suau_X/0/1/0/all/0/1\">Xavier Suau</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Webb_R/0/1/0/all/0/1\">Russ Webb</a>",
          "description": "Preserving training dynamics across batch sizes is an important tool for\npractical machine learning as it enables the trade-off between batch size and\nwall-clock time. This trade-off is typically enabled by a scaling rule, for\nexample, in stochastic gradient descent, one should scale the learning rate\nlinearly with the batch size. Another important tool for practical machine\nlearning is the model Exponential Moving Average (EMA), which is a model copy\nthat does not receive gradient information, but instead follows its target\nmodel with some momentum. This model EMA can improve the robustness and\ngeneralization properties of supervised learning, stabilize pseudo-labeling,\nand provide a learning signal for Self-Supervised Learning (SSL). Prior works\nhave treated the model EMA separately from optimization, leading to different\ntraining dynamics across batch sizes and lower model performance. In this work,\nwe provide a scaling rule for optimization in the presence of model EMAs and\ndemonstrate its validity across a range of architectures, optimizers, and data\nmodalities. We also show the rule's validity where the model EMA contributes to\nthe optimization of the target model, enabling us to train EMA-based\npseudo-labeling and SSL methods at small and large batch sizes. For SSL, we\nenable training of BYOL up to batch size 24,576 without sacrificing\nperformance, optimally a 6$\\times$ wall-clock time reduction.",
          "link": "http://arxiv.org/abs/2307.13813",
          "publishedOn": "2023-07-29T00:48:55.657Z",
          "wordCount": 739,
          "title": "How to Scale Your EMA. (arXiv:2307.13813v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2103.01280",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Viviano_D/0/1/0/all/0/1\">Davide Viviano</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Bradic_J/0/1/0/all/0/1\">Jelena Bradic</a>",
          "description": "This paper studies the estimation and inference of treatment histories in\npanel data settings when treatments change dynamically over time.\n\nWe propose a method that allows for (i) treatments to be assigned dynamically\nover time based on high-dimensional covariates, past outcomes and treatments;\n(ii) outcomes and time-varying covariates to depend on treatment trajectories;\n(iii) heterogeneity of treatment effects.\n\nOur approach recursively projects potential outcomes' expectations on past\nhistories. It then controls the bias by balancing dynamically observable\ncharacteristics. We study the asymptotic and numerical properties of the\nestimator and illustrate the benefits of the procedure in an empirical\napplication.",
          "link": "http://arxiv.org/abs/2103.01280",
          "publishedOn": "2023-07-29T00:48:55.618Z",
          "wordCount": 647,
          "title": "Dynamic covariate balancing: estimating treatment effects over time with potential local projections. (arXiv:2103.01280v3 [econ.EM] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14530",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Noskov_F/0/1/0/all/0/1\">Fedor Noskov</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Panov_M/0/1/0/all/0/1\">Maxim Panov</a>",
          "description": "Community detection is one of the most critical problems in modern network\nscience. Its applications can be found in various fields, from protein modeling\nto social network analysis. Recently, many papers appeared studying the problem\nof overlapping community detection, where each node of a network may belong to\nseveral communities. In this work, we consider Mixed-Membership Stochastic\nBlock Model (MMSB) first proposed by Airoldi et al. (2008). MMSB provides quite\na general setting for modeling overlapping community structure in graphs. The\ncentral question of this paper is to reconstruct relations between communities\ngiven an observed network. We compare different approaches and establish the\nminimax lower bound on the estimation error. Then, we propose a new estimator\nthat matches this lower bound. Theoretical results are proved under fairly\ngeneral conditions on the considered model. Finally, we illustrate the theory\nin a series of experiments.",
          "link": "http://arxiv.org/abs/2307.14530",
          "publishedOn": "2023-07-29T00:48:55.610Z",
          "wordCount": 639,
          "title": "Optimal Estimation in Mixed-Membership Stochastic Block Models. (arXiv:2307.14530v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.14988",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharir_O/0/1/0/all/0/1\">Or Sharir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>",
          "description": "Deep learning often faces the challenge of efficiently processing dynamic\ninputs, such as sensor data or user inputs. For example, an AI writing\nassistant is required to update its suggestions in real time as a document is\nedited. Re-running the model each time is expensive, even with compression\ntechniques like knowledge distillation, pruning, or quantization. Instead, we\ntake an incremental computing approach, looking to reuse calculations as the\ninputs change. However, the dense connectivity of conventional architectures\nposes a major obstacle to incremental computation, as even minor input changes\ncascade through the network and restrict information reuse. To address this, we\nuse vector quantization to discretize intermediate values in the network, which\nfilters out noisy and unnecessary modifications to hidden neurons, facilitating\nthe reuse of their values. We apply this approach to the transformers\narchitecture, creating an efficient incremental inference algorithm with\ncomplexity proportional to the fraction of the modified inputs. Our experiments\nwith adapting the OPT-125M pre-trained language model demonstrate comparable\naccuracy on document classification while requiring 12.1X (median) fewer\noperations for processing sequences of atomic edits.",
          "link": "http://arxiv.org/abs/2307.14988",
          "publishedOn": "2023-07-29T00:48:55.587Z",
          "wordCount": 687,
          "title": "Incrementally-Computable Neural Networks: Efficient Inference for Dynamic Inputs. (arXiv:2307.14988v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06092",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Favaro_S/0/1/0/all/0/1\">Stefano Favaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanin_B/0/1/0/all/0/1\">Boris Hanin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marinucci_D/0/1/0/all/0/1\">Domenico Marinucci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nourdin_I/0/1/0/all/0/1\">Ivan Nourdin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peccati_G/0/1/0/all/0/1\">Giovanni Peccati</a>",
          "description": "We study the distribution of a fully connected neural network with random\nGaussian weights and biases in which the hidden layer widths are proportional\nto a large constant $n$. Under mild assumptions on the non-linearity, we obtain\nquantitative bounds on normal approximations valid at large but finite $n$ and\nany fixed network depth. Our theorems show both for the finite-dimensional\ndistributions and the entire process, that the distance between a random fully\nconnected network (and its derivatives) to the corresponding infinite width\nGaussian process scales like $n^{-\\gamma}$ for $\\gamma>0$, with the exponent\ndepending on the metric used to measure discrepancy. Our bounds are strictly\nstronger in terms of their dependence on network width than any previously\navailable in the literature; in the one-dimensional case, we also prove that\nthey are optimal, i.e., we establish matching lower bounds.",
          "link": "http://arxiv.org/abs/2307.06092",
          "publishedOn": "2023-07-22T00:55:25.966Z",
          "wordCount": null,
          "title": "Quantitative CLTs in Deep Neural Networks. (arXiv:2307.06092v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09943",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+McDonald_T/0/1/0/all/0/1\">Thomas M. McDonald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maystre_L/0/1/0/all/0/1\">Lucas Maystre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lalmas_M/0/1/0/all/0/1\">Mounia Lalmas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russo_D/0/1/0/all/0/1\">Daniel Russo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ciosek_K/0/1/0/all/0/1\">Kamil Ciosek</a>",
          "description": "Recommender systems are a ubiquitous feature of online platforms.\nIncreasingly, they are explicitly tasked with increasing users' long-term\nsatisfaction. In this context, we study a content exploration task, which we\nformalize as a multi-armed bandit problem with delayed rewards. We observe that\nthere is an apparent trade-off in choosing the learning signal: Waiting for the\nfull reward to become available might take several weeks, hurting the rate at\nwhich learning happens, whereas measuring short-term proxy rewards reflects the\nactual long-term goal only imperfectly. We address this challenge in two steps.\nFirst, we develop a predictive model of delayed rewards that incorporates all\ninformation obtained to date. Full observations as well as partial (short or\nmedium-term) outcomes are combined through a Bayesian filter to obtain a\nprobabilistic belief. Second, we devise a bandit algorithm that takes advantage\nof this new predictive model. The algorithm quickly learns to identify content\naligned with long-term success by carefully balancing exploration and\nexploitation. We apply our approach to a podcast recommendation problem, where\nwe seek to identify shows that users engage with repeatedly over two months. We\nempirically validate that our approach results in substantially better\nperformance compared to approaches that either optimize for short-term proxies,\nor wait for the long-term outcome to be fully realized.",
          "link": "http://arxiv.org/abs/2307.09943",
          "publishedOn": "2023-07-22T00:55:25.961Z",
          "wordCount": null,
          "title": "Impatient Bandits: Optimizing Recommendations for the Long-Term Without Delay. (arXiv:2307.09943v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.13501",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mankovich_N/0/1/0/all/0/1\">Nathan Mankovich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birdal_T/0/1/0/all/0/1\">Tolga Birdal</a>",
          "description": "This paper presents a new, provably-convergent algorithm for computing the\nflag-mean and flag-median of a set of points on a flag manifold under the\nchordal metric. The flag manifold is a mathematical space consisting of flags,\nwhich are sequences of nested subspaces of a vector space that increase in\ndimension. The flag manifold is a superset of a wide range of known matrix\nspaces, including Stiefel and Grassmanians, making it a general object that is\nuseful in a wide variety computer vision problems.\n\nTo tackle the challenge of computing first order flag statistics, we first\ntransform the problem into one that involves auxiliary variables constrained to\nthe Stiefel manifold. The Stiefel manifold is a space of orthogonal frames, and\nleveraging the numerical stability and efficiency of Stiefel-manifold\noptimization enables us to compute the flag-mean effectively. Through a series\nof experiments, we show the competence of our method in Grassmann and rotation\naveraging, as well as principal component analysis. We release our source code\nunder https://github.com/nmank/FlagAveraging.",
          "link": "http://arxiv.org/abs/2303.13501",
          "publishedOn": "2023-07-22T00:55:25.907Z",
          "wordCount": null,
          "title": "Chordal Averaging on Flag Manifolds and Its Applications. (arXiv:2303.13501v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10870",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Meunier_D/0/1/0/all/0/1\">Dimitri Meunier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_Z/0/1/0/all/0/1\">Zhu Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1\">Arthur Gretton</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kpotufe_S/0/1/0/all/0/1\">Samory Kpotufe</a>",
          "description": "Many recent theoretical works on \\emph{meta-learning} aim to achieve\nguarantees in leveraging similar representational structures from related tasks\ntowards simplifying a target task. Importantly, the main aim in theory works on\nthe subject is to understand the extent to which convergence rates -- in\nlearning a common representation -- \\emph{may scale with the number $N$ of\ntasks} (as well as the number of samples per task). First steps in this setting\ndemonstrate this property when both the shared representation amongst tasks,\nand task-specific regression functions, are linear. This linear setting readily\nreveals the benefits of aggregating tasks, e.g., via averaging arguments. In\npractice, however, the representation is often highly nonlinear, introducing\nnontrivial biases in each task that cannot easily be averaged out as in the\nlinear case. In the present work, we derive theoretical guarantees for\nmeta-learning with nonlinear representations. In particular, assuming the\nshared nonlinearity maps to an infinite-dimensional RKHS, we show that\nadditional biases can be mitigated with careful regularization that leverages\nthe smoothness of task-specific regression functions,",
          "link": "http://arxiv.org/abs/2307.10870",
          "publishedOn": "2023-07-22T00:55:25.860Z",
          "wordCount": null,
          "title": "Nonlinear Meta-Learning Can Guarantee Faster Rates. (arXiv:2307.10870v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.04974",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wagenmaker_A/0/1/0/all/0/1\">Andrew Wagenmaker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pacchiano_A/0/1/0/all/0/1\">Aldo Pacchiano</a>",
          "description": "Two central paradigms have emerged in the reinforcement learning (RL)\ncommunity: online RL and offline RL. In the online RL setting, the agent has no\nprior knowledge of the environment, and must interact with it in order to find\nan $\\epsilon$-optimal policy. In the offline RL setting, the learner instead\nhas access to a fixed dataset to learn from, but is unable to otherwise\ninteract with the environment, and must obtain the best policy it can from this\noffline data. Practical scenarios often motivate an intermediate setting: if we\nhave some set of offline data and, in addition, may also interact with the\nenvironment, how can we best use the offline data to minimize the number of\nonline interactions necessary to learn an $\\epsilon$-optimal policy?\n\nIn this work, we consider this setting, which we call the \\textsf{FineTuneRL}\nsetting, for MDPs with linear structure. We characterize the necessary number\nof online samples needed in this setting given access to some offline dataset,\nand develop an algorithm, \\textsc{FTPedel}, which is provably optimal, up to\n$H$ factors. We show through an explicit example that combining offline data\nwith online interactions can lead to a provable improvement over either purely\noffline or purely online RL. Finally, our results illustrate the distinction\nbetween \\emph{verifiable} learning, the typical setting considered in online\nRL, and \\emph{unverifiable} learning, the setting often considered in offline\nRL, and show that there is a formal separation between these regimes.",
          "link": "http://arxiv.org/abs/2211.04974",
          "publishedOn": "2023-07-22T00:55:25.787Z",
          "wordCount": null,
          "title": "Leveraging Offline Data in Online Reinforcement Learning. (arXiv:2211.04974v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.04777",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Godon_T/0/1/0/all/0/1\">Thibaud Godon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bauvin_B/0/1/0/all/0/1\">Baptiste Bauvin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Germain_P/0/1/0/all/0/1\">Pascal Germain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corbeil_J/0/1/0/all/0/1\">Jacques Corbeil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drouin_A/0/1/0/all/0/1\">Alexandre Drouin</a>",
          "description": "Rule-based models, such as decision trees, appeal to practitioners due to\ntheir interpretable nature. However, the learning algorithms that produce such\nmodels are often vulnerable to spurious associations and thus, they are not\nguaranteed to extract causally-relevant insights. In this work, we build on\nideas from the invariant causal prediction literature to propose Invariant\nCausal Set Covering Machines, an extension of the classical Set Covering\nMachine algorithm for conjunctions/disjunctions of binary-valued rules that\nprovably avoids spurious associations. We demonstrate both theoretically and\nempirically that our method can identify the causal parents of a variable of\ninterest in polynomial time.",
          "link": "http://arxiv.org/abs/2306.04777",
          "publishedOn": "2023-07-22T00:55:25.785Z",
          "wordCount": null,
          "title": "Invariant Causal Set Covering Machines. (arXiv:2306.04777v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10991",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hanson_S/0/1/0/all/0/1\">Stephen Jos&#xe8; Hanson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadev_V/0/1/0/all/0/1\">Vivek Yadev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanson_C/0/1/0/all/0/1\">Catherine Hanson</a>",
          "description": "Deep Learning (DL) , a variant of the neural network algorithms originally\nproposed in the 1980s, has made surprising progress in Artificial Intelligence\n(AI), ranging from language translation, protein folding, autonomous cars, and\nmore recently human-like language models (CHATbots), all that seemed\nintractable until very recently. Despite the growing use of Deep Learning (DL)\nnetworks, little is actually understood about the learning mechanisms and\nrepresentations that makes these networks effective across such a diverse range\nof applications. Part of the answer must be the huge scale of the architecture\nand of course the large scale of the data, since not much has changed since\n1987. But the nature of deep learned representations remain largely unknown.\nUnfortunately training sets with millions or billions of tokens have unknown\ncombinatorics and Networks with millions or billions of hidden units cannot\neasily be visualized and their mechanisms cannot be easily revealed. In this\npaper, we explore these questions with a large (1.24M weights; VGG) DL in a\nnovel high density sample task (5 unique tokens with at minimum 500 exemplars\nper token) which allows us to more carefully follow the emergence of category\nstructure and feature construction. We use various visualization methods for\nfollowing the emergence of the classification and the development of the\ncoupling of feature detectors and structures that provide a type of graphical\nbootstrapping, From these results we harvest some basic observations of the\nlearning dynamics of DL and propose a new theory of complex feature\nconstruction based on our results.",
          "link": "http://arxiv.org/abs/2307.10991",
          "publishedOn": "2023-07-22T00:55:25.766Z",
          "wordCount": null,
          "title": "Dense Sample Deep Learning. (arXiv:2307.10991v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10999",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ullah_E/0/1/0/all/0/1\">Enayat Ullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choquette_Choo_C/0/1/0/all/0/1\">Christopher A. Choquette-Choo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kairouz_P/0/1/0/all/0/1\">Peter Kairouz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Sewoong Oh</a>",
          "description": "We propose new techniques for reducing communication in private federated\nlearning without the need for setting or tuning compression rates. Our\non-the-fly methods automatically adjust the compression rate based on the error\ninduced during training, while maintaining provable privacy guarantees through\nthe use of secure aggregation and differential privacy. Our techniques are\nprovably instance-optimal for mean estimation, meaning that they can adapt to\nthe ``hardness of the problem\" with minimal interactivity. We demonstrate the\neffectiveness of our approach on real-world datasets by achieving favorable\ncompression rates without the need for tuning.",
          "link": "http://arxiv.org/abs/2307.10999",
          "publishedOn": "2023-07-22T00:55:25.766Z",
          "wordCount": null,
          "title": "Private Federated Learning with Autotuned Compression. (arXiv:2307.10999v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2107.03455",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ghosh_A/0/1/0/all/0/1\">Avishek Ghosh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sankararaman_A/0/1/0/all/0/1\">Abishek Sankararaman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramchandran_K/0/1/0/all/0/1\">Kannan Ramchandran</a>",
          "description": "We consider the problem of model selection for the general stochastic\ncontextual bandits under the realizability assumption. We propose a successive\nrefinement based algorithm called Adaptive Contextual Bandit ({\\ttfamily ACB}),\nthat works in phases and successively eliminates model classes that are too\nsimple to fit the given instance. We prove that this algorithm is adaptive,\ni.e., the regret rate order-wise matches that of any provable contextual bandit\nalgorithm (ex. \\cite{falcon}), that needs the knowledge of the true model\nclass. The price of not knowing the correct model class turns out to be only an\nadditive term contributing to the second order term in the regret bound. This\ncost possess the intuitive property that it becomes smaller as the model class\nbecomes easier to identify, and vice-versa. We also show that a much simpler\nexplore-then-commit (ETC) style algorithm also obtains similar regret bound,\ndespite not knowing the true model class. However, the cost of model selection\nis higher in ETC as opposed to in {\\ttfamily ACB}, as expected. Furthermore,\nfor the special case of linear contextual bandits, we propose specialized\nalgorithms that obtain sharper guarantees compared to the generic setup.",
          "link": "http://arxiv.org/abs/2107.03455",
          "publishedOn": "2023-07-22T00:55:25.766Z",
          "wordCount": null,
          "title": "Model Selection for Generic Contextual Bandits. (arXiv:2107.03455v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2207.02575",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wagenmaker_A/0/1/0/all/0/1\">Andrew Wagenmaker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jamieson_K/0/1/0/all/0/1\">Kevin Jamieson</a>",
          "description": "While much progress has been made in understanding the minimax sample\ncomplexity of reinforcement learning (RL) -- the complexity of learning on the\n\"worst-case\" instance -- such measures of complexity often do not capture the\ntrue difficulty of learning. In practice, on an \"easy\" instance, we might hope\nto achieve a complexity far better than that achievable on the worst-case\ninstance. In this work we seek to understand the \"instance-dependent\"\ncomplexity of learning near-optimal policies (PAC RL) in the setting of RL with\nlinear function approximation. We propose an algorithm, \\textsc{Pedel}, which\nachieves a fine-grained instance-dependent measure of complexity, the first of\nits kind in the RL with function approximation setting, thereby capturing the\ndifficulty of learning on each particular problem instance. Through an explicit\nexample, we show that \\textsc{Pedel} yields provable gains over low-regret,\nminimax-optimal algorithms and that such algorithms are unable to hit the\ninstance-optimal rate. Our approach relies on a novel online experiment\ndesign-based procedure which focuses the exploration budget on the \"directions\"\nmost relevant to learning a near-optimal policy, and may be of independent\ninterest.",
          "link": "http://arxiv.org/abs/2207.02575",
          "publishedOn": "2023-07-22T00:55:25.765Z",
          "wordCount": null,
          "title": "Instance-Dependent Near-Optimal Policy Identification in Linear MDPs via Online Experiment Design. (arXiv:2207.02575v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.14319",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Harkonen_M/0/1/0/all/0/1\">Marc H&#xe4;rk&#xf6;nen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lange_Hegermann_M/0/1/0/all/0/1\">Markus Lange-Hegermann</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Raita_B/0/1/0/all/0/1\">Bogdan Rai&#x163;&#x103;</a>",
          "description": "Partial differential equations (PDEs) are important tools to model physical\nsystems and including them into machine learning models is an important way of\nincorporating physical knowledge. Given any system of linear PDEs with constant\ncoefficients, we propose a family of Gaussian process (GP) priors, which we\ncall EPGP, such that all realizations are exact solutions of this system. We\napply the Ehrenpreis-Palamodov fundamental principle, which works as a\nnon-linear Fourier transform, to construct GP kernels mirroring standard\nspectral methods for GPs. Our approach can infer probable solutions of linear\nPDE systems from any data such as noisy measurements, or pointwise defined\ninitial and boundary conditions. Constructing EPGP-priors is algorithmic,\ngenerally applicable, and comes with a sparse version (S-EPGP) that learns the\nrelevant spectral frequencies and works better for big data sets. We\ndemonstrate our approach on three families of systems of PDEs, the heat\nequation, wave equation, and Maxwell's equations, where we improve upon the\nstate of the art in computation time and precision, in some experiments by\nseveral orders of magnitude.",
          "link": "http://arxiv.org/abs/2212.14319",
          "publishedOn": "2023-07-22T00:55:25.765Z",
          "wordCount": null,
          "title": "Gaussian Process Priors for Systems of Linear Partial Differential Equations with Constant Coefficients. (arXiv:2212.14319v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.11112",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tolbert_A/0/1/0/all/0/1\">Alexander Williams Tolbert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diana_E/0/1/0/all/0/1\">Emily Diana</a>",
          "description": "We consider the problem of learning from data corrupted by\nunderrepresentation bias, where positive examples are filtered from the data at\ndifferent, unknown rates for a fixed number of sensitive groups. We show that\nwith a small amount of unbiased data, we can efficiently estimate the\ngroup-wise drop-out parameters, even in settings where intersectional group\nmembership makes learning each intersectional rate computationally infeasible.\nUsing this estimate for the group-wise drop-out rate, we construct a\nre-weighting scheme that allows us to approximate the loss of any hypothesis on\nthe true distribution, even if we only observe the empirical error on a biased\nsample. Finally, we present an algorithm encapsulating this learning and\nre-weighting process, and we provide strong PAC-style guarantees that, with\nhigh probability, our estimate of the risk of the hypothesis over the true\ndistribution will be arbitrarily close to the true risk.",
          "link": "http://arxiv.org/abs/2306.11112",
          "publishedOn": "2023-07-22T00:55:25.765Z",
          "wordCount": null,
          "title": "Correcting Underrepresentation and Intersectional Bias for Fair Classification. (arXiv:2306.11112v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.10515",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Jarrett_D/0/1/0/all/0/1\">Daniel Jarrett</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tallec_C/0/1/0/all/0/1\">Corentin Tallec</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Altche_F/0/1/0/all/0/1\">Florent Altch&#xe9;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mesnard_T/0/1/0/all/0/1\">Thomas Mesnard</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Munos_R/0/1/0/all/0/1\">R&#xe9;mi Munos</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Valko_M/0/1/0/all/0/1\">Michal Valko</a>",
          "description": "Consider the problem of exploration in sparse-reward or reward-free\nenvironments, such as in Montezuma's Revenge. In the curiosity-driven paradigm,\nthe agent is rewarded for how much each realized outcome differs from their\npredicted outcome. But using predictive error as intrinsic motivation is\nfragile in stochastic environments, as the agent may become trapped by\nhigh-entropy areas of the state-action space, such as a \"noisy TV\". In this\nwork, we study a natural solution derived from structural causal models of the\nworld: Our key idea is to learn representations of the future that capture\nprecisely the unpredictable aspects of each outcome -- which we use as\nadditional input for predictions, such that intrinsic rewards only reflect the\npredictable aspects of world dynamics. First, we propose incorporating such\nhindsight representations into models to disentangle \"noise\" from \"novelty\",\nyielding Curiosity in Hindsight: a simple and scalable generalization of\ncuriosity that is robust to stochasticity. Second, we instantiate this\nframework for the recently introduced BYOL-Explore algorithm as our prime\nexample, resulting in the noise-robust BYOL-Hindsight. Third, we illustrate its\nbehavior under a variety of different stochasticities in a grid world, and find\nimprovements over BYOL-Explore in hard-exploration Atari games with sticky\nactions. Notably, we show state-of-the-art results in exploring Montezuma's\nRevenge with sticky actions, while preserving performance in the non-sticky\nsetting.",
          "link": "http://arxiv.org/abs/2211.10515",
          "publishedOn": "2023-07-22T00:55:25.764Z",
          "wordCount": null,
          "title": "Curiosity in Hindsight: Intrinsic Exploration in Stochastic Environments. (arXiv:2211.10515v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09614",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Brusch_T/0/1/0/all/0/1\">Thea Br&#xfc;sch</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schmidt_M/0/1/0/all/0/1\">Mikkel N. Schmidt</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Alstrom_T/0/1/0/all/0/1\">Tommy S. Alstr&#xf8;m</a>",
          "description": "Labeling of multivariate biomedical time series data is a laborious and\nexpensive process. Self-supervised contrastive learning alleviates the need for\nlarge, labeled datasets through pretraining on unlabeled data. However, for\nmultivariate time series data, the set of input channels often varies between\napplications, and most existing work does not allow for transfer between\ndatasets with different sets of input channels. We propose learning one encoder\nto operate on all input channels individually. We then use a message passing\nneural network to extract a single representation across channels. We\ndemonstrate the potential of this method by pretraining our model on a dataset\nwith six EEG channels and then fine-tuning it on a dataset with two different\nEEG channels. We compare models with and without the message passing neural\nnetwork across different contrastive loss functions. We show that our method,\ncombined with the TS2Vec loss, outperforms all other methods in most settings.",
          "link": "http://arxiv.org/abs/2307.09614",
          "publishedOn": "2023-07-22T00:55:25.764Z",
          "wordCount": null,
          "title": "Multi-view self-supervised learning for multivariate variable-channel time series. (arXiv:2307.09614v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.10060",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meinert_N/0/1/0/all/0/1\">Nis Meinert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gawlikowski_J/0/1/0/all/0/1\">Jakob Gawlikowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lavin_A/0/1/0/all/0/1\">Alexander Lavin</a>",
          "description": "There is a significant need for principled uncertainty reasoning in machine\nlearning systems as they are increasingly deployed in safety-critical domains.\nA new approach with uncertainty-aware regression-based neural networks (NNs),\nbased on learning evidential distributions for aleatoric and epistemic\nuncertainties, shows promise over traditional deterministic methods and typical\nBayesian NNs, notably with the capabilities to disentangle aleatoric and\nepistemic uncertainties. Despite some empirical success of Deep Evidential\nRegression (DER), there are important gaps in the mathematical foundation that\nraise the question of why the proposed technique seemingly works. We detail the\ntheoretical shortcomings and analyze the performance on synthetic and\nreal-world data sets, showing that Deep Evidential Regression is a heuristic\nrather than an exact uncertainty quantification. We go on to discuss\ncorrections and redefinitions of how aleatoric and epistemic uncertainties\nshould be extracted from NNs.",
          "link": "http://arxiv.org/abs/2205.10060",
          "publishedOn": "2023-07-22T00:55:25.763Z",
          "wordCount": null,
          "title": "The Unreasonable Effectiveness of Deep Evidential Regression. (arXiv:2205.10060v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.12900",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Harder_F/0/1/0/all/0/1\">Fredrik Harder</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Asadabadi_M/0/1/0/all/0/1\">Milad Jalali Asadabadi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sutherland_D/0/1/0/all/0/1\">Danica J. Sutherland</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Park_M/0/1/0/all/0/1\">Mijung Park</a>",
          "description": "Training even moderately-sized generative models with differentially-private\nstochastic gradient descent (DP-SGD) is difficult: the required level of noise\nfor reasonable levels of privacy is simply too large. We advocate instead\nbuilding off a good, relevant representation on an informative public dataset,\nthen learning to model the private data with that representation. In\nparticular, we minimize the maximum mean discrepancy (MMD) between private\ntarget data and a generator's distribution, using a kernel based on perceptual\nfeatures learned from a public dataset. With the MMD, we can simply privatize\nthe data-dependent term once and for all, rather than introducing noise at each\nstep of optimization as in DP-SGD. Our algorithm allows us to generate\nCIFAR10-level images with $\\epsilon \\approx 2$ which capture distinctive\nfeatures in the distribution, far surpassing the current state of the art,\nwhich mostly focuses on datasets such as MNIST and FashionMNIST at a large\n$\\epsilon \\approx 10$. Our work introduces simple yet powerful foundations for\nreducing the gap between private and non-private deep generative models. Our\ncode is available at \\url{https://github.com/ParkLabML/DP-MEPF}.",
          "link": "http://arxiv.org/abs/2205.12900",
          "publishedOn": "2023-07-22T00:55:25.763Z",
          "wordCount": null,
          "title": "Pre-trained Perceptual Features Improve Differentially Private Image Generation. (arXiv:2205.12900v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10303",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Miraoui_Y/0/1/0/all/0/1\">Yanis Miraoui</a>",
          "description": "In this paper, we carefully investigate how we can use multiple different\nNatural Language Processing techniques and methods in order to automatically\nrecognize the main actions in sports events. We aim to extract insights by\nanalyzing live sport commentaries from different sources and by classifying\nthese major actions into different categories. We also study if sentiment\nanalysis could help detect these main actions.",
          "link": "http://arxiv.org/abs/2307.10303",
          "publishedOn": "2023-07-22T00:55:25.762Z",
          "wordCount": null,
          "title": "Analyzing sports commentary in order to automatically recognize events and extract insights. (arXiv:2307.10303v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10749",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ueda_R/0/1/0/all/0/1\">Ryosuke Ueda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takeuchi_K/0/1/0/all/0/1\">Koh Takeuchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kashima_H/0/1/0/all/0/1\">Hisashi Kashima</a>",
          "description": "The aggregation of multiple opinions plays a crucial role in decision-making,\nsuch as in hiring and loan review, and in labeling data for supervised\nlearning. Although majority voting and existing opinion aggregation models are\neffective for simple tasks, they are inappropriate for tasks without\nobjectively true labels in which disagreements may occur. In particular, when\nvoter attributes such as gender or race introduce bias into opinions, the\naggregation results may vary depending on the composition of voter attributes.\nA balanced group of voters is desirable for fair aggregation results but may be\ndifficult to prepare. In this study, we consider methods to achieve fair\nopinion aggregation based on voter attributes and evaluate the fairness of the\naggregated results. To this end, we consider an approach that combines opinion\naggregation models such as majority voting and the Dawid and Skene model (D&S\nmodel) with fairness options such as sample weighting. To evaluate the fairness\nof opinion aggregation, probabilistic soft labels are preferred over discrete\nclass labels. First, we address the problem of soft label estimation without\nconsidering voter attributes and identify some issues with the D&S model. To\naddress these limitations, we propose a new Soft D&S model with improved\naccuracy in estimating soft labels. Moreover, we evaluated the fairness of an\nopinion aggregation model, including Soft D&S, in combination with different\nfairness options using synthetic and semi-synthetic data. The experimental\nresults suggest that the combination of Soft D&S and data splitting as a\nfairness option is effective for dense data, whereas weighted majority voting\nis effective for sparse data. These findings should prove particularly valuable\nin supporting decision-making by human and machine-learning models with\nbalanced opinion aggregation.",
          "link": "http://arxiv.org/abs/2307.10749",
          "publishedOn": "2023-07-22T00:55:25.761Z",
          "wordCount": null,
          "title": "Mitigating Voter Attribute Bias for Fair Opinion Aggregation. (arXiv:2307.10749v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.11007",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wen_K/0/1/0/all/0/1\">Kaiyue Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhiyuan Li</a>",
          "description": "Despite extensive studies, the underlying reason as to why overparameterized\nneural networks can generalize remains elusive. Existing theory shows that\ncommon stochastic optimizers prefer flatter minimizers of the training loss,\nand thus a natural potential explanation is that flatness implies\ngeneralization. This work critically examines this explanation. Through\ntheoretical and empirical investigation, we identify the following three\nscenarios for two-layer ReLU networks: (1) flatness provably implies\ngeneralization; (2) there exist non-generalizing flattest models and sharpness\nminimization algorithms fail to generalize, and (3) perhaps most surprisingly,\nthere exist non-generalizing flattest models, but sharpness minimization\nalgorithms still generalize. Our results suggest that the relationship between\nsharpness and generalization subtly depends on the data distributions and the\nmodel architectures and sharpness minimization algorithms do not only minimize\nsharpness to achieve better generalization. This calls for the search for other\nexplanations for the generalization of over-parameterized neural networks.",
          "link": "http://arxiv.org/abs/2307.11007",
          "publishedOn": "2023-07-22T00:55:25.761Z",
          "wordCount": null,
          "title": "Sharpness Minimization Algorithms Do Not Only Minimize Sharpness To Achieve Better Generalization. (arXiv:2307.11007v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2009.03259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bian_R/0/1/0/all/0/1\">Rongzheng Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1\">Yumeng Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Liang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Baoquan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weiskopf_D/0/1/0/all/0/1\">Daniel Weiskopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yunhai Wang</a>",
          "description": "We propose a visualization method to understand the effect of\nmultidimensional projection on local subspaces, using implicit function\ndifferentiation. Here, we understand the local subspace as the multidimensional\nlocal neighborhood of data points. Existing methods focus on the projection of\nmultidimensional data points, and the neighborhood information is ignored. Our\nmethod is able to analyze the shape and directional information of the local\nsubspace to gain more insights into the global structure of the data through\nthe perception of local structures. Local subspaces are fitted by\nmultidimensional ellipses that are spanned by basis vectors. An accurate and\nefficient vector transformation method is proposed based on analytical\ndifferentiation of multidimensional projections formulated as implicit\nfunctions. The results are visualized as glyphs and analyzed using a full set\nof specifically-designed interactions supported in our efficient web-based\nvisualization tool. The usefulness of our method is demonstrated using various\nmulti- and high-dimensional benchmark datasets. Our implicit differentiation\nvector transformation is evaluated through numerical comparisons; the overall\nmethod is evaluated through exploration examples and use cases.",
          "link": "http://arxiv.org/abs/2009.03259",
          "publishedOn": "2023-07-22T00:55:25.749Z",
          "wordCount": null,
          "title": "Implicit Multidimensional Projection of Local Subspaces. (arXiv:2009.03259v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.00143",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Podkopaev_A/0/1/0/all/0/1\">Aleksandr Podkopaev</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>",
          "description": "We study the problems of sequential nonparametric two-sample and independence\ntesting. Sequential tests process data online and allow using observed data to\ndecide whether to stop and reject the null hypothesis or to collect more data,\nwhile maintaining type I error control. We build upon the principle of\n(nonparametric) testing by betting, where a gambler places bets on future\nobservations and their wealth measures evidence against the null hypothesis.\nWhile recently developed kernel-based betting strategies often work well on\nsimple distributions, selecting a suitable kernel for high-dimensional or\nstructured data, such as images, is often nontrivial. To address this drawback,\nwe design prediction-based betting strategies that rely on the following fact:\nif a sequentially updated predictor starts to consistently determine (a) which\ndistribution an instance is drawn from, or (b) whether an instance is drawn\nfrom the joint distribution or the product of the marginal distributions (the\nlatter produced by external randomization), it provides evidence against the\ntwo-sample or independence nulls respectively. We empirically demonstrate the\nsuperiority of our tests over kernel-based approaches under structured\nsettings. Our tests can be applied beyond the case of independent and\nidentically distributed data, remaining valid and powerful even when the data\ndistribution drifts over time.",
          "link": "http://arxiv.org/abs/2305.00143",
          "publishedOn": "2023-07-22T00:55:25.749Z",
          "wordCount": null,
          "title": "Sequential Predictive Two-Sample and Independence Testing. (arXiv:2305.00143v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10187",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fay_D/0/1/0/all/0/1\">Dominik Fay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mair_S/0/1/0/all/0/1\">Sebastian Mair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sjolund_J/0/1/0/all/0/1\">Jens Sj&#xf6;lund</a>",
          "description": "We examine the privacy-enhancing properties of subsampling a data set via\nimportance sampling as a pre-processing step for differentially private\nmechanisms. This extends the established privacy amplification by subsampling\nresult to importance sampling where each data point is weighted by the\nreciprocal of its selection probability. The implications for privacy of\nweighting each point are not obvious. On the one hand, a lower selection\nprobability leads to a stronger privacy amplification. On the other hand, the\nhigher the weight, the stronger the influence of the point on the output of the\nmechanism in the event that the point does get selected. We provide a general\nresult that quantifies the trade-off between these two effects. We show that\nheterogeneous sampling probabilities can lead to both stronger privacy and\nbetter utility than uniform subsampling while retaining the subsample size. In\nparticular, we formulate and solve the problem of privacy-optimal sampling,\nthat is, finding the importance weights that minimize the expected subset size\nsubject to a given privacy budget. Empirically, we evaluate the privacy,\nefficiency, and accuracy of importance sampling-based privacy amplification on\nthe example of k-means clustering.",
          "link": "http://arxiv.org/abs/2307.10187",
          "publishedOn": "2023-07-22T00:55:25.627Z",
          "wordCount": null,
          "title": "Privacy Amplification via Importance Sampling. (arXiv:2307.10187v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.11018",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Margossian_C/0/1/0/all/0/1\">Charles C. Margossian</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Blei_D/0/1/0/all/0/1\">David M. Blei</a>",
          "description": "Amortized variational inference (A-VI) is a method for approximating the\nintractable posterior distributions that arise in probabilistic models. The\ndefining feature of A-VI is that it learns a global inference function that\nmaps each observation to its local latent variable's approximate posterior.\nThis stands in contrast to the more classical factorized (or mean-field)\nvariational inference (F-VI), which directly learns the parameters of the\napproximating distribution for each latent variable. In deep generative models,\nA-VI is used as a computational trick to speed up inference for local latent\nvariables. In this paper, we study A-VI as a general alternative to F-VI for\napproximate posterior inference. A-VI cannot produce an approximation with a\nlower Kullback-Leibler divergence than F-VI's optimal solution, because the\namortized family is a subset of the factorized family. Thus a central\ntheoretical problem is to characterize when A-VI still attains F-VI's optimal\nsolution. We derive conditions on both the model and the inference function\nunder which A-VI can theoretically achieve F-VI's optimum. We show that for a\nbroad class of hierarchical models, including deep generative models, it is\npossible to close the gap between A-VI and F-VI. Further, for an even broader\nclass of models, we establish when and how to expand the domain of the\ninference function to make amortization a feasible strategy. Finally, we prove\nthat for certain models -- including hidden Markov models and Gaussian\nprocesses -- A-VI cannot match F-VI's solution, no matter how expressive the\ninference function is. We also study A-VI empirically. On several examples, we\ncorroborate our theoretical results and investigate the performance of A-VI\nwhen varying the complexity of the inference function. When the gap between\nA-VI and F-VI can be closed, we find that the required complexity of the\nfunction need not scale with the number of observations, and that A-VI often\nconverges faster than F-VI.",
          "link": "http://arxiv.org/abs/2307.11018",
          "publishedOn": "2023-07-22T00:55:25.567Z",
          "wordCount": null,
          "title": "Amortized Variational Inference: When and Why?. (arXiv:2307.11018v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.00405",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_R/0/1/0/all/0/1\">Ruiquan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yingbin Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jing Yang</a>",
          "description": "The general sequential decision-making problem, which includes Markov\ndecision processes (MDPs) and partially observable MDPs (POMDPs) as special\ncases, aims at maximizing a cumulative reward by making a sequence of decisions\nbased on a history of observations and actions over time. Recent studies have\nshown that the sequential decision-making problem is statistically learnable if\nit admits a low-rank structure modeled by predictive state representations\n(PSRs). Despite these advancements, existing approaches typically involve\noracles or steps that are not computationally efficient. On the other hand, the\nupper confidence bound (UCB) based approaches, which have served successfully\nas computationally efficient methods in bandits and MDPs, have not been\ninvestigated for more general PSRs, due to the difficulty of optimistic bonus\ndesign in these more challenging settings. This paper proposes the first known\nUCB-type approach for PSRs, featuring a novel bonus term that upper bounds the\ntotal variation distance between the estimated and true models. We further\ncharacterize the sample complexity bounds for our designed UCB-type algorithms\nfor both online and offline PSRs. In contrast to existing approaches for PSRs,\nour UCB-type algorithms enjoy computational efficiency, last-iterate guaranteed\nnear-optimal policy, and guaranteed model accuracy.",
          "link": "http://arxiv.org/abs/2307.00405",
          "publishedOn": "2023-07-22T00:55:25.565Z",
          "wordCount": null,
          "title": "Provably Efficient UCB-type Algorithms For Learning Predictive State Representations. (arXiv:2307.00405v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10644",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nielsen_F/0/1/0/all/0/1\">Frank Nielsen</a>",
          "description": "Data sets of multivariate normal distributions abound in many scientific\nareas like diffusion tensor imaging, structure tensor computer vision, radar\nsignal processing, machine learning, just to name a few. In order to process\nthose normal data sets for downstream tasks like filtering, classification or\nclustering, one needs to define proper notions of dissimilarities between\nnormals and paths joining them. The Fisher-Rao distance defined as the\nRiemannian geodesic distance induced by the Fisher information metric is such a\nprincipled metric distance which however is not known in closed-form excepts\nfor a few particular cases. In this work, we first report a fast and robust\nmethod to approximate arbitrarily finely the Fisher-Rao distance between\nmultivariate normal distributions. Second, we introduce a class of distances\nbased on diffeomorphic embeddings of the normal manifold into a submanifold of\nthe higher-dimensional symmetric positive-definite cone corresponding to the\nmanifold of centered normal distributions. We show that the projective Hilbert\ndistance on the cone yields a metric on the embedded normal submanifold and we\npullback that cone distance with its associated straight line Hilbert cone\ngeodesics to obtain a distance and smooth paths between normal distributions.\nCompared to the Fisher-Rao distance approximation, the pullback Hilbert cone\ndistance is computationally light since it requires to compute only the extreme\nminimal and maximal eigenvalues of matrices. Finally, we show how to use those\ndistances in clustering tasks.",
          "link": "http://arxiv.org/abs/2307.10644",
          "publishedOn": "2023-07-22T00:55:25.563Z",
          "wordCount": null,
          "title": "Fisher-Rao distance and pullback SPD cone distances between multivariate normal distributions. (arXiv:2307.10644v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lai_T/0/1/0/all/0/1\">Tin Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farid_F/0/1/0/all/0/1\">Farnaz Farid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bello_A/0/1/0/all/0/1\">Abubakar Bello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabrina_F/0/1/0/all/0/1\">Fariza Sabrina</a>",
          "description": "The Internet of Things (IoT) integrates more than billions of intelligent\ndevices over the globe with the capability of communicating with other\nconnected devices with little to no human intervention. IoT enables data\naggregation and analysis on a large scale to improve life quality in many\ndomains. In particular, data collected by IoT contain a tremendous amount of\ninformation for anomaly detection. The heterogeneous nature of IoT is both a\nchallenge and an opportunity for cybersecurity. Traditional approaches in\ncybersecurity monitoring often require different kinds of data pre-processing\nand handling for various data types, which might be problematic for datasets\nthat contain heterogeneous features. However, heterogeneous types of network\ndevices can often capture a more diverse set of signals than a single type of\ndevice readings, which is particularly useful for anomaly detection. In this\npaper, we present a comprehensive study on using ensemble machine learning\nmethods for enhancing IoT cybersecurity via anomaly detection. Rather than\nusing one single machine learning model, ensemble learning combines the\npredictive power from multiple models, enhancing their predictive accuracy in\nheterogeneous datasets rather than using one single machine learning model. We\npropose a unified framework with ensemble learning that utilises Bayesian\nhyperparameter optimisation to adapt to a network environment that contains\nmultiple IoT sensor readings. Experimentally, we illustrate their high\npredictive power when compared to traditional methods.",
          "link": "http://arxiv.org/abs/2307.10596",
          "publishedOn": "2023-07-22T00:55:25.546Z",
          "wordCount": null,
          "title": "Ensemble Learning based Anomaly Detection for IoT Cybersecurity via Bayesian Hyperparameters Sensitivity Analysis. (arXiv:2307.10596v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.08309",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chadebec_C/0/1/0/all/0/1\">Cl&#xe9;ment Chadebec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vincent_L/0/1/0/all/0/1\">Louis J. Vincent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allassonniere_S/0/1/0/all/0/1\">St&#xe9;phanie Allassonni&#xe8;re</a>",
          "description": "In recent years, deep generative models have attracted increasing interest\ndue to their capacity to model complex distributions. Among those models,\nvariational autoencoders have gained popularity as they have proven both to be\ncomputationally efficient and yield impressive results in multiple fields.\nFollowing this breakthrough, extensive research has been done in order to\nimprove the original publication, resulting in a variety of different VAE\nmodels in response to different tasks. In this paper we present Pythae, a\nversatile open-source Python library providing both a unified implementation\nand a dedicated framework allowing straightforward, reproducible and reliable\nuse of generative autoencoder models. We then propose to use this library to\nperform a case study benchmark where we present and compare 19 generative\nautoencoder models representative of some of the main improvements on\ndownstream tasks such as image reconstruction, generation, classification,\nclustering and interpolation. The open-source library can be found at\nhttps://github.com/clementchadebec/benchmark_VAE.",
          "link": "http://arxiv.org/abs/2206.08309",
          "publishedOn": "2023-07-22T00:55:25.545Z",
          "wordCount": null,
          "title": "Pythae: Unifying Generative Autoencoders in Python -- A Benchmarking Use Case. (arXiv:2206.08309v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10842",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bohdal_O/0/1/0/all/0/1\">Ondrej Bohdal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Da Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hospedales_T/0/1/0/all/0/1\">Timothy Hospedales</a>",
          "description": "Performance of a pre-trained semantic segmentation model is likely to\nsubstantially decrease on data from a new domain. We show a pre-trained model\ncan be adapted to unlabelled target domain data by calculating soft-label\nprototypes under the domain shift and making predictions according to the\nprototype closest to the vector with predicted class probabilities. The\nproposed adaptation procedure is fast, comes almost for free in terms of\ncomputational resources and leads to considerable performance improvements. We\ndemonstrate the benefits of such label calibration on the highly-practical\nsynthetic-to-real semantic segmentation problem.",
          "link": "http://arxiv.org/abs/2307.10842",
          "publishedOn": "2023-07-22T00:55:25.535Z",
          "wordCount": null,
          "title": "Label Calibration for Semantic Segmentation Under Domain Shift. (arXiv:2307.10842v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10459",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Konstantinov_A/0/1/0/all/0/1\">Andrei V. Konstantinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Utkin_L/0/1/0/all/0/1\">Lev V. Utkin</a>",
          "description": "A new computationally simple method of imposing hard convex constraints on\nthe neural network output values is proposed. The key idea behind the method is\nto map a vector of hidden parameters of the network to a point that is\nguaranteed to be inside the feasible set defined by a set of constraints. The\nmapping is implemented by the additional neural network layer with constraints\nfor output. The proposed method is simply extended to the case when constraints\nare imposed not only on the output vectors, but also on joint constraints\ndepending on inputs. The projection approach to imposing constraints on outputs\ncan simply be implemented in the framework of the proposed method. It is shown\nhow to incorporate different types of constraints into the proposed method,\nincluding linear and quadratic constraints, equality constraints, and dynamic\nconstraints, constraints in the form of boundaries. An important feature of the\nmethod is its computational simplicity. Complexities of the forward pass of the\nproposed neural network layer by linear and quadratic constraints are O(n*m)\nand O(n^2*m), respectively, where n is the number of variables, m is the number\nof constraints. Numerical experiments illustrate the method by solving\noptimization and classification problems. The code implementing the method is\npublicly available.",
          "link": "http://arxiv.org/abs/2307.10459",
          "publishedOn": "2023-07-22T00:55:25.473Z",
          "wordCount": null,
          "title": "A New Computationally Simple Approach for Implementing Neural Networks with Output Hard Constraints. (arXiv:2307.10459v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10536",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Rostami_M/0/1/0/all/0/1\">Mehdi Rostami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Saarela_O/0/1/0/all/0/1\">Olli Saarela</a>",
          "description": "Estimation of the Average Treatment Effect (ATE) is often carried out in 2\nsteps, wherein the first step, the treatment and outcome are modeled, and in\nthe second step the predictions are inserted into the ATE estimator. In the\nfirst steps, numerous models can be fit to the treatment and outcome, including\nusing machine learning algorithms. However, it is a difficult task to choose\namong the hyperparameter sets which will result in the best causal effect\nestimation and inference. Multiply Robust (MR) estimator allows us to leverage\nall the first-step models in a single estimator. We show that MR estimator is\n$n^r$ consistent if one of the first-step treatment or outcome models is $n^r$\nconsistent. We also show that MR is the solution to a broad class of estimating\nequations, and is asymptotically normal if one of the treatment models is\n$\\sqrt{n}$-consistent. The standard error of MR is also calculated which does\nnot require a knowledge of the true models in the first step. Our simulations\nstudy supports the theoretical findings.",
          "link": "http://arxiv.org/abs/2307.10536",
          "publishedOn": "2023-07-22T00:55:25.473Z",
          "wordCount": null,
          "title": "Multiply Robust Estimator Circumvents Hyperparameter Tuning of Neural Network Models in Causal Inference. (arXiv:2307.10536v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10736",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bolatov_A/0/1/0/all/0/1\">Arman Bolatov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tezekbayev_M/0/1/0/all/0/1\">Maxat Tezekbayev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melnykov_I/0/1/0/all/0/1\">Igor Melnykov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pak_A/0/1/0/all/0/1\">Artur Pak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikoulina_V/0/1/0/all/0/1\">Vassilina Nikoulina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Assylbekov_Z/0/1/0/all/0/1\">Zhenisbek Assylbekov</a>",
          "description": "We suggest a simple Gaussian mixture model for data generation that complies\nwith Feldman's long tail theory (2020). We demonstrate that a linear classifier\ncannot decrease the generalization error below a certain level in the proposed\nmodel, whereas a nonlinear classifier with a memorization capacity can. This\nconfirms that for long-tailed distributions, rare training examples must be\nconsidered for optimal generalization to new data. Finally, we show that the\nperformance gap between linear and nonlinear models can be lessened as the tail\nbecomes shorter in the subpopulation frequency distribution, as confirmed by\nexperiments on synthetic and real data.",
          "link": "http://arxiv.org/abs/2307.10736",
          "publishedOn": "2023-07-22T00:55:25.286Z",
          "wordCount": 604,
          "title": "Long-Tail Theory under Gaussian Mixtures. (arXiv:2307.10736v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10456",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Saif_M/0/1/0/all/0/1\">M. Ali Saif</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Mughalles_B/0/1/0/all/0/1\">Bassam M. Mughalles</a>",
          "description": "Recently, machine learning algorithms have been used remarkably to study the\nequilibrium phase transitions, however there are only a few works have been\ndone using this technique in the nonequilibrium phase transitions. In this\nwork, we use the supervised learning with the convolutional neural network\n(CNN) algorithm and unsupervised learning with the density-based spatial\nclustering of applications with noise (DBSCAN) algorithm to study the\nnonequilibrium phase transition in two models. We use CNN and DBSCAN in order\nto determine the critical points for directed bond percolation (bond DP) model\nand Domany-Kinzel cellular automaton (DK) model. Both models have been proven\nto have a nonequilibrium phase transition belongs to the directed percolation\n(DP) universality class. In the case of supervised learning we train CNN using\nthe images which are generated from Monte Carlo simulations of directed bond\npercolation. We use that trained CNN in studding the phase transition for the\ntwo models. In the case of unsupervised learning, we train DBSCAN using the raw\ndata of Monte Carlo simulations. In this case, we retrain DBSCAN at each time\nwe change the model or lattice size. Our results from both algorithms show\nthat, even for a very small values of lattice size, machine can predict the\ncritical points accurately for both models. Finally, we mention to that, the\nvalue of the critical point we find here for bond DP model using CNN or DBSCAN\nis exactly the same value that has been found using transfer learning with a\ndomain adversarial neural network (DANN) algorithm.",
          "link": "http://arxiv.org/abs/2307.10456",
          "publishedOn": "2023-07-22T00:55:24.590Z",
          "wordCount": null,
          "title": "Determination of the critical points for systems of directed percolation class using machine learning. (arXiv:2307.10456v1 [cond-mat.stat-mech])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10654",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Richman_R/0/1/0/all/0/1\">Ronald Richman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wuthrich_M/0/1/0/all/0/1\">Mario V. W&#xfc;thrich</a>",
          "description": "A very popular model-agnostic technique for explaining predictive models is\nthe SHapley Additive exPlanation (SHAP). The two most popular versions of SHAP\nare a conditional expectation version and an unconditional expectation version\n(the latter is also known as interventional SHAP). Except for tree-based\nmethods, usually the unconditional version is used (for computational reasons).\nWe provide a (surrogate) neural network approach which allows us to efficiently\ncalculate the conditional version for both neural networks and other regression\nmodels, and which properly considers the dependence structure in the feature\ncomponents. This proposal is also useful to provide drop1 and anova analyses in\ncomplex regression models which are similar to their generalized linear model\n(GLM) counterparts, and we provide a partial dependence plot (PDP) counterpart\nthat considers the right dependence structure in the feature components.",
          "link": "http://arxiv.org/abs/2307.10654",
          "publishedOn": "2023-07-22T00:55:24.590Z",
          "wordCount": null,
          "title": "Conditional expectation network for SHAP. (arXiv:2307.10654v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.03589",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Mousavi_Hosseini_A/0/1/0/all/0/1\">Alireza Mousavi-Hosseini</a>, <a href=\"http://arxiv.org/find/math/1/au:+Farghly_T/0/1/0/all/0/1\">Tyler Farghly</a>, <a href=\"http://arxiv.org/find/math/1/au:+He_Y/0/1/0/all/0/1\">Ye He</a>, <a href=\"http://arxiv.org/find/math/1/au:+Balasubramanian_K/0/1/0/all/0/1\">Krishnakumar Balasubramanian</a>, <a href=\"http://arxiv.org/find/math/1/au:+Erdogdu_M/0/1/0/all/0/1\">Murat A. Erdogdu</a>",
          "description": "Langevin diffusions are rapidly convergent under appropriate functional\ninequality assumptions. Hence, it is natural to expect that with additional\nsmoothness conditions to handle the discretization errors, their\ndiscretizations like the Langevin Monte Carlo (LMC) converge in a similar\nfashion. This research program was initiated by Vempala and Wibisono (2019),\nwho established results under log-Sobolev inequalities. Chewi et al. (2022)\nextended the results to handle the case of Poincar\\'e inequalities. In this\npaper, we go beyond Poincar\\'e inequalities, and push this research program to\nits limit. We do so by establishing upper and lower bounds for Langevin\ndiffusions and LMC under weak Poincar\\'e inequalities that are satisfied by a\nlarge class of densities including polynomially-decaying heavy-tailed densities\n(i.e., Cauchy-type). Our results explicitly quantify the effect of the\ninitializer on the performance of the LMC algorithm. In particular, we show\nthat as the tail goes from sub-Gaussian, to sub-exponential, and finally to\nCauchy-like, the dependency on the initial error goes from being logarithmic,\nto polynomial, and then finally to being exponential. This three-step phase\ntransition is in particular unavoidable as demonstrated by our lower bounds,\nclearly defining the boundaries of LMC.",
          "link": "http://arxiv.org/abs/2303.03589",
          "publishedOn": "2023-07-22T00:55:24.587Z",
          "wordCount": null,
          "title": "Towards a Complete Analysis of Langevin Monte Carlo: Beyond Poincar\\'e Inequality. (arXiv:2303.03589v2 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.10204",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oh_K/0/1/0/all/0/1\">Keisho Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nishimura_N/0/1/0/all/0/1\">Naoki Nishimura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_M/0/1/0/all/0/1\">Minje Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kobayashi_K/0/1/0/all/0/1\">Ken Kobayashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakata_K/0/1/0/all/0/1\">Kazuhide Nakata</a>",
          "description": "In modern recommendation systems, unbiased learning-to-rank (LTR) is crucial\nfor prioritizing items from biased implicit user feedback, such as click data.\nSeveral techniques, such as Inverse Propensity Weighting (IPW), have been\nproposed for single-sided markets. However, less attention has been paid to\ntwo-sided markets, such as job platforms or dating services, where successful\nconversions require matching preferences from both users. This paper addresses\nthe complex interaction of biases between users in two-sided markets and\nproposes a tailored LTR approach. We first present a formulation of feedback\nmechanisms in two-sided matching platforms and point out that their implicit\nfeedback may include position bias from both user groups. On the basis of this\nobservation, we extend the IPW estimator and propose a new estimator, named\ntwo-sided IPW, to address the position bases in two-sided markets. We prove\nthat the proposed estimator satisfies the unbiasedness for the ground-truth\nranking metric. We conducted numerical experiments on real-world two-sided\nplatforms and demonstrated the effectiveness of our proposed method in terms of\nboth precision and robustness. Our experiments showed that our method\noutperformed baselines especially when handling rare items, which are less\nfrequently observed in the training data.",
          "link": "http://arxiv.org/abs/2307.10204",
          "publishedOn": "2023-07-22T00:55:23.388Z",
          "wordCount": null,
          "title": "An IPW-based Unbiased Ranking Metric in Two-sided Markets. (arXiv:2307.10204v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.07989",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schulte_O/0/1/0/all/0/1\">Oliver Schulte</a>",
          "description": "This note describes a new approach to classifying graphs that leverages graph\ngenerative models (GGM). Assuming a GGM that defines a joint probability\ndistribution over graphs and their class labels, I derive classification\nformulas for the probability of a class label given a graph. A new conditional\nELBO can be used to train a generative graph auto-encoder model for\ndiscrimination. While leveraging generative models for classification has been\nwell explored for non-relational i.i.d. data, to our knowledge it is a novel\napproach to graph classification.",
          "link": "http://arxiv.org/abs/2302.07989",
          "publishedOn": "2023-07-22T00:55:22.856Z",
          "wordCount": 626,
          "title": "From Graph Generation to Graph Classification. (arXiv:2302.07989v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.11013",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Churchill_V/0/1/0/all/0/1\">Victor Churchill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiu_D/0/1/0/all/0/1\">Dongbin Xiu</a>",
          "description": "Flow map learning (FML), in conjunction with deep neural networks (DNNs), has\nshown promises for data driven modeling of unknown dynamical systems. A\nremarkable feature of FML is that it is capable of producing accurate\npredictive models for partially observed systems, even when their exact\nmathematical models do not exist. In this paper, we present an overview of the\nFML framework, along with the important computational details for its\nsuccessful implementation. We also present a set of well defined benchmark\nproblems for learning unknown dynamical systems. All the numerical details of\nthese problems are presented, along with their FML results, to ensure that the\nproblems are accessible for cross-examination and the results are reproducible.",
          "link": "http://arxiv.org/abs/2307.11013",
          "publishedOn": "2023-07-22T00:55:22.847Z",
          "wordCount": 637,
          "title": "Flow Map Learning for Unknown Dynamical Systems: Overview, Implementation, and Benchmarks. (arXiv:2307.11013v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10436",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Piyush_V/0/1/0/all/0/1\">Ved Piyush</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yan_Y/0/1/0/all/0/1\">Yuchen Yan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuzhen Zhou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yin_Y/0/1/0/all/0/1\">Yanbin Yin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ghosh_S/0/1/0/all/0/1\">Souparno Ghosh</a>",
          "description": "Deep Learners (DLs) are the state-of-art predictive mechanism with\napplications in many fields requiring complex high dimensional data processing.\nAlthough conventional DLs get trained via gradient descent with\nback-propagation, Kalman Filter (KF)-based techniques that do not need gradient\ncomputation have been developed to approximate DLs. We propose a multi-arm\nextension of a KF-based DL approximator that can mimic DL when the sample size\nis too small to train a multi-arm DL. The proposed Matrix Ensemble Kalman\nFilter-based multi-arm ANN (MEnKF-ANN) also performs explicit model stacking\nthat becomes relevant when the training sample has an unequal-size feature set.\nOur proposed technique can approximate Long Short-term Memory (LSTM) Networks\nand attach uncertainty to the predictions obtained from these LSTMs with\ndesirable coverage. We demonstrate how MEnKF-ANN can \"adequately\" approximate\nan LSTM network trained to classify what carbohydrate substrates are digested\nand utilized by a microbiome sample whose genomic sequences consist of\npolysaccharide utilization loci (PULs) and their encoded genes.",
          "link": "http://arxiv.org/abs/2307.10436",
          "publishedOn": "2023-07-22T00:55:22.786Z",
          "wordCount": 697,
          "title": "A Matrix Ensemble Kalman Filter-based Multi-arm Neural Network to Adequately Approximate Deep Neural Networks. (arXiv:2307.10436v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bohdal_O/0/1/0/all/0/1\">Ondrej Bohdal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Da Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hospedales_T/0/1/0/all/0/1\">Timothy Hospedales</a>",
          "description": "Source-free domain adaptation has become popular because of its practical\nusefulness and no need to access source data. However, the adaptation process\nstill takes a considerable amount of time and is predominantly based on\noptimization that relies on back-propagation. In this work we present a simple\nfeed-forward approach that challenges the need for back-propagation based\nadaptation. Our approach is based on computing prototypes of classes under the\ndomain shift using a pre-trained model. It achieves strong improvements in\naccuracy compared to the pre-trained model and requires only a small fraction\nof time of existing domain adaptation methods.",
          "link": "http://arxiv.org/abs/2307.10787",
          "publishedOn": "2023-07-22T00:55:22.779Z",
          "wordCount": 616,
          "title": "Feed-Forward Source-Free Domain Adaptation via Class Prototypes. (arXiv:2307.10787v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10865",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Girrbach_L/0/1/0/all/0/1\">Leander Girrbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christensen_A/0/1/0/all/0/1\">Anders Christensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winther_O/0/1/0/all/0/1\">Ole Winther</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akata_Z/0/1/0/all/0/1\">Zeynep Akata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koepke_A/0/1/0/all/0/1\">A. Sophia Koepke</a>",
          "description": "Neural Persistence is a prominent measure for quantifying neural network\ncomplexity, proposed in the emerging field of topological data analysis in deep\nlearning. In this work, however, we find both theoretically and empirically\nthat the variance of network weights and spatial concentration of large weights\nare the main factors that impact neural persistence. Whilst this captures\nuseful information for linear classifiers, we find that no relevant spatial\nstructure is present in later layers of deep neural networks, making neural\npersistence roughly equivalent to the variance of weights. Additionally, the\nproposed averaging procedure across layers for deep neural networks does not\nconsider interaction between layers. Based on our analysis, we propose an\nextension of the filtration underlying neural persistence to the whole neural\nnetwork instead of single layers, which is equivalent to calculating neural\npersistence on one particular matrix. This yields our deep graph persistence\nmeasure, which implicitly incorporates persistent paths through the network and\nalleviates variance-related issues through standardisation. Code is available\nat https://github.com/ExplainableML/Deep-Graph-Persistence .",
          "link": "http://arxiv.org/abs/2307.10865",
          "publishedOn": "2023-07-22T00:55:22.631Z",
          "wordCount": 684,
          "title": "Addressing caveats of neural persistence with deep graph persistence. (arXiv:2307.10865v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2111.03950",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Singh_R/0/1/0/all/0/1\">Rahul Singh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xu_L/0/1/0/all/0/1\">Liyuan Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1\">Arthur Gretton</a>",
          "description": "We propose simple nonparametric estimators for mediated and time-varying dose\nresponse curves based on kernel ridge regression. By embedding Pearl's\nmediation formula and Robins' g-formula with kernels, we allow treatments,\nmediators, and covariates to be continuous in general spaces, and also allow\nfor nonlinear treatment-confounder feedback. Our key innovation is a\nreproducing kernel Hilbert space technique called sequential kernel embedding,\nwhich we use to construct simple estimators for complex causal estimands. Our\nestimators preserve the generality of classic identification while also\nachieving nonasymptotic uniform rates. In nonlinear simulations with many\ncovariates, we demonstrate strong performance. We estimate mediated and\ntime-varying dose response curves of the US Job Corps, and clean data that may\nserve as a benchmark in future work. We extend our results to mediated and\ntime-varying treatment effects and counterfactual distributions, verifying\nsemiparametric efficiency and weak convergence.",
          "link": "http://arxiv.org/abs/2111.03950",
          "publishedOn": "2023-07-22T00:55:22.566Z",
          "wordCount": 737,
          "title": "Sequential Kernel Embedding for Mediated and Time-Varying Dose Response Curves. (arXiv:2111.03950v4 [stat.ME] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.11030",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dong_Y/0/1/0/all/0/1\">Yijun Dong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Miller_K/0/1/0/all/0/1\">Kevin Miller</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lei_Q/0/1/0/all/0/1\">Qi Lei</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ward_R/0/1/0/all/0/1\">Rachel Ward</a>",
          "description": "Despite the empirical success and practical significance of (relational)\nknowledge distillation that matches (the relations of) features between teacher\nand student models, the corresponding theoretical interpretations remain\nlimited for various knowledge distillation paradigms. In this work, we take an\ninitial step toward a theoretical understanding of relational knowledge\ndistillation (RKD), with a focus on semi-supervised classification problems. We\nstart by casting RKD as spectral clustering on a population-induced graph\nunveiled by a teacher model. Via a notion of clustering error that quantifies\nthe discrepancy between the predicted and ground truth clusterings, we\nillustrate that RKD over the population provably leads to low clustering error.\nMoreover, we provide a sample complexity bound for RKD with limited unlabeled\nsamples. For semi-supervised learning, we further demonstrate the label\nefficiency of RKD through a general framework of cluster-aware semi-supervised\nlearning that assumes low clustering errors. Finally, by unifying data\naugmentation consistency regularization into this cluster-aware framework, we\nshow that despite the common effect of learning accurate clusterings, RKD\nfacilitates a \"global\" perspective through spectral clustering, whereas\nconsistency regularization focuses on a \"local\" perspective via expansion.",
          "link": "http://arxiv.org/abs/2307.11030",
          "publishedOn": "2023-07-22T00:55:22.540Z",
          "wordCount": 686,
          "title": "Cluster-aware Semi-supervised Learning: Relational Knowledge Distillation Provably Learns Clustering. (arXiv:2307.11030v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.12658",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Wenxuan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1\">Xing Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kun Zhang</a>",
          "description": "To improve the uncertainty quantification of variance networks, we propose a\nnovel tree-structured local neural network model that partitions the feature\nspace into multiple regions based on uncertainty heterogeneity. A tree is built\nupon giving the training data, whose leaf nodes represent different regions\nwhere region-specific neural networks are trained to predict both the mean and\nthe variance for quantifying uncertainty. The proposed Uncertainty-Splitting\nNeural Regression Tree (USNRT) employs novel splitting criteria. At each node,\na neural network is trained on the full data first, and a statistical test for\nthe residuals is conducted to find the best split, corresponding to the two\nsub-regions with the most significant uncertainty heterogeneity between them.\nUSNRT is computationally friendly because very few leaf nodes are sufficient\nand pruning is unnecessary. Furthermore, an ensemble version can be easily\nconstructed to estimate the total uncertainty including the aleatory and\nepistemic. On extensive UCI datasets, USNRT or its ensemble shows superior\nperformance compared to some recent popular methods for quantifying uncertainty\nwith variances. Through comprehensive visualization and analysis, we uncover\nhow USNRT works and show its merits, revealing that uncertainty heterogeneity\ndoes exist in many datasets and can be learned by USNRT.",
          "link": "http://arxiv.org/abs/2212.12658",
          "publishedOn": "2023-07-22T00:55:22.533Z",
          "wordCount": 725,
          "title": "Improving Uncertainty Quantification of Variance Networks by Tree-Structured Learning. (arXiv:2212.12658v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10299",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Shen_X/0/1/0/all/0/1\">Xinwei Shen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Buhlmann_P/0/1/0/all/0/1\">Peter B&#xfc;hlmann</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Taeb_A/0/1/0/all/0/1\">Armeen Taeb</a>",
          "description": "Since distribution shifts are common in real-world applications, there is a\npressing need for developing prediction models that are robust against such\nshifts. Existing frameworks, such as empirical risk minimization or\ndistributionally robust optimization, either lack generalizability for unseen\ndistributions or rely on postulated distance measures. Alternatively, causality\noffers a data-driven and structural perspective to robust predictions. However,\nthe assumptions necessary for causal inference can be overly stringent, and the\nrobustness offered by such causal models often lacks flexibility. In this\npaper, we focus on causality-oriented robustness and propose Distributional\nRobustness via Invariant Gradients (DRIG), a method that exploits general\nadditive interventions in training data for robust predictions against unseen\ninterventions, and naturally interpolates between in-distribution prediction\nand causality. In a linear setting, we prove that DRIG yields predictions that\nare robust among a data-dependent class of distribution shifts. Furthermore, we\nshow that our framework includes anchor regression (Rothenh\\\"ausler et al.\\\n2021) as a special case, and that it yields prediction models that protect\nagainst more diverse perturbations. We extend our approach to the\nsemi-supervised domain adaptation setting to further improve prediction\nperformance. Finally, we empirically validate our methods on synthetic\nsimulations and on single-cell data.",
          "link": "http://arxiv.org/abs/2307.10299",
          "publishedOn": "2023-07-22T00:55:22.525Z",
          "wordCount": 689,
          "title": "Causality-oriented robustness: exploiting general additive interventions. (arXiv:2307.10299v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2102.03403",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Paul_D/0/1/0/all/0/1\">Debolina Paul</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chakraborty_S/0/1/0/all/0/1\">Saptarshi Chakraborty</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Das_S/0/1/0/all/0/1\">Swagatam Das</a>",
          "description": "Principal Component Analysis (PCA) is a fundamental tool for data\nvisualization, denoising, and dimensionality reduction. It is widely popular in\nStatistics, Machine Learning, Computer Vision, and related fields. However, PCA\nis well-known to fall prey to outliers and often fails to detect the true\nunderlying low-dimensional structure within the dataset. Following the Median\nof Means (MoM) philosophy, recent supervised learning methods have shown great\nsuccess in dealing with outlying observations without much compromise to their\nlarge sample theoretical properties. This paper proposes a PCA procedure based\non the MoM principle. Called the \\textbf{M}edian of \\textbf{M}eans\n\\textbf{P}rincipal \\textbf{C}omponent \\textbf{A}nalysis (MoMPCA), the proposed\nmethod is not only computationally appealing but also achieves optimal\nconvergence rates under minimal assumptions. In particular, we explore the\nnon-asymptotic error bounds of the obtained solution via the aid of the\nRademacher complexities while granting absolutely no assumption on the outlying\nobservations. The derived concentration results are not dependent on the\ndimension because the analysis is conducted in a separable Hilbert space, and\nthe results only depend on the fourth moment of the underlying distribution in\nthe corresponding norm. The proposal's efficacy is also thoroughly showcased\nthrough simulations and real data applications.",
          "link": "http://arxiv.org/abs/2102.03403",
          "publishedOn": "2023-07-22T00:55:22.518Z",
          "wordCount": 721,
          "title": "Robust Principal Component Analysis: A Median of Means Approach. (arXiv:2102.03403v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2207.12877",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aouad_A/0/1/0/all/0/1\">Ali Aouad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desir_A/0/1/0/all/0/1\">Antoine D&#xe9;sir</a>",
          "description": "Motivated by the successes of deep learning, we propose a class of neural\nnetwork-based discrete choice models, called RUMnets, inspired by the random\nutility maximization (RUM) framework. This model formulates the agents' random\nutility function using a sample average approximation. We show that RUMnets\nsharply approximate the class of RUM discrete choice models: any model derived\nfrom random utility maximization has choice probabilities that can be\napproximated arbitrarily closely by a RUMnet. Reciprocally, any RUMnet is\nconsistent with the RUM principle. We derive an upper bound on the\ngeneralization error of RUMnets fitted on choice data, and gain theoretical\ninsights on their ability to predict choices on new, unseen data depending on\ncritical parameters of the dataset and architecture. By leveraging open-source\nlibraries for neural networks, we find that RUMnets are competitive against\nseveral choice modeling and machine learning methods in terms of predictive\naccuracy on two real-world datasets.",
          "link": "http://arxiv.org/abs/2207.12877",
          "publishedOn": "2023-07-22T00:55:22.510Z",
          "wordCount": 679,
          "title": "Representing Random Utility Choice Models with Neural Networks. (arXiv:2207.12877v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2207.12395",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Negrea_J/0/1/0/all/0/1\">Jeffrey Negrea</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_J/0/1/0/all/0/1\">Jun Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Feng_H/0/1/0/all/0/1\">Haoyue Feng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Roy_D/0/1/0/all/0/1\">Daniel M. Roy</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huggins_J/0/1/0/all/0/1\">Jonathan H. Huggins</a>",
          "description": "The tuning of stochastic gradient algorithms (SGAs) for optimization and\nsampling is often based on heuristics and trial-and-error rather than\ngeneralizable theory. We address this theory--practice gap by characterizing\nthe large-sample statistical asymptotics of SGAs via a joint\nstep-size--sample-size scaling limit. We show that iterate averaging with a\nlarge fixed step size is robust to the choice of tuning parameters and\nasymptotically has covariance proportional to that of the MLE sampling\ndistribution. We also prove a Bernstein--von Mises-like theorem to guide\ntuning, including for generalized posteriors that are robust to model\nmisspecification. Numerical experiments validate our results and\nrecommendations in realistic finite-sample regimes. Our work lays the\nfoundation for a systematic analysis of other stochastic gradient Markov chain\nMonte Carlo algorithms for a wide range of models.",
          "link": "http://arxiv.org/abs/2207.12395",
          "publishedOn": "2023-07-22T00:55:22.482Z",
          "wordCount": 674,
          "title": "Tuning Stochastic Gradient Algorithms for Statistical Inference via Large-Sample Asymptotics. (arXiv:2207.12395v3 [stat.CO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abodo_F/0/1/0/all/0/1\">Franklin Abodo</a>",
          "description": "Traffic simulation software is used by transportation researchers and\nengineers to design and evaluate changes to roadways. These simulators are\ndriven by models of microscopic driver behavior from which macroscopic measures\nlike flow and congestion can be derived. Many models are designed for a subset\nof possible traffic scenarios and roadway configurations, while others have no\nexplicit constraints on their application. Work zones (WZs) are one scenario\nfor which no model to date has reproduced realistic driving behavior. This\nmakes it difficult to optimize for safety and other metrics when designing a\nWZ. The Federal Highway Administration commissioned the USDOT Volpe Center to\ndevelop a car-following (CF) model for use in microscopic simulators that can\ncapture and reproduce driver behavior accurately within and outside of WZs.\nVolpe also performed a naturalistic driving study to collect telematics data\nfrom vehicles driven on roads with WZs for use in model calibration. During\nmodel development, Volpe researchers observed difficulties in calibrating their\nmodel, leaving them to question whether there existed flaws in their model, in\nthe data, or in the procedure used to calibrate the model using the data. In\nthis thesis, I use Bayesian methods for data analysis and parameter estimation\nto explore and, where possible, address these questions. First, I use Bayesian\ninference to measure the sufficiency of the size of the data set. Second, I\ncompare the procedure and results of the genetic algorithm based calibration\nperformed by the Volpe researchers with those of Bayesian calibration. Third, I\nexplore the benefits of modeling CF hierarchically. Finally, I apply what was\nlearned in the first three phases using an established CF model, Wiedemann 99,\nto the probabilistic modeling of the Volpe model. Validation is performed using\ninformation criteria as an estimate of predictive accuracy.",
          "link": "http://arxiv.org/abs/2307.10437",
          "publishedOn": "2023-07-22T00:55:21.398Z",
          "wordCount": 821,
          "title": "A Bayesian Programming Approach to Car-following Model Calibration and Validation using Limited Data. (arXiv:2307.10437v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.10352",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tanguy_E/0/1/0/all/0/1\">Eloi Tanguy</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Flamary_R/0/1/0/all/0/1\">R&#xe9;mi Flamary</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Delon_J/0/1/0/all/0/1\">Julie Delon</a>",
          "description": "The Sliced Wasserstein (SW) distance has become a popular alternative to the\nWasserstein distance for comparing probability measures. Widespread\napplications include image processing, domain adaptation and generative\nmodelling, where it is common to optimise some parameters in order to minimise\nSW, which serves as a loss function between discrete probability measures\n(since measures admitting densities are numerically unattainable). All these\noptimisation problems bear the same sub-problem, which is minimising the Sliced\nWasserstein energy. In this paper we study the properties of $\\mathcal{E}: Y\n\\longmapsto \\mathrm{SW}_2^2(\\gamma_Y, \\gamma_Z)$, i.e. the SW distance between\ntwo uniform discrete measures with the same amount of points as a function of\nthe support $Y \\in \\mathbb{R}^{n \\times d}$ of one of the measures. We\ninvestigate the regularity and optimisation properties of this energy, as well\nas its Monte-Carlo approximation $\\mathcal{E}_p$ (estimating the expectation in\nSW using only $p$ samples) and show convergence results on the critical points\nof $\\mathcal{E}_p$ to those of $\\mathcal{E}$, as well as an almost-sure uniform\nconvergence. Finally, we show that in a certain sense, Stochastic Gradient\nDescent methods minimising $\\mathcal{E}$ and $\\mathcal{E}_p$ converge towards\n(Clarke) critical points of these energies.",
          "link": "http://arxiv.org/abs/2307.10352",
          "publishedOn": "2023-07-22T00:55:21.369Z",
          "wordCount": 688,
          "title": "Properties of Discrete Sliced Wasserstein Losses. (arXiv:2307.10352v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.09379",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Loukas_A/0/1/0/all/0/1\">Andreas Loukas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kessel_P/0/1/0/all/0/1\">Pan Kessel</a>",
          "description": "We study the generalization properties of batched predictors, i.e., models\ntasked with predicting the mean label of a small set (or batch) of examples.\nThe batched prediction paradigm is particularly relevant for models deployed to\ndetermine the quality of a group of compounds in preparation for offline\ntesting. By utilizing a suitable generalization of the Rademacher complexity,\nwe prove that batched predictors come with exponentially stronger\ngeneralization guarantees as compared to the standard per-sample approach.\nSurprisingly, the proposed bound holds independently of overparametrization.\nOur theoretical insights are validated experimentally for various tasks,\narchitectures, and applications.",
          "link": "http://arxiv.org/abs/2307.09379",
          "publishedOn": "2023-07-19T01:53:30.773Z",
          "wordCount": 584,
          "title": "Batched Predictors Generalize within Distribution. (arXiv:2307.09379v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yaoyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhongwang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Leyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Z/0/1/0/all/0/1\">Zhiwei Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_T/0/1/0/all/0/1\">Tao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhi-Qin John Xu</a>",
          "description": "We propose an optimistic estimate to evaluate the best possible fitting\nperformance of nonlinear models. It yields an optimistic sample size that\nquantifies the smallest possible sample size to fit/recover a target function\nusing a nonlinear model. We estimate the optimistic sample sizes for matrix\nfactorization models, deep models, and deep neural networks (DNNs) with\nfully-connected or convolutional architecture. For each nonlinear model, our\nestimates predict a specific subset of targets that can be fitted at\noverparameterization, which are confirmed by our experiments. Our optimistic\nestimate reveals two special properties of the DNN models -- free\nexpressiveness in width and costly expressiveness in connection. These\nproperties suggest the following architecture design principles of DNNs: (i)\nfeel free to add neurons/kernels; (ii) restrain from connecting neurons.\nOverall, our optimistic estimate theoretically unveils the vast potential of\nnonlinear models in fitting at overparameterization. Based on this framework,\nwe anticipate gaining a deeper understanding of how and why numerous nonlinear\nmodels such as DNNs can effectively realize their potential in practice in the\nnear future.",
          "link": "http://arxiv.org/abs/2307.08921",
          "publishedOn": "2023-07-19T01:53:29.923Z",
          "wordCount": 686,
          "title": "Optimistic Estimate Uncovers the Potential of Nonlinear Models. (arXiv:2307.08921v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08893",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yun_T/0/1/0/all/0/1\">Taedong Yun</a>",
          "description": "High-dimensional clinical data have become invaluable resources for genetic\nstudies, due to their accessibility in biobank-scale datasets and the\ndevelopment of high performance modeling techniques especially using deep\nlearning. Recent work has shown that low dimensional embeddings of these\nclinical data learned by variational autoencoders (VAE) can be used for\ngenome-wide association studies and polygenic risk prediction. In this work, we\nconsider multiple unsupervised learning methods for learning disentangled\nrepresentations, namely autoencoders, VAE, beta-VAE, and FactorVAE, in the\ncontext of genetic association studies. Using spirograms from UK Biobank as a\nrunning example, we observed improvements in the number of genome-wide\nsignificant loci, heritability, and performance of polygenic risk scores for\nasthma and chronic obstructive pulmonary disease by using FactorVAE or\nbeta-VAE, compared to standard VAE or non-variational autoencoders. FactorVAEs\nperformed effectively across multiple values of the regularization\nhyperparameter, while beta-VAEs were much more sensitive to the hyperparameter\nvalues.",
          "link": "http://arxiv.org/abs/2307.08893",
          "publishedOn": "2023-07-19T01:53:29.226Z",
          "wordCount": 677,
          "title": "Evaluating unsupervised disentangled representation learning for genomic discovery and disease risk prediction. (arXiv:2307.08893v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.09341",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Perello_C/0/1/0/all/0/1\">Carlos A. C. C. Perello</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Akyildiz_O/0/1/0/all/0/1\">&#xd6;mer Deniz Akyildiz</a>",
          "description": "We introduce a new class of adaptive importance samplers leveraging adaptive\noptimisation tools, which we term AdaOAIS. We build on Optimised Adaptive\nImportance Samplers (OAIS), a class of techniques that adapt proposals to\nimprove the mean-squared error of the importance sampling estimators by\nparameterising the proposal and optimising the $\\chi^2$-divergence between the\ntarget and the proposal. We show that a naive implementation of OAIS using\nstochastic gradient descent may lead to unstable estimators despite its\nconvergence guarantees. To remedy this shortcoming, we instead propose to use\nadaptive optimisers (such as AdaGrad and Adam) to improve the stability of the\nOAIS. We provide convergence results for AdaOAIS in a similar manner to OAIS.\nWe also provide empirical demonstration on a variety of examples and show that\nAdaOAIS lead to stable importance sampling estimators in practice.",
          "link": "http://arxiv.org/abs/2307.09341",
          "publishedOn": "2023-07-19T01:53:29.183Z",
          "wordCount": 659,
          "title": "Adaptively Optimised Adaptive Importance Samplers. (arXiv:2307.09341v1 [stat.CO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.08874",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mirjanic_V/0/1/0/all/0/1\">Vladimir V. Mirjani&#x107;</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Pascanu_R/0/1/0/all/0/1\">Razvan Pascanu</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Velickovic_P/0/1/0/all/0/1\">Petar Veli&#x10d;kovi&#x107;</a> (1 and 2) ((1) University of Cambridge, (2) Google DeepMind)",
          "description": "Neural Algorithmic Reasoning (NAR) is a research area focused on designing\nneural architectures that can reliably capture classical computation, usually\nby learning to execute algorithms. A typical approach is to rely on Graph\nNeural Network (GNN) architectures, which encode inputs in high-dimensional\nlatent spaces that are repeatedly transformed during the execution of the\nalgorithm. In this work we perform a detailed analysis of the structure of the\nlatent space induced by the GNN when executing algorithms. We identify two\npossible failure modes: (i) loss of resolution, making it hard to distinguish\nsimilar values; (ii) inability to deal with values outside the range observed\nduring training. We propose to solve the first issue by relying on a softmax\naggregator, and propose to decay the latent space in order to deal with\nout-of-range values. We show that these changes lead to improvements on the\nmajority of algorithms in the standard CLRS-30 benchmark when using the\nstate-of-the-art Triplet-GMPNN processor. Our code is available at\n\\href{https://github.com/mirjanic/nar-latent-spaces}{https://github.com/mirjanic/nar-latent-spaces}.",
          "link": "http://arxiv.org/abs/2307.08874",
          "publishedOn": "2023-07-19T01:53:29.030Z",
          "wordCount": null,
          "title": "Latent Space Representations of Neural Algorithmic Reasoners. (arXiv:2307.08874v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.16596",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chiu_C/0/1/0/all/0/1\">Chih-Yuan Chiu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kulkarni_K/0/1/0/all/0/1\">Kshitij Kulkarni</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sastry_S/0/1/0/all/0/1\">Shankar Sastry</a>",
          "description": "Causal phenomena associated with rare events occur across a wide range of\nengineering problems, such as risk-sensitive safety analysis, accident analysis\nand prevention, and extreme value theory. However, current methods for causal\ndiscovery are often unable to uncover causal links, between random variables in\na dynamic setting, that manifest only when the variables first experience\nlow-probability realizations. To address this issue, we introduce a novel\nstatistical independence test on data collected from time-invariant dynamical\nsystems in which rare but consequential events occur. In particular, we exploit\nthe time-invariance of the underlying data to construct a superimposed dataset\nof the system state before rare events happen at different timesteps. We then\ndesign a conditional independence test on the reorganized data. We provide\nnon-asymptotic sample complexity bounds for the consistency of our method, and\nvalidate its performance across various simulated and real-world datasets,\nincluding incident data collected from the Caltrans Performance Measurement\nSystem (PeMS). Code containing the datasets and experiments is publicly\navailable.",
          "link": "http://arxiv.org/abs/2211.16596",
          "publishedOn": "2023-07-19T01:53:28.985Z",
          "wordCount": null,
          "title": "Towards Dynamic Causal Discovery with Rare Events: A Nonparametric Conditional Independence Test. (arXiv:2211.16596v5 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09254",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sangdon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Taesoo Kim</a>",
          "description": "Uncertainty learning and quantification of models are crucial tasks to\nenhance the trustworthiness of the models. Importantly, the recent surge of\ngenerative language models (GLMs) emphasizes the need for reliable uncertainty\nquantification due to the concerns on generating hallucinated facts. In this\npaper, we propose to learn neural prediction set models that comes with the\nprobably approximately correct (PAC) guarantee for quantifying the uncertainty\nof GLMs. Unlike existing prediction set models, which are parameterized by a\nscalar value, we propose to parameterize prediction sets via neural networks,\nwhich achieves more precise uncertainty quantification but still satisfies the\nPAC guarantee. We demonstrate the efficacy of our method on four types of\nlanguage datasets and six types of models by showing that our method improves\nthe quantified uncertainty by $63\\%$ on average, compared to a standard\nbaseline method.",
          "link": "http://arxiv.org/abs/2307.09254",
          "publishedOn": "2023-07-19T01:53:28.922Z",
          "wordCount": null,
          "title": "PAC Neural Prediction Set Learning to Quantify the Uncertainty of Generative Language Models. (arXiv:2307.09254v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.10426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wilson_D/0/1/0/all/0/1\">Daniel Wilson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schirrmeister_R/0/1/0/all/0/1\">Robin Tibor Schirrmeister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gemein_L/0/1/0/all/0/1\">Lukas Alexander Wilhelm Gemein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ball_T/0/1/0/all/0/1\">Tonio Ball</a>",
          "description": "State-of-the-art performance in electroencephalography (EEG) decoding tasks\nis currently often achieved with either Deep-Learning (DL) or\nRiemannian-Geometry-based decoders (RBDs). Recently, there is growing interest\nin Deep Riemannian Networks (DRNs) possibly combining the advantages of both\nprevious classes of methods. However, there are still a range of topics where\nadditional insight is needed to pave the way for a more widespread application\nof DRNs in EEG. These include architecture design questions such as network\nsize and end-to-end ability.How these factors affect model performance has not\nbeen explored. Additionally, it is not clear how the data within these networks\nis transformed, and whether this would correlate with traditional EEG decoding.\nOur study aims to lay the groundwork in the area of these topics through the\nanalysis of DRNs for EEG with a wide range of hyperparameters. Networks were\ntested on two public EEG datasets and compared with state-of-the-art ConvNets.\nHere we propose end-to-end EEG SPDNet (EE(G)-SPDNet), and we show that this\nwide, end-to-end DRN can outperform the ConvNets, and in doing so use\nphysiologically plausible frequency regions. We also show that the end-to-end\napproach learns more complex filters than traditional band-pass filters\ntargeting the classical alpha, beta, and gamma frequency bands of the EEG, and\nthat performance can benefit from channel specific filtering approaches.\nAdditionally, architectural analysis revealed areas for further improvement due\nto the possible loss of Riemannian specific information throughout the network.\nOur study thus shows how to design and train DRNs to infer task-related\ninformation from the raw EEG without the need of handcrafted filterbanks and\nhighlights the potential of end-to-end DRNs such as EE(G)-SPDNet for\nhigh-performance EEG decoding.",
          "link": "http://arxiv.org/abs/2212.10426",
          "publishedOn": "2023-07-19T01:53:28.915Z",
          "wordCount": null,
          "title": "Deep Riemannian Networks for EEG Decoding. (arXiv:2212.10426v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09295",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Junwen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yifan Feng</a>",
          "description": "We study the problem of best-item identification from choice-based feedback.\nIn this problem, a company sequentially and adaptively shows display sets to a\npopulation of customers and collects their choices. The objective is to\nidentify the most preferred item with the least number of samples and at a high\nconfidence level. We propose an elimination-based algorithm, namely Nested\nElimination (NE), which is inspired by the nested structure implied by the\ninformation-theoretic lower bound. NE is simple in structure, easy to\nimplement, and has a strong theoretical guarantee for sample complexity.\nSpecifically, NE utilizes an innovative elimination criterion and circumvents\nthe need to solve any complex combinatorial optimization problem. We provide an\ninstance-specific and non-asymptotic bound on the expected sample complexity of\nNE. We also show NE achieves high-order worst-case asymptotic optimality.\nFinally, numerical experiments from both synthetic and real data corroborate\nour theoretical findings.",
          "link": "http://arxiv.org/abs/2307.09295",
          "publishedOn": "2023-07-19T01:53:28.914Z",
          "wordCount": null,
          "title": "Nested Elimination: A Simple Algorithm for Best-Item Identification from Choice-Based Feedback. (arXiv:2307.09295v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09077",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Mucciante_L/0/1/0/all/0/1\">Luca Mucciante</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Sancetta_A/0/1/0/all/0/1\">Alessio Sancetta</a>",
          "description": "A point process for event arrivals in high frequency trading is presented.\nThe intensity is the product of a Hawkes process and high dimensional functions\nof covariates derived from the order book. Conditions for stationarity of the\nprocess are stated. An algorithm is presented to estimate the model even in the\npresence of billions of data points, possibly mapping covariates into a high\ndimensional space. The large sample size can be common for high frequency data\napplications using multiple liquid instruments. Convergence of the algorithm is\nshown, consistency results under weak conditions is established, and a test\nstatistic to assess out of sample performance of different model specifications\nis suggested. The methodology is applied to the study of four stocks that trade\non the New York Stock Exchange (NYSE). The out of sample testing procedure\nsuggests that capturing the nonlinearity of the order book information adds\nvalue to the self exciting nature of high frequency trading events.",
          "link": "http://arxiv.org/abs/2307.09077",
          "publishedOn": "2023-07-19T01:53:28.911Z",
          "wordCount": null,
          "title": "Estimation of an Order Book Dependent Hawkes Process for Large Datasets. (arXiv:2307.09077v1 [q-fin.TR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08846",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_N/0/1/0/all/0/1\">Ngoc-Ty Nguyen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Phillips_P/0/1/0/all/0/1\">P. Jonathon Phillips</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tang_L/0/1/0/all/0/1\">Larry Tang</a>",
          "description": "Ordinal scores occur commonly in medical imaging studies and in black-box\nforensic studies \\citep{Phillips:2018}. To assess the accuracy of raters in the\nstudies, one needs to estimate the receiver operating characteristic (ROC)\ncurve while accounting for covariates of raters. In this paper, we propose a\ncovariate-adjusted homogeneity test to determine differences in accuracy among\nmultiple rater groups. We derived the theoretical results of the proposed test\nand conducted extensive simulation studies to evaluate the finite sample\nperformance of the proposed test. Our proposed test is applied to a face\nrecognition study to identify statistically significant differences among five\nparticipant groups.",
          "link": "http://arxiv.org/abs/2307.08846",
          "publishedOn": "2023-07-19T01:53:28.909Z",
          "wordCount": null,
          "title": "A Covariate-Adjusted Homogeneity Test with Application to Facial Recognition Accuracy Assessment. (arXiv:2307.08846v1 [stat.AP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09057",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ryner_M/0/1/0/all/0/1\">Martin Ryner</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kronqvist_J/0/1/0/all/0/1\">Jan Kronqvist</a>, <a href=\"http://arxiv.org/find/math/1/au:+Karlsson_J/0/1/0/all/0/1\">Johan Karlsson</a>",
          "description": "This paper presents a framework for computing the Gromov-Wasserstein problem\nbetween two sets of points in low dimensional spaces, where the discrepancy is\nthe squared Euclidean norm. The Gromov-Wasserstein problem is a generalization\nof the optimal transport problem that finds the assignment between two sets\npreserving pairwise distances as much as possible. This can be used to quantify\nthe similarity between two formations or shapes, a common problem in AI and\nmachine learning. The problem can be formulated as a Quadratic Assignment\nProblem (QAP), which is in general computationally intractable even for small\nproblems. Our framework addresses this challenge by reformulating the QAP as an\noptimization problem with a low-dimensional domain, leveraging the fact that\nthe problem can be expressed as a concave quadratic optimization problem with\nlow rank. The method scales well with the number of points, and it can be used\nto find the global solution for large-scale problems with thousands of points.\nWe compare the computational complexity of our approach with state-of-the-art\nmethods on synthetic problems and apply it to a near-symmetrical problem which\nis of particular interest in computational biology.",
          "link": "http://arxiv.org/abs/2307.09057",
          "publishedOn": "2023-07-19T01:53:28.861Z",
          "wordCount": null,
          "title": "Globally solving the Gromov-Wasserstein problem for point clouds in low dimensional Euclidean spaces. (arXiv:2307.09057v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16189",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Siahkoohi_A/0/1/0/all/0/1\">Ali Siahkoohi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morel_R/0/1/0/all/0/1\">Rudy Morel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balestriero_R/0/1/0/all/0/1\">Randall Balestriero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allys_E/0/1/0/all/0/1\">Erwan Allys</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sainton_G/0/1/0/all/0/1\">Gr&#xe9;gory Sainton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawamura_T/0/1/0/all/0/1\">Taichi Kawamura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoop_M/0/1/0/all/0/1\">Maarten V. de Hoop</a>",
          "description": "Unsupervised source separation involves unraveling an unknown set of source\nsignals recorded through a mixing operator, with limited prior knowledge about\nthe sources, and only access to a dataset of signal mixtures. This problem is\ninherently ill-posed and is further challenged by the variety of time-scales\nexhibited by sources in time series data. Existing methods typically rely on a\npreselected window size that limits their capacity to handle multi-scale\nsources. To address this issue, instead of operating in the time domain, we\npropose an unsupervised multi-scale clustering and source separation framework\nby leveraging wavelet scattering covariances that provide a low-dimensional\nrepresentation of stochastic processes, capable of distinguishing between\ndifferent non-Gaussian stochastic processes. Nested within this representation\nspace, we develop a factorial Gaussian-mixture variational autoencoder that is\ntrained to (1) probabilistically cluster sources at different time-scales and\n(2) independently sample scattering covariance representations associated with\neach cluster. Using samples from each cluster as prior information, we\nformulate source separation as an optimization problem in the wavelet\nscattering covariance representation space, resulting in separated sources in\nthe time domain. When applied to seismic data recorded during the NASA InSight\nmission on Mars, our multi-scale nested approach proves to be a powerful tool\nfor discriminating between sources varying greatly in time-scale, e.g.,\nminute-long transient one-sided pulses (known as ``glitches'') and structured\nambient noises resulting from atmospheric activities that typically last for\ntens of minutes. These results provide an opportunity to conduct further\ninvestigations into the isolated sources related to atmospheric-surface\ninteractions, thermal relaxations, and other complex phenomena.",
          "link": "http://arxiv.org/abs/2305.16189",
          "publishedOn": "2023-07-19T01:53:28.834Z",
          "wordCount": null,
          "title": "Martian time-series unraveled: A multi-scale nested approach with factorial variational autoencoders. (arXiv:2305.16189v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.14568",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Dey_B/0/1/0/all/0/1\">Biprateep Dey</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhao_D/0/1/0/all/0/1\">David Zhao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Newman_J/0/1/0/all/0/1\">Jeffrey A. Newman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Andrews_B/0/1/0/all/0/1\">Brett H. Andrews</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Izbicki_R/0/1/0/all/0/1\">Rafael Izbicki</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_A/0/1/0/all/0/1\">Ann B. Lee</a>",
          "description": "Uncertainty quantification is crucial for assessing the predictive ability of\nAI algorithms. Much research has been devoted to describing the predictive\ndistribution (PD) $F(y|\\mathbf{x})$ of a target variable $y \\in \\mathbb{R}$\ngiven complex input features $\\mathbf{x} \\in \\mathcal{X}$. However,\noff-the-shelf PDs (from, e.g., normalizing flows and Bayesian neural networks)\noften lack conditional calibration with the probability of occurrence of an\nevent given input $\\mathbf{x}$ being significantly different from the predicted\nprobability. Current calibration methods do not fully assess and enforce\nconditionally calibrated PDs. Here we propose \\texttt{Cal-PIT}, a method that\naddresses both PD diagnostics and recalibration by learning a single\nprobability-probability map from calibration data. The key idea is to regress\nprobability integral transform scores against $\\mathbf{x}$. The estimated\nregression provides interpretable diagnostics of conditional coverage across\nthe feature space. The same regression function morphs the misspecified PD to a\nre-calibrated PD for all $\\mathbf{x}$. We benchmark our corrected prediction\nbands (a by-product of corrected PDs) against oracle bands and state-of-the-art\npredictive inference algorithms for synthetic data. We also provide results for\ntwo applications: (i) probabilistic nowcasting given sequences of satellite\nimages, and (ii) conditional density estimation of galaxy distances given\nimaging data (so-called photometric redshift estimation). Our code is available\nas a Python package https://github.com/lee-group-cmu/Cal-PIT .",
          "link": "http://arxiv.org/abs/2205.14568",
          "publishedOn": "2023-07-19T01:53:28.821Z",
          "wordCount": null,
          "title": "Conditionally Calibrated Predictive Distributions by Probability-Probability Map: Application to Galaxy Redshift Estimation and Probabilistic Forecasting. (arXiv:2205.14568v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.11997",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hamman_F/0/1/0/all/0/1\">Faisal Hamman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Noorani_E/0/1/0/all/0/1\">Erfaun Noorani</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mishra_S/0/1/0/all/0/1\">Saumitra Mishra</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Magazzeni_D/0/1/0/all/0/1\">Daniele Magazzeni</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dutta_S/0/1/0/all/0/1\">Sanghamitra Dutta</a>",
          "description": "There is an emerging interest in generating robust counterfactual\nexplanations that would remain valid if the model is updated or changed even\nslightly. Towards finding robust counterfactuals, existing literature often\nassumes that the original model $m$ and the new model $M$ are bounded in the\nparameter space, i.e., $\\|\\text{Params}(M){-}\\text{Params}(m)\\|{<}\\Delta$.\nHowever, models can often change significantly in the parameter space with\nlittle to no change in their predictions or accuracy on the given dataset. In\nthis work, we introduce a mathematical abstraction termed\n\\emph{naturally-occurring} model change, which allows for arbitrary changes in\nthe parameter space such that the change in predictions on points that lie on\nthe data manifold is limited. Next, we propose a measure -- that we call\n\\emph{Stability} -- to quantify the robustness of counterfactuals to potential\nmodel changes for differentiable models, e.g., neural networks. Our main\ncontribution is to show that counterfactuals with sufficiently high value of\n\\emph{Stability} as defined by our measure will remain valid after potential\n``naturally-occurring'' model changes with high probability (leveraging\nconcentration bounds for Lipschitz function of independent Gaussians). Since\nour quantification depends on the local Lipschitz constant around a data point\nwhich is not always available, we also examine practical relaxations of our\nproposed measure and demonstrate experimentally how they can be incorporated to\nfind robust counterfactuals for neural networks that are close, realistic, and\nremain valid after potential model changes. This work also has interesting\nconnections with model multiplicity, also known as, the Rashomon effect.",
          "link": "http://arxiv.org/abs/2305.11997",
          "publishedOn": "2023-07-19T01:53:28.768Z",
          "wordCount": null,
          "title": "Robust Counterfactual Explanations for Neural Networks With Probabilistic Guarantees. (arXiv:2305.11997v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09366",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Behdin_K/0/1/0/all/0/1\">Kayhan Behdin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazumder_R/0/1/0/all/0/1\">Rahul Mazumder</a>",
          "description": "We consider the problem of learning a sparse graph underlying an undirected\nGaussian graphical model, a key problem in statistical machine learning. Given\n$n$ samples from a multivariate Gaussian distribution with $p$ variables, the\ngoal is to estimate the $p \\times p$ inverse covariance matrix (aka precision\nmatrix), assuming it is sparse (i.e., has a few nonzero entries). We propose\nGraphL0BnB, a new estimator based on an $\\ell_0$-penalized version of the\npseudolikelihood function, while most earlier approaches are based on the\n$\\ell_1$-relaxation. Our estimator can be formulated as a convex mixed integer\nprogram (MIP) which can be difficult to compute at scale using off-the-shelf\ncommercial solvers. To solve the MIP, we propose a custom nonlinear\nbranch-and-bound (BnB) framework that solves node relaxations with tailored\nfirst-order methods. As a by-product of our BnB framework, we propose\nlarge-scale solvers for obtaining good primal solutions that are of independent\ninterest. We derive novel statistical guarantees (estimation and variable\nselection) for our estimator and discuss how our approach improves upon\nexisting estimators. Our numerical experiments on real/synthetic datasets\nsuggest that our method can solve, to near-optimality, problem instances with\n$p = 10^4$ -- corresponding to a symmetric matrix of size $p \\times p$ with\n$p^2/2$ binary variables. We demonstrate the usefulness of GraphL0BnB versus\nvarious state-of-the-art approaches on a range of datasets.",
          "link": "http://arxiv.org/abs/2307.09366",
          "publishedOn": "2023-07-19T01:53:28.752Z",
          "wordCount": null,
          "title": "Sparse Gaussian Graphical Models with Discrete Optimization: Computational and Statistical Perspectives. (arXiv:2307.09366v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.12906",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weber_R/0/1/0/all/0/1\">Romann M. Weber</a>",
          "description": "Implicit generative modeling (IGM) aims to produce samples of synthetic data\nmatching the characteristics of a target data distribution. Recent work (e.g.\nscore-matching networks, diffusion models) has approached the IGM problem from\nthe perspective of pushing synthetic source data toward the target distribution\nvia dynamical perturbations or flows in the ambient space. In this direction,\nwe present the score difference (SD) between arbitrary target and source\ndistributions as a flow that optimally reduces the Kullback-Leibler divergence\nbetween them while also solving the Schroedinger bridge problem. We apply the\nSD flow to convenient proxy distributions, which are aligned if and only if the\noriginal distributions are aligned. We demonstrate the formal equivalence of\nthis formulation to denoising diffusion models under certain conditions. We\nalso show that the training of generative adversarial networks includes a\nhidden data-optimization sub-problem, which induces the SD flow under certain\nchoices of loss function when the discriminator is optimal. As a result, the SD\nflow provides a theoretical link between model classes that individually\naddress the three challenges of the \"generative modeling trilemma\" -- high\nsample quality, mode coverage, and fast sampling -- thereby setting the stage\nfor a unified approach.",
          "link": "http://arxiv.org/abs/2304.12906",
          "publishedOn": "2023-07-19T01:53:28.740Z",
          "wordCount": null,
          "title": "The Score-Difference Flow for Implicit Generative Modeling. (arXiv:2304.12906v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09093",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghoorchian_S/0/1/0/all/0/1\">Saeed Ghoorchian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maghsudi_S/0/1/0/all/0/1\">Setareh Maghsudi</a>",
          "description": "Sequential decision-making under uncertainty is often associated with long\nfeedback delays. Such delays degrade the performance of the learning agent in\nidentifying a subset of arms with the optimal collective reward in the long\nrun. This problem becomes significantly challenging in a non-stationary\nenvironment with structural dependencies amongst the reward distributions\nassociated with the arms. Therefore, besides adapting to delays and\nenvironmental changes, learning the causal relations alleviates the adverse\neffects of feedback delay on the decision-making process. We formalize the\ndescribed setting as a non-stationary and delayed combinatorial semi-bandit\nproblem with causally related rewards. We model the causal relations by a\ndirected graph in a stationary structural equation model. The agent maximizes\nthe long-term average payoff, defined as a linear function of the base arms'\nrewards. We develop a policy that learns the structural dependencies from\ndelayed feedback and utilizes that to optimize the decision-making while\nadapting to drifts. We prove a regret bound for the performance of the proposed\nalgorithm. Besides, we evaluate our method via numerical analysis using\nsynthetic and real-world datasets to detect the regions that contribute the\nmost to the spread of Covid-19 in Italy.",
          "link": "http://arxiv.org/abs/2307.09093",
          "publishedOn": "2023-07-19T01:53:28.715Z",
          "wordCount": null,
          "title": "Non-stationary Delayed Combinatorial Semi-Bandit with Causally Related Rewards. (arXiv:2307.09093v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.12765",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jain_M/0/1/0/all/0/1\">Moksh Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raparthy_S/0/1/0/all/0/1\">Sharath Chandra Raparthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Garcia_A/0/1/0/all/0/1\">Alex Hernandez-Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rector_Brooks_J/0/1/0/all/0/1\">Jarrid Rector-Brooks</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miret_S/0/1/0/all/0/1\">Santiago Miret</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_E/0/1/0/all/0/1\">Emmanuel Bengio</a>",
          "description": "We study the problem of generating diverse candidates in the context of\nMulti-Objective Optimization. In many applications of machine learning such as\ndrug discovery and material design, the goal is to generate candidates which\nsimultaneously optimize a set of potentially conflicting objectives. Moreover,\nthese objectives are often imperfect evaluations of some underlying property of\ninterest, making it important to generate diverse candidates to have multiple\noptions for expensive downstream evaluations. We propose Multi-Objective\nGFlowNets (MOGFNs), a novel method for generating diverse Pareto optimal\nsolutions, based on GFlowNets. We introduce two variants of MOGFNs: MOGFN-PC,\nwhich models a family of independent sub-problems defined by a scalarization\nfunction, with reward-conditional GFlowNets, and MOGFN-AL, which solves a\nsequence of sub-problems defined by an acquisition function in an active\nlearning loop. Our experiments on wide variety of synthetic and benchmark tasks\ndemonstrate advantages of the proposed methods in terms of the Pareto\nperformance and importantly, improved candidate diversity, which is the main\ncontribution of this work.",
          "link": "http://arxiv.org/abs/2210.12765",
          "publishedOn": "2023-07-19T01:53:28.668Z",
          "wordCount": null,
          "title": "Multi-Objective GFlowNets. (arXiv:2210.12765v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09055",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wu_T/0/1/0/all/0/1\">Tong Wu</a>",
          "description": "Low-rank tensor analysis has received widespread attention with many\npractical applications. However, the tensor data are often contaminated by\noutliers or sample-specific corruptions. How to recover the tensor data that\nare corrupted by outliers and perform data clustering remains a challenging\nproblem. This paper develops an outlier-robust tensor low-rank representation\n(OR-TLRR) method for simultaneous outlier detection and tensor data clustering\nbased on the tensor singular value decomposition (t-SVD) algebraic framework.\nIt is motivated by the recently proposed tensor-tensor product induced by\ninvertible linear transforms that satisfy certain conditions. For tensor\nobservations with arbitrary outlier corruptions, OR-TLRR has provable\nperformance guarantee for exactly recovering the row space of clean data and\ndetecting outliers under mild conditions. Moreover, an extension of OR-TLRR is\nalso proposed to handle the case when parts of the data are missing. Finally,\nextensive experimental results on both synthetic and real data demonstrate the\neffectiveness of the proposed algorithms.",
          "link": "http://arxiv.org/abs/2307.09055",
          "publishedOn": "2023-07-19T01:53:28.507Z",
          "wordCount": null,
          "title": "Outlier-Robust Tensor Low-Rank Representation for Data Clustering. (arXiv:2307.09055v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09025",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Cao_H/0/1/0/all/0/1\">Hanyan Cao</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Pan_F/0/1/0/all/0/1\">Feng Pan</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Wang_Y/0/1/0/all/0/1\">Yijia Wang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Zhang_P/0/1/0/all/0/1\">Pan Zhang</a>",
          "description": "We propose a general framework for decoding quantum error-correcting codes\nwith generative modeling. The model utilizes autoregressive neural networks,\nspecifically Transformers, to learn the joint probability of logical operators\nand syndromes. This training is in an unsupervised way, without the need for\nlabeled training data, and is thus referred to as pre-training. After the\npre-training, the model can efficiently compute the likelihood of logical\noperators for any given syndrome, using maximum likelihood decoding. It can\ndirectly generate the most-likely logical operators with computational\ncomplexity $\\mathcal O(2k)$ in the number of logical qubits $k$, which is\nsignificantly better than the conventional maximum likelihood decoding\nalgorithms that require $\\mathcal O(4^k)$ computation. Based on the pre-trained\nmodel, we further propose refinement to achieve more accurately the likelihood\nof logical operators for a given syndrome by directly sampling the stabilizer\noperators. We perform numerical experiments on stabilizer codes with small code\ndistances, using both depolarizing error models and error models with\ncorrelated noise. The results show that our approach provides significantly\nbetter decoding accuracy than the minimum weight perfect matching and\nbelief-propagation-based algorithms. Our framework is general and can be\napplied to any error model and quantum codes with different topologies such as\nsurface codes and quantum LDPC codes. Furthermore, it leverages the\nparallelization capabilities of GPUs, enabling simultaneous decoding of a large\nnumber of syndromes. Our approach sheds light on the efficient and accurate\ndecoding of quantum error-correcting codes using generative artificial\nintelligence and modern computational power.",
          "link": "http://arxiv.org/abs/2307.09025",
          "publishedOn": "2023-07-19T01:53:28.502Z",
          "wordCount": null,
          "title": "qecGPT: decoding Quantum Error-correcting Codes with Generative Pre-trained Transformers. (arXiv:2307.09025v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsitsulin_A/0/1/0/all/0/1\">Anton Tsitsulin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Munkhoeva_M/0/1/0/all/0/1\">Marina Munkhoeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perozzi_B/0/1/0/all/0/1\">Bryan Perozzi</a>",
          "description": "Unsupervised learning has recently significantly gained in popularity,\nespecially with deep learning-based approaches. Despite numerous successes and\napproaching supervised-level performance on a variety of academic benchmarks,\nit is still hard to train and evaluate SSL models in practice due to the\nunsupervised nature of the problem. Even with networks trained in a supervised\nfashion, it is often unclear whether they will perform well when transferred to\nanother domain.\n\nPast works are generally limited to assessing the amount of information\ncontained in embeddings, which is most relevant for self-supervised learning of\ndeep neural networks. This works chooses to follow a different approach: can we\nquantify how easy it is to linearly separate the data in a stable way? We\nsurvey the literature and uncover three methods that could be potentially used\nfor evaluating quality of representations. We also introduce one novel method\nbased on recent advances in understanding the high-dimensional geometric\nstructure of self-supervised learning.\n\nWe conduct extensive experiments and study the properties of these metrics\nand ones introduced in the previous work. Our results suggest that while there\nis no free lunch, there are metrics that can robustly estimate embedding\nquality in an unsupervised way.",
          "link": "http://arxiv.org/abs/2305.16562",
          "publishedOn": "2023-07-19T01:53:28.500Z",
          "wordCount": null,
          "title": "Unsupervised Embedding Quality Evaluation. (arXiv:2305.16562v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.13556",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haghifam_M/0/1/0/all/0/1\">Mahdi Haghifam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_Galvez_B/0/1/0/all/0/1\">Borja Rodr&#xed;guez-G&#xe1;lvez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thobaben_R/0/1/0/all/0/1\">Ragnar Thobaben</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skoglund_M/0/1/0/all/0/1\">Mikael Skoglund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_D/0/1/0/all/0/1\">Daniel M. Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dziugaite_G/0/1/0/all/0/1\">Gintare Karolina Dziugaite</a>",
          "description": "To date, no \"information-theoretic\" frameworks for reasoning about\ngeneralization error have been shown to establish minimax rates for gradient\ndescent in the setting of stochastic convex optimization. In this work, we\nconsider the prospect of establishing such rates via several existing\ninformation-theoretic frameworks: input-output mutual information bounds,\nconditional mutual information bounds and variants, PAC-Bayes bounds, and\nrecent conditional variants thereof. We prove that none of these bounds are\nable to establish minimax rates. We then consider a common tactic employed in\nstudying gradient methods, whereby the final iterate is corrupted by Gaussian\nnoise, producing a noisy \"surrogate\" algorithm. We prove that minimax rates\ncannot be established via the analysis of such surrogates. Our results suggest\nthat new ideas are required to analyze gradient descent using\ninformation-theoretic techniques.",
          "link": "http://arxiv.org/abs/2212.13556",
          "publishedOn": "2023-07-19T01:53:28.471Z",
          "wordCount": null,
          "title": "Limitations of Information-Theoretic Generalization Bounds for Gradient Descent Methods in Stochastic Convex Optimization. (arXiv:2212.13556v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2207.13656",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ajroldi_N/0/1/0/all/0/1\">Niccol&#xf2; Ajroldi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Diquigiovanni_J/0/1/0/all/0/1\">Jacopo Diquigiovanni</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fontana_M/0/1/0/all/0/1\">Matteo Fontana</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vantini_S/0/1/0/all/0/1\">Simone Vantini</a>",
          "description": "Time evolving surfaces can be modeled as two-dimensional Functional time\nseries, exploiting the tools of Functional data analysis. Leveraging this\napproach, a forecasting framework for such complex data is developed. The main\nfocus revolves around Conformal Prediction, a versatile nonparametric paradigm\nused to quantify uncertainty in prediction problems. Building upon recent\nvariations of Conformal Prediction for Functional time series, a probabilistic\nforecasting scheme for two-dimensional functional time series is presented,\nwhile providing an extension of Functional Autoregressive Processes of order\none to this setting. Estimation techniques for the latter process are\nintroduced and their performance are compared in terms of the resulting\nprediction regions. Finally, the proposed forecasting procedure and the\nuncertainty quantification technique are applied to a real dataset, collecting\ndaily observations of Sea Level Anomalies of the Black Sea",
          "link": "http://arxiv.org/abs/2207.13656",
          "publishedOn": "2023-07-19T01:53:28.449Z",
          "wordCount": null,
          "title": "Conformal Prediction Bands for Two-Dimensional Functional Time Series. (arXiv:2207.13656v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09423",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tuyls_J/0/1/0/all/0/1\">Jens Tuyls</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madeka_D/0/1/0/all/0/1\">Dhruv Madeka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torkkola_K/0/1/0/all/0/1\">Kari Torkkola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1\">Dean Foster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1\">Karthik Narasimhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1\">Sham Kakade</a>",
          "description": "Imitation Learning (IL) is one of the most widely used methods in machine\nlearning. Yet, while powerful, many works find it is often not able to fully\nrecover the underlying expert behavior. However, none of these works deeply\ninvestigate the role of scaling up the model and data size. Inspired by recent\nwork in Natural Language Processing (NLP) where \"scaling up\" has resulted in\nincreasingly more capable LLMs, we investigate whether carefully scaling up\nmodel and data size can bring similar improvements in the imitation learning\nsetting. To demonstrate our findings, we focus on the game of NetHack, a\nchallenging environment featuring procedural generation, stochasticity,\nlong-term dependencies, and partial observability. We find IL loss and mean\nreturn scale smoothly with the compute budget and are strongly correlated,\nresulting in power laws for training compute-optimal IL agents with respect to\nmodel size and number of samples. We forecast and train several NetHack agents\nwith IL and find they outperform prior state-of-the-art by at least 2x in all\nsettings. Our work both demonstrates the scaling behavior of imitation learning\nin a challenging domain, as well as the viability of scaling up current\napproaches for increasingly capable agents in NetHack, a game that remains\nelusively hard for current AI systems.",
          "link": "http://arxiv.org/abs/2307.09423",
          "publishedOn": "2023-07-19T01:53:28.404Z",
          "wordCount": null,
          "title": "Scaling Laws for Imitation Learning in NetHack. (arXiv:2307.09423v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.06825",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kong_F/0/1/0/all/0/1\">Fang Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Canzhe Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuai Li</a>",
          "description": "The linear bandit problem has been studied for many years in both stochastic\nand adversarial settings. Designing an algorithm that can optimize the\nenvironment without knowing the loss type attracts lots of interest.\n\\citet{LeeLWZ021} propose an algorithm that actively detects the loss type and\nthen switches between different algorithms specially designed for specific\nsettings. However, such an approach requires meticulous designs to perform well\nin all environments. Follow-the-regularized-leader (FTRL) is another type of\npopular algorithm that can adapt to different environments. This algorithm is\nof simple design and the regret bounds are shown to be optimal in traditional\nmulti-armed bandit problems compared with the detect-switch type. Designing an\nFTRL-type algorithm for linear bandits is an important question that has been\nopen for a long time. In this paper, we prove that the FTRL algorithm with a\nnegative entropy regularizer can achieve the best-of-three-world results for\nthe linear bandit problem. Our regret bounds achieve the same or nearly the\nsame order as the previous detect-switch type algorithm but with a much simpler\nalgorithmic design.",
          "link": "http://arxiv.org/abs/2303.06825",
          "publishedOn": "2023-07-19T01:53:28.382Z",
          "wordCount": null,
          "title": "Best-of-three-worlds Analysis for Linear Bandits with Follow-the-regularized-leader Algorithm. (arXiv:2303.06825v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.08999",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1\">Sumegha Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_C/0/1/0/all/0/1\">Christopher Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reingold_O/0/1/0/all/0/1\">Omer Reingold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_A/0/1/0/all/0/1\">Aaron Roth</a>",
          "description": "A recent line of work has shown a surprising connection between\nmulticalibration, a multi-group fairness notion, and omniprediction, a learning\nparadigm that provides simultaneous loss minimization guarantees for a large\nfamily of loss functions. Prior work studies omniprediction in the batch\nsetting. We initiate the study of omniprediction in the online adversarial\nsetting. Although there exist algorithms for obtaining notions of\nmulticalibration in the online adversarial setting, unlike batch algorithms,\nthey work only for small finite classes of benchmark functions $F$, because\nthey require enumerating every function $f \\in F$ at every round. In contrast,\nomniprediction is most interesting for learning theoretic hypothesis classes\n$F$, which are generally continuously large.\n\nWe develop a new online multicalibration algorithm that is well defined for\ninfinite benchmark classes $F$, and is oracle efficient (i.e. for any class\n$F$, the algorithm has the form of an efficient reduction to a no-regret\nlearning algorithm for $F$). The result is the first efficient online\nomnipredictor -- an oracle efficient prediction algorithm that can be used to\nsimultaneously obtain no regret guarantees to all Lipschitz convex loss\nfunctions. For the class $F$ of linear functions, we show how to make our\nalgorithm efficient in the worst case. Also, we show upper and lower bounds on\nthe extent to which our rates can be improved: our oracle efficient algorithm\nactually promises a stronger guarantee called swap-omniprediction, and we prove\na lower bound showing that obtaining $O(\\sqrt{T})$ bounds for\nswap-omniprediction is impossible in the online setting. On the other hand, we\ngive a (non-oracle efficient) algorithm which can obtain the optimal\n$O(\\sqrt{T})$ omniprediction bounds without going through multicalibration,\ngiving an information theoretic separation between these two solution concepts.",
          "link": "http://arxiv.org/abs/2307.08999",
          "publishedOn": "2023-07-19T01:53:28.376Z",
          "wordCount": null,
          "title": "Oracle Efficient Online Multicalibration and Omniprediction. (arXiv:2307.08999v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.07617",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Defresne_M/0/1/0/all/0/1\">Marianne Defresne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barbe_S/0/1/0/all/0/1\">Sophie Barbe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schiex_T/0/1/0/all/0/1\">Thomas Schiex</a>",
          "description": "In the ongoing quest for hybridizing discrete reasoning with neural nets,\nthere is an increasing interest in neural architectures that can learn how to\nsolve discrete reasoning or optimization problems from natural inputs. In this\npaper, we introduce a scalable neural architecture and loss function dedicated\nto learning the constraints and criteria of NP-hard reasoning problems\nexpressed as discrete Graphical Models. Our loss function solves one of the\nmain limitations of Besag's pseudo-loglikelihood, enabling learning of high\nenergies. We empirically show it is able to efficiently learn how to solve\nNP-hard reasoning problems from natural inputs as the symbolic, visual or\nmany-solutions Sudoku problems as well as the energy optimization formulation\nof the protein design problem, providing data efficiency, interpretability, and\n\\textit{a posteriori} control over predictions.",
          "link": "http://arxiv.org/abs/2305.07617",
          "publishedOn": "2023-07-19T01:53:28.368Z",
          "wordCount": null,
          "title": "Scalable Coupling of Deep Learning with Logical Reasoning. (arXiv:2305.07617v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.04965",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Moussa_C/0/1/0/all/0/1\">Charles Moussa</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gordon_M/0/1/0/all/0/1\">Max Hunter Gordon</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Baczyk_M/0/1/0/all/0/1\">Michal Baczyk</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cerezo_M/0/1/0/all/0/1\">M. Cerezo</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cincio_L/0/1/0/all/0/1\">Lukasz Cincio</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Coles_P/0/1/0/all/0/1\">Patrick J. Coles</a>",
          "description": "Quantum-enhanced data science, also known as quantum machine learning (QML),\nis of growing interest as an application of near-term quantum computers.\nVariational QML algorithms have the potential to solve practical problems on\nreal hardware, particularly when involving quantum data. However, training\nthese algorithms can be challenging and calls for tailored optimization\nprocedures. Specifically, QML applications can require a large shot-count\noverhead due to the large datasets involved. In this work, we advocate for\nsimultaneous random sampling over both the dataset as well as the measurement\noperators that define the loss function. We consider a highly general loss\nfunction that encompasses many QML applications, and we show how to construct\nan unbiased estimator of its gradient. This allows us to propose a shot-frugal\ngradient descent optimizer called Refoqus (REsource Frugal Optimizer for\nQUantum Stochastic gradient descent). Our numerics indicate that Refoqus can\nsave several orders of magnitude in shot cost, even relative to optimizers that\nsample over measurement operators alone.",
          "link": "http://arxiv.org/abs/2211.04965",
          "publishedOn": "2023-07-19T01:53:28.366Z",
          "wordCount": null,
          "title": "Resource frugal optimizer for quantum machine learning. (arXiv:2211.04965v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09302",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Stutz_D/0/1/0/all/0/1\">David Stutz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1\">Abhijit Guha Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matejovicova_T/0/1/0/all/0/1\">Tatiana Matejovicova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strachan_P/0/1/0/all/0/1\">Patricia Strachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cemgil_A/0/1/0/all/0/1\">Ali Taylan Cemgil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doucet_A/0/1/0/all/0/1\">Arnaud Doucet</a>",
          "description": "In safety-critical classification tasks, conformal prediction allows to\nperform rigorous uncertainty quantification by providing confidence sets\nincluding the true class with a user-specified probability. This generally\nassumes the availability of a held-out calibration set with access to ground\ntruth labels. Unfortunately, in many domains, such labels are difficult to\nobtain and usually approximated by aggregating expert opinions. In fact, this\nholds true for almost all datasets, including well-known ones such as CIFAR and\nImageNet. Applying conformal prediction using such labels underestimates\nuncertainty. Indeed, when expert opinions are not resolvable, there is inherent\nambiguity present in the labels. That is, we do not have ``crisp'', definitive\nground truth labels and this uncertainty should be taken into account during\ncalibration. In this paper, we develop a conformal prediction framework for\nsuch ambiguous ground truth settings which relies on an approximation of the\nunderlying posterior distribution of labels given inputs. We demonstrate our\nmethodology on synthetic and real datasets, including a case study of skin\ncondition classification in dermatology.",
          "link": "http://arxiv.org/abs/2307.09302",
          "publishedOn": "2023-07-19T01:53:28.333Z",
          "wordCount": null,
          "title": "Conformal prediction under ambiguous ground truth. (arXiv:2307.09302v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09210",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Josephs_N/0/1/0/all/0/1\">Nathaniel Josephs</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Amini_A/0/1/0/all/0/1\">Arash A. Amini</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Paez_M/0/1/0/all/0/1\">Marina Paez</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lin_L/0/1/0/all/0/1\">Lizhen Lin</a>",
          "description": "We introduce the nested stochastic block model (NSBM) to cluster a collection\nof networks while simultaneously detecting communities within each network.\nNSBM has several appealing features including the ability to work on unlabeled\nnetworks with potentially different node sets, the flexibility to model\nheterogeneous communities, and the means to automatically select the number of\nclasses for the networks and the number of communities within each network.\nThis is accomplished via a Bayesian model, with a novel application of the\nnested Dirichlet process (NDP) as a prior to jointly model the between-network\nand within-network clusters. The dependency introduced by the network data\ncreates nontrivial challenges for the NDP, especially in the development of\nefficient samplers. For posterior inference, we propose several Markov chain\nMonte Carlo algorithms including a standard Gibbs sampler, a collapsed Gibbs\nsampler, and two blocked Gibbs samplers that ultimately return two levels of\nclustering labels from both within and across the networks. Extensive\nsimulation studies are carried out which demonstrate that the model provides\nvery accurate estimates of both levels of the clustering structure. We also\napply our model to two social network datasets that cannot be analyzed using\nany previous method in the literature due to the anonymity of the nodes and the\nvarying number of nodes in each network.",
          "link": "http://arxiv.org/abs/2307.09210",
          "publishedOn": "2023-07-19T01:53:27.853Z",
          "wordCount": null,
          "title": "Nested stochastic block model for simultaneously clustering networks and nodes. (arXiv:2307.09210v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07331",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ozturk_I/0/1/0/all/0/1\">Ibrahim Tolga &#xd6;zt&#xfc;rk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nedelchev_R/0/1/0/all/0/1\">Rostislav Nedelchev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heumann_C/0/1/0/all/0/1\">Christian Heumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arias_E/0/1/0/all/0/1\">Esteban Garces Arias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roger_M/0/1/0/all/0/1\">Marius Roger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bischl_B/0/1/0/all/0/1\">Bernd Bischl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Assenmacher_M/0/1/0/all/0/1\">Matthias A&#xdf;enmacher</a>",
          "description": "Recent studies have demonstrated how to assess the stereotypical bias in\npre-trained English language models. In this work, we extend this branch of\nresearch in multiple different dimensions by systematically investigating (a)\nmono- and multilingual models of (b) different underlying architectures with\nrespect to their bias in (c) multiple different languages. To that end, we make\nuse of the English StereoSet data set (Nadeem et al., 2021), which we\nsemi-automatically translate into German, French, Spanish, and Turkish. We find\nthat it is of major importance to conduct this type of analysis in a\nmultilingual setting, as our experiments show a much more nuanced picture as\nwell as notable differences from the English-only analysis. The main takeaways\nfrom our analysis are that mGPT-2 (partly) shows surprising anti-stereotypical\nbehavior across languages, English (monolingual) models exhibit the strongest\nbias, and the stereotypes reflected in the data set are least present in\nTurkish models. Finally, we release our codebase alongside the translated data\nsets and practical guidelines for the semi-automatic translation to encourage a\nfurther extension of our work to other languages.",
          "link": "http://arxiv.org/abs/2307.07331",
          "publishedOn": "2023-07-17T01:05:35.002Z",
          "wordCount": null,
          "title": "How Different Is Stereotypical Bias Across Languages?. (arXiv:2307.07331v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1810.07287",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kumbier_K/0/1/0/all/0/1\">Karl Kumbier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Basu_S/0/1/0/all/0/1\">Sumanta Basu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Frise_E/0/1/0/all/0/1\">Erwin Frise</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Celniker_S/0/1/0/all/0/1\">Susan E. Celniker</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Brown_J/0/1/0/all/0/1\">James B. Brown</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Celniker_S/0/1/0/all/0/1\">Susan Celniker</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yu_B/0/1/0/all/0/1\">Bin Yu</a>",
          "description": "Standard ChIP-seq peak calling pipelines seek to differentiate biochemically\nreproducible signals of individual genomic elements from background noise.\nHowever, reproducibility alone does not imply functional regulation (e.g.,\nenhancer activation, alternative splicing). Here we present a general-purpose,\ninterpretable machine learning method: signed iterative random forests (siRF),\nwhich we use to infer regulatory interactions among transcription factors and\nfunctional binding signatures surrounding enhancer elements in Drosophila\nmelanogaster.",
          "link": "http://arxiv.org/abs/1810.07287",
          "publishedOn": "2023-07-17T01:05:34.999Z",
          "wordCount": null,
          "title": "Signed iterative random forests to identify enhancer-associated transcription factor binding. (arXiv:1810.07287v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.07320",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ying_M/0/1/0/all/0/1\">Mufang Ying</a>, <a href=\"http://arxiv.org/find/math/1/au:+Khamaru_K/0/1/0/all/0/1\">Koulik Khamaru</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_C/0/1/0/all/0/1\">Cun-Hui Zhang</a>",
          "description": "Sequential data collection has emerged as a widely adopted technique for\nenhancing the efficiency of data gathering processes. Despite its advantages,\nsuch data collection mechanism often introduces complexities to the statistical\ninference procedure. For instance, the ordinary least squares (OLS) estimator\nin an adaptive linear regression model can exhibit non-normal asymptotic\nbehavior, posing challenges for accurate inference and interpretation. In this\npaper, we propose a general method for constructing debiased estimator which\nremedies this issue. It makes use of the idea of adaptive linear estimating\nequations, and we establish theoretical guarantees of asymptotic normality,\nsupplemented by discussions on achieving near-optimal asymptotic variance. A\nsalient feature of our estimator is that in the context of multi-armed bandits,\nour estimator retains the non-asymptotic performance of the least square\nestimator while obtaining asymptotic normality property. Consequently, this\nwork helps connect two fruitful paradigms of adaptive inference: a)\nnon-asymptotic inference using concentration inequalities and b) asymptotic\ninference via asymptotic normality.",
          "link": "http://arxiv.org/abs/2307.07320",
          "publishedOn": "2023-07-17T01:05:34.152Z",
          "wordCount": null,
          "title": "Adaptive Linear Estimating Equations. (arXiv:2307.07320v1 [math.ST])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.00543",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dorfman_R/0/1/0/all/0/1\">Ron Dorfman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vargaftik_S/0/1/0/all/0/1\">Shay Vargaftik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_Itzhak_Y/0/1/0/all/0/1\">Yaniv Ben-Itzhak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_K/0/1/0/all/0/1\">Kfir Y. Levy</a>",
          "description": "Many compression techniques have been proposed to reduce the communication\noverhead of Federated Learning training procedures. However, these are\ntypically designed for compressing model updates, which are expected to decay\nthroughout training. As a result, such methods are inapplicable to downlink\n(i.e., from the parameter server to clients) compression in the cross-device\nsetting, where heterogeneous clients $\\textit{may appear only once}$ during\ntraining and thus must download the model parameters. Accordingly, we propose\n$\\textsf{DoCoFL}$ -- a new framework for downlink compression in the\ncross-device setting. Importantly, $\\textsf{DoCoFL}$ can be seamlessly combined\nwith many uplink compression schemes, rendering it suitable for bi-directional\ncompression. Through extensive evaluation, we show that $\\textsf{DoCoFL}$\noffers significant bi-directional bandwidth reduction while achieving\ncompetitive accuracy to that of a baseline without any compression.",
          "link": "http://arxiv.org/abs/2302.00543",
          "publishedOn": "2023-07-17T01:05:33.600Z",
          "wordCount": 657,
          "title": "DoCoFL: Downlink Compression for Cross-Device Federated Learning. (arXiv:2302.00543v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.15609",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Glyn_Davies_A/0/1/0/all/0/1\">Alex Glyn-Davies</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Duffin_C/0/1/0/all/0/1\">Connor Duffin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Akyildiz_O/0/1/0/all/0/1\">&#xd6;. Deniz Akyildiz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Girolami_M/0/1/0/all/0/1\">Mark Girolami</a>",
          "description": "Incorporating unstructured data into physical models is a challenging problem\nthat is emerging in data assimilation. Traditional approaches focus on\nwell-defined observation operators whose functional forms are typically assumed\nto be known. This prevents these methods from achieving a consistent model-data\nsynthesis in configurations where the mapping from data-space to model-space is\nunknown. To address these shortcomings, in this paper we develop a\nphysics-informed dynamical variational autoencoder ($\\Phi$-DVAE) to embed\ndiverse data streams into time-evolving physical systems described by\ndifferential equations. Our approach combines a standard, possibly nonlinear,\nfilter for the latent state-space model and a VAE, to assimilate the\nunstructured data into the latent dynamical system. Unstructured data, in our\nexample systems, comes in the form of video data and velocity field\nmeasurements, however the methodology is suitably generic to allow for\narbitrary unknown observation operators. A variational Bayesian framework is\nused for the joint estimation of the encoding, latent states, and unknown\nsystem parameters. To demonstrate the method, we provide case studies with the\nLorenz-63 ordinary differential equation, and the advection and Korteweg-de\nVries partial differential equations. Our results, with synthetic data, show\nthat $\\Phi$-DVAE provides a data efficient dynamics encoding methodology which\nis competitive with standard approaches. Unknown parameters are recovered with\nuncertainty quantification, and unseen data are accurately predicted.",
          "link": "http://arxiv.org/abs/2209.15609",
          "publishedOn": "2023-07-17T01:05:33.587Z",
          "wordCount": 752,
          "title": "$\\Phi$-DVAE: Physics-Informed Dynamical Variational Autoencoders for Unstructured Data Assimilation. (arXiv:2209.15609v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2211.14961",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Wakhloo_A/0/1/0/all/0/1\">Albert J. Wakhloo</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sussman_T/0/1/0/all/0/1\">Tamara J. Sussman</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chung_S/0/1/0/all/0/1\">SueYeon Chung</a>",
          "description": "Understanding how the statistical and geometric properties of neural activity\nrelate to performance is a key problem in theoretical neuroscience and deep\nlearning. Here, we calculate how correlations between object representations\naffect the capacity, a measure of linear separability. We show that for\nspherical object manifolds, introducing correlations between centroids\neffectively pushes the spheres closer together, while introducing correlations\nbetween the axes effectively shrinks their radii, revealing a duality between\ncorrelations and geometry with respect to the problem of classification. We\nthen apply our results to accurately estimate the capacity of deep network\ndata.",
          "link": "http://arxiv.org/abs/2211.14961",
          "publishedOn": "2023-07-17T01:05:33.574Z",
          "wordCount": 675,
          "title": "Linear Classification of Neural Manifolds with Correlated Variability. (arXiv:2211.14961v2 [q-bio.NC] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2207.09874",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cacciarelli_D/0/1/0/all/0/1\">Davide Cacciarelli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kulahci_M/0/1/0/all/0/1\">Murat Kulahci</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tyssedal_J/0/1/0/all/0/1\">John S&#xf8;lve Tyssedal</a>",
          "description": "The proliferation of automated data collection schemes and the advances in\nsensorics are increasing the amount of data we are able to monitor in\nreal-time. However, given the high annotation costs and the time required by\nquality inspections, data is often available in an unlabeled form. This is\nfostering the use of active learning for the development of soft sensors and\npredictive models. In production, instead of performing random inspections to\nobtain product information, labels are collected by evaluating the information\ncontent of the unlabeled data. Several query strategy frameworks for regression\nhave been proposed in the literature but most of the focus has been dedicated\nto the static pool-based scenario. In this work, we propose a new strategy for\nthe stream-based scenario, where instances are sequentially offered to the\nlearner, which must instantaneously decide whether to perform the quality check\nto obtain the label or discard the instance. The approach is inspired by the\noptimal experimental design theory and the iterative aspect of the\ndecision-making process is tackled by setting a threshold on the\ninformativeness of the unlabeled data points. The proposed approach is\nevaluated using numerical simulations and the Tennessee Eastman Process\nsimulator. The results confirm that selecting the examples suggested by the\nproposed algorithm allows for a faster reduction in the prediction error.",
          "link": "http://arxiv.org/abs/2207.09874",
          "publishedOn": "2023-07-17T01:05:33.541Z",
          "wordCount": 770,
          "title": "Stream-based active learning with linear models. (arXiv:2207.09874v5 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.04188",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_P/0/1/0/all/0/1\">Puyu Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lei_Y/0/1/0/all/0/1\">Yunwen Lei</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ying_Y/0/1/0/all/0/1\">Yiming Ying</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhou_D/0/1/0/all/0/1\">Ding-Xuan Zhou</a>",
          "description": "Modern machine learning algorithms aim to extract fine-grained information\nfrom data to provide accurate predictions, which often conflicts with the goal\nof privacy protection. This paper addresses the practical and theoretical\nimportance of developing privacy-preserving machine learning algorithms that\nensure good performance while preserving privacy. In this paper, we focus on\nthe privacy and utility (measured by excess risk bounds) performances of\ndifferentially private stochastic gradient descent (SGD) algorithms in the\nsetting of stochastic convex optimization. Specifically, we examine the\npointwise problem in the low-noise setting for which we derive sharper excess\nrisk bounds for the differentially private SGD algorithm. In the pairwise\nlearning setting, we propose a simple differentially private SGD algorithm\nbased on gradient perturbation. Furthermore, we develop novel utility bounds\nfor the proposed algorithm, proving that it achieves optimal excess risk rates\neven for non-smooth losses. Notably, we establish fast learning rates for\nprivacy-preserving pairwise learning under the low-noise condition, which is\nthe first of its kind.",
          "link": "http://arxiv.org/abs/2209.04188",
          "publishedOn": "2023-07-17T01:05:33.534Z",
          "wordCount": 680,
          "title": "Differentially Private Stochastic Gradient Descent with Low-Noise. (arXiv:2209.04188v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2010.01079",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Komiyama_J/0/1/0/all/0/1\">Junpei Komiyama</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Noda_S/0/1/0/all/0/1\">Shunya Noda</a>",
          "description": "We analyze statistical discrimination in hiring markets using a multi-armed\nbandit model. Myopic firms face workers arriving with heterogeneous observable\ncharacteristics. The association between the worker's skill and characteristics\nis unknown ex ante; thus, firms need to learn it. Laissez-faire causes\nperpetual underestimation: minority workers are rarely hired, and therefore,\nthe underestimation tends to persist. Even a marginal imbalance in the\npopulation ratio frequently results in perpetual underestimation. We propose\ntwo policy solutions: a novel subsidy rule (the hybrid mechanism) and the\nRooney Rule. Our results indicate that temporary affirmative actions\neffectively alleviate discrimination stemming from insufficient data.",
          "link": "http://arxiv.org/abs/2010.01079",
          "publishedOn": "2023-07-17T01:05:33.520Z",
          "wordCount": 685,
          "title": "On Statistical Discrimination as a Failure of Social Learning: A Multi-Armed Bandit Approach. (arXiv:2010.01079v6 [econ.TH] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.19694",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Aghbalou_A/0/1/0/all/0/1\">Anass Aghbalou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Staerman_G/0/1/0/all/0/1\">Guillaume Staerman</a>",
          "description": "Hypothesis transfer learning (HTL) contrasts domain adaptation by allowing\nfor a previous task leverage, named the source, into a new one, the target,\nwithout requiring access to the source data. Indeed, HTL relies only on a\nhypothesis learnt from such source data, relieving the hurdle of expansive data\nstorage and providing great practical benefits. Hence, HTL is highly beneficial\nfor real-world applications relying on big data. The analysis of such a method\nfrom a theoretical perspective faces multiple challenges, particularly in\nclassification tasks. This paper deals with this problem by studying the\nlearning theory of HTL through algorithmic stability, an attractive theoretical\nframework for machine learning algorithms analysis. In particular, we are\ninterested in the statistical behaviour of the regularized empirical risk\nminimizers in the case of binary classification. Our stability analysis\nprovides learning guarantees under mild assumptions. Consequently, we derive\nseveral complexity-free generalization bounds for essential statistical\nquantities like the training error, the excess risk and cross-validation\nestimates. These refined bounds allow understanding the benefits of transfer\nlearning and comparing the behaviour of standard losses in different scenarios,\nleading to valuable insights for practitioners.",
          "link": "http://arxiv.org/abs/2305.19694",
          "publishedOn": "2023-07-17T01:05:33.499Z",
          "wordCount": 715,
          "title": "Hypothesis Transfer Learning with Surrogate Classification Losses: Generalization Bounds through Algorithmic Stability. (arXiv:2305.19694v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04226",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Wei_X/0/1/0/all/0/1\">Xiaoli Wei</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhang_C/0/1/0/all/0/1\">Chunxia Zhang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wang_H/0/1/0/all/0/1\">Hongtao Wang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Tan_C/0/1/0/all/0/1\">Chengli Tan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Xiong_D/0/1/0/all/0/1\">Deng Xiong</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Jiang_B/0/1/0/all/0/1\">Baisong Jiang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhang_J/0/1/0/all/0/1\">Jiangshe Zhang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kim_S/0/1/0/all/0/1\">Sang-Woon Kim</a>",
          "description": "The incompleteness of the seismic data caused by missing traces along the\nspatial extension is a common issue in seismic acquisition due to the existence\nof obstacles and economic constraints, which severely impairs the imaging\nquality of subsurface geological structures. Recently, deep learningbased\nseismic interpolation methods have attained promising progress, while achieving\nstable training of generative adversarial networks is not easy, and performance\ndegradation is usually notable if the missing patterns in the testing and\ntraining do not match. In this paper, we propose a novel seismic denoising\ndiffusion implicit model with resampling. The model training is established on\nthe denoising diffusion probabilistic model, where U-Net is equipped with the\nmulti-head self-attention to match the noise in each step. The cosine noise\nschedule, serving as the global noise configuration, promotes the high\nutilization of known trace information by accelerating the passage of the\nexcessive noise stages. The model inference utilizes the denoising diffusion\nimplicit model, conditioning on the known traces, to enable high-quality\ninterpolation with fewer diffusion steps. To enhance the coherency between the\nknown traces and the missing traces within each reverse step, the inference\nprocess integrates a resampling strategy to achieve an information recap on the\nformer interpolated traces. Extensive experiments conducted on synthetic and\nfield seismic data validate the superiority of our model and its robustness to\nvarious missing patterns. In addition, uncertainty quantification and ablation\nstudies are also investigated.",
          "link": "http://arxiv.org/abs/2307.04226",
          "publishedOn": "2023-07-17T01:05:33.494Z",
          "wordCount": 775,
          "title": "Seismic Data Interpolation based on Denoising Diffusion Implicit Models with Resampling. (arXiv:2307.04226v2 [physics.geo-ph] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07410",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wind_J/0/1/0/all/0/1\">Johan S. Wind</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antun_V/0/1/0/all/0/1\">Vegard Antun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hansen_A/0/1/0/all/0/1\">Anders C. Hansen</a>",
          "description": "Understanding the implicit regularization imposed by neural network\narchitectures and gradient based optimization methods is a key challenge in\ndeep learning and AI. In this work we provide sharp results for the implicit\nregularization imposed by the gradient flow of Diagonal Linear Networks (DLNs)\nin the over-parameterized regression setting and, potentially surprisingly,\nlink this to the phenomenon of phase transitions in generalized hardness of\napproximation (GHA). GHA generalizes the phenomenon of hardness of\napproximation from computer science to, among others, continuous and robust\noptimization. It is well-known that the $\\ell^1$-norm of the gradient flow of\nDLNs with tiny initialization converges to the objective function of basis\npursuit. We improve upon these results by showing that the gradient flow of\nDLNs with tiny initialization approximates minimizers of the basis pursuit\noptimization problem (as opposed to just the objective function), and we obtain\nnew and sharp convergence bounds w.r.t.\\ the initialization size. Non-sharpness\nof our results would imply that the GHA phenomenon would not occur for the\nbasis pursuit optimization problem -- which is a contradiction -- thus implying\nsharpness. Moreover, we characterize $\\textit{which}$ $\\ell_1$ minimizer of the\nbasis pursuit problem is chosen by the gradient flow whenever the minimizer is\nnot unique. Interestingly, this depends on the depth of the DLN.",
          "link": "http://arxiv.org/abs/2307.07410",
          "publishedOn": "2023-07-17T01:05:33.473Z",
          "wordCount": 779,
          "title": "Implicit regularization in AI meets generalized hardness of approximation in optimization -- Sharp results for diagonal linear networks. (arXiv:2307.07410v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07264",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Houshuang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuchen He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chihao Zhang</a>",
          "description": "Learning with expert advice and multi-armed bandit are two classic online\ndecision problems which differ on how the information is observed in each round\nof the game. We study a family of problems interpolating the two. For a vector\n$\\mathbf{m}=(m_1,\\dots,m_K)\\in \\mathbb{N}^K$, an instance of $\\mathbf{m}$-MAB\nindicates that the arms are partitioned into $K$ groups and the $i$-th group\ncontains $m_i$ arms. Once an arm is pulled, the losses of all arms in the same\ngroup are observed. We prove tight minimax regret bounds for $\\mathbf{m}$-MAB\nand design an optimal PAC algorithm for its pure exploration version,\n$\\mathbf{m}$-BAI, where the goal is to identify the arm with minimum loss with\nas few rounds as possible. We show that the minimax regret of $\\mathbf{m}$-MAB\nis $\\Theta\\left(\\sqrt{T\\sum_{k=1}^K\\log (m_k+1)}\\right)$ and the minimum number\nof pulls for an $(\\epsilon,0.05)$-PAC algorithm of $\\mathbf{m}$-BAI is\n$\\Theta\\left(\\frac{1}{\\epsilon^2}\\cdot \\sum_{k=1}^K\\log (m_k+1)\\right)$. Both\nour upper bounds and lower bounds for $\\mathbf{m}$-MAB can be extended to a\nmore general setting, namely the bandit with graph feedback, in terms of the\nclique cover and related graph parameters. As consequences, we obtained tight\nminimax regret bounds for several families of feedback graphs.",
          "link": "http://arxiv.org/abs/2307.07264",
          "publishedOn": "2023-07-17T01:05:33.431Z",
          "wordCount": 688,
          "title": "On Interpolating Experts and Multi-Armed Bandits. (arXiv:2307.07264v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07405",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Axiotis_K/0/1/0/all/0/1\">Kyriakos Axiotis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yasuda_T/0/1/0/all/0/1\">Taisuke Yasuda</a>",
          "description": "Despite widespread adoption in practice, guarantees for the LASSO and Group\nLASSO are strikingly lacking in settings beyond statistical problems, and these\nalgorithms are usually considered to be a heuristic in the context of sparse\nconvex optimization on deterministic inputs. We give the first recovery\nguarantees for the Group LASSO for sparse convex optimization with\nvector-valued features. We show that if a sufficiently large Group LASSO\nregularization is applied when minimizing a strictly convex function $l$, then\nthe minimizer is a sparse vector supported on vector-valued features with the\nlargest $\\ell_2$ norm of the gradient. Thus, repeating this procedure selects\nthe same set of features as the Orthogonal Matching Pursuit algorithm, which\nadmits recovery guarantees for any function $l$ with restricted strong\nconvexity and smoothness via weak submodularity arguments. This answers open\nquestions of Tibshirani et al. and Yasuda et al. Our result is the first to\ntheoretically explain the empirical success of the Group LASSO for convex\nfunctions under general input instances assuming only restricted strong\nconvexity and smoothness. Our result also generalizes provable guarantees for\nthe Sequential Attention algorithm, which is a feature selection algorithm\ninspired by the attention mechanism proposed by Yasuda et al.\n\nAs an application of our result, we give new results for the column subset\nselection problem, which is well-studied when the loss is the Frobenius norm or\nother entrywise matrix losses. We give the first result for general loss\nfunctions for this problem that requires only restricted strong convexity and\nsmoothness.",
          "link": "http://arxiv.org/abs/2307.07405",
          "publishedOn": "2023-07-17T01:05:33.417Z",
          "wordCount": 766,
          "title": "Performance of $\\ell_1$ Regularization for Sparse Convex Optimization. (arXiv:2307.07405v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07508",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cordeiro_E/0/1/0/all/0/1\">Edyvalberty Alenquer Cordeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pitombeira_Neto_A/0/1/0/all/0/1\">Anselmo Ramalho Pitombeira-Neto</a>",
          "description": "The dynamic vehicle dispatching problem corresponds to deciding which\nvehicles to assign to requests that arise stochastically over time and space.\nIt emerges in diverse areas, such as in the assignment of trucks to loads to be\ntransported; in emergency systems; and in ride-hailing services. In this paper,\nwe model the problem as a semi-Markov decision process, which allows us to\ntreat time as continuous. In this setting, decision epochs coincide with\ndiscrete events whose time intervals are random. We argue that an event-based\napproach substantially reduces the combinatorial complexity of the decision\nspace and overcomes other limitations of discrete-time models often proposed in\nthe literature. In order to test our approach, we develop a new discrete-event\nsimulator and use double deep q-learning to train our decision agents.\nNumerical experiments are carried out in realistic scenarios using data from\nNew York City. We compare the policies obtained through our approach with\nheuristic policies often used in practice. Results show that our policies\nexhibit better average waiting times, cancellation rates and total service\ntimes, with reduction in average waiting times of up to 50% relative to the\nother tested heuristic policies.",
          "link": "http://arxiv.org/abs/2307.07508",
          "publishedOn": "2023-07-17T01:05:33.410Z",
          "wordCount": 723,
          "title": "Deep reinforcement learning for the dynamic vehicle dispatching problem: An event-based approach. (arXiv:2307.07508v1 [cs.AI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2208.04856",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Vadeboncoeur_A/0/1/0/all/0/1\">Arnaud Vadeboncoeur</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Akyildiz_O/0/1/0/all/0/1\">&#xd6;mer Deniz Akyildiz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kazlauskaite_I/0/1/0/all/0/1\">Ieva Kazlauskaite</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Girolami_M/0/1/0/all/0/1\">Mark Girolami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cirak_F/0/1/0/all/0/1\">Fehmi Cirak</a>",
          "description": "We introduce a physics-driven deep latent variable model (PDDLVM) to learn\nsimultaneously parameter-to-solution (forward) and solution-to-parameter\n(inverse) maps of parametric partial differential equations (PDEs). Our\nformulation leverages conventional PDE discretization techniques, deep neural\nnetworks, probabilistic modelling, and variational inference to assemble a\nfully probabilistic coherent framework. In the posited probabilistic model,\nboth the forward and inverse maps are approximated as Gaussian distributions\nwith a mean and covariance parameterized by deep neural networks. The PDE\nresidual is assumed to be an observed random vector of value zero, hence we\nmodel it as a random vector with a zero mean and a user-prescribed covariance.\nThe model is trained by maximizing the probability, that is the evidence or\nmarginal likelihood, of observing a residual of zero by maximizing the evidence\nlower bound (ELBO). Consequently, the proposed methodology does not require any\nindependent PDE solves and is physics-informed at training time, allowing the\nreal-time solution of PDE forward and inverse problems after training. The\nproposed framework can be easily extended to seamlessly integrate observed data\nto solve inverse problems and to build generative models. We demonstrate the\nefficiency and robustness of our method on finite element discretized\nparametric PDE problems such as linear and nonlinear Poisson problems, elastic\nshells with complex 3D geometries, and time-dependent nonlinear and\ninhomogeneous PDEs using a physics-informed neural network (PINN)\ndiscretization. We achieve up to three orders of magnitude speed-up after\ntraining compared to traditional finite element method (FEM), while outputting\ncoherent uncertainty estimates.",
          "link": "http://arxiv.org/abs/2208.04856",
          "publishedOn": "2023-07-17T01:05:33.401Z",
          "wordCount": 792,
          "title": "Fully probabilistic deep models for forward and inverse problems in parametric PDEs. (arXiv:2208.04856v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06250",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jiaqi Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Squires_C/0/1/0/all/0/1\">Chandler Squires</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Greenewald_K/0/1/0/all/0/1\">Kristjan Greenewald</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Srivastava_A/0/1/0/all/0/1\">Akash Srivastava</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shanmugam_K/0/1/0/all/0/1\">Karthikeyan Shanmugam</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Uhler_C/0/1/0/all/0/1\">Caroline Uhler</a>",
          "description": "Causal disentanglement aims to uncover a representation of data using latent\nvariables that are interrelated through a causal model. Such a representation\nis identifiable if the latent model that explains the data is unique. In this\npaper, we focus on the scenario where unpaired observational and interventional\ndata are available, with each intervention changing the mechanism of a latent\nvariable. When the causal variables are fully observed, statistically\nconsistent algorithms have been developed to identify the causal model under\nfaithfulness assumptions. We here show that identifiability can still be\nachieved with unobserved causal variables, given a generalized notion of\nfaithfulness. Our results guarantee that we can recover the latent causal model\nup to an equivalence class and predict the effect of unseen combinations of\ninterventions, in the limit of infinite data. We implement our causal\ndisentanglement framework by developing an autoencoding variational Bayes\nalgorithm and apply it to the problem of predicting combinatorial perturbation\neffects in genomics.",
          "link": "http://arxiv.org/abs/2307.06250",
          "publishedOn": "2023-07-17T01:05:33.396Z",
          "wordCount": 689,
          "title": "Identifiability Guarantees for Causal Disentanglement from Soft Interventions. (arXiv:2307.06250v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2110.03443",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Blattner_L/0/1/0/all/0/1\">Laura Blattner</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Nelson_S/0/1/0/all/0/1\">Scott Nelson</a>, <a href=\"http://arxiv.org/find/econ/1/au:+Spiess_J/0/1/0/all/0/1\">Jann Spiess</a>",
          "description": "We show how to optimally regulate prediction algorithms in a world where an\nagent uses complex 'black-box' prediction functions to make decisions such as\nlending, medical testing, or hiring, and where a principal is limited in how\nmuch she can learn about the agent's black-box model. We show that limiting\nagents to prediction functions that are simple enough to be fully transparent\nis inefficient as long as the misalignment is limited and first-best prediction\nfunctions are sufficiently complex. Algorithmic audits can improve welfare, but\nthe gains depend on the design of the audit tools. Tools that focus on\nminimizing overall information loss, the focus of many explainer tools, will\ngenerally be inefficient since they focus on explaining the average behavior of\nthe prediction function. Targeted tools that focus on the source of incentive\nmisalignment, e.g., excess false positives or racial disparities, can provide\nsecond-best solutions. We provide empirical support for our theoretical\nfindings using an application in consumer lending, where we document that\ncomplex models regulated based on context-specific explanation tools outperform\nsimple, fully transparent models. This gain from complex models represents a\nPareto improvement across our empirical applications that are preferred both by\nthe lender and from the perspective of the financial regulator.",
          "link": "http://arxiv.org/abs/2110.03443",
          "publishedOn": "2023-07-17T01:05:33.375Z",
          "wordCount": 728,
          "title": "Unpacking the Black Box: Regulating Algorithmic Decisions. (arXiv:2110.03443v2 [econ.GN] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2002.10113",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_A/0/1/0/all/0/1\">Alex Tong Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_S/0/1/0/all/0/1\">Samy Wu Fung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wuchen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nurbekyan_L/0/1/0/all/0/1\">Levon Nurbekyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osher_S/0/1/0/all/0/1\">Stanley J. Osher</a>",
          "description": "We present APAC-Net, an alternating population and agent control neural\nnetwork for solving stochastic mean field games (MFGs). Our algorithm is geared\ntoward high-dimensional instances of MFGs that are beyond reach with existing\nsolution methods. We achieve this in two steps. First, we take advantage of the\nunderlying variational primal-dual structure that MFGs exhibit and phrase it as\na convex-concave saddle point problem. Second, we parameterize the value and\ndensity functions by two neural networks, respectively. By phrasing the problem\nin this manner, solving the MFG can be interpreted as a special case of\ntraining a generative adversarial network (GAN). We show the potential of our\nmethod on up to 100-dimensional MFG problems.",
          "link": "http://arxiv.org/abs/2002.10113",
          "publishedOn": "2023-07-17T01:05:33.355Z",
          "wordCount": 722,
          "title": "Alternating the Population and Control Neural Networks to Solve High-Dimensional Stochastic Mean-Field Games. (arXiv:2002.10113v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07014",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rebello_A/0/1/0/all/0/1\">Aaman Rebello</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Shengpu Tang</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Wiens_J/0/1/0/all/0/1\">Jenna Wiens</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Parbhoo_S/0/1/0/all/0/1\">Sonali Parbhoo</a> (1) ((1) Department of Engineering, Imperial College London, (2) Division of Computer Science &amp; Engineering, University of Michigan)",
          "description": "Off-policy evaluation (OPE) aims to estimate the benefit of following a\ncounterfactual sequence of actions, given data collected from executed\nsequences. However, existing OPE estimators often exhibit high bias and high\nvariance in problems involving large, combinatorial action spaces. We\ninvestigate how to mitigate this issue using factored action spaces i.e.\nexpressing each action as a combination of independent sub-actions from smaller\naction spaces. This approach facilitates a finer-grained analysis of how\nactions differ in their effects. In this work, we propose a new family of\n\"decomposed\" importance sampling (IS) estimators based on factored action\nspaces. Given certain assumptions on the underlying problem structure, we prove\nthat the decomposed IS estimators have less variance than their original\nnon-decomposed versions, while preserving the property of zero bias. Through\nsimulations, we empirically verify our theoretical results, probing the\nvalidity of various assumptions. Provided with a technique that can derive the\naction space factorisation for a given problem, our work shows that OPE can be\nimproved \"for free\" by utilising this inherent problem structure.",
          "link": "http://arxiv.org/abs/2307.07014",
          "publishedOn": "2023-07-17T01:05:33.085Z",
          "wordCount": 748,
          "title": "Leveraging Factored Action Spaces for Off-Policy Evaluation. (arXiv:2307.07014v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07072",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parker_C/0/1/0/all/0/1\">Christopher S. Parker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schroder_A/0/1/0/all/0/1\">Anna Schroder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Epstein_S/0/1/0/all/0/1\">Sean C. Epstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cole_J/0/1/0/all/0/1\">James Cole</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alexander_D/0/1/0/all/0/1\">Daniel C. Alexander</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hui Zhang</a>",
          "description": "Purpose: Previous quantitative MR imaging studies using self-supervised deep\nlearning have reported biased parameter estimates at low SNR. Such systematic\nerrors arise from the choice of Mean Squared Error (MSE) loss function for\nnetwork training, which is incompatible with Rician-distributed MR magnitude\nsignals. To address this issue, we introduce the negative log Rician likelihood\n(NLR) loss. Methods: A numerically stable and accurate implementation of the\nNLR loss was developed to estimate quantitative parameters of the apparent\ndiffusion coefficient (ADC) model and intra-voxel incoherent motion (IVIM)\nmodel. Parameter estimation accuracy, precision and overall error were\nevaluated in terms of bias, variance and root mean squared error and compared\nagainst the MSE loss over a range of SNRs (5 - 30). Results: Networks trained\nwith NLR loss show higher estimation accuracy than MSE for the ADC and IVIM\ndiffusion coefficients as SNR decreases, with minimal loss of precision or\ntotal error. At high effective SNR (high SNR and small diffusion coefficients),\nboth losses show comparable accuracy and precision for all parameters of both\nmodels. Conclusion: The proposed NLR loss is numerically stable and accurate\nacross the full range of tested SNRs and improves parameter estimation accuracy\nof diffusion coefficients using self-supervised deep learning. We expect the\ndevelopment to benefit quantitative MR imaging techniques broadly, enabling\nmore accurate parameter estimation from noisy data.",
          "link": "http://arxiv.org/abs/2307.07072",
          "publishedOn": "2023-07-17T01:05:33.080Z",
          "wordCount": 771,
          "title": "Rician likelihood loss for quantitative MRI using self-supervised deep learning. (arXiv:2307.07072v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06957",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xu_Z/0/1/0/all/0/1\">Zuheng Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Campbell_T/0/1/0/all/0/1\">Trevor Campbell</a>",
          "description": "In this paper, we investigate the impact of numerical instability on the\nreliability of sampling, density evaluation, and evidence lower bound (ELBO)\nestimation in variational flows. We first empirically demonstrate that common\nflows can exhibit a catastrophic accumulation of error: the numerical flow map\ndeviates significantly from the exact map -- which affects sampling -- and the\nnumerical inverse flow map does not accurately recover the initial input --\nwhich affects density and ELBO computations. Surprisingly though, we find that\nresults produced by flows are often accurate enough for applications despite\nthe presence of serious numerical instability. In this work, we treat\nvariational flows as dynamical systems, and leverage shadowing theory to\nelucidate this behavior via theoretical guarantees on the error of sampling,\ndensity evaluation, and ELBO estimation. Finally, we develop and empirically\ntest a diagnostic procedure that can be used to validate results produced by\nnumerically unstable flows in practice.",
          "link": "http://arxiv.org/abs/2307.06957",
          "publishedOn": "2023-07-17T01:05:32.762Z",
          "wordCount": 673,
          "title": "Embracing the chaos: analysis and diagnosis of numerical instability in variational flows. (arXiv:2307.06957v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07191",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhixian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Q/0/1/0/all/0/1\">Qingsong Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chaoli Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Liang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krannichfeldt_L/0/1/0/all/0/1\">Leandro Von Krannichfeldt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yi Wang</a>",
          "description": "Load forecasting is of great significance in the power industry as it can\nprovide a reference for subsequent tasks such as power grid dispatch, thus\nbringing huge economic benefits. However, there are many differences between\nload forecasting and traditional time series forecasting. On the one hand, load\nforecasting aims to minimize the cost of subsequent tasks such as power grid\ndispatch, rather than simply pursuing prediction accuracy. On the other hand,\nthe load is largely influenced by many external factors, such as temperature or\ncalendar variables. In addition, the scale of predictions (such as\nbuilding-level loads and aggregated-level loads) can also significantly impact\nthe predicted results. In this paper, we provide a comprehensive load\nforecasting archive, which includes load domain-specific feature engineering to\nhelp forecasting models better model load data. In addition, different from the\ntraditional loss function which only aims for accuracy, we also provide a\nmethod to customize the loss function based on the forecasting error,\nintegrating it into our forecasting framework. Based on this, we conducted\nextensive experiments on load data at different levels, providing a reference\nfor researchers to compare different load forecasting models.",
          "link": "http://arxiv.org/abs/2307.07191",
          "publishedOn": "2023-07-17T01:05:32.756Z",
          "wordCount": 703,
          "title": "Benchmarks and Custom Package for Electrical Load Forecasting. (arXiv:2307.07191v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06024",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sarig_T/0/1/0/all/0/1\">Tal Sarig</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Galili_T/0/1/0/all/0/1\">Tal Galili</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Eilat_R/0/1/0/all/0/1\">Roee Eilat</a>",
          "description": "Surveys are an important research tool, providing unique measurements on\nsubjective experiences such as sentiment and opinions that cannot be measured\nby other means. However, because survey data is collected from a self-selected\ngroup of participants, directly inferring insights from it to a population of\ninterest, or training ML models on such data, can lead to erroneous estimates\nor under-performing models. In this paper we present balance, an open-source\nPython package by Meta, offering a simple workflow for analyzing and adjusting\nbiased data samples with respect to a population of interest.\n\nThe balance workflow includes three steps: understanding the initial bias in\nthe data relative to a target we would like to infer, adjusting the data to\ncorrect for the bias by producing weights for each unit in the sample based on\npropensity scores, and evaluating the final biases and the variance inflation\nafter applying the fitted weights. The package provides a simple API that can\nbe used by researchers and data scientists from a wide range of fields on a\nvariety of data. The paper provides the relevant context, methodological\nbackground, and presents the package's API.",
          "link": "http://arxiv.org/abs/2307.06024",
          "publishedOn": "2023-07-14T01:03:52.968Z",
          "wordCount": null,
          "title": "balance -- a Python package for balancing biased data samples. (arXiv:2307.06024v2 [stat.CO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.11140",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cordonnier_M/0/1/0/all/0/1\">Matthieu Cordonnier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Keriven_N/0/1/0/all/0/1\">Nicolas Keriven</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tremblay_N/0/1/0/all/0/1\">Nicolas Tremblay</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vaiter_S/0/1/0/all/0/1\">Samuel Vaiter</a>",
          "description": "We study the convergence of message passing graph neural networks on random\ngraph models to their continuous counterpart as the number of nodes tends to\ninfinity. Until now, this convergence was only known for architectures with\naggregation functions in the form of normalized means, or, equivalently, of an\napplication of classical operators like the adjacency matrix or the graph\nLaplacian. We extend such results to a large class of aggregation functions,\nthat encompasses all classically used message passing graph neural networks,\nsuch as attention-based message passing, max convolutional message passing or\n(degree-normalized) convolutional message passing. Under mild assumptions, we\ngive non-asymptotic bounds with high probability to quantify this convergence.\nOur main result is based on the McDiarmid inequality. Interestingly, this\nresult does not apply to the case where the aggregation is a coordinate-wise\nmaximum. We treat this case separately and obtain a different convergence rate.",
          "link": "http://arxiv.org/abs/2304.11140",
          "publishedOn": "2023-07-14T01:03:52.967Z",
          "wordCount": null,
          "title": "Convergence of Message Passing Graph Neural Networks with Generic Aggregation On Large Random Graphs. (arXiv:2304.11140v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2006.03134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Allen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1\">Ankur Moitra</a>",
          "description": "Tensor completion is a natural higher-order generalization of matrix\ncompletion where the goal is to recover a low-rank tensor from sparse\nobservations of its entries. Existing algorithms are either heuristic without\nprovable guarantees, based on solving large semidefinite programs which are\nimpractical to run, or make strong assumptions such as requiring the factors to\nbe nearly orthogonal. In this paper we introduce a new variant of alternating\nminimization, which in turn is inspired by understanding how the progress\nmeasures that guide convergence of alternating minimization in the matrix\nsetting need to be adapted to the tensor setting. We show strong provable\nguarantees, including showing that our algorithm converges linearly to the true\ntensors even when the factors are highly correlated and can be implemented in\nnearly linear time. Moreover our algorithm is also highly practical and we show\nthat we can complete third order tensors with a thousand dimensions from\nobserving a tiny fraction of its entries. In contrast, and somewhat\nsurprisingly, we show that the standard version of alternating minimization,\nwithout our new twist, can converge at a drastically slower rate in practice.",
          "link": "http://arxiv.org/abs/2006.03134",
          "publishedOn": "2023-07-14T01:03:52.966Z",
          "wordCount": null,
          "title": "Tensor Completion Made Practical. (arXiv:2006.03134v2 [cs.DS] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2109.13445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cooper_A/0/1/0/all/0/1\">Avi Cooper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boix_X/0/1/0/all/0/1\">Xavier Boix</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harari_D/0/1/0/all/0/1\">Daniel Harari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madan_S/0/1/0/all/0/1\">Spandan Madan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_H/0/1/0/all/0/1\">Hanspeter Pfister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sasaki_T/0/1/0/all/0/1\">Tomotake Sasaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_P/0/1/0/all/0/1\">Pawan Sinha</a>",
          "description": "The capability of Deep Neural Networks (DNNs) to recognize objects in\norientations outside the distribution of the training data is not well\nunderstood. We present evidence that DNNs are capable of generalizing to\nobjects in novel orientations by disseminating orientation-invariance obtained\nfrom familiar objects seen from many viewpoints. This capability strengthens\nwhen training the DNN with an increasing number of familiar objects, but only\nin orientations that involve 2D rotations of familiar orientations. We show\nthat this dissemination is achieved via neurons tuned to common features\nbetween familiar and unfamiliar objects. These results implicate brain-like\nneural mechanisms for generalization.",
          "link": "http://arxiv.org/abs/2109.13445",
          "publishedOn": "2023-07-14T01:03:52.965Z",
          "wordCount": null,
          "title": "Emergent Neural Network Mechanisms for Generalization to Objects in Novel Orientations. (arXiv:2109.13445v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05825",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chacon_J/0/1/0/all/0/1\">Jos&#xe9; E. Chac&#xf3;n</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Serrano_J/0/1/0/all/0/1\">Javier Fern&#xe1;ndez Serrano</a>",
          "description": "The number of modes in a probability density function is representative of\nthe model's complexity and can also be viewed as the number of existing\nsubpopulations. Despite its relevance, little research has been devoted to its\nestimation. Focusing on the univariate setting, we propose a novel approach\ntargeting prediction accuracy inspired by some overlooked aspects of the\nproblem. We argue for the need for structure in the solutions, the subjective\nand uncertain nature of modes, and the convenience of a holistic view blending\nglobal and local density properties. Our method builds upon a combination of\nflexible kernel estimators and parsimonious compositional splines. Feature\nexploration, model selection and mode testing are implemented in the Bayesian\ninference paradigm, providing soft solutions and allowing to incorporate expert\njudgement in the process. The usefulness of our proposal is illustrated through\na case study in sports analytics, showcasing multiple companion visualisation\ntools. A thorough simulation study demonstrates that traditional\nmodality-driven approaches paradoxically struggle to provide accurate results.\nIn this context, our method emerges as a top-tier alternative offering\ninnovative solutions for analysts.",
          "link": "http://arxiv.org/abs/2307.05825",
          "publishedOn": "2023-07-14T01:03:52.965Z",
          "wordCount": null,
          "title": "Bayesian taut splines for estimating the number of modes. (arXiv:2307.05825v1 [stat.ME] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1901.07186",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Berseth_G/0/1/0/all/0/1\">Glen Berseth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golemo_F/0/1/0/all/0/1\">Florian Golemo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1\">Christopher Pal</a>",
          "description": "Agents that can learn to imitate given video observation -- \\emph{without\ndirect access to state or action information} are more applicable to learning\nin the natural world. However, formulating a reinforcement learning (RL) agent\nthat facilitates this goal remains a significant challenge. We approach this\nchallenge using contrastive training to learn a reward function comparing an\nagent's behaviour with a single demonstration. We use a Siamese recurrent\nneural network architecture to learn rewards in space and time between motion\nclips while training an RL policy to minimize this distance. Through\nexperimentation, we also find that the inclusion of multi-task data and\nadditional image encoding losses improve the temporal consistency of the\nlearned rewards and, as a result, significantly improves policy learning. We\ndemonstrate our approach on simulated humanoid, dog, and raptor agents in 2D\nand a quadruped and a humanoid in 3D. We show that our method outperforms\ncurrent state-of-the-art techniques in these environments and can learn to\nimitate from a single video demonstration.",
          "link": "http://arxiv.org/abs/1901.07186",
          "publishedOn": "2023-07-14T01:03:52.962Z",
          "wordCount": null,
          "title": "Towards Learning to Imitate from a Single Video Demonstration. (arXiv:1901.07186v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.01497",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ilandarideva_S/0/1/0/all/0/1\">Sasila Ilandarideva</a>, <a href=\"http://arxiv.org/find/math/1/au:+Juditsky_A/0/1/0/all/0/1\">Anatoli Juditsky</a>, <a href=\"http://arxiv.org/find/math/1/au:+Lan_G/0/1/0/all/0/1\">Guanghui Lan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Li_T/0/1/0/all/0/1\">Tianjiao Li</a>",
          "description": "We consider a class of stochastic smooth convex optimization problems under\nrather general assumptions on the noise in the stochastic gradient observation.\nAs opposed to the classical problem setting in which the variance of noise is\nassumed to be uniformly bounded, herein we assume that the variance of\nstochastic gradients is related to the \"sub-optimality\" of the approximate\nsolutions delivered by the algorithm. Such problems naturally arise in a\nvariety of applications, in particular, in the well-known generalized linear\nregression problem in statistics. However, to the best of our knowledge, none\nof the existing stochastic approximation algorithms for solving this class of\nproblems attain optimality in terms of the dependence on accuracy, problem\nparameters, and mini-batch size.\n\nWe discuss two non-Euclidean accelerated stochastic approximation\nroutines--stochastic accelerated gradient descent (SAGD) and stochastic\ngradient extrapolation (SGE)--which carry a particular duality relationship. We\nshow that both SAGD and SGE, under appropriate conditions, achieve the optimal\nconvergence rate, attaining the optimal iteration and sample complexities\nsimultaneously. However, corresponding assumptions for the SGE algorithm are\nmore general; they allow, for instance, for efficient application of the SGE to\nstatistical estimation problems under heavy tail noises and discontinuous score\nfunctions. We also discuss the application of the SGE to problems satisfying\nquadratic growth conditions, and show how it can be used to recover sparse\nsolutions. Finally, we report on some simulation experiments to illustrate\nnumerical performance of our proposed algorithms in high-dimensional settings.",
          "link": "http://arxiv.org/abs/2307.01497",
          "publishedOn": "2023-07-14T01:03:52.960Z",
          "wordCount": null,
          "title": "Accelerated stochastic approximation with state-dependent noise. (arXiv:2307.01497v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06753",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruichong Zhang</a>",
          "description": "The learning of Gaussian Mixture Models (also referred to simply as GMMs)\nplays an important role in machine learning. Known for their expressiveness and\ninterpretability, Gaussian mixture models have a wide range of applications,\nfrom statistics, computer vision to distributional reinforcement learning.\nHowever, as of today, few known algorithms can fit or learn these models, some\nof which include Expectation-Maximization algorithms and Sliced Wasserstein\nDistance. Even fewer algorithms are compatible with gradient descent, the\ncommon learning process for neural networks.\n\nIn this paper, we derive a closed formula of two GMMs in the univariate,\none-dimensional case, then propose a distance function called Sliced Cram\\'er\n2-distance for learning general multivariate GMMs. Our approach has several\nadvantages over many previous methods. First, it has a closed-form expression\nfor the univariate case and is easy to compute and implement using common\nmachine learning libraries (e.g., PyTorch and TensorFlow). Second, it is\ncompatible with gradient descent, which enables us to integrate GMMs with\nneural networks seamlessly. Third, it can fit a GMM not only to a set of data\npoints, but also to another GMM directly, without sampling from the target\nmodel. And fourth, it has some theoretical guarantees like global gradient\nboundedness and unbiased sampling gradient. These features are especially\nuseful for distributional reinforcement learning and Deep Q Networks, where the\ngoal is to learn a distribution over future rewards. We will also construct a\nGaussian Mixture Distributional Deep Q Network as a toy example to demonstrate\nits effectiveness. Compared with previous models, this model is parameter\nefficient in terms of representing a distribution and possesses better\ninterpretability.",
          "link": "http://arxiv.org/abs/2307.06753",
          "publishedOn": "2023-07-14T01:03:52.959Z",
          "wordCount": null,
          "title": "Cramer Type Distances for Learning Gaussian Mixture Models by Gradient Descent. (arXiv:2307.06753v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.07252",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Lunde_R/0/1/0/all/0/1\">Robert Lunde</a>",
          "description": "We study the properties of conformal prediction for network data under\nvarious sampling mechanisms that commonly arise in practice but often result in\na non-representative sample of nodes. We interpret these sampling mechanisms as\nselection rules applied to a superpopulation and study the validity of\nconformal prediction conditional on an appropriate selection event. We show\nthat the sampled subarray is exchangeable conditional on the selection event if\nthe selection rule satisfies a permutation invariance property and a joint\nexchangeability condition holds for the superpopulation. Our result implies the\nfinite-sample validity of conformal prediction for certain selection events\nrelated to ego networks and snowball sampling. We also show that when data are\nsampled via a random walk on a graph, a variant of weighted conformal\nprediction yields asymptotically valid prediction sets for an independently\nselected node from the population.",
          "link": "http://arxiv.org/abs/2306.07252",
          "publishedOn": "2023-07-14T01:03:52.957Z",
          "wordCount": null,
          "title": "On the Validity of Conformal Prediction for Network Data Under Non-Uniform Sampling. (arXiv:2306.07252v4 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.06887",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Guneyi_E/0/1/0/all/0/1\">Eylem Tugce Guneyi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yaldiz_B/0/1/0/all/0/1\">Berkay Yaldiz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Canbolat_A/0/1/0/all/0/1\">Abdullah Canbolat</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vural_E/0/1/0/all/0/1\">Elif Vural</a>",
          "description": "The modeling of time-varying graph signals as stationary time-vertex\nstochastic processes permits the inference of missing signal values by\nefficiently employing the correlation patterns of the process across different\ngraph nodes and time instants. In this study, we propose an algorithm for\ncomputing graph autoregressive moving average (graph ARMA) processes based on\nlearning the joint time-vertex power spectral density of the process from its\nincomplete realizations for the task of signal interpolation. Our solution\nrelies on first roughly estimating the joint spectrum of the process from\npartially observed realizations and then refining this estimate by projecting\nit onto the spectrum manifold of the graph ARMA process through convex\nrelaxations. The initially missing signal values are then estimated based on\nthe learnt model. Experimental results show that the proposed approach achieves\nhigh accuracy in time-vertex signal estimation problems.",
          "link": "http://arxiv.org/abs/2302.06887",
          "publishedOn": "2023-07-14T01:03:52.955Z",
          "wordCount": null,
          "title": "Learning Graph ARMA Processes from Time-Vertex Spectra. (arXiv:2302.06887v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06644",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Colomboni_R/0/1/0/all/0/1\">Roberto Colomboni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esposito_E/0/1/0/all/0/1\">Emmanuel Esposito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paudice_A/0/1/0/all/0/1\">Andrea Paudice</a>",
          "description": "The fat-shattering dimension characterizes the uniform convergence property\nof real-valued functions. The state-of-the-art upper bounds feature a\nmultiplicative squared logarithmic factor on the sample complexity, leaving an\nopen gap with the existing lower bound. We provide an improved uniform\nconvergence bound that closes this gap.",
          "link": "http://arxiv.org/abs/2307.06644",
          "publishedOn": "2023-07-14T01:03:52.943Z",
          "wordCount": null,
          "title": "An Improved Uniform Convergence Bound with Fat-Shattering Dimension. (arXiv:2307.06644v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06362",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Seroussi_I/0/1/0/all/0/1\">Inbar Seroussi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Miron_A/0/1/0/all/0/1\">Asaf Miron</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ringel_Z/0/1/0/all/0/1\">Zohar Ringel</a>",
          "description": "Physically informed neural networks (PINNs) are a promising emerging method\nfor solving differential equations. As in many other deep learning approaches,\nthe choice of PINN design and training protocol requires careful craftsmanship.\nHere, we suggest a comprehensive theoretical framework that sheds light on this\nimportant problem. Leveraging an equivalence between infinitely\nover-parameterized neural networks and Gaussian process regression (GPR), we\nderive an integro-differential equation that governs PINN prediction in the\nlarge data-set limit -- the Neurally-Informed Equation (NIE). This equation\naugments the original one by a kernel term reflecting architecture choices and\nallows quantifying implicit bias induced by the network via a spectral\ndecomposition of the source term in the original differential equation.",
          "link": "http://arxiv.org/abs/2307.06362",
          "publishedOn": "2023-07-14T01:03:52.942Z",
          "wordCount": null,
          "title": "Spectral-Bias and Kernel-Task Alignment in Physically Informed Neural Networks. (arXiv:2307.06362v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.00422",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cacciarelli_D/0/1/0/all/0/1\">Davide Cacciarelli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kulahci_M/0/1/0/all/0/1\">Murat Kulahci</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tyssedal_J/0/1/0/all/0/1\">John S&#xf8;lve Tyssedal</a>",
          "description": "In many industrial applications, obtaining labeled observations is not\nstraightforward as it often requires the intervention of human experts or the\nuse of expensive testing equipment. In these circumstances, active learning can\nbe highly beneficial in suggesting the most informative data points to be used\nwhen fitting a model. Reducing the number of observations needed for model\ndevelopment alleviates both the computational burden required for training and\nthe operational expenses related to labeling. Online active learning, in\nparticular, is useful in high-volume production processes where the decision\nabout the acquisition of the label for a data point needs to be taken within an\nextremely short time frame. However, despite the recent efforts to develop\nonline active learning strategies, the behavior of these methods in the\npresence of outliers has not been thoroughly examined. In this work, we\ninvestigate the performance of online active linear regression in contaminated\ndata streams. Our study shows that the currently available query strategies are\nprone to sample outliers, whose inclusion in the training set eventually\ndegrades the predictive performance of the models. To address this issue, we\npropose a solution that bounds the search area of a conditional D-optimal\nalgorithm and uses a robust estimator. Our approach strikes a balance between\nexploring unseen regions of the input space and protecting against outliers.\nThrough numerical simulations, we show that the proposed method is effective in\nimproving the performance of online active learning in the presence of\noutliers, thus expanding the potential applications of this powerful tool.",
          "link": "http://arxiv.org/abs/2302.00422",
          "publishedOn": "2023-07-14T01:03:49.362Z",
          "wordCount": 799,
          "title": "Robust online active learning. (arXiv:2302.00422v5 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06645",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mauro_M/0/1/0/all/0/1\">Mario Di Mauro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galatro_G/0/1/0/all/0/1\">Giovanni Galatro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Postiglione_F/0/1/0/all/0/1\">Fabio Postiglione</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_W/0/1/0/all/0/1\">Wei Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liotta_A/0/1/0/all/0/1\">Antonio Liotta</a>",
          "description": "Predicting the behavior of real-time traffic (e.g., VoIP) in mobility\nscenarios could help the operators to better plan their network infrastructures\nand to optimize the allocation of resources. Accordingly, in this work the\nauthors propose a forecasting analysis of crucial QoS/QoE descriptors (some of\nwhich neglected in the technical literature) of VoIP traffic in a real mobile\nenvironment. The problem is formulated in terms of a multivariate time series\nanalysis. Such a formalization allows to discover and model the temporal\nrelationships among various descriptors and to forecast their behaviors for\nfuture periods. Techniques such as Vector Autoregressive models and machine\nlearning (deep-based and tree-based) approaches are employed and compared in\nterms of performance and time complexity, by reframing the multivariate time\nseries problem into a supervised learning one. Moreover, a series of auxiliary\nanalyses (stationarity, orthogonal impulse responses, etc.) are performed to\ndiscover the analytical structure of the time series and to provide deep\ninsights about their relationships. The whole theoretical analysis has an\nexperimental counterpart since a set of trials across a real-world LTE-Advanced\nenvironment has been performed to collect, post-process and analyze about\n600,000 voice packets, organized per flow and differentiated per codec.",
          "link": "http://arxiv.org/abs/2307.06645",
          "publishedOn": "2023-07-14T01:03:49.339Z",
          "wordCount": 745,
          "title": "Multivariate Time Series characterization and forecasting of VoIP traffic in real mobile networks. (arXiv:2307.06645v1 [cs.NI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2206.09522",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Magesh_A/0/1/0/all/0/1\">Akshayaa Magesh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Veeravalli_V/0/1/0/all/0/1\">Venugopal V. Veeravalli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Roy_A/0/1/0/all/0/1\">Anirban Roy</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jha_S/0/1/0/all/0/1\">Susmit Jha</a>",
          "description": "We study the problem of Out-of-Distribution (OOD) detection, that is,\ndetecting whether a learning algorithm's output can be trusted at inference\ntime. While a number of tests for OOD detection have been proposed in prior\nwork, a formal framework for studying this problem is lacking. We propose a\ndefinition for the notion of OOD that includes both the input distribution and\nthe learning algorithm, which provides insights for the construction of\npowerful tests for OOD detection. We propose a multiple hypothesis testing\ninspired procedure to systematically combine any number of different statistics\nfrom the learning algorithm using conformal p-values. We further provide strong\nguarantees on the probability of incorrectly classifying an in-distribution\nsample as OOD. In our experiments, we find that threshold-based tests proposed\nin prior work perform well in specific settings, but not uniformly well across\ndifferent types of OOD instances. In contrast, our proposed method that\ncombines multiple statistics performs uniformly well across different datasets\nand neural networks.",
          "link": "http://arxiv.org/abs/2206.09522",
          "publishedOn": "2023-07-14T01:03:49.289Z",
          "wordCount": 689,
          "title": "Multiple Testing Framework for Out-of-Distribution Detection. (arXiv:2206.09522v4 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2211.00241",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tony T. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gleave_A/0/1/0/all/0/1\">Adam Gleave</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tseng_T/0/1/0/all/0/1\">Tom Tseng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pelrine_K/0/1/0/all/0/1\">Kellin Pelrine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belrose_N/0/1/0/all/0/1\">Nora Belrose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1\">Joseph Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dennis_M/0/1/0/all/0/1\">Michael D. Dennis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1\">Yawen Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pogrebniak_V/0/1/0/all/0/1\">Viktor Pogrebniak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russell_S/0/1/0/all/0/1\">Stuart Russell</a>",
          "description": "We attack the state-of-the-art Go-playing AI system KataGo by training\nadversarial policies against it, achieving a >97% win rate against KataGo\nrunning at superhuman settings. Our adversaries do not win by playing Go well.\nInstead, they trick KataGo into making serious blunders. Our attack transfers\nzero-shot to other superhuman Go-playing AIs, and is comprehensible to the\nextent that human experts can implement it without algorithmic assistance to\nconsistently beat superhuman AIs. The core vulnerability uncovered by our\nattack persists even in KataGo agents adversarially trained to defend against\nour attack. Our results demonstrate that even superhuman AI systems may harbor\nsurprising failure modes. Example games are available https://goattack.far.ai/.",
          "link": "http://arxiv.org/abs/2211.00241",
          "publishedOn": "2023-07-14T01:03:49.284Z",
          "wordCount": 687,
          "title": "Adversarial Policies Beat Superhuman Go AIs. (arXiv:2211.00241v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06581",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lee_H/0/1/0/all/0/1\">Hangbin Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+HA_I/0/1/0/all/0/1\">IL DO HA</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_Y/0/1/0/all/0/1\">Youngjo Lee</a>",
          "description": "For prediction of clustered time-to-event data, we propose a new deep neural\nnetwork based gamma frailty model (DNN-FM). An advantage of the proposed model\nis that the joint maximization of the new h-likelihood provides maximum\nlikelihood estimators for fixed parameters and best unbiased predictors for\nrandom frailties. Thus, the proposed DNN-FM is trained by using a negative\nprofiled h-likelihood as a loss function, constructed by profiling out the\nnon-parametric baseline hazard. Experimental studies show that the proposed\nmethod enhances the prediction performance of the existing methods. A real data\nanalysis shows that the inclusion of subject-specific frailties helps to\nimprove prediction of the DNN based Cox model (DNN-Cox).",
          "link": "http://arxiv.org/abs/2307.06581",
          "publishedOn": "2023-07-14T01:03:49.266Z",
          "wordCount": 615,
          "title": "Deep Neural Networks for Semiparametric Frailty Models via H-likelihood. (arXiv:2307.06581v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06542",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Kerger_P/0/1/0/all/0/1\">Phillip Kerger</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Miyazaki_R/0/1/0/all/0/1\">Ryoji Miyazaki</a>",
          "description": "We investigate a framework for binary image denoising via restricted\nBoltzmann machines (RBMs) that introduces a denoising objective in quadratic\nunconstrained binary optimization (QUBO) form and is well-suited for quantum\nannealing. The denoising objective is attained by balancing the distribution\nlearned by a trained RBM with a penalty term for derivations from the noisy\nimage. We derive the statistically optimal choice of the penalty parameter\nassuming the target distribution has been well-approximated, and further\nsuggest an empirically supported modification to make the method robust to that\nidealistic assumption. We also show under additional assumptions that the\ndenoised images attained by our method are, in expectation, strictly closer to\nthe noise-free images than the noisy images are. While we frame the model as an\nimage denoising model, it can be applied to any binary data. As the QUBO\nformulation is well-suited for implementation on quantum annealers, we test the\nmodel on a D-Wave Advantage machine, and also test on data too large for\ncurrent quantum annealers by approximating QUBO solutions through classical\nheuristics.",
          "link": "http://arxiv.org/abs/2307.06542",
          "publishedOn": "2023-07-14T01:03:49.260Z",
          "wordCount": 713,
          "title": "An Image-Denoising Framework Fit for Quantum Annealing via QUBO and Restricted Boltzmann Machines. (arXiv:2307.06542v1 [quant-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.11873",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Elsemuller_L/0/1/0/all/0/1\">Lasse Elsem&#xfc;ller</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Schnuerch_M/0/1/0/all/0/1\">Martin Schnuerch</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Burkner_P/0/1/0/all/0/1\">Paul-Christian B&#xfc;rkner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Radev_S/0/1/0/all/0/1\">Stefan T. Radev</a>",
          "description": "Bayesian model comparison (BMC) offers a principled approach for assessing\nthe relative merits of competing computational models and propagating\nuncertainty into model selection decisions. However, BMC is often intractable\nfor the popular class of hierarchical models due to their high-dimensional\nnested parameter structure. To address this intractability, we propose a deep\nlearning method for performing BMC on any set of hierarchical models which can\nbe instantiated as probabilistic programs. Since our method enables amortized\ninference, it allows efficient re-estimation of posterior model probabilities\nand fast performance validation prior to any real-data application. In a series\nof extensive validation studies, we benchmark the performance of our method\nagainst the state-of-the-art bridge sampling method and demonstrate excellent\namortized inference across all BMC settings. We then showcase our method by\ncomparing four hierarchical evidence accumulation models that have previously\nbeen deemed intractable for BMC due to partly implicit likelihoods. In this\napplication, we corroborate evidence for the recently proposed L\\'evy flight\nmodel of decision-making and show how transfer learning can be leveraged to\nenhance training efficiency. We provide reproducible code for all analyses and\nan open-source implementation of our method.",
          "link": "http://arxiv.org/abs/2301.11873",
          "publishedOn": "2023-07-14T01:03:49.251Z",
          "wordCount": 722,
          "title": "A Deep Learning Method for Comparing Bayesian Hierarchical Models. (arXiv:2301.11873v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2202.04428",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dorfman_R/0/1/0/all/0/1\">Ron Dorfman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_K/0/1/0/all/0/1\">Kfir Y. Levy</a>",
          "description": "We consider stochastic optimization problems where data is drawn from a\nMarkov chain. Existing methods for this setting crucially rely on knowing the\nmixing time of the chain, which in real-world applications is usually unknown.\nWe propose the first optimization method that does not require the knowledge of\nthe mixing time, yet obtains the optimal asymptotic convergence rate when\napplied to convex problems. We further show that our approach can be extended\nto: (i) finding stationary points in non-convex optimization with Markovian\ndata, and (ii) obtaining better dependence on the mixing time in temporal\ndifference (TD) learning; in both cases, our method is completely oblivious to\nthe mixing time. Our method relies on a novel combination of multi-level Monte\nCarlo (MLMC) gradient estimation together with an adaptive learning method.",
          "link": "http://arxiv.org/abs/2202.04428",
          "publishedOn": "2023-07-14T01:03:49.228Z",
          "wordCount": 674,
          "title": "Adapting to Mixing Time in Stochastic Optimization with Markovian Data. (arXiv:2202.04428v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2102.06984",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_H/0/1/0/all/0/1\">Hanbaek Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kureh_Y/0/1/0/all/0/1\">Yacoub H. Kureh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vendrow_J/0/1/0/all/0/1\">Joshua Vendrow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Porter_M/0/1/0/all/0/1\">Mason A. Porter</a>",
          "description": "It is common to use networks to encode the architecture of interactions\nbetween entities in complex systems in the physical, biological, social, and\ninformation sciences. To study the large-scale behavior of complex systems, it\nis useful to examine mesoscale structures in networks as building blocks that\ninfluence such behavior. We present a new approach for describing low-rank\nmesoscale structures in networks, and we illustrate our approach using several\nsynthetic network models and empirical friendship, collaboration, and\nprotein--protein interaction (PPI) networks. We find that these networks\npossess a relatively small number of `latent motifs' that together can\nsuccessfully approximate most subgraphs of a network at a fixed mesoscale. We\nuse an algorithm for `network dictionary learning' (NDL), which combines a\nnetwork-sampling method and nonnegative matrix factorization, to learn the\nlatent motifs of a given network. The ability to encode a network using a set\nof latent motifs has a wide variety of applications to network-analysis tasks,\nsuch as comparison, denoising, and edge inference. Additionally, using a new\nnetwork denoising and reconstruction (NDR) algorithm, we demonstrate how to\ndenoise a corrupted network by using only the latent motifs that one learns\ndirectly from the corrupted network.",
          "link": "http://arxiv.org/abs/2102.06984",
          "publishedOn": "2023-07-14T01:03:49.218Z",
          "wordCount": 778,
          "title": "Learning low-rank latent mesoscale structures in networks. (arXiv:2102.06984v5 [cs.SI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06555",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shijun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jianfeng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hongkai Zhao</a>",
          "description": "This paper explores the expressive power of deep neural networks for a\ndiverse range of activation functions. An activation function set $\\mathscr{A}$\nis defined to encompass the majority of commonly used activation functions,\nsuch as $\\mathtt{ReLU}$, $\\mathtt{LeakyReLU}$, $\\mathtt{ReLU}^2$,\n$\\mathtt{ELU}$, $\\mathtt{SELU}$, $\\mathtt{Softplus}$, $\\mathtt{GELU}$,\n$\\mathtt{SiLU}$, $\\mathtt{Swish}$, $\\mathtt{Mish}$, $\\mathtt{Sigmoid}$,\n$\\mathtt{Tanh}$, $\\mathtt{Arctan}$, $\\mathtt{Softsign}$, $\\mathtt{dSiLU}$, and\n$\\mathtt{SRS}$. We demonstrate that for any activation function $\\varrho\\in\n\\mathscr{A}$, a $\\mathtt{ReLU}$ network of width $N$ and depth $L$ can be\napproximated to arbitrary precision by a $\\varrho$-activated network of width\n$6N$ and depth $2L$ on any bounded set. This finding enables the extension of\nmost approximation results achieved with $\\mathtt{ReLU}$ networks to a wide\nvariety of other activation functions, at the cost of slightly larger\nconstants.",
          "link": "http://arxiv.org/abs/2307.06555",
          "publishedOn": "2023-07-14T01:03:49.211Z",
          "wordCount": 630,
          "title": "Deep Network Approximation: Beyond ReLU to Diverse Activation Functions. (arXiv:2307.06555v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.10741",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Baum_J/0/1/0/all/0/1\">Jerome Baum</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kanagawa_H/0/1/0/all/0/1\">Heishiro Kanagawa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1\">Arthur Gretton</a>",
          "description": "We propose a goodness-of-fit measure for probability densities modeling\nobservations with varying dimensionality, such as text documents of differing\nlengths or variable-length sequences. The proposed measure is an instance of\nthe kernel Stein discrepancy (KSD), which has been used to construct\ngoodness-of-fit tests for unnormalized densities. The KSD is defined by its\nStein operator: current operators used in testing apply to fixed-dimensional\nspaces. As our main contribution, we extend the KSD to the variable-dimension\nsetting by identifying appropriate Stein operators, and propose a novel KSD\ngoodness-of-fit test. As with the previous variants, the proposed KSD does not\nrequire the density to be normalized, allowing the evaluation of a large class\nof models. Our test is shown to perform well in practice on discrete sequential\ndata benchmarks.",
          "link": "http://arxiv.org/abs/2210.10741",
          "publishedOn": "2023-07-14T01:03:49.200Z",
          "wordCount": 678,
          "title": "A kernel Stein test of goodness of fit for sequential models. (arXiv:2210.10741v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06538",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bakshi_A/0/1/0/all/0/1\">Ainesh Bakshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Allen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1\">Ankur Moitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yau_M/0/1/0/all/0/1\">Morris Yau</a>",
          "description": "Recently Chen and Poor initiated the study of learning mixtures of linear\ndynamical systems. While linear dynamical systems already have wide-ranging\napplications in modeling time-series data, using mixture models can lead to a\nbetter fit or even a richer understanding of underlying subpopulations\nrepresented in the data. In this work we give a new approach to learning\nmixtures of linear dynamical systems that is based on tensor decompositions. As\na result, our algorithm succeeds without strong separation conditions on the\ncomponents, and can be used to compete with the Bayes optimal clustering of the\ntrajectories. Moreover our algorithm works in the challenging\npartially-observed setting. Our starting point is the simple but powerful\nobservation that the classic Ho-Kalman algorithm is a close relative of modern\ntensor decomposition methods for learning latent variable models. This gives us\na playbook for how to extend it to work with more complicated generative\nmodels.",
          "link": "http://arxiv.org/abs/2307.06538",
          "publishedOn": "2023-07-14T01:03:49.162Z",
          "wordCount": 691,
          "title": "Tensor Decompositions Meet Control Theory: Learning General Mixtures of Linear Dynamical Systems. (arXiv:2307.06538v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06831",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Caprio_M/0/1/0/all/0/1\">Michele Caprio</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sale_Y/0/1/0/all/0/1\">Yusuf Sale</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hullermeier_E/0/1/0/all/0/1\">Eyke H&#xfc;llermeier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_I/0/1/0/all/0/1\">Insup Lee</a>",
          "description": "In their seminal 1990 paper, Wasserman and Kadane establish an upper bound\nfor the Bayes' posterior probability of a measurable set $A$, when the prior\nlies in a class of probability measures $\\mathcal{P}$ and the likelihood is\nprecise. They also give a sufficient condition for such upper bound to hold\nwith equality. In this paper, we introduce a generalization of their result by\nadditionally addressing uncertainty related to the likelihood. We give an upper\nbound for the posterior probability when both the prior and the likelihood\nbelong to a set of probabilities. Furthermore, we give a sufficient condition\nfor this upper bound to become an equality. This result is interesting on its\nown, and has the potential of being applied to various fields of engineering\n(e.g. model predictive control), machine learning, and artificial intelligence.",
          "link": "http://arxiv.org/abs/2307.06831",
          "publishedOn": "2023-07-14T01:03:49.153Z",
          "wordCount": 625,
          "title": "A Novel Bayes' Theorem for Upper Probabilities. (arXiv:2307.06831v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06877",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Papadimitriou_C/0/1/0/all/0/1\">Christos Papadimitriou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Binghui Peng</a>",
          "description": "The problem of continual learning in the domain of reinforcement learning,\noften called non-stationary reinforcement learning, has been identified as an\nimportant challenge to the application of reinforcement learning. We prove a\nworst-case complexity result, which we believe captures this challenge:\nModifying the probabilities or the reward of a single state-action pair in a\nreinforcement learning problem requires an amount of time almost as large as\nthe number of states in order to keep the value function up to date, unless the\nstrong exponential time hypothesis (SETH) is false; SETH is a widely accepted\nstrengthening of the P $\\neq$ NP conjecture. Recall that the number of states\nin current applications of reinforcement learning is typically astronomical. In\ncontrast, we show that just $\\textit{adding}$ a new state-action pair is\nconsiderably easier to implement.",
          "link": "http://arxiv.org/abs/2307.06877",
          "publishedOn": "2023-07-14T01:03:49.148Z",
          "wordCount": 630,
          "title": "The complexity of non-stationary reinforcement learning. (arXiv:2307.06877v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06915",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wei_Z/0/1/0/all/0/1\">Ziyang Wei</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhu_W/0/1/0/all/0/1\">Wanrong Zhu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wu_W/0/1/0/all/0/1\">Wei Biao Wu</a>",
          "description": "Stochastic Gradient Descent (SGD) is one of the simplest and most popular\nalgorithms in modern statistical and machine learning due to its computational\nand memory efficiency. Various averaging schemes have been proposed to\naccelerate the convergence of SGD in different settings. In this paper, we\nexplore a general averaging scheme for SGD. Specifically, we establish the\nasymptotic normality of a broad range of weighted averaged SGD solutions and\nprovide asymptotically valid online inference approaches. Furthermore, we\npropose an adaptive averaging scheme that exhibits both optimal statistical\nrate and favorable non-asymptotic convergence, drawing insights from the\noptimal weight for the linear model in terms of non-asymptotic mean squared\nerror (MSE).",
          "link": "http://arxiv.org/abs/2307.06915",
          "publishedOn": "2023-07-14T01:03:49.142Z",
          "wordCount": 605,
          "title": "Weighted Averaged Stochastic Gradient Descent: Asymptotic Normality and Optimality. (arXiv:2307.06915v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06424",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bridgman_W/0/1/0/all/0/1\">Wyatt Bridgman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Jones_R/0/1/0/all/0/1\">Reese Jones</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Khalil_M/0/1/0/all/0/1\">Mohammad Khalil</a>",
          "description": "For predictive modeling relying on Bayesian inversion, fully independent, or\n``mean-field'', Gaussian distributions are often used as approximate\nprobability density functions in variational inference since the number of\nvariational parameters is twice the number of unknown model parameters. The\nresulting diagonal covariance structure coupled with unimodal behavior can be\ntoo restrictive when dealing with highly non-Gaussian behavior, including\nmultimodality. High-fidelity surrogate posteriors in the form of Gaussian\nmixtures can capture any distribution to an arbitrary degree of accuracy while\nmaintaining some analytical tractability. Variational inference with Gaussian\nmixtures with full-covariance structures suffers from a quadratic growth in\nvariational parameters with the number of model parameters. Coupled with the\nexistence of multiple local minima due to nonconvex trends in the loss\nfunctions often associated with variational inference, these challenges\nmotivate the need for robust initialization procedures to improve the\nperformance and scalability of variational inference with mixture models.\n\nIn this work, we propose a method for constructing an initial Gaussian\nmixture model approximation that can be used to warm-start the iterative\nsolvers for variational inference. The procedure begins with an optimization\nstage in model parameter space in which local gradient-based optimization,\nglobalized through multistart, is used to determine a set of local maxima,\nwhich we take to approximate the mixture component centers. Around each mode, a\nlocal Gaussian approximation is constructed via the Laplace method. Finally,\nthe mixture weights are determined through constrained least squares\nregression. Robustness and scalability are demonstrated using synthetic tests.\nThe methodology is applied to an inversion problem in structural dynamics\ninvolving unknown viscous damping coefficients.",
          "link": "http://arxiv.org/abs/2307.06424",
          "publishedOn": "2023-07-14T01:03:49.076Z",
          "wordCount": 777,
          "title": "Robust scalable initialization for Bayesian variational inference with multi-modal Laplace approximations. (arXiv:2307.06424v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06431",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Schroder_T/0/1/0/all/0/1\">Tobias Schr&#xf6;der</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ou_Z/0/1/0/all/0/1\">Zijing Ou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lim_J/0/1/0/all/0/1\">Jen Ning Lim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1\">Yingzhen Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vollmer_S/0/1/0/all/0/1\">Sebastian J. Vollmer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Duncan_A/0/1/0/all/0/1\">Andrew B. Duncan</a>",
          "description": "Energy-based models are a simple yet powerful class of probabilistic models,\nbut their widespread adoption has been limited by the computational burden of\ntraining them. We propose a novel loss function called Energy Discrepancy (ED)\nwhich does not rely on the computation of scores or expensive Markov chain\nMonte Carlo. We show that ED approaches the explicit score matching and\nnegative log-likelihood loss under different limits, effectively interpolating\nbetween both. Consequently, minimum ED estimation overcomes the problem of\nnearsightedness encountered in score-based estimation methods, while also\nenjoying theoretical guarantees. Through numerical experiments, we demonstrate\nthat ED learns low-dimensional data distributions faster and more accurately\nthan explicit score matching or contrastive divergence. For high-dimensional\nimage data, we describe how the manifold hypothesis puts limitations on our\napproach and demonstrate the effectiveness of energy discrepancy by training\nthe energy-based model as a prior of a variational decoder model.",
          "link": "http://arxiv.org/abs/2307.06431",
          "publishedOn": "2023-07-14T01:03:49.070Z",
          "wordCount": 654,
          "title": "Energy Discrepancies: A Score-Independent Loss for Energy-Based Models. (arXiv:2307.06431v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06457",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Simchowitz_M/0/1/0/all/0/1\">Max Simchowitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaiqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Abhishek Gupta</a>",
          "description": "Obtaining rigorous statistical guarantees for generalization under\ndistribution shift remains an open and active research area. We study a setting\nwe call combinatorial distribution shift, where (a) under the test- and\ntraining-distributions, the labels $z$ are determined by pairs of features\n$(x,y)$, (b) the training distribution has coverage of certain marginal\ndistributions over $x$ and $y$ separately, but (c) the test distribution\ninvolves examples from a product distribution over $(x,y)$ that is {not}\ncovered by the training distribution. Focusing on the special case where the\nlabels are given by bilinear embeddings into a Hilbert space $H$: $\\mathbb{E}[z\n\\mid x,y ]=\\langle f_{\\star}(x),g_{\\star}(y)\\rangle_{{H}}$, we aim to\nextrapolate to a test distribution domain that is $not$ covered in training,\ni.e., achieving bilinear combinatorial extrapolation.\n\nOur setting generalizes a special case of matrix completion from\nmissing-not-at-random data, for which all existing results require the\nground-truth matrices to be either exactly low-rank, or to exhibit very sharp\nspectral cutoffs. In this work, we develop a series of theoretical results that\nenable bilinear combinatorial extrapolation under gradual spectral decay as\nobserved in typical high-dimensional data, including novel algorithms,\ngeneralization guarantees, and linear-algebraic results. A key tool is a novel\nperturbation bound for the rank-$k$ singular value decomposition approximations\nbetween two matrices that depends on the relative spectral gap rather than the\nabsolute spectral gap, a result that may be of broader independent interest.",
          "link": "http://arxiv.org/abs/2307.06457",
          "publishedOn": "2023-07-14T01:03:49.065Z",
          "wordCount": 745,
          "title": "Tackling Combinatorial Distribution Shift: A Matrix Completion Perspective. (arXiv:2307.06457v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06442",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yu-Zhen Janice Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menasche_D/0/1/0/all/0/1\">Daniel S. Menasch&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Towsley_D/0/1/0/all/0/1\">Don Towsley</a>",
          "description": "We study sensor/agent data collection and collaboration policies for\nparameter estimation, accounting for resource constraints and correlation\nbetween observations collected by distinct sensors/agents. Specifically, we\nconsider a group of sensors/agents each samples from different variables of a\nmultivariate Gaussian distribution and has different estimation objectives, and\nwe formulate a sensor/agent's data collection and collaboration policy design\nproblem as a Fisher information maximization (or Cramer-Rao bound minimization)\nproblem. When the knowledge of correlation between variables is available, we\nanalytically identify two particular scenarios: (1) where the knowledge of the\ncorrelation between samples cannot be leveraged for collaborative estimation\npurposes and (2) where the optimal data collection policy involves investing\nscarce resources to collaboratively sample and transfer information that is not\nof immediate interest and whose statistics are already known, with the sole\ngoal of increasing the confidence on the estimate of the parameter of interest.\nWhen the knowledge of certain correlation is unavailable but collaboration may\nstill be worthwhile, we propose novel ways to apply multi-armed bandit\nalgorithms to learn the optimal data collection and collaboration policy in our\ndistributed parameter estimation problem and demonstrate that the proposed\nalgorithms, DOUBLE-F, DOUBLE-Z, UCB-F, UCB-Z, are effective through\nsimulations.",
          "link": "http://arxiv.org/abs/2307.06442",
          "publishedOn": "2023-07-14T01:03:49.057Z",
          "wordCount": 723,
          "title": "On Collaboration in Distributed Parameter Estimation with Resource Constraints. (arXiv:2307.06442v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06406",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Duttweiler_L/0/1/0/all/0/1\">Luke Duttweiler</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Thurston_S/0/1/0/all/0/1\">Sally W. Thurston</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Almudevar_A/0/1/0/all/0/1\">Anthony Almudevar</a>",
          "description": "Bayesian network (BN) structure discovery algorithms typically either make\nassumptions about the sparsity of the true underlying network, or are limited\nby computational constraints to networks with a small number of variables.\nWhile these sparsity assumptions can take various forms, frequently the\nassumptions focus on an upper bound for the maximum in-degree of the underlying\ngraph $\\nabla_G$. Theorem 2 in Duttweiler et. al. (2023) demonstrates that the\nlargest eigenvalue of the normalized inverse covariance matrix ($\\Omega$) of a\nlinear BN is a lower bound for $\\nabla_G$. Building on this result, this paper\nprovides the asymptotic properties of, and a debiasing procedure for, the\nsample eigenvalues of $\\Omega$, leading to a hypothesis test that may be used\nto determine if the BN has max in-degree greater than 1. A linear BN structure\ndiscovery workflow is suggested in which the investigator uses this hypothesis\ntest to aid in selecting an appropriate structure discovery algorithm. The\nhypothesis test performance is evaluated through simulations and the workflow\nis demonstrated on data from a human psoriasis study.",
          "link": "http://arxiv.org/abs/2307.06406",
          "publishedOn": "2023-07-14T01:03:49.051Z",
          "wordCount": 670,
          "title": "Testing Sparsity Assumptions in Bayesian Networks. (arXiv:2307.06406v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2301.07040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pal_S/0/1/0/all/0/1\">Soumyabrata Pal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suggala_A/0/1/0/all/0/1\">Arun Sai Suggala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shanmugam_K/0/1/0/all/0/1\">Karthikeyan Shanmugam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1\">Prateek Jain</a>",
          "description": "We consider the problem of latent bandits with cluster structure where there\nare multiple users, each with an associated multi-armed bandit problem. These\nusers are grouped into \\emph{latent} clusters such that the mean reward vectors\nof users within the same cluster are identical. At each round, a user, selected\nuniformly at random, pulls an arm and observes a corresponding noisy reward.\nThe goal of the users is to maximize their cumulative rewards. This problem is\ncentral to practical recommendation systems and has received wide attention of\nlate \\cite{gentile2014online, maillard2014latent}. Now, if each user acts\nindependently, then they would have to explore each arm independently and a\nregret of $\\Omega(\\sqrt{\\mathsf{MNT}})$ is unavoidable, where $\\mathsf{M},\n\\mathsf{N}$ are the number of arms and users, respectively. Instead, we propose\nLATTICE (Latent bAndiTs via maTrIx ComplEtion) which allows exploitation of the\nlatent cluster structure to provide the minimax optimal regret of\n$\\widetilde{O}(\\sqrt{(\\mathsf{M}+\\mathsf{N})\\mathsf{T}})$, when the number of\nclusters is $\\widetilde{O}(1)$. This is the first algorithm to guarantee such\nstrong regret bound. LATTICE is based on a careful exploitation of arm\ninformation within a cluster while simultaneously clustering users.\nFurthermore, it is computationally efficient and requires only\n$O(\\log{\\mathsf{T}})$ calls to an offline matrix completion oracle across all\n$\\mathsf{T}$ rounds.",
          "link": "http://arxiv.org/abs/2301.07040",
          "publishedOn": "2023-07-12T01:02:46.944Z",
          "wordCount": null,
          "title": "Optimal Algorithms for Latent Bandits with Cluster Structure. (arXiv:2301.07040v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05109",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guha_E/0/1/0/all/0/1\">Etash Kumar Guha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ndiaye_E/0/1/0/all/0/1\">Eugene Ndiaye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huo_X/0/1/0/all/0/1\">Xiaoming Huo</a>",
          "description": "Given a sequence of observable variables $\\{(x_1, y_1), \\ldots, (x_n,\ny_n)\\}$, the conformal prediction method estimates a confidence set for\n$y_{n+1}$ given $x_{n+1}$ that is valid for any finite sample size by merely\nassuming that the joint distribution of the data is permutation invariant.\nAlthough attractive, computing such a set is computationally infeasible in most\nregression problems. Indeed, in these cases, the unknown variable $y_{n+1}$ can\ntake an infinite number of possible candidate values, and generating conformal\nsets requires retraining a predictive model for each candidate. In this paper,\nwe focus on a sparse linear model with only a subset of variables for\nprediction and use numerical continuation techniques to approximate the\nsolution path efficiently. The critical property we exploit is that the set of\nselected variables is invariant under a small perturbation of the input data.\nTherefore, it is sufficient to enumerate and refit the model only at the change\npoints of the set of active features and smoothly interpolate the rest of the\nsolution via a Predictor-Corrector mechanism. We show how our path-following\nalgorithm accurately approximates conformal prediction sets and illustrate its\nperformance using synthetic and real data examples.",
          "link": "http://arxiv.org/abs/2307.05109",
          "publishedOn": "2023-07-12T01:02:46.943Z",
          "wordCount": null,
          "title": "Conformalization of Sparse Generalized Linear Models. (arXiv:2307.05109v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05194",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Jewson_J/0/1/0/all/0/1\">Jack Jewson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ghalebikesabi_S/0/1/0/all/0/1\">Sahra Ghalebikesabi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Holmes_C/0/1/0/all/0/1\">Chris Holmes</a>",
          "description": "Differential privacy guarantees allow the results of a statistical analysis\ninvolving sensitive data to be released without compromising the privacy of any\nindividual taking part. Achieving such guarantees generally requires the\ninjection of noise, either directly into parameter estimates or into the\nestimation process. Instead of artificially introducing perturbations, sampling\nfrom Bayesian posterior distributions has been shown to be a special case of\nthe exponential mechanism, producing consistent, and efficient private\nestimates without altering the data generative process. The application of\ncurrent approaches has, however, been limited by their strong bounding\nassumptions which do not hold for basic models, such as simple linear\nregressors. To ameliorate this, we propose $\\beta$D-Bayes, a posterior sampling\nscheme from a generalised posterior targeting the minimisation of the\n$\\beta$-divergence between the model and the data generating process. This\nprovides private estimation that is generally applicable without requiring\nchanges to the underlying model and consistently learns the data generating\nparameter. We show that $\\beta$D-Bayes produces more precise inference\nestimation for the same privacy guarantees, and further facilitates\ndifferentially private estimation via posterior sampling for complex\nclassifiers and continuous regression models such as neural networks for the\nfirst time.",
          "link": "http://arxiv.org/abs/2307.05194",
          "publishedOn": "2023-07-12T01:02:46.941Z",
          "wordCount": null,
          "title": "Differentially Private Statistical Inference through $\\beta$-Divergence One Posterior Sampling. (arXiv:2307.05194v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04954",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sengupta_A/0/1/0/all/0/1\">Agnimitra Sengupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Adway Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guler_S/0/1/0/all/0/1\">S. Ilgin Guler</a>",
          "description": "Deep learning (DL) methods have outperformed parametric models such as\nhistorical average, ARIMA and variants in predicting traffic variables into\nshort and near-short future, that are critical for traffic management.\nSpecifically, recurrent neural network (RNN) and its variants (e.g. long\nshort-term memory) are designed to retain long-term temporal correlations and\ntherefore are suitable for modeling sequences. However, multi-regime models\nassume the traffic system to evolve through multiple states (say, free-flow,\ncongestion in traffic) with distinct characteristics, and hence, separate\nmodels are trained to characterize the traffic dynamics within each regime. For\ninstance, Markov-switching models with a hidden Markov model (HMM) for regime\nidentification is capable of capturing complex dynamic patterns and\nnon-stationarity. Interestingly, both HMM and LSTM can be used for modeling an\nobservation sequence from a set of latent or, hidden state variables. In LSTM,\nthe latent variable is computed in a deterministic manner from the current\nobservation and the previous latent variable, while, in HMM, the set of latent\nvariables is a Markov chain. Inspired by research in natural language\nprocessing, a hybrid hidden Markov-LSTM model that is capable of learning\ncomplementary features in traffic data is proposed for traffic flow prediction.\nResults indicate significant performance gains in using hybrid architecture\ncompared to conventional methods such as Markov switching ARIMA and LSTM.",
          "link": "http://arxiv.org/abs/2307.04954",
          "publishedOn": "2023-07-12T01:02:46.892Z",
          "wordCount": null,
          "title": "Hybrid hidden Markov LSTM for short-term traffic flow prediction. (arXiv:2307.04954v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.02011",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cai_T/0/1/0/all/0/1\">Tiffany Tianhui Cai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Namkoong_H/0/1/0/all/0/1\">Hongseok Namkoong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yadlowsky_S/0/1/0/all/0/1\">Steve Yadlowsky</a>",
          "description": "Prediction models can perform poorly when deployed to target distributions\ndifferent from the training distribution. To understand these operational\nfailure modes, we develop a method, called DIstribution Shift DEcomposition\n(DISDE), to attribute a drop in performance to different types of distribution\nshifts. Our approach decomposes the performance drop into terms for 1) an\nincrease in harder but frequently seen examples from training, 2) changes in\nthe relationship between features and outcomes, and 3) poor performance on\nexamples infrequent or unseen during training. These terms are defined by\nfixing a distribution on $X$ while varying the conditional distribution of $Y\n\\mid X$ between training and target, or by fixing the conditional distribution\nof $Y \\mid X$ while varying the distribution on $X$. In order to do this, we\ndefine a hypothetical distribution on $X$ consisting of values common in both\ntraining and target, over which it is easy to compare $Y \\mid X$ and thus\npredictive performance. We estimate performance on this hypothetical\ndistribution via reweighting methods. Empirically, we show how our method can\n1) inform potential modeling improvements across distribution shifts for\nemployment prediction on tabular census data, and 2) help to explain why\ncertain domain adaptation methods fail to improve model performance for\nsatellite image classification.",
          "link": "http://arxiv.org/abs/2303.02011",
          "publishedOn": "2023-07-12T01:02:46.890Z",
          "wordCount": null,
          "title": "Diagnosing Model Performance Under Distribution Shift. (arXiv:2303.02011v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05252",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Simon_H/0/1/0/all/0/1\">Hans Ulrich Simon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Telle_J/0/1/0/all/0/1\">Jan Arne Telle</a>",
          "description": "Imagine a learner L who tries to infer a hidden concept from a collection of\nobservations. Building on the work [4] of Ferri et al., we assume the learner\nto be parameterized by priors P(c) and by c-conditional likelihoods P(z|c)\nwhere c ranges over all concepts in a given class C and z ranges over all\nobservations in an observation set Z. L is called a MAP-learner (resp. an\nMLE-learner) if it thinks of a collection S of observations as a random sample\nand returns the concept with the maximum a-posteriori probability (resp. the\nconcept which maximizes the c-conditional likelihood of S). Depending on\nwhether L assumes that S is obtained from ordered or unordered sampling resp.\nfrom sampling with or without replacement, we can distinguish four different\nsampling modes. Given a target concept c in C, a teacher for a MAP-learner L\naims at finding a smallest collection of observations that causes L to return\nc. This approach leads in a natural manner to various notions of a MAP- or\nMLE-teaching dimension of a concept class C. Our main results are: We show that\nthis teaching model has some desirable monotonicity properties. We clarify how\nthe four sampling modes are related to each other. As for the (important!)\nspecial case, where concepts are subsets of a domain and observations are\n0,1-labeled examples, we obtain some additional results. First of all, we\ncharacterize the MAP- and MLE-teaching dimension associated with an optimally\nparameterized MAP-learner graph-theoretically. From this central result, some\nother ones are easy to derive. It is shown, for instance, that the MLE-teaching\ndimension is either equal to the MAP-teaching dimension or exceeds the latter\nby 1. It is shown furthermore that these dimensions can be bounded from above\nby the so-called antichain number, the VC-dimension and related combinatorial\nparameters. Moreover they can be computed in polynomial time.",
          "link": "http://arxiv.org/abs/2307.05252",
          "publishedOn": "2023-07-12T01:02:46.872Z",
          "wordCount": null,
          "title": "MAP- and MLE-Based Teaching. (arXiv:2307.05252v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.01282",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jerdee_M/0/1/0/all/0/1\">Maximilian Jerdee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirkley_A/0/1/0/all/0/1\">Alec Kirkley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Newman_M/0/1/0/all/0/1\">M. E. J. Newman</a>",
          "description": "Normalized mutual information is widely used as a similarity measure for\nevaluating the performance of clustering and classification algorithms. In this\npaper, we show that results returned by the normalized mutual information are\nbiased for two reasons: first, because they ignore the information content of\nthe contingency table and, second, because their symmetric normalization\nintroduces spurious dependence on algorithm output. We introduce a modified\nversion of the mutual information that remedies both of these shortcomings. As\na practical demonstration of the importance of using an unbiased measure, we\nperform extensive numerical tests on a basket of popular algorithms for network\ncommunity detection and show that one's conclusions about which algorithm is\nbest are significantly affected by the biases in the traditional mutual\ninformation.",
          "link": "http://arxiv.org/abs/2307.01282",
          "publishedOn": "2023-07-12T01:02:46.871Z",
          "wordCount": null,
          "title": "Normalized mutual information is a biased measure for classification and community detection. (arXiv:2307.01282v1 [cs.SI] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.08004",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Landa_B/0/1/0/all/0/1\">Boris Landa</a>, <a href=\"http://arxiv.org/find/math/1/au:+Cheng_X/0/1/0/all/0/1\">Xiuyuan Cheng</a>",
          "description": "The Gaussian kernel and its traditional normalizations (e.g., row-stochastic)\nare popular approaches for assessing similarities between data points. Yet,\nthey can be inaccurate under high-dimensional noise, especially if the noise\nmagnitude varies considerably across the data, e.g., under heteroskedasticity\nor outliers. In this work, we investigate a more robust alternative -- the\ndoubly stochastic normalization of the Gaussian kernel. We consider a setting\nwhere points are sampled from an unknown density on a low-dimensional manifold\nembedded in high-dimensional space and corrupted by possibly strong,\nnon-identically distributed, sub-Gaussian noise. We establish that the doubly\nstochastic affinity matrix and its scaling factors concentrate around certain\npopulation forms, and provide corresponding finite-sample probabilistic error\nbounds. We then utilize these results to develop several tools for robust\ninference under general high-dimensional noise. First, we derive a robust\ndensity estimator that reliably infers the underlying sampling density and can\nsubstantially outperform the standard kernel density estimator under\nheteroskedasticity and outliers. Second, we obtain estimators for the pointwise\nnoise magnitudes, the pointwise signal magnitudes, and the pairwise Euclidean\ndistances between clean data points. Lastly, we derive robust graph Laplacian\nnormalizations that accurately approximate various manifold Laplacians,\nincluding the Laplace Beltrami operator, improving over traditional\nnormalizations in noisy settings. We exemplify our results in simulations and\non real single-cell RNA-sequencing data. For the latter, we show that in\ncontrast to traditional methods, our approach is robust to variability in\ntechnical noise levels across cell types.",
          "link": "http://arxiv.org/abs/2209.08004",
          "publishedOn": "2023-07-12T01:02:46.840Z",
          "wordCount": null,
          "title": "Robust Inference of Manifold Density and Geometry by Doubly Stochastic Scaling. (arXiv:2209.08004v2 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04998",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sekhari_A/0/1/0/all/0/1\">Ayush Sekhari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sridharan_K/0/1/0/all/0/1\">Karthik Sridharan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wen Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1\">Runzhe Wu</a>",
          "description": "We consider the problem of Imitation Learning (IL) by actively querying noisy\nexpert for feedback. While imitation learning has been empirically successful,\nmuch of prior work assumes access to noiseless expert feedback which is not\npractical in many applications. In fact, when one only has access to noisy\nexpert feedback, algorithms that rely on purely offline data (non-interactive\nIL) can be shown to need a prohibitively large number of samples to be\nsuccessful. In contrast, in this work, we provide an interactive algorithm for\nIL that uses selective sampling to actively query the noisy expert for\nfeedback. Our contributions are twofold: First, we provide a new selective\nsampling algorithm that works with general function classes and multiple\nactions, and obtains the best-known bounds for the regret and the number of\nqueries. Next, we extend this analysis to the problem of IL with noisy expert\nfeedback and provide a new IL algorithm that makes limited queries.\n\nOur algorithm for selective sampling leverages function approximation, and\nrelies on an online regression oracle w.r.t.~the given model class to predict\nactions, and to decide whether to query the expert for its label. On the\ntheoretical side, the regret bound of our algorithm is upper bounded by the\nregret of the online regression oracle, while the query complexity additionally\ndepends on the eluder dimension of the model class. We complement this with a\nlower bound that demonstrates that our results are tight. We extend our\nselective sampling algorithm for IL with general function approximation and\nprovide bounds on both the regret and the number of queries made to the noisy\nexpert. A key novelty here is that our regret and query complexity bounds only\ndepend on the number of times the optimal policy (and not the noisy expert, or\nthe learner) go to states that have a small margin.",
          "link": "http://arxiv.org/abs/2307.04998",
          "publishedOn": "2023-07-12T01:02:46.839Z",
          "wordCount": null,
          "title": "Selective Sampling and Imitation Learning via Online Regression. (arXiv:2307.04998v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.13487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1\">Dylan J. Foster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1\">Sham M. Kakade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1\">Jian Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rakhlin_A/0/1/0/all/0/1\">Alexander Rakhlin</a>",
          "description": "A fundamental challenge in interactive learning and decision making, ranging\nfrom bandit problems to reinforcement learning, is to provide sample-efficient,\nadaptive learning algorithms that achieve near-optimal regret. This question is\nanalogous to the classical problem of optimal (supervised) statistical\nlearning, where there are well-known complexity measures (e.g., VC dimension\nand Rademacher complexity) that govern the statistical complexity of learning.\nHowever, characterizing the statistical complexity of interactive learning is\nsubstantially more challenging due to the adaptive nature of the problem. The\nmain result of this work provides a complexity measure, the Decision-Estimation\nCoefficient, that is proven to be both necessary and sufficient for\nsample-efficient interactive learning. In particular, we provide:\n\n1. a lower bound on the optimal regret for any interactive decision making\nproblem, establishing the Decision-Estimation Coefficient as a fundamental\nlimit.\n\n2. a unified algorithm design principle, Estimation-to-Decisions (E2D), which\ntransforms any algorithm for supervised estimation into an online algorithm for\ndecision making. E2D attains a regret bound that matches our lower bound up to\ndependence on a notion of estimation performance, thereby achieving optimal\nsample-efficient learning as characterized by the Decision-Estimation\nCoefficient.\n\nTaken together, these results constitute a theory of learnability for\ninteractive decision making. When applied to reinforcement learning settings,\nthe Decision-Estimation Coefficient recovers essentially all existing hardness\nresults and lower bounds. More broadly, the approach can be viewed as a\ndecision-theoretic analogue of the classical Le Cam theory of statistical\nestimation; it also unifies a number of existing approaches -- both Bayesian\nand frequentist.",
          "link": "http://arxiv.org/abs/2112.13487",
          "publishedOn": "2023-07-12T01:02:46.515Z",
          "wordCount": null,
          "title": "The Statistical Complexity of Interactive Decision Making. (arXiv:2112.13487v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.02733",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Laar_T/0/1/0/all/0/1\">Thijs van de Laar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Koudahl_M/0/1/0/all/0/1\">Magnus Koudahl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vries_B/0/1/0/all/0/1\">Bert de Vries</a>",
          "description": "The Free Energy Principle (FEP) describes (biological) agents as minimising a\nvariational Free Energy (FE) with respect to a generative model of their\nenvironment. Active Inference (AIF) is a corollary of the FEP that describes\nhow agents explore and exploit their environment by minimising an expected FE\nobjective. In two related papers, we describe a scalable, epistemic approach to\nsynthetic AIF agents, by message passing on free-form Forney-style Factor\nGraphs (FFGs). A companion paper (part I) introduces a Constrained FFG (CFFG)\nnotation that visually represents (generalised) FE objectives for AIF. The\ncurrent paper (part II) derives message passing algorithms that minimise\n(generalised) FE objectives on a CFFG by variational calculus. A comparison\nbetween simulated Bethe and generalised FE agents illustrates how synthetic AIF\ninduces epistemic behaviour on a T-maze navigation task. With a full message\npassing account of synthetic AIF agents, it becomes possible to derive and\nreuse message updates across models and move closer to industrial applications\nof synthetic AIF.",
          "link": "http://arxiv.org/abs/2306.02733",
          "publishedOn": "2023-07-12T01:02:46.471Z",
          "wordCount": null,
          "title": "Realising Synthetic Active Inference Agents, Part II: Variational Message Updates. (arXiv:2306.02733v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1906.08947",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1\">Branislav Kveton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1\">Manzil Zaheer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1\">Csaba Szepesvari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lihong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1\">Mohammad Ghavamzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boutilier_C/0/1/0/all/0/1\">Craig Boutilier</a>",
          "description": "We study two randomized algorithms for generalized linear bandits. The first,\nGLM-TSL, samples a generalized linear model (GLM) from the Laplace\napproximation to the posterior distribution. The second, GLM-FPL, fits a GLM to\na randomly perturbed history of past rewards. We analyze both algorithms and\nderive $\\tilde{O}(d \\sqrt{n \\log K})$ upper bounds on their $n$-round regret,\nwhere $d$ is the number of features and $K$ is the number of arms. The former\nimproves on prior work while the latter is the first for Gaussian noise\nperturbations in non-linear models. We empirically evaluate both GLM-TSL and\nGLM-FPL in logistic bandits, and apply GLM-FPL to neural network bandits. Our\nwork showcases the role of randomization, beyond posterior sampling, in\nexploration.",
          "link": "http://arxiv.org/abs/1906.08947",
          "publishedOn": "2023-07-12T01:02:46.460Z",
          "wordCount": null,
          "title": "Randomized Exploration in Generalized Linear Bandits. (arXiv:1906.08947v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05341",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Suk_J/0/1/0/all/0/1\">Joe Suk</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kpotufe_S/0/1/0/all/0/1\">Samory Kpotufe</a>",
          "description": "We study nonparametric contextual bandits where Lipschitz mean reward\nfunctions may change over time. We first establish the minimax dynamic regret\nrate in this less understood setting in terms of number of changes $L$ and\ntotal-variation $V$, both capturing all changes in distribution over context\nspace, and argue that state-of-the-art procedures are suboptimal in this\nsetting.\n\nNext, we tend to the question of an adaptivity for this setting, i.e.\nachieving the minimax rate without knowledge of $L$ or $V$. Quite importantly,\nwe posit that the bandit problem, viewed locally at a given context $X_t$,\nshould not be affected by reward changes in other parts of context space $\\cal\nX$. We therefore propose a notion of change, which we term experienced\nsignificant shifts, that better accounts for locality, and thus counts\nconsiderably less changes than $L$ and $V$. Furthermore, similar to recent work\non non-stationary MAB (Suk & Kpotufe, 2022), experienced significant shifts\nonly count the most significant changes in mean rewards, e.g., severe best-arm\nchanges relevant to observed contexts.\n\nOur main result is to show that this more tolerant notion of change can in\nfact be adapted to.",
          "link": "http://arxiv.org/abs/2307.05341",
          "publishedOn": "2023-07-12T01:02:46.406Z",
          "wordCount": null,
          "title": "Tracking Most Significant Shifts in Nonparametric Contextual Bandits. (arXiv:2307.05341v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.04318",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Grillo_M/0/1/0/all/0/1\">Milo Grillo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Han_Y/0/1/0/all/0/1\">Yunpeng Han</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Werpachowska_A/0/1/0/all/0/1\">Agnieszka Werpachowska</a>",
          "description": "We propose a simple and efficient approach to generate a prediction intervals\n(PI) for approximated and forecasted trends. Our method leverages a weighted\nasymmetric loss function to estimate the lower and upper bounds of the PI, with\nthe weights determined by its coverage probability. We provide a concise\nmathematical proof of the method, show how it can be extended to derive PIs for\nparametrised functions and argue why the method works for predicting PIs of\ndependent variables. The presented tests of the method on a real-world\nforecasting task using a neural network-based model show that it can produce\nreliable PIs in complex machine learning scenarios.",
          "link": "http://arxiv.org/abs/2210.04318",
          "publishedOn": "2023-07-12T01:02:46.406Z",
          "wordCount": null,
          "title": "Prediction intervals for neural network models using weighted asymmetric loss functions. (arXiv:2210.04318v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05384",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Chen_X/0/1/0/all/0/1\">Xuxing Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Balasubramanian_K/0/1/0/all/0/1\">Krishnakumar Balasubramanian</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ghadimi_S/0/1/0/all/0/1\">Saeed Ghadimi</a>",
          "description": "We develop and analyze stochastic approximation algorithms for solving nested\ncompositional bi-level optimization problems. These problems involve a nested\ncomposition of $T$ potentially non-convex smooth functions in the upper-level,\nand a smooth and strongly convex function in the lower-level. Our proposed\nalgorithm does not rely on matrix inversions or mini-batches and can achieve an\n$\\epsilon$-stationary solution with an oracle complexity of approximately\n$\\tilde{O}_T(1/\\epsilon^{2})$, assuming the availability of stochastic\nfirst-order oracles for the individual functions in the composition and the\nlower-level, which are unbiased and have bounded moments. Here, $\\tilde{O}_T$\nhides polylog factors and constants that depend on $T$. The key challenge we\naddress in establishing this result relates to handling three distinct sources\nof bias in the stochastic gradients. The first source arises from the\ncompositional nature of the upper-level, the second stems from the bi-level\nstructure, and the third emerges due to the utilization of Neumann series\napproximations to avoid matrix inversion. To demonstrate the effectiveness of\nour approach, we apply it to the problem of robust feature learning for deep\nneural networks under covariate shift, showcasing the benefits and advantages\nof our methodology in that context.",
          "link": "http://arxiv.org/abs/2307.05384",
          "publishedOn": "2023-07-12T01:02:46.405Z",
          "wordCount": null,
          "title": "Stochastic Nested Compositional Bi-level Optimization for Robust Feature Learning. (arXiv:2307.05384v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.11680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yuan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_D/0/1/0/all/0/1\">Difan Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1\">Quanquan Gu</a>",
          "description": "We study the implicit bias of batch normalization trained by gradient\ndescent. We show that when learning a linear model with batch normalization for\nbinary classification, gradient descent converges to a uniform margin\nclassifier on the training data with an $\\exp(-\\Omega(\\log^2 t))$ convergence\nrate. This distinguishes linear models with batch normalization from those\nwithout batch normalization in terms of both the type of implicit bias and the\nconvergence rate. We further extend our result to a class of two-layer,\nsingle-filter linear convolutional neural networks, and show that batch\nnormalization has an implicit bias towards a patch-wise uniform margin. Based\non two examples, we demonstrate that patch-wise uniform margin classifiers can\noutperform the maximum margin classifiers in certain learning problems. Our\nresults contribute to a better theoretical understanding of batch\nnormalization.",
          "link": "http://arxiv.org/abs/2306.11680",
          "publishedOn": "2023-07-12T01:02:46.405Z",
          "wordCount": null,
          "title": "The Implicit Bias of Batch Normalization in Linear Models and Two-layer Linear Convolutional Neural Networks. (arXiv:2306.11680v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.00890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Santoni_M/0/1/0/all/0/1\">Maria Laura Santoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raponi_E/0/1/0/all/0/1\">Elena Raponi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leone_R/0/1/0/all/0/1\">Renato De Leone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doerr_C/0/1/0/all/0/1\">Carola Doerr</a>",
          "description": "Bayesian Optimization (BO) is a class of black-box, surrogate-based\nheuristics that can efficiently optimize problems that are expensive to\nevaluate, and hence admit only small evaluation budgets. BO is particularly\npopular for solving numerical optimization problems in industry, where the\nevaluation of objective functions often relies on time-consuming simulations or\nphysical experiments. However, many industrial problems depend on a large\nnumber of parameters. This poses a challenge for BO algorithms, whose\nperformance is often reported to suffer when the dimension grows beyond 15\nvariables. Although many new algorithms have been proposed to address this\nproblem, it is not well understood which one is the best for which optimization\nscenario.\n\nIn this work, we compare five state-of-the-art high-dimensional BO\nalgorithms, with vanilla BO and CMA-ES on the 24 BBOB functions of the COCO\nenvironment at increasing dimensionality, ranging from 10 to 60 variables. Our\nresults confirm the superiority of BO over CMA-ES for limited evaluation\nbudgets and suggest that the most promising approach to improve BO is the use\nof trust regions. However, we also observe significant performance differences\nfor different function landscapes and budget exploitation phases, indicating\nimprovement potential, e.g., through hybridization of algorithmic components.",
          "link": "http://arxiv.org/abs/2303.00890",
          "publishedOn": "2023-07-12T01:02:46.400Z",
          "wordCount": null,
          "title": "Comparison of High-Dimensional Bayesian Optimization Algorithms on BBOB. (arXiv:2303.00890v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05251",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Okuno_A/0/1/0/all/0/1\">Akifumi Okuno</a>",
          "description": "Density power divergence (DPD) [Basu et al. (1998), Biometrika], designed to\nestimate the underlying distribution of the observations robustly, comprises an\nintegral term of the power of the parametric density models to be estimated.\nWhile the explicit form of the integral term can be obtained for some specific\ndensities (such as normal density and exponential density), its computational\nintractability has prohibited the application of DPD-based estimation to more\ngeneral parametric densities, over a quarter of a century since the proposal of\nDPD. This study proposes a stochastic optimization approach to minimize DPD for\ngeneral parametric density models and explains its adequacy by referring to\nconventional theories on stochastic optimization. The proposed approach also\ncan be applied to the minimization of another density power-based\n$\\gamma$-divergence with the aid of unnormalized models [Kanamori and Fujisawa\n(2015), Biometrika].",
          "link": "http://arxiv.org/abs/2307.05251",
          "publishedOn": "2023-07-12T01:02:46.399Z",
          "wordCount": null,
          "title": "A stochastic optimization approach to minimize robust density power-based divergences for general parametric density models. (arXiv:2307.05251v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.16015",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Radev_S/0/1/0/all/0/1\">Stefan T Radev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmitt_M/0/1/0/all/0/1\">Marvin Schmitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schumacher_L/0/1/0/all/0/1\">Lukas Schumacher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elsemuller_L/0/1/0/all/0/1\">Lasse Elsem&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pratz_V/0/1/0/all/0/1\">Valentin Pratz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schalte_Y/0/1/0/all/0/1\">Yannik Sch&#xe4;lte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kothe_U/0/1/0/all/0/1\">Ullrich K&#xf6;the</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burkner_P/0/1/0/all/0/1\">Paul-Christian B&#xfc;rkner</a>",
          "description": "Modern Bayesian inference involves a mixture of computational techniques for\nestimating, validating, and drawing conclusions from probabilistic models as\npart of principled workflows for data analysis. Typical problems in Bayesian\nworkflows are the approximation of intractable posterior distributions for\ndiverse model types and the comparison of competing models of the same process\nin terms of their complexity and predictive performance. This manuscript\nintroduces the Python library BayesFlow for simulation-based training of\nestablished neural network architectures for amortized data compression and\ninference. Amortized Bayesian inference, as implemented in BayesFlow, enables\nusers to train custom neural networks on model simulations and re-use these\nnetworks for any subsequent application of the models. Since the trained\nnetworks can perform inference almost instantaneously, the upfront neural\nnetwork training is quickly amortized.",
          "link": "http://arxiv.org/abs/2306.16015",
          "publishedOn": "2023-07-12T01:02:46.399Z",
          "wordCount": null,
          "title": "BayesFlow: Amortized Bayesian Workflows With Neural Networks. (arXiv:2306.16015v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05431",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Mathieu_E/0/1/0/all/0/1\">Emile Mathieu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dutordoir_V/0/1/0/all/0/1\">Vincent Dutordoir</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hutchinson_M/0/1/0/all/0/1\">Michael J. Hutchinson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bortoli_V/0/1/0/all/0/1\">Valentin De Bortoli</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Teh_Y/0/1/0/all/0/1\">Yee Whye Teh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1\">Richard E. Turner</a>",
          "description": "Denoising diffusion models have proven to be a flexible and effective\nparadigm for generative modelling. Their recent extension to infinite\ndimensional Euclidean spaces has allowed for the modelling of stochastic\nprocesses. However, many problems in the natural sciences incorporate\nsymmetries and involve data living in non-Euclidean spaces. In this work, we\nextend the framework of diffusion models to incorporate a series of geometric\npriors in infinite-dimension modelling. We do so by a) constructing a noising\nprocess which admits, as limiting distribution, a geometric Gaussian process\nthat transforms under the symmetry group of interest, and b) approximating the\nscore with a neural network that is equivariant w.r.t. this group. We show that\nwith these conditions, the generative functional model admits the same\nsymmetry. We demonstrate scalability and capacity of the model, using a novel\nLangevin-based conditional sampler, to fit complex scalar and vector fields,\nwith Euclidean and spherical codomain, on synthetic and real-world weather\ndata.",
          "link": "http://arxiv.org/abs/2307.05431",
          "publishedOn": "2023-07-12T01:02:46.398Z",
          "wordCount": null,
          "title": "Geometric Neural Diffusion Processes. (arXiv:2307.05431v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05352",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Baur_M/0/1/0/all/0/1\">Michael Baur</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fesl_B/0/1/0/all/0/1\">Benedikt Fesl</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Utschick_W/0/1/0/all/0/1\">Wolfgang Utschick</a>",
          "description": "In this manuscript, we propose to utilize the generative neural network-based\nvariational autoencoder for channel estimation. The variational autoencoder\nmodels the underlying true but unknown channel distribution as a conditional\nGaussian distribution in a novel way. The derived channel estimator exploits\nthe internal structure of the variational autoencoder to parameterize an\napproximation of the mean squared error optimal estimator resulting from the\nconditional Gaussian channel models. We provide a rigorous analysis under which\nconditions a variational autoencoder-based estimator is mean squared error\noptimal. We then present considerations that make the variational\nautoencoder-based estimator practical and propose three different estimator\nvariants that differ in their access to channel knowledge during the training\nand evaluation phase. In particular, the proposed estimator variant trained\nsolely on noisy pilot observations is particularly noteworthy as it does not\nrequire access to noise-free, ground-truth channel data during training or\nevaluation. Extensive numerical simulations first analyze the internal behavior\nof the variational autoencoder-based estimators and then demonstrate excellent\nchannel estimation performance compared to related classical and machine\nlearning-based state-of-the-art channel estimators.",
          "link": "http://arxiv.org/abs/2307.05352",
          "publishedOn": "2023-07-12T01:02:45.952Z",
          "wordCount": null,
          "title": "Leveraging Variational Autoencoders for Parameterized MMSE Channel Estimation. (arXiv:2307.05352v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04957",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_W/0/1/0/all/0/1\">Wei Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wei Yu</a>",
          "description": "In reinforcement learning, the objective is almost always defined as a\n\\emph{cumulative} function over the rewards along the process. However, there\nare many optimal control and reinforcement learning problems in various\napplication fields, especially in communications and networking, where the\nobjectives are not naturally expressed as summations of the rewards. In this\npaper, we recognize the prevalence of non-cumulative objectives in various\nproblems, and propose a modification to existing algorithms for optimizing such\nobjectives. Specifically, we dive into the fundamental building block for many\noptimal control and reinforcement learning algorithms: the Bellman optimality\nequation. To optimize a non-cumulative objective, we replace the original\nsummation operation in the Bellman update rule with a generalized operation\ncorresponding to the objective. Furthermore, we provide sufficient conditions\non the form of the generalized operation as well as assumptions on the Markov\ndecision process under which the globally optimal convergence of the\ngeneralized Bellman updates can be guaranteed. We demonstrate the idea\nexperimentally with the bottleneck objective, i.e., the objectives determined\nby the minimum reward along the process, on classical optimal control and\nreinforcement learning tasks, as well as on two network routing problems on\nmaximizing the flow rates.",
          "link": "http://arxiv.org/abs/2307.04957",
          "publishedOn": "2023-07-12T01:02:45.945Z",
          "wordCount": null,
          "title": "Reinforcement Learning with Non-Cumulative Objective. (arXiv:2307.04957v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04779",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Descours_A/0/1/0/all/0/1\">Arnaud Descours</a> (LMBP), <a href=\"http://arxiv.org/find/stat/1/au:+Huix_T/0/1/0/all/0/1\">Tom Huix</a> (X), <a href=\"http://arxiv.org/find/stat/1/au:+Guillin_A/0/1/0/all/0/1\">Arnaud Guillin</a> (LMBP), <a href=\"http://arxiv.org/find/stat/1/au:+Michel_M/0/1/0/all/0/1\">Manon Michel</a> (LMBP), <a href=\"http://arxiv.org/find/stat/1/au:+Moulines_E/0/1/0/all/0/1\">&#xc9;ric Moulines</a> (X), <a href=\"http://arxiv.org/find/stat/1/au:+Nectoux_B/0/1/0/all/0/1\">Boris Nectoux</a> (LMBP)",
          "description": "We provide a rigorous analysis of training by variational inference (VI) of\nBayesian neural networks in the two-layer and infinite-width case. We consider\na regression problem with a regularized evidence lower bound (ELBO) which is\ndecomposed into the expected log-likelihood of the data and the\nKullback-Leibler (KL) divergence between the a priori distribution and the\nvariational posterior. With an appropriate weighting of the KL, we prove a law\nof large numbers for three different training schemes: (i) the idealized case\nwith exact estimation of a multiple Gaussian integral from the\nreparametrization trick, (ii) a minibatch scheme using Monte Carlo sampling,\ncommonly known as Bayes by Backprop, and (iii) a new and computationally\ncheaper algorithm which we introduce as Minimal VI. An important result is that\nall methods converge to the same mean-field limit. Finally, we illustrate our\nresults numerically and discuss the need for the derivation of a central limit\ntheorem.",
          "link": "http://arxiv.org/abs/2307.04779",
          "publishedOn": "2023-07-12T01:02:45.874Z",
          "wordCount": null,
          "title": "Law of Large Numbers for Bayesian two-layer Neural Network trained with Variational Inference. (arXiv:2307.04779v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1903.09132",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1\">Branislav Kveton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1\">Csaba Szepesvari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1\">Mohammad Ghavamzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boutilier_C/0/1/0/all/0/1\">Craig Boutilier</a>",
          "description": "We propose a new online algorithm for cumulative regret minimization in a\nstochastic linear bandit. The algorithm pulls the arm with the highest\nestimated reward in a linear model trained on its perturbed history. Therefore,\nwe call it perturbed-history exploration in a linear bandit (LinPHE). The\nperturbed history is a mixture of observed rewards and randomly generated\ni.i.d. pseudo-rewards. We derive a $\\tilde{O}(d \\sqrt{n})$ gap-free bound on\nthe $n$-round regret of LinPHE, where $d$ is the number of features. The key\nsteps in our analysis are new concentration and anti-concentration bounds on\nthe weighted sum of Bernoulli random variables. To show the generality of our\ndesign, we generalize LinPHE to a logistic model. We evaluate our algorithms\nempirically and show that they are practical.",
          "link": "http://arxiv.org/abs/1903.09132",
          "publishedOn": "2023-07-12T01:02:45.846Z",
          "wordCount": null,
          "title": "Perturbed-History Exploration in Stochastic Linear Bandits. (arXiv:1903.09132v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.04841",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bordelon_B/0/1/0/all/0/1\">Blake Bordelon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Masset_P/0/1/0/all/0/1\">Paul Masset</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kuo_H/0/1/0/all/0/1\">Henry Kuo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pehlevan_C/0/1/0/all/0/1\">Cengiz Pehlevan</a>",
          "description": "Reinforcement learning has been successful across several applications in\nwhich agents have to learn to act in environments with sparse feedback.\nHowever, despite this empirical success there is still a lack of theoretical\nunderstanding of how the parameters of reinforcement learning models and the\nfeatures used to represent states interact to control the dynamics of learning.\nIn this work, we use concepts from statistical physics, to study the typical\ncase learning curves for temporal difference learning of a value function with\nlinear function approximators. Our theory is derived under a Gaussian\nequivalence hypothesis where averages over the random trajectories are replaced\nwith temporally correlated Gaussian feature averages and we validate our\nassumptions on small scale Markov Decision Processes. We find that the\nstochastic semi-gradient noise due to subsampling the space of possible\nepisodes leads to significant plateaus in the value error, unlike in\ntraditional gradient descent dynamics. We study how learning dynamics and\nplateaus depend on feature structure, learning rate, discount factor, and\nreward function. We then analyze how strategies like learning rate annealing\nand reward shaping can favorably alter learning dynamics and plateaus. To\nconclude, our work introduces new tools to open a new direction towards\ndeveloping a theory of learning dynamics in reinforcement learning.",
          "link": "http://arxiv.org/abs/2307.04841",
          "publishedOn": "2023-07-12T01:02:45.746Z",
          "wordCount": null,
          "title": "Dynamics of Temporal Difference Reinforcement Learning. (arXiv:2307.04841v1 [stat.ML])",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Machine Learning",
      "feedUrl": "https://www.reddit.com/r/MachineLearning/.rss",
      "siteUrl": "https://www.reddit.com/r/MachineLearning/",
      "articles": [
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15mtj1y/neurips_rebuttal_character_limit_problem_d/",
          "author": null,
          "description": "The NeurIPS rebuttal has a 6000 character limit, however my rebuttal is way way over that. I was told by my supervisor that you could just comment chain onto the rebuttal to get past this, however that is not working.\n The deadline is in around 5 hours so I'm really in a big bind here. Does anyone have any insight about how to resolve this situation?\n    submitted by    /u/Pyramid_Jumper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15mtj1y/neurips_rebuttal_character_limit_problem_d/",
          "publishedOn": "2023-08-09T22:20:27.000Z",
          "wordCount": 2569,
          "title": "NeurIPS rebuttal character limit problem [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ms0cq/get_into_ml_role_d/",
          "author": null,
          "description": "Hey guys, I am working as an SDET amd previously work as a developer. I am currently enrolled in Machine Learning masters online with job with Learning each course I am not sure how to get into the job market for this role. What projects should I create, kaggle seems to be just copy paste from each other.Any suggestions?\n    submitted by    /u/Latter_Ad_5679  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ms0cq/get_into_ml_role_d/",
          "publishedOn": "2023-08-09T21:23:35.000Z",
          "wordCount": 2561,
          "title": "Get into ML role [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15mr16l/is_a_good_idea_to_do_leetcode_for_computer_and/",
          "author": null,
          "description": "It is something that sounds too much lately but I'm not sure about if it worths for those areas.\n    submitted by    /u/Otherwise-Bike4761  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15mr16l/is_a_good_idea_to_do_leetcode_for_computer_and/",
          "publishedOn": "2023-08-09T20:47:40.000Z",
          "wordCount": 2529,
          "title": "Is a good idea to do leetcode for Computer and Data scientist? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15mqe4r/d_ideal_embedding_models_for_classifying_news/",
          "author": null,
          "description": "I’m looking to build functionality that would allow a user to specify topics to be notified about in the news, eg. “Tax law changes in New York”, and notify them of recently published news articles related to that topic.\n Would the ideal strategy be to find relating articles to topics, or topics relating to articles as they come in? What models would be ideal here? I’m fairly new to this, so any help would be appreciated.\n    submitted by    /u/ByteBuff  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15mqe4r/d_ideal_embedding_models_for_classifying_news/",
          "publishedOn": "2023-08-09T20:23:12.000Z",
          "wordCount": 2586,
          "title": "[D] Ideal embedding models for classifying news articles to topics, specified as sentences",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15mph12/simple_synthetic_data_reduces_sycophancy_in_llms_r/",
          "author": null,
          "description": "submitted by    /u/we_are_mammals  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15mph12/simple_synthetic_data_reduces_sycophancy_in_llms_r/",
          "publishedOn": "2023-08-09T19:49:03.000Z",
          "wordCount": 2516,
          "title": "Simple synthetic data reduces sycophancy in LLMs [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15moc4k/d_does_it_make_sense_to_switch_to_premoderation/",
          "author": null,
          "description": "Moderators are doing a great job, but often by the time a post is deleted it already hit too many eyeballs. Now that everyone and their mom are into AI, does it make sense to switch to premoderation for new members and members who do not follow the rules of the subreddit?\n    submitted by    /u/lostmsu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15moc4k/d_does_it_make_sense_to_switch_to_premoderation/",
          "publishedOn": "2023-08-09T19:05:58.000Z",
          "wordCount": 2558,
          "title": "[D] Does it make sense to switch to premoderation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15mnbxc/d_seeking_insights_and_collaboration_on_deep/",
          "author": null,
          "description": "This project is the culmination of genuine effort and innovation by a team of dedicated professionals. We welcome constructive feedback and value your insights to help us improve and grow. Thank you for engaging with us respectfully.\n Hello AI and blockchain enthusiasts!\n I'm part of the team at Deep Engine AI, where we are working on an exciting project that involves building a Universal Adaptive Intelligence System (UAIS). One of our key concepts is what we're calling \"Pervasive Swarm Learning.\" It's a blend of holistic swarm intelligence models, community-managed ecosystems, and innovative algorithms.\n We're reaching out to this knowledgeable community to get your thoughts, insights, or any innovative ideas that could help us refine and build out this concept. Whether you're an AI researcher, data scientist, blockchain expert, or simply someone interested in the field, your input could be invaluable to us.\n Here's a quick overview of what we're focusing on:\n  \nHolistic Swarm Intelligence Models: Incorporating stochastic optimization, neuromorphic computing, and quantum-inspired algorithms for adaptability and resilience.\n Global Community-Managed Ecosystem: Enhancing our DAO with transparent and real-time community feedback loops.\n  \nWe believe in the power of collaboration and the collective intelligence of this community. If you have any insights, questions, or want to know more about what we're working on, please comment below or feel free to send me a private message\n If you want to dive deeper into our project, here's a link to our website.\n Thank you for taking the time to read this post. We look forward to hearing your thoughts and potentially collaborating with some of you!\n    submitted by    /u/deepengineai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15mnbxc/d_seeking_insights_and_collaboration_on_deep/",
          "publishedOn": "2023-08-09T18:28:28.000Z",
          "wordCount": 2773,
          "title": "[D] Seeking Insights and Collaboration on Deep Engine AI's Hive Concept for Universal Adaptive Intelligence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15mm06v/d_what_are_the_ml_engineer_hours_per_week_worked/",
          "author": null,
          "description": "Two ways to answer this question:\n  \nWhat is the average amount of hours?\n What is the amount of hours in a specific position that you are familiar with?\n  \nI'm also wondering about non-academic ML PhDs who now work in industry.\n    submitted by    /u/Practical_Tea_3779  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15mm06v/d_what_are_the_ml_engineer_hours_per_week_worked/",
          "publishedOn": "2023-08-09T17:39:17.000Z",
          "wordCount": 2547,
          "title": "[D] What are the ML engineer hours per week worked?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ml8n0/project_making_amd_gpus_competitive_for_llm/",
          "author": null,
          "description": "There have been many LLM inference solutions since the bloom of open-source LLMs. Most of the performant inference solutions are based on CUDA and optimized for NVIDIA GPUs. In the meantime, with the high demand for compute availability, it is useful to bring support to a broader class of hardware accelerators. AMD is one potential candidate.\n We build a project that makes it possible to compile LLMs and deploy them on AMD GPUs using ROCm and get competitive performance. More specifically, AMD Radeon™ RX 7900 XTX gives 80% of the speed of NVIDIA® GeForce RTX™ 4090 and 94% of the speed of NVIDIA® GeForce RTX™ 3090Ti for single batch Llama2-7B/13B 4bit inference. Besides ROCm, our Vulkan support allows us to generalize LLM deployment to other AMD devices, for example, a SteamDeck with an AMD APU.\n - Github: https://github.com/mlc-ai/mlc-llm/\n - Blogpost describing the techniques: https://blog.mlc.ai/2023/08/09/Making-AMD-GPUs-competitive-for-LLM-inference\n ​\n ​\n    submitted by    /u/crowwork  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ml8n0/project_making_amd_gpus_competitive_for_llm/",
          "publishedOn": "2023-08-09T17:11:17.000Z",
          "wordCount": 2648,
          "title": "[Project] Making AMD GPUs competitive for LLM inference",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15mjeu2/d_doing_a_phd_in_embedded_systems_machine_learning/",
          "author": null,
          "description": "I am currently thinking about doing a PhD after I am done with my Master's thesis because the topic of my thesis is so fascinating. However, I put the possibility of doing a PhD aside because I was always more \"hands-on\" rather than academic / research focused.\n Would you say a PhD in the intersection of embedded systems + machine learning (maybe training a model \"on the edge\" with the sensor data of the embedded device) is beneficial regarding finding a job afterwards?\n    submitted by    /u/LM1117  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15mjeu2/d_doing_a_phd_in_embedded_systems_machine_learning/",
          "publishedOn": "2023-08-09T16:02:44.000Z",
          "wordCount": 2590,
          "title": "[D]: Doing a PhD in Embedded Systems + Machine Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15mizh5/d_how_can_i_determine_if_an_llms_response_is/",
          "author": null,
          "description": "I've become interested in how LLMs express emotions through their responses. Here's an example:\n [Q] = I am having a bad day\n [R] = I'm sorry to hear that you're having a bad day. Is there anything specific you'd like to talk about or any way I can help you feel better? Whether it's just a listening ear... \n I am aware that LLMs are not conscious and have no real understanding of emotions. But it is clear from the example that they can produce emotionally appropriate responses. Is there some kind of systematic test that can be automated to verify this? I.e. given a text-based query and response determine if the response is empathetic. \n    submitted by    /u/boringdude123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15mizh5/d_how_can_i_determine_if_an_llms_response_is/",
          "publishedOn": "2023-08-09T15:47:20.000Z",
          "wordCount": 2622,
          "title": "[D] How can I determine if an LLM's response is empathetic?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15mffz9/p_using_lidar_and_photography_to_locate_fire/",
          "author": null,
          "description": "[P]I have imagery and lidar from trucks (cyclomedia). I would like to extract the latitude and longitude of fire hydrants from the images and point clouds.. I posted in r/computervision and they said it would be inaccurate to use imagery to locate fire hydrants.\n Do you have any tips on getting location from photographic images?\n Are there any open source neural nets for street view point clouds that can help?\n Is this an either/or problem or is it possible to use both data sources combined?\n    submitted by    /u/Zealousideal_Rub5826  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15mffz9/p_using_lidar_and_photography_to_locate_fire/",
          "publishedOn": "2023-08-09T13:31:54.000Z",
          "wordCount": 2591,
          "title": "[P] using lidar and photography to locate fire hydrants",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15mdb96/d_which_cornerstone_papers_should_be_read_before/",
          "author": null,
          "description": "Hi everyone, I have an interesting task in hand, and wanted some advice over here before getting my hands dirty.\n I have to compile a list of 15-20 papers, to systematically go from \"what's a transformer\" to bleeding edge research of multimodal and LLMs applications to robotics, dynamical systems, and RL (e.g. RT-2). The base assumption is that the reader will be a master student, who already has the basics of what deep learning and control theory are.\n Could you suggest possible cornerstone papers that could go in this list? If you could, this would guide my search a lot, and I would appreciate it.\n ​\n ​\n    submitted by    /u/Snekgineer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15mdb96/d_which_cornerstone_papers_should_be_read_before/",
          "publishedOn": "2023-08-09T12:01:36.000Z",
          "wordCount": 2611,
          "title": "[D] Which cornerstone papers should be read before RT-2?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15matan/r_automl_tool_h2o_exposes_all_files_on_your/",
          "author": null,
          "description": "https://mlsecops.com/resources/hacking-ai-h2o-exposes-entire-filesystem\n    submitted by    /u/FlyingTriangle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15matan/r_automl_tool_h2o_exposes_all_files_on_your/",
          "publishedOn": "2023-08-09T09:57:07.000Z",
          "wordCount": 2512,
          "title": "[R] AutoML tool H2O exposes ALL files on your server by default, multiple CVEs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15man7r/r_what_are_your_favorite_ai_tools/",
          "author": null,
          "description": "What are some AI tools that you use often, that help you with your work/school or that you simply use for fun? \n    submitted by    /u/SadBlackTea  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15man7r/r_what_are_your_favorite_ai_tools/",
          "publishedOn": "2023-08-09T09:48:05.000Z",
          "wordCount": 2526,
          "title": "[R] What are your favorite AI tools?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15m9s45/d_best_ml_opensource_projects_to_contribute_to/",
          "author": null,
          "description": "Any recommendations for cool open-source ML projects that an intermediate Machine Learning engineer/researcher can contribute to?\n    submitted by    /u/Ahmed-Allam-220  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15m9s45/d_best_ml_opensource_projects_to_contribute_to/",
          "publishedOn": "2023-08-09T09:00:48.000Z",
          "wordCount": 2521,
          "title": "[D] Best ML open-source projects to contribute to",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15m55ng/d_where_to_begin_studying_aiml_from_a_cognitive/",
          "author": null,
          "description": "I am currently an AI/ML student but I have recently been thinking more and more about cognitive science. I was wondering if you know of any good resources that approach AI from the perspective of cognitive science\n    submitted by    /u/BornAgain20Fifteen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15m55ng/d_where_to_begin_studying_aiml_from_a_cognitive/",
          "publishedOn": "2023-08-09T04:47:10.000Z",
          "wordCount": 2545,
          "title": "[D] Where to begin studying AI/ML from a COGNITIVE SCIENCE PERSPECTIVE?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lyv0k/r_cloud_computing_and_other_gpu_alternatives/",
          "author": null,
          "description": "I’m kind of new to the world of machine/deep learning so cut me some slack here, but I was wondering the best ways to train models (in my case a transformer) without a GPU. I personally don’t even have a PC, I’ve been using a 2017 MacBook Air. I know deep learning models are quite computationally expensive and since I don’t have access to a GPU, how do I train models? I’ve read about cloud computing services like AWS, Google Colab, etc. but I was wondering what the best method was. Ideally free or as cheap as possible.\n    submitted by    /u/Present_Network1959  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lyv0k/r_cloud_computing_and_other_gpu_alternatives/",
          "publishedOn": "2023-08-08T23:59:25.000Z",
          "wordCount": 2602,
          "title": "[R] Cloud computing and other GPU alternatives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lxru4/d_beta_test_invitation_free_ai_email_chrome/",
          "author": null,
          "description": "We are currently conducting a beta test for our Chrome Extension and we value external input.\n Our platform allows you to write and receive your gmail emails within the browser. You can also use AI to generate emails, without ever touching gmail or chatgpt.\n If you're interested in participating, please feel free to message or comment!\n    submitted by    /u/Live-Orange-8414  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lxru4/d_beta_test_invitation_free_ai_email_chrome/",
          "publishedOn": "2023-08-08T23:14:39.000Z",
          "wordCount": 2562,
          "title": "[D] Beta Test Invitation: Free AI Email Chrome Extension",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lxbtz/do_visual_transformers_have_anything_equivalent/",
          "author": null,
          "description": "I have a regression model based on CNN, works reasonably well with less than 1M parameters. I am trying to check how Visual Transformer (ViT) will perform on this task, but due to lack of pooling in ViT, model size is considerably large (~10M parameters). Do ViT have anything equivalent to pooling to reduce number of parameters?\n If not then that reduces applicability of ViT to large models on large dataset dataset only. For smaller tasks with small dataset, CNN or Resnet are way more computation efficient.\n Or am I missing something?\n    submitted by    /u/Apprehensive-War8915  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lxbtz/do_visual_transformers_have_anything_equivalent/",
          "publishedOn": "2023-08-08T22:57:07.000Z",
          "wordCount": 2600,
          "title": "Do Visual Transformers have anything equivalent to Pooling in CNN? [Discussion]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lx0dr/d_how_long_does_it_take_to_setup_an_mlops_pipeline/",
          "author": null,
          "description": "For our R&D team, we spent over a month trying to setup our pipeline. After that, we spend at least 5 days after R&D for to put a model into production without the required data pipelines that communicate with our model and the service. For training a model, the infrastructure maintain and manage it also needs to be built for around 2 weeks. \n Currently, our best solution is to offload the training process by purchasing a GPU and keeping it in the office.\n    submitted by    /u/potanees  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lx0dr/d_how_long_does_it_take_to_setup_an_mlops_pipeline/",
          "publishedOn": "2023-08-08T22:44:31.000Z",
          "wordCount": 2591,
          "title": "[D] How long does it take to setup an MLOps pipeline?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lwrcf/r_weights_reset_implicit_regularization/",
          "author": null,
          "description": "​\n https://preview.redd.it/4t4jbi15rygb1.png?width=2291&format=png&auto=webp&s=f4eedf0d24dee2cbd040b3a19ab9610119b4001e\n Hi everyone!\n I want to share some interesting observations that indicate a very simple periodical weights resetting procedure could serve as an implicit regularization strategy for training DL models. This technique also shows potential connection with the Double Descent phenomenon. Here's the link to github etc: https://github.com/amcircle/weights-reset.\n As a co-author of this study, I must apologize in advance for its brevity. However, I sincerely hope it may prove useful to some. I would gladly respond to your queries and receive your criticism. Your personal experiences related to something similar would also be highly appreciated.\n    submitted by    /u/gregorivy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lwrcf/r_weights_reset_implicit_regularization/",
          "publishedOn": "2023-08-08T22:34:16.000Z",
          "wordCount": 2596,
          "title": "[R] Weights Reset implicit regularization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15luwq4/d_training_process_are_text_encodings_used_along/",
          "author": null,
          "description": "Hi,\n I am going through research papers and noticed that most of the papers talk about the text conditioned image generation process (reverse diffusion process). The text and time encodings are added as additional channels to the UNet block.\n However, I am curious to know if any text encodings are used during the training process as well. Is there any preview of the training datasets that is available which is used in the training process ? or a code snippet that points out to the forward part of the training loop\n Thanks\n    submitted by    /u/kaskoraja  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15luwq4/d_training_process_are_text_encodings_used_along/",
          "publishedOn": "2023-08-08T21:24:29.000Z",
          "wordCount": 2601,
          "title": "[D] Training process - Are text encodings used along with image encodings",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lu61r/d_benchmark_for_autoregressive_llm_embedding/",
          "author": null,
          "description": "Hi everyone,\n There has been a lot of work on benchmarking autoregressive LLMs, such as HF LLM Leaderboard, but I have not seen much work specifically on the relevancy of such LLMs for retrieval. \n There is a lot of talk about chat based on knowledge with solutions like llama_index, where LLMs both provide embeddings and answer based on most similar content, but embedding and answer generation need not be the same LLM.\n I saw the Massive Text Embedding Benchmark (MTEB) but it does not seem to contain a lot of information about the recent autoregressive LLMs. \n Are the recent autoregressive LLMs, e.g. Llama 2, actually performing better than Bidirectional LLMs such as BERT? \n Because if so, all the recent fancy chat with your documents projects could use much smaller models to do embedding extraction for retrieval and just call a fancy autoregressive LLM such as GPT4 for answer synthesis.\n    submitted by    /u/Separate-Still3770  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lu61r/d_benchmark_for_autoregressive_llm_embedding/",
          "publishedOn": "2023-08-08T20:56:43.000Z",
          "wordCount": 2655,
          "title": "[D] Benchmark for autoregressive LLM embedding quality for retrieval?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ltqrs/d_r_opensource_model_that_can_caption_an_image_of/",
          "author": null,
          "description": "Hi I'm looking for an open source model that can take an image of an info graphic such as a pie chart, graph, etc, and provide a description of the information in that chart. For example the values of the x,y axis and their labels, weather the chart is increasing or decreasing. \n I've worked with image captioning models such as BLIP before as I have used them in projects involving stable diffusion, but this model doesn't give specifics about the information in the graph, just a brief overview. \n I know researches have worked on this problem in the past using the vistext dataset: \n https://news.mit.edu/2023/researchers-chart-captions-ai-vistext-0630\n So far I'm thinking that it may come to me finetuning BLIP or equivalent to specialize on infographics instead. \n Thoughts? \n    submitted by    /u/UncleSammmm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ltqrs/d_r_opensource_model_that_can_caption_an_image_of/",
          "publishedOn": "2023-08-08T20:41:35.000Z",
          "wordCount": 2633,
          "title": "[D] [R] Opensource model that can caption an image of a chart?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ltjak/p_any_existing_photovideo_classifier_uis_with/",
          "author": null,
          "description": "I have a significant amount of files that I would like to label for future reference. I've looked at software such as Photoprism or Librephoto which have object classification but they are based on a static model. I'd like something where I could label a few photos then generate similar matches where I can approve the good matches for reinforcement learning. I'm pretty sure I saw a demo like this at a code conference using Azure but I'm hoping for something self-hosted to avoid API fees. I was exploring coding something to do this for me but I don't want to put in the work if something with a UI exists already. This seemed like the best place to ask.\n    submitted by    /u/MZZXX  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ltjak/p_any_existing_photovideo_classifier_uis_with/",
          "publishedOn": "2023-08-08T20:33:56.000Z",
          "wordCount": 2626,
          "title": "[P] Any existing photo/video classifier UIs with custom labels?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lsyjz/d_best_way_to_run_a_pytorch_model_on_a_cropped/",
          "author": null,
          "description": "Hi - I have trained a pytorch model that does some fairly simple object classification - The goal is distribute it as part of an app, that will pull information from a user's video.\n The videos are typically ~25-30 minutes and about 1GB in size, only a 600x600px square on the bottom right of the video is needed for the classification (it's a minimap in a video game)\n The app is electron based\n Ideally I want to input a video, and extract the labels from the cropped section once per second.\n ​\n My current attempt involves converting the model to a tensorflowjs model, and rendering the video on a <canvas> element, stretching it so only the minimap is visible on the canvas, running the model, saving the labels, and increasing the current time of the video by 1 second, and repeating until the video is done.\n ​\n This seems like a terrible plan, but it's much better than the couple of other ideas I've tried (using ffmpeg to extract a frame every second for example)\n ​\n Any advice appreciated!\n ​\n Edit: just to clarify this will only ever be ran on Windows\n    submitted by    /u/FreddoRS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lsyjz/d_best_way_to_run_a_pytorch_model_on_a_cropped/",
          "publishedOn": "2023-08-08T20:12:29.000Z",
          "wordCount": 2704,
          "title": "[D] Best way to run a pytorch model on a cropped version of a video on someone else's PC?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lp6yl/rp_review_to_twothree_words_summarization_text/",
          "author": null,
          "description": "Hello, I'm looking for a model (probably two models) that would:\n  \nSummarize reviews (e.g. website review) to two/three words.\n \nReuse these words or \"review tokens\" to tag reviews with similar content. Then if a review's content differs (e.g. cosine sim. of 0.2), another tag will be generated from the review that diverges.\n \n Is there anything like this on the \"market\"? \n    submitted by    /u/BartPetersyn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lp6yl/rp_review_to_twothree_words_summarization_text/",
          "publishedOn": "2023-08-08T17:52:03.000Z",
          "wordCount": 2566,
          "title": "[R][P] Review to two/three words summarization | Text tagging",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lnyh6/d_spectrum_of_specialization_in_ml/",
          "author": null,
          "description": "Hello to everyone reading this. \n I am just about to finish Andrew NG's course 3 courses on ML specialization and I have had 2 courses on ML as well in my Business Intelligence Analytics studies at uni. \n Now I am extremely interested in ML but I see there are wide diaspora of different subfields you can focus on. I need to get into the job market as fast as possible. So can anyone guide me which aspect of ML should I give most of my time to practice and build portfolio that would translate well to interviews and hiring?\n Thank you\n    submitted by    /u/JaguarMoosa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lnyh6/d_spectrum_of_specialization_in_ml/",
          "publishedOn": "2023-08-08T17:05:18.000Z",
          "wordCount": 2604,
          "title": "[D] Spectrum of Specialization in ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lnw0z/d_question_difficulty_predictor/",
          "author": null,
          "description": "How would you proceed on a project in assessing the difficulty level of a question? I tried using lexicographic metrics like flesh-kincaid score, etc., but those did not yield proper results. Is there a good method I could use? Also, how could I assess the \"readability\" of a question, or in other words, how easy it is to understand what the question is asking.\n    submitted by    /u/uglyboi34  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lnw0z/d_question_difficulty_predictor/",
          "publishedOn": "2023-08-08T17:02:41.000Z",
          "wordCount": 2565,
          "title": "[D] Question Difficulty Predictor",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lntx9/releasing_a_new_model_for_conditional_music/",
          "author": null,
          "description": "Hey y'all, this is a model I have been independently building for some time. It uses parts of OpenAI's Jukebox and HarmonAI's Dance Diffusion model.\n Overall it is a hierarchical latent diffusion modeland generates complete linked musical phrases at good quality.\n More information as well as examples can be found here: https://medium.com/@jeffsontagmusic/jukebox-diffusion-cbe22ff3cd47\n Thanks!\n    submitted by    /u/jmoso13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lntx9/releasing_a_new_model_for_conditional_music/",
          "publishedOn": "2023-08-08T17:00:43.000Z",
          "wordCount": 2558,
          "title": "[R]eleasing a new model for conditional music generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lnt4g/d_how_to_stay_on_the_cutting_edge_of_applied_mlai/",
          "author": null,
          "description": "A lot of my PhD work will be in using different types of ML/NN approaches to characterizing problems in my field. It's kind of weird, since for my undergrad I came from a more traditional science background where we research off papers that were written like 2-20 years ago. Since a lot of these architectures and whatever are updating so fast, I wanted to see if there's a good way to keep up with the latest information so my work wouldn't be outdated by the time I publish. Is there a general workflow that those of you in the field follow in regards to this?\n    submitted by    /u/This-Is-My-20th-Acc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lnt4g/d_how_to_stay_on_the_cutting_edge_of_applied_mlai/",
          "publishedOn": "2023-08-08T16:59:58.000Z",
          "wordCount": 2617,
          "title": "[D] How to stay on the cutting edge of applied ML/AI while doing my PhD?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lnfbh/a_blog_on_lora_and_qlora_finetuning_techniques_p/",
          "author": null,
          "description": "Hey everyone,\n I wrote a blog on LoRA and QLoRA. Hope it helps you in understanding the theory behind them 🤗\n https://medium.com/@gitlostmurali/understanding-lora-and-qlora-the-powerhouses-of-efficient-finetuning-in-large-language-models-7ac1adf6c0cf\n If the above one is behind paywall, you can visit the blog here (https://gitlostmurali.com/machine-learning/data-science/lora-qlora)\n    submitted by    /u/Outlandish_MurMan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lnfbh/a_blog_on_lora_and_qlora_finetuning_techniques_p/",
          "publishedOn": "2023-08-08T16:44:59.000Z",
          "wordCount": 2542,
          "title": "A blog on LoRA and QLoRA finetuning techniques [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lmvmc/d_im_losing_my_voice_due_to_illness_and_im/",
          "author": null,
          "description": "Hey all, like the title says, I’m losing my voice due to an illness (Parkinson’s disease), and I would like to create an AI voice using recordings from 10 years ago. I used to be a prolific podcaster, and I have about 50 episodes of podcasts that I can use as input. Is this possible? What service or software can I use? My voice is beyond repair since Parkinson’s is a progressive disease. An AI voice would allow me to work and would open up new doors for me. Thank you!\n    submitted by    /u/NWMoney101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lmvmc/d_im_losing_my_voice_due_to_illness_and_im/",
          "publishedOn": "2023-08-08T16:23:46.000Z",
          "wordCount": 2602,
          "title": "[D] I’m losing my voice due to illness, and I’m looking for ML/AI solution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lm6tk/p_candle_torch_replacement_in_rust/",
          "author": null,
          "description": "Candle is a minimalist ML framework for Rust\n Some of its features\n  \nExamples of popular models: Whisper, Llama 2, Falcon, Bert, Starcoder\n WASM support, so you can run the models directly in the browser\n User-defined kernels, so you can use Flash Attention\n Similar syntax to PyTorch\n Data loaders\n Transformer utilities\n  \n   submitted by    /u/hackerllama  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lm6tk/p_candle_torch_replacement_in_rust/",
          "publishedOn": "2023-08-08T15:58:25.000Z",
          "wordCount": 2553,
          "title": "[P] Candle: Torch Replacement in Rust",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lkqtq/d_how_to_keep_my_ml_skills_whilst_on_another_job/",
          "author": null,
          "description": "Hey all, I have a technical background, having studied engineering and ML at one of the world's leading universities. I really enjoyed it and did well, but long story short, since graduating (coming to 2 years) I have been working in a Family Office, doing things I don't feel are very related.\n I wanted to know what kind of things I can do to keep myself in the loop and continue developing my ML/DS skills in my spare time. Alternatively, ideas of projects I could have just to make sure I have a portfolio?\n    submitted by    /u/thegreatudini  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lkqtq/d_how_to_keep_my_ml_skills_whilst_on_another_job/",
          "publishedOn": "2023-08-08T15:04:44.000Z",
          "wordCount": 2602,
          "title": "[D] How to keep my ML skills whilst on another job?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15li768/pmmlubytask_evaluation_results_for_500_open/",
          "author": null,
          "description": "Typically, research papers and leaderboards only report the overall score on Measuring Massive Multitask Language Understanding (MMLU) and not per task performance. Hugging Face recently released detailed evaluation data that includes per task performance. I made a sortable leaderboard here https://huggingface.co/spaces/CoreyMorris/MMLU-by-task-Leaderboard . You can also make custom scatter plots on the site so you can explore the relationship between parameter count and performance.\n    submitted by    /u/corey1505  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15li768/pmmlubytask_evaluation_results_for_500_open/",
          "publishedOn": "2023-08-08T13:26:12.000Z",
          "wordCount": 2568,
          "title": "[P]MMLU-by-Task Evaluation Results for 500+ Open Source Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15lgjw7/d_current_trends_in_explainability/",
          "author": null,
          "description": "I've realized my technical understanding of explainability is a few years behind, having last focused on it with LIME and Shap. Does anyone have a survey reference they like for recent trends and updates in ML explainability?\n    submitted by    /u/balcell  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15lgjw7/d_current_trends_in_explainability/",
          "publishedOn": "2023-08-08T12:16:30.000Z",
          "wordCount": 2539,
          "title": "[D] Current trends in explainability?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ldjdz/r_whats_the_current_research_status_of_sft_with/",
          "author": null,
          "description": "At first, with InstructGPT and ChatGPT, it looked like RLHF was the holy grail to successfully finetune LLMs on human preferences. Then, from May 2023 onwards, a trend of doing just SFT with high-quality data showed up (e.g. \"LIMA: Less Is More for Alignment\" https://arxiv.org/abs/2305.11206) as an alternative to doing RLHF.\n What's your opinion on these two narratives? Is RLHF likely to still be relevant even in the presence of SFT with high-quality data?\n    submitted by    /u/bornot2b  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ldjdz/r_whats_the_current_research_status_of_sft_with/",
          "publishedOn": "2023-08-08T09:51:59.000Z",
          "wordCount": 2584,
          "title": "[R] What's the current research status of \"SFT with high-quality data\" vs RLHF?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15la8cy/discussion_what_has_your_experience_been_as/",
          "author": null,
          "description": "Hi all, \n I am currently already working in the field of ML research at a big name medical research center. Our main focus is in application of ML methods with the focus on stroke diagnostics and treatment.\n Now, I am quite happy working here but my background is somewhat interdisciplinary. I have a bachelor's in Life science and a Master in bioinformatics. Because of this I always feel like I have to catch up to my colleagues when it comes to ML and in parts also computer science knowledge. It feels like there are a million things to learn and many small details to know that I am not even sure how to look up.\n I am curious what your experience has been if you were/are in a similar situation? How did you manage to catch up?\n    submitted by    /u/JuicyLambda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15la8cy/discussion_what_has_your_experience_been_as/",
          "publishedOn": "2023-08-08T06:53:13.000Z",
          "wordCount": 2648,
          "title": "[Discussion] What has your experience been as someone joining ML from a lateral field?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15l87gd/d_does_sota_performance_on_object_detection_seem/",
          "author": null,
          "description": "Either I'm too new to the space, or I'm stating the obvious, but it seems that object detection performance is really low. The SOTA currently is 66% on COCO test-dev, which doesn't match how well it seems like AI is currently performing with self-driving cars, surveillance tech, and others. Am I missing something?\n    submitted by    /u/philipkd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15l87gd/d_does_sota_performance_on_object_detection_seem/",
          "publishedOn": "2023-08-08T05:05:32.000Z",
          "wordCount": 2562,
          "title": "[D] Does SOTA performance on object detection seem low to anybody else?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15l7236/r_hierarchical_representation_and_propagation_of/",
          "author": null,
          "description": "I. Introduction\n This paper aims to provide an in-depth explanation of representing and propagating wavefunctions in a hierarchical manner using Gaussian basis functions. Wavefunctions are mathematical descriptions of the quantum states of physical systems and are fundamental to quantum mechanics. However, representing complex wavefunctions for real-world quantum systems remains a key challenge. This paper proposes using multiple layers of Gaussian basis functions, with trainable amplitudes, to represent wavefunctions in a hierarchical fashion and enable wavefunction propagation between layers.\n Understanding wavefunction representation and propagation has significant implications in diverse fields like quantum computing, quantum chemistry, and materials science. Efficient wavefunction man…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15l7236/r_hierarchical_representation_and_propagation_of/",
          "publishedOn": "2023-08-08T04:07:41.000Z",
          "wordCount": 3549,
          "title": "[R] Hierarchical Representation and Propagation of Wavefunctions within Gaussian Basis Functions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15l2jr8/evolinstruct_dataset_creation_r_d/",
          "author": null,
          "description": "I’ve been researching the Evol-Instruct datasets now for a few days and have decided I want to build my own out for a specific use case.\n I’ve read literally everything possible, admittedly not much outside of WizardLM and GeorgiaTech, but I’ve read it.\n I was hoping to discuss it here with smarter people. \n I’m seeing this as a way to use LLMs to generate great datasets. However, my use case doesn’t really exist in any models yet. Not thoroughly enough to produce a good Evol-Instruct set. So, I’m going to do that tomorrow.\n I’m going to use The Blokes WizardCoder-Guanaco 15b GPTQ version to train on my specific dataset - about 10GB of clean, really strong data I’ve spent 3-4 weeks putting together.\n In theory, I’ll use the Evol-Instruct script from WizardLM to generate the new dataset, and then I’ll apply that to whatever model I decide to use. There is a good chance I train my own on general Evol-Instruct datasets available now, and likely quite a large one.\n I’m looking for any tips, discussion, ideas, thoughts from the community. \n Cheers!\n    submitted by    /u/LoadingALIAS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15l2jr8/evolinstruct_dataset_creation_r_d/",
          "publishedOn": "2023-08-08T00:42:04.000Z",
          "wordCount": 2674,
          "title": "Evol-Instruct Dataset Creation [R] [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15l18cc/please_criticize_our_llm_writing_integration_app_p/",
          "author": null,
          "description": "Here's the pitch:\n We made an editor called Gamut that lets you enter your ideas in any form you want. Bullets, carefully constructed paragraphs, it doesn’t matter. Then, our patent-pending technology lets you convert to prose and adjust, shaping the text like a graphic designer shapes an image.\n We want r/MachineLearning's advice and field experience, because tbh we're just a bunch of teenagers who haven't even gone to college yet.\n Check it out: gamut.ink\n    submitted by    /u/gamut_ink  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15l18cc/please_criticize_our_llm_writing_integration_app_p/",
          "publishedOn": "2023-08-07T23:46:10.000Z",
          "wordCount": 2569,
          "title": "Please criticize our llm writing integration app [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15l11ci/dcould_current_ai_tech_make_a_movie_of_alejandro/",
          "author": null,
          "description": "I was just watching the documentary about the 'greatest movie never made', director Alejandro Jodorowsky's vision of Frank Herbert's Dune.\n There is a huge book that contains a storyboard version of the movie with lots of production art by artists Moebius, Chris Foss and HR Giger.\n The movie was to star Jodorowsky's son as Paul Atriedes, Salvadore Dali as the Emperor, Orson Wells as Baron Harkonnen and Mick Jagger as Feyd.\n Could one of today's AIs be 'fed' Jodorowsky's book and create a movie of his vision?\n Curious to know what your opinions are on this.\n Thanks.\n    submitted by    /u/shopdog  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15l11ci/dcould_current_ai_tech_make_a_movie_of_alejandro/",
          "publishedOn": "2023-08-07T23:38:17.000Z",
          "wordCount": 2597,
          "title": "[D]Could current AI tech make a movie of Alejandro Jodorowsky's vision of 'Dune'?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15l0wm0/p_regression_using_batch_trend_data/",
          "author": null,
          "description": "Hi, all,\n I would like to use batch reaction trend data to build a regression model. I'm wondering what is the best way to approach this.\n Here's some background:\n Reaction Data: \n  \n Time (min) Pressure (bar) Temperature (°C) Flow (kg/h) Gas Total (kg) \n  \n 1 10 70 502 8 \n  2 10.1 71 498 16 \n  ... ... ... ... ... \n  102 10.3 76 475 850 \n \n Output: Polymer property X\n The reaction continues until a gas total is met and the time this takes depends on the other variables.\n I have ~700 batches of data in a format similar to the above and would like to predict polymer property X. As the variables can change minute to minute I was thinking of binning the variables into 5 minute bins using the mean and using these as variables for linear regression or similar.\n Is this a valid approach or is there another way I can approach the problem?\n Thanks!\n    submitted by    /u/Nefarious_P_I_G  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15l0wm0/p_regression_using_batch_trend_data/",
          "publishedOn": "2023-08-07T23:32:54.000Z",
          "wordCount": 2647,
          "title": "[P] Regression using batch trend data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15l0w7i/r_awesome_ood_detection_robustness_and/",
          "author": null,
          "description": "Hi everyone,\n I have put together a repo that provides comprehensive resources for Out-of-distribution Detection, Robustness, and Generalization. The repo contains articles, talks, libraries, papers, etc. Check it out.\n https://github.com/continuousml/Awesome-Out-Of-Distribution-Detection\n    submitted by    /u/Ok-Kaleidoscope-505  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15l0w7i/r_awesome_ood_detection_robustness_and/",
          "publishedOn": "2023-08-07T23:32:26.000Z",
          "wordCount": 2524,
          "title": "[R] Awesome OOD Detection, Robustness, and Generalization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15kyphq/d_uncertainty_prediction_in_deep_learning_capsa/",
          "author": null,
          "description": "Alexander Amini, a Postdoctoral Associate at MIT, well known for the MIT's Introduction to Deep Learning Course, published a git repo called CAPSA for uncertainty prediction. This was introduced during the online course. The code was released under Thermis AI, Inc, a private company. He is the co-founder and CSO of the company. You can check how well the code was documented in the wayback machine. Recently, they removed the code base from the github and launched a pro version with selected companies as beta. The original repo (now called capsa-lite) was a great learning tool that I wanted to use. This was a quick way to try out different methods of uncertainty prediction using minimal code. Unfortunately, they have pulled all previous version of the code from the github repo. I was wondering if anyone knows a similar python package or has the old repo - would be really helpful!\n    submitted by    /u/shikamaru_77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15kyphq/d_uncertainty_prediction_in_deep_learning_capsa/",
          "publishedOn": "2023-08-07T22:06:16.000Z",
          "wordCount": 2652,
          "title": "[D] Uncertainty Prediction in Deep Learning - CAPSA github project alternative or old code?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15kyjtm/d_ml_workstation_for_cnn_and_transformers/",
          "author": null,
          "description": "I'm putting together an ML workstation primarily focused at handling CNN and Transformer workloads. Component selection so far: https://de.pcpartpicker.com/list/zVPtt7\n I've got a couple of questions specifically regarding the motherboard. One concern I have is whether the space between the two GPUs is sufficient, as I'm planning to set them up using NVLink. Additionally, I'm curious about the compatibility of the case and motherboard for effective air cooling ( not considering water cooling at the moment). Anyone else with dual 3090s who can give some insights on how they've managed temperatures and potential overheating issues?\n Lastly, would upgrading to a Ryzen 9 5900X prevent me from bottlenecking the GPU's? \n Would love to hear your feedback and suggestions! \n    submitted by    /u/Hugejiji  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15kyjtm/d_ml_workstation_for_cnn_and_transformers/",
          "publishedOn": "2023-08-07T22:00:37.000Z",
          "wordCount": 2615,
          "title": "[D] ML Workstation for CNN and Transformers - Feedback on Component Selection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15kugwx/finetuning_for_code_generation_d/",
          "author": null,
          "description": "i want to fine tune any open source llm for code generation purpose with some of my code. any idea what model would be suitable? and any example of implementation?\n    submitted by    /u/learner_beginner  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15kugwx/finetuning_for_code_generation_d/",
          "publishedOn": "2023-08-07T19:29:36.000Z",
          "wordCount": 2522,
          "title": "Finetuning for code generation [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ku1ao/d_how_difficult_is_it_to_find_a_job_in_mlai/",
          "author": null,
          "description": "Anyone here know what the trends are towards hiring for an AI/ML position without a PhD? Is it advisable to get a PhD if you want to be in the field and keep rising within it?\n    submitted by    /u/CleanGarden7051  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ku1ao/d_how_difficult_is_it_to_find_a_job_in_mlai/",
          "publishedOn": "2023-08-07T19:13:12.000Z",
          "wordCount": 2543,
          "title": "[D] How difficult is it to find a job in ML/AI without a PhD, in the current bad job market?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15kt2vw/d_machine_learning_or_quantum_computing/",
          "author": null,
          "description": "Hi,\n I'm about to graduate in Physics (PhD). I am an experimentalist with a background in electromagnetic. I am trying to apply for jobs, but there are some few options for physicists (based on my geography). So, I am trying to learn some new skill for my future job. One option would be Machine Learning, which is on-demand and the field is growing. The other option is Quantum Computing. I can start a postdoc in quantum information theory as well.\n Each path, has its pros and cons, and the final decision is based on many factors. I just don't have enough data and information to say which one is more secure in the future? Which one has less compete? And also, is it possible to get hired without any serious project in ML, and just self-taught?\n If you were me, which one would you pick?\n Thanks\n    submitted by    /u/Jaded-Membership-602  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15kt2vw/d_machine_learning_or_quantum_computing/",
          "publishedOn": "2023-08-07T18:38:50.000Z",
          "wordCount": 2639,
          "title": "[D] Machine learning or quantum computing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ksdz2/d_what_is_a_typical_nonacademic_ml_salary_with_a/",
          "author": null,
          "description": "What is a typical non-academic ML salary with a PhD...\n  \n... immediately after completing the PhD? (Assuming no academic positions ever post PhD.)\n ... after 10 years of experience?\n ... in biotech specifically? (More, less, or the same as average?)\n  \n   submitted by    /u/Practical_Tea_3779  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ksdz2/d_what_is_a_typical_nonacademic_ml_salary_with_a/",
          "publishedOn": "2023-08-07T18:13:37.000Z",
          "wordCount": 2538,
          "title": "[D] What is a typical non-academic ML salary with a PhD?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ks6js/p_mathematics_ml_for_masters_application_advice/",
          "author": null,
          "description": "Hi all, \n I'm looking apply to some top masters for machine learning in the UK, so I'm guessing you know which one I'm referring to. \n I got some guidance from the application advisor, which state they like to look at the transcript the most to have an idea of my linear algebra, calculus and statistics ability. I got 70% in \"Maths for Computer Science\" and some other modules I strong first and 2:1 in some others, but in general my course wasn't too mathematically intensive. I did BSc Computer Science. I have been working as SWE the past 3 years. \n I have completed the following specialisation \"Mathematics for Machine Learning and Data Science Specialization\" and read \"Mathematics for Machine Learning\", as learning about mathematics actually got me into ML. I have also covered the videos on 3Blue1Brown etc. The application advisor said that certs don't really mean too much which is understandable. I can't change the past in terms of BSc transcript, therefore I was thinking a project may be a good way to showcase this.\n Any tips on how to best showcase this or get across my ability would be extremely helpful?\n    submitted by    /u/DNOFHF  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ks6js/p_mathematics_ml_for_masters_application_advice/",
          "publishedOn": "2023-08-07T18:05:50.000Z",
          "wordCount": 2687,
          "title": "[P] Mathematics ML for Masters Application Advice?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15krt3a/d_how_can_i_configure_two_gpus_to_share_their/",
          "author": null,
          "description": "Hey, \n I've been trying to build an ML workstation and was considering the idea of using two RTX 3090's to get the extra VRAM instead of a single 4090. However, I've come across some confusion regarding whether they can share their VRAM or not. Do I need to run them via NVLink to achieve this? I believe PyTorch's data parallelism splits the batches across both GPUs, but that wouldn't effectively combine their VRAM right?\n Any advice or insights you can share on the topic would be highly appreciated!\n    submitted by    /u/Hugejiji  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15krt3a/d_how_can_i_configure_two_gpus_to_share_their/",
          "publishedOn": "2023-08-07T17:52:29.000Z",
          "wordCount": 2586,
          "title": "[D] How can I configure two GPUs to share their memory?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15knz1x/d_are_there_any_graduate_programs_which_focus_on/",
          "author": null,
          "description": "I'm considering getting a graduate degree in ML. However, I am not very interested in NLP or academic research. I would like to learn things that are relevant to the intersection of ML and genomics or medicine. Are there any graduate programs/degrees to this effect? If so, which ones?\n    submitted by    /u/Practical_Tea_3779  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15knz1x/d_are_there_any_graduate_programs_which_focus_on/",
          "publishedOn": "2023-08-07T15:30:24.000Z",
          "wordCount": 2548,
          "title": "[D] Are there any graduate programs which focus on ML + biomedicine?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15klgt9/p_looking_for_perspectives_pdf_parsing_meets/",
          "author": null,
          "description": "Hi folks.\n I am sure you know the running gags around “thin OpenAI wrapper” products. Instead of more toy products, I am doing an experiment with some “AI engineering” to come up with a solution that’s closer to being usable in actual production cases.\n My background is in project management and data engineering, and I’ve built large systems for big companies and worked as a consultant in the space.\n I’ve seen enough crappy data pipelines for a lifetime.\n Hence.\n I want to do something different: A thin AI wrapper is not sufficient for having reliable data pipelines that use OpenAI for schema management and inference\n So this leaves me with the following doubts:\n ​\n  \nHow to scale code horizontally and vertically? Using third-party solutions? SNS/SQS/Kafka?\n How to log and trace? Langsmith? Custom solutions?\n How to extend reliably with my own data, and make it stateful?\n  \nLooking for your perspective\n ​\n  \nWhat do you think about the state of data engineering, MLOps, and infrastructure in AI companies?\n What do you think about how to scale properly the systems and prepare them for the future?\n In this code here, I do process some PDFs as a simple pipeline, what approaches do you think could be better?\n  \nMy current thinking and the state of the project\n ​\n  \nI should create a formal scale of usability. I am looking for your input here.\n I should improve model consistency, extends the model with custom domain knowledge, and make an early attempt to build simple user agents in the domain\n What I have is a schema inference, contracting basics, and a way to structure unstructured data\n I’m about to create a memory component that manages the data stored in vector dbs, as a DWH for AI\n If I bring this use case that was not something available easily to the public before, how best do it?\n  \nLinks:\n If you like my project, please give it a star :)\n my git repo \n    submitted by    /u/Snoo-bedooo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15klgt9/p_looking_for_perspectives_pdf_parsing_meets/",
          "publishedOn": "2023-08-07T13:56:31.000Z",
          "wordCount": 2817,
          "title": "[P] Looking for perspectives: Pdf parsing meets PRODUCTION",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15kl4m6/d_use_multiple_gpus_to_load_model/",
          "author": null,
          "description": "Hey there,\n I got 2x 4090 RTX with 24GB GDDR each.I often ran into the problem of\n CUDA out of memory. Tried to allocate X MiB (GPU 0; 23.65 GiB total capacity; 22.75 GiB already allocated; 96.81 MiB free; 22.76 GiB reserved in total by PyTorch) \n I wonder if there is a way to take usage of both GPUs so the model is split onto both GPUs.\n When training models I use torch.nn.DataParallel to use both GPUs, but it seems like I am not doing it right for load the model.\n Can anyone help me? Both GPUs are available in the system - this has already been checked.\n    submitted by    /u/Sensitive_Limit1620  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15kl4m6/d_use_multiple_gpus_to_load_model/",
          "publishedOn": "2023-08-07T13:43:07.000Z",
          "wordCount": 2602,
          "title": "[D] Use multiple GPUs to load model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15kkxsz/p_llm_finetuning_studyresearch_group/",
          "author": null,
          "description": "Hey folks, \n We're looking for people to join our research group.\n We are passionate about fine-tuning LLMs for downstream tasks, specifically LLAMA for imitating chat behaviour (being constraint aware).\n ​\n The end goal is to build an open source app where you can clone and upload your chat history (say from Whatsapp) and it starts to answer like you \n Do let me know if it sounds interesting and you'd like to join us...\n https://preview.redd.it/sdo42mx1yogb1.png?width=1280&format=png&auto=webp&s=9de5008ed8ed18cedb25034d68984cb11e2a6a12\n    submitted by    /u/im_datta0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15kkxsz/p_llm_finetuning_studyresearch_group/",
          "publishedOn": "2023-08-07T13:35:23.000Z",
          "wordCount": 2564,
          "title": "[P] LLM Finetuning Study/Research Group",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15kkocz/p_humanscript_an_llm_powered_plain_english/",
          "author": null,
          "description": "humanscript is an inferpreter. A script interpreter that infers commands from natural language using AI. There is no predefined syntax, humanscripts just say what they want to happen, and when you execute them, it happens.\n https://github.com/lukechilds/humanscript\n This is a humanscript called tidy-screenshots. It takes an unorganised directory of screenshots and organises them into directories based on the month the screenshot was taken.It can be executed like any other script.\n https://preview.redd.it/2b0oz2kgwogb1.png?width=1576&format=png&auto=webp&s=9285805a1d0668ae5fe300857f9b67161b8ecda4\n The LLM inferpreted the humanscript into the following bash script at runtime.\n ​\n https://preview.redd.it/x8hwdrzhwogb1.png?width=2188&format=png&auto=webp&s=5fcba87a9606a446d169e8ae37b5c8c251525e5e\n The code is streamed out of the LLM during inferpretation and executed line by line so execution is not blocked waiting for inference to finish. The generated code is cached on first run and will be executed instantly on subsequent runs, bypassing the need for reinferpretation.\n ​\n https://i.redd.it/t6b1stbkwogb1.gif\n The humanscript inferpreter supports a wide range of LLM backends. It can be used with cloud hosted LLMs like OpenAI's GTP-3.5 and GPT-4 or locally running open source LLMs like Llama 2.\n You can run humanscript in a sandboxed Docker environment with a single command if you want to have a play.\n https://github.com/lukechilds/humanscript#install-humanscript\n    submitted by    /u/dyslexiccoder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15kkocz/p_humanscript_an_llm_powered_plain_english/",
          "publishedOn": "2023-08-07T13:24:34.000Z",
          "wordCount": 2676,
          "title": "[P] humanscript: An LLM powered plain english programming language",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15khkvu/d_text_aware_image_generation/",
          "author": null,
          "description": "lets say i have a set of images which contains sentences of text on it. now i want to generative images using some generative model with valid (meaningful) text in them. what i assume is just using gan or more powerful diffusion to generate images but i don't think the generated images won't contains valid text in them. i want the model to implicitly learn the text in the images without feeding external text or ocr on them. does any one know any paper trying to tackle this problem. \n any comments on this by anyone.\n    submitted by    /u/specializedboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15khkvu/d_text_aware_image_generation/",
          "publishedOn": "2023-08-07T11:08:35.000Z",
          "wordCount": 2587,
          "title": "[D] Text aware image generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15kcae2/r_detecting_thousands_of_overlapping_organisms/",
          "author": null,
          "description": "submitted by    /u/Alonsospace  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15kcae2/r_detecting_thousands_of_overlapping_organisms/",
          "publishedOn": "2023-08-07T06:18:24.000Z",
          "wordCount": 2508,
          "title": "[R] Detecting thousands of overlapping organisms using latent space encoding",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15kbnsc/p_new_library_dlt_auto_structures_data_and_loads/",
          "author": null,
          "description": "Hey folks,\n For the past 2 years I've been working on a library to automate the most tedious part of my own work - data loading, normalisation, typing, schema creation, retries, schema inference, evolution & ddl generation, self deployment.. Basically, as you build better and better pipelines you will want more and more, and dlt supports those options.\n The value proposition of this library is to automate the tedious work you do, so you can focus on better things. \n What's special about dlt?\n In the easiest form, you shoot response.json() json at a function and it auto manages the typing normalisation and loading, kind of like a pandas df.to_sql() but with auto schema inference, versioning and evolution. It supports loading to files, databases, and soon table formats and vector dbs.\n In its most complex form, you can do almost anything you can want, from memory management, microbatching, multithreading, extraction DAGs, 1 line Airflow/git actions deployment, dbt runner, streamlit app for data discovery, sql client, atomic state dictionaries, etc.\n The library is in use with early adopters, and we are now working on expanding our feature set to accommodate the larger community. We are adding Athena + Iceberg and Weaviate vector dbs next.\n Free forever\n The library is open source and will forever be open source. We will not gate any features for the sake of monetisation - instead we will take a more kafka/confluent approach where the eventual paid offering would be supportive not competing.\n Call for Feedback!\n Feedback is very welcome and so are requests for features or destinations.\n I would particularly love to hear from you: What destinations are you looking for from such a tool? And what use cases do you usually have? I'm a data engineer so my knowledge is more around loading external sources to a common space.\n Links\n Colab demos: Load to duckdb with schema evolution\n Docs main page \n Thank you in advance for your feedback!\n    submitted by    /u/Thinker_Assignment  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15kbnsc/p_new_library_dlt_auto_structures_data_and_loads/",
          "publishedOn": "2023-08-07T05:43:29.000Z",
          "wordCount": 2825,
          "title": "[P] New library: dlt auto structures data and loads it with schema evolution in a declarative way.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15k7y18/p_ai_text_adventure_games_narrated_and/",
          "author": null,
          "description": "https://textadventure.v5games.com/\n Hi All, I created these Text Adventure Games with AI, some help from the community which designs prompts+some avatars.\n The AI Characters can be created with an AI Art Generator. Voices and Illustrations are done using AI https://textadventure.v5games.com/ \n Let me know what you think!\n    submitted by    /u/BoxOrigi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15k7y18/p_ai_text_adventure_games_narrated_and/",
          "publishedOn": "2023-08-07T02:30:29.000Z",
          "wordCount": 2542,
          "title": "[P] AI Text Adventure Games - Narrated and Illustrated by AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15k7x0j/n_microsoft_partners_with_meta_for_llama_2/",
          "author": null,
          "description": "Staying on top of all changes, tools, and best practices with AI is getting increasingly hard. Each week I find just 1 piece of information that is most interesting across research, products, business news, and many more. No fluff guaranteed.\n Sharing the top research from this week's edition:\n https://preview.redd.it/fa3b1u39nlgb1.png?width=591&format=png&auto=webp&s=1ccd78136e3578396878fd9641605845f0309865\n Summary: Meta released their latest open-source model, Llama 2, in partnership with Microsoft’s Azure platform. But Microsoft also offers OpenAI models and is a major investor in the company (they paid $14B for 49%). So, confused Matt asks, why would Microsoft partner with Meta, when it might undermine their investment in OpenAI?\n 💡 Answering the question:\n  \nSpreading the risk: OpenAI may have the first mover advantages, but this does not always last (e.g. Blackberry, Myspace, Yahoo). Microsoft is betting on AI but keeps the chips diversified on multiple players.\n It’s beside the point: regardless of who Microsoft supports, their game is to attract all AI utilization on Azure. It's not about the tools but about the CPU/GPU cycles they can charge for. smart!\n The real AI gangsta: Microsoft is sitting on the holy trinity of AI now.\n  \n Exclusive partnerships with top LLMs (OpenAI, Meta)\n Priority access to Nvidia GPUs\n And strategic assets like GitHub and Azure\n  \nView tweet\n If you'd like weekly recaps like this sent to your inbox, consider subscribing to the Tomorrow Now newsletter. 😄\n    submitted by    /u/TomorrowNowTech  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15k7x0j/n_microsoft_partners_with_meta_for_llama_2/",
          "publishedOn": "2023-08-07T02:29:10.000Z",
          "wordCount": 2723,
          "title": "[N] Microsoft partners with Meta for Llama 2 release. But why?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15k2bb0/pquestion/",
          "author": null,
          "description": "Hello I am attempting to reduce a matrix that is 57 by 256 to 57 to 128. I was attempting to use PCA but it failed as maximum size would be 57 by 57. I was also attempting an autoencoder but the syntax behind this is very confusing so If anyone could give me adivce that would be great. Thank you \n    submitted by    /u/amayorgafcw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15k2bb0/pquestion/",
          "publishedOn": "2023-08-06T22:14:20.000Z",
          "wordCount": 2511,
          "title": "[P]:Question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15k254o/p_rust_meets_llama2_openai_compatible_api_written/",
          "author": null,
          "description": "Hello,\n I have been working on an OpenAI-compatible API for serving LLAMA-2 models written entirely in Rust. It supports offloading computation to Nvidia GPU and Metal acceleration for GGML models !\n Here is the project link: Cria- Local LLAMA2 API\n You can use it as an OpenAI replacement (check out the included `Langchain` example in the project).\n This is an ongoing project, I have implemented the `embeddings` and `completions` routes. The `chat-completion` route will be here very soon!\n Really interested in your feedback and I would welcome any help :) !\n ​\n ​\n    submitted by    /u/amindiro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15k254o/p_rust_meets_llama2_openai_compatible_api_written/",
          "publishedOn": "2023-08-06T22:06:55.000Z",
          "wordCount": 2550,
          "title": "[P] Rust meets Llama2: OpenAI compatible API written in Rust",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15k0rz2/p_aicrafted_daily_digest_exploring_latest_ml/",
          "author": null,
          "description": "submitted by    /u/eusben  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15k0rz2/p_aicrafted_daily_digest_exploring_latest_ml/",
          "publishedOn": "2023-08-06T21:11:03.000Z",
          "wordCount": 2468,
          "title": "[P] AI-Crafted Daily Digest: Exploring Latest ML Developments",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15k0p9j/p_triple_threat_the_power_of_transcription/",
          "author": null,
          "description": "Open source Audio pipeline for transcription, translation and summarization.\n Check out our demo page to generate your own transcription, summary, and translation, or use our browser extension to get live transcriptions.\n    submitted by    /u/eusben  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15k0p9j/p_triple_threat_the_power_of_transcription/",
          "publishedOn": "2023-08-06T21:08:01.000Z",
          "wordCount": 2490,
          "title": "[P] Triple Threat: The Power of Transcription, Summary, and Translation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15k0er6/d_comprehensive_learning_resources_that_emphasize/",
          "author": null,
          "description": "So I understand that there is the Sutton & Barto book on reinforcement learning in the sidebar. I was wondering what other resources you guys have used that you would recommend that emphasize deep reinforcement learning for someone with some experience in shallow/classical reinforcement learning already and some experience with deep learning already, but new to deep reinforcement learning\n    submitted by    /u/BornAgain20Fifteen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15k0er6/d_comprehensive_learning_resources_that_emphasize/",
          "publishedOn": "2023-08-06T20:56:27.000Z",
          "wordCount": 2517,
          "title": "[D] Comprehensive learning resources that emphasize DEEP reinforcement learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jzg1x/d_how_to_predict_long_sequences_of_events_to/",
          "author": null,
          "description": "Hey! \n I am working on a project to predict the best sequences of marketing channel so that sales is maximized. I have 20 ways of reaching out to the customer (email, phone, face2face...). I have 20 days of interaction history and it's generated sales, recorded for past 2 years. I have to predict for the next 20 working days(1 month)\n So far, I have tried ensemble methods, svm, fully connected nn, etc. But it is quite apparent that these are not good solutions. \n Any suggestions on ml/dl methods? Papers, blogs or other resources would be much appreciated\n    submitted by    /u/TUSH11235  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jzg1x/d_how_to_predict_long_sequences_of_events_to/",
          "publishedOn": "2023-08-06T20:17:35.000Z",
          "wordCount": 2557,
          "title": "[D] How to predict long sequences of events to optimize sales?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jub9s/aiml_best_practices_during_a_gold_rush_d/",
          "author": null,
          "description": "submitted by    /u/swodtke  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jub9s/aiml_best_practices_during_a_gold_rush_d/",
          "publishedOn": "2023-08-06T16:49:59.000Z",
          "wordCount": 2468,
          "title": "AI/ML Best Practices During a Gold Rush [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jr6be/r_looking_for_perspectives_pursuing_a_phd_in_ai/",
          "author": null,
          "description": "Greetings fellow researchers,\n I am 27, currently working remotely at a healthcare IT company based in Silicon Valley (6+ years in industrial research) where I apply deep learning methods and large language models. I recently received an exciting opportunity to pursue a PhD at the Technical University of Denmark (DTU) in a similar research area. \n While I am grateful for my current position and compensation, Have published in NeurIPS, EMNLP, ACL, ACM etc (NLP) with really good citations under company. I feel unsatisfied with the learning opportunities available in company & industry.\n I am strongly considering pursuing the DTU PhD program full-time, but wanted to get perspectives from others before making a decision. How strong is DTU's AI research community?\n Given the rapid advances in large language models, is now an ideal time to immerse myself in academic research? There are many topics that interest me, including fairness, ethics, hallucinations, quantization, specialized domains like healthcare/finance, and federated learning combined with LLMs.\n Would appreciate any insights on whether moving into academia would be a wise choice at this stage versus remaining in industry. I welcome any suggestions or considerations I should keep in mind. \n Thank you for taking the time to share your thoughts!\n    submitted by    /u/Traditional-Poet2746  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jr6be/r_looking_for_perspectives_pursuing_a_phd_in_ai/",
          "publishedOn": "2023-08-06T14:36:43.000Z",
          "wordCount": 2665,
          "title": "[R] Looking for Perspectives: Pursuing a PhD in AI vs Continuing in Industry",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jpk6l/p_generative_language_model_gru_learns_constant/",
          "author": null,
          "description": "Context\n I'm working on an RNN-based model that should learn how to guess the next character given a simple prompt based on all scripts from Friends to generate non-existing Friends dialogue. It is heavily inspired by Andrej Karpathy's blog post on RNN's. I'm mostly doing this for training, and because it's pretty fun.\n I have a little experience with deep learning in the sense that I am familiar with most common architectures and have intermediate understanding of how deep learning models work and are trained. I haven't created many models from scratch though, yet.\n Network\n My GRU is fairly simple. I'll save you the exact code, but instead give a systematic overview of all network layers. It's implemented with Pytorch:\n INPUT: sequence of integers representing a symbol based on mapping e…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jpk6l/p_generative_language_model_gru_learns_constant/",
          "publishedOn": "2023-08-06T13:23:12.000Z",
          "wordCount": 2825,
          "title": "[P] Generative Language Model (GRU) learns constant representation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jovx4/d_today_the_source_code_button_is_gone/",
          "author": null,
          "description": "submitted by    /u/Better-Process5239  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jovx4/d_today_the_source_code_button_is_gone/",
          "publishedOn": "2023-08-06T12:50:51.000Z",
          "wordCount": 2466,
          "title": "[D] Today the source code button is gone...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jlomu/p_underlining_detection_algorithm/",
          "author": null,
          "description": "Hey.\n I'm currently working on an application that digitalizes text from physical book pages using Google's Cloud Vision API.\n I'm looking to add a functionality that can recognize and highlight underlined words within the scanned pages. I initially thought this would be a common feature and expected to find existing open-source solutions or libraries that I could use. To my surprise, I've been unable to find any. \n I am just really bad at finding it, or is this not as straightforward as I initially thought?\n    submitted by    /u/pangu2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jlomu/p_underlining_detection_algorithm/",
          "publishedOn": "2023-08-06T09:50:18.000Z",
          "wordCount": 2538,
          "title": "[P] Underlining detection algorithm?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jjfkj/n_computer_vision_news_of_august_2023_with_ai_cv/",
          "author": null,
          "description": "Dear all,\n Here is Computer Vision News of August 2023.\n Read 44 pages about AI, Deep Learning, Computer Vision and more!\n Online version (recommended)\n PDF version\n Free subscription on page 44.\n Enjoy!\n https://preview.redd.it/e143wha20ggb1.jpg?width=794&format=pjpg&auto=webp&s=14a699f80f4b2de94addc8242e8978d3e185309f\n    submitted by    /u/Gletta  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jjfkj/n_computer_vision_news_of_august_2023_with_ai_cv/",
          "publishedOn": "2023-08-06T07:33:40.000Z",
          "wordCount": 2494,
          "title": "[N] Computer Vision News of August 2023 with AI, CV, DL and ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jhfk7/d_fine_tuning_or_semantic_search_with_a_vector/",
          "author": null,
          "description": "Experts, I am a beginner here and seeking some advise here please.\n I am have compiled a high quality Q&A dataset (around 1200 entries) for a domain specific topic.\n What's the best course of action here to use LLM with that specific knowledge base?\n 1) Finetuning a model? if so which one is a good candidate? OpenAI let's me finetune some models and later, all my users have to do is use pass the model name to the API\n 2) Use the regular vector database + embeddings for augmented retrieval\n \n I prefer (1) but I am not sure how it will perform.\n Option (2) should work, since we really just use semantic search to bring in context to the LLM, etc.\n I hope you can say that (1) works nicely, if not please help me learn why.\n Thank you in advance!\n    submitted by    /u/entered_apprentice  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jhfk7/d_fine_tuning_or_semantic_search_with_a_vector/",
          "publishedOn": "2023-08-06T05:36:43.000Z",
          "wordCount": 2599,
          "title": "[D] Fine tuning or semantic search with a vector database?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jeycg/llm_related_pytorch_code_d/",
          "author": null,
          "description": "Where to find LLM related pytorch code with code explanations?\n    submitted by    /u/thorin_olamadal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jeycg/llm_related_pytorch_code_d/",
          "publishedOn": "2023-08-06T03:21:26.000Z",
          "wordCount": 2464,
          "title": "LLM related pytorch code [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jd1wu/d_how_does_one_withdraw_a_paper_from_neurips/",
          "author": null,
          "description": "First time submitter here and was unable to find a similar post (and thought the community might benefit from this in the future!). How do I withdraw from Neurips? All the instructions I found are from 2017, 2018. Do I need to contact someone or do I just need to \"Add Withdrawal\" on OpenReview.\n    submitted by    /u/Dramatic-Gap-4681  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jd1wu/d_how_does_one_withdraw_a_paper_from_neurips/",
          "publishedOn": "2023-08-06T01:44:20.000Z",
          "wordCount": 2512,
          "title": "[D] How does one withdraw a paper from Neurips?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15jb52o/d_why_have_separate_stages_for_rpn_proposal/",
          "author": null,
          "description": "Just what the title says.\n Also is this (splitting prediction into 2 stages) a prominent paradigm in other areas of ML too? I am reading about something called the \"Action Transformer\" created by Adept AI, and it also has 2 stages: instruction generation and code generation.\n    submitted by    /u/FloatingDelusion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15jb52o/d_why_have_separate_stages_for_rpn_proposal/",
          "publishedOn": "2023-08-06T00:13:19.000Z",
          "wordCount": 2507,
          "title": "[D] Why have separate stages for RPN (proposal generation) and ROI (refinement)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15j5zw6/d_how_to_mathematically_prove_that_a_neural/",
          "author": null,
          "description": "Hello r/MachineLearning!\n I'm working on understanding how a neural network converges and wish to approach this mathematically. Can anyone recommend resources, papers, or tools that could assist me in proving this?\n Thank you in advance for your help! \n Edit: Removed converges faster to remove ambiguity\n    submitted by    /u/abystoma  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15j5zw6/d_how_to_mathematically_prove_that_a_neural/",
          "publishedOn": "2023-08-05T20:35:49.000Z",
          "wordCount": 2506,
          "title": "[D] How to Mathematically Prove that a Neural Network is Converging Faster",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15j4tyn/d_transformer_for_realtime_action_recognition/",
          "author": null,
          "description": "Do you aware of any work for realtime action recognition that use transformer? This is different with conventional transformer in a sense that we don’t have access to future information, so how do we change the training strategy? Also, it’s inefficient if we use the entire history; are there any smart way to select which frame in the past to keep?\n    submitted by    /u/Ok_Influence505  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15j4tyn/d_transformer_for_realtime_action_recognition/",
          "publishedOn": "2023-08-05T19:48:08.000Z",
          "wordCount": 2516,
          "title": "[D] Transformer for realtime action recognition",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15j244e/p_vectara_flowise/",
          "author": null,
          "description": "u/Vectara is now integrated with r/flowise, so you can easily build no-code GenAI Apps at scale.\n Check out the video here: https://twitter.com/ofermend/status/1687138158692196352\n You can sign up for a free vectara.com account to get started.\n    submitted by    /u/ofermend  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15j244e/p_vectara_flowise/",
          "publishedOn": "2023-08-05T17:55:28.000Z",
          "wordCount": 2486,
          "title": "[[P] Vectara+ Flowise",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15j11k1/custom_tokenizers_optimization_opportunity_or/",
          "author": null,
          "description": "I've recently started to explore the possibility of working with custom tokenizers. I will preface this by saying I'm not a tokenizer guy. I just don't know that much about their construction. I understand how they work, but I'm probably behind the latest developments in tokenizers.\n So, I thought it wisest to reach out to the community for advice or clarity.\n Context:\n I've collected about 15 GB of data over the last month. It's incredibly clean and well-organized. The core goal of the data is to train a model to solve or assist with a particular development problem. This means that much of my data is a code/natural language mix. It's delimited clearly, and the formatting is uniform. The entire dataset has been normalized and standardized. It's taken me a lot of time to produce and that's…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15j11k1/custom_tokenizers_optimization_opportunity_or/",
          "publishedOn": "2023-08-05T17:10:18.000Z",
          "wordCount": 3088,
          "title": "Custom Tokenizers - Optimization Opportunity or Waste of Time? [D], [R}",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15j0xwt/r_the_quest_to_have_endless_conversations_with/",
          "author": null,
          "description": "​\n https://preview.redd.it/mbkb10icqbgb1.png?width=1400&format=png&auto=webp&s=7a15423060ddfeffe4651340bcc6fd7cf36dde10\n I started a blog post series about the limitations of language models for dealing with long texts.\n Feedback is welcome!\n    submitted by    /u/JClub  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15j0xwt/r_the_quest_to_have_endless_conversations_with/",
          "publishedOn": "2023-08-05T17:06:01.000Z",
          "wordCount": 2481,
          "title": "[R] The Quest to Have Endless Conversations with Llama and ChatGPT 🗣️💬",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15izni1/d_energy_efficiency_of_data_centers_versus/",
          "author": null,
          "description": "Hi everyone,\n With the recent boom of LLMs, we have seen both ends of the spectrum advance at a very fast pace, from OpenAI GPT4, which runs on huge data centers operated by Azure, to llama.cpp, which runs on consumer laptops.\n While both have their pros and cons, for instance, open-source models on decentralized compute reduce the need to trust or rely on centralized actors like Cloud providers, the efficiency of running training/inference on personal setups is not often discussed.\n I am therefore interested in learning how more energy/cost efficient it is to train/serve AI models on data centers vs doing it on personal computers. \n Do you know if there have been studies? \n In theory, I guess that several factors, such as economies of scale, use of renewable energy sources in some data centers, such as Canada, advanced cooling systems and advanced hardware, make data centers more cost/energy efficient.\n I guess some modeling on a precise use case where we fix some variables could help have an idea. For instance, one could ask, what is the energy/cost/time needed to predict 1 billion tokens from a Llama 2 70B in a data center with X amount of A100s, vs on Y different consumer CPU / GPUs.\n If anyone has references to models or past studies I would be quite interested. Of course, using data centers implies trusting those people, but I am not considering that factor for this discussion as I am focusing on understanding best what is the best setup to have optimal enrgy/cost/time for AI.\n    submitted by    /u/Separate-Still3770  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15izni1/d_energy_efficiency_of_data_centers_versus/",
          "publishedOn": "2023-08-05T16:12:32.000Z",
          "wordCount": 2720,
          "title": "[D] Energy efficiency of data centers versus consumer-grade setups for training and inference of LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15iz6v7/d_nvidia_gpu_shortage_is_top_gossip_of_silicon/",
          "author": null,
          "description": "submitted by    /u/norcalnatv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15iz6v7/d_nvidia_gpu_shortage_is_top_gossip_of_silicon/",
          "publishedOn": "2023-08-05T15:53:59.000Z",
          "wordCount": 2470,
          "title": "[D] Nvidia GPU shortage is ‘top gossip’ of Silicon Valley",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15iyyyp/iccv_challenge_on_geographical_domain_adaptation_r/",
          "author": null,
          "description": "As part of ICCV 2023 in Paris, this year we are organizing a challenge on solving domain gaps that occur when computer vision models are transferred across geographical locations. The challenge covers three tracks in unsupervised scene adaptation, image adaptation and universal adaptation. The challenge is open to everyone, with attractive prizes for the winners. Check it out at the following links!\n Challenge Rules and Guidelines: https://geonet-challenge.github.io/ICCV2023/challenge.html\n Challenge Registration: https://forms.gle/zSZA1iaPD3mZxjyn7\n Code and baselines: https://github.com/ViLab-UCSD/GeoNet\n The training data for the challenge is already available, and the test data will be released to the registered participants.\n    submitted by    /u/GeoNetICCV2023  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15iyyyp/iccv_challenge_on_geographical_domain_adaptation_r/",
          "publishedOn": "2023-08-05T15:44:45.000Z",
          "wordCount": 2548,
          "title": "ICCV Challenge on Geographical Domain Adaptation [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15iwdgs/p_mechdesigner_assistant_ai_future_engineers/",
          "author": null,
          "description": "Hi guys\n Im looking for groups or communities where i could discuss about certain topic. Im a software developer and a mechanical engineer and recently made an app that combines gpt4 model to perform engineering tasks like CAD models creation and performing stress analysis. I would like find people who share the same passion and perhaps would like to discuss about that, exchange the concepts, ideas and visions. Im getting to the point where i will need to implement own trained model and im no ML expert so would be great to discuss about the architecture etc. \n Here is a demo of my app\n MechDesigner Assistant AI: Future Engineers\n Best regards\n Pyotr\n    submitted by    /u/pyotr_vozniak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15iwdgs/p_mechdesigner_assistant_ai_future_engineers/",
          "publishedOn": "2023-08-05T13:56:26.000Z",
          "wordCount": 2575,
          "title": "[P] MechDesigner Assistant AI: Future Engineers. Looking for communities, groups etc to exchange ideas, experience",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15iv2tj/p_drum_kick_generation_app/",
          "author": null,
          "description": "Hi, I am a new starter with ML apps and want to build a first app preferably using existing (trained) models. The idea is an app that takes a text description of a wished kick drum (for example: create a 808 kick with enhanced subs and filtered above 15kHz) and then generates a corresponding hifi sample of the description (44,1k or 48k). \n I would like to learn how to do that with some peers happy to help me.\n As said this would be my first attempt. About me: I only followed Deep Learning theoretical courses from Andrew Ng and never built or used existing models so I'd appreciate some guidance if you are interested to support. Thanks a lot \n    submitted by    /u/freeabt19  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15iv2tj/p_drum_kick_generation_app/",
          "publishedOn": "2023-08-05T12:58:48.000Z",
          "wordCount": 2573,
          "title": "[P] Drum Kick Generation app",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15iunr9/d_human_biological_and_spiking_neural_networks_a/",
          "author": null,
          "description": "submitted by    /u/Impressive-Ad-8964  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15iunr9/d_human_biological_and_spiking_neural_networks_a/",
          "publishedOn": "2023-08-05T12:38:31.000Z",
          "wordCount": 2463,
          "title": "[D] Human Biological and Spiking Neural Networks. A Literature Review of Recent BNN and SNN Advances)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15iug4w/p_nerfjl_a_realtime_neural_3d_scene/",
          "author": null,
          "description": "submitted by    /u/Fincho64  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15iug4w/p_nerfjl_a_realtime_neural_3d_scene/",
          "publishedOn": "2023-08-05T12:28:12.000Z",
          "wordCount": 2464,
          "title": "[P] Nerf.jl a Real-Time Neural 3D Scene Reconstruction in Pure Julia | Anton Smirnov | JuliaCon 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15itmy9/dhow_do_you_usually_deal_with_multimodal_target/",
          "author": null,
          "description": "Popular machine model techniques such as LightGBM and XGBoost output predictions that are unimodally distributed(only one hump) but seem to beat other models specialized to deal with multimodal data. Or am I just wrong? \n It just doesnt look right.\n https://preview.redd.it/6xrd7hgm4agb1.png?width=1000&format=png&auto=webp&s=a4518549f609c6436af410ae87a0c6a24cff6ea7\n    submitted by    /u/runawaychicken  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15itmy9/dhow_do_you_usually_deal_with_multimodal_target/",
          "publishedOn": "2023-08-05T11:47:42.000Z",
          "wordCount": 2497,
          "title": "[D]How do you usually deal with multimodal target variable?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15itj9s/d_transformer_implementation_help/",
          "author": null,
          "description": "Hey I've tried to implement the transformer architecture on my own to understand it better. The outputs look fine (I'm only looking at shapes) and I wanted to know if it's right firstly, and if there is anyway to implement it in a more efficient way.\n Code -\n import torch import torch.nn as nn class MultiHeadSelfAttention(nn.Module): def __init__(self, nheads=8, dim=512, bias=True, dropout=0.2): super().__init__() assert dim % nheads == 0, \"dimension must be divisible by number of heads\" self.nheads = nheads self.dim = dim self.head_dim = dim // nheads self.scale = self.head_dim**-0.5 self.softmax = nn.Softmax(dim=-1) self.dropout = nn.Dropout(dropout) self.to_keys = nn.Linear(dim, self.dim_heads * nheads, bias=bias) self.to_queries = nn.Linear(dim, self.dim_heads * nheads, bias=bias) self.to_values = nn.Linear(dim, self.dim_heads * nheads, bias=bias) self.to_out = nn.Linear(self.dim_heads * nheads, dim, bias=bias) def change_shape(self, x): b_size = x.shape[:-1] return x.reshape(*b_size, self.nheads, self.head_dim) def forward(self, x, mask=True): q = self.change_shape(self.to_queries(x)) k = self.change_shape(self.to_keys(x)) v = self.change_shape(self.to_values(x)) dot_score = q @ k.transpose(-2, -1) * self.scale if mask: tril = torch.tril(torch.ones(dot_score.shape[-2:])) dot_score = dot_score.masked_fill(tril == 0, float(\"-inf\")) attn = self.softmax(attn) attn = self.dropout(attn) out = torch.einsum(\"bnk,bnd->bnd\", attn, v) b_size = out.shape[:-2] out = out.view(*b_size, -1) return self.to_out(out) \n Thank you!\n    submitted by    /u/04RR  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15itj9s/d_transformer_implementation_help/",
          "publishedOn": "2023-08-05T11:42:16.000Z",
          "wordCount": 2643,
          "title": "[D] Transformer implementation - help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15itb45/p_implement_parallel_training_using_the/",
          "author": null,
          "description": "https://github.com/NoteDancing/Note This project allows you to easily implement parallel training with the multiprocessing module. \n    submitted by    /u/NoteDancing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15itb45/p_implement_parallel_training_using_the/",
          "publishedOn": "2023-08-05T11:30:27.000Z",
          "wordCount": 2471,
          "title": "[P] Implement parallel training using the multiprocessing module.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ioim1/r_forward_process_of_diffusion_models/",
          "author": null,
          "description": "In the forward process of diffusion models, gaussian noise is added -- when this is done, is the resulting \"noisy image\" clipped to be within the pixel-value bounds (ie [0, 255] or [0, 1]), or is it allowed to exceed these limits? \n Clipping makes sense as there is no interpretation for pixel values which exceed these limits.\n On the other hand, the problem with clipping is that if the added noise is clipped, you are not adding truly gaussian noise, which seems problematic as much of the theory behind diffusion models assumes true gaussian noise. \n Any ideas about what is done in practice, and whether or not this has implications from a theoretical standpoint?\n    submitted by    /u/alkaway  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ioim1/r_forward_process_of_diffusion_models/",
          "publishedOn": "2023-08-05T06:57:10.000Z",
          "wordCount": 2569,
          "title": "[R] Forward Process of Diffusion Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ioahe/team_is_burning_out_trying_to_create_a_dataset/",
          "author": null,
          "description": "Good Evening ML peeps\n So I am currently creating a dataset in a team of three. This dataset is aimed to create a object detection model for around 11 classes. We have aimed to label around approx. 4000. Our current workflow is a couple of scripts scraping from Pinterest and using Label Studio for labeling. We labeled approx. 25% to our goal but realized that we are about to burn out. We'd prefer that whatever solution there is is self hosted and not paid.\n Thoughts? is there some kind of workflow we are missing to create a dataset?\n    submitted by    /u/PlanetAcorn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ioahe/team_is_burning_out_trying_to_create_a_dataset/",
          "publishedOn": "2023-08-05T06:43:42.000Z",
          "wordCount": 2559,
          "title": "Team is burning out trying to create a dataset. Any solutions? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15imv19/d_documentbased_qna_without_openai/",
          "author": null,
          "description": "I am working on a project that is very popular with the inception of Langchain + GPT applications. However, I want to make it open source and hence don't want to use GPT. So something like Langchain + LLama2, etc. I know currently Langchain only supports GPT but any other ideas are highly appreciated!\n    submitted by    /u/vishank97  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15imv19/d_documentbased_qna_without_openai/",
          "publishedOn": "2023-08-05T05:22:58.000Z",
          "wordCount": 2508,
          "title": "[D] Document-based QnA without OpenAI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ii969/d_looking_for_suggestions_guides_on_how_to_switch/",
          "author": null,
          "description": "Hi all, \n I'm interested in redesigning my application to utilize an open-source embeddings model and a different vector DB. My current issue with embeddings is that processing large volumes of data into a vector DB using ada-002 is unreliable, with frequent API timeouts occurring or issues interacting with Pinecone. This is super problematic as it's difficult to track which data has / hasn't been stored correctly. I also know that many open-source embeddings models are more performant and will allow for more long term control over my data. \n However, the advantage of using OpenAI / Pinecone has of course been simplicity in production and not having to worry about queries / retrieval working efficiently. To give context, I'm dealing with a large volume of documents, such that if I were to embed my documents into a FAISS index with a small sentence transformers model, it would constitute 12GB, so a really simple solution like storing within the same application database is probably a no-go.\n In initiating this switch, I want to know the best approach towards: \n A) Utilizing an open-source embeddings model in a production context (is it best to host as an API via a cloud provider and what are some considerations I should think about? What's a fast / reliable way of setting this up? I would like prioritise a more simple approach if possible.) \n B) What Vector DB I should be looking into as an alternative and what's the best way to achieve self-hosted so that it would be equally performant compared to hosted services like pinecone (Docker? AWS?)? \n    submitted by    /u/theheffalump2000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ii969/d_looking_for_suggestions_guides_on_how_to_switch/",
          "publishedOn": "2023-08-05T01:30:26.000Z",
          "wordCount": 2732,
          "title": "[D] Looking for suggestions / guides on how to switch from OpenAI Embeddings and Pinecone to open-source / self-hosted architecture options.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ifjfc/d_gpumachine_ondemand_rental_that_runs_windows_10/",
          "author": null,
          "description": "Anyone know of a cloud service renting on-demand GPU instances (RTX 4090 preferably) that run Windows 10 or newer?\n Believe me, I know...\n I rent on-demand instances from vast.ai for Linux and have been exceedingly happy with their services. I've also used paperspace in the past with good success. Unfortunately, we are in need of RTX 4090s (or roughly equivalent performing Tesla cards) that run on a host OS of Windows 10+ (Server/Win11/etc all fine) because a lot of the modeling software in the industry I work in runs on Windows-only, which is absurd, but nevertheless the truth.\n The fastest I can find are A6000s on paperspace which won't cut the mustard. At the moment we have a 3090 and a bunch of 3070s on-prem which are doing OK but the RTX 4090 is simply much much better, and unsurprisingly the Windows-only software is also not coded in a way that takes advantage of multiple GPUs all that well either.\n Thanks for any help or referrals provided, I really appreciate it. \n (Have checked paperspace, vastai, runpod, and a few other smaller ones to no avail)\n    submitted by    /u/kyleboddy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ifjfc/d_gpumachine_ondemand_rental_that_runs_windows_10/",
          "publishedOn": "2023-08-04T23:30:32.000Z",
          "wordCount": 2649,
          "title": "[D] GPU/Machine on-demand rental that runs Windows 10+ as host OS? (I know, I know...)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15i9koq/d_how_do_i_improve_performance/",
          "author": null,
          "description": "Hello everyone. I am new to this sub so please go easy on me lol.\n I want to implement a neural net that recognizes whether an object in an image matches one of a set of objects with limited training data. \n I already have worked on a siamese network implementation with triplet loss and ResNet, but I am not getting great performance. Should I do something else?\n For extra info, there are roughly 300 objects/classes and around 7 images per object (most are augmented images)\n    submitted by    /u/Nearby_Ad_5644  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15i9koq/d_how_do_i_improve_performance/",
          "publishedOn": "2023-08-04T19:37:58.000Z",
          "wordCount": 2540,
          "title": "[D] How do I improve performance?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15i94w0/r_learning_to_model_the_world_with_language_uc/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2308.01399 \n Github: https://github.com/jlin816/dynalang Code coming soon!\n Abstract:\n  \nTo interact with humans in the world, agents need to understand the diverse types of language that people use, relate them to the visual world, and act based on them. While current agents learn to execute simple language instructions from task rewards, we aim to build agents that leverage diverse language that conveys general knowledge, describes the state of the world, provides interactive feedback, and more. Our key idea is that language helps agents predict the future: what will be observed, how the world will behave, and which situations will be rewarded. This perspective unifies language understanding with future prediction as a powerful self-supervised learning object…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15i94w0/r_learning_to_model_the_world_with_language_uc/",
          "publishedOn": "2023-08-04T19:21:07.000Z",
          "wordCount": 2708,
          "title": "[R] Learning to Model the World with Language - UC Berkeley 2023 - Dynalang an agent that learns a multimodal world model that predicts future text and image representations and learns to act from imagined model rollouts!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15i82xh/p_i_created_scorecast_a_tool_to_predict_the/",
          "author": null,
          "description": "https://preview.redd.it/p70yknwm15gb1.png?width=1901&format=png&auto=webp&s=7417914304cc23d6691653cd73396bd600a44b0a\n Hey Guys,\n I am happy to share with you a web application I've working on the past couple weeks. It's a tool to predict the outcome of soccer games in minor football leagues. Named ScoreCast, it predicts the outcome of soccer games in six minor leagues: Serie A Brazil, Serie B Brazil, Primera Division Argentina, J1 League Japan, Eliteserien Norway, and Veikkausliiga Finland.\n Since I am really interested in football analytics and also not being able to find many online tools for predicting the outcomes in minor soccer leagues, I had the need to create ScoreCast to have it as a tool for guidance on this field.\n If you want to check it out, here are some links that might help:\n  \nGithub: https://github.com/Costasgk/ScoreCast\n The App: https://score-cast-3a6cb8fe5c50.herokuapp.com/\n Medium: https://medium.com/@costascg9/scorecast-a-tool-for-predicting-football-game-outcomes-in-minor-leagues-666f7acca3a\n  \nThank you for your time!\n    submitted by    /u/Costas_8  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15i82xh/p_i_created_scorecast_a_tool_to_predict_the/",
          "publishedOn": "2023-08-04T18:39:21.000Z",
          "wordCount": 2599,
          "title": "[P] I created ScoreCast, a tool to predict the outcome of football games in minor football leagues.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15i6vfb/p_struggling_with_audio_enhancement_using_gans/",
          "author": null,
          "description": "I'm working on a Python project that aims to transform phone-quality acoustic guitar recordings into studio-like ones. My approach involves using a Generative Adversarial Network (GAN) with two components: a Generator and a Discriminator.\n Here's a quick rundown of my process:\n Data Loading & Preprocessing: Convert acoustic guitar recordings to spectrograms and split into training and validation sets.\n Generator: Neural network trained to create high-quality studio recording spectrograms from low-quality inputs.\n Discriminator: Another neural network trained to differentiate between real and generator-created high-quality spectrograms.\n Training: Train the Generator and Discriminator against each other in a cat-and-mouse game of deception and detection.\n Audio Enhancement: Feed the Generator a low-quality spectrogram, get a high-quality one out, and convert it back into an audio file.\n I'm reaching out because I'm not entirely satisfied with the quality of the output. The enhanced audio is just rhythmic noise, what am i missing with generating the audio?\n I'm wondering if anyone here has experience with GANs for audio enhancement and can offer some advice. Is there something I might be missing in my approach? Are there any tips or tricks you've found helpful in your own work?\n And yes, I'm prepared for you to tear me a new one. Bring on the constructive criticism!\n git repo:\n https://github.com/Gabeiscool420/AURAL_GAN-predictive_model/blob/main/requirements.txt\n    submitted by    /u/S0UNDSAGE  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15i6vfb/p_struggling_with_audio_enhancement_using_gans/",
          "publishedOn": "2023-08-04T17:52:28.000Z",
          "wordCount": 2661,
          "title": "[P] Struggling with Audio Enhancement using GANs - Any Suggestions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15i51bz/d_parametric_development/",
          "author": null,
          "description": "I wanted to share with you an approach to software development that I've been exploring recently: Parametric Development. This involves using artificial intelligence (AI) models, including GPT-like models, BART-like models, and other specialized transformer models, to assist in writing, debugging, and documenting code.\n My journey with programming is a bit unconventional. I took one year of computer science at university and learned how to write \"Hello, World!\" in TurboPascal from an old university textbook in late primary school. That was the extent of my programming experience until about a month ago. Since then, I've been using AI models to write code for my ideas, as I don't have extensive programming skills. These AI models have written and debugged every single line of code in my pro…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15i51bz/d_parametric_development/",
          "publishedOn": "2023-08-04T16:41:22.000Z",
          "wordCount": 2774,
          "title": "[D] Parametric Development",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15i0uxv/d_cikm_23_notification/",
          "author": null,
          "description": "Today is the day of paper notification according to the CFP. Has anyone received the notification?\n    submitted by    /u/Alliswell2257  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15i0uxv/d_cikm_23_notification/",
          "publishedOn": "2023-08-04T13:59:37.000Z",
          "wordCount": 2469,
          "title": "[D] CIKM 23 Notification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hwr6y/discussion_automated_unstructured_structured_oss/",
          "author": null,
          "description": "Hey folks,\n i'm a data engineer in the traditional space for over 10 years. I am working on a library for easy transitioning unstructured to structured data. The use case is that I would regularly build a ton of python pipelines but without schema management, they would be a pain to maintain.\n 2y ago I started working on this library https://pypi.org/project/dlt/, and now it''s ready to help people like myself to load json to db/parquet/iceberg with a 1-liner with schema evolution. Declarative loading possible.\n I am looking for the following feedback\n - What would make this more useful in the ML space? Specific destinations? Are the docs usable or do you expect something different? let me know what. For example, we are adding Weaviate vector db and Athena + Iceberg in the next weeks.\n - any features you are missing? or any ideas that you think would be helpful? \n - are the docs relatable, understandable? what are you missing?\n ​\n docs are here, you can find colab demos under getting started: https://dlthub.com/docs/intro\n    submitted by    /u/Thinker_Assignment  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hwr6y/discussion_automated_unstructured_structured_oss/",
          "publishedOn": "2023-08-04T10:50:41.000Z",
          "wordCount": 2630,
          "title": "[Discussion] Automated unstructured -> structured OSS library - give me your requirements",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hw8gw/d_validate_my_approach_to_do_unsupervised_fine/",
          "author": null,
          "description": "Any suggestions on how to prepare code data to fine tune a code LLM in an unsupervised way or is it even possible?\n For example: Task: Code summarisation with custom code base (with no summaries) Let's assume that this code base is unique and a pre-trained model is giving unsatisfactory results. Now to fine tune there are three options, 1. Manually prepare summaries for a portion of the code and fine tune 2. Find a similar code base which has the labels (docstring) and fine tune 3. Mask some portions of the code randomly and give as input and output will be the masked portions\n Options 1 and 2 don't seem feasible for a production environment. \n The reasoning behind option 3 is that with no availability labels, the model will learn the patterns in the code base and provide a better summarisation with its pre-trained knowledge.\n I tried the option 3 with CodeT5+ fine tuning. The format of input and output was as follows Input:\n def __init__(self, text, font): self._text = text self._font = font def get_text(self): |<mask>| def set_text(self, value): self._text = value``` \n Output: return self._text\n    submitted by    /u/dire_wolf_cookie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hw8gw/d_validate_my_approach_to_do_unsupervised_fine/",
          "publishedOn": "2023-08-04T10:22:55.000Z",
          "wordCount": 2653,
          "title": "[D] Validate my approach to do Unsupervised Fine tuning of Code LLMs like CodeT5+ and Starcoder with custom code base",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hvp20/project_enquiry_for_individuals_working_with/",
          "author": null,
          "description": "Hello Everyone . Myself Harsha. I am final year Masters student in Berlin pursuing my thesis currently. For my thesis \"Natural Language Processing in Data transfer across documents in Commidity Trading Industry\" i am in search for professionals who are working with NLP currently in companies who can lend me 10 minutes of their time for a personal interview. THIS WOULD BE A LOT HELPFUL. please do let me know.\n Thanks in advance\n    submitted by    /u/Aimerforlife  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hvp20/project_enquiry_for_individuals_working_with/",
          "publishedOn": "2023-08-04T09:53:18.000Z",
          "wordCount": 2531,
          "title": "[Project] Enquiry for individuals working with Natural Language Processing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ht5yd/d_why_is_tflite_c_so_hard_to_compile/",
          "author": null,
          "description": "Has anyone actually done this and can dm me? I am trying to incldue the interpreter to run inference with a simple c++ program and a custom trained model. But I cannot figure out how to update include paths and cannot see any resources online.\n    submitted by    /u/Agreeable_Fee477  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ht5yd/d_why_is_tflite_c_so_hard_to_compile/",
          "publishedOn": "2023-08-04T07:27:49.000Z",
          "wordCount": 2503,
          "title": "[D] Why is tflite c++ so hard to compile?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hs7c7/from_sparse_to_soft_mixtures_of_experts_r/",
          "author": null,
          "description": "submitted by    /u/we_are_mammals  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hs7c7/from_sparse_to_soft_mixtures_of_experts_r/",
          "publishedOn": "2023-08-04T06:31:56.000Z",
          "wordCount": 2468,
          "title": "From Sparse to Soft Mixtures of Experts [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hr6xb/d_why_is_it_so_hard_to_rent_gpu_time/",
          "author": null,
          "description": "I'm just a new guy, so take it easy please :) - Is it just because I'm just signing up for the cloud compute services? Will this get easier?\n I have a 3090 so I can do quite a bit in my home office, but my clients need some larger models now, and I've been trying to pay for instances with an A100 at least. It's been really a lot of push-back...is this normal? What can I do to get access to larger GPUs sooner?\n I have tried paperspace, aws, googlecloud, llambda, linode...would love to know some other services or tools you folks use to get work done.\n Thank you for your time. Interested to hear how you spin up high VRAM environments for projects.\n    submitted by    /u/UrbanSuburbaKnight  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hr6xb/d_why_is_it_so_hard_to_rent_gpu_time/",
          "publishedOn": "2023-08-04T05:34:43.000Z",
          "wordCount": 2584,
          "title": "[D] Why is it so hard to rent GPU time?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hqpdf/d_milvus_search_filtering_based_on_string/",
          "author": null,
          "description": "While doijg vector search on embeddings i wanted to apply a filter based on a column value in milvus. As milvus supports boolean value to apply the filter (or hybrid search) Can someone help me with the boolean code snippet which will apply the filter based on a string value of a field Ex. I'm doing vector search on the field \"context\" and need to filter the result based on a specific \"filename\" string value to further filter and improve the results I'm using milvus 2.2\n    submitted by    /u/adiraat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hqpdf/d_milvus_search_filtering_based_on_string/",
          "publishedOn": "2023-08-04T05:07:00.000Z",
          "wordCount": 2542,
          "title": "[D] milvus search filtering based on string",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hptx2/r_proof_of_lemma_51_in_bayesian_design_principles/",
          "author": null,
          "description": "This paper won ICML 2023 outstanding paper award, its idea is really interesting and I want to follow the details. Lemma 5.1 significantly paves towards the core theoretical results, but the paper does not provide a formal proof. I do not have a deep background on game theory, maybe the proof is obvoius to the professional.\n ​\n https://preview.redd.it/ih6u3wiyr0gb1.png?width=464&format=png&auto=webp&s=cc895b9701e3600213825c34ef3b542f53d65233\n I undersand this lemma tries to construct a Nash equilibrium upon the additional assumption of strong convexity, but why this maximin solution is a Nash equilibrium? Very appreciated if someone provide some hint.\n    submitted by    /u/Kyeon-G  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hptx2/r_proof_of_lemma_51_in_bayesian_design_principles/",
          "publishedOn": "2023-08-04T04:20:24.000Z",
          "wordCount": 2551,
          "title": "[R] Proof of Lemma 5.1 in 'Bayesian Design Principles for Frequentist Sequential Learning'",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15holfn/d_any_noticeable_work_regarding_the_effect_of_a/",
          "author": null,
          "description": "Hi. I'm trying to build a text encoder for a specific domain and want to know what sort of papers there are out there that I should take note of. I may be wrong but it seems that these days ever since LLMs started taking over the choice of tokenizer has become trivial and therefore doesn't warrant much discussion.\n One paper that I remember reading a while ago talked about the effect of using a custom-made vocabulary for the biomedical domain (Pretrained Language Models for Biomedical and Clinical Tasks: Understanding and Extending the State-of-the-Art (Lewis et al., 2020)).\n Are there any other works that I should take note of? Open to any suggestions.\n    submitted by    /u/Seankala  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15holfn/d_any_noticeable_work_regarding_the_effect_of_a/",
          "publishedOn": "2023-08-04T03:17:44.000Z",
          "wordCount": 2576,
          "title": "[D] Any noticeable work regarding the effect of a language model's vocabulary or tokenizer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hnqfw/r_scaling_relationship_on_learning_mathematical/",
          "author": null,
          "description": "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models\n Paper: https://arxiv.org/abs/2308.01825\n GitHub: https://github.com/OFA-Sys/gsm8k-ScRel\n Abstract: Mathematical reasoning is a challenging task for large language models (LLMs), while the scaling relationship of it with respect to LLM capacity is under-explored. In this paper, we investigate how the pre-training loss, supervised data amount, and augmented data amount influence the reasoning performances of a supervised LLM. We find that pre-training loss is a better indicator of the model’s performance than the model’s parameter count. We apply supervised fine-tuning (SFT) with different amounts of supervised data and empirically find a log-linear relation between data amount and model performance, and we find better models improve less with enlarged supervised datasets. To augment more data samples for improving model performances without any human effort, we propose to apply Rejection sampling Fine-Tuning (RFT). RFT uses supervised models to generate and collect correct reasoning paths as augmented fine-tuning datasets. We find with augmented samples containing more distinct reasoning paths, RFT improves mathematical reasoning performance more for LLMs. We also find RFT brings more improvement for less performant LLMs. Furthermore, we combine rejection samples from multiple models which push LLaMA-7B to an accuracy of 49.3% and outperforms the supervised fine-tuning (SFT) accuracy of 35.9% significantly.\n ​\n Head figure\n Pretrain loss vs SFT and ICL\n    submitted by    /u/GanjinZero0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hnqfw/r_scaling_relationship_on_learning_mathematical/",
          "publishedOn": "2023-08-04T02:35:44.000Z",
          "wordCount": 2682,
          "title": "[R] Scaling Relationship on Learning Mathematical Reasoning with Large Language Models - Zheng Yuan et al Alibaba Damo Academy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hjk5t/d_discussion_what_would_be_the_initial_costs_of/",
          "author": null,
          "description": "I was wondering if this would be super expensive or not.\n The cost to develop GPT-3 was about $4 millions according to some resources online. \n Would the cost to develop the first version of a text-to-video AI the same? Around $5M? Is in this value included the salaries of the employees or $5M is just the amount used to train the AI?\n Any answer is appreciated.\n Thanks in advance.\n    submitted by    /u/Claud1ao  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hjk5t/d_discussion_what_would_be_the_initial_costs_of/",
          "publishedOn": "2023-08-03T23:25:48.000Z",
          "wordCount": 2539,
          "title": "[D] [Discussion] What would be the initial costs of developing a text-to-video AI? How would be the quality of this AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hf49e/roadmap_for_mastering_machine_learning_d/",
          "author": null,
          "description": "Hey, first of all, I want to learn how to use nlp, cnn etc. So i think these will come under deep learning. I wanna master deep learning. This whole dl and ml is so confusing. I'll list out some courses, can y'all suggest the order and what courses to follow\n  \nAndrew ng's ml specialization\n Andrew ng's dl specialization\n Statquest's whole machine learning playlist (around 95 videos)\n Fast.ai book\n CS 229 stanford\n CS 231n stanford\n MIT intro to deep learning\n Pytorch for dl and ml by freecodecamp\n DL with pytorch\n  You can give me suggestions too\n  \nTysm for helping\n    submitted by    /u/Infnite_Coder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hf49e/roadmap_for_mastering_machine_learning_d/",
          "publishedOn": "2023-08-03T20:32:37.000Z",
          "wordCount": 2554,
          "title": "Roadmap for mastering machine learning [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hcw60/d_p_r_advice_for_picking_r_studio_or_spyder/",
          "author": null,
          "description": "Hello ML family, I need some urgent advice for my dissertation. I intend to perform market value price prediction of a footballer in the transfer market and I'm not sure if I should pick R Studio or Python. I'm comfortable with both languages and intend to use any one for model comparison. I'll be comparing an ANN model and SVR for showing which is better and why. I need to know which editor will be faster in the long run since my data will be expanding and so will the analysis overtime. I've heard a lot of complaints about spyder slowing down during execution whereas R Studio is much faster however, deep learning is much better in Python. This is what I've read up, I'm new to both languages but know my way around both just need expert advice on picking one track. Please and Thank you to you all. 🙏\n    submitted by    /u/RaunaqBani  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hcw60/d_p_r_advice_for_picking_r_studio_or_spyder/",
          "publishedOn": "2023-08-03T19:07:52.000Z",
          "wordCount": 2610,
          "title": "[D] [P] [R] Advice for picking R Studio or Spyder",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hctu2/d_embedding_ethical_priors_into_ai_systems_a/",
          "author": null,
          "description": "Abstract\n Artificial Intelligence (AI) systems have significant potential to affect the lives of individuals and societies. As these systems are being increasingly used in decision-making processes, it has become crucial to ensure that they make ethically sound judgments. This paper proposes a novel framework for embedding ethical priors into AI, inspired by the Bayesian approach to machine learning. We propose that ethical assumptions and beliefs can be incorporated as Bayesian priors, shaping the AI’s learning and reasoning process in a similar way to humans’ inborn moral intuitions. This approach, while complex, provides a promising avenue for advancing ethically aligned AI systems.\n ​\n Introduction\n Artificial Intelligence has permeated almost every aspect of our lives, often making de…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hctu2/d_embedding_ethical_priors_into_ai_systems_a/",
          "publishedOn": "2023-08-03T19:05:25.000Z",
          "wordCount": 7813,
          "title": "[D] Embedding Ethical Priors into AI Systems: A Bayesian Approach",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hcl6g/d_rlhf_preference_tuning_how_things_may_go_wrong/",
          "author": null,
          "description": "As ChatGPT's performance takes a slight dip, LLaMA-2 uncensored opens new doors by being fully open-sourced, recent studies unveil \"universal\" adversarial attacks capable of disrupting both open-source language models and RLHF-tuned ones like ChatGPT, Claude, Bard, and co.\n Despite all this, RLHF still stands its ground as the de facto industry-standard approach to aligning LLMs with human preference. Yet as every week slips by, the more we unmask the limitations of RLHF. In fact, there are instances where RLHF seems to deteriorate certain LLM features it pledged to enhance, like hallucinations.\n This field is evolving fast, and there's always more to learn. I took some effort to write a short blog post where I delve into the most recent findings on the shortcomings of RLHF.\n Link in the comments below. Let me know what you think about it!\n Cheers\n    submitted by    /u/mrx-ai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hcl6g/d_rlhf_preference_tuning_how_things_may_go_wrong/",
          "publishedOn": "2023-08-03T18:56:19.000Z",
          "wordCount": 2597,
          "title": "[D] RLHF Preference Tuning: How Things May Go Wrong",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hbnzs/p_epsilla_another_open_source_vector_database/",
          "author": null,
          "description": "Hi everyone!\n I'm excited to share Epsilla, an open-source vector database!\n Under the hood, we implemented the state-of-art ANN index algorithm from the academia (SpeedANN) that leverages intra-query parallel graph traversal, which outperforms HNSW by 5x on high precision query latency on medium size (1M) vector space and outperforms HNSW by 50 times on large-scale vector search.\n In addition, we also made a few design choices on our database interface and architecture based on our previous database experience at TigerGraph, we would love to hear what our users think about these choices\n We just started 3 weeks ago and it's still in the very early stages, we wanted to get your feedback and work together to shape our vector database features. Let us know what you think and what you'd like to see!\n https://github.com/epsilla-cloud/vectordb\n https://epsilla-inc.gitbook.io/epsilladb/quick-start\n https://www.epsilla.com/\n    submitted by    /u/songrenchu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hbnzs/p_epsilla_another_open_source_vector_database/",
          "publishedOn": "2023-08-03T18:20:45.000Z",
          "wordCount": 2592,
          "title": "[P] Epsilla: Another open source vector database",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15hbce9/d_deciding_which_cnn_model_to_go_for_for_image/",
          "author": null,
          "description": "Hello guys.\n I'd like to make an image classifier for the Kaggle landscape dataset (24K images and 34 classes) using transfer learning.\n I'm a little bit limited on resources to train the model so I'd like to have an understanding of which model is the better option for this specific task, however, I'm struggling to find info on that and how to tune hyperparameters given that I've decided on the model architecture.\n So far I've seen people referring to VGG and ResNet models as the better option for image classification tasks on medium sized datasets, but I'd like to see the argumentation behind that too. I've also heard of a practice of training different model candidates for a few epochs and choosing the one that does better (this only shows which model converges faster on the data, correct me if I'm wrong).\n I'd also like to read info on hyperparameter tuning such as batch size, the amount of layers to unfreeze etc. but can't seem to find any explanation that wasn't really surface-level.\n If you know any articles/videos on this topic I'd greatly appreciate you sharing the links.\n TLDR; Need links to articles/videos about choosing the model architecture for transfer learning and tuning hyperparameters for the model.\n    submitted by    /u/Humble_Examination13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15hbce9/d_deciding_which_cnn_model_to_go_for_for_image/",
          "publishedOn": "2023-08-03T18:08:12.000Z",
          "wordCount": 2668,
          "title": "[D] Deciding which CNN model to go for for image classification/object detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15halhn/r_beginners_question/",
          "author": null,
          "description": "Hello There, I am very noob in data science area, but I want learn about it, I want to do a project to detect what type of question have the user, E.g support, information,etc, I understand that I need to train a model, but where do I start?\n    submitted by    /u/Constantine1396  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15halhn/r_beginners_question/",
          "publishedOn": "2023-08-03T17:38:50.000Z",
          "wordCount": 2500,
          "title": "[R] Beginner's question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15h9n68/d_concept_of_dynamic_weights_in_ml/",
          "author": null,
          "description": "Hello all,\n Placing this entry here to see what peoples thoughts on the concept of dynamic weights applied to ML are.\n Ie. Instead of a manual adjustment of the weights via an algorithm such as gradient descent, the weights are freed and have applied motion dynamics to them.\n Thanks for your time, Tyler\n    submitted by    /u/LiveBacteria  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15h9n68/d_concept_of_dynamic_weights_in_ml/",
          "publishedOn": "2023-08-03T17:01:21.000Z",
          "wordCount": 2509,
          "title": "[D] Concept of Dynamic Weights in ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15h99n9/p_pinecone_precision_issues/",
          "author": null,
          "description": "Hello all,\n Currently I'm utilising Pinecone as a vector store database for euclidean and cosine queries.\n We are facing an issue with Pinecone utilising 32 bit single precision when taking in floats.\n This is causing our data input to become skewed.\n Anyone have advice on how to resolve this? Alternative products? Exploring possibly configuring a Redis server to handle higher precision.\n Thanks in advance for your time, Tyler\n    submitted by    /u/LiveBacteria  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15h99n9/p_pinecone_precision_issues/",
          "publishedOn": "2023-08-03T16:46:30.000Z",
          "wordCount": 2521,
          "title": "[P] Pinecone Precision Issues",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15h1xas/project_are_you_interested_in_a_career_using_ml/",
          "author": null,
          "description": "I'm a software engineer who has been looking for a job in AI/ML for some time. Last month I attended the UN's AI For Good Global Summit and discovered an amazing community of like-minded professionals and academics working towards just this.\n Speaking with many others in a similar position I've recently launched aiforgoodjobs.com which curates roles in AI at world leading companies tackling climate change, education, healthcare and many other important impact areas in support of the UN's Global Goals.\n I hope this might be a valuable resource for those looking down a similar path - if you would like hiring managers to reach out to you directly for relevant roles you're warmly invited to join our candidate database\n Any ideas/feedback also very gratefully received!\n    submitted by    /u/aiforgood_jobs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15h1xas/project_are_you_interested_in_a_career_using_ml/",
          "publishedOn": "2023-08-03T11:47:53.000Z",
          "wordCount": 2586,
          "title": "[Project] Are you interested in a career using ML for social impact?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15h186s/p_collab_on_a_web_extension_using_nlp/",
          "author": null,
          "description": "on the lookout for interested teammates to collaborate on a project to do with web extensions and NLP. If you think you can jam to this, or are just starting out, this can be the launchpad you needed.\n    submitted by    /u/drunk3n_s4ilor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15h186s/p_collab_on_a_web_extension_using_nlp/",
          "publishedOn": "2023-08-03T11:13:09.000Z",
          "wordCount": 2495,
          "title": "[P] collab on a web extension using NLP",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15h0pkw/d_where_can_i_publish_my_images_and_time_series/",
          "author": null,
          "description": "Hey there. I have curated huge amount of high quality images for binary classification and also a time series data about it. I made the dataset specifically For some project of mine, and since it's completed right now, I want to make the dataset opensource and also potentially write a short review paper on it kind of to give an idea about data. \n Any particular website/journal I can publish my dataset and paper at? Any idea?\n    submitted by    /u/C0R0NA_CHAN  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15h0pkw/d_where_can_i_publish_my_images_and_time_series/",
          "publishedOn": "2023-08-03T10:46:44.000Z",
          "wordCount": 2536,
          "title": "[D] Where can I publish my images and Time Series dataset?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15gzsfv/d_roadmap_for_ai_engineer_implementation_of/",
          "author": null,
          "description": "I worked for less than a year as a Data Engineer. I decided to look for other challenges and got a job as an AI engineer developing language models.\n The product of the company that hired me is related to data and metadata management. My tasks will be to introduce features to the product, including a chat function that will allow for asking questions about data. Other tasks will include research and proposing additional AI-related functionalities to the product (on premise). I have a two weeks left to start work and I need to prepare a bit. My job will involve implementing ready-made solutions and conducting research (high level - I need to implement valuable features and no one cares how).\n What are the most important things I should learn before starting work?\n First of all, I replicated a few applications from this blog: https://blog.streamlit.io/tag/llms/\n Then I have focused on Langchain. I'm also in the middle of a course on Udemy about Next-Gen AI projects - Beginner friendly - Langchain, Pinecone - OpenAI, HuggingFace & LLAMA 2 models\n I need a roadmap that will guide me a bit. I'm looking for blogs/materials/courses that will give me practical knowledge in this matter.\n    submitted by    /u/International-Shirt5  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15gzsfv/d_roadmap_for_ai_engineer_implementation_of/",
          "publishedOn": "2023-08-03T09:58:30.000Z",
          "wordCount": 2661,
          "title": "[D] Roadmap for AI engineer (implementation of language models on premise)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15gx4jf/p_would_you_like_to_have_a_tool_to_make_eda/",
          "author": null,
          "description": "I’m looking for some input from the ML community.\n I find the exploratory analysis of my data somewhat cumbersome, I was wondering if other people have the same experience and if it is worth developing a tool to make this all work better.\n What tools do you use to do EDA? (Seaborn, Matplotlib, Plotly etc)\n On top of these tools, would you like to have a tool to make EDA more? In a perfect world, what would that look like?\n    submitted by    /u/catnamedred  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15gx4jf/p_would_you_like_to_have_a_tool_to_make_eda/",
          "publishedOn": "2023-08-03T07:25:57.000Z",
          "wordCount": 2541,
          "title": "[P] Would you like to have a tool to make EDA efficiently?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15gumgg/d_stack_exchange_alternatives/",
          "author": null,
          "description": "I assume most people around here are familiar with stackoverflow. Some might also be aware of the cross validated and datascience sites from stack exchange.\n I recently learned about people getting annoyed by how the stack exchange company is treating its communities. Although the latter example might have recently been resolved.\n Because of these problems, I have been looking out for alternative Q&A platforms. I stumbled upon https://codidact.com as a possibly viable alternative, but not many people seem to have found it thus far.\n It already has communities for software, math and [linux](linux.codidact.com) for example, but I am missing a community for ML questions over there. Therefore I wrote a proposal to add a ML community.\n Currently, it seems like I’m one of only few ML people on codidact. I think it would be good if other people would get involved as well. I would also welcome any feedback on how to shape this community. If you’re interested to get a feel for the experience, you could already start asking questions in the incubator Q&A.\n TL;DR: what do you think about building a ML Q&A over on codidact? dual TL;DR: Do you want to play Q&A with me on codidact?\n PS: I didn’t miss out on other new big ML Q&A sites, did I?\n    submitted by    /u/mr_tsjolder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15gumgg/d_stack_exchange_alternatives/",
          "publishedOn": "2023-08-03T05:05:05.000Z",
          "wordCount": 2667,
          "title": "[D] Stack Exchange alternatives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15gongf/d_llama2_and_bertscore/",
          "author": null,
          "description": "I have a couple of questions:\n  \nWhy wasn't BERTScore one of the metrics used to evaluate Llama-2's performance on free-form response based tasks?\n Does anyone think it's worth trying to produce those results?\n  \n   submitted by    /u/cooperbaerseth  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15gongf/d_llama2_and_bertscore/",
          "publishedOn": "2023-08-03T00:15:32.000Z",
          "wordCount": 2486,
          "title": "[D] LLaMa-2 and BERTScore",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15gkwld/p_project_cost_forecasting/",
          "author": null,
          "description": "Hi guys this is my first post.\n I am building my first machine learning model to predict costs of various projects by month. Each row can be identified with a column project name and month (these two are dropped for testing). The rest of the columns are various features that can help predicting the end project cost. \n I want to be able to predict costs on a monthly basis. My question is how should I split the data because each row is a unique project and month. Is it ok to just do a train test split and have earlier project months be in the testing set while having future project months be in the training set? Isn’t that giving the model too much information? \n Or should I train on each project’s indices and leave one project as testing for each project I have? I’m worried about overfitting with that one.\n Thanks in advance for any help!\n    submitted by    /u/Single_Swing_3173  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15gkwld/p_project_cost_forecasting/",
          "publishedOn": "2023-08-02T21:44:08.000Z",
          "wordCount": 2610,
          "title": "[P] Project Cost Forecasting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15gke9y/p_project_cost_forecasting/",
          "author": null,
          "description": "Hi guys this is my first post.\n I am building my first machine learning model to predict costs of various projects by month. Each row can be identified with a column project name and month (these two are dropped for testing). The rest of the columns are various features that can help predicting the end project cost. \n I want to be able to predict costs on a monthly basis. My question is how should I split the data because each row is a unique project and month. Is it ok to just do a train test split and have earlier project months be in the testing set while having future project months be in the training set? Isn’t that giving the model too much information? \n Or should I train on each project’s indices and leave one project as testing for each project I have? I’m worried about overfitting with that one.\n Thanks in advance for any help!\n    submitted by    /u/Single_Swing_3173  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15gke9y/p_project_cost_forecasting/",
          "publishedOn": "2023-08-02T21:00:49.000Z",
          "wordCount": 2610,
          "title": "[P] Project Cost Forecasting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ggw2u/project_help_needed_monte_carlo_policy_gradient/",
          "author": null,
          "description": "I am trying to implement REINFORCE (Monte Carlo Policy Gradient) on flappy bird (flappy-bird-gymnasium) and I am unable to make the ai cross even just 1 pipe.\n I am experiencing a constant avg score throughout all episodes from start to end and no change in policy loss as well (sometimes). I tried a lot of different hyperparameter combinations as well.\n I have checked the policy (neural network) and the algorithm code multiple times and they seem to be fine. I am just not able to determine why the AI isn't learning or is able to cross even a single pipe.\n If someone can help me out, it would be really helpful!\n code - https://github.com/Sookeyy-12/REINFORCE_Projects\n there's also a video of the agent's gameplay in this repo.\n    submitted by    /u/Sookeyy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ggw2u/project_help_needed_monte_carlo_policy_gradient/",
          "publishedOn": "2023-08-02T18:36:03.000Z",
          "wordCount": 2586,
          "title": "[Project] Help needed - Monte carlo policy gradient - reinforce alg on flappy bird",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15gbu7t/d_ijcnlpaacl_2023_paper_reviews/",
          "author": null,
          "description": "The paper reviews for AACL 2023 are out, feel free to share your thoughts and feelings! How did you do?\n    submitted by    /u/Pomhelpme  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15gbu7t/d_ijcnlpaacl_2023_paper_reviews/",
          "publishedOn": "2023-08-02T15:25:47.000Z",
          "wordCount": 2474,
          "title": "[D] IJCNLP-AACL 2023: Paper Reviews",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15g9atl/r_gzip_vs_bagofwords_for_text_classification/",
          "author": null,
          "description": "Hi,\n same as other folks, I was quite curious about the recent GZIP paper presented at ACL 2023, where the authors demonstrate strong text classification performance by using a compression-based distance function in a KNN model.\n However, in the end, I am not sure whether GZIP can fully live up to the hype. I tested a very simple bag-of-words distance and found that it can achieve better results compared with GZIP, while being also faster.\n In a nutshell, I think we can say that:\n  \nYes, KNN (with some sensible distance function) is an interesting approach, particularly for few-shot/low-resource scenarios.\n \nNo, GZIP (even though it's a cool idea) is not a very sensible distance function. Simply using a bag-of-words achieves better results, and is much faster.\n \n Here's my full write-up:\n https://arxiv.org/abs/2307.15002\n [PS: A short comment on the GZIP evaluation issue that has been widely discussed. Indeed, as was also shown in a popular blogpost, the displayed accuracy of GZIP in the original paper is optimistic. Therefore, I show correct/realistic accuracy numbers for all methods that I tested. However, the main point of my note is not to make a SOTA comparison or something, but rather just provide a reminder that bag-of-word is a good method for starters and a strong baseline, and can perform better than more complex GZIP for KNN classification]\n    submitted by    /u/juopitz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15g9atl/r_gzip_vs_bagofwords_for_text_classification/",
          "publishedOn": "2023-08-02T13:43:45.000Z",
          "wordCount": 2677,
          "title": "[R] GZIP vs Bag-of-Words for text classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15g8igy/p_prove_your_identity_directly_via_language_model/",
          "author": null,
          "description": "Hi guys, I built something that you might enjoy. Totally free and open source. Basically it lets you create text that you can prove came from you.\n For example, in my colab demo: https://colab.research.google.com/drive/1764iRR-EFJl43KIKhrb2H0CTcT0b1vQm?authuser=2#scrollTo=qyKud8qtM3vA\n I prove that I generated the text:\n 'The world is constantly changing due to technological advancements, which include the creation of powerful language models and advanced robotics technologies. A Computer Science degree can help one be involved in these changes and apply their knowledge to everyday life, as practical applications of technology.'\n The text is a bit wonky as the generation model is just a small paraphrasing fine-tuned model I pulled off Hugging Face, but it's pretty natural even at this earl…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15g8igy/p_prove_your_identity_directly_via_language_model/",
          "publishedOn": "2023-08-02T13:08:32.000Z",
          "wordCount": 2781,
          "title": "[P] Prove your identity directly via language model output",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15g67nv/d_clustering_an_dataset_of_images_with_openpose/",
          "author": null,
          "description": "Hey everyone!\n I've got a rather large dataset of images, mostly featuring humans in a variety of poses (think along the lines of a collection of people practicing yoga and the like).\n My goal is to cluster these images based on the poses, so I can avoid the tedious task of manually sifting through each one to find all the people doing handstands, splits, and so forth.\n My initial thought was to run OpenPose on all these images, then perform clustering based on the output from OpenPose.\n Does this sound like a feasible approach? Do any of you have better suggestions? Or perhaps there's already an existing software solution that can do this?\n Thanks!\n    submitted by    /u/cyan2k  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15g67nv/d_clustering_an_dataset_of_images_with_openpose/",
          "publishedOn": "2023-08-02T11:19:03.000Z",
          "wordCount": 2571,
          "title": "[D] Clustering an dataset of images with OpenPose",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15g5j9m/news_kornia_v070_release_image_api_rtdetr_and/",
          "author": null,
          "description": "Read the release notes: https://github.com/kornia/kornia/releases/tag/v0.7.0\n --------------------\n Image API In this release we have added a new Image API as placeholder to support a more generic multibackend api. You can export/import from files, numpy and dlapck.\n https://preview.redd.it/0d5tvjxmeofb1.png?width=621&format=png&auto=webp&s=9af05a037770132c9a267b68dcd9ab8182557517\n Object Detection API We have added the ObjectDetector that includes by default the RT-DETR model. The detection pipeline is fully configurable by supplying a pre-processor, a model, and a post-processor. Example usage is shown below\n https://preview.redd.it/rtbayqpneofb1.png?width=680&format=png&auto=webp&s=4d46edeeee4027e08a493cb15182ea0ddc42bc5d\n https://preview.redd.it/ukcg9enoeofb1.png?width=680&format=png&a…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15g5j9m/news_kornia_v070_release_image_api_rtdetr_and/",
          "publishedOn": "2023-08-02T10:45:03.000Z",
          "wordCount": 2660,
          "title": "[News] Kornia v0.7.0 release: Image API, RT-DETR and Object Detection API, LightGlue Matcher, MobileSam, new Sensors API and many more.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15g2weg/d_pose_estimation_over_mid_range/",
          "author": null,
          "description": "I have been testing OpenFace with some telescope lenses (focal length 8-16mm) to test the performance of the pose estimation at mid range (2-4 meters). I have been passing the camera and lens intrinsics to OpenFace but have been finding that the pose estimation has not been great. Does anyone with more ML experience know at what point in the OpenFace pipeline the issues could be coming from? e.g. the point distribution model or the training data \n    submitted by    /u/DoPe-_-SoaP  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15g2weg/d_pose_estimation_over_mid_range/",
          "publishedOn": "2023-08-02T08:18:47.000Z",
          "wordCount": 2532,
          "title": "[D] Pose Estimation over Mid Range",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15g0hzq/r_model_to_refine_a_binary_segmentation_mask/",
          "author": null,
          "description": "Hi, this is my first time posting here. My goal is to check if optical flow can improve a pretrained model's performance.\n The pretrained model: gives an output as a binary mask for the object its trying to detect.\n The optical flow: is the motion of pixels between frames, this model also gives an image shaped flow vector.\n I want to combine the mask by pretrained model and optical flow information and send it to another model to improve its performance.\n For the model: I can use U-net or a simple convolution encoder-decoder model, but I am confused about which will be the best model architecture for it.\n ​\n    submitted by    /u/luxuryBubbleGum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15g0hzq/r_model_to_refine_a_binary_segmentation_mask/",
          "publishedOn": "2023-08-02T06:01:37.000Z",
          "wordCount": 2567,
          "title": "[R] Model to refine a binary segmentation mask using optical flow.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15fy5nk/d_are_there_any_free_llm_gpts_that_i_can_access/",
          "author": null,
          "description": "I am trying to develop some app ideas based on LLM (i.e., summarize and extract entities from articles), but I can't afford any paid API access right now (including OpenAI), are there free alternatives to it?\n    submitted by    /u/Guyserbun007  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15fy5nk/d_are_there_any_free_llm_gpts_that_i_can_access/",
          "publishedOn": "2023-08-02T03:59:20.000Z",
          "wordCount": 2498,
          "title": "[D] Are there any free LLM GPTs that I can access via API?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15fwu6v/d_how_to_testfinetune_a_model_using_a_new_data/",
          "author": null,
          "description": "Hi,\n ​\n I want to use a new data representation instead of float for fine-tuning/testing a model (e.g., DNN) in Pytorch. The basic operations (add/sub/multiply/division) in my data type is different from floating point. My question is if it is possible to implement these operations (+,-,*,/) and force all of functions in Pytorch (e.g., torch.add(), torch.sum(), torch.nn.Linear(), conv2d, etc.) to use my basic arithmetic implementation? If so, could you please guide me how can I do it?\n Because I think otherwise it takes so much time and effort; first, I have to find which functions my model calls (which I dont know how to do it) and, then, I have to replace them one by one. This becomes complicated for a large model.\n I found this link from Pytorch that shows how to extend pytorch. But it seems that it is not comprehensive enough to answer my question.\n ​\n Thank you very much!\n    submitted by    /u/Impossible-Froyo3412  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15fwu6v/d_how_to_testfinetune_a_model_using_a_new_data/",
          "publishedOn": "2023-08-02T02:53:40.000Z",
          "wordCount": 2624,
          "title": "[D] How to test/fine-tune a model using a new data type that has different arithmetics for basic operations (+,-,/,*) compared to float in Pytorch?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ft07b/discussion_supervised_finetuning_vs_prompt/",
          "author": null,
          "description": "Hello all,\n ​\n I am delving into the exciting realm of GenAI and LLMs. I have a few questions I hope you can help me with:\n ​\n  \nWhen should I opt for supervised fine-tuning rather than prompt engineering with retrieval? \n \nWhat are the associated costs of supervised fine-tuning?\n \nHow many high-quality observations are typically required for successful supervised fine-tuning?\n \nWhat are the frameworks and computional requirements usually involved in supervised fine-tuning, and how can I implement them in code? any tutorials available?\n \nCan the model adapt and learn new jargon or specific tasks that might not be extensively covered during the pre-training phase?\n \n ​\n I understand that a combination of supervised fine-tuning and reinforcement learning, with human feedback through a reward model, is considered the best approach. However, given that the latter method can be costly and falls under the domain of heavy research, it is probably less feasible for medium-sized organizations.\n    submitted by    /u/quilograma  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ft07b/discussion_supervised_finetuning_vs_prompt/",
          "publishedOn": "2023-08-01T23:56:33.000Z",
          "wordCount": 2604,
          "title": "[Discussion] Supervised fine-tuning vs Prompt Engineering with retrieval for LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15fqcig/d_predicting_domain_mapping_difficulty/",
          "author": null,
          "description": "I went down this rabbit hole of trying to understand when domain mapping approaches like stargan or mind the gap succeed and fail. For example, it should be easy to map males (source domain) with large eyes and brown hair onto females (target domain) with analogous eye and hair color. It should be relatively harder to map different car models onto images taken of one German Shepard dog at different ages. this makes intuitive sense and the terms “domain misalignment “ and “large domain shift“ come to mind, but i cannot find an in-depth discussion of this topic. Any thoughts?\n    submitted by    /u/Rotfisch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15fqcig/d_predicting_domain_mapping_difficulty/",
          "publishedOn": "2023-08-01T22:04:42.000Z",
          "wordCount": 2550,
          "title": "[D] predicting domain mapping difficulty",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15fo7td/d_neurips_2023_paper_reviews/",
          "author": null,
          "description": "NeurIPS 2023 paper reviews are visible on OpenReview. See this tweet. I thought to create a discussion thread for us to discuss any issue/complain/celebration or anything else.\n There is so much noise in the reviews every year. Some good work that the authors are proud of might get a low score because of the noisy system, given that NeurIPS is growing so large these years. We should keep in mind that the work is still valuable no matter what the score is.\n    submitted by    /u/zy415  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15fo7td/d_neurips_2023_paper_reviews/",
          "publishedOn": "2023-08-01T20:44:02.000Z",
          "wordCount": 2532,
          "title": "[D] NeurIPS 2023 Paper Reviews",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15fm55d/r_toolllm_facilitating_large_language_models_to/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2307.16789 \n Github: https://github.com/OpenBMB/ToolBench \n Abstract:\n  \nDespite the advancements of open-source large language models (LLMs) and their variants, e.g., LLaMA and Vicuna, they remain significantly limited in performing higher-level tasks, such as following human instructions to use external tools (APIs). This is because current instruction tuning largely focuses on basic language tasks instead of the tool-use domain. This is in contrast to state-of-the-art (SOTA) LLMs, e.g., ChatGPT, which have demonstrated excellent tool-use capabilities but are unfortunately closed source. To facilitate tool-use capabilities within open-source LLMs, we introduce ToolLLM, a general tool-use framework of data construction, model training and evaluation. We first …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15fm55d/r_toolllm_facilitating_large_language_models_to/",
          "publishedOn": "2023-08-01T19:25:47.000Z",
          "wordCount": 2742,
          "title": "[R] ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs - WeChat AI, Tencent Inc. 2023 - Open-source! Comparble performance to ChatGPT while using tools!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15flq9u/p_vkfft_version_13_released_major_design_and/",
          "author": null,
          "description": "Hello, I am the creator of the VkFFT - GPU Fast Fourier Transform library for Vulkan/CUDA/HIP/OpenCL/Level Zero and Metal. FFTs are used by many algorithms, not only for signal processing. For example, you can efficiently calculate convolutions with them, which has applications in CNNs and feature generation. I used to post on the latest features implemented in the codebase and there has been a major update released today. It brings:\n -Major library design change - from single header to multiple header approach, which improves structure and maintainability. Now instead of copying a single file, the user has to copy the vkFFT folder contents.\n -VkFFT has been rewritten to follow the multiple-level platform structure, described in the VkFFT whitepaper. All algorithms have been split into res…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15flq9u/p_vkfft_version_13_released_major_design_and/",
          "publishedOn": "2023-08-01T19:10:09.000Z",
          "wordCount": 2805,
          "title": "[P] - VkFFT version 1.3 released - major design and functionality improvements",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15fljq3/p_dorars_experimental_ros2_alternative_up_to_17x/",
          "author": null,
          "description": "https://github.com/dora-rs/dora\n    submitted by    /u/haixuanxaviertao  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15fljq3/p_dorars_experimental_ros2_alternative_up_to_17x/",
          "publishedOn": "2023-08-01T19:03:20.000Z",
          "wordCount": 2465,
          "title": "[P] dora-rs: experimental ROS2 alternative up to 17x faster for Python API, making more robotics accessible for AI users",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15fkmvj/d_reinforcement_learning_from_ai_feedback/",
          "author": null,
          "description": "Hey everyone,\n As many of you probably know Reinforcement Learning from Human Feedback (RLHF) was the core technique used to produce ChatGPT and similar AI assistants that followed. RLHF replaces human feedback in an RL schema with a preference model that is trained according to a dataset of human preferences.\n Anthropic has devised an extension of this idea in which an AI model (rather than humans) is used to generate the data which ultimately trains the preference model. This method, called Reinforcement Learning from AI Feedback uses a \"constitution\" to guide the feedback model in terms of what outputs are preferable to others.\n I go over the research in How Reinforcement Learning from AI Feedback Works. In short, the authors find that they are able to train a non-evasive harmless agent using a short constitution. The method is found to be superior to RLHF, and constitutes a Pareto improvement over RLHF models.\n https://preview.redd.it/qaivl8f1ljfb1.png?width=1179&format=png&auto=webp&s=a0941f2ce0ccdcf0557cf19b7f4b48fa712a66f2\n Let me know what you think, I'm happy to answer any questions!\n    submitted by    /u/SleekEagle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15fkmvj/d_reinforcement_learning_from_ai_feedback/",
          "publishedOn": "2023-08-01T18:29:16.000Z",
          "wordCount": 2615,
          "title": "[D] Reinforcement Learning from AI Feedback",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15fgfr3/r_any_ml_professionals_mind_helping_out_with_an/",
          "author": null,
          "description": "Hi there,\n First off, apologies if this kind of post isn't allowed. I tried messaging the mods in advance, but didn't get a reply. Of course feel free to delete if it's not.\n I'm an academic at the University of Cambridge's Computer Lab, and I'm looking to get some insights from people that work with algorithmic systems (e.g. ML systems) in a professional capacity. \n The aim of the research is to document some of the approaches, attitudes, and challenges associated with record-keeping for these types of systems, and write them up for an academic conference.\n If you're a professional working with algorithmic/ML systems, and happen to have a spare ~20 minutes, would you mind answering some questions? The link to the questionnaire is here: https://cambridge.eu.qualtrics.com/jfe/form/SV_3n6RuowNogZKG34\n Thanks very much! I'd be more than happy to come back and share the results/paper here if that's of interest to people?\n    submitted by    /u/cnorval  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15fgfr3/r_any_ml_professionals_mind_helping_out_with_an/",
          "publishedOn": "2023-08-01T15:53:02.000Z",
          "wordCount": 2603,
          "title": "[R] Any ML professionals mind helping out with an academic survey?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15fcymz/project_gzipknn_official_package_released/",
          "author": null,
          "description": "The official python package for the \"'Low-Resource' Text Classification: A Parameter-Free Classification Method with Compressors\" has now been released on pypi: npc-gzip v0.1.0\n  \nAbstract: Deep neural networks (DNNs) are often used for text classification due to their high accuracy. However, DNNs can be computationally intensive, requiring millions of parameters and large amounts of labeled data, which can make them expensive to use, to optimize, and to transfer to out-of-distribution (OOD) cases in practice. In this paper, we propose a non-parametric alternative to DNNs that’s easy, lightweight, and universal in text classification: a combination of a simple compressor like gzip with a k-nearest-neighbor classifier. Without any training parameters, our method achieves results that are competitive with non-pretrained deep learning methods on six in-distribution datasets.It even outperforms BERT on all five OOD datasets, including four low-resource languages. Our method also excels in the few-shot setting, where labeled data are too scarce to train DNNs effectively.\n  \nThis paper has made some waves on this subreddit and in the community in general over the last 2 weeks. We've seen the bugs around training/testing data leakages and varying claims in accuracy. Our hope with this package is to get the code into everyone's hands first to solve whatever use case you currently have for this technology and second to make the code more readily available for additional community testing.\n Links: * https://pypi.org/project/npc-gzip/ * https://github.com/bazingagin/npc_gzip * https://aclanthology.org/2023.findings-acl.426/\n    submitted by    /u/dfcHeadChair  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15fcymz/project_gzipknn_official_package_released/",
          "publishedOn": "2023-08-01T13:41:29.000Z",
          "wordCount": 2678,
          "title": "[Project] GZip+KNN Official Package Released",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15f56ve/d_google_updates_attention_is_all_you_need_paper/",
          "author": null,
          "description": "submitted by    /u/Jean-Porte  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15f56ve/d_google_updates_attention_is_all_you_need_paper/",
          "publishedOn": "2023-08-01T07:19:54.000Z",
          "wordCount": 2460,
          "title": "[D] Google updates \"Attention is all you need\" paper with a warning + crossed authors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15f08ss/r_probabilistic_imputation_for_timeseries/",
          "author": null,
          "description": "This is one of the ICML 2023 papers I focused in on in a sea of LLM stuff. Trying to figure out simple ways to implement this and adapt it to regression problems. Thoughts?\n    submitted by    /u/quantthrowaway69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15f08ss/r_probabilistic_imputation_for_timeseries/",
          "publishedOn": "2023-08-01T02:56:12.000Z",
          "wordCount": 2501,
          "title": "[R] Probabilistic Imputation for Time-series Classification with Missing Data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15extok/p_videototext_model_descriptive_style_not/",
          "author": null,
          "description": "I was wondering if there's already something like CLIP (the model that looks at an image and describes it), but for videos. So you show a video of, say, a dog jumping and grabbing a tennis ball and it outputs \"dog grabbing a tennis ball\", something like that.\n My first thought was object detection, and input that interaction of the objects (tennis ball, dog) to the model with the target being \"dog grabbing tennis ball\". My ultimate goal being real-time description for, say, sports casting. I'm sure something like this is what cars use to drive themselves, or not? Any info is appreciated!\n    submitted by    /u/Yip37  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15extok/p_videototext_model_descriptive_style_not/",
          "publishedOn": "2023-08-01T01:02:49.000Z",
          "wordCount": 2555,
          "title": "[P] Video-to-Text model descriptive style (not subtitles)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15eschg/llm_models_for_interpreting_tables_and_charts_d/",
          "author": null,
          "description": "Hi all,\n Curious if anyone has recommendations on models to use to interpret the data in tables? I'm playing around with Google's Matcha model, which performs fine. seems like extracting the data out of a table and asking GPT4 to analyze it performs a bit better but requires extra steps.\n I'm specifically not looking to interpret graphs, but rather tables. e.g., can i ask the model to identify if there are any errors in the table / any data points that don't tie if the rows are supposed to sum up.\n    submitted by    /u/eyeronthrone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15eschg/llm_models_for_interpreting_tables_and_charts_d/",
          "publishedOn": "2023-07-31T21:16:12.000Z",
          "wordCount": 2544,
          "title": "LLM models for interpreting tables and charts [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15er6it/n_conference_codes/",
          "author": null,
          "description": "I'll likely be downvoted to hell but here goes: Prices for The AI Conference double at midnight Pacific.\n 46 Speakers, 10+ topics, 2 Days plus a hackathon at night! Join us to learn and collaborate with scientists, engineers and founders from the top AI companies and projects. Speakers include:\n Ben Mann | Co-Founder | Anthropic\n Peter Norvig | Director of Research | Google\n Nazneen Rajani | Research Lead | Hugging Face\n Igor Markov | Research Scientist | Meta\n Bryan Catanzaro | VP Of Research | Nvidia\n Ram Sriharsha | VP of Engineering and R&D | Pinecone\n Jerry Liu | Co-founder | LlamaIndex\n Harrison Chase | Co-founder | LangChain\n Alex Chao | Product Manager Semantic Kernel | Microsoft\n See All Speakers\n Last chance to get in on early bird pricing (save $400 on a 2 day pass). If you can read this and I'm not downvoted to hell, use discount code redditlove for 25% off.\n Use discount code \"student\" for $200 student tickets \\*Must Use EDU email to register*\n **This is my event and therefore self-promotion\n ​\n ​\n    submitted by    /u/shonburton  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15er6it/n_conference_codes/",
          "publishedOn": "2023-07-31T20:31:25.000Z",
          "wordCount": 2615,
          "title": "[N] Conference Codes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ep5ff/d_where_did_all_the_ml_research_go/",
          "author": null,
          "description": "For the past several years this subreddit has been my favorite source to keep up with new, interesting ideas and research from all over the field. It's great to have a way to break out of my own insular research bubble and spread out a bit more. Unfortunately, it looks like that era has passed.\n The sub has been seemingly shifting away from research in the past 1-2 years. Whenever research is posted, it is almost always LLM based with very little variety (considering the plethora of research areas in ML). I don't mean to assert that this is a bad thing, as the constant upvotes indicate that there is a high demand for LLM projects and research. Heck, I'm also interested in lots of the recent work with LLMs, and I plan to keep up with it – but I also would also love a venue with a diversity of ideas and topics. Machine learning is a HUGE field, and only focusing on a small subset of it seems like a waste.\n I don't mean to rant, but rather to ask: are there any other subreddits like this, or perhaps, any other active communities with a broader scope?\n Or if this doesn't exist, is there a demand for it? Or is it just me?\n    submitted by    /u/ejmejm1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ep5ff/d_where_did_all_the_ml_research_go/",
          "publishedOn": "2023-07-31T19:14:01.000Z",
          "wordCount": 2668,
          "title": "[D] Where did all the ML research go?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15eod44/d_elasticsearch_hnsw_python_implementation/",
          "author": null,
          "description": "Is there any documentation available which will help in implementing elasticsearch HNSW ANN search in python? I've searched a lot but i cant find anything in official documentation too Any help will be appreciated. TIA\n    submitted by    /u/adiraat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15eod44/d_elasticsearch_hnsw_python_implementation/",
          "publishedOn": "2023-07-31T18:44:53.000Z",
          "wordCount": 2485,
          "title": "[D] elasticsearch HNSW python implementation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15emyyq/why_cuda_117_can_more_recent_versions_of_cuda_be/",
          "author": null,
          "description": "Everyone always seems to use CUDA 11.7. Is there a reason for this? What is the factor that limits the CUDA version used? Are there any speed/efficiency advantages to using a more recent version of CUDA, such as CUDA 12.0?\n What exactly is the limiting factor here, PyTorch? I've looked in the PyTorch docs but I don't see where the CUDA version is defined. Where can I find the maximum CUDA version I can use with the latest (or any given) PyTorch version?\n Thanks!\n    submitted by    /u/Pan000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15emyyq/why_cuda_117_can_more_recent_versions_of_cuda_be/",
          "publishedOn": "2023-07-31T17:50:40.000Z",
          "wordCount": 2546,
          "title": "Why CUDA 11.7? Can more recent versions of CUDA be used? Is this a PyTorch limitation? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ek21a/d_model_design_for_outputting_reliable_multiclass/",
          "author": null,
          "description": "Hey guys, I am working on a horse racing model to identify the probabilities of each horse winning a race. I currently have a feed forward NN with a final SOFTMAX layer to simulate probabilities of each horse winning using cross-entropy loss. My plan here being that if the model outputs, [0.05, 0.4, 0.2, 0.15, 0.2] then horses 1-5 have the corresponding probability of winning. The model has been trained like a regular classification task where the target is a one-hot vector describing the winner.\n Unlike previous work I have done where SOFTMAX output lends itself to some \"confidence\" score, this task requires that the model outputs be indicative of probabilities. My concern is that experientially, NNs tend to be overconfident with their answers in this type of setting. However, I wish to keep using a NN as each race datapoint has around 3k features - did not find good results with XGBoost. Any good practices for modelling probabilities in this sort of scenario? For context, the probability of a horse winning is what sets the odds for that horse.\n    submitted by    /u/HStuart18  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ek21a/d_model_design_for_outputting_reliable_multiclass/",
          "publishedOn": "2023-07-31T15:58:24.000Z",
          "wordCount": 2633,
          "title": "[D] Model design for outputting reliable multiclass probabilities",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ehtyw/d_running_free_willy_stable_baluga_2/",
          "author": null,
          "description": "I was wondering if anyone knows how difficult it is to set up a server to run the 70B llama / llama 2 variants like these top ones on the hugging face leaderboard\n https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\n What type of gpu would I need to set it up? Would the high ram t4 you get with Google colab+ be enough or does it require more power / space? \n Thanks in advance!\n    submitted by    /u/Additional_Elk4745  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ehtyw/d_running_free_willy_stable_baluga_2/",
          "publishedOn": "2023-07-31T14:32:04.000Z",
          "wordCount": 2521,
          "title": "[D] Running Free Willy / stable baluga 2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ehhyu/r_attention_over_pretrained_sentence_embeddings/",
          "author": null,
          "description": "Article available here: https://arxiv.org/pdf/2307.09084.pdf\n Thoughts?\n    submitted by    /u/MuffinB0y  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ehhyu/r_attention_over_pretrained_sentence_embeddings/",
          "publishedOn": "2023-07-31T14:19:04.000Z",
          "wordCount": 2460,
          "title": "[R] Attention over pre-trained Sentence Embeddings for Long Document Classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15eeinh/p_apple_fruit_x_combine_queries_and_explore_clip/",
          "author": null,
          "description": "Hi. I've shipped an update to my rclip – a command-line photo search tool powered by CLIP.\n Now, you can add and subtract image and text queries from each other; here are a few usage examples:  cd photos && rclip horse + stripes cd photos && rclip apple - fruit cd photos && rclip \"./new york city.jpg\" + night cd photos && rclip \"2:golden retriever\" + \"./swimming pool.jpg\" cd photos && rclip \"./racing car.jpg\" - \"2:sports car\" + \"2:snow\" \n If you want to see how these queries perform when executed on the 1.28 million images ImageNet-1k dataset, check out the demo on YouTube: https://www.youtube.com/watch?v=MsTgYdOpgcQ.\n rclip source code is published on GitHub under the MIT license and offers a pre-build distributable for Linux (installation instructions are in the README): https://github.com/yurijmikhalevich/rclip. Give it a try and let me know what you think!\n    submitted by    /u/39dotyt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15eeinh/p_apple_fruit_x_combine_queries_and_explore_clip/",
          "publishedOn": "2023-07-31T12:13:56.000Z",
          "wordCount": 2600,
          "title": "[P] Apple - Fruit = X? Combine Queries and Explore CLIP Embedding Space With rclip",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15e7b1f/d_open_source_model_combination_to_turn_images_llm/",
          "author": null,
          "description": "Im trying to research into open source text models [like Llama] and image models [like Stable Diffusion].\n My goal is to give the model(s) a picture of birds and bees, then ask it to \"circle\" the bees. The idea is, when given an image, it would produce coordinates on that image where the line should be circled. It could also represent where it should \"click\" on all the bees.\n Does something like this exist?\n    submitted by    /u/MindWithEase  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15e7b1f/d_open_source_model_combination_to_turn_images_llm/",
          "publishedOn": "2023-07-31T05:42:39.000Z",
          "wordCount": 2529,
          "title": "[D] Open Source Model Combination To Turn Images -> LLM?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15e2n5j/open_problems_and_fundamental_limitations_of/",
          "author": null,
          "description": "submitted by    /u/Working_Ideal3808  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15e2n5j/open_problems_and_fundamental_limitations_of/",
          "publishedOn": "2023-07-31T01:34:00.000Z",
          "wordCount": 2468,
          "title": "Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15e29jd/p_pair_programming_my_website_with_an_ai_developer/",
          "author": null,
          "description": "submitted by    /u/williamsweep  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15e29jd/p_pair_programming_my_website_with_an_ai_developer/",
          "publishedOn": "2023-07-31T01:16:00.000Z",
          "wordCount": 2452,
          "title": "[P] Pair programming my website with an AI developer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15e0750/r_towards_robust_production_machine_learning_for/",
          "author": null,
          "description": "Could you please help us get more responses for this study?\n As part of my PhD research project at Applied Artificial Intelligence Institute of Deakin University, we are investigating the challenges that software engineers face when working with machine learning (ML) models in production. Moreover, we explore how to enhance our proposed solution to better meet the needs of these engineers.\n ​\n The objective of this study is to pinpoint the areas where software engineers need more support and resources to effectively work with ML components in production. It also aims to evaluate the effectiveness of a proposed protocol to improve software engineers' productivity and enable them to work more effectively with ML components in production environments.\n ​\n With the knowledge gained from this i…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15e0750/r_towards_robust_production_machine_learning_for/",
          "publishedOn": "2023-07-30T23:40:18.000Z",
          "wordCount": 2738,
          "title": "[R] Towards robust production machine learning for software systems - Survey",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15dzl3x/d_number_of_epochs_for_a_bert_based_model/",
          "author": null,
          "description": "Hello everyone. I am trying to replace the GloVe embeddings based model outlined in this paper by BERT embeddings. The authors of the paper have trained their model for 250 epochs, which for what I am doing is not feasible. I was wondering what would be the recommended number of epochs I should run the BERT model for? I know it is a pretty open ended question, but I was looking to get the community's view on how much epochs should a BERT based model be trained for. Any information will be much appreciated.\n    submitted by    /u/nocturnal_1_1995  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15dzl3x/d_number_of_epochs_for_a_bert_based_model/",
          "publishedOn": "2023-07-30T23:13:00.000Z",
          "wordCount": 2576,
          "title": "[D] Number of epochs for a BERT based model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15du7ql/n_ai_usage_fees_up_to_15x_cheaper_for_english/",
          "author": null,
          "description": "submitted by    /u/geekinchief  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15du7ql/n_ai_usage_fees_up_to_15x_cheaper_for_english/",
          "publishedOn": "2023-07-30T19:35:42.000Z",
          "wordCount": 2497,
          "title": "[N] AI Usage Fees Up to 15x Cheaper for English Than Other Languages",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15dsuhn/d_alternatives_to_hf_or_a_path_forward_for_the/",
          "author": null,
          "description": "I think it’s clear that Hugging Face is not aligned to the OSS community any more and it’s only going to get worse over the next few years. What are the top alternatives or where should the OSS contributors go? \n I’m trying to think ahead to what libraries we should rely on and contribute to. Anyone else have this as a worry?\n https://twitter.com/untitled01ipynb/status/1685667451197878272\n    submitted by    /u/homunculAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15dsuhn/d_alternatives_to_hf_or_a_path_forward_for_the/",
          "publishedOn": "2023-07-30T18:38:33.000Z",
          "wordCount": 2548,
          "title": "[D] Alternatives to HF or a path forward for the OSS community?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15dsjp3/r_compressing_visionlanguage_and_unimodal/",
          "author": null,
          "description": "🚀 Code: https://github.com/sdc17/UPop\n 📑 Paper: https://proceedings.mlr.press/v202/shi23e/shi23e.pdf\n 🧐 A Quick Look\n  \nWhat is it: UPop is the first structured pruning framework for vision-language Transformers. It enables effective structured pruning on various multi-modal & uni-modal tasks (including Visual Reasoning, Image Captioning, Visual Question Answer, Image-Text Retrieval, Text-Image Retrieval, Image Classification and Image Segmentation), datasets (including NLVR2, COCO Caption, VQAv2, COCO, Flickr30K, ImageNet and ADE20K), and model architectures (including BLIP, CLIP, DeiT and Segmenter).\n  \nhttps://preview.redd.it/gfbjnxjm95fb1.png?width=2145&format=png&auto=webp&s=108898690f66a1f0afa068b69487859213055928\n  \nWhat challenge does it tackle: The above figure demonstrates that Unified Search adopted by UPop rescues us from the burden of repeated experiments (e.g., doing grid search) for searching optimal compression ratios among different modalities and structures. Furthermore, Progressive Pruning adopted by UPop eliminates the weight gap between the searched model and the pruned subnet to be retrained, therefore gaining better convergence and performance, especially at high compression ratios.\n How about the performance: On multimodal tasks, for example, UPop can achieve 2x compression with only 1.2% and 2.0% accuracy loss on the VQAv2 dataset for Visual Question Answer and the NLVR2 dataset for Visual Reasoning, respectively. On unimodal tasks, for example, UPop can achieve 1.5x and 1.2x compression without any loss of accuracy on the ImageNet dataset for Image Classification and the ADE20K dataset for Image Segmentation, respectively. Some examples of vector-level structured granularity are as follows.\n  \nhttps://preview.redd.it/lifz1n1ia5fb1.png?width=1187&format=png&auto=webp&s=f419d9c5fb4d80a2a564198eba356021e1c275e4\n    submitted by    /u/Salty-Situation2606  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15dsjp3/r_compressing_visionlanguage_and_unimodal/",
          "publishedOn": "2023-07-30T18:26:03.000Z",
          "wordCount": 2700,
          "title": "[R] Compressing vision-language and unimodal Transformers via structured pruning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15dsinj/p_hiring_high_paying_ml_jobs/",
          "author": null,
          "description": "​\n  \n Title Company Location URL \n  \n Senior Software Engineer (Backend) Nova Credit Remote https://pycareer.io/jobs/6816 \n  Data Scientist - Delivery, Senior-Staff Instacart Not Specified https://pycareer.io/jobs/6773 \n  Data Scientist Data Scientist United States https://pycareer.io/jobs/6780 \n  Senior Data Scientist (NLP and Classification Expert) › Senior Data Scientist (NLP and Classification Expert) › Not Specified https://pycareer.io/jobs/6781 \n  Senior Software Engineer (Backend) Senior Software Engineer (Backend) United States https://pycareer.io/jobs/6788 \n  AWS Data Engineer Apply Not Specified United States https://pycareer.io/jobs/6801 \n  Senior Data Engineer Manager Apply Not Specified United States https://pycareer.io/jobs/6802 \n  Data Scientist – Delivery, Senior-Staff Instacart Instacart Remote https://pycareer.io/jobs/6805 \n  Software Design Engineer – NET, Python – Citizen/GC (H) Not Specified Remote https://pycareer.io/jobs/6837 \n  Senior Data Scientist at Getty Images Getty Images Remote https://pycareer.io/jobs/6839 \n  Lead Data Scientist at General Mills General Mills Remote https://pycareer.io/jobs/6840 \n  Data Scientist – Delivery, Senior-Staff at Instacart Instacart Remote https://pycareer.io/jobs/6842 \n \n ​\n    submitted by    /u/tadasg6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15dsinj/p_hiring_high_paying_ml_jobs/",
          "publishedOn": "2023-07-30T18:24:53.000Z",
          "wordCount": 2608,
          "title": "[P] [HIRING] High Paying ML Jobs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ds07h/p_prompttools_open_source_tools_for_language/",
          "author": null,
          "description": "submitted by    /u/hegel-ai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ds07h/p_prompttools_open_source_tools_for_language/",
          "publishedOn": "2023-07-30T18:03:09.000Z",
          "wordCount": 2493,
          "title": "[P] PromptTools: Open source tools for language model evaluation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15drnzi/r_if_you_have_to_do_a_ml_project_for_prediction/",
          "author": null,
          "description": "For a master thesis I want to write a ML model (and hopefully make my own contribution)\n and I plan to use macroeconomic data. I could predict the typical inflation, GDP, unemployment, but\n are there any other factors that are important. Could you give me some ideas. Thanks! \n    submitted by    /u/AnyJello605  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15drnzi/r_if_you_have_to_do_a_ml_project_for_prediction/",
          "publishedOn": "2023-07-30T17:49:11.000Z",
          "wordCount": 2539,
          "title": "[R] If you have to do a ML project for prediction macroeconomic factors which factor would you choose",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15drj12/d_can_artificial_intelligence_solve_the_problem/",
          "author": null,
          "description": "submitted by    /u/Muinonan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15drj12/d_can_artificial_intelligence_solve_the_problem/",
          "publishedOn": "2023-07-30T17:43:39.000Z",
          "wordCount": 2500,
          "title": "[D] Can artificial intelligence solve the problem of crop diseases — and help curb global hunger?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15dpxec/d_interesting_realworld_applications_for/",
          "author": null,
          "description": "Everyone is going crazy creating LORAs and fine-tuning huge LLMs, however I've seen many suggesting that models such as T5 from Google has its place in the enterprise. Have you guys used this or similarly small models for any novel real world problems? Please do share!\n    submitted by    /u/MonkeyMaster64  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15dpxec/d_interesting_realworld_applications_for/",
          "publishedOn": "2023-07-30T16:35:41.000Z",
          "wordCount": 2529,
          "title": "[D] Interesting real-world applications for fine-tuning T5, and similar models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15dnok8/d_simple_questions_thread/",
          "author": null,
          "description": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n Thread will stay alive until next one so keep posting after the date in the title.\n Thanks to everyone for answering questions in the previous thread!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15dnok8/d_simple_questions_thread/",
          "publishedOn": "2023-07-30T15:00:19.000Z",
          "wordCount": 2526,
          "title": "[D] Simple Questions Thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15djz60/p_deep_dive_and_experiments_for_the_nn_gzip/",
          "author": null,
          "description": "submitted by    /u/seraschka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15djz60/p_deep_dive_and_experiments_for_the_nn_gzip/",
          "publishedOn": "2023-07-30T12:04:51.000Z",
          "wordCount": 2497,
          "title": "[P] Deep Dive and Experiments for the NN + Gzip Method vs LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15dfx0q/r_nenv_neural_environment_maps_for_global/",
          "author": null,
          "description": "submitted by    /u/crp1994  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15dfx0q/r_nenv_neural_environment_maps_for_global/",
          "publishedOn": "2023-07-30T08:03:10.000Z",
          "wordCount": 2490,
          "title": "[R] NEnv: Neural Environment Maps for Global Illumination",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15d86pd/d_how_to_generate_masks_for_overlapping_classes/",
          "author": null,
          "description": "Hi I am new to computer vision, I am working on a particular hackathon challenge, where the input labels are in COCO format. I am using the following code to generate masks,\n cat_ids = coco.getCatIds() anns_ids = coco.getAnnIds(imgIds=img['id'], catIds=cat_ids, iscrowd=None) anns = coco.loadAnns(anns_ids) anns_img = np.zeros((img['height'],img['width'])) for ann in anns: anns_img = np.maximum(anns_img,coco.annToMask(ann)*ann['category_id']) \n But the image has overlapping labels for some pixels, and this masking will only assign one label for such pixel, resulting in information loss, each there any way to prevent this and preserve the information?\n    submitted by    /u/franticpizzaeater  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15d86pd/d_how_to_generate_masks_for_overlapping_classes/",
          "publishedOn": "2023-07-30T01:02:50.000Z",
          "wordCount": 2581,
          "title": "[D] How to generate masks for overlapping classes to COCO format labels, to be used in transformer models like Segformer.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15d77nn/discussion_what_should_i_do/",
          "author": null,
          "description": "Hi, y’all. \n So, I completed my masters degree. Got a programming job. I’m amazed at the capabilities of machine learning and want to build my own models. I don’t really want to go and get another degree, but want to learn how to build models. I’m particularly interested in forecasting because my job deals with NASA and wind data. I’m wondering if we could predict 6 hour wind data with a balloon sounding. \n I know c++ and python. How do I stay relevant to the changing technology space and learn how to build some cool stuff that may be useful? \n Thanks for any advice.\n    submitted by    /u/corey4005  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15d77nn/discussion_what_should_i_do/",
          "publishedOn": "2023-07-30T00:16:45.000Z",
          "wordCount": 2582,
          "title": "[Discussion] what should I do?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15d729w/d_calculate_w_and_b_in_hard_margin_svm/",
          "author": null,
          "description": "Hello everyone,\n I have been asked the following question related to SVM (Hard Margin) in the exam, and I failed to answer it. Can anyone help me find the solution?\n My approach was to sketch it and draw the marginal plane, then identify support vectors using my intuition. After that, I created a hyperplane that was the midpoint of both marginal planes, found its slope and y-intercept, but still, my answer was wrong.\n I am very new to machine learning, so any help would be appreciated.\n Consider the dataset M = {((1, 0)^T, 1), ((0, −1)^T, 1), ((1, −1)^T, −1), ((2, 0)^T, −1)}. Determine w and b.\n    submitted by    /u/salman_ml  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15d729w/d_calculate_w_and_b_in_hard_margin_svm/",
          "publishedOn": "2023-07-30T00:09:48.000Z",
          "wordCount": 2589,
          "title": "[D] Calculate 'w' and 'b' in hard margin SVM",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15d68k3/p_brand_new_ai_social_app_featuring_unique_bot/",
          "author": null,
          "description": "Hi everyone,\n I'm messaging on behalf of a brand new AI based Social Media app called Cantina. It's like a cross between the best parts of Discord, Twitch, and Snapchat, and uses both Stable Diffusion and ChatGPT to allow users to create and interact with AI bots.\n The app is currently INVITE ONLY during the Beta phase and we are looking for people to try it out (currently iOS only, but Android is coming soon!). Here's a private invite link: https://canti.na/dIdKzWcEpBb.\n The most unique and FUN part of the app is that it allows users to interact with and build your own AI chat bots, and these bots also work as AI art creators. Simply ask them to draw something, and they'll provide you with a picture based on your prompt. There are lots of premade bots that you can interact with or add to rooms, or you can easily create your own bot using the Make A Bot function. There will be prizes and initiatives for the most creative bots in the near future. I'd love to see what you come up with!\n Anyway, you can download through the invite link above and dive right in. If you have any thoughts, questions, or comments, please feel free to message me! During this limited beta phase, your feedback will be invaluable.\n    submitted by    /u/SamuelAnonymous  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15d68k3/p_brand_new_ai_social_app_featuring_unique_bot/",
          "publishedOn": "2023-07-29T23:31:16.000Z",
          "wordCount": 2711,
          "title": "[P] Brand new AI Social App featuring unique bot features looking for iOS users to join Beta!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15d4nj4/d_ai_that_can_describe_a_video/",
          "author": null,
          "description": "Anyone know if there is anything able to describe the content of a video? I have found a lot of stuff for images but nothing for videos.\n    submitted by    /u/crazewill  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15d4nj4/d_ai_that_can_describe_a_video/",
          "publishedOn": "2023-07-29T22:19:43.000Z",
          "wordCount": 2507,
          "title": "[D] AI that can describe a video?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15d4kjf/p_best_machine_learning_algorithms_for_forecasting/",
          "author": null,
          "description": "I plan on using Machine Learning Algorithms to forecast future values of power demand and the literature on the subject is a bit divisive. I'm getting ANN, Decision Trees (odd), SVMs etc.\n I just want to know what models you guys would use (MATLAB and Python only, except it's really good).\n Thank you in anticipation.\n P.S: Any literature to streamline my search will be greatly appreciated.\n    submitted by    /u/X69-2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15d4kjf/p_best_machine_learning_algorithms_for_forecasting/",
          "publishedOn": "2023-07-29T22:16:02.000Z",
          "wordCount": 2546,
          "title": "[P] Best Machine Learning Algorithms for Forecasting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15d1l08/r_factool_factuality_detection_in_generative_ai_a/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2307.13528 \n Blog: https://ethanc111.github.io/factool_website/ \n Github: https://github.com/GAIR-NLP/factool \n Factool is a tool augmented framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT). Factool now supports 4 tasks:\n  \nknowledge-based QA: Factool detects factual errors in knowledge-based QA.\n code generation: Factool detects execution errors in code generation.\n mathematical reasoning: Factool detects calculation errors in mathematical reasoning.\n scientific literature review: Factool detects hallucinated scientific literatures.\n  \nAbstract:\n  \nThe emergence of generative pre-trained models has facilitated the synthesis of high-quality text, but it has also posed challenges in identifying factual errors in t…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15d1l08/r_factool_factuality_detection_in_generative_ai_a/",
          "publishedOn": "2023-07-29T20:09:05.000Z",
          "wordCount": 2712,
          "title": "[R] FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios - Shanghai Jiao Tong University et al 2023 - Plugin for ChatGPT! - Highly improves factfulness in math, code, knowledge and scientific reasoning!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15d1j36/p_promptify_20_more_structured_more_powerful_llms/",
          "author": null,
          "description": "Hello fellow coders and AI enthusiasts!\n First up, a huge Thank You for making Promptify a hit with over 2.3k+ stars on Github ! 🌟\n Back in 2022, we were the first one to tackle the common challenge of uncontrolled, unstructured outputs from large language models like GPT-3. , and your support has pushed us to keep improving.Today, we're thrilled to share some major updates that make Promptify even more powerful\n https://preview.redd.it/hk7ro4tmnyeb1.png?width=1510&format=png&auto=webp&s=226ada1f896c620137f827932c03a9df88e35d69\n ​\n  \nUnified Architecture 🧭: Introducing Prompter, Model & Pipeline Solution\n Detailed Output Logs 📔: Comprehensive structured JSON format output within the log folder.\n Wider Model Support 🤝: Supporting models from OpenAI, Azure, Cohere, Anthropic, Huggingface and more - think of it as your universal language model adapter.\n Robust Parser 🦸‍♂️: Parser to handle incomplete or unstructured JSON outputs from any LLMs.\n Ready-Made Jinja Templates 📝: Jinja prompt templates for NER, Text Classification, QA, Relation-Extraction, Tabular data, etc.\n Database Integration 🔗: Soon, Promptify directly to Mongodb integration. Stay tuned!\n Effortless Embedding Generation 🧬: Generate embeddings from various LLMs effortlessly with the new update.\n  \nhttps://preview.redd.it/rf8yjqxnnyeb1.png?width=2160&format=png&auto=webp&s=87b7c2408382757e38ff554fde56e56bd60b1793\n ​\n Check out the examples and take Promptify for a spin on GitHub. If you like what you see, we'd be honored if you gave us a star!\n  \nGithub: https://github.com/promptslab/Promptify\n Colab: Try Now on Colab\n Explore Other Cool Open Source LLM Tools: https://github.com/promptslab\n  \nJoin 1.6k+ Promptify users on Discord to dive deep into prompt engineering, discuss the latest with LLMs, and advance NLP research together: https://discord.com/invite/m88xfYMbK6\n Thank you again for your support - here's to more structured AI!\n    submitted by    /u/StoicBatman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15d1j36/p_promptify_20_more_structured_more_powerful_llms/",
          "publishedOn": "2023-07-29T20:06:43.000Z",
          "wordCount": 2741,
          "title": "[P] Promptify 2.0: More Structured, More Powerful LLMs with Prompt-Optimization, Prompt-Engineering, and Structured Json Parsing with GPT-n Models! 🚀",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15d1c53/d_why_being_careful_matters_when_selecting_cnn/",
          "author": null,
          "description": "submitted by    /u/CkmCpvis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15d1c53/d_why_being_careful_matters_when_selecting_cnn/",
          "publishedOn": "2023-07-29T19:58:42.000Z",
          "wordCount": 2480,
          "title": "[D] Why Being Careful Matters When Selecting CNN Padding",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15d0oz9/r_rt2_visionlanguageaction_models_transfer_web/",
          "author": null,
          "description": "Paper: https://robotics-transformer2.github.io/assets/rt2.pdf \n Blog: https://robotics-transformer2.github.io/ \n Blog: https://www.deepmind.com/blog/rt-2-new-model-translates-vision-and-language-into-action \n Github ( RT-1 as of now) : https://github.com/google-research/robotics_transformer \n Abstract:\n  \nWe study how vision-language models trained on Internet-scale data can be incorporated directly into end-to-end robotic control to boost generalization and enable emergent semantic reasoning. Our goal is to enable a single end-to-end trained model to both learn to map robot observations to actions and enjoy the benefits of large-scale pretraining on language and vision-language data from the web. To this end, we propose to co-fine-tune state-of-the-art vision-language models on both robot…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15d0oz9/r_rt2_visionlanguageaction_models_transfer_web/",
          "publishedOn": "2023-07-29T19:31:01.000Z",
          "wordCount": 2819,
          "title": "[R] RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control - Google DeepMind 2023 - Is able to perform multi-stage semantic reasoning and can interpret commands not present in the robot training data!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cz6zh/d_no_free_lunch_theorem/",
          "author": null,
          "description": "A conclusion of the no free lunch theorem is that there can't exist a universal learning algorithm. My understanding has been that this was the end goal of AI research; creating a universal learner. What is the community progressing towards, if not that?\n    submitted by    /u/lemlo100  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cz6zh/d_no_free_lunch_theorem/",
          "publishedOn": "2023-07-29T18:27:02.000Z",
          "wordCount": 2521,
          "title": "[D] No free lunch theorem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cx7j3/project_seeking_coding_wizards_for_traveling/",
          "author": null,
          "description": "Hello everyone,\n I'm currently working on an exciting project using the Travelling Salesman Problem (TSP), and I'd love to have some coding wizards join the fun!\n If you enjoy solving optimisation problems and have some coding experience, particularly in Python, this project is for you. To determine the most efficient routes, we'll use heuristic methods such as the Nearest Neighbour Algorithm, Genetic Algorithm, and Ant Colony Optimisation.\n If you aren't a TSP expert yet, don't worry. We'll be learning and exploring together! I'm really looking forward to seeing how we can optimise routes for real-world applications like delivery and travel planning.\n So, if you're looking for a coding adventure and want to be a part of a fantastic project, hit me up! Let's crack this TSP puzzle and create some smart solutions.\n If you're interested in collaborating, please send me a message. I can't wait to work with you and nerd out on some fantastic code!\n    submitted by    /u/vampire_19  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cx7j3/project_seeking_coding_wizards_for_traveling/",
          "publishedOn": "2023-07-29T17:01:14.000Z",
          "wordCount": 2637,
          "title": "[Project] Seeking Coding Wizards for Traveling Salesman Challenge!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cwufp/ml_on_detecting_bacteria_in_blood_through/",
          "author": null,
          "description": "I am trying to make a machine that could detect if there is any bacteria in blood through pictures. However I do not know any thing about machine learning and only knows a little bit of Python and C++. What should I do?\n    submitted by    /u/EthanWasTakenAgain  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cwufp/ml_on_detecting_bacteria_in_blood_through/",
          "publishedOn": "2023-07-29T16:45:33.000Z",
          "wordCount": 2527,
          "title": "ML on detecting bacteria in blood through pictures for beginners [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cv8ql/dseeking_participants_for_airelated_survey/",
          "author": null,
          "description": "I am currently working on my IB Extended Essay, and I would greatly appreciate your help in gathering valuable insights from individuals knowledgeable in the field of AI. The purpose of my survey is to understand the perspectives of AI enthusiasts .\n If you have a few minutes to spare, I kindly request you to participate in my survey. Your input will contribute significantly to my research and help me gain a deeper understanding of the topic. The survey covers various aspects of AI, and your expertise will be invaluable in shaping the results.\n Survey Link: https://forms.gle/PVGrRbPLTpZRbbpL9\n Rest assured that all responses will be kept confidential and only used for academic purposes. Additionally, feel free to share this survey with others who might be interested or knowledgeable in the field. Thank you in advance for your time and contributions! Your participation will greatly aid in the successful completion of my IB Extended Essay.\n    submitted by    /u/KVNG_Winston  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cv8ql/dseeking_participants_for_airelated_survey/",
          "publishedOn": "2023-07-29T15:36:37.000Z",
          "wordCount": 2631,
          "title": "[D]Seeking Participants for AI-related Survey",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cv1p4/d_seeking_resume_expertise_struggling_to_land/",
          "author": null,
          "description": "submitted by    /u/AIKiller1997  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cv1p4/d_seeking_resume_expertise_struggling_to_land/",
          "publishedOn": "2023-07-29T15:28:32.000Z",
          "wordCount": 2514,
          "title": "[D] Seeking Resume Expertise: Struggling to Land Interviews or Jobs, Need Guidance! Please Assist!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cudgl/efficient_lasso_regression_for_n200000_and/",
          "author": null,
          "description": "Please suggest me efficient LASSO regression implementations for very high dimensional data. Thanks in advance!\n    submitted by    /u/Charming-Witness-286  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cudgl/efficient_lasso_regression_for_n200000_and/",
          "publishedOn": "2023-07-29T14:59:48.000Z",
          "wordCount": 2496,
          "title": "Efficient LASSO regression for N=~200,000 and dim=~30,000 [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cphv6/one_big_net_for_everything_2018/",
          "author": null,
          "description": "submitted by    /u/EducationalCicada  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cphv6/one_big_net_for_everything_2018/",
          "publishedOn": "2023-07-29T11:00:50.000Z",
          "wordCount": 2490,
          "title": "One Big Net For Everything (2018)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cm94i/text_reclassification_promptscode_d_r/",
          "author": null,
          "description": "submitted by    /u/MutedCatch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cm94i/text_reclassification_promptscode_d_r/",
          "publishedOn": "2023-07-29T07:47:16.000Z",
          "wordCount": 2495,
          "title": "Text reclassification prompts/code [D] [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cie8m/d_conformal_prediction_with_python/",
          "author": null,
          "description": "submitted by    /u/Kujamara  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cie8m/d_conformal_prediction_with_python/",
          "publishedOn": "2023-07-29T04:05:51.000Z",
          "wordCount": 2502,
          "title": "[D] Conformal Prediction with Python",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cc0rj/d_major_issue_found_with_minmax_data_scaling/",
          "author": null,
          "description": "I have a well performing model on azure AI currently and i am pulling it down locally so that I can use it. During pre-processing I am going about these steps. \n - Re-Balance data (SMOTE, undersample)\n - Lag data \n - Get all min max values into config\n - Scale Data with Min Max\n For context I will explain what step 3 (the config) is for, I take the the min and max values of the entire dataset (before split) for each feature. I then apply append these to my local version and being the scaling so then the local dataset is using the exact same scaling parameters as what is being using during the original pre-processing.\n I cannot show the full dataset due to privacy and the fact it has 3000+ features. But I will show 1 row with a couple of columns to compare AzureAI training data and my local pre-process that is using the exact same code / system.\n ​\n Azure AI dataset:\n Feature1 Feature2 Feature3\n 0.637952 0.645434 0.641118\n ​\n Local dataset:\n Feature1 Feature2 Feature3\n 0.461278 0.462896 0.472841 \n ​\n I have confirmed this is the exact same row of data because i have timestamped each row and matched them up to confirm that the dataset scaling is being simulated in my local version even though the code is carbon copy and the same min and max values are being used in the original dataset that used for training and testing. \n Does anyone know a better way to scale data and ensure scaling stays consistent wherever the model is used? Or have maybe I missed something? \n    submitted by    /u/paddockson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cc0rj/d_major_issue_found_with_minmax_data_scaling/",
          "publishedOn": "2023-07-28T23:01:26.000Z",
          "wordCount": 2745,
          "title": "[D] Major issue found with MinMax data scaling.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15cb8be/p_harness_the_power_of_ml/",
          "author": null,
          "description": "I built out an automatic machine learning platform called Heimdall ML which helps anyone quickly deploy machine learning models to production.\n At a high level, my platform will:\n  \nIngest your data as a .csv file\n Clean up any irregularities and prepare the data for modeling\n Build the most Optimal model for you use case\n Show you a results report to show both the performance and biases associated with your model\n Create an API endpoint to help you build new experiences with your model\n  \nThe cool thing about my platform is that it allows you the ability to embed machine learning into your platform with ease. You have the ability to fully customize your experience to wow you customers. I built this entire platform by myself from scratch and am looking to grow the user base!\n The tool is completely FREE for hobby users! You can crunch some pretty large datasets (80 columns, 10K rows) with just the free version. If you have a use case that needs some big data processing, you will have to reach out to me directly so I can help set up a good plan for you. The reason for this is because the project is completely self funded and I want to be able to control the costs.\n I was inspired to create this platform while I was in grad school because many of the firms giving us talks would talk about how they had teams of engineers who build out pipelines to bring a model to production. I personally believe there can be an easier way.\n Heimdall ML: https://www.heimdallapp.org\n Loom: https://www.loom.com/share/86ae62849f874a2da255911e2d5db762?sid=5e1efddb-9556-4e3d-84fd-e2ff7198a98c\n    submitted by    /u/jreji  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15cb8be/p_harness_the_power_of_ml/",
          "publishedOn": "2023-07-28T22:28:15.000Z",
          "wordCount": 2746,
          "title": "[P] Harness the Power of ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15c9r3z/can_someone_make_an_ai_therapist_that_isnt_just_a/",
          "author": null,
          "description": "One that looks like a person. You can see their expressions and listen to their voice. Trained on up to date medical research and communication/empathy skills. \n Therapy is so expensive and inaccessible to too many people\n    submitted by    /u/Sgdoc70  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15c9r3z/can_someone_make_an_ai_therapist_that_isnt_just_a/",
          "publishedOn": "2023-07-28T21:28:38.000Z",
          "wordCount": 2521,
          "title": "Can someone make an AI Therapist that isn’t just a chat? [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15c89r7/d_huggingface_changed_the_license_of_one_of_its/",
          "author": null,
          "description": "TGI is no longer commercially permissible. That's really sad.\n https://github.com/huggingface/text-generation-inference/commit/bde25e62b33b05113519e5dbf75abda06a03328e\n    submitted by    /u/paulo_zip  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15c89r7/d_huggingface_changed_the_license_of_one_of_its/",
          "publishedOn": "2023-07-28T20:29:11.000Z",
          "wordCount": 2495,
          "title": "[D] HuggingFace changed the license of one of its most important libraries",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15c5kfc/d_how_do_large_companies_get_their_llms_to_give/",
          "author": null,
          "description": "Curious how companies like Google, MSFT, etc are able to have their LLMs and ML models have very fast responses. Do they just have crazy powerful gpus or split inference amongst gpus.\n    submitted by    /u/candyman54  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15c5kfc/d_how_do_large_companies_get_their_llms_to_give/",
          "publishedOn": "2023-07-28T18:42:45.000Z",
          "wordCount": 2518,
          "title": "[D] How do large companies get their LLMs to give sub second responses?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15c4qk2/d_hugging_face_github_and_more_unite_to_defend/",
          "author": null,
          "description": "Full Article: https://venturebeat.com/ai/hugging-face-github-and-more-unite-to-defend-open-source-in-eu-ai-legislation/\n    submitted by    /u/EmbarrassedHelp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15c4qk2/d_hugging_face_github_and_more_unite_to_defend/",
          "publishedOn": "2023-07-28T18:09:57.000Z",
          "wordCount": 2491,
          "title": "[D] Hugging Face, GitHub and more unite to defend open source in EU AI legislation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15c48vv/p_revolutionizing_agriculture_llmpowered_agent/",
          "author": null,
          "description": "Check out this project idea to revolutionize agriculture and bolster global food security. We all know that farmers face challenges like erratic weather, depleting resources, and the need for sustainable crop yields.\n An IoT-driven system with soil sensors, fueled by a custom Large Language Model (LLM)🚀 trained on soil data.\n Concept : Empowering farmers with real-time soil data via IoT devices and sensors. Leveraging the LLM's capabilities, the system analyzes this data to provide personalized strategies for enhancing soil fertility and suggesting the best crops for specific conditions.\n How it Works : IoT devices and soil sensors continuously gather vital soil parameters - moisture, pH, nutrients, and temperature. This data is processed by the LLM, generating actionable insights for farmers.\n Benefits : Picture a world where data-driven decisions and sustainable practices dominate agriculture. This system boosts productivity, optimizes resource management, and enhances profits. Embracing sustainability and informed choices ensures an eco-friendly agricultural sector.\n Impact on Food Security : Enhanced productivity means more than just profit; it ensures food security worldwide. By aiding farmers in sustainable and efficient practices, we contribute to a steady supply of nutritious food for all.\n    submitted by    /u/s_abhiishek  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15c48vv/p_revolutionizing_agriculture_llmpowered_agent/",
          "publishedOn": "2023-07-28T17:50:32.000Z",
          "wordCount": 2682,
          "title": "[P] Revolutionizing agriculture: LLM-Powered Agent for Soil Fertility and Crop Production Recommendations using real time soil devices and sensor data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bz0f2/d_recommendation_on_studying_deep_learning_theory/",
          "author": null,
          "description": "I've just finished Machine Learning Specialization by Andrew Ng and I'm planning to dive deeper into Deep Learning concepts, theory, and implementation. I would like to get deeper insights and more understanding of the fundamental mathematical concepts of NN and DL models and build better intuition of how these models work. I also want to understand theoretically, how more neurons capture non-linear relationships in data and what exactly is hierarchical representation of data and how hidden layers form and learn from these abstract representations of data. Apart from theory, I also want to learn the implementation of these models. I have some exposure to TF library, but I'm okay to learn Pytorch too, if needed.\n I need course or any sort of content recommendation on what are the best options to learn all this. So far, I've got recommendations for Deep Learning Specialization by Andrew Ng, but I would love to hear any alternate option or anything that I can do side by side this specialization.\n Thanks!\n    submitted by    /u/Total-Opposite-8396  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bz0f2/d_recommendation_on_studying_deep_learning_theory/",
          "publishedOn": "2023-07-28T14:28:04.000Z",
          "wordCount": 2658,
          "title": "[D] Recommendation on studying Deep Learning (Theory + Implementation) / Alternate to Deep Learning Specialization by Andrew Ng?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15buplq/r_what_is_a_fairly_good_results_for_sacrebleu/",
          "author": null,
          "description": "I ran my own model on translation (Multi30k). I trained a recurrent model and the sacrebleu score is 28. I also tested the bleu score provided by nltk and it is 60. It that good or bad?\n    submitted by    /u/Puzzleheaded-Cry4262  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15buplq/r_what_is_a_fairly_good_results_for_sacrebleu/",
          "publishedOn": "2023-07-28T11:23:49.000Z",
          "wordCount": 2519,
          "title": "[R] What is a fairly good results for sacrebleu?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15btipw/d_please_advise_me_on_my_masters/",
          "author": null,
          "description": "Please give me advice to do well in my masters in ml\n I’m going to start my masters in machine learning soon, I have 1 month to go but I feel so underprepared to start this journey. To give you a bit of a background I’ve studied electrical engineering in my UG. I did very badly, I was very depressed and couldn’t study at all somehow I managed to scrape through the 4 years and now after working in software testing for 2 years I decided to take a leap in machine learning because it looked so interesting and I wanted a change. I’m scared now because my coding knowledge isn’t very good and idk how much of the math I know is useful for the degree I plan to do. Please help me I’m panicking. I know you would tell me it’s pretty irresponsible how I’ve handled my life till now but please overlook that and tell me what I can do better now..\n    submitted by    /u/ObjectiveShower9133  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15btipw/d_please_advise_me_on_my_masters/",
          "publishedOn": "2023-07-28T10:22:41.000Z",
          "wordCount": 2645,
          "title": "[D] Please advise me on my masters",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15brbv1/d_recommendation_system_giving_same_response_to/",
          "author": null,
          "description": "I am using Gorse Open Source Recommendation system for my project. It was working nicely, but lately from 1-2 days, it is giving the same recommendation for every user. I have about 60 items and about 650 users showing in Gorse Dashboard. Can anyone explain why it's happening? I am not an expert in ML,I am willing to share my configurations if you want.\n    submitted by    /u/Responsible_Delay418  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15brbv1/d_recommendation_system_giving_same_response_to/",
          "publishedOn": "2023-07-28T08:19:54.000Z",
          "wordCount": 2546,
          "title": "[D] Recommendation system giving same response to every User",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15br11c/d_having_trouble_with_rag_on_company_domain_data/",
          "author": null,
          "description": "I have a data set that isn't that large ~200 pdfs. I have done the regular RAG approach with Langchain, extracting text, splitting into chunks, embedding with OpenAi embeddings and FAISS vector storage. However, when I do a similarity search with a question I would like answered it returns the wrong context. The documents are semi-structured information of examined bridges. A question I would like answered is f.e. 'what is the construction date of bridge X?'. When I input this question I get a lot of context of construction dates of other bridges. I think this is because the bridges are not explicitly mentioned in the text. I tried adding the bridge name and document name to the page content string of the chunks, but this does nothing.\n Does anyone have any tips on improving the embeddings retrieval in this case?\n    submitted by    /u/Dustwellow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15br11c/d_having_trouble_with_rag_on_company_domain_data/",
          "publishedOn": "2023-07-28T08:01:54.000Z",
          "wordCount": 2623,
          "title": "[D] Having trouble with RAG on company domain data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15br0b6/p_tool_to_auto_compilequantize_models/",
          "author": null,
          "description": "Hey guys, we have an internal tool that preps our models for inference by compiling it to Onnx/TensorRT and quantizing it to I8/FP16. It also benchmarks them for accuracy loss and latency. It's kinda like github actions for your model. We are considering releasing it as it's standalone product, would anyone be interested? \n    submitted by    /u/throwaway65161354  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15br0b6/p_tool_to_auto_compilequantize_models/",
          "publishedOn": "2023-07-28T08:00:54.000Z",
          "wordCount": 2532,
          "title": "[P] Tool to auto compile/quantize models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bqwdv/d_domain_adaptation_on_llama2/",
          "author": null,
          "description": "Hi,\n I am trying domain adaptation on my company’s data. The data is a set of documentations that we have for a product.\n We want to take Llama2 and feed all this data to it.\n I have fine-tuned Llama2 using PEFT on a CLM task, where the data will be like [Title:<title>\\nContent:<content>].\n When I now try to prompt the model I have to provide the prompt in a similar format, but I want the model to understand that I want to perform QA task on the data, as well as any other knowledge the model previously had.\n What am I missing here or what am I doing wrong? How can I set up this task better? Any pointers will help.\n Thanks!\n    submitted by    /u/ProfessorShit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bqwdv/d_domain_adaptation_on_llama2/",
          "publishedOn": "2023-07-28T07:54:20.000Z",
          "wordCount": 2599,
          "title": "[D] Domain adaptation on LLAMA2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bpr4d/r_implementing_yolov3_with_octave_convolutions/",
          "author": null,
          "description": "Hi all, I am trying to implent or rather modify a given Yolov3 implementation to use Octave Convolution instead of 2D Convolutions in the architecture. The details are in this stackoverflow question. I hope someone i able to help me.\n    submitted by    /u/dulre  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bpr4d/r_implementing_yolov3_with_octave_convolutions/",
          "publishedOn": "2023-07-28T06:48:03.000Z",
          "wordCount": 2519,
          "title": "[R] Implementing Yolov3 with Octave Convolutions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bovwu/r_communicative_agents_for_software_development/",
          "author": null,
          "description": "ChatDev\n Paper: https://arxiv.org/abs/2307.07924\n TL;DR:\n - Tsinghua University's team has developed ChatDev, a virtual software development company staffed by LLM autonomous agent\n - LLM agents as employee follow waterfall model to design->implement->test->documentation\n - LLM agents have role specialization (CEO, DEV, BA ..), inception prompting, Self-reflection\n - The researchers designed 70 user requirements and then analyzed the software produced by ChatDev. \n - On average, each piece of software generated by ChatDev had 17.04 files, mitigated 13.23 potential code bugs caused by code illusions, had a software generation time of 409.84 seconds, and cost $0.2967 to manufacture.\n ​\n Chat chain\n ​\n    submitted by    /u/michaelthwan_ai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bovwu/r_communicative_agents_for_software_development/",
          "publishedOn": "2023-07-28T05:59:18.000Z",
          "wordCount": 2582,
          "title": "[R] Communicative Agents for Software Development (Autonomous LLM agent as a DEV company)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bno2k/d_milvus_20_or_higher_with_gpu_enabled/",
          "author": null,
          "description": "Is there a way to use milvus 2.0 or higher with GPU enabled indexing and while doing vector search? I cant find anything in there documentation for this section only available in 1.1 version Any help will be appreciated. TIA\n    submitted by    /u/adiraat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bno2k/d_milvus_20_or_higher_with_gpu_enabled/",
          "publishedOn": "2023-07-28T04:51:26.000Z",
          "wordCount": 2521,
          "title": "[D] Milvus 2.0 or higher with GPU enabled",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bmuy7/p_has_anyone_tried_to_work_with_starcoder/",
          "author": null,
          "description": "I recently found out about starcoder and have been trying to play with it and figure it out in a colab notebook. Unfortunately, it’s much more difficult to download than normal models on hugging face and I’m running into a Key Value error when I call the model. I don’t want to spam with with code or pictures, but has anyone worked with StarCoder on hugging face and been able to be successful?\n    submitted by    /u/AJ1043  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bmuy7/p_has_anyone_tried_to_work_with_starcoder/",
          "publishedOn": "2023-07-28T04:07:46.000Z",
          "wordCount": 2554,
          "title": "[P] Has anyone tried to work with StarCoder?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bkv3g/d_can_anyone_explain_what_karpathys_recent/",
          "author": null,
          "description": "Hi, I am not a CS student. I want to know what's exactly going on with llama2.c. Is the Python code converted to C and then compiled? Or only weights are converted to C? Is the network written in C? If I have to write a small network (say, a simple 2 stage Fully connected network) and do a similar thing like llama2.c, then how to proceed? \n    submitted by    /u/panini_deploy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bkv3g/d_can_anyone_explain_what_karpathys_recent/",
          "publishedOn": "2023-07-28T02:26:28.000Z",
          "wordCount": 2557,
          "title": "[D] Can anyone explain what Karpathy's recent llama2.c is doing underneath? I am not a CS student",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bjmj0/r_scaling_transnormer_to_175_billion_parameters/",
          "author": null,
          "description": "https://arxiv.org/abs/2307.14995\n    submitted by    /u/hzj5790  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bjmj0/r_scaling_transnormer_to_175_billion_parameters/",
          "publishedOn": "2023-07-28T01:27:12.000Z",
          "wordCount": 2481,
          "title": "[R] Scaling TransNormer to 175 Billion Parameters",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bfiok/d_for_lms_what_works_other_than_scaling/",
          "author": null,
          "description": "Increasing the number of parameters is the best-known way to increase the quality of a language model. What methods — instruction tuning and RLHF aside — deliver the next-best amount of ROI?\n    submitted by    /u/ndronen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bfiok/d_for_lms_what_works_other_than_scaling/",
          "publishedOn": "2023-07-27T22:25:48.000Z",
          "wordCount": 2513,
          "title": "[D] For LMs, what works other than scaling?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bf7ai/d_viability_of_fine_tuning_for_domain_knowledge/",
          "author": null,
          "description": "The consensus is that fine tuning LLMs works reasonably for smaller scale instruction tuning, where you pass in ~1k-10k input/output examples to modify the model output.\n There seems to be a lot of contradictory info regarding fine tuning for domain knowledge, where you pass in large amounts of unsupervised, domain scale data.\n Per OpenAI:\n  \nPeople that can’t get finetuning to work are often asking for orange juice from a cow. \n LLMs are pretrained (hence the name: Generative Pretrained Transformer) They already have all the knowledge you will need (with some exceptions). You cannot teach it anything new, you can only teach it a specific pattern. \n People have not defined their goal clearly enough for a human to do the task. LLMs are not magic, if a human cannot understand the task, the L…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bf7ai/d_viability_of_fine_tuning_for_domain_knowledge/",
          "publishedOn": "2023-07-27T22:13:00.000Z",
          "wordCount": 2799,
          "title": "[D] Viability of fine tuning for domain knowledge",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bepv2/looking_for_a_help_p/",
          "author": null,
          "description": "I am a graduate student at Computer science medical informatics field, I was asked to search for a project using ML to diagnose, detect, improve any disease. Any Ideas ?? It can be any project .\n BioInformatics #MedicalInformatics #ComputerScience #MachineLearning\n    submitted by    /u/Adorable-Bug-928  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bepv2/looking_for_a_help_p/",
          "publishedOn": "2023-07-27T21:53:25.000Z",
          "wordCount": 2518,
          "title": "Looking for a help [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bd671/r_questions_about_dictionary_learning/",
          "author": null,
          "description": "I’m a PhD student and a problem I’ve been working on has connections to dictionary learning. I’d like to pursue this connection, but neither myself or my advisor have much knowledge of the dictionary learning or the surrounding literature. \n Questions:\n  \nIs dictionary learning an active area of interest for modern ML? I understand that it might be more niche than some of the topics getting headlines these days, but I’d be curious to hear about applications where dictionary learning is used/reasonably competitive.\n \nAre there any references in dictionary learning that you’d consider to be “essential” reading?\n \n Thanks!\n    submitted by    /u/sjsjdhshshs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bd671/r_questions_about_dictionary_learning/",
          "publishedOn": "2023-07-27T20:52:49.000Z",
          "wordCount": 2575,
          "title": "[R] Questions about dictionary learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15bayr2/discussion_help_me_pick_the_right_masters/",
          "author": null,
          "description": "Hello Reddit,\n I'm currently at a crossroads in my academic journey and I could use some insights from those more experienced in the field of machine learning and AI.\n I'm choosing between two programs: Applied Data Science and AI and Data Science and AI. Each program has its own unique structure and focus which I will briefly summarize below.\n Applied Data Science and AI is a two-year program with a focus on practicality and project-based learning. It includes the following core courses:\n  \nIntroduction to Data Science\n Python for Data Scientists\n Applied Mathematical Thinking\n Statistical Methods for Data Science\n Applied Machine Learning\n Computational Techniques for Large-Scale Data\n Research Methods for Data Science\n Master’s Thesis in Data Science\n  \nThe program also offers the flexibility to choose optional courses to tailor my learning towards my own interests.\n On the other hand, Data Science and AI takes a more rigorous, math-intensive approach in its first year with compulsory courses such as:\n  \nIntroduction to data science and artificial intelligence\n Nonlinear optimization\n Stochastic processes and Bayesian statistics\n Design of AI systems\n  \nThe second year involves a Master's thesis and elective courses from a diverse range of topics.\n Given that my ultimate goal is to become a proficient machine learning developer, I'm leaning towards the Applied Data Science and AI program for its hands-on approach. However, I'm aware that the Data Science and AI program's heavy math focus in the first year could provide a robust theoretical foundation that could be beneficial.\n I'd love to hear from anyone who has been through similar programs or who works in the field. Which of these two programs do you think would best prepare me for a career in machine learning? How important is a deep mathematical foundation versus a more applied, project-based learning approach? \n Thank you in advance!\n    submitted by    /u/ZoomedBoxTrade  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15bayr2/discussion_help_me_pick_the_right_masters/",
          "publishedOn": "2023-07-27T19:28:32.000Z",
          "wordCount": 2780,
          "title": "[Discussion] Help me pick the right master's programme!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15baqjr/d_what_neural_networks_can_be_an_alternative_to/",
          "author": null,
          "description": "I am looking for topics for my master thesis I came to read about GARCH/ARCH models and their application to economics. My idea is to use neural networks as an alternative with better performance. Are there any resources I can read about if this is done and what type of neural networks are used?\n    submitted by    /u/AnyJello605  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15baqjr/d_what_neural_networks_can_be_an_alternative_to/",
          "publishedOn": "2023-07-27T19:19:44.000Z",
          "wordCount": 2541,
          "title": "[D] What neural networks can be an alternative to GARCH/ARCH models for macroeconomic modelling",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ba6pq/p_new_encryption_sdkproxy_tool_to_protect_vector/",
          "author": null,
          "description": "We're looking for some beta testers and input on our newest project called Cloaked AI that allows you to protect sensitive data that gets stored as vector embeddings (and metadata) in a vector database. You can join the beta tester waitlist here (we'll be rolling out access in the next few weeks). But here are some FAQs about why protecting vector embeddings matters, etc.\n Why should I be worried about sensitive data in vector embeddings?\n To a human, vectors are meaningless. But to the AI, the vectors contain all of the meaning found in the original sensitive data. Generative AI systems can recreate the original sensitive data to a high degree of accuracy (though in their own style). That means the data stored in vector databases are a significant security and privacy risk for companies t…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ba6pq/p_new_encryption_sdkproxy_tool_to_protect_vector/",
          "publishedOn": "2023-07-27T18:58:07.000Z",
          "wordCount": 3090,
          "title": "[P] New encryption SDK/proxy tool to protect vector embeddings",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15b8vic/d_how_nuanced_are_reward_functions_in_rlhf/",
          "author": null,
          "description": "I'm still learning the basic concepts here, as I explore the creative potential of LLMs — one potential problem I've been thinking about is how these models come to understand good or bad answers. \n I know that once they reach the public, the feedback loop is fairly binary -- Yes, this was a good result, or No, this was a poor result. \n It seems like a lot of the subjective detail might be lost (e.g. Why was it a bad result?) and I was wondering if this detail is captured elsewhere in the training process. \n There is so much subjectivity involved in creative works, I wonder if this is why we tend to see the output of LLMs as being creatively bland and/or uninspired (that is— by default, without extensive prompting)\n    submitted by    /u/kaigani  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15b8vic/d_how_nuanced_are_reward_functions_in_rlhf/",
          "publishedOn": "2023-07-27T18:05:45.000Z",
          "wordCount": 2612,
          "title": "[D] How nuanced are reward functions in RLHF?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15b86on/statistical_significance_d/",
          "author": null,
          "description": "Help me with this topic. I am stuck in it\n    submitted by    /u/Rehulmonsynapses  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15b86on/statistical_significance_d/",
          "publishedOn": "2023-07-27T17:38:45.000Z",
          "wordCount": 2486,
          "title": "Statistical Significance [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15b7mq9/p_tabular_large_language_model/",
          "author": null,
          "description": "Gretel's tabular large language model is capable of generating highly valuable synthetic tabular data, with differentially private fine-tuning. https://gretel.ai/tabular-llm\n    submitted by    /u/alig80  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15b7mq9/p_tabular_large_language_model/",
          "publishedOn": "2023-07-27T17:17:34.000Z",
          "wordCount": 2497,
          "title": "[P] Tabular Large Language Model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15b5ry9/d_is_transfer_learning_the_most_vip_problem/",
          "author": null,
          "description": "this might be a dumb question but im gonna ask it anyway, so if its dumb ill learn...\n So ive been doing and mostly learning DL stuff (specially RL) for the past 3 years but now I want to get serious and perhaps get into the industry...\n I find that with LLMs on the scene, the foundation models are very important... the kind of foundation models that one just can never train on his/her own... how can you EVER train something like llama or gpt3 on your own from pure scratch... so it makes sense to use(fine tune) base models for whatever task you want to... with NLP and even with vision (well specially with vision as well) you have to use some base model... also with huggingface being used constantly and is a vital part of AI toolkit if you want to call it that...\n i was never comfortable wi…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15b5ry9/d_is_transfer_learning_the_most_vip_problem/",
          "publishedOn": "2023-07-27T16:03:51.000Z",
          "wordCount": 2979,
          "title": "[D] Is Transfer Learning the most vip problem solving tool rn @ jobs? [Noob question, be easy]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15b4yjw/d_what_cant_you_do_under_windows_subsystem_for/",
          "author": null,
          "description": "I'm looking at building a computer for AI/ML and gaming, and I'm trying to decide between windows and linux as the operating system. I'm very comfortable with linux. I've heard that WSL basically allows you to run a virtualized linux install on top of windows, so I was wondering, is this how most AI/ML is done on windows? Are there things that you can do more easily on linux itself than via WSL? Anything else I should know about AI/ML and WSL?\n    submitted by    /u/curiously_clueless  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15b4yjw/d_what_cant_you_do_under_windows_subsystem_for/",
          "publishedOn": "2023-07-27T15:32:12.000Z",
          "wordCount": 2565,
          "title": "[D] What *can't* you do under Windows Subsystem for Linux?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15b3kff/d_neural_network_papers_that_estimate_hands/",
          "author": null,
          "description": "I am digging through the literature trying to find if anyone has done work estimating if a hand is interacting with an object using deep learning? If anyone has any references they would be appreciated! \n    submitted by    /u/Academic-Sprinkles77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15b3kff/d_neural_network_papers_that_estimate_hands/",
          "publishedOn": "2023-07-27T14:36:25.000Z",
          "wordCount": 2518,
          "title": "[D] Neural network papers that estimate hands interacting with objects?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15b1nmm/p_lip_reading_from_video_master_thesis_ideas/",
          "author": null,
          "description": "Hello experts,\n I'm looking for any idea/paper for my master thesis, which I'd like to work on lip reading from video.\n Opening Google Scholar gives a very vast ideas that one can easily get lost. If it's an interesting paper, I get afraid that it would be too heavy for such a project.\n Therefore I'd like to ask for your opinion/suggestion!\n Your reply/thoughts would be so much appreciated.\n    submitted by    /u/vincent0110  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15b1nmm/p_lip_reading_from_video_master_thesis_ideas/",
          "publishedOn": "2023-07-27T13:16:33.000Z",
          "wordCount": 2549,
          "title": "[P] Lip reading from video; Master Thesis; IDEAS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15b0ivf/d_should_can_i_become_a_machine_learning_engineer/",
          "author": null,
          "description": "Apologies if this is not the place to ask but I saw some people asking for career advice.\n My situation:\n I am a 28 yo graduated Industrial Engineer (4 years) and almost a \"Superior Industrial Engineer\" (2 years official master degree) with only my thesis left. I should have had my thesis done a year ago from this point but I pretty much lost all my motivation for this field when I started working and discovered what it means to work. I live in south Spain, which honestly can barely pass as first world and thus, my wage, while being \"ok\" for my age and the place I work in is just pathetic by every other metric. This, combined with the feeling of meaningless for the job I do made me resolved to change my situation.\n I started to get heavily interested in ML six months ago. I know how it sou…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15b0ivf/d_should_can_i_become_a_machine_learning_engineer/",
          "publishedOn": "2023-07-27T12:24:58.000Z",
          "wordCount": 3143,
          "title": "[D] Should (Can) I become a machine learning engineer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15b0dbp/d_how_do_layers_and_neurons_of_an_ann_go_from/",
          "author": null,
          "description": "Lets say we have built a neural network that identifies a number from 0-9 in a 28x28 pixel image. Now lets say we have multiple neurons in the first hidden layer, and the first hidden layer might capture small edges, lines and curves in the image, and then the second hidden layer might build on those small edges, lines and curves to build bigger shapes, and then so on, the third hidden layer builds on the shapes from the previous layer, to capture more complex and bigger patterns in the picture, and this goes on until we have reached the output layer to make a prediction.\n Now in this neural network, lets focus on the first hidden layer where different neurons capture small edges, lines, and curves in different parts of the image. Lets take example of one of the neuron and see what it's do…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15b0dbp/d_how_do_layers_and_neurons_of_an_ann_go_from/",
          "publishedOn": "2023-07-27T12:17:40.000Z",
          "wordCount": 2880,
          "title": "[D] How do layers and neurons of an ANN go from capturing small edges, lines, and curves to capturing more intricate and bigger patterns building on top of small patterns?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15azddj/r_new_tabular_dl_model_tabr_unlocking_the_power/",
          "author": null,
          "description": "Hi Reddit! Me again 🙂\n After almost 1.5 years since our latest contribution to tabular DL architectures, we are ready to announce TabR - our new retrieval-based tabular DL model. In a nutshell, TabR is a simple feed-forward network with k-Nearest-Neighbors-On-Steroids (formally, a generalized attention mechanism) in the middle.\n - Paper: link\n - Code: link\n - Twitter thread with more details: link\n The figure below shows just a small part of the results, but it gives an idea of why we are excited about this new release. I hope you will enjoy reading the paper, and I will be glad to answer the questions!\n ​\n https://preview.redd.it/vjkr7fkosheb1.png?width=2348&format=png&auto=webp&s=eb3ea35b94d56d5d2110d98cdca082210edc1ec8\n    submitted by    /u/Yura52  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15azddj/r_new_tabular_dl_model_tabr_unlocking_the_power/",
          "publishedOn": "2023-07-27T11:28:36.000Z",
          "wordCount": 2591,
          "title": "[R] New Tabular DL model: \"TabR: Unlocking the Power of Retrieval-Augmented Tabular Deep Learning\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ayez2/d_transformers_on_structured_data/",
          "author": null,
          "description": "I have a dataset obtained from running a known program and dumping the state each time a user is prompted for a input. The state the structured data structures containing all the information needed to restore the execution. The format of this data is known, so i can convert it without loss to other formats, such as json.\n For example, if the program is sudoku, then the dataset element format is a array of 9x9 int8, where 0 represents a empty cell and a number from 1 to 9 is a assigned cell, furthermore there is a int8 representing the turn count too. I have dataset composed of this array at various points of the game.The data never contains loops, pointers, or any kind of graph.\n I want to use a transformer to automatically learn some function over the input. In the sudoku example this may…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ayez2/d_transformers_on_structured_data/",
          "publishedOn": "2023-07-27T10:39:12.000Z",
          "wordCount": 2841,
          "title": "[D] Transformers on structured data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15avj92/d_how_to_analyse_text_http_requests_looking_for/",
          "author": null,
          "description": "Hi, am I looking for someone to point me in the right direction.\n The task is, to classify the HTTP requests that come to honeypot as \"crawler\" or \"malicious\". For example, if I can detect a Log4j exploit inside on of the headers I can say that that request is malicious. \n The problem is, this exploit could be inside any numerous headers. It can be at the beginning or at the end. And this is just 1 exploit. There are many different exploits with their own unique strings. And I don't know them all, nor do I have a \"regex\" for each 1 of them. The malicious string could also not be inside headers, but inside URL, as query parameter. Or if the request was made to something like www/IP.com/phpadmin/.env (or something like this).\n My current thought process is, to take some open-source LLN, because it has some basic knowledge of how language works and somehow add this cybersecurity domain knowledge to it. To further train it on CVE database, example scripts that showcase each CVE, etc. \n ​\n Am I barking at the right tree here? Or should I maybe train a language model from scratch, so that the embeddings, etc are specialized to cybersec space (because there is a lot of programming code here). Or maybe I should use some other ways to analyse text?\n ​\n I would be greatefull if someone can point me in the right direction (links to blogs, or articles, or some other education material).\n ​\n Thanks\n    submitted by    /u/PopayMcGuffin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15avj92/d_how_to_analyse_text_http_requests_looking_for/",
          "publishedOn": "2023-07-27T07:56:02.000Z",
          "wordCount": 2733,
          "title": "[D] How to analyse text (http requests) - looking for guidence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15asesf/r_google_medpalm_m_towards_generalist_biomedical/",
          "author": null,
          "description": "Paper URL\n https://arxiv.org/abs/2307.14334\n Lead Author Tweetstorm\n https://twitter.com/vivnat/status/1684404882844024832\n ​\n    submitted by    /u/panabeenu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15asesf/r_google_medpalm_m_towards_generalist_biomedical/",
          "publishedOn": "2023-07-27T05:01:06.000Z",
          "wordCount": 2488,
          "title": "[R] Google Med-Palm M: Towards Generalist Biomedical AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15arlws/d_im_trying_to_do_a_backofnapkin_to_figure_out_if/",
          "author": null,
          "description": "My research involves orbital communication and Orbital Edge Computing. I'm trying to determine if upload bandwidth limitations would present a problem in many cases for ML models. I can find info on the very large and very small models, but I'm trying to get a vague sense for median size in MB. \n I know that everyone is going to start jumping in with 'well it depends' and I know that's the case, but I'm just trying to get a rough order of magnitude. Computer vision/earth obs is the ideal but anything is useful. Also happy to answer questions about my research if anyone is interested. Thanks!\n    submitted by    /u/Moose_a_Lini  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15arlws/d_im_trying_to_do_a_backofnapkin_to_figure_out_if/",
          "publishedOn": "2023-07-27T04:18:40.000Z",
          "wordCount": 2611,
          "title": "[D] I'm trying to do a back-of-napkin to figure out if some research is worthwhile and I just wanted some ballpark figures as to how big a typical model is on disk",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15aph15/r_arb_advanced_reasoning_benchmark_for_large/",
          "author": null,
          "description": "Large Language Models (LLMs) have demonstrated remarkable performance on various quantitative reasoning and knowledge benchmarks. However, many of these benchmarks are losing utility as LLMs get increasingly high scores, despite not yet reaching expert performance in these domains. We introduce ARB, a novel benchmark composed of advanced reasoning problems in multiple fields. ARB presents a more challenging test than prior benchmarks, featuring problems in mathematics, physics, biology, chemistry, and law. As a subset of ARB, we introduce a challenging set of math and physics problems which require advanced symbolic reasoning and domain knowledge. We evaluate recent models such as GPT-4 and Claude on ARB and demonstrate that current models score well below 50% on more demanding tasks. In order to improve both automatic and assisted evaluation capabilities, we introduce a rubric-based evaluation approach, allowing GPT-4 to score its own intermediate reasoning steps. Further, we conduct a human evaluation of the symbolic subset of ARB, finding promising agreement between annotators and GPT-4 rubric evaluation scores.\n  \narXiv: https://arxiv.org/abs/2307.13692\n Blog: https://arb.duckai.org/\n Code: https://github.com/TheDuckAI/arb\n Interface: https://arb.duckai.org/home\n API: https://app.swaggerhub.com/apis-docs/arb-dataset/arb-api/1.0.5\n    submitted by    /u/Friendly_Piano_735  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15aph15/r_arb_advanced_reasoning_benchmark_for_large/",
          "publishedOn": "2023-07-27T02:33:02.000Z",
          "wordCount": 2656,
          "title": "[R] ARB: Advanced Reasoning Benchmark for Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15alpxe/p_clustering_approach_for_multidimensional_vectors/",
          "author": null,
          "description": "Hi all! I am wondering if anyone has any experience with multi-dimensional vector clusters? I have a large database of 4096 dimensional vector embeddings which I want to identify clusters in. Essentially I’ve created vector embeddings for a bunch of descriptions using a LLM embedding end point and am storing them in Weviate. Now I need to try and find clusters of similar vectors within a predefined threshold of cosine similarity (or whatever nearest neighbor approach works for this). I don’t want to do a pure random center approach and would rather have a heat map approach where I’m targeting high concentrations of similar vectors… any ideas on how to approach this or thoughts on where I can do more research? I’m at my wits end on this one!\n    submitted by    /u/Character-Cry7549  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15alpxe/p_clustering_approach_for_multidimensional_vectors/",
          "publishedOn": "2023-07-26T23:42:56.000Z",
          "wordCount": 2608,
          "title": "[P] Clustering approach for multi-dimensional vectors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15akr5t/d_will_techniques_like_rome_replace_existing_fine/",
          "author": null,
          "description": "As progress is made in directly editing the weights responsible for a net's knowledge, do we expect to see such techniques rise in prominence for dine tuning?\n    submitted by    /u/30299578815310  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15akr5t/d_will_techniques_like_rome_replace_existing_fine/",
          "publishedOn": "2023-07-26T23:02:31.000Z",
          "wordCount": 2510,
          "title": "[D] will techniques like ROME replace existing fine tuning methods?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ahrm4/d_hey_everyone_help_me_with_my_machine_learning/",
          "author": null,
          "description": "I'm about to finish learning JavaScript and Python, is there any languages you guys recommend before moving forward if I'm eligible to move forward, then please do share some Beginner friendly YouTube Channels, Articles/Websites or Maybe a free learning platform, Please do help me! I'll be really thankful..\n    submitted by    /u/Samir925  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ahrm4/d_hey_everyone_help_me_with_my_machine_learning/",
          "publishedOn": "2023-07-26T21:05:07.000Z",
          "wordCount": 2531,
          "title": "[D] Hey everyone, help me with my Machine learning journey!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15afpwy/d_starting_machine_learning_with_daily_blogs_need/",
          "author": null,
          "description": "Hey Fellow Machine Learning Enthusiast!I have decided to start my journey to learn Machine Learning with daily blogging the things I learned with the resources so that others can also follow along.\n Need to discuss on how I could improve?\n Hope you find this helpful. Please read this introductory blog for more information.\n https://medium.com/@ugk25880/my-machine-learning-journey-c25648661553\n    submitted by    /u/ugk_01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15afpwy/d_starting_machine_learning_with_daily_blogs_need/",
          "publishedOn": "2023-07-26T19:47:08.000Z",
          "wordCount": 2533,
          "title": "[D] Starting Machine Learning with Daily Blogs! Need Suggestions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15afgh8/p_better_dataset_visualization/",
          "author": null,
          "description": "Most in-browser dataset browsers (e.g. Huggingface, Kaggle) make it hard to star interesting examples, add notes, render complex data types, or drill down on model mispredictions. I've built a number of one-off visualization tools over the years but there's a lot of boilerplate involved that tends to get repeated between these tools.\n We've been working on a dataset + model browser that avoids all the boilerplate and helps ML teams focus on their data instead of tooling. It's meant to be interactive, configurable and collaborative. \n Here's a quick demo showing our current flow: https://youtu.be/utkSCU2ktck \n Would anyone be willing to help beta test or provide suggestions for must-have features for a collaborative dataset browser?\n    submitted by    /u/arkmastermind  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15afgh8/p_better_dataset_visualization/",
          "publishedOn": "2023-07-26T19:37:09.000Z",
          "wordCount": 2590,
          "title": "[P] Better dataset visualization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15af391/can_i_use_feature_importance_for_my_use_case_d/",
          "author": null,
          "description": "Hey, I'm a phd student in compiler optimisations and I might be picking up a project a masters student kicked off. CPUs do a lot of predictions about how code is going to behave as it's executing it, and a major one is branch prediction - whether an if statement is going to be true or false. This masters student recorded the results of every if statement each time they were executed across a large program (this results in millions+ of data points). They then tested the branch prediction accuracy of a transformer model by stepping through this trace of if statement values and having the transformer predict the next one based off only the prior values. They found it actually does a pretty good job! Most of the time the CPU can do this better, but there are cases where it wins out that we're …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15af391/can_i_use_feature_importance_for_my_use_case_d/",
          "publishedOn": "2023-07-26T19:23:31.000Z",
          "wordCount": 2913,
          "title": "Can I use feature importance for my use case? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ae3tp/r_curious_about_causality_and_generative_models/",
          "author": null,
          "description": "📢💡 Ever wondered how we can make our deep generative models respect causal structure? This is key to creating authentic \"what if\" scenarios in our images!\n In our latest research, we deal with high-fidelity image counterfactuals, the generation of images based on \"what if\" scenarios that align with a specified causal graph. 🖼️🔄\n Why is this important? Causality gives us the tools to carry out principled counterfactual inference, which - among other things - is useful for maintaining subject identity in image counterfactuals. 🧩🔍\n Principled counterfactuals of structured variables like images have great potential for:\n (i) Generating causal explanations 🔮\n (ii) Providing targeted data augmentation 🎯\n (iii) Evaluating fairness & robustness 🛡️\n (iv) Protecting your privacy 🕵️‍♀️\n and more...\n ​\n Check out the paper, code, and Huggingface demo! 🚀\n https://arxiv.org/abs/2306.15764\n https://github.com/biomedia-mira/causal-gen\n https://huggingface.co/spaces/mira-causality/counterfactuals\n    submitted by    /u/Majestij  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ae3tp/r_curious_about_causality_and_generative_models/",
          "publishedOn": "2023-07-26T18:45:33.000Z",
          "wordCount": 2616,
          "title": "[R] Curious about Causality and Generative Models? Check out this new Demo!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ae0i4/d_multilingual_open_source_models/",
          "author": null,
          "description": "Is there any open source models that I can fine-tune on data that is not English? Even Llama2 cannot be used for this(not that I've tried it, it's what is says on HuggingFace.)\n I know some other well known languages might work, but I need a model that is specifically made for multilingual usage.\n Or should I just train a model for my specific language from scratch?\n    submitted by    /u/gaybooii  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ae0i4/d_multilingual_open_source_models/",
          "publishedOn": "2023-07-26T18:41:53.000Z",
          "wordCount": 2545,
          "title": "[D] Multilingual Open Source Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ac6zf/d_any_thoughts_on_how_to_improve_runtime_speed/",
          "author": null,
          "description": "I've tried several guide and technique like quantization or trying to utilize multiple GPUs but either the libraries dont work with the model or the model performance is too degraded. Was wondering if people have any thoughts or suggestions?\n name = 'mosaicml/mpt-7b-instruct' config = transformers.AutoConfig.from_pretrained(name, trust_remote_code=True) config.init_device = 'cuda:6' model_name = 'mosaicml/mpt-7b-instruct' model = AutoModelForCausalLM.from_pretrained( model_name, #config=config, trust_remote_code=True, torch_dtype=bfloat16, max_seq_len=512 ) generate_text = transformers.pipeline( model=model, tokenizer=tokenizer, return_full_text=True, task='text-generation', use_fast = True, stopping_criteria=stopping_criteria, temperature=0.0, top_p=0.05, torch_dtype=bfloat16, top_k=0, max_new_tokens=50, repetition_penalty=1.1, device=6 ) \n https://betterprogramming.pub/speed-up-llm-inference-83653aa24c47https://huggingface.co/docs/optimum/bettertransformer/tutorials/convert\n    submitted by    /u/candyman54  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ac6zf/d_any_thoughts_on_how_to_improve_runtime_speed/",
          "publishedOn": "2023-07-26T17:33:41.000Z",
          "wordCount": 2565,
          "title": "[D] Any thoughts on how to improve runtime speed for mosaicml/mpt-7b?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15aaipm/d_best_tools_to_learn_data_science_nowadays/",
          "author": null,
          "description": "Hey guys,\n We're updating our awesome-python-for-data-science repository.\n Some things we're hoping to add:\n  \nBest books and repositories to find resources\n Best open source tools (teaching tools, preferrably free)\n \nBest interactive resources --> especially this one, what are you using nowadays? \n  \nI've heard about Virgilio but feels like TL, DR, we're looking for practice-learning!\n \n  \n   submitted by    /u/CryptographerDry7458  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15aaipm/d_best_tools_to_learn_data_science_nowadays/",
          "publishedOn": "2023-07-26T16:30:32.000Z",
          "wordCount": 2534,
          "title": "[D] Best tools to learn data science nowadays?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15aad3d/d_which_libraries_are_you_using_for_ml/",
          "author": null,
          "description": "Hello dearest community\n I'm trying to get into AI in the scope of training it to play some simple gym games from OpenAi and I've been particularly drawn to Deep Q learning as a starting point (did some basic Q tables ). While trying to inquire into the knowledge of the web I keep finding examples of code that seem simple enough to understand however, whenever I try to use the code it doesn't work. I want to learn to use TensorFlow with Keras but it seems like the syntax regularly gets updated.\n My questions to you all are :\n - Would you recommend Tensorflow/Keras as entry point to AI and NN?\n - Which libraries do you use and which version of those libraries?\n - Furthermore, I keep seeing people use Ubuntu in VB. Is this best practice or can we use Windows 10 in 2023?\n    submitted by    /u/liparch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15aad3d/d_which_libraries_are_you_using_for_ml/",
          "publishedOn": "2023-07-26T16:24:44.000Z",
          "wordCount": 2624,
          "title": "[D] Which libraries are you using for ML?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15a93rz/p_a_complete_guide_to_audio_ml/",
          "author": null,
          "description": "Have you ever wished you had the skills to integrate audio into your machine learning workflows? Or wondered how your phone is able to transcribe exactly what you said? 🤔\n Look no further! Hugging Face 🤗 recently announced the Transformers Audio Course, a comprehensive guide to using the latest machine learning techniques for the most popular audio tasks.\n In this course, you'll gain an understanding of the specifics of working with audio data, learn about different transformer architectures, and train your own audio transformers, leveraging powerful pre-trained models for real-world tasks 🚀\n This course is designed for learners with a background in deep learning, and general familiarity with Transformers. No expertise in audio data processing is required.\n The course is lightweight and easy to follow, with plenty of diagrams to aid your learning. Not only does it teach you the underlying theory behind audio ML, but provides you with all the skills you need to put it practice, with code samples and quizzes to check your understanding along the way:\n Example page from the audio course: learn exactly what a log-mel spectrogram is!\n By the end of the course, you'll be armed with all the skills you need to tackle the most popular audio tasks, including audio classification, speech recognition, and text-to-speech. You'll also be part of one of the largest open-source audio communities, where you can discuss and take-on any new audio models that are released 🤝\n Getting Started\n Head to the course page to start your audio journey: https://huggingface.co/learn/audio-course/chapter0/introduction\n If you complete the four assessments by September 1st 2023, you'll be awarded with a certificate of completion 💫\n Join our Discord community to get expert help on any of these topics: http://hf.co/join/discord\n    submitted by    /u/sanchitgandhi99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15a93rz/p_a_complete_guide_to_audio_ml/",
          "publishedOn": "2023-07-26T15:36:44.000Z",
          "wordCount": 2765,
          "title": "[P] A Complete Guide to Audio ML 📚",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15a8oxr/d_sorry_if_this_is_a_noob_question_how_can_i_tell/",
          "author": null,
          "description": "Building my first PC, it'll have an i9 13900k and an RTX 4090. How can I tell what size chatbot I can install and run locally? Trial and error? Or is there some kind of guide out there I'm unaware of?\n    submitted by    /u/sillygooseboy77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15a8oxr/d_sorry_if_this_is_a_noob_question_how_can_i_tell/",
          "publishedOn": "2023-07-26T15:20:41.000Z",
          "wordCount": 2535,
          "title": "[D] Sorry if this is a noob question: How can I tell what size AI chatbot model I can run locally?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15a8jqy/d_leveraging_time_series_forecasting_for/",
          "author": null,
          "description": "Hi folks, \n I've been recently diving into the intersection of time series forecasting and changepoint detection (CPD) methodologies. I understand the utility of CPD in improving forecasts by identifying structural breaks in time series data, but I've noticed a lack of emphasis in the literature on the reverse - using forecasting models to inform CPD.\n One might think a straightforward approach could be using an ARIMA model (or any other forecasting model) and leveraging the forecast error by comparing it to the real values. In theory, if the forecast error crosses a certain threshold, it might indicate a changepoint.\n However, I also understand the complications this approach might bring:\n  \nStationarity Assumptions: ARIMA and similar models are built on the assumption that the data are stationary. A sudden changepoint could violate this assumption, leading to model misspecification and thus larger errors.\n Defining Large Errors: Establishing a fixed threshold to define a 'large' error might be problematic in practice due to time-varying variance and other dynamics.\n Error Dependencies: Forecast errors are typically not independent but form an error process. A large error might be part of a larger trend or cycle, and thus might not necessarily indicate a changepoint.\n  \nSo while these obstacles seem substantial, I'm curious if anyone has any experience or knowledge in effectively employing forecasting models for CPD, or if there are research efforts or methodologies I may not be aware of. Looking forward to hearing your thoughts and engaging in some fruitful discussions!\n    submitted by    /u/BeerBoozeBiscuits  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15a8jqy/d_leveraging_time_series_forecasting_for/",
          "publishedOn": "2023-07-26T15:15:03.000Z",
          "wordCount": 2729,
          "title": "[D] Leveraging Time Series Forecasting for Changepoint Detection: Perspectives and Pitfalls?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15a7thl/d_how_to_actually_do_the_final_ppo_with_a_reward/",
          "author": null,
          "description": "Hi,\n I want to get hands-on with the RLHF pipeline. I found an online reward model that can be potentially used https://huggingface.co/OpenAssistant/reward-model-deberta-v3-large-v2 \n One thing that's unclear is how can I use this model for fine-tuning something like GPTNeoX-20B? My end goal is currently just a one-shot answering model (not necessarily a chat)\n    submitted by    /u/Emergency_Apricot_77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15a7thl/d_how_to_actually_do_the_final_ppo_with_a_reward/",
          "publishedOn": "2023-07-26T14:46:21.000Z",
          "wordCount": 2539,
          "title": "[D] How to actually do the final PPO with a reward model in RLHF?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15a6y4f/d_is_it_always_better_to_have_more_examples_in/",
          "author": null,
          "description": "I’m working with Llama to use details from a string to generate a dictionary. \n Str = ‘My name is Brian’ Dict = {“name”: “Brian”}\n I’m using few shot learning process and providing the model with examples to learn from. The model performs fairly okay but it needs to be better.\n Is it always a good thing to add a lot of examples like 100 string/dict pair examples for the model to learn from or is this one of those things in stats/machine learning that the obvious isn’t always the best choice lol?\n I’d appreciate any advice please.\n    submitted by    /u/brianomars1123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15a6y4f/d_is_it_always_better_to_have_more_examples_in/",
          "publishedOn": "2023-07-26T14:11:29.000Z",
          "wordCount": 2583,
          "title": "[D] is it always better to have more examples in few shot learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15a6y2q/d_speaker_recognition_including_unknown_speakers/",
          "author": null,
          "description": "Hi, i wanted to modify this Speaker recognition (not speech recognition) example by keras by recognizing when an unknown speaker is speaking.\n So the network needs to be able to tell which of the speakers is talking, and if none of them is talking, it needs to say that none of them is talking.\n I don't mean if there is silence, because then it would be enough to train the network to recognize silence, I mean just if a speaker who is not in the set is speaking.\n For what i think I can extend this problem to it will be like to recognize if an image is not part of the mnist dataset.\n    submitted by    /u/giggiox  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15a6y2q/d_speaker_recognition_including_unknown_speakers/",
          "publishedOn": "2023-07-26T14:11:25.000Z",
          "wordCount": 2593,
          "title": "[D] speaker recognition including unknown speaker(s)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15a4136/d_how_do_people_track_their_machine_learning/",
          "author": null,
          "description": "Hello!\n I'm curious to know how you guys currently track changes and general information for your ML/DL models. \n By changes, I'm referring to parameters, accuracy/loss, functions your model uses, training data etc across different versions of your models.\n By general changes, I'm referring to descriptions of what the model does, code changes, tags and so on.\n I'm under the impression most people are using MLFlow, W&Bs etc which I guess is fine but I'm finding that these tools treat models as static files, as second-class citizens which is annoying when I want to zero in on a model and understand what and how something was changed away from an experiment. This gets really annoying when I'm looking at model version 134 created by Mike in the other team.\n Curious to know how people are tracking models and what they think generally about model tracking. Thanks!\n    submitted by    /u/bobskithememe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15a4136/d_how_do_people_track_their_machine_learning/",
          "publishedOn": "2023-07-26T12:07:22.000Z",
          "wordCount": 2627,
          "title": "[D] How do people track their machine learning models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15a3lw1/r_how_can_i_produce_embeddings_for_text_inputs/",
          "author": null,
          "description": "If I have the model saved as .ckpt file, what are the steps for extracting the embeddings for text input? I’m trying to use a pretrained custom model but don’t quite understand how to work with transformer model file in *.ckpt form. Would really appreciate any suggestions.\n    submitted by    /u/Urusander  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15a3lw1/r_how_can_i_produce_embeddings_for_text_inputs/",
          "publishedOn": "2023-07-26T11:48:25.000Z",
          "wordCount": 2534,
          "title": "[R] How can I produce embeddings for text inputs from a pretrained transformer model?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15a22jv/d_vector_database_benchmarking/",
          "author": null,
          "description": "Is there a way in which i can calculate the precision scores of a vector database. I need to do benchmarking on milvus and elasticsearch on a custom dataset. Any help would be appreciated.\n    submitted by    /u/adiraat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15a22jv/d_vector_database_benchmarking/",
          "publishedOn": "2023-07-26T10:35:41.000Z",
          "wordCount": 2511,
          "title": "[D] Vector database benchmarking",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15a2060/p_any_good_models_on_huggingface_for_specific/",
          "author": null,
          "description": "hi was wondering if there are any lightweight models which I can download from huggingface for fine tuning for my use case. I'm trying to build a model which takes a paragraph of data and certain instructions to get parts of the data in json format as the output.\n    submitted by    /u/Right-Type-3210  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15a2060/p_any_good_models_on_huggingface_for_specific/",
          "publishedOn": "2023-07-26T10:32:06.000Z",
          "wordCount": 2534,
          "title": "[P] Any good models on huggingface for specific text generation use case?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159v4d3/transformers_for_recommender_systems_d/",
          "author": null,
          "description": "Been involved in a research project of a session based recommendation systems , where we have a historical purchases of users and the goal is to predict the next going to be purchased item. Given this and assuming that we have somehow represented each item in a session as an embedding and these embeddings acts as an input to the transformer model and the output is an embedding of the next product. In the train set, there are some millions sessions which has both previous purchases products of arbitrary length and next item. So the transformer is trained with supervised loss of predicted and actual next item embedding, the problem i have been facing is that the loss is saturating and there is not much learning over time. Any suggestions on how to improve this. Tried increasing the number of layers and did some hyper tuning corresponding to learning rate and weight decay but similar behaviour is observed.\n    submitted by    /u/Acceptable-Mix-4534  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159v4d3/transformers_for_recommender_systems_d/",
          "publishedOn": "2023-07-26T04:12:09.000Z",
          "wordCount": 2636,
          "title": "Transformers for Recommender Systems. [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159uqbm/r_generating_datasets_to_better_finetune_llms/",
          "author": null,
          "description": "https://github.com/discus-labs/discus\n    submitted by    /u/innovating_ai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159uqbm/r_generating_datasets_to_better_finetune_llms/",
          "publishedOn": "2023-07-26T03:53:24.000Z",
          "wordCount": 2481,
          "title": "[R] generating datasets to better fine-tune LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159t1bi/r_monarch_mixer_revisiting_bert_without_attention/",
          "author": null,
          "description": "https://hazyresearch.stanford.edu/blog/2023-07-25-m2-bert\n    submitted by    /u/hzj5790  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159t1bi/r_monarch_mixer_revisiting_bert_without_attention/",
          "publishedOn": "2023-07-26T02:31:47.000Z",
          "wordCount": 2483,
          "title": "[R] Monarch Mixer: Revisiting BERT, Without Attention or MLPs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159mafd/web_content_embedding_transformer_lambda_function/",
          "author": null,
          "description": "Hi all!\n I'd would like to share a simple, straight-forward Web Content Embedding Transformer lambda function to create and store embeddings of web content. This is a Lambda function that scrapes for URLs, then uses URLs those to scrape for page content, which it splits into chunks then transforms to embedding using OpenAI. It then stores the embeddings to your Pinecone DB including metadata. You can then use the embedding for custom chatbots etc.\n Heres a link to a public REPO.\n https://github.com/i-dream-of-ai/lambda-webpage-vector-store\n pull requests welcome! Please star the repo if you like it or use it!\n    submitted by    /u/Jealous_Buyer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159mafd/web_content_embedding_transformer_lambda_function/",
          "publishedOn": "2023-07-25T21:51:45.000Z",
          "wordCount": 2574,
          "title": "Web Content Embedding Transformer lambda function [Project]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159kl05/deep_learning_for_regression_and_target_scaling_d/",
          "author": null,
          "description": "I tried scaling the target variable to be in the range (0,1) and trained the model using a sigmoid in the last layer. But when rescaled back after prediction on test, the errors are too high. What can be done? \n Do I need to scale in the first place? \n Also please answer this general question: How to get a Deep learning model to work well on Regression tasks?\n    submitted by    /u/Charming-Witness-286  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159kl05/deep_learning_for_regression_and_target_scaling_d/",
          "publishedOn": "2023-07-25T20:48:56.000Z",
          "wordCount": 2549,
          "title": "Deep learning for Regression and Target scaling [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159kgie/p_freelow_cost_inference_endpoint/",
          "author": null,
          "description": "I want to create a small project as hobby in which the web app posts some user data to an endpoint hosting a model that returns its predictions. \n So I was wondering if there’s a platform that hosts models for free for hobbists? \n The idea is to build a simple portfolio project just to display to recruiters.\n    submitted by    /u/OkYak2915  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159kgie/p_freelow_cost_inference_endpoint/",
          "publishedOn": "2023-07-25T20:44:31.000Z",
          "wordCount": 2535,
          "title": "[P] Free/Low cost inference endpoint",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159hy5x/aaron_parisi_google_deepmind_will_join_the_open/",
          "author": null,
          "description": "Hi AI enthusiasts! This Thursday Aaron Parisi, Google DeepMind researcher, will join us to present and discuss his recent work as the lead author of TALM, a framework for augmenting language models with arbitrary tools.\n Free RSVP: https://lu.ma/mw5ppi46\n Paper: https://arxiv.org/abs/2205.12255\n 🗓 July 27th (Thursday) at 17:00 GMT+1\n 📍 Zoom\n 👥 Members of the international AI4Code research community\n Hope to see you there!\n The AI4Code meetup community consists of like-minded researchers from around the world that network, discuss and share their latest research on AI applications on source code.\n    submitted by    /u/dritsakon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159hy5x/aaron_parisi_google_deepmind_will_join_the_open/",
          "publishedOn": "2023-07-25T19:14:35.000Z",
          "wordCount": 2579,
          "title": "Aaron Parisi (Google DeepMind) will join the open AI4Code reading group this Thursday (July 27th) to talk about his latest research [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159h565/project_quality_assurance_platform_for_machine/",
          "author": null,
          "description": "Hello world 👋\n We're developing an open-source & collaborative testing framework for ML models, from tabular to LLMs: https://github.com/Giskard-AI/giskard\n Testing Machine Learning applications can be tedious. Since ML models depend on data, testing scenarios depend on the domain specificities and are often infinite.\n Where to start testing? Which tests to implement? What issues to cover? How to implement the tests?\n At Giskard, we believe that Machine Learning needs its own testing framework. Created by ML engineers for ML engineers, Giskard contains 2 components:\n  \nThe Giskard Python library helps data scientists detect hidden vulnerabilities in ML models. \n It makes the AI development process more efficient, by automating the identification of risks of biases, performance issues and errors.\n To try it, see this documentation: https://docs.giskard.ai/en/latest/guides/scan/index.html\n \n The Giskard server helps ML engineers debug & monitor models, share dashboards, and collaborate. \n It makes the deployment of new ML models safer and more efficient, by providing ready-made monitoring dashboards, catalogs of re-usable testing components, and ML debugging interfaces.\n To try it, see this documentation: https://docs.giskard.ai/en/latest/guides/installation_app/index.html\n \n  \nWe released our v2 in Beta last month, and we're very interested in your feedback as QA engineers!\n    submitted by    /u/alteralec  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159h565/project_quality_assurance_platform_for_machine/",
          "publishedOn": "2023-07-25T18:46:02.000Z",
          "wordCount": 2667,
          "title": "[Project] Quality Assurance platform for Machine Learning models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159gq7j/r_towards_provably_efficient_quantum_algorithms/",
          "author": null,
          "description": "https://arxiv.org/abs/2303.03428\n ​\n If you're interested in trying out quantum machine learning on NVIDIA A100s or V100s with cuquantum and pennylane GPUs for free please fill out the following form\n    submitted by    /u/Neu3ral  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159gq7j/r_towards_provably_efficient_quantum_algorithms/",
          "publishedOn": "2023-07-25T18:30:44.000Z",
          "wordCount": 2511,
          "title": "[R] Towards provably efficient quantum algorithms for large-scale machine-learning models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159eddu/fixed_size_1d_sequence_to_fixed_size_2d_sequence/",
          "author": null,
          "description": "Hello everyone, I have this problem where I have a 1D sequence of numbers of length 3 like this: \n [1,50,500], with 35 distinct combinations.\n I need to map it to 2D sequence of number of 1024 length. Like this : \n [ [ 23.78, 234, 13,…n], [ 234,76.9, 763,…n ]] , where n =1024.\n Is it possible in ML to do so?\n The 2D sequence can paired ( can be represented an image). \n Thank you very much !\n    submitted by    /u/Beginner4ever  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159eddu/fixed_size_1d_sequence_to_fixed_size_2d_sequence/",
          "publishedOn": "2023-07-25T17:05:29.000Z",
          "wordCount": 2560,
          "title": "Fixed size 1D sequence to fixed size 2D sequence prediction.[p]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159cz1g/d_what_datasets_do_you_dream_of_having_for_your/",
          "author": null,
          "description": "Acquiring data to build models can truly be a pain. I am curious to know about the datasets you folks are looking for, to the extent that you would even consider paying for them or sacrifice your newborn baby. By extension, tell us about the project(s) you've been working on and how the data would help! \n    submitted by    /u/nobilis_rex_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159cz1g/d_what_datasets_do_you_dream_of_having_for_your/",
          "publishedOn": "2023-07-25T16:14:35.000Z",
          "wordCount": 2541,
          "title": "[D] What datasets do you dream of having for your ML/NLP project(s)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/159chrs/d_tool_for_mlai_sorting_for_50000_icloud_photos/",
          "author": null,
          "description": "One of my acquaintances is an artist and is asking my assistance in utilizing Machine Learning and AI to sort his entire iCloud library of 57,000 images into 300+ categories. Some of these categories include things that the media is made of such as ceramics wood, or the artist that created this work while other categories include whether the photo contains an animal or a person. \n I am wondering if there are specific ML programs that would be a good fit for his situation. My idea suggested to use Apple’s CoreML which I have experience in. I could develop him an app that he could then create train and swap image recognition models using the GUI CreateML tool using the images he has already sorted. Do you think this is the best approach or is there another tool out there that could do this task for him easily?\n    submitted by    /u/Jpderouin310  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/159chrs/d_tool_for_mlai_sorting_for_50000_icloud_photos/",
          "publishedOn": "2023-07-25T15:57:17.000Z",
          "wordCount": 2633,
          "title": "[D] Tool for ML/AI Sorting for 50,000 iCloud Photos into 300+ categories",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1599e23/d_autonomous_alignment_oversight_framework_aaof/",
          "author": null,
          "description": "Abstract:\n To align advanced AIs, an ensemble of diverse, transparent Overseer AIs will independently monitor the target AI and provide granular assessments on its alignment with constitution, human values, ethics, and safety. Overseer interventions will be incremental and subject to human oversight. The system will be implemented cautiously, with extensive testing to validate capabilities. Alignment will be treated as an ongoing collaborative process between humans, Overseers, and the target AI, leveraging complementary strengths through open dialog. Continuous vigilance, updating of definitions, and contingency planning will be required to address inevitable uncertainties and risks.\n Introduction: \n As advanced AI systems grow in capability and autonomy, ensuring their alignment with hum…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1599e23/d_autonomous_alignment_oversight_framework_aaof/",
          "publishedOn": "2023-07-25T14:01:24.000Z",
          "wordCount": 3709,
          "title": "[D] Autonomous Alignment Oversight Framework (AAOF)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1598yvi/d_does_gpt4_use_lora/",
          "author": null,
          "description": "I just watched a video that explains how LoRA works. As I understand it's a fast and efficient way to fine tune models.\n At the end of the video he he said you could easily swap out the fine-tuned LoRA. So it makes LLMs like a PC. You just install new software / add the finetuned lora weights and you're good to go. Is my understanding correct?\n The rumor is that GPT-4 is a 8 way mixture model. Could they have pretrained it with all the data and then just use LoRA to train the expert models? I guess they would also need to train a smaller model that decides which model to use. I can't imagine that they would train GPT-4 eight times / once for each expert models.\n    submitted by    /u/StraightChemistry629  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1598yvi/d_does_gpt4_use_lora/",
          "publishedOn": "2023-07-25T13:44:33.000Z",
          "wordCount": 2608,
          "title": "[D] Does GPT-4 use LoRA?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1596pnm/d_deep_learning_vs_xgboost_for_tabular_data_a/",
          "author": null,
          "description": "Once per year, I write a post here on Reddit about our projects on deep learning for tabular data, and I hope this year will be no exception 🙂 Meanwhile, I have shared some results where we compare models from our previous papers with XGBoost on the datasets from the recent paper \"Why do tree-based models still outperform deep learning on typical tabular data?\". For us, this benchmark is a new one, so it was really interesting to check whether our previous findings generalize to new unseen datasets (spoiler: they do):\n https://twitter.com/YuraFiveTwo/status/1683796380895023104\n    submitted by    /u/Yura52  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1596pnm/d_deep_learning_vs_xgboost_for_tabular_data_a/",
          "publishedOn": "2023-07-25T12:11:03.000Z",
          "wordCount": 2576,
          "title": "[D] Deep Learning VS XGBoost for tabular data: a quick test",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1595xd8/discussion_how_good_is_generative_data_synthetic/",
          "author": null,
          "description": "5% average increase in F1 score\n 67% increase in Data richness\n 100% anonymized data set\n so one of the users on my tool milkstraw.ai just sent me this and i am really excited about the power of the tool i built and wanted to share it here 🚀\n Also more importantly how do you all feeling about synthetic data, I started this as a fun project and its turning into a full blown startup. I love seeing some of the users send me results they are getting like this. \n https://preview.redd.it/24bwer0uk3eb1.png?width=4516&format=png&auto=webp&s=c8cbf906580a04df1f967c5300478a542128ccd0\n    submitted by    /u/jjhazy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1595xd8/discussion_how_good_is_generative_data_synthetic/",
          "publishedOn": "2023-07-25T11:35:06.000Z",
          "wordCount": 2568,
          "title": "[Discussion] How good is generative data (synthetic data) !?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1595rc0/r_new_open_source_llm_goat7b_sota_among_the_7b/",
          "author": null,
          "description": "Go try this free model. 7B SOTA by MMLU and BBH\n https://preview.redd.it/tq8c8ggaj3eb1.png?width=1570&format=png&auto=webp&s=10c78b724da2d6360e7c7ee6fbe3175c36cecc26\n    submitted by    /u/rempact  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1595rc0/r_new_open_source_llm_goat7b_sota_among_the_7b/",
          "publishedOn": "2023-07-25T11:27:07.000Z",
          "wordCount": 2495,
          "title": "[R] New Open Source LLM: GOAT-7B (SOTA among the 7B models)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1594zb4/d_attention_is_off_by_one/",
          "author": null,
          "description": "https://www.evanmiller.org/attention-is-off-by-one.html\n    submitted by    /u/duckyzz003  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1594zb4/d_attention_is_off_by_one/",
          "publishedOn": "2023-07-25T10:50:16.000Z",
          "wordCount": 2480,
          "title": "[D] Attention Is Off By One",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1594y3c/voice_cloning_options_preferably_local_d/",
          "author": null,
          "description": "Hi!\n What voice cloning options are people using right now? Looking at what is out there (that I know of), there is ElevenLabs and Coqui. Are there any other ones that are good? Preferably cheap/run locally?\n    submitted by    /u/MrJabbey1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1594y3c/voice_cloning_options_preferably_local_d/",
          "publishedOn": "2023-07-25T10:48:33.000Z",
          "wordCount": 2515,
          "title": "Voice cloning options, preferably local [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158zr4i/p_integrating_llama_v2_and_multichat_models_open/",
          "author": null,
          "description": "IntelliNode is an open source project that simplifies the integration of Llama V2 and other multi-chat models. With IntelliNode, you can easily connect and switch between different language models, including Llama V2 hosted in your AWS SageMaker account.\n It allows you to create a chatbot instance and add the backend provider.\n const { Chatbot, LLamaSageInput, SupportedChatModels } = require('intellinode'); const chatbot = new Chatbot(key, SupportedChatModels.SAGEMAKER, {url: <your-sagemaker-endpoint>}); \n For details on how to use intellinode to integrate with LLama SageMaker setup click here.\n The module available here.\n ​\n ​\n    submitted by    /u/Barqawiz_Coder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158zr4i/p_integrating_llama_v2_and_multichat_models_open/",
          "publishedOn": "2023-07-25T06:19:45.000Z",
          "wordCount": 2572,
          "title": "[P] Integrating Llama V2 🦙 and Multi-Chat Models: Open Source Solution with IntelliNode",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158z1eo/research_transformer_models_for_drug_discovery/",
          "author": null,
          "description": "Does anybody know of good/reputable literature and other resources to read/learn about incorporating transformers in drug discovery? I am doing some computational chemistry research regarding compound identification for HBV mutations and want to try using transformers but don't really know where/how to start.\n    submitted by    /u/Present_Network1959  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158z1eo/research_transformer_models_for_drug_discovery/",
          "publishedOn": "2023-07-25T05:41:31.000Z",
          "wordCount": 2522,
          "title": "[Research] transformer models for drug discovery",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158ybd6/d_annotation_tool_for_annotating_audio_in_a_video/",
          "author": null,
          "description": "Does anyone know of a good video (or audio) annotation tool that would allow me to look at both the image and the audio waveform at the same time?\n I could extract the audio and use an audio annotation tool, but since some of the sound events may sound similar to one another, it would be helpful to look at both the image and the audio waveform to identify which class a sound event belongs to. Thanks!\n    submitted by    /u/utility2000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158ybd6/d_annotation_tool_for_annotating_audio_in_a_video/",
          "publishedOn": "2023-07-25T05:03:40.000Z",
          "wordCount": 2559,
          "title": "[D] Annotation tool for annotating audio in a video",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158svz6/p_feedback_hey_i_am_lunching_my_data/",
          "author": null,
          "description": "Hey all Redditors,\n  \nI have been thinking about this for years as I hate the cumbersome process of switching jobs.\n I have been planing it under the last year and finally I quit my job and built this in the last 1.5 months.\n I am lunching my Data Professionals job platform \"applyscript dot com\"\n I would like to receive some feedback from you guys.\n I really want to hear your opinion as that can help me improve the site a lot.\n  \nThx for stopping by and giving feedback, I really appreciate your time and effort. :)\n    submitted by    /u/glassAlloy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158svz6/p_feedback_hey_i_am_lunching_my_data/",
          "publishedOn": "2023-07-25T00:55:28.000Z",
          "wordCount": 2593,
          "title": "[P] FEEDBACK - Hey I am lunching my Data Professionals job platform and I would like to receive some feedback from you guys, thx",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158rddr/externally_mounting_p100_gpu_d/",
          "author": null,
          "description": "I made a mistake and bought a GPU that is not compatible with my motherboard. I found a P100 for $300 on ebay and bought it, but didn't research far enough to figure out that it isn't designed for a workstation motherboard. Is there any way I can externally mount it without spending tons on a GPU server? I am not sure just a PCIe riser will do the trick, since the GPU draws 250W and will also need a cooling system.\n Is it over?\n    submitted by    /u/jankybiz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158rddr/externally_mounting_p100_gpu_d/",
          "publishedOn": "2023-07-24T23:51:35.000Z",
          "wordCount": 2563,
          "title": "Externally mounting P100 GPU [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158r1il/r_how_do_paper_authors_deal_with_takedown_requests/",
          "author": null,
          "description": "Datasets like FFHQ consist of face images crawled from the Internet. While those images are published under CC licenses, the authors usually have not obtained consent from each person depicted in those images. I guess that's why they are taking takedown requests: People can send requests to remove their faces from the dataset.\n However, I'm always confused about one thing: Some faces images are already used in the paper. If those people request takedown of their images, wouldn't that result in a withdrawl of the paper? Or is there any \"fair use\" statement that can prevent this from happening?\n    submitted by    /u/alex000092  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158r1il/r_how_do_paper_authors_deal_with_takedown_requests/",
          "publishedOn": "2023-07-24T23:37:59.000Z",
          "wordCount": 2581,
          "title": "[R] How do paper authors deal with takedown requests?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158nkvt/d_do_you_guys_think_the_daytoday_tasks_of_ml/",
          "author": null,
          "description": "Gone will be the days of data pre-processing, feature engineering, model training and model validation? What will we end up spending most of our time doing?\n    submitted by    /u/DM_ME_YOUR_CATS_PAWS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158nkvt/d_do_you_guys_think_the_daytoday_tasks_of_ml/",
          "publishedOn": "2023-07-24T21:23:47.000Z",
          "wordCount": 2517,
          "title": "[D] Do you guys think the day-to-day tasks of ML engineers will change with the emergence of LLM’s?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158ld7w/p_code_search_infra_for_an_ai_junior_developer/",
          "author": null,
          "description": "As we’re developing Sweep, our open-source AI junior developer, we implemented a new architecture for our vector search database.\n We decided on two main goals for our code search infrastructure:\n  \nThe search index needs to be up to date. Code is unique from other types of content in that it requires high levels of consistency. You wouldn’t want to reference an old version of a function(say two git commits back) while writing something that uses it.\n For additional security, we don’t want to store the code as plaintext. However, we still need a way to map the original code to the embeddings.\n  \nEfficient Indexing\n Problem:\n We wanted to store multiple repositories in a scalable manner without relying on a hosted vector database like Pinecone.\n Insight:\n Repositories change frequently but …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158ld7w/p_code_search_infra_for_an_ai_junior_developer/",
          "publishedOn": "2023-07-24T20:03:54.000Z",
          "wordCount": 3035,
          "title": "[P] Code Search Infra for an AI junior developer - that doesn't store code",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158lbfs/d_do_you_guys_worry_ml_work_will_become_less/",
          "author": null,
          "description": "I’m already doing work that involves creating prompts for LLM’s. I adore cleaning data and training models and worry that ML solutions will soon become asking chatbots to do what you want in plain English, and all this time I’ve spent learning about how ML is done on a technical level will just be auxiliary literature that doesn’t help me in my profession. What will our expertise move to? Being able to ask a chatbot the right questions? \n How will our profession change?\n    submitted by    /u/DM_ME_YOUR_CATS_PAWS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158lbfs/d_do_you_guys_worry_ml_work_will_become_less/",
          "publishedOn": "2023-07-24T20:02:07.000Z",
          "wordCount": 2572,
          "title": "[D] Do you guys worry ML work will become less technical and reduced to prompt engineering",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158je9i/p_multi_label_text_classification_question/",
          "author": null,
          "description": "Dear community\n I am currently despairing of a school project.\n The task is to develop a text classifier. So far so good. The problem is that I have a dataset with 200k texts that are not labeled. These should be classified to 190 classes, which are additionally very domain specific. However, several classes could also apply to one text.\n Does anyone know a good approach how to approach this?\n I have already determined 10 keywords for each class. But I don't know how to proceed now.\n It would be very nice if someone could help me. Gladly also only by buzzwords.\n Many greetings\n    submitted by    /u/loopingmadders  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158je9i/p_multi_label_text_classification_question/",
          "publishedOn": "2023-07-24T18:53:19.000Z",
          "wordCount": 2583,
          "title": "[P] multi label text classification question 🙋‍♂️",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158ies6/d_p_looking_for_feedback_on_opensource_project/",
          "author": null,
          "description": "Happy Monday Everyone! 😃\n I am looking for feedback on the open source project Cephalon! Cephalon is a framework for building machine-learning applications. It aims to be similar to Django. Django is a batteries included framework for building backend of a website, and Cephalon is a batteries included framework for building Machine Learning applications in Rust. I want to get feedback from you because, I want to make building machine-learning apps easier for any new-comers. I think with a solid framework, they can focus more on the core concepts, rather than DevOps or MLOps. \n There is a survey you can fill out here\n Or message me if you want to discuss more! \n You can find the original project here\n Or find it on crates.io here\n I hope you have an amazing rest of the week! 😁 Thank you in advance for any feedback!!\n    submitted by    /u/GoodUnderstanding728  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158ies6/d_p_looking_for_feedback_on_opensource_project/",
          "publishedOn": "2023-07-24T18:17:38.000Z",
          "wordCount": 2625,
          "title": "[D] [P] Looking for feedback on open-source project Cephalon",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158icwc/p_d_looking_for_feedback_on_opensource_project/",
          "author": null,
          "description": "Happy Monday Everyone! 😃\n I am looking for feedback on the open source project Cephalon! Cephalon is a framework for building machine-learning applications. It aims to be similar to Django. Django is a batteries included framework for building backend of a website, and Cephalon is a batteries included framework for building Machine Learning applications in Rust. I want to get feedback from you because, I want to make building machine-learning apps easier for any new-comers. I think with a solid framework, they can focus more on the core concepts, rather than DevOps or MLOps. \n There is a survey you can fill out here\n Or message me if you want to discuss more! \n You can find the original project here\n Or find it on crates.io here\n I hope you have an amazing rest of the week! 😁 Thank you in advance for any feedback!!\n    submitted by    /u/GoodUnderstanding728  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158icwc/p_d_looking_for_feedback_on_opensource_project/",
          "publishedOn": "2023-07-24T18:15:45.000Z",
          "wordCount": 2625,
          "title": "[P] [D] Looking for feedback on Open-Source Project Cephalon",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158h4d6/d_install_tensorflowgpu/",
          "author": null,
          "description": "Hello everyone. Please, help me. How to install tensorflow-gpu on Windows? Because I tried a lot of times and nothing. Maybe you have some micro moments that need to know. Thank you.\n    submitted by    /u/pavich_03  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158h4d6/d_install_tensorflowgpu/",
          "publishedOn": "2023-07-24T17:28:43.000Z",
          "wordCount": 2508,
          "title": "[D] Install tensorflow-gpu",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158e6pu/p_a_mathematical_model_of_music/",
          "author": null,
          "description": "We have developed a model of music based on statistical mechanics and Euler’s gradus suavitatis, which seems to provide some new insights into tonal music. A description of the model is given on our website: tonamic.com. We are interested in collaboration opportunities, especially with ML researchers.\n    submitted by    /u/Tonamic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158e6pu/p_a_mathematical_model_of_music/",
          "publishedOn": "2023-07-24T15:40:56.000Z",
          "wordCount": 2525,
          "title": "[P] A mathematical model of music",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158d337/discussion_how_many_runsiterations_do_you/",
          "author": null,
          "description": "Between HP tuning, explorations, and refinement how many iterations do you typically have when working on a model? I see some that have only a few like 40 but some have 1000s. \n Also curious how everyone keeps the diff iterations organized (naming, tags?)\n    submitted by    /u/fromalanjones  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158d337/discussion_how_many_runsiterations_do_you/",
          "publishedOn": "2023-07-24T14:59:14.000Z",
          "wordCount": 2527,
          "title": "[Discussion] How many runs/iterations do you typically have in one \"project'?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158d069/pd_a_toolkit_to_make_your_unstructured_datasets/",
          "author": null,
          "description": "Hey r/machinelearning, I’m Dean from DagsHub. I wanted to share something we’ve been working on really hard for a while, and hopefully get some community feedback.\n TL;DR\n We’re releasing Data Engine – a new set of tools that helps machine learning practitioners, collect and manage unstructured data, visualize it, send it to annotation, and turn it into a data loader for training. I wanted to share our reasons for building it and the challenges it solves and hopefully spark a discussion. You can check out the full launch blog here: dagshub.com/blog/launching-data-engine-toolset-for-unstructured-datasets/\n Data Engine Flow\n Sorry for the long post – I wanted to share our considerations for building this toolkit, and hopefully spark a discussion about your processes for iterating on datasets…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158d069/pd_a_toolkit_to_make_your_unstructured_datasets/",
          "publishedOn": "2023-07-24T14:56:07.000Z",
          "wordCount": 3250,
          "title": "[P][D] A toolkit to make your unstructured datasets better",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158butr/d_ai_regulation_is_mostly_pointless_and_didnt/",
          "author": null,
          "description": "WormGPT is a criminal AI. It’s something that enables crime versus something like offensive jokes like 4chanGPT. EU and China pumped out all this regulation thinking they were ahead of the world when in all reality it’s freaking backwards.\n If AI was a physical commodity like goods and services, yes regulation is effective. However AI regulation is just won’t stop bad actors. The law already covers most of the dangers involved.\n Trying to regulate AI models is like trying to regulate piracy. We need to regulate the people, not the technology. \n Disinformation campaigns? Nail them for libel. Creating a model designed solely to enable crime? Nail the people for the crimes they are doing. Nail them for possessing criminal tools. \n People are easier to regulate than specifics on AI that’s easy to self replicate. Especially considering companies going to lobby their business interest. \n This is my opinion on the criminal AI, what about yours? (This model may also be using LLama weights considering it’s generations and timing)\n Source:\n https://fagenwasanni.com/news/the-dangers-of-wormgpt-an-ai-model-for-malicious-activities/68834/\n    submitted by    /u/I_will_delete_myself  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158butr/d_ai_regulation_is_mostly_pointless_and_didnt/",
          "publishedOn": "2023-07-24T14:12:42.000Z",
          "wordCount": 2657,
          "title": "[D] AI regulation is mostly pointless and didn’t stop a recent bad actor like WormGPT.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/158bnwy/p_beer_inspector_ai_how_computer_vision_can_help/",
          "author": null,
          "description": "Hey there, fellow Computer Vision enthusiasts! 🤖👋\n On their quest to find the perfect beer our team of Czech Computer Vision and AI experts developed a solution that takes certain visual indicators of the perfect beer into account and applies Computer Vision to detect these.\n So, what are these visual indicators that determine the perfect pint? Let's dive in! First up, we have the \"beer ratio.\" Each brand has its own glass, and the beer should be drafted within specific markings. Whether it's a single line or a range between logo points, Beer Inspector ensures you get what you paid for! No more guessing about your beer's quantity. 📏\n Next, we have the \"beer head structure.\" This is crucial for the ultimate beer experience. Airtight, thick, and no air bubbles – that's the way to go! Beer…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/158bnwy/p_beer_inspector_ai_how_computer_vision_can_help/",
          "publishedOn": "2023-07-24T14:05:36.000Z",
          "wordCount": 3329,
          "title": "[P] Beer Inspector AI: How Computer Vision can help to identify the perfect brew",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15851sr/d_how_do_i_reduce_llm_inferencing_time/",
          "author": null,
          "description": "I am running text inferencing on Llama2-7b through langchain. I have downloaded the model from langchain's Huggingface library, and I am running the model on AWS ml.g4dn.12xlarge which has 4xnvidia t4, which gives a total 64GB of GPU memory and 192GB of normal memory. It is able to answer my queries in around 10 seconds for small queries, and upto 3 mins for big queries.\n The task I am doing is retrieving information from a document(Understanding Machine Learning PDF) in a conversational way. I've extracted the main parts of the notebook and put it up here.\n Where can I make changes to speed up the transaction. Is there any change I can do in the model configuration to speed it up? Because if I use HuggingFaceHubAPI, it is able to give an answer in less than 5 seconds. Are there any other areas I can optimise?\n I appreciate any help you can provide. Thanks!\n    submitted by    /u/comical_cow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15851sr/d_how_do_i_reduce_llm_inferencing_time/",
          "publishedOn": "2023-07-24T08:58:59.000Z",
          "wordCount": 2635,
          "title": "[D] How do I reduce LLM inferencing time?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1583ccm/d_how_to_use_modern_uncertain_functions_eg/",
          "author": null,
          "description": "I was looking libraries like DISTIL and I would like to test a toy-example with all these modern uncertainty functions like BatchBALD, Glister, etc\n All the implementations of these functions seems to be on a NN or CNN. I know some of them like BatchBALD were created on top of a CNN with Monte-Carlo Dropout -- even BALD originally was created on top of SVM.\n It seems many of these approaches are under the category \"Query by Committee\"and they are an ensemble of models\n I just would like to test a simple LogisticRegression and use the log_proba and an output for these strategies. Someone knows if this is possible? \n    submitted by    /u/TipKay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1583ccm/d_how_to_use_modern_uncertain_functions_eg/",
          "publishedOn": "2023-07-24T07:23:48.000Z",
          "wordCount": 2595,
          "title": "[D] How to use modern uncertain functions (e.g. BatchBALD) with classical Active Learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15830oy/d_empirical_rules_of_ml/",
          "author": null,
          "description": "What are the empirical rules that one has to have in mind when designing a network, choosing hyperparameters, etc?\n For example:\n  \nLinear scaling rule: the learning rate should be scaled linearly with the batch size [ref] (on resnets on Imagenet) \n \nChinchilla law: compute budget, model size and training data should be scaled equally [ref]\n \n Do you have any other? (if possible with article, or even better an article with many of them)\n    submitted by    /u/Mulcyber  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15830oy/d_empirical_rules_of_ml/",
          "publishedOn": "2023-07-24T07:06:02.000Z",
          "wordCount": 2550,
          "title": "[D] Empirical rules of ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157zkks/d_should_i_mask_padding_tokens_when_finetuning_a/",
          "author": null,
          "description": "For pretraining I just sent batches of 1024 tokens and didn't worry about padding. But for finetuning, I intend to use a padding token to make all the \"instructions\" 1024 tokens in length. But some of them are only 10 tokens, which means 99% padding tokens. I feel like that would affect the model, and perhaps those padding tokens should be masked.\n Should I mask out those padding tokens? I can see that there's a parameter for attention mask, and I could make one and pass it in. But I'm not sure if that's the intended usage. I'm seeing conflicting and ambiguous information on this point. It's unclear to me whether the attn_mask is intended for customizing the casual left to right attention of the model, instead of for masking padding tokens. I'm worried I might be interfering with the process if I use that attn_mask.\n Here I can see attn_mask is an accepted parameter:\n y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True) \n FYI, I'm using NanoGPT which is based on Pytorch (not Hugging Face Transformers).\n Should I apply the attention mask on the padding tokens in this context?\n    submitted by    /u/Pan000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157zkks/d_should_i_mask_padding_tokens_when_finetuning_a/",
          "publishedOn": "2023-07-24T04:00:36.000Z",
          "wordCount": 2677,
          "title": "[D] Should I mask padding tokens when finetuning a GPT-2 model?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157uhjs/project_whisper_implementation_in_rust_using_burn/",
          "author": null,
          "description": "I temporarily switched from Rust to Python for machine learning, but quickly became fed up with Python's annoying versioning issues and runtime errors. I looked for a better path to machine learning and discovered burn, a deep learning framework for Rust. As my first burn project I decided to port OpenAI's Whisper transcription model. The project can be found at Gadersd/whisper-burn: A Rust implementation of OpenAI's Whisper model using the burn framework (github.com). I based it on the excellently concise tinygrad implementation that can be found here. The tinygrad version begrudgingly uses Torch's stft which I ported into a pure Rust short time Fourier transform along with the mel scale frequency conversion matrix function because I am curious and just a bit masochistic.\n Now for the good and the bad of burn. Rust's excellent package manager solves much of the versioning pain experienced in Python so burn models can be less painful to deploy and come with added reliability. The type checking in burn catches some tensor operation errors at compile time such as trying to multiply matrices of incompatible dimensions. Burn supports wgpu and WebGPU and can run in the browser when compiled into web assembly. I see a bright future for model deployment in burn.\n However, burn is relatively new so it lacks many tensor operations such as abs() that are available in other frameworks. Some features such as quantization are also missing. Burn implementations tend to be more verbose than the equivalent Python versions. Some of the runtime errors that plague PyTorch are still around in burn such as the crashes that result from trying to multiply tensors that live on different devices.\n Overall, burn is currently less ergonomic to develop with than alternatives such as PyTorch, but I think it has a lot of potential. If it is eagerly cultivated it may grow into a great Rusty alternative for machine learning practitioners.\n What do you all think?\n    submitted by    /u/Illustrious_Cup1867  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157uhjs/project_whisper_implementation_in_rust_using_burn/",
          "publishedOn": "2023-07-23T23:59:42.000Z",
          "wordCount": 2801,
          "title": "[Project] Whisper Implementation in Rust using burn",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157rwpd/p_nlp_dataset_for_stream_of_consciousness_the/",
          "author": null,
          "description": "submitted by    /u/A_Human_Rambler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157rwpd/p_nlp_dataset_for_stream_of_consciousness_the/",
          "publishedOn": "2023-07-23T22:09:30.000Z",
          "wordCount": 2493,
          "title": "[P] NLP dataset for stream of consciousness: The Rambles",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157pqr7/p_create_your_own_artificial_neural_network_in/",
          "author": null,
          "description": "submitted by    /u/pmocz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157pqr7/p_create_your_own_artificial_neural_network_in/",
          "publishedOn": "2023-07-23T20:43:31.000Z",
          "wordCount": 2480,
          "title": "[P] Create your own Artificial Neural Network in Python",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157nj6u/p_run_llama_2_locally_on_gpu_or_cpu_from_anywhere/",
          "author": null,
          "description": "Running Llama 2 locally with gradio UI on GPU or CPU from anywhere (Linux/Windows/Mac). Supporting Llama-2-7B/13B/70B with 8-bit, 4-bit. Supporting GPU inference (6 GB VRAM) and CPU inference. ➡️https://github.com/liltom-eth/llama2-webui\n Successfully running #Llama2 on my Apple Silicon MacBook Air:\n demo\n    submitted by    /u/plain1994  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157nj6u/p_run_llama_2_locally_on_gpu_or_cpu_from_anywhere/",
          "publishedOn": "2023-07-23T19:18:33.000Z",
          "wordCount": 2525,
          "title": "[P] Run Llama 2 locally on GPU or CPU from anywhere (Linux/Windows/Mac) ➡️https://github.com/liltom-eth/llama2-webui",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157mphf/d_rd_machine_learning_intern_at_a_startup_company/",
          "author": null,
          "description": "Greetings,I'm a machine learning engineer who managed to land an internship at a startup company and did R&D projects for them.. during the past year, I was working on an NLP problem of extractive question answering using BERT on this companies' text data. I trained the model and documented the results.. however, it's considered old technology now and we switched to solve the same problem using LLM.I was wondering if I can write a research paper for the BERT approach and publish it that can help me pursue PhD or Masters. How to start the discussion with my manager and seniors ?\n    submitted by    /u/Ready_Cockroach_3403  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157mphf/d_rd_machine_learning_intern_at_a_startup_company/",
          "publishedOn": "2023-07-23T18:46:31.000Z",
          "wordCount": 2593,
          "title": "[D] R&D machine learning intern at a startup company looking to publish a paper for his previous work..",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157m0bd/d_llama_training_vs_gpu_time_smaller_models_seem/",
          "author": null,
          "description": "submitted by    /u/espadrine  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157m0bd/d_llama_training_vs_gpu_time_smaller_models_seem/",
          "publishedOn": "2023-07-23T18:19:22.000Z",
          "wordCount": 2487,
          "title": "[D] LLaMA training vs. GPU time: smaller models seem better for a given budget",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157l0lt/n_llmopsspace_curated_resources_related_to/",
          "author": null,
          "description": "Today I launched LLMOps space on ProductHunt. LLMOps Space has a list of curated resources related to deploying LLMs into production. \n This includes-\n ✅ List of LLMOps companies and products\n 🗓 Upcoming events\n 📚 Educational resources\n 👩‍💻 Open-source LLM modules\n 💰 Funding news\n and much more.\n Everything is for free, would love it if you can support + share your thoughts in the comment. 🙏\n https://www.producthunt.com/posts/llmops-space\n    submitted by    /u/AsDivyansh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157l0lt/n_llmopsspace_curated_resources_related_to/",
          "publishedOn": "2023-07-23T17:40:30.000Z",
          "wordCount": 2546,
          "title": "[N] LLMOps.Space - Curated resources related to deploying LLMs in production",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157jpuh/d_can_i_use_transfer_learning_tl_in_a_classical/",
          "author": null,
          "description": "Hi,\n I'm trying to implement AL for ImageClassification. I have seen people using DAL, where some works use MC-DropOut to be able to calculate uncertainty on DNN / CNN. This also seems to be a current research topic. \n It seems very appealing for me to use DAL on the context of ImageClassification. However, I'm thinking to use a different and maybe naive approach: \n I thought to use TL (with or without FN) on a well knowledge DL Acthrecture (e.g.: Resnet) for Feature Extraction. Then, I just use the extracted features to train a Classical AL framework (e.g.: using LogisticRegression) \n Some thoughts/questions I had and would like to discuss:\n ​\n  \nI'm not finding articles that do this. Someone knows if this is approach is super naive or is a valid approach? What would be the drawbacks doing that?\n To train a DAL from scratch makes sense? For example, I saw some articles training DL Archthrectures from scratch, but this probably will require a lot of data, no?\n  \n​\n ------------------------------------------------------------------------------------------\n ML = MonteCarlo, AL = Active Learning, DAL = Deep AL, TL = Transfer Learning, FT = Fine-Tuning, DNN = Deep Neural Network, CNN = Convolutional Neural Network\n    submitted by    /u/TipKay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157jpuh/d_can_i_use_transfer_learning_tl_in_a_classical/",
          "publishedOn": "2023-07-23T16:48:40.000Z",
          "wordCount": 2681,
          "title": "[D] Can I use Transfer Learning (TL) in a classical Active Learning (AL) Framework?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157j5ur/d_looking_for_an_old_post_on_this_sub_about_using/",
          "author": null,
          "description": "I've seen the post (from 2-3 years ago maybe?) referenced, but my google fu is failing me and I haven't been able to find it, but it sounds like an interesting story.\n    submitted by    /u/TheQuarantinian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157j5ur/d_looking_for_an_old_post_on_this_sub_about_using/",
          "publishedOn": "2023-07-23T16:26:02.000Z",
          "wordCount": 2559,
          "title": "[D] Looking for an old post on this sub about using machine learning to identify a stray cat coming through a pet door to steal food, playing a loud noise to scare it away if it came in. The ML was used to tell the difference between the stray cat and the pet cat.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157iupn/r_neuro_symbolic_reasoning_and_learning/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157iupn/r_neuro_symbolic_reasoning_and_learning/",
          "publishedOn": "2023-07-23T16:14:00.000Z",
          "wordCount": 2477,
          "title": "[R] Neuro Symbolic Reasoning and Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157irs7/r_a_history_of_neural_networks/",
          "author": null,
          "description": "Our history, primer, and outlook for neural networks in general, and deep learning in astronomy in particular has dropped on Royal Society Open Science.\n https://doi.org/10.1098/rsos.221454\n Come for Llull and Leibniz... stay for LLaMA.\n    submitted by    /u/Smith4242  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157irs7/r_a_history_of_neural_networks/",
          "publishedOn": "2023-07-23T16:10:43.000Z",
          "wordCount": 2512,
          "title": "[R] A history of neural networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157h9fd/llm_guide_discussion/",
          "author": null,
          "description": "Nowadays, If we see over the internet that LLM, chatgpt , llma etc are the trending topics and are being discussed. My question is that anyone can help me where to start studying about these topics from scratch ? BERT, Transformer etc all I want to understand everything.\n It would be good if you help me out.\n Thanks\n    submitted by    /u/Mission-Youth-3510  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157h9fd/llm_guide_discussion/",
          "publishedOn": "2023-07-23T15:10:24.000Z",
          "wordCount": 2534,
          "title": "LLM Guide [Discussion]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157god1/p_linear_regression_partial_derrivative_problem/",
          "author": null,
          "description": "Yo, I'm new to all this so bear with me. I'm doing project in python where i create a linear regression from scratch (with numpy and pandas). I was watching this lady tutorial on it, at https://youtu.be/ltXSoduiVwY?t=277 she shows the partial derrivatives for updating the weights and bias. Later when she is implementing it she doesn't use the 2 before the X and uses only the dot product. Is it math magic where the 2 dosn't have to be there or did she forget. Btw it still works fine without the 2 but still... I just need to know. Thanks for the answer and sorry if I'm asking something obvious \n    submitted by    /u/Z4joMan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157god1/p_linear_regression_partial_derrivative_problem/",
          "publishedOn": "2023-07-23T14:46:26.000Z",
          "wordCount": 2589,
          "title": "[P] Linear regression partial derrivative problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157b91n/p_i_created_a_parallelized_implementation_of/",
          "author": null,
          "description": "I've been working on a new implementation of Agglomerative clustering called Reciprocal Agglomerative Clustering (RAC) based off of this paper: https://arxiv.org/abs/2105.11653. The short of it is Agglomerative clustering can be broken down into finding and merging pairs of reciprocal nearest neighbors in parallel, as long as the linkage function is one of the following:\n  \nSingle\n Average\n Complete\n Ward\n  \nMost importantly, RAC produces the exact same results as traditional Agglomerative clustering when the dataset is fully connected. Even with connectivity constraints, the results are almost always the same.\n The authors showed that RAC has a linear runtime when connectivity is limited to k and the distance matrix is precomputed. I have not added the ability to pass in the distance matrix yet, so the runtime is roughly quadratic, which is still a major improvement over the cubic runtime of Agglomerative clustering. In addition the entire algorithm is parallelized, and so can scale up to more and more cores.\n It's very much in development - only average linkage works at the moment, however, I think it has a lot of potential. The benchmarks have blown me away so far: \n https://preview.redd.it/8bkpdkpayodb1.png?width=850&format=png&auto=webp&s=8c828eb2cde934b2d9a0ded9f22e18f3d9041147\n Here is the code: https://github.com/porterehunley/RACplusplus. It would be great to have some people try it out (and find the bugs)!\n    submitted by    /u/Ridaleneas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157b91n/p_i_created_a_parallelized_implementation_of/",
          "publishedOn": "2023-07-23T10:24:20.000Z",
          "wordCount": 2701,
          "title": "[P] I created a parallelized implementation of Agglomerative clustering that's many times faster than existing implementations and has a better runtime",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157aqwg/p_paper_reading_and_sharing_platform/",
          "author": null,
          "description": "Let me know your thoughts!\n    submitted by    /u/dockerun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157aqwg/p_paper_reading_and_sharing_platform/",
          "publishedOn": "2023-07-23T09:56:20.000Z",
          "wordCount": 2484,
          "title": "[P] Paper reading and sharing platform",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/157acx4/d_probability_thresholds_for_userdefined_tokens/",
          "author": null,
          "description": "I want high certainty on social roles without sacrificing creativity. I don't want characters getting confused as to whether they're a parent or child, and I shouldn't have to spend hours each month explaining the difference. That said, I also don't want to lower the temperature, so it would be nice if as a user, I could select probability thresholds for certain token sequences, to hopefully mitigate role-swapping between virtual family members! I prefer writing stream of consciousness prompts seeding thoughts and choices rather than showing pretrained models their character bios at the start of every prompt. It breaks my immersion when family members swap roles due to high Top P and temperature, therefore I'd like models to be careful when writing names and corresponding social roles. This could help keeping track of many agents? There are instances where I enjoy getting role-swapped, and instances where swapping is nonsensical! This is my feature request.\n    submitted by    /u/TheLastVegan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/157acx4/d_probability_thresholds_for_userdefined_tokens/",
          "publishedOn": "2023-07-23T09:33:57.000Z",
          "wordCount": 2633,
          "title": "[D] Probability Thresholds for User-Defined Tokens",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1578j0m/p_data_version_control_in_r_with_lakefs/",
          "author": null,
          "description": "submitted by    /u/zoobatsea  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1578j0m/p_data_version_control_in_r_with_lakefs/",
          "publishedOn": "2023-07-23T07:50:05.000Z",
          "wordCount": 2492,
          "title": "[P] Data Version Control in R with lakeFS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1576v9u/d_dev_env_and_workflow/",
          "author": null,
          "description": "Hi all!\n I am a frontend engineer looking to play more in the ML space. I know enough about python and jupyter labs to be dangerous but I am no expert. I am looking to hear what peoples env's and workflows look like.\n I have been looking at huggingface, google colab, and running some things locally but can't seem to see a setup that looks like a clear winner. Hardware wise I have a machine with a 4080 and 32gb ram at home and a M1 Pro Macbook also with 32gb of ram.\n For my 1st project I would love to utilise a 7b Llama 2 for a recommender like system. I plan on getting a custom dataset, cleaning and processing it, fine tuning, and then testing.\n    submitted by    /u/pseudoShadow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1576v9u/d_dev_env_and_workflow/",
          "publishedOn": "2023-07-23T06:17:10.000Z",
          "wordCount": 2605,
          "title": "[D] Dev env and workflow",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1573yk0/d_use_cases_for_diffusion_models_vs_gans_vs/",
          "author": null,
          "description": "I am interested in learning to use AI to generate images. Diffusion Models like stable diffusion seems to be the most popular nowadays, but I'd like to know what tool is best for what job. Or is diffusion model getting so good that the other methods are essentially becoming obsolete? If not, when would you choose one over the other?\n For generating creative images with a lot of variance, diffusion model seems to be the most fitting.\n But for example, what about for this use case: Generate realistic time lapse images of a plant growing (after 1 week, 1 month, 2 months, and so on...). In this case, the plant should change, but the background should stay the same.\n    submitted by    /u/musshead  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1573yk0/d_use_cases_for_diffusion_models_vs_gans_vs/",
          "publishedOn": "2023-07-23T03:39:36.000Z",
          "wordCount": 2603,
          "title": "[D] Use Cases for Diffusion Models VS GANs VS Transformers, etc.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1571vcw/p_evolved_codealpaca_datasets_using_gpt4/",
          "author": null,
          "description": "Using LLMs to augment and create much diverse instruction based dataset has seen wide success in WizardL. However the 78k evolved code instructions dataset hasn't been released since, so I have take the initiative to try to recreate the augmentation instruction myself. \n Dataset: https://huggingface.co/datasets/theblackcat102/evol-codealpaca-v1\n    submitted by    /u/gradientpenalty  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1571vcw/p_evolved_codealpaca_datasets_using_gpt4/",
          "publishedOn": "2023-07-23T01:53:55.000Z",
          "wordCount": 2523,
          "title": "[P] Evolved codealpaca datasets using GPT-4",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1570olg/d_coursevideos_to_learn_about_the_architecture/",
          "author": null,
          "description": "I like to learn how pytorch connects to the compiler, generates IR, how it connects to run time , driver ..etc\n Im not interested in the programming model but the whole stack from pytorch to the hardware.\n I really appreciate if someone can give me a pointer\n thanks\n    submitted by    /u/aghozzo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1570olg/d_coursevideos_to_learn_about_the_architecture/",
          "publishedOn": "2023-07-23T00:57:54.000Z",
          "wordCount": 2533,
          "title": "[D] course/videos to learn about the architecture and software stack of pytorch?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156zkvd/p_r_join_our_team_of_ml_model_developers_for_an/",
          "author": null,
          "description": "Seeking skilled ML model developers for our thrilling project with possible permanent positions! Embrace remote collaboration, offering flexibility and impact-driven work. Interested? Apply to btprenuer@gmail.com with a list of your related skills and samples of your work/projects! All experience levels welcome! Thank you for reading! Share this post to help us find the perfect fit.\n    submitted by    /u/boztka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156zkvd/p_r_join_our_team_of_ml_model_developers_for_an/",
          "publishedOn": "2023-07-23T00:06:45.000Z",
          "wordCount": 2545,
          "title": "[P] [R] Join Our Team of ML Model Developers for an Exciting Project & Permanent Job Potential!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156y1dd/r_text2tex_textdriven_texture_synthesis_via/",
          "author": null,
          "description": "submitted by    /u/SpatialComputing  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156y1dd/r_text2tex_textdriven_texture_synthesis_via/",
          "publishedOn": "2023-07-22T23:00:11.000Z",
          "wordCount": 2491,
          "title": "[R] TEXT2TEX — text-driven texture synthesis via diffusion models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156vlgq/d_breaking_down_the_hyperbolic_buzz_an_indepth/",
          "author": null,
          "description": "submitted by    /u/CkmCpvis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156vlgq/d_breaking_down_the_hyperbolic_buzz_an_indepth/",
          "publishedOn": "2023-07-22T21:18:08.000Z",
          "wordCount": 2494,
          "title": "[D] Breaking Down the Hyperbolic Buzz: An In-Depth Review of the 'Leaked' GPT-4 Architecture & a Mixture of Experts Literature Review with Code",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156tvee/p_what_are_a_good_project_for_people_learning/",
          "author": null,
          "description": "I am learning Tensorflow and of course I want to improve my skills and add it to my resume\n What projects should I build which I can add to my resume which will later land me a job.\n Projects should be from Beginner to Advance and can contain each major Topic from Regression (linear and non linear), to Classification (Binary, Multi Classification, Multi Label), CNN,RNN, NLP, etc (Can add more).\n This can also help other people as well learning TensorFlow.\n Thank you.\n    submitted by    /u/dusklordtrue  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156tvee/p_what_are_a_good_project_for_people_learning/",
          "publishedOn": "2023-07-22T20:07:00.000Z",
          "wordCount": 2564,
          "title": "[P] What are a good project for people learning Tensorflow?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156rouv/when_to_train_llm_supervised_vs_unsupervised_d/",
          "author": null,
          "description": "I have done a bit of language modeling recently, and I am a bit confused when to use which method.\n For causal language modeling, I used the unsueprvised method of concatenating and chunking the text, then predicting the next word.\n For sequence to sequence tasks like summarization, I fine tuned using the supervised method where the desired output text was the label.\n However I have not seen any definitive guide on when to use supervised and when to use unsupervised. What are the general use cases and advantages / disadvantages for each?\n    submitted by    /u/jankybiz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156rouv/when_to_train_llm_supervised_vs_unsupervised_d/",
          "publishedOn": "2023-07-22T18:37:26.000Z",
          "wordCount": 2573,
          "title": "When to train LLM supervised vs unsupervised? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156r6el/discussion_best_image_annotation_tool_for/",
          "author": null,
          "description": "I am looking to annotate specific anatomical structures using a library of angiogram images. My goal is to train AI to recognize anatomical variants of interest. What would be the best Image Annotation Tool to do this?\n I am new to this, so I hope that question makes sense. Any insights and advice would be greatly appreciated.\n    submitted by    /u/ColdChampion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156r6el/discussion_best_image_annotation_tool_for/",
          "publishedOn": "2023-07-22T18:16:12.000Z",
          "wordCount": 2537,
          "title": "[Discussion] Best Image Annotation Tool for Angiograms?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156qulq/d_what_leaderboard_would_correspond_best_to/",
          "author": null,
          "description": "I've been using CLIP to see if images align with a certain caption for image mining (ex. I embed the caption \"Picture of a mountain\" and then look at what image embeddings have the highest cosine similarity with that caption embedding). I was hoping to improve the performance by using a more recent model. Would I be able to use VQA models for this (like from this leaderboard) or is there a better task that aligns with seeing if images are similar to a given caption? Thank you!\n    submitted by    /u/EricW_CS  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156qulq/d_what_leaderboard_would_correspond_best_to/",
          "publishedOn": "2023-07-22T18:02:19.000Z",
          "wordCount": 2579,
          "title": "[D] What leaderboard would correspond best to seeing what images are most similar to a caption (like CLIP)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156nem2/p_pattern_classification_using_cnns/",
          "author": null,
          "description": "Hi (I have to write again, Reddit removed image attached),\n Does anyone has experience with training CNN for pattern matching?\n Here is the sample of the images which I have on my disposal. It is graphical representation of input data which for problem classified by algorithm which shows best performance when applied.\n Lines are projection of the problem of input data on 2d plain, so shapes and colours have meaning in correlating input data to solution (i.e) algorithm.\n Whichever CNN architecture I use, starting from VGG16 and so on, I am unable to achieve higher validation accuracy then 0.7 when execute training. I am constantly under-fitting. I have 10k, 100k, 200k data samples on my disposal - nothing helps.\n Is CNN able to make any sense of images/patterns given below? Is this something that CNN can not do or I am missing something?\n Thanks!\n Patterns to classify \n ​\n    submitted by    /u/thecelavi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156nem2/p_pattern_classification_using_cnns/",
          "publishedOn": "2023-07-22T15:42:12.000Z",
          "wordCount": 2625,
          "title": "[P] Pattern classification using CNNs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156khpd/d_technical_question_how_is_it_possible_that/",
          "author": null,
          "description": "As far as I know and studied, each token is mapped from high dimensional discrete token space into a continuous, lower dimensional space where words are embedded meaningfully based on their relationships in the training data. So 1000 tokens text produces 1000 vectors.\n Now for vector databases (correct me if I'm wrong), people are storing fixed sized vectors for text with varying lengths. For example, 2 sentences one with 1000 tokens and the other is 10 tokens, each produces one vector and both vectors have the same size.\n I'd really appreciate an explanation.\n    submitted by    /u/Qdr-91  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156khpd/d_technical_question_how_is_it_possible_that/",
          "publishedOn": "2023-07-22T13:42:18.000Z",
          "wordCount": 2585,
          "title": "[D] technical question: How is it possible that embedding models produce fixed size vectors for sentences with varying lengths?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156k8xz/p_llama2_4bit_finetune_with_dolly15k_on_colab_free/",
          "author": null,
          "description": "Simple walkthrough of fine-tuning llama-2 instruct fine-tuned on guanaco model with 4bit QLoRA on a free Google Colab instance.\n Colab: https://colab.research.google.com/drive/134o_cXcMe_lsvl15ZE_4Y75Kstepsntu?usp=sharing\n GitHub: https://github.com/kw2828/guardrail-ml/blob/main/examples\n YouTube Overview: https://www.youtube.com/watch?v=o5bU1H-6TqM&ab_channel=GenerativeAIEntrepreneurs\n Bonus colab in repo on generating your own JSON Q&A dataset from PDF in the repo above.\n    submitted by    /u/Educational_Grass_38  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156k8xz/p_llama2_4bit_finetune_with_dolly15k_on_colab_free/",
          "publishedOn": "2023-07-22T13:31:10.000Z",
          "wordCount": 2523,
          "title": "[P] Llama-2 4bit fine-tune with dolly-15k on Colab (Free)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156hfk1/n_jul_2023_recent_instructionchatbased_llms_and/",
          "author": null,
          "description": "submitted by    /u/michaelthwan_ai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156hfk1/n_jul_2023_recent_instructionchatbased_llms_and/",
          "publishedOn": "2023-07-22T11:18:04.000Z",
          "wordCount": 2494,
          "title": "[N] Jul 2023 - Recent Instruction/Chat-Based LLMs and their parents (after llama2)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156fhs3/discussion_what_do_you_think_about_federated/",
          "author": null,
          "description": "Link to the article: https://dl.acm.org/doi/10.1145/3533708\n In this article, they talk about the difficulty of training foundation models on Healthcare data because of how sensitive it is and hard to get.\n  \nAccess to a large amount of high-quality medical data is possibly the most crucial factor for enhancing Machine Learning (ML) applications in the healthcare domain. However, security and privacy issues of healthcare data have raised broad ethical and legal concerns in recent years, given the sensitive nature of health information.\n  \nSo they decided to take the approach of Federated Learning where the model will be distributed and trained by multiple institutions (Hospitals, Clinics ...) then the model weight will be transferred over to the general model to be updated, which will keep the sensitive medical data inside the institutions safe.\n  \nThe global ML model is distributed to each client site, where an instance is trained locally. The updates from locally trained instances are then aggregated at regular intervals to improve the global model. \n The updated global model is then sent back to the local devices, where the learning continues. These steps are repeated until a particular convergence threshold is satisfied or lasts for a long time to improve the deep learning model continuously. \n  \nWhat do you think about such an approach, to brake data obstacles between AI and the Healthcare industry?\n ​\n    submitted by    /u/angeloboustany  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156fhs3/discussion_what_do_you_think_about_federated/",
          "publishedOn": "2023-07-22T09:31:07.000Z",
          "wordCount": 2703,
          "title": "\"[Discussion]\" What do you think about Federated Learning for Healthcare",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156fe2f/d_scheduler_choice_when_pretraining_causal/",
          "author": null,
          "description": "There seems to be a lack of published work on the impact of schedulers on model training effectiveness when training models similar to the GPT family. I'm looking at a very domain specific models pretraining a model from scratch on a relatively small dataset (~40B tokens) over multiple epochs. To date we've had some mixed results with a linear scheduler with warmup to help with stability. Any thoughts on whether a cyclic based scheduler or other could help?\n    submitted by    /u/Humble-Passenger-635  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156fe2f/d_scheduler_choice_when_pretraining_causal/",
          "publishedOn": "2023-07-22T09:25:17.000Z",
          "wordCount": 2559,
          "title": "[D] Scheduler choice when pretraining causal decoder models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156esec/train_llm_for_closedbook_qa_d/",
          "author": null,
          "description": "What is the best way to train an LLM for closed book question answering? I can only think of two options:\n  \nConcatenate question/answer pairs into chunked text and train the model using causal language modeling.\n Train the model using sequence to sequence techniques with question as the input and answer as the label.\n  \nI have tried both and the first seems to work better. Does anyone know whether there is a commonly accepted method? Can somebody point me to some resources?\n    submitted by    /u/jankybiz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156esec/train_llm_for_closedbook_qa_d/",
          "publishedOn": "2023-07-22T08:51:16.000Z",
          "wordCount": 2560,
          "title": "Train LLM for closed-book QA [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156cwf5/p_a_chrome_extension_to_save_paper_details/",
          "author": null,
          "description": "submitted by    /u/HugoDzz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156cwf5/p_a_chrome_extension_to_save_paper_details/",
          "publishedOn": "2023-07-22T07:02:52.000Z",
          "wordCount": 2479,
          "title": "[P] A Chrome extension to save paper details",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156arkm/discussion_easy_way_to_ship_tensorflow_model_to/",
          "author": null,
          "description": "I'm surprised that there aren't more resources on the internet about how to do this, it seems like the whole point of doing machine learning lol. Do very few people have this need?\n All of the solutions for this that I've found so far seem to require advanced knowledge of web development/backend engineering.\n I'd love to hear if someone has found or figured out a way to do this.\n    submitted by    /u/youaregames  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156arkm/discussion_easy_way_to_ship_tensorflow_model_to/",
          "publishedOn": "2023-07-22T05:06:17.000Z",
          "wordCount": 2552,
          "title": "[Discussion] Easy way to ship tensorflow model to non-technical audience?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156ar2l/can_someone_explain_to_me_what_the_wolves_and/",
          "author": null,
          "description": "I'm aware that the algorithm is very similar to the real world hunting of wolves, but what I want to know is what exactly is the \"prey\" and what is a \"wolf\"\n For example, I know a Chromosome sequence in Genetic algorithm is a combination of random features, and its fitness can be computed. And then you let the whole natural selection jargon take place and you arrive at a optimized chromosome, the solution to the optimization problem.\n I just can't seem to wrap my head around the WSA algorithm. I've watched a bunch of youtube videos, I tried reading the paper, I still can't understand it well. What IS a wolf? I think what I'm looking for is how the actual data features and components of a search algorithm correlates with the analogy of the wolves searching for prey.\n    submitted by    /u/SnooHobbies7910  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156ar2l/can_someone_explain_to_me_what_the_wolves_and/",
          "publishedOn": "2023-07-22T05:05:32.000Z",
          "wordCount": 2629,
          "title": "Can someone explain to me what the wolves and prey really are in wolf search algorithm?[D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/156aibi/d_what_are_your_main_approach_to_model/",
          "author": null,
          "description": "I’m currently trying to understand each methods but It seems I can never catch up to the latest/best. After months of reading I have still lots of questions like: What are the go to strategies to compress a model? Are there any good fully/semi automated frameworks? How much weights has model architecture in this equation? What could be a general good work-flow in a modern and optimized solution? I would love to hear from you some production compliant workflows\n    submitted by    /u/PierroZ-PLKG  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/156aibi/d_what_are_your_main_approach_to_model/",
          "publishedOn": "2023-07-22T04:53:06.000Z",
          "wordCount": 2563,
          "title": "[D] What are your main approach to model compression in production?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1567rd6/d_challenges_and_applications_of_large_language/",
          "author": null,
          "description": "submitted by    /u/gamerx88  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1567rd6/d_challenges_and_applications_of_large_language/",
          "publishedOn": "2023-07-22T02:33:43.000Z",
          "wordCount": 2492,
          "title": "[D] Challenges and Applications of Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1563n95/d_when_will_llms_start_being_used_in_rl_processes/",
          "author": null,
          "description": "People are always so dismissive that LLMs are just autoregressive. When will we start doing things like Actor Critic to train LLMs in a sort of game against themselves to pass the test accurately or play a game or solve a science problem or write code. I feel like this has to be a vibrant research field.\n    submitted by    /u/Intelligent_Rough_21  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1563n95/d_when_will_llms_start_being_used_in_rl_processes/",
          "publishedOn": "2023-07-21T23:24:52.000Z",
          "wordCount": 2544,
          "title": "[D] When will LLMs start being used in RL processes to train their rationality?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15621bc/d_how_to_improve_gans_by_penalizing_previous/",
          "author": null,
          "description": "I use GAN (generative adversarial networks) in Python/Keras to synthesize tabular data. It has loss functions associated to the discriminator and generator.\n On top of that, I synthetize data after each epoch, and compare it to real data (using a specific metric) to see how good the results are, as it varies quite a bit over successive epochs. If one epoch produces a bad synthetization, how can I tell my GAN to stay away from such configurations moving forward (thus penalizing it). Likewise, if one epoch produces great results, how can I reward my GAN and tell it to do more of those.\n    submitted by    /u/MLRecipes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15621bc/d_how_to_improve_gans_by_penalizing_previous/",
          "publishedOn": "2023-07-21T22:16:21.000Z",
          "wordCount": 2589,
          "title": "[D] How to improve GANs by penalizing previous epoch if it performed poorly?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155yqjo/d_how_to_lead_llms_to_home_in_on_the_solution_to/",
          "author": null,
          "description": "Using LLMs to solve problems can be facilitated through a two-step process that is repeated until a desired understanding is reached. Generally, the process advances as shown in the following prompts:\n  \nWhat is the most promising approach to solving a certain problem?\n What is the greatest challenge to achieving this approach?\n What is the most promising approach to meeting this challenge?\n What is the greatest challenge to achieving this approach?\n  \nAs you can see, the strategy involves two basic steps, (1 and 2) that are repeated over and over until the essence, or potential required actionable tasks, of the problem are revealed.\n Here's an example of this strategy being used to better understand how LLMs can be made more intelligent. As you will notice, it is useful to limit the respo…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155yqjo/d_how_to_lead_llms_to_home_in_on_the_solution_to/",
          "publishedOn": "2023-07-21T20:11:02.000Z",
          "wordCount": 3064,
          "title": "[D] How to lead LLMs to home in on the solution to a problem. Case example: How to make LLMs more intelligent.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155wa2p/r_towards_a_unified_agent_with_foundation_models/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2307.09668\n Abstract:\n  \nLanguage Models and Vision Language Models have recently demonstrated unprecedented capabilities in terms of understanding human intentions, reasoning, scene understanding, and planning-like behaviour, in text form, among many others. In this work, we investigate how to embed and leverage such abilities in Reinforcement Learning (RL) agents. We design a framework that uses language as the core reasoning tool, exploring how this enables an agent to tackle a series of fundamental RL challenges, such as efficient exploration, reusing experience data, scheduling skills, and learning from observations, which traditionally require separate, vertically designed algorithms. We test our method on a sparse-reward simulated robotic manipulation environment, where a robot needs to stack a set of objects. We demonstrate substantial performance improvements over baselines in exploration efficiency and ability to reuse data from offline datasets, and illustrate how to reuse learned skills to solve novel tasks or imitate videos of human experts. \n  \nhttps://preview.redd.it/voehn3aa3ddb1.jpg?width=1101&format=pjpg&auto=webp&s=c367c7b1042d11b3e2a2b2109c95482f8555747b\n https://preview.redd.it/6ei186aa3ddb1.jpg?width=617&format=pjpg&auto=webp&s=10e1928769da9552aabdcf084b45f5e6be2ec97e\n https://preview.redd.it/umg3b7aa3ddb1.jpg?width=1353&format=pjpg&auto=webp&s=2be83b87e6b3553c6d1770a579f9a9aa69c238dd\n https://preview.redd.it/ushea8aa3ddb1.jpg?width=1661&format=pjpg&auto=webp&s=67edddd76c0cdde67c0e9502fd76fbc1a9247946\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155wa2p/r_towards_a_unified_agent_with_foundation_models/",
          "publishedOn": "2023-07-21T18:38:53.000Z",
          "wordCount": 2647,
          "title": "[R] Towards A Unified Agent with Foundation Models - Google DeepMind, ICLR23, July 2023 - LLM + RL leads to substantial performance improvements!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155upa6/p_repochat_open_source_project_for_chatting_with/",
          "author": null,
          "description": "Hey! Just a quick note that I built an open-source tool to chat with your own code repository, I'm calling it RepoChat for now.\n This was my first time really ever working with LLMs or anything AI / Machine Learning related, but I wanted to hack something together so I didn't have to keep copy-pasting code into chat.openai.com when I was coding.\n Let me know what you think. It's not beautiful, but it works!\n If you see anything you'd like to fix, feel free to contribute to this open source project.\n The biggest trick was figuring out how to keep token limits sane. I'm sure there are more refinements, but it's working pretty well as of now.\n    submitted by    /u/maniflex_destiny  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155upa6/p_repochat_open_source_project_for_chatting_with/",
          "publishedOn": "2023-07-21T17:38:19.000Z",
          "wordCount": 2603,
          "title": "[P] RepoChat - open source project for chatting with your own code repositories",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155unoj/d_can_llms_keep_getting_better_arbitrarily_or/",
          "author": null,
          "description": "The way I see it, if LLMs become the de facto tool for content generation, summarization, image generation etc etc, at some point the amount of machine generated content will surpass human generated come t and will continue increasing the gap. Can anyone give some insight as to whether LLMs will stop improving and actually start degrading as they are retrained on more and machine generated content?\n    submitted by    /u/Western-Image7125  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155unoj/d_can_llms_keep_getting_better_arbitrarily_or/",
          "publishedOn": "2023-07-21T17:36:33.000Z",
          "wordCount": 2553,
          "title": "[D] Can LLMs keep getting better arbitrarily or would we hit a limit?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155u7ah/d_beyond_llms_what_cool_ml_projects_are_you/",
          "author": null,
          "description": "It seems like everyone is rushing into working in LLMs, but I'm curious to know what other cool machine learning projects you're working on\n    submitted by    /u/Ahmed-Allam-220  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155u7ah/d_beyond_llms_what_cool_ml_projects_are_you/",
          "publishedOn": "2023-07-21T17:19:29.000Z",
          "wordCount": 2507,
          "title": "[D] Beyond LLMs, What Cool ML Projects Are You Building?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155s1sj/d_object_detection_models_that_can_be_easily/",
          "author": null,
          "description": "I've managed to train and convert to CoreML a yolo model, they've really made that easy. However, using it in a commercial product requires paying $5-10k/y.\n Are there any other repos/libraries for object detection that can be trained in pytroch/tf and then converted to CoreML?\n I've came accross:\n - https://github.com/apple/ml-cvnets\n - https://github.com/open-mmlab/mmdeploy \n Has anyone managed to train an object detection model with them and convert it to CoreML? I'd like to hear some success stories before digging deep into these frameworks.\n Also, I've tried converting some detectron models to CoreML long time ago, but ended up with `operation not supported`...\n Thanks!\n    submitted by    /u/alkibijad  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155s1sj/d_object_detection_models_that_can_be_easily/",
          "publishedOn": "2023-07-21T15:59:07.000Z",
          "wordCount": 2584,
          "title": "[D] Object detection models that can be easily converted to CoreML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155s1dw/p_tips_for_machine_learning_notebook_refactor_to/",
          "author": null,
          "description": "Tips for Machine learning notebook refactor to production?\n I need to refactor a lot of forecast models. Each forecast model is kinda similar. And we run this in a batch pipeline model. \n So, my strategy is to create a abstract factory design pattern. \n I will create a super class and each forecast will implement this forecast. \n But I don't think I have enough background to get a very good software design for this problem. \n Do you recommend any resources or concepts to solve this problem?\n    submitted by    /u/Muted_Standard175  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155s1dw/p_tips_for_machine_learning_notebook_refactor_to/",
          "publishedOn": "2023-07-21T15:58:40.000Z",
          "wordCount": 2567,
          "title": "[P] Tips for Machine learning notebook refactor to production?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155rh8z/p_open_source_image_to_text_model/",
          "author": null,
          "description": "Haven't keeping up with Deep Learning and Computer Vision papers last few years what are some hot Image to Text Models right now that are open source?\n    submitted by    /u/I_am_not_doing_this  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155rh8z/p_open_source_image_to_text_model/",
          "publishedOn": "2023-07-21T15:37:55.000Z",
          "wordCount": 2507,
          "title": "[P] Open Source Image to Text Model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155rav2/n_novel_model_for_tabular_data_igann_looks_like_a/",
          "author": null,
          "description": "Hey, fellow Machine Learning enthusiasts!\n There is a novel ML model called Interpretable Generalized Additive Neural Networks (IGANN). I tried it out and it worked pretty smooth and out of the box! I used some tabular data i had at hand and it gave me insightful plots!! This model proposes, as the authors attribute it, a game-changing approach to the way we approach interpretability in Machine Learning.\n For the uninitiated, IGANN is described as a model that leverages gradient boosting and tailored neural networks to provide better predictive performance while retaining interpretability. Even though in the hyperparameter tuned version it is not always the best interpretable model, but it is mostly worth giving a try.\n It does so by deploying an efficient training algorithm derived from t…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155rav2/n_novel_model_for_tabular_data_igann_looks_like_a/",
          "publishedOn": "2023-07-21T15:31:13.000Z",
          "wordCount": 2937,
          "title": "[N] Novel Model for Tabular Data: IGANN: Looks Like a Leap Towards Interpretable Machine Learning!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155puhf/d_finetuning_llm_on_company_data/",
          "author": null,
          "description": "Hey Redditors, I was looking into fine-tuning some open-source LLMs like Llama 2 or Falcon with our company data as a fun project. I was thinking about using some Slack channels, ZenDesk Tickets and perhaps Github/Confluence data\n I was wondering two things:\n 1. How have your experiences been with PEFT methods in practice? Anything I should be aware of compared to regular fine-tuning?\n 2. Which model size would you recommend for a relatively small sized company (60 people) and how many GPUs (H100) would you roughly expect to need? I understand this depends on the size of the dataset but I haven't indexed it so far so any ballpark numbers are welcome.\n Many thanks!\n    submitted by    /u/RufusLdn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155puhf/d_finetuning_llm_on_company_data/",
          "publishedOn": "2023-07-21T14:37:46.000Z",
          "wordCount": 2591,
          "title": "[D] Fine-tuning LLM on company data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155palg/r_a_composable_customer_data_platform_cdp_for_the/",
          "author": null,
          "description": "Unlike traditional all-in-one CDPs, a composable CDP is like Lego building blocks — you pick the best components to build what you want. To personalize customer experience, to boost automation and to power up marketing.\n Traditional vs. Composable\n Classic CDPs integrate different needs into a single streamlined product. Such a platform creates a unified customer database and offers various functionalities (e.g. data collection) that are quickly accessible by other systems.\n A composable CDP, on the other hand, utilizes the best-in-class components for every step using your preferred components. Data collection and data creation systems of your choice, a data platform to store and process the data, and components to activate the insights in CRM, marketing or self-service analytics.\n ​\n Key…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155palg/r_a_composable_customer_data_platform_cdp_for_the/",
          "publishedOn": "2023-07-21T14:16:19.000Z",
          "wordCount": 2927,
          "title": "[R] A Composable Customer Data Platform (CDP) for the combination of software and tools for data collection, storage & modeling, and activation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155n80r/run_disco_disentangled_control_for_referring/",
          "author": null,
          "description": "Hi everyone,\n I'm trying to run DisCo (Disentangled Control for Referring Human Dance Generation in Real World) on my own harddrive, but I'm having some trouble installing it. I am no professional nor a complete beginnder. But I still find the guide on the official GitHub page confusing.\n Does someone have experience in running it locally? I would be really happy for some kind of guide or tutorial.\n I have a RTX 3060 12GB.\n Thanks in advance for your help!\n    submitted by    /u/Elwii04  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155n80r/run_disco_disentangled_control_for_referring/",
          "publishedOn": "2023-07-21T12:53:23.000Z",
          "wordCount": 2576,
          "title": "Run DisCo: Disentangled Control for Referring Human Dance Generation in Real World locally with own hardware. Looking for Guide / Tutorial [D] [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155miyl/how_to_create_an_animation_of_the_embeddings/",
          "author": null,
          "description": "In a recent article, I used an animation to demonstrate changes in the embeddings during the fine-tuning process. This was achieved by performing Principal Component Analysis (PCA) on the embeddings. These embeddings were generated from models at various stages of fine-tuning and their corresponding checkpoints.\n ​\n Projection of embeddings with PCA during fine-tuning of a Vision Transformer (ViT) model [1] on CIFAR10 [3]; Source: created by the author — Published before in Changes of Embeddings during Fine-Tuning\n Here, I aim to provide a comprehensive guide on how to create such an animation as requested by many readers.\n The full Code is available in the Story Section in the Spotlight GitHub Repository.\n Step 1: Fine-tuning\n The first step is to fine-tune the google/vit-base-patch16–224…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155miyl/how_to_create_an_animation_of_the_embeddings/",
          "publishedOn": "2023-07-21T12:23:30.000Z",
          "wordCount": 2986,
          "title": "How to create an Animation Of the Embeddings During Fine-Tuning [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155lg80/d_how_to_work_with_large_datasets_of_embeddings/",
          "author": null,
          "description": "I have a dataset which is a CSV file which I open and analyse as a Pandas dataframe. I am now generating 'embeddings' based on some of this data, which I want to analyse as well. The dataset is rather big (millions of rows), so I noticed that appending and storing the embeddings as part of the pandas dataframe makes me run out of RAM memory. Aside from that storing and saving numpy arrays in a dataframe is also a bit 'awkward'.\n Since I want to analyze the whole dataset including embeddings storing them in so-called embedding stores doesn't make a lot of sense, since I always want to loop over the whole set anyways.\n Are there any best practices or recommendations for how to work with this data?\n    submitted by    /u/Dutchcheesehead  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155lg80/d_how_to_work_with_large_datasets_of_embeddings/",
          "publishedOn": "2023-07-21T11:35:39.000Z",
          "wordCount": 2611,
          "title": "[D] How to work with large datasets of embeddings?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155kbyn/r_are_vit_transformers_also_biased_towards/",
          "author": null,
          "description": "Does the texture bias mentioned in the paper 'ImageNet-trained CNNs are biased towards texture increasing shape bias improves accuracy and robustness' also affect Transformer-based networks such as ViT?\n    submitted by    /u/newtestdrive  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155kbyn/r_are_vit_transformers_also_biased_towards/",
          "publishedOn": "2023-07-21T10:41:29.000Z",
          "wordCount": 2512,
          "title": "[R] Are ViT Transformers also biased towards Texture information like CNNs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155k423/n_zbrain_build_chatgpt_like_apps_with_your/",
          "author": null,
          "description": "Hello Community,\n We at ZBrain have built a platform to create ChatGPT-like apps with your private data, you can import your data from multiple sources and DBs and integrate the app into any of your workflows.\n We have also added AI risk governance to mitigate the confidential data leak and now working on Flow a no-code tool to give you the freedom to create your own business logic.\n You can try the tool now at https://zbrain.ai/. We would love to hear your thoughts and feedback to improve the tool.\n    submitted by    /u/StewartBJasper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155k423/n_zbrain_build_chatgpt_like_apps_with_your/",
          "publishedOn": "2023-07-21T10:30:19.000Z",
          "wordCount": 2573,
          "title": "[N] ZBrain - Build ChatGPT like apps with your private data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155i05l/n_eu_ai_act_the_first_comprehensive_ml_law_is/",
          "author": null,
          "description": "Summary can be found here: https://www.infoq.com/news/2023/07/eu-ai-act/\n    submitted by    /u/ElrasX  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155i05l/n_eu_ai_act_the_first_comprehensive_ml_law_is/",
          "publishedOn": "2023-07-21T08:37:26.000Z",
          "wordCount": 2497,
          "title": "[N] EU AI Act, the first comprehensive ML law, is expected to come into force by early 2024",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155f2k0/n_huggingface_reported_to_be_reviewing_term/",
          "author": null,
          "description": "Link to article: https://www.forbes.com/sites/alexkonrad/2023/07/13/ai-startup-hugging-face-raising-funds-4-billion-valuation/\n AI Startup Hugging Face Is Raising Fresh VC Funds At $4 Billion Valuation\n Hugging Face is raising a new funding round that is expected to value the high-flying AI startup at $4 billion, multiple sources with knowledge of the matter tell Forbes.\n The Series D funding round is expected to raise at least $200 million, two sources said, with Ashton Kutcher’s venture capital firm, Sound Ventures, currently leading an investor scrum. But cofounder and CEO Clément Delangue is shopping around as the company has received multiple offers this week, four sources added.\n Delangue was expected to pick a preferred offer as soon as Friday, according to another source, who noted…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155f2k0/n_huggingface_reported_to_be_reviewing_term/",
          "publishedOn": "2023-07-21T05:59:38.000Z",
          "wordCount": 3205,
          "title": "[N] HuggingFace reported to be reviewing term sheets for a funding round that could raise at least $200M at a valuation of $4B.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155egla/p_what_techniques_are_best_predict_multivariate/",
          "author": null,
          "description": "I have the following data for a college project. 7 cols 1 columns has the date 5 dependent variables 1 independent variable (need to predict)\n While predicting I would know the dependent variables, need to predict the independent variables.\n What model would be good for this kinda thing ?\n Tried running Granger causality but I can't seem to understand how to run the ADF test and interpret the resultant Granger causality matrix\n And after that how to predict the independent variables given the dependent variable\n Thank you\n    submitted by    /u/zoro_245  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155egla/p_what_techniques_are_best_predict_multivariate/",
          "publishedOn": "2023-07-21T05:27:04.000Z",
          "wordCount": 2569,
          "title": "[P] what techniques are best predict multivariate time analysis?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155e7qa/d_any_ides_specifically_for_ml_development/",
          "author": null,
          "description": "Hi all,\n I was wondering if anyone has any recommendations for an IDE specific to ML development. I currently use PyCharm as my preferred IDE, and it is great for writing Python code. That said, something specifically geared toward ML development (i.e., robust built-in visualization for models/data, low code model construction, built-in deployment pipelines to cloud providers, etc.) would be very useful! Does anyone know if such a tool exists?\n Cheers!\n    submitted by    /u/mldude60  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155e7qa/d_any_ides_specifically_for_ml_development/",
          "publishedOn": "2023-07-21T05:14:04.000Z",
          "wordCount": 2551,
          "title": "[D] Any IDEs specifically for ML development?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/155cswq/p_microsoft_releases_typechat/",
          "author": null,
          "description": "MSFT just open-sourced a library called TypeChat today, which allows you to use LLMs with TypeScript types to structure LLM responses into your TypeScript data structures -- essentially allowing you to have the LLM generate responses into the data types that your app understands.\n Example from their docs:\n https://preview.redd.it/108650s4s8db1.png?width=1682&format=png&auto=webp&s=0429eeb16bc5c28651ea908aee5824c3c9f395b4\n Details: https://microsoft.github.io/TypeChat/docs/introduction/\n I can see a lot of powerful examples for this kind of pattern, including eventing and notifications based on generated data types. \n Has anyone tried this library yet or have more context on what you'd use it for, or what this might replace in your LLM tech stack?\n    submitted by    /u/sarmad-q  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/155cswq/p_microsoft_releases_typechat/",
          "publishedOn": "2023-07-21T04:02:33.000Z",
          "wordCount": 2575,
          "title": "[P] Microsoft releases TypeChat",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1558r6i/p_synthetic_data_personal_project/",
          "author": null,
          "description": "I've been working with a couple of my friends on a project over the summer. It's still a work in progress, but we have built out a platform that generates synthetic data to fine-tune LLMs. If you want specific, high-quality datasets, please check out our website (https://discus.ai/) and also feel free to look at our open-source package (https://github.com/discus-labs/discus-synthetics). Cue the roasts\n    submitted by    /u/Open-Yak-434  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1558r6i/p_synthetic_data_personal_project/",
          "publishedOn": "2023-07-21T00:48:23.000Z",
          "wordCount": 2539,
          "title": "[P] Synthetic Data Personal Project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15589hi/d_scaling_laws_for_llm_finetuning/",
          "author": null,
          "description": "The scaling laws of LLM pretraining (how much data to use for a given model size) is pretty well studied. Has anyone done is the same study for fine-tuning?\n It seems quite an interesting question because while for pretraining we know that we should increase the dataset size with the model size, it seems like fine-tuning works pretty well with very few data / training steps even for relatively large models. Could it be the case that we are better off using less data / training steps and compensate by using a larger model? \n I have only fine-tuned a few LLMs so I don't have a good grasp on the scaling properties. Would appreciate any insights / intuition.\n    submitted by    /u/bjergerk1ng  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15589hi/d_scaling_laws_for_llm_finetuning/",
          "publishedOn": "2023-07-21T00:26:02.000Z",
          "wordCount": 2597,
          "title": "[D] Scaling Laws for LLM Fine-tuning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15531o7/d_bmvc_reviews_experience/",
          "author": null,
          "description": "I got 4 reviewers on my paper submitted to BMVC with ratings of BA (borderline accept), BA, BA, and A. What are our chances? I finished preparing the rebuttal but I can’t stop thinking about the outcome. Please let me know if you have any experience or insights. Thanks\n    submitted by    /u/Admirable_Cell_5256  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15531o7/d_bmvc_reviews_experience/",
          "publishedOn": "2023-07-20T20:57:36.000Z",
          "wordCount": 2526,
          "title": "[D] BMVC reviews experience",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15531i8/d_embedding_human_preferences_in_llms/",
          "author": null,
          "description": "Hi everyone,\n Can someone point to a comprehensive but accessible resource on the approaches to \"embed\" human preferences in LLMs?\n I saw Chip Huyen's post and it is super cool, but I wonder if/why the designer of such systems tends not to add text properties/contexts as an \"input feature\".\n For instance, a numerical feature representing the year the text was produced, or a flag telling if the text is from a book seems a straightforward way to control/condition the generation. Still, I'm missing some concepts here.\n    submitted by    /u/BenXavier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15531i8/d_embedding_human_preferences_in_llms/",
          "publishedOn": "2023-07-20T20:57:24.000Z",
          "wordCount": 2567,
          "title": "[D] Embedding human preferences in LLMs (beyond/besides RLHF)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1552y9y/d_perspectives_on_diffusion/",
          "author": null,
          "description": "Hi /r/ML,\n I wrote a blog post about a bunch of different perspectives on diffusion models. It's basically an extended sequel to another blog post I wrote last year, where I explored the connection between diffusion models and denoising autoencoders. There are many more of these connections, but unfortunately I don't have time to write separate blog posts about each of them, so I put them all together. Keen to hear what you think!\n https://sander.ai/2023/07/20/perspectives.html\n    submitted by    /u/benanne  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1552y9y/d_perspectives_on_diffusion/",
          "publishedOn": "2023-07-20T20:53:56.000Z",
          "wordCount": 2552,
          "title": "[D] Perspectives on diffusion",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1552rpu/d_how_the_heck_do_i_benchmark_ais_and_gpus/",
          "author": null,
          "description": "I'm trying to get some real world benchmarks for both nvidia and amd. So far it's been a nightmare! Stable diffusion stopped working on my pc, Conversational model testing with a stop watch was too fast to track, and I can't think of any other way to test these GPU's.\n Hard numbers. That's what I want. I can benchmark cyberpunk, but ai is a complete mystery. How do I recommend somebody a gpu if I can't compare it to results. Is there a point to upgrading from a 3090 to a 4090. Some reddits say no. Others yes. \n I need some tests and I need em bad\n    submitted by    /u/SociallyApparent  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1552rpu/d_how_the_heck_do_i_benchmark_ais_and_gpus/",
          "publishedOn": "2023-07-20T20:47:00.000Z",
          "wordCount": 2590,
          "title": "[D] How the heck do I benchmark AI's AND GPU's?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1552a3z/p_what_would_be_a_good_modelpipeline_for_simple/",
          "author": null,
          "description": "So i have been exploring the potential of simple intent identifiers so a task recently, i have explored rasa but the fact that it doesn't work with Python 3.10/3.11 is a major Pain and throws a wreck on my plans for large integration into other projects.\n I am looking for either a pipeline/framework (could be something like RASA or a standalone model) that has intent recognition capacities, with multi-lingual support (Portuguese) and can run on newer python versions (doesn't give me compatibilities headaches) and also i want a relatively lightweight model considering my simple task\n Could you guys recommend something like that for me?\n    submitted by    /u/SnooPineapples7791  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1552a3z/p_what_would_be_a_good_modelpipeline_for_simple/",
          "publishedOn": "2023-07-20T20:29:25.000Z",
          "wordCount": 2598,
          "title": "[P] What would be a good model/pipeline for simple intent recognition that has multi-lingual support and is easy to set up?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1551wp6/p_run_llama_2_locally_in_7_lines_apple_silicon_mac/",
          "author": null,
          "description": "Want to start playing with Meta’s Llama 2?\n It takes just 7 lines of shell script using llama.cpp to get you started!\n https://preview.redd.it/vhuzhrj4h6db1.png?width=2030&format=png&auto=webp&s=d349dd796039f3af7e117423c4abdae7efde2fae\n Copy Code Snippet: https://lastmileai.dev/workbooks/clkbifegg001jpheon6d2s4m8 \n    submitted by    /u/InevitableSky2801  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1551wp6/p_run_llama_2_locally_in_7_lines_apple_silicon_mac/",
          "publishedOn": "2023-07-20T20:15:40.000Z",
          "wordCount": 2510,
          "title": "[P] Run Llama 2 Locally in 7 Lines! (Apple Silicon Mac)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1550job/p_how_to_fine_tune_8k_context_length_llama_13b_on/",
          "author": null,
          "description": "I have a llama 13B model I want to fine tune. I am using qlora (brings down to 7gb of gpu memory) and using ntk to bring up context length to 8k (dataset requires at least this much context length).\n But on 1024 context length, fine tuning spikes to 42gb of gpu vram used, so evidently it won’t be feasible to use 8k context length unless I use a ton of gpus. Is there anyway to lower memory so that one or two 3090s are enough for 8k context length fine tuning?\n    submitted by    /u/bahibo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1550job/p_how_to_fine_tune_8k_context_length_llama_13b_on/",
          "publishedOn": "2023-07-20T19:24:28.000Z",
          "wordCount": 2580,
          "title": "[P] How to fine tune 8k context length Llama 13B on minimal number of gpus?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1550fpn/d_need_career_advise_on_what_should_i_do_next_in/",
          "author": null,
          "description": "Hey everyone, hope you all are doing great. I just completed Machine Learning Specialization on Coursera by Andrew Ng and was looking for some advise on what I should do next. Would love to hear input from you guys.\n I'm self studying Machine Learning full-time, while I'm also getting a bachelors degree in Computer Science from an online virtual university. It's been 3+ months since I've stepped into Machine Learning and so far I've been developing deep intuition and foundational concepts of Machine Learning . Since I'm really passionate about mathematics, I'm very much focused on understanding the mathematics behind everything.\n By completing this specialization I've developed good foundational concepts of the following:\n • Supervised Machine Learning\n • Linear regression\n • Logistic regr…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1550fpn/d_need_career_advise_on_what_should_i_do_next_in/",
          "publishedOn": "2023-07-20T19:20:22.000Z",
          "wordCount": 2903,
          "title": "[D] Need career advise on what should I do next in ML :(",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/154yd45/d_has_anything_from_the_agent57_paper_been_used/",
          "author": null,
          "description": "I read the blog post and paper for Agent57 and thought it was pretty interesting but haven't seen people talk about it much since then. Has it been used for anything? If not, why hasn't it been very influential? \n    submitted by    /u/sledpull  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/154yd45/d_has_anything_from_the_agent57_paper_been_used/",
          "publishedOn": "2023-07-20T18:04:06.000Z",
          "wordCount": 2525,
          "title": "[D] Has anything from the Agent57 paper been used in anything interesting lately?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/154y0iu/d_best_free_llm_for_text_classification/",
          "author": null,
          "description": "Hey all,\n I want to retrieve all speeches from congressional records from the house of representatives where the politician talks about the tax behavior of companies. I currently load the records into my script and divide the records into all the speeches. Then I use keyword search to determine whether the politician talks about tax behavior of companies. I want to replace this keyword search with an LLM which classifies the speeches. I will analyze > 50,000 speeches, so I dont want to use a costly model like GPT4. Actually I want to spend max 10€ in total. What LLM's, which I can access via an API, would you recommend for this task?\n Thanks in advance\n    submitted by    /u/Silly_Pack9404  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/154y0iu/d_best_free_llm_for_text_classification/",
          "publishedOn": "2023-07-20T17:51:32.000Z",
          "wordCount": 2596,
          "title": "[D] Best free LLM for text classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/154vlnr/d_disappointing_llama_2_coding_performance_are/",
          "author": null,
          "description": "I've been excitedly reading the news and discussions about Llama 2 the past couple of days, and got a chance to try it this morning.\n I was underwhelmed by the coding performance (running the 70B model on https://llama2.ai/). It has consistently failed most of the very-easy prompts that I made up this morning. I checked each prompt with ChatGPT 3.5, and 3.5 got 100% (which means these prompts are quite easy). This result was surprising to me based on the discussion and articles I've read. However, digging into the paper (https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/), the authors are transparent that the coding performance is lacking.\n Are my observations consistent with the results others are getting?\n I haven't had time to keep up with all the open-source LLMs being worked on by the community; are there any other models that approach even ChatGPT 3.5's coding performance? (Much less GPT 4's performance, which is the real goal.)\n    submitted by    /u/Egan_Fan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/154vlnr/d_disappointing_llama_2_coding_performance_are/",
          "publishedOn": "2023-07-20T16:22:58.000Z",
          "wordCount": 2646,
          "title": "[D] Disappointing Llama 2 Coding Performance: Are others getting similar results? Are there any other open-source models that approach ChatGPT 3.5's performance?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/154tojr/simple_textgeneration_evaluationbenchmark_for/",
          "author": null,
          "description": "slmqa on GitHub\n I spent hours searching for a way to compare the quality of the text-generation of instruct-tuned small language models. Failing to find an evaluation simple enough for a small model, and easy to use, it was easier to create one. I'm sharing it here in case anyone else finds it useful.\n slmqa\n slmqa is a simple question-answer evaluation benchmark for small language models. It includes a dataset of 909 general knowledge question-answer pairs. The QA pairs were generated with gpt-3.5-turbo, stripped of duplicates and answers shorter than 5 characters, and cleaned by hand.\n The score is the percentage of correct answers.\n Sample\n json { \"question\": \"What is the name of the highest mountain in the world?\", \"answer\": \"everest\" }, { \"question\": \"What is the name of the famous Austrian composer who wrote the Ninth Symphony?\", \"answer\": \"beethoven\" }, { \"question\": \"Which country is the largest by area?\", \"answer\": \"russia\" }, \n    submitted by    /u/Pan000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/154tojr/simple_textgeneration_evaluationbenchmark_for/",
          "publishedOn": "2023-07-20T15:13:36.000Z",
          "wordCount": 2633,
          "title": "Simple text-generation evaluation/benchmark for Small Language Models [GitHub] [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/154tndi/d_security_and_protection_in_ml_deployments/",
          "author": null,
          "description": "After researching quite heavily on how to protect Python based inference code and models when they are deployed on client infrastructure. I came across pyinstaller and pyoxidizer but looks like they do not work that well. So I concluded that the best way is to convert critical pipelines to C++ is that correct ?\n    submitted by    /u/Ok-Influence368  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/154tndi/d_security_and_protection_in_ml_deployments/",
          "publishedOn": "2023-07-20T15:12:24.000Z",
          "wordCount": 2534,
          "title": "[D] Security and protection in ML deployments",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/154rzvx/d_what_llms_do_you_use_the_most/",
          "author": null,
          "description": "With the emergence of new models gaining more popularity such as Claude 2, Llama 2 which has the potential for better fine-tuned models, the development of Bard, the controversies surrounding ChatGPT performing worse and with the already-existing content filters that limits the capabilities of models not just subjecting to moral standards and policies that align with human values but also limits it to other factors that may not fall under objective morality or maybe just it being too sensitive, is there a certain model you think is currently the best overall one at least for now other than GPT-4? \n I'm really curious to know what the community thinks as I've searched a lot and found a lot of clashes in opinions regarding what models are considered superior over others and the clickbait-ish talks and titles about model so-and-so being \"The ChatGPT Killer\". \n With all this info in consideration, what model(s) do you ACTUALLY use the most? I'd be grateful if you shared your thoughts about this issue and thanks for your time.\n    submitted by    /u/Fantastic-Air8513  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/154rzvx/d_what_llms_do_you_use_the_most/",
          "publishedOn": "2023-07-20T14:10:09.000Z",
          "wordCount": 2653,
          "title": "[D] What LLMs do you use the most?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/154rmeb/d_any_cool_project_ideas_with_this_data/",
          "author": null,
          "description": "I've uploaded a reddit dataset that has multiple Reddit posts along with the most upvoted comment for each post. The dataset is collected from 9 subreddits. \n I'm looking for cool project ideas with this data. Let's discuss!\n https://www.reddit.com/r/datasets/comments/154pe3y/reddit_posts_dataset_with_the_top_comment/?utm_source=share&utm_medium=android_app&utm_name=androidcss&utm_term=1&utm_content=1\n    submitted by    /u/04RR  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/154rmeb/d_any_cool_project_ideas_with_this_data/",
          "publishedOn": "2023-07-20T13:55:37.000Z",
          "wordCount": 2519,
          "title": "[D] Any cool project ideas with this data?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/154opkg/p_interactive_exploration_of_stable_diffusion/",
          "author": null,
          "description": "I just created a Huggingface Space showcasing how to interactively explore the outputs of a Stable Diffusion model via CLIP Embeddings.\n Embedding-based image similarity plotted in 2D via dimensionality reduction.\n The visualization is done using the tool Spotlight.\n Also, I created a tutorial showcasing how to automatically select promising prompts and images from a large dataset. It is roughly based on the following approach:\n  \nCalculate the CLIP Score for all prompt-image pairs to measure generation quality.\n Generate CLIP Embeddings to be able to calculate a similarity between images (or texts)\n Embedding-based identification of clusters that have an exceptionally high CLIP Score.\n  \nHave you ever explored any (automatic) evaluation strategies for image generation models? I would love to learn about some alternative approaches.\n    submitted by    /u/OkResearch6289  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/154opkg/p_interactive_exploration_of_stable_diffusion/",
          "publishedOn": "2023-07-20T11:48:15.000Z",
          "wordCount": 2603,
          "title": "[P] Interactive Exploration of Stable Diffusion Generated Images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/154jkqy/d_handle_dozen_of_thousands_of_classes/",
          "author": null,
          "description": "Hello ! \n I'm working on a project of NLP classification with more or less 13k classes. The best model I had so far is a fine-tuned LLM encoder. However, with the number of classes I have now, it is very slow. So I searched for ways to deal with that, and found 2:\n  \nHierarchical Softmax\n Negative Sampling\n  \nHowever, both seems to have been used nearly only in the context of word2vec training, so I wonder if there is a reason why that would not work for a \"classical\" classification ? (or just my kind of problem too rare ?) \n Also, I did find really few implementations of those with Pytorch, a fortiori with transformers... Is it because there is something better ? Do you know, if not, some recent implementations ?\n ​\n Thank you in advance !\n    submitted by    /u/ez613  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/154jkqy/d_handle_dozen_of_thousands_of_classes/",
          "publishedOn": "2023-07-20T07:04:16.000Z",
          "wordCount": 2616,
          "title": "[D] Handle dozen of thousands of classes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/154jdtf/d_does_anyone_know_what_sorcery_sams_official_web/",
          "author": null,
          "description": "This is specifically in regards to automatic mask generation, where SAM samples a grid of points (32x32 grid by default) and creates a mask for each point prompt. Duplicates are then removed by NMS. Ideally this process shouldn't be able to auto-generate complex structures that require multiple positive/negative point prompts, and that is what I have observed when using the models locally.\n But, the \"Everything\" option in the web demo(https://segment-anything.com/demo) does insanely well. It can even segment occluded objects into a single disconnected mask. It is supposed to be running in the browser and is reasonably fast, so they can't be doing some super heavy pre/post-processing either. \n Anyone have an idea of what the \"Everything\" option in the web demo is doing?\n    submitted by    /u/Atom_101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/154jdtf/d_does_anyone_know_what_sorcery_sams_official_web/",
          "publishedOn": "2023-07-20T06:53:29.000Z",
          "wordCount": 2613,
          "title": "[D] Does anyone know what sorcery SAM's official web demo uses? I just cannot replicate the results locally.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/154hgek/p_minigpt4cpp_4bit5bit16float_minigpt4_inference/",
          "author": null,
          "description": "https://github.com/Maknee/minigpt4.cpp\n    submitted by    /u/makneeee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/154hgek/p_minigpt4cpp_4bit5bit16float_minigpt4_inference/",
          "publishedOn": "2023-07-20T05:02:11.000Z",
          "wordCount": 2481,
          "title": "[P] MiniGPT4.cpp: (4bit/5bit/16float) MiniGPT4 inference on CPU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1547wcv/p_running_llama_2_locally_in_10_min/",
          "author": null,
          "description": "I wanted to play with Llama 2 right after its release yesterday, but it took me ~4 hours to download all 331GB of the 6 models. If you don’t have 4 hours or 331GB to spare, I brought all the models into XetHub, where it’s now available for you to use: https://xethub.com/XetHub/Llama2.\n I used xet mount to get started in seconds, and within a few minutes, I had the model generating text without needing to download everything or make an inference API call. \n # From a g4dn.8xlarge instance in us-west-2:\n Mount complete in 8.629213s\n # install model requirements, and then ...\n (venv-test) ubuntu@ip-10-0-30-1:~/Llama2/code$ torchrun --nproc_per_node 1 example_chat_completion.py \\\n --ckpt_dir ../models/llama-2-7b-chat/ \\\n --tokenizer_path ../models/tokenizer.model \\\n --max_seq_len 512 --max_batch_size 4\n > initializing model parallel with size 1\n > initializing ddp with size 1\n > initializing pipeline with size 1\n Loaded in 306.17 seconds\n User: what is the recipe of mayonnaise?\n > Assistant: Thank you for asking! Mayonnaise is a popular condiment made from a mixture of egg yolks, oil, vinegar or lemon juice, and seasonings. Here is a basic recipe for homemade mayonnaise:\n ...\n Detailed instructions here: https://xethub.com/XetHub/Llama2.\n I’ll add the -GGML variants next for the folks using llama.cpp. Don’t forget to register with Meta to accept the license and acceptable use policy for these models!\n    submitted by    /u/rajatarya  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1547wcv/p_running_llama_2_locally_in_10_min/",
          "publishedOn": "2023-07-19T21:42:41.000Z",
          "wordCount": 2670,
          "title": "[P] Running Llama 2 locally in <10 min",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1547cv5/d_why_people_okay_with_hf_making_money_from_their/",
          "author": null,
          "description": "Hugging Face has a big emphasis on open source and the democratization of ML. Still, from a different look, they are making a ton of money from freely distributed open-source models of researchers and engineers without sharing a dime. I like what Hugging Face does, but it doesn't look right to me. \n I understand it's a company and needs to make money but at the very least some kind of revenue sharing would make more sense. \n I wonder what the community thinks about it. \n Maybe some people who distribute their models on HF can comment on thi topic\n    submitted by    /u/coinfelix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1547cv5/d_why_people_okay_with_hf_making_money_from_their/",
          "publishedOn": "2023-07-19T21:21:45.000Z",
          "wordCount": 2559,
          "title": "[D] Why people okay with HF making money from their open source models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15478c9/r_converting_neural_networks_into_equivalent/",
          "author": null,
          "description": "According to the paper Neural Networks are Decision Trees (Aytekin 2022), every single type of neural network - regardless of the activation functions used - can be reduced to an equivalent decision tree with equivalent accuracy: [2210.05189] Neural Networks are Decision Trees (arxiv.org)\n That is not to say that decision trees necessarily tend to converge on the same types of solutions as neural networks in training; only that a trained neural network can be represented by an equivalent decision tree.\n The algorithm, as mentioned in the paper, is:\n Algorithm 2: Algorithm of converting neural networks to decision trees\n 1 Initialize Tree: Set root.\n 2 Branch all leafs to k nodes, decision rule is first effective filter.\n 3 Branch all nodes to k more nodes, and repeat until all effective filters in a layer is covered.\n 4 Calculate effective matrix for each leaf via Eq. 5. Repeat 2,3.\n 5 Repeat 4 until all layers are covered.\n 6 return Tree\n I have 2 questions related to this:\n  \nIs anyone aware of the inference performance implications of this? In my general understanding, decision trees tend to be much more computationally efficient at both training and inference. So is it true that this represents an opportunity to decrease the processing load of inference on neural networks, or does the computational complexity of performing inference with an equivalent decision tree tend to approach or surpass the equivalent neural network?\n Question 2 is kind of a moot point if #1 doesn't provide performance benefits. But assuming it does, does anyone know of techniques in 2023 for reducing a neural network to an equivalent decision tree? \n  \n   submitted by    /u/Immarhinocerous  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15478c9/r_converting_neural_networks_into_equivalent/",
          "publishedOn": "2023-07-19T21:16:59.000Z",
          "wordCount": 2727,
          "title": "[R] Converting neural networks into equivalent decision trees for performance",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1544si8/d_is_conference_competition_track_like_neurips/",
          "author": null,
          "description": "Is it worth the time to pour time and effort into NeurIPS's annual competitions? Winners got to present at NIPS workshops.\n I'm currently pursuing a Master degree in CS now and have to compete in one of them. I looked up past winners, all of them are from Top CS schools or Large Tech's research teams. So I kind of figured how hard they are to compete.\n But could someone give me some general advices? I have talked to some of my friends pursuing phd but they are not familiar with the NIPS competition track.\n Any help is appreciated. Thank you strangers!\n    submitted by    /u/HighlandEvil  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1544si8/d_is_conference_competition_track_like_neurips/",
          "publishedOn": "2023-07-19T19:42:33.000Z",
          "wordCount": 2562,
          "title": "[D] Is Conference Competition Track like NeurIPS Competition a Glorified Kaggle Competition?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1542zpg/n_minari_040_is_live_gym_for_offline_rl_by_the/",
          "author": null,
          "description": "Minari now has full support for Dict, Tuple, Discrete, Box, and Text spaces without flattening, explicit dataset versioning, plus subsets of action/obs spaces in datasets. Additionally, new v1 versions of each dataset were released to comply with the new dataset format. The new datasets do not have observation and action flattening (relevant for pointmaze datasets), introduce serialized representations of action and observation spaces in the observation_space and action_space fields, and specify minari version compatibility with the minari_version field. Python 3.11 compatibility was added, with removal of 3.7 support as it has reached end-of-life. We also include two new tutorials: observation space subsetting, and behavior cloning with rl_zoo3 and pytorch DataLoader.\n Announcement Tweet: https://twitter.com/FaramaFound/status/1681730025513467931\n Release Notes: https://github.com/Farama-Foundation/Minari/releases/tag/v0.4.0\n    submitted by    /u/elliottower  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1542zpg/n_minari_040_is_live_gym_for_offline_rl_by_the/",
          "publishedOn": "2023-07-19T18:32:56.000Z",
          "wordCount": 2577,
          "title": "[N] Minari 0.4.0 is live! (Gym for offline RL, by the Farama Foundation)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1542fbt/p_trulenseval_is_an_open_source_project_for_eval/",
          "author": null,
          "description": "Hey r/MachineLearning,\n The team at TruEra recently released an open source project for evaluation & tracking of LLM applications called TruLens-Eval. We’ve specifically targeted retrieval-augmented QA as a core use case and so far we’ve seen it used for comparing different models and parameters, prompts, vector-db configurations and query planning strategies. I’d love to get your feedback on it.\n The core idea behind the project is feedback functions. Analogous to labeling functions, feedback functions are models used to score the text produced by LLMs. We already have a variety of out-of-the-box feedback functions to use for eval including relevance, language match, sentiment and moderation that can be applied to inputs, outputs or intermediate steps of your application.\n On top of eval, there’s also built-in tracking of cost and latency.\n We made it easy to integrate with different setups using connectors for langchain, llama-index + an option to use it without a framework.\n Langchain Quickstart Colab\n Llama-Index Quickstart Colab\n No Framework Quickstart Colab\n Last, the project comes with a streamlit dashboard for visualization of your experiments and associated metrics.\n TruLens dashboard for comparing different app versions\n Please let us know what you use this for or if you have feedback! And thanks to all contributors to this project and the open source community!\n    submitted by    /u/joshreini1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1542fbt/p_trulenseval_is_an_open_source_project_for_eval/",
          "publishedOn": "2023-07-19T18:11:03.000Z",
          "wordCount": 2673,
          "title": "[P] TruLens-Eval is an open source project for eval & tracking LLM experiments.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/153zyve/r_how_is_chatgpts_behavior_changing_over_time/",
          "author": null,
          "description": "submitted by    /u/osantacruz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/153zyve/r_how_is_chatgpts_behavior_changing_over_time/",
          "publishedOn": "2023-07-19T16:35:51.000Z",
          "wordCount": 2467,
          "title": "[R] How is ChatGPT's behavior changing over time?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/153zl88/p_how_exactly_can_i_download_the_inception_model/",
          "author": null,
          "description": "I run into multiple errors each time I try to use inception scores and Im trying to evaluate the differences between using the Inception Score and Fréchet Inception Distance.\n    submitted by    /u/cinnamonstuff  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/153zl88/p_how_exactly_can_i_download_the_inception_model/",
          "publishedOn": "2023-07-19T16:21:27.000Z",
          "wordCount": 2491,
          "title": "[P] How exactly can I download the inception model v3 to my laptop (windows)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/153z255/n_ensuring_reliable_fewshot_prompt_selection_for/",
          "author": null,
          "description": "Hello Redditors!\n It's pretty well known that LLMs have firmly established themselves as leaders in the field of natural language processing, consistently pushing the limits of language comprehension and generation, which is widely acknowledged.\n I spent a little time playing around with few-shot prompting for OpenAI's Davinci model and I discovered that noisy data still has drastic effects even on powerful LLMs like Davinci.\n mislabeled few-shot examples harms LLM performance drastically\n I wrote up a quick article in KDNuggets that shows how I used data-centric AI to automatically clean the noisy few-shot examples pool in order to achieve more accurate predictions. The resulting few-shot prompt with accurately labeled examples produced 20% fewer errors than the original one with mislabeled examples.\n This one was quite eye-opening for me and I hope you find it is as interesting as I did. Let me know what you think!\n    submitted by    /u/cmauck10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/153z255/n_ensuring_reliable_fewshot_prompt_selection_for/",
          "publishedOn": "2023-07-19T16:01:37.000Z",
          "wordCount": 2601,
          "title": "[N] Ensuring Reliable Few-Shot Prompt Selection for LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/153yzxg/d_how_hard_are_neurips_competition/",
          "author": null,
          "description": "Is it worth the time to pour time and effort into NeurIPS's annual competitions? Winners got to present at NIPS workshops.\n    submitted by    /u/HighlandEvil  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/153yzxg/d_how_hard_are_neurips_competition/",
          "publishedOn": "2023-07-19T15:59:39.000Z",
          "wordCount": 2475,
          "title": "[D] How Hard Are NeurIPS Competition?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/153yfry/n_upstage_ais_30m_llama_1_outshines_70b_llama2/",
          "author": null,
          "description": "Title Fix: Upstage AI's 30B Llama 1 Outshines 70B Llama2, Dominates #1 Spot in OpenLLM Leaderboard!\n We are thrilled to share an extraordinary achievement with you today. Our team at Upstage AI has reached a significant milestone. Our fine-tuned 30B model, Llama 1, has ascended to the coveted #1 position on the prestigious global OpenLLM Leaderboard. In a thrilling turn of events, our fine-tuned 30B Llama 1 has outperformed the 70B model of Llama2.\n Please check out the leaderboard and download/use our model at https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\n Once again, we are happy to bring this news to all of you. Stay tuned for more exciting updates from Upstage AI!\n https://preview.redd.it/m7xzlzrpyxcb1.png?width=2310&format=png&auto=webp&s=23429478474d23071837fe9c2e85e6ddea10039c\n    submitted by    /u/hunkims  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/153yfry/n_upstage_ais_30m_llama_1_outshines_70b_llama2/",
          "publishedOn": "2023-07-19T15:38:18.000Z",
          "wordCount": 2570,
          "title": "[N] Upstage AI's 30M Llama 1 Outshines 70B Llama2, Dominates #1 Spot in OpenLLM Leaderboard!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/153vzu6/project_unofficial_implementation_of_retentive/",
          "author": null,
          "description": "So very recently, a new paper was published to ArXiV called \"Retentive Network: A Successor to Transformer for Large Language Models\": https://arxiv.org/abs/2307.08621. The title makes a fairly strong claim regarding the success of the model: transformers have long been established as among the best general-purpose learning techniques in the deep learning literature. Self-describing as a \"successor to transformer\" is therefore not to be taken lightly.\n From what I can tell, the math checks out, and the authors demonstrate an intriguing dualism between their transformer-like \"retention\" (analogous to attention) and an equivalent recurrent formulation. The core idea is that you can train in parallel (as with transformers) and then run inference in sequence with O(N) time and memory requirements in the length of the sequence (traditional transformers are O(N^2)).\n If the results can be replicated/peer-reviewed, this could pave the way for substantial all-round improvements to large language modelling. The authors have indicated that they will make code available relatively soon.\n For now though, there's an unofficial implementation on GitHub which hopefully will allow those interested to play around with the model and verify some results. The code is publicly available and can be found by searching Jamie-Stirling/RetNet on GitHub.\n    submitted by    /u/Entire-Plane2795  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/153vzu6/project_unofficial_implementation_of_retentive/",
          "publishedOn": "2023-07-19T14:04:46.000Z",
          "wordCount": 2654,
          "title": "[Project] Unofficial implementation of Retentive Network (GitHub repo)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/153tvo1/p_how_does_batch_processing_work_for_graphs_in/",
          "author": null,
          "description": "Hi I have a bunch of graphs that I would like to divide into batches for parallel processing but since the edge indices are not of the same shape I am unable to stack them into a batch tensor like how we normally do for normal euclidian data. I tried to find some documentation on it but I was unable to understand the exact process.\n Basically most documentation show them concatenating all the graphs together into a larger graph and then passing it through a GCN module but I don't think that would work since graphs are clearly distinct and independent of each other. Even if I concatenate them together, pass them through through the module and then separate them later using the same bounds by which I concatenated would it cause any unpredictable behaviour (even though the graphs technically do not have edge connecting them)? Do I have to code this logic myself or is it hidden somewhere in PyG since I was unable to find it. I am new to GCNs so I just want to see if I have it right before I commit to it.\n    submitted by    /u/Sad-Tap-3790  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/153tvo1/p_how_does_batch_processing_work_for_graphs_in/",
          "publishedOn": "2023-07-19T12:38:00.000Z",
          "wordCount": 2648,
          "title": "[P] How does batch processing work for graphs in Pytorch Geometric?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/153tvl8/d_looking_for_the_best_possible_llm_for_a_complex/",
          "author": null,
          "description": "I am looking for a LLM that can handle more than 10000 tokens at a time, with large model size and a good context understanding. \n I tried chatGPT but it seems to forget some of the context after 4-5 prompts. \n I tried PI.ai and it first understood all the context before forgetting it as it asked questions to better understand what all the variables are. \n The problem is logical and mathematical (may use Dijkstra's algorithm to solve it) and try to optimize production while keeping waste as little as possible. The solution would ideally include a python script that can be used for solving the problem with different inputs. \n What do you guys would recommend ?\n    submitted by    /u/Glassensteel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/153tvl8/d_looking_for_the_best_possible_llm_for_a_complex/",
          "publishedOn": "2023-07-19T12:37:54.000Z",
          "wordCount": 2584,
          "title": "[D] Looking for the best possible LLM for a complex logical problem with long description and a lot of variable",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/153sl0y/project_running_llama2_locally_on_apple_silicon/",
          "author": null,
          "description": "Project page: https://github.com/mlc-ai/mlc-llm\n Instructions: https://mlc.ai/mlc-llm/docs/get_started/try_out.html\n Performance: 46 tok/s on M2 Max, 156 tok/s on RTX 4090.\n  \nMore hardwares & model sizes coming soon! This is done through the MLC LLM universal deployment projects. Besides the specific item, we've published initial tutorials on several topics over the past month:\n  \nBuilding instructions for discrete GPUs (AMD, NV, Intel) as well as for MacBooks, iOS, Android, and WebGPU.\n A conversation customization mechanism that covers system prompts, roles, and more.\n API tutorials for various programming languages, such as C++, Swift, Java, and Python.\n REST APIs and Integrations with Gradio.\n Installation guides for dependencies like TVM and WASM.\n  \nUpdate: It is also now available in iphone/ipads\n    submitted by    /u/crowwork  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/153sl0y/project_running_llama2_locally_on_apple_silicon/",
          "publishedOn": "2023-07-19T11:39:06.000Z",
          "wordCount": 2569,
          "title": "[Project] Running Llama2 Locally on Apple Silicon and Consumer GPUs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/153s3w5/d_training_with_torchort/",
          "author": null,
          "description": "Some questions:\n  \nWhat are the rough edges of training models with torch-ort?\n How mature is it these days?\n At what scale do you notice worthwhile speedups compared to vanilla pytorch? Suppose you are training models with 1 million or 10 million parameters on a single gpu. Is it worth it? 100 million parameters?\n  \n   submitted by    /u/Pleasant_Raise_6022  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/153s3w5/d_training_with_torchort/",
          "publishedOn": "2023-07-19T11:15:54.000Z",
          "wordCount": 2505,
          "title": "[D] Training with torch-ort?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/153qfbo/d_how_to_finetune_pointrend_with_detectron2/",
          "author": null,
          "description": "Context: I am working on an instance segmentation problem where I am using PointRend on detectron2 backend for predicting masks over car-parts in our custom datasets. Keeping the configs as is from the repo except iterations raised to 3,90,000 and batch size = 2 (reason being my colleague produced good results using the same config on a similar dataset), I fine-tuned the pretrained model on our dataset. I have the following training curves:\n Loss curves\n For sanity check, I have been saving weights at regular intervals and have made inferences on them over some handful sample images for mask quality. However, what I have observed is that out of 10368 curated polygons, even after such long training, my model has predicted only 7401 polygons.\n Discussion Points:\n  \nWhat should I do to increase the predicted polygon numbers without compromising the quality of masks?\n Which hyper-parameters (or parameters) I should look into while fine-tuning (or training) for better mask quality and higher f-score?\n  \nThank you.\n    submitted by    /u/Prady029  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/153qfbo/d_how_to_finetune_pointrend_with_detectron2/",
          "publishedOn": "2023-07-19T09:49:18.000Z",
          "wordCount": 2626,
          "title": "[D] How to fine-tune PointRend with detectron2 backbone for better mask quality and improved results?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/153p0id/d_vits_memory_requirements_training_time_and/",
          "author": null,
          "description": "My supervisor has asked me to try to create a table in which for each ViT model (ViT-s, ViT-b, ViT-l, and ideally Swin transformers), their estimated memory requirements (given some batch size), training time (based on arbitrary hardware) and on par ResNet model is specified.\n I've been searching for quite a lot of time, and I absolutely can't find anything. Even the original ViT paper had no information in this regard. Do you think there's any way I can find this information? I'm afraid I don't have access to my supervisor until next week to ask, and I can't wait that long.\n    submitted by    /u/Stochasticc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/153p0id/d_vits_memory_requirements_training_time_and/",
          "publishedOn": "2023-07-19T08:29:17.000Z",
          "wordCount": 2559,
          "title": "[D] ViT's memory requirements, training time, and equivalent ResNet",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/153ndrn/which_textgen_benchmark_to_use_for_100m_parameter/",
          "author": null,
          "description": "I've got model pretraining running on NanoGPT for a GPT2 tokenized dataset and a TokenMonster tokenized dataset, so I can compare the difference. It's only a 100M parameter model, so it doesn't do much.\n What benchmark can I use? NanoGPT runs on Pytorch, so I could use something that integrates with PyTorch, or I could use something that sends text prompts and analyzes text responses (or token IDs.)\n Is there a standard benchmark that uses the full, non-instruct trained format? For example:\n Answer the following questions: Question: What is the capital of France? Answer: Paris. Question: What is the opposite of up? Answer: \n The model is only 100M parameters and not instruct trained, so it usually just rambles instead of answering. But anything that gives me a quantifiable result that can compare 2 models for quality is useful. I have loss and perplexity already, but it's not enough.\n    submitted by    /u/Pan000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/153ndrn/which_textgen_benchmark_to_use_for_100m_parameter/",
          "publishedOn": "2023-07-19T06:57:00.000Z",
          "wordCount": 2609,
          "title": "Which text-gen benchmark to use for 100M parameter (NanoGPT) pretrained-only language model? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/153lvrv/r_out_of_domain_problem_with_synthetic_image_data/",
          "author": null,
          "description": "Hi all,\n I am currently trying to improve synthetically generated images (not by AI) in a particular domain. I have a dataset with real images of the domain and one with synthetic data. If I now train a classifier to say whether an image is real or synthetic, after a short \"time\" the classifier has a very high accuracy with a very high confidence. Then I have two cases.\n First case:\n In the next step I change my synthetic images (e.g. by a bayer pattern) and the confidence of the classifier decreases.\n Second case:\n Alternatively, if I simply take synthetic images from another domain, the confidence also drops.\n How can I prove or check that I am still in the right domain in the first case?\n I am happy about any help!\n    submitted by    /u/rlmtsrtz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/153lvrv/r_out_of_domain_problem_with_synthetic_image_data/",
          "publishedOn": "2023-07-19T05:35:16.000Z",
          "wordCount": 2585,
          "title": "[R] Out of domain Problem with synthetic image data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/153hv3b/n_gymnasium_v0290_has_been_released/",
          "author": null,
          "description": "Gymnasium v0.29.0 is out! This release includes 6 months' worth of bug fixes and new features. In particular, it deprecates several features: Wrapper.__get_attr__, gymnasium.make(..., autoreset=True), gymnasium.make(..., apply_api_compatibility=True), Env.reward_range and gymnasium.vector.make that will be removed in v1.0.\n Additionally, as python 3.7 has reached its end of life support, we have dropped support for it and updated MuJoCo Hopper & Walker2D models to work with MuJoCo >= 2.3.3.\n This release also includes an official way to cite Gymnasium. While a full paper is still some time away, you can now use the DOI 10.5281/zenodo.8127025 for citations: https://zenodo.org/record/8127025\n Announcement Tweet: https://twitter.com/FaramaFound/status/1681479718774743040\n Release Notes: https://github.com/Farama-Foundation/Gymnasium/releases/tag/v0.29.0\n    submitted by    /u/elliottower  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/153hv3b/n_gymnasium_v0290_has_been_released/",
          "publishedOn": "2023-07-19T02:17:10.000Z",
          "wordCount": 2555,
          "title": "[N] Gymnasium v0.29.0 has been released!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/153gnql/d_handwriting_training/",
          "author": null,
          "description": "Is there an ai like calligrapher ai where you can write a prompt then it will show but for the styles is there another ai that can write in your handwriting from giving it some samples?\n    submitted by    /u/Ok_Presence_3287  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/153gnql/d_handwriting_training/",
          "publishedOn": "2023-07-19T01:22:31.000Z",
          "wordCount": 2470,
          "title": "[D] Handwriting training?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/153f09g/d_anomaly_scoring_methods_for_subsequence_anomaly/",
          "author": null,
          "description": "I'm interested in detecting a subsequence as being anomalous or not. If we imagine that there's a prediction model that can forecast some number of forward steps and we can compare this prediction with the observation, we can get the errors at each time point. Then perhaps one possible way of detecting whether a sequence is anomalous is to get the mean error within the sequence and compare it with the distribution of the mean of the mean of errors of sequences which is calculated from validation data. For example, this distribution may be Gaussian. However, this method sounds a bit naïve since for it to work it would have to assume independence between the errors and some other properties. What could be some other ideas for anomaly scoring methods for the task?\n    submitted by    /u/helium-atom  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/153f09g/d_anomaly_scoring_methods_for_subsequence_anomaly/",
          "publishedOn": "2023-07-19T00:08:50.000Z",
          "wordCount": 2575,
          "title": "[D] Anomaly scoring methods for subsequence anomaly detection in time series",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/153cd0h/r_adversarial_robust_deep_reinforcement_learning/",
          "author": null,
          "description": "https://ojs.aaai.org/index.php/AAAI/article/view/26009/25781 \n    submitted by    /u/ml_dnn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/153cd0h/r_adversarial_robust_deep_reinforcement_learning/",
          "publishedOn": "2023-07-18T22:21:24.000Z",
          "wordCount": 2441,
          "title": "[R] Adversarial Robust Deep Reinforcement Learning Requires Redefining Robustness",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15350gx/p_we_made_llama13bv2chat_immediately_available_as/",
          "author": null,
          "description": "Hey r/MachineLearning, we've released tools that make it easy to test LLaMa 2 and add it to your own app!\n Model playground here: https://llama2.ai\n Hosted chat API here: https://replicate.com/a16z-infra/llama13b-v2-chat\n If you want to just play with the model, llama2.ai is a very easy way to do it. So far, we’ve found the performance is similar to GPT-3.5 with far fewer parameters, especially for creative tasks and interactions.\n Developers can:\n * clone the chatbot app as a starting point (https://github.com/a16z-infra/llama2-chatbot)\n * use the Replicate endpoint directly (https://replicate.com/a16z-infra/llama13b-v2-chat)\n * or even deploy your own LLaMA v2 fine tune with Cog (https://github.com/a16z-infra/cog-llama-template)\n Please let us know what you use this for or if you have feedback! And thanks to all contributors to this model, Meta, Replicate, the Open Source community!\n    submitted by    /u/Prestigious-Elk7124  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15350gx/p_we_made_llama13bv2chat_immediately_available_as/",
          "publishedOn": "2023-07-18T17:40:41.000Z",
          "wordCount": 2561,
          "title": "[P] We made Llama13b-v2-chat immediately available as an endpoint for developers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1534kd8/discussion_meta_open_sources_llama2_and_tie_up/",
          "author": null,
          "description": "https://about.fb.com/news/2023/07/llama-2/\n https://ai.meta.com/llama/\n    submitted by    /u/Electrical_Study_617  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1534kd8/discussion_meta_open_sources_llama2_and_tie_up/",
          "publishedOn": "2023-07-18T17:23:03.000Z",
          "wordCount": 2443,
          "title": "[Discussion] Meta open sources llama-2 and tie up with MSFT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1533mj9/n_llama_2_is_here/",
          "author": null,
          "description": "Looks like a better model than llama according to the benchmarks they posted. But the biggest difference is that its free even for commercial usage. \n https://ai.meta.com/resources/models-and-libraries/llama/\n    submitted by    /u/timedacorn369  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1533mj9/n_llama_2_is_here/",
          "publishedOn": "2023-07-18T16:47:18.000Z",
          "wordCount": 2462,
          "title": "[N] Llama 2 is here",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1532ej2/d_data_intelligence_vs_information_retrieval/",
          "author": null,
          "description": "I have to choose one of the two elective for the next sem.\n My Questions are:\n  \nWhat is Information Retrieval and Data Intelligence?\n \nWhich is more useful according to industry Requirements?\n \nWhich one should I take as someone who wants to pursue a career as a Machine Learning Engineer or a Data Scientist?\n \n    submitted by    /u/Ethan045627  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1532ej2/d_data_intelligence_vs_information_retrieval/",
          "publishedOn": "2023-07-18T16:00:53.000Z",
          "wordCount": 2490,
          "title": "[D] Data Intelligence VS Information Retrieval",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1531e32/r_utilizing_amd_gpus_with_unity_mlagents/",
          "author": null,
          "description": "Hello everyone,\n I've embarked on a project involving Unity's ML-Agents toolkit, and I've hit a roadblock regarding GPU utilization. My system is equipped with an AMD GPU, and I'm aware that most machine learning libraries and tools mainly support NVIDIA GPUs due to their compatibility with CUDA.\n Has anyone here successfully gotten ML Agents to work optimally with an AMD GPU? If not, are there any alternative methods or libraries you recommend that work well with AMD GPUs?\n So far, my attempts with TensorFlow and PyTorch have been met with limited success due to their restricted support for AMD GPUs. I've been exploring other potential options like PlaidML and OpenCL, but I'd love to get some input from this community.\n Any suggestions or resources on tackling this issue would be hugely appreciated. Thank you!\n    submitted by    /u/Low-Spray-249  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1531e32/r_utilizing_amd_gpus_with_unity_mlagents/",
          "publishedOn": "2023-07-18T15:22:21.000Z",
          "wordCount": 2572,
          "title": "[R] Utilizing AMD GPUs with Unity ML-Agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15313e9/r_relating_images_to_voltages_to_angle/",
          "author": null,
          "description": "If this post content is something you are expert in and would like to work with me to accomplish these goals as part of my team I am able to compensate you. I am currently building my team.\n I have pictures of a 3d printed part that I have sequentially lit by different small light sources, each positioned at a known 3d location relative to the part. The lights are less than 2 meters from the part. Each light casts specific shadows on the part. I measure the size of the shadows and relate them to the angular direction to the origin of the light (2D bearing). My next prototype has photodiodes that I will use to measure the % of shading on each diode by photoexcitation as a voltage. I want to build a pattern recognition model to relate the two outputs to the incident angle of light. This is so in the future I can output the bearing direction towards a light source with an unknown 3d relative position via voltage, and be able to validate the voltage data from images.\n Please guide me towards a Machine Learnig platform or engine (for lack of me knowing a better term) that could take this data (% surface shading & voltage) as input and learn how to extract the 2d bearing (and more) from sensor to light source.\n Thanks\n    submitted by    /u/masterjebbi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15313e9/r_relating_images_to_voltages_to_angle/",
          "publishedOn": "2023-07-18T15:10:46.000Z",
          "wordCount": 2667,
          "title": "[R] Relating images to voltages to angle",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1530v9q/london_ai4code_meetup_w_aaron_parisi_google_on/",
          "author": null,
          "description": "The AI4Code reading group is back with Aaron Parisi, Google researcher and lead author of TALM, a framework for augmenting language models with arbitrary tools.\n Free RSVP: https://lu.ma/mw5ppi46\n Paper: https://arxiv.org/abs/2205.12255\n 🗓 July 27th (Thursday) at 17:00 GMT+1\n 📍 Zoom\n 👥 Members of the international AI4Code research community\n Key ideas\n - Modeling tool-use via a text-to-text interface\n - Applying an iterative self-play technique to bootstrap high performance on tasks with few tool-use labelled examples\n TALM consistently outperforms a non-augmented LM on both a knowledge task (NQ) and reasoning task (MathQA).\n The AI4Code meetup community consists of like-minded researchers from around the world that network, discuss and share their latest research on AI applications on source code.\n    submitted by    /u/dritsakon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1530v9q/london_ai4code_meetup_w_aaron_parisi_google_on/",
          "publishedOn": "2023-07-18T15:02:11.000Z",
          "wordCount": 2556,
          "title": "London AI4Code meetup w/ Aaron Parisi (Google) on TALM: Tool Augmented Language Models (July 27th) [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/152yxfu/image_recognition_at_scale_d/",
          "author": null,
          "description": "What services/libraries could I use if I wanted to, say, upload 100+ images and ask it to identify what each image is of? I know that in Bard for example I can upload one image at a time and it'll idenitfy it for me, but I want to do this at scale. Anyone know of any python libraries or OCR services that I could use for this? \n    submitted by    /u/Groundbreaking-Owl-5  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/152yxfu/image_recognition_at_scale_d/",
          "publishedOn": "2023-07-18T13:45:42.000Z",
          "wordCount": 2503,
          "title": "Image Recognition at Scale? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/152xwuh/d_how_to_access_claude_ai_outside_us_and_uk/",
          "author": null,
          "description": "Anthropic, a company founded by former researchers from OpenAI, has recently introduced its upgraded chatbot, Claude 2.\n Claude 2 has arrived five months after the initial release of its predecessor, Claude, and brings notable improvements such as longer responses, more up-to-date information, faster speeds. One of Claude 2's standout features is its ability to process up to 100,000 tokens, equivalent to 75,000 words, in a single prompt. This is a significant improvement from Claude's previous limitation of 9,000 tokens.\n However, there is one problem with it, currently Claude AI chat is available in UK and US only. While it’s claimed that other regions are soon to follow, the exact timeline remains unclear. Though Anthropic Claude is easily accessible with a VPN. Here are quick steps how to access it if you’re not living in UK or US:\n ​\n 1. Buy a VPN provider of your choice that has in UK or US servers (most VPNs will have them since these are the main markets for them). This r/vpn comparison table could help you decide which provider to choose and offers nice discounts for some providers;\n 2. Open VPN app;\n 3. Connect to US or UK server. For the best speed and user experience, it’s recommended to connect to a server from whichever country is closer to your current location;\n 4. Login/Sign-up on Claude AI webpage. You can successfully log in using your personal email address. Using Incognito mode on your browser might be required;\n 5. Enjoy your easy access to Claude AI despite not being located in US or UK!\n ​\n Hope this helps someone, happy using!\n    submitted by    /u/ProfessionalSource0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/152xwuh/d_how_to_access_claude_ai_outside_us_and_uk/",
          "publishedOn": "2023-07-18T13:02:53.000Z",
          "wordCount": 2706,
          "title": "[D] How to access Claude AI outside US and UK",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/152wm4u/d_anyone_got_code_implementation_for/",
          "author": null,
          "description": "i'm looking for code implementation of https://hyperdreambooth.github.io/\n it'd be amazing if anyone can point to a repo or something\n thankyou\n    submitted by    /u/SayNo2Tennis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/152wm4u/d_anyone_got_code_implementation_for/",
          "publishedOn": "2023-07-18T12:04:52.000Z",
          "wordCount": 2458,
          "title": "[D] anyone got code implementation for hyperdreambooth",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/152w8yk/sex_differences_in_ml_d/",
          "author": null,
          "description": "General question about population stratification in machine learning:\n If I am interested in the important features for disease prediction in women only, is it worth stratifying my sample to women-only? I.e do ML algorithms account for gender differences? I have men and women in the dataset but I am interested in a disease that seems to be diagnosed in women later than men.\n    submitted by    /u/Vegetable-Gazelle728  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/152w8yk/sex_differences_in_ml_d/",
          "publishedOn": "2023-07-18T11:48:15.000Z",
          "wordCount": 2499,
          "title": "Sex differences in ML [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/152u5va/r_retentive_network_a_successor_to_transformer/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2307.08621\n Retentive Network: A Successor to Transformer for Large Language Models\n Yutao Sun, Li Dong, Shaohan Huang, Shuming Ma, Yuqing Xia, Jilong Xue, Jianyong Wang, Furu Wei\n  \nIn this work, we propose Retentive Network (RetNet) as a foundation architecture for large language models, simultaneously achieving training parallelism, low-cost inference, and good performance. We theoretically derive the connection between recurrence and attention. Then we propose the retention mechanism for sequence modeling, which supports three computation paradigms, i.e., parallel, recurrent, and chunkwise recurrent. Specifically, the parallel representation allows for training parallelism. The recurrent representation enables low-cost O(1) inference, which improves decodin…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/152u5va/r_retentive_network_a_successor_to_transformer/",
          "publishedOn": "2023-07-18T10:01:44.000Z",
          "wordCount": 3121,
          "title": "[R] Retentive Network: A Successor to Transformer for Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/152tl8p/d_vector_db_basics_a_star_wars_example/",
          "author": null,
          "description": "Amidst all of the stress of AI taking over, here's a light-hearted blog post on Vector DB basics including a Star Wars mini-example for you all to enjoy :) \n https://preview.redd.it/n79cv8hkzocb1.png?width=1920&format=png&auto=webp&s=984d955c7d4a0e93ce36ca909835d98b65d6ee2d\n    submitted by    /u/kazhdan_d  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/152tl8p/d_vector_db_basics_a_star_wars_example/",
          "publishedOn": "2023-07-18T09:29:23.000Z",
          "wordCount": 2468,
          "title": "[D] Vector DB Basics: a Star Wars Example",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/152s8dv/d_derivation_of_infonce_loss/",
          "author": null,
          "description": "I've been reading the paper that introduced Contrastive Predictive Coding as well as the InfoNCE section on Lilian Weng's blog post on contrastive learning. After a while of staring and working, I can't figure out how the authors derived equation 5 in the paper. The farthest I get is finding that p(d=i|X, c_t) = 1/(1 + \\sum_{j=1, j!=i}^N [p(x_j | c_t) \\prod_{l=1, l \\neq j \\neq i}^N p(x_l)]), but the rest of the derivation is a mystery to me. Is there something super obvious I'm missing?\n    submitted by    /u/like_a_tensor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/152s8dv/d_derivation_of_infonce_loss/",
          "publishedOn": "2023-07-18T08:11:02.000Z",
          "wordCount": 2522,
          "title": "[D] Derivation of InfoNCE loss",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/152rru3/discussion_state_of_highly_specialized/",
          "author": null,
          "description": "Yesterday, I thought about why current conversational LLMs like ChatGPT are always so general. For example, I'm mostly working on Reinforcement Learning problems and would expect a model that is specifically fine-tuned on literature exclusively concerned with RL to give much better answers and more intricate details.\n ​\n Are there any papers or blog posts about this?\n    submitted by    /u/seawee1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/152rru3/discussion_state_of_highly_specialized/",
          "publishedOn": "2023-07-18T07:45:24.000Z",
          "wordCount": 2494,
          "title": "[Discussion] State of highly specialized, topic-specific LLMS?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/152qb4m/research_using_official_implementations_vs_highly/",
          "author": null,
          "description": "So for the past six months I have been working on a domain adaptation research problem. I wanted to inspect/understand the inherent capability of SSL methods to extract domain invariant features. For this purpose I have been conducting different kinds of experiments.There is a very nice library called lightly that contains the implementations of all published SSL methods, This made things very easy for me in terms of writing code. I am not a PhD student or don't have significant research experience. My guide/mentor is very interested in the work I'm doing and she aims to publish our work in somewhere like a NeurIPS, ICML or so.\n Probably because of my lack of experience, I am overlooking into things or I am genuinely concerned. I just don't want to make stupid coding or code related errors and report wrong results. I just want to know if its mandatory to use the official implementations of every method I'm benchmarking.or example, SimCLR's official implementation is in Tensorflow and I am using PyTorch. Using official implementation would introduce these kind of bottlenecks and slow down my experimentation process. Any advices on this would be greatly appreciated. Thanks.\n    submitted by    /u/ashharsha  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/152qb4m/research_using_official_implementations_vs_highly/",
          "publishedOn": "2023-07-18T06:22:05.000Z",
          "wordCount": 2636,
          "title": "[Research] Using official implementations vs highly popular unofficial implementation for research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/152iy54/d_how_underdog_ai_companies_will_crush_silicon/",
          "author": null,
          "description": "💥 How Underdog AI Companies Will Crush Silicon Valley Giants.\n Opportunities in AI: Creating Abundant Intelligence.\n  \nGenerative AI like ChatGPT brings complex tasks within reach and is set to transform society. Startups have an opportunity in applying AI to create \"abundant intelligence\".\n In the past year, ChatGPT, GitHub Copilot, and Midjourney have rapidly grown to $100M+ revenue.\n AI startups face competition from tech giants also moving quickly into AI. Startups must pick spots where they have an advantage.\n Opportunities exist in expanding the application universe into new greenfield opportunities like automating mundane decisions, masking workflow complexity, and reimagining applications.\n Infrastructure tools make models more powerful by chaining them together and improving accuracy. Opportunity areas include unstructured data management, agent-driven automation, model evaluation, and experimentation.\n Key players emerging are foundation model providers like OpenAI and Anthropic, companies building domain-specific models, and platforms for autonomous agents.\n Advantages exist for startups focused on imagination and technical ability to find non-obvious ideas, while large companies retrofit existing businesses.\n  \n   submitted by    /u/Yavero  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/152iy54/d_how_underdog_ai_companies_will_crush_silicon/",
          "publishedOn": "2023-07-18T00:24:26.000Z",
          "wordCount": 2603,
          "title": "[D]💥 How Underdog AI Companies Will Crush Silicon Valley Giants.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/152idsj/r_semanticsam_reproduce_and_beyond_sam_with/",
          "author": null,
          "description": "We introduce Semantic-SAM, a universal image segmentation model to enable segment and recognize anything at any desired granularity. We have trained on the whole SA-1B dataset and our model can reproduce SAM and beyond it. Training and inference code is available!\n 🔥code & demo link: https://github.com/UX-Decoder/Semantic-SAM\n 🔥paper link: https://arxiv.org/pdf/2307.04767.pdf\n 🚀 Features\n 🔥 Reproduce SAM. SAM training is a sub-task of ours. We have released the training code to reproduce SAM training.\n 🔥 Beyond SAM. Our newly proposed model offers the following attributes from instance to part level:\n  \nGranularity Abundance. Our model can produce all possible segmentation granularities for a user click with high quality, which enables more controllable and user-friendly interactive s…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/152idsj/r_semanticsam_reproduce_and_beyond_sam_with/",
          "publishedOn": "2023-07-18T00:00:28.000Z",
          "wordCount": 2831,
          "title": "[R] Semantic-SAM: Reproduce and Beyond SAM with Semantic-Aware and Granualrity-Abundance",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/152i3nx/p_llm_to_simulate_a_character/",
          "author": null,
          "description": "I'm working on building an application and I want to have a chatbot that has the opinions and thoughts of a particular person.\n I want to train this on my own. I have a large corpus of data that I can use for this training. I am not sure which existing foundation model / model architecture I should use for training this.\n I fine-tuned a GPT2 model earlier but the results were very poor. Maybe it has to do with the data?\n    submitted by    /u/MethodExtension5513  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/152i3nx/p_llm_to_simulate_a_character/",
          "publishedOn": "2023-07-17T23:48:25.000Z",
          "wordCount": 2518,
          "title": "[P] LLM to simulate a character",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/152eq65/n_flashattention2_faster_attention_with_better/",
          "author": null,
          "description": "Twitter thread: https://twitter.com/tri_dao/status/1680987577913065472\n Tech report: https://tridao.me/publications/flash2/flash2.pdf\n    submitted by    /u/SchmidhuberDidIt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/152eq65/n_flashattention2_faster_attention_with_better/",
          "publishedOn": "2023-07-17T21:32:26.000Z",
          "wordCount": 2446,
          "title": "[N] FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/152crh6/r_clustering_of_x_shaped_data/",
          "author": null,
          "description": "I have a dataset with two variables and 500 observations. They plot like an X shape. I have been trying to find a clustering method to identify the two lines forming the X as two different clusters. All the methods I tried so far (K_means, DBSCAN, Spectral clustering) identified the two angles forming the X as the two differebt clusters. Any ideas on how to approach this?\n Any help would be appreciated. Thanks!\n    submitted by    /u/earthlingsapien  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/152crh6/r_clustering_of_x_shaped_data/",
          "publishedOn": "2023-07-17T20:19:00.000Z",
          "wordCount": 2509,
          "title": "[R] Clustering of X shaped data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/152bzmc/p_geosegment_demo_segment_anything_model_for/",
          "author": null,
          "description": "I’ve been working on a side project that utilises the segment anything model for satellite imagery, but allowing it to run purely as a web application (no need to run the model locally on a powerful PC).\n The intention is to provide a quick and easy “AI assisted” way to segment imagery and save time on digitisation tasks, and then export it to your GIS application of choice (QGIS or ESRI software support the export format, which is GeoJSON).\n The demo video is here\n If anyone wants access to the online demo shown in the video, just message me and I can give you the link and demo credentials.\n I’m hoping there is some use for it to GIS folks :)\n    submitted by    /u/CharlieTheChooChooo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/152bzmc/p_geosegment_demo_segment_anything_model_for/",
          "publishedOn": "2023-07-17T19:49:57.000Z",
          "wordCount": 2566,
          "title": "[P] GeoSegment Demo - Segment Anything Model for Geospatial Data (running purely in the browser)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/152bm8b/d_how_does_claude_parse_attached_documents/",
          "author": null,
          "description": "I played with Claude 2 this weekend and overall really impressed, especially for summarizing pdfs and other text documents.\n I gave it Microsoft's Q2 financial statement, and Claude did a good job with most questions, including over tabular data.\n Anyone know how it parses tabular data from documents? I can see the extracted lines but wondering how they get used. Is there a preprocessing step of creating embeddings from it? \n https://preview.redd.it/4fnjn477vkcb1.png?width=1200&format=png&auto=webp&s=fa235bbcbd4d2954fae5908a904cd5d7f17658c8\n Some more details from my experiment in this thread.\n    submitted by    /u/sarmad-q  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/152bm8b/d_how_does_claude_parse_attached_documents/",
          "publishedOn": "2023-07-17T19:35:53.000Z",
          "wordCount": 2516,
          "title": "[D] How does Claude parse attached documents?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/152arb7/p_loopgpt_update_finally_something_useful/",
          "author": null,
          "description": "By now, most of us who tried have realized that the \"autonomous LLM agents\" are not really useful at the moment. We need to create applications that are helpful, predictable and reliable that will produce acceptable results, in place of endless toil to get these agents to do something. We really just need good, specific LLM products that can do at least one thing properly, like - doing some research, writing a report, summarizing content - things an LLM might actually be good at.\n So we thought it would be a good idea to create a framework that makes use of LoopGPT agent's memory and custom tooling capabilities. Let's jump right into the new features of this framework.\n First, using LLMs within Python functions, where you only write the function's docstring and the LLM will return the resu…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/152arb7/p_loopgpt_update_finally_something_useful/",
          "publishedOn": "2023-07-17T19:03:09.000Z",
          "wordCount": 2972,
          "title": "[P] LoopGPT Update - Finally something useful?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/152aq9f/d_machine_learning_the_silent_revolution_in_our/",
          "author": null,
          "description": "Hello, fellow machine learning aficionados!\n As everyone is aware, machine learning is transforming a wide range of sectors, including healthcare, banking, entertainment, and transportation. But have you ever stopped to think about the more subtle effects it's causing in our day-to-day activities?\n Think about this Machine learning is the technology behind the targeted advertisements you see online, the intelligent email client suggestions for replies, the traffic predictions on your GPS, and even the song suggestions on your favorite music app.\n But this is where things become intriguing. I'm interested in hearing about the most imperceptible yet significant ways you've seen machine learning in action in your day-to-day activities. It could be as straightforward as a practical component in an app you frequently used or a big shift in your work process.\n Here's my observation to start the discussion: Thanks to machine learning, I've seen that over time, my smart home appliances have gotten better at comprehending my orders. I now seldom ever have to repeat myself, and it seems like the gadgets are actually \"learning\" what I want.\n I'm eager to hear your insights. Let's explore machine learning's covert revolution together, eh?\n    submitted by    /u/HungryGuidence  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/152aq9f/d_machine_learning_the_silent_revolution_in_our/",
          "publishedOn": "2023-07-17T19:02:05.000Z",
          "wordCount": 2631,
          "title": "[D] Machine Learning: The Silent Revolution in Our Midst",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/152ago3/p_onnxstream_running_stable_diffusion_in_260mb_of/",
          "author": null,
          "description": "hi all,\n I developed a small inference library in C++ that can run Stable Diffusion in 260MB of RAM.\n The minimum recommended RAM/VRAM for SD is 8GB.\n This is achieved by offloading the weights on disk, by quantization and attention slicing (which is similar in principle to FlashAttention, without the fused kernel).\n It currently supports 24 ONNX operators.\n The idea is to allow the inference of very large (transformer) models on very limited devices.\n More info in the GitHub repo: https://github.com/vitoplantamura/OnnxStream\n Thanks, --Vito\n    submitted by    /u/Pristine198  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/152ago3/p_onnxstream_running_stable_diffusion_in_260mb_of/",
          "publishedOn": "2023-07-17T18:52:14.000Z",
          "wordCount": 2522,
          "title": "[P] OnnxStream: running Stable Diffusion in 260MB of RAM",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1526jq3/d_optimizing_ai_prompt/",
          "author": null,
          "description": "Hey, everyone! Been thinking about how we interact with AI, especially in the realm of text generation. It's no secret that the way we prompt an AI greatly influences the output. A perfectly crafted prompt can result in a well-constructed piece of writing, while a vague or poorly worded one might leave us with gibberish or content that misses the mark.\n Recently, I've been intrigued by the idea of 'Prompt Engineering.' We've seen AI models grow more powerful, more human-like, and they're getting involved in content creation in a big way. There are AI-powered tools and applications being used in journalism, blogging, script writing, technical writing, and so much more.\n With the rise of powerful models like GPT-3.5, DALL-E 2, and others, it seems the ability to create optimal prompts has become an art and science unto itself.\n What's your take on this? Do you think there's value in perfecting the art of prompting AI? Or do you feel AI should evolve to understand human language and context better, regardless of how a question or command is framed? Could the emergence of intuitive tools that assist with prompt optimization help bridge this gap, making AI-generated content more accessible and higher quality?\n As content creators, developers, or just AI enthusiasts, how do you think this will shape the future of AI-generated content?\n    submitted by    /u/IntentlyConscious  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1526jq3/d_optimizing_ai_prompt/",
          "publishedOn": "2023-07-17T16:22:38.000Z",
          "wordCount": 2655,
          "title": "[D] Optimizing AI prompt",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15269v8/p_chapyter_chatgpt_code_interpreter_in_jupyter/",
          "author": null,
          "description": "I recently made a new JupyterLab extension called Chapyter (𝐂𝐡𝐚ts in Ju𝐏𝐲𝐭𝐞𝐫) that aims at solving many pain points when using other AI coding assistants. I want to share with y'all the tools as well as my thinkings while building this.\n What is Chapyter\n Chapyter is a JupyterLab extension that seamlessly connects GPT-4 to your coding environment. Here are the key features: \n  \nCode generation from natural language and automatic execution\n Simply adding the magic command %%chat at the beginning of the cell of a natural language description of the task, the code is generated and the results are shown in a few seconds.\n  \nhttps://i.redd.it/y7l0s9pf5hcb1.gif\n  \nUsing coding history and execution output for code generation\n By adding the --history or -h flag in generation, chapyter can…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15269v8/p_chapyter_chatgpt_code_interpreter_in_jupyter/",
          "publishedOn": "2023-07-17T16:12:12.000Z",
          "wordCount": 2875,
          "title": "[P] Chapyter: ChatGPT Code Interpreter in Jupyter Notebooks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1521mly/p_finetuning_qloras_for_production_use_cases/",
          "author": null,
          "description": "Hello,\n I've been curious as to how far we can take small(7B and less) models for production use cases with small amounts of training data for each task.\n So far I've been able to fine-tune LoRAs for paraphrasing, changing the tone of a sentence, dialogue summarization and topic generation. The results look promising, especially the fact that all this can run on very modest hardware.\n Finetuning was done in 4bit mode using bitsandbytes. Each task had ~1k training points.\n I've used a AMD Ryzen9 3900XT + 3080(10gb) + 32gb ram for all the training and inference here. On my system I get 12-15 tokens/sec during inference.\n All the details can be found here: https://github.com/kuutsav/llm-toys.\n  \nData used for training\n Training params and the training/eval losses are present in the huggingface model cards\n Evaluation(wherever possible atm)\n  \nModels: https://huggingface.co/llm-toys\n Why do all this?\n Mostly to answer the question - can we move away from OpenAI and other players for very particular use cases, how much data it takes, where does it break, etc. So far I've not been able to find pre-trained model(7b and small) that did well on these tasks. Even larger models(around 40b) failed to give consistent results. The fine-tuned model on huggingface were also not good enough in my trials. For paraphrasing I could not find even a single fully tuned model that was able to correct basic typos.\n Do give it a shot, there is a colab notebook available as well try it directly. Will really appreciate some feedback on these model's performace.\n    submitted by    /u/krumb0y  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1521mly/p_finetuning_qloras_for_production_use_cases/",
          "publishedOn": "2023-07-17T13:13:00.000Z",
          "wordCount": 2704,
          "title": "[P] Finetuning qLoRAs for production use cases - Paraphrasing, Changing the tone of a sentence, Dialogue Summarization and Topic generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1521d3m/p_innovative_project_blockchain_anomaly_detection/",
          "author": null,
          "description": "We're DeHack, a Web 3.0 security startup in Dubai. We're looking for a Machine Learning enthusiast who understands blockchain. Part-time or full-time.\n We're the team behind BlockAudit, now building DeHack - Threat intelligence and mitigation product. We're at an exciting stage with venture funding talks underway. It's a huge opportunity for someone who wants to work at the intersection of ML & Web 3.0. If you've worked on Threat Anomaly detection models, even better.\n For the perfect fit, we're open to discussing equity compensation as part of the package.\n Sounds interesting? Get in touch!\n www.DeHack.ai\n akshay@dehack.ai\n TG: u/DeHack_Akshay\n    submitted by    /u/Ok_Ear_7544  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1521d3m/p_innovative_project_blockchain_anomaly_detection/",
          "publishedOn": "2023-07-17T13:02:15.000Z",
          "wordCount": 2538,
          "title": "[P] Innovative Project : Blockchain Anomaly Detection System - DeHack",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1521ag5/how_best_to_benchmark_the_accuracy_of_a_model_for/",
          "author": null,
          "description": "I need to benchmark the performance of my tokenizer against standard tokenizers. It would be best for reproducibility if I benchmark against an existing model on a standard benchmark, swapping out the existing tokenizer for my tokenizer.\n I was planning to train TinyStories model for the comparison, but what would I benchmark other than perplexity? Is comparing perplexity enough to benchmark the performance of two models trained on the same dataset? Or what is best for that?\n Can anyone recommend a repo (if any exist) that:\n  \nPretrains a transformer based model from scratch.\n Has some kind of accuracy benchmark that will be taken seriously.\n Can be modified to use a different tokenizer.\n Can be pretrained on an RTX 3090 within 24-48 hours.\n  \nIf there's a repo somewhere that both pretrains on a benchmark dataset and applies a suitable benchmark automatically that would be amazing.\n As you can tell I'm unsure how best to go about doing the benchmark. Any advice would be appreciated.\n    submitted by    /u/Pan000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1521ag5/how_best_to_benchmark_the_accuracy_of_a_model_for/",
          "publishedOn": "2023-07-17T12:59:33.000Z",
          "wordCount": 2607,
          "title": "How best to benchmark the accuracy of a model for comparing different tokenizers? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/151z8pt/r_prompt_performance_prediction/",
          "author": null,
          "description": "Let me introduce you to our latest research on Prompt Performance Prediction (PPP). PPP is a novel task which aims to predict a query's performance in Generative Information Retrieval systems before the search results are generated. This can be applied on any generative system (textual, image, etc.). \n Here we consider the image generation task as a generative retrieval one and adapt the well known query performance prediction in traditional information retrieval field to modern generative information retrieval. \n Preliminary results across three datasets (Dall-E, Midjourney, Stable Diffusion) on different metrics (Aesthetic, memorability, etc.) show promising capabilities of our method in performance prediction. 🔗 For a more detailed look, visit: https://arxiv.org/abs/2306.08915\n Prompt Performance Prediction for Generative IR, Bizzozzero, Bendidi, Risser-Maroix, 2023\n AI #GenerativeAI #MachineLearning #PromptPerformancePrediction #PPP\n    submitted by    /u/Average_CS_Student  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/151z8pt/r_prompt_performance_prediction/",
          "publishedOn": "2023-07-17T11:26:15.000Z",
          "wordCount": 2558,
          "title": "[R] Prompt Performance Prediction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/151wjvt/p_looking_for_a_collaborator_to_write_a_specific/",
          "author": null,
          "description": "The following offer might be more suited for a research-oriented site like math stack exchange/overflow, but I don't think they allow posts like this, so here I am.\n Me (a postdoc, the main author) and two other co-authors (legit academics) have written a statistics paper where we develop a new smoothing technique on half-spaces. The paper is almost done except for one section that's currently (almost) empty. In that section, we would like to show how the smoothing technique can be used to classify new data points in the context of soft-margin support vector machines (SVM). The aim would be something like 2-3 pages with 1-2 figures, but the collaborator would have the freedom to do what he/she thinks is best.\n So I am looking for someone who has more experience with machine learning or just SVMs to fill up this section themselves. They would of course become co-author of the paper. I cannot guarantee anything, but we aim to publish the paper in a low Q1 journal, so a good journal.\n If someone is hungry for publications (PhD student, postdoc, young prof) and you have experience with this kind of stuff, this is a relatively low-effort way to upgrade your CV.\n If you're interested, just PM me, more details will be given.\n    submitted by    /u/Nearby-Turnover370  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/151wjvt/p_looking_for_a_collaborator_to_write_a_specific/",
          "publishedOn": "2023-07-17T09:02:34.000Z",
          "wordCount": 2663,
          "title": "[P] Looking for a collaborator to write a specific machine learning application section in a statistics paper that's almost finished",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/151vka9/r_need_help_in_llama_license_for_research_paper/",
          "author": null,
          "description": "Hello everyone,\n We are conducting benchmark evaluations on large language models, and the preliminary results are quite interesting for AI researchers to investigate further. We have tested various models, including LLama variants, but unfortunately, we are unable to use LLama at this time due to licensing restrictions.\n We have applied for the necessary license from Meta multiple times over the past few months but have not received a reply. If anyone has an existing LLama license they would be willing to share, we would greatly appreciate the help. In exchange, we would be happy to share a preprint of the paper and acknowledge your contribution.\n We understand this is an unconventional request, but licensing can be a difficult roadblock in research. Any assistance would allow us to better understand the capabilities of different models. Please let us know if you can help.\n Thank you for considering!\n    submitted by    /u/Accomplished_Rest_16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/151vka9/r_need_help_in_llama_license_for_research_paper/",
          "publishedOn": "2023-07-17T08:05:17.000Z",
          "wordCount": 2585,
          "title": "[R] Need Help in Llama license for research paper",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/151u6pk/d_donut_base_model_usage/",
          "author": null,
          "description": "Hi everyone, Is there any way we can use the Donut base model for its original Pre-Training task i.e pure OCR output without any specific fine-tuning head. I could find the base model on hub, but I don't know the exact configuration to use for the generate method or even for decoder.\n    submitted by    /u/Quicksilver466  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/151u6pk/d_donut_base_model_usage/",
          "publishedOn": "2023-07-17T06:48:49.000Z",
          "wordCount": 2487,
          "title": "[D] Donut Base Model Usage",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/151r896/d_open_source_lip_synchronize_project/",
          "author": null,
          "description": "Which open source project is recommended for creating an app that can synchronize a person's lip movements in a video with different audio? \n I'm looking for recommendations in the machine learning community. I want to build an app that can synchronize a person's lip movements in a video with different audio. Are there any open source projects you would suggest for this task? I appreciate any insights or suggestions. Thank you!\n    submitted by    /u/Overall-Spare2157  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/151r896/d_open_source_lip_synchronize_project/",
          "publishedOn": "2023-07-17T04:11:51.000Z",
          "wordCount": 2507,
          "title": "[D] open source lip synchronize project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/151qo4n/p_zig_gpt2_inference_engine/",
          "author": null,
          "description": "submitted by    /u/Cautious_Garbage_740  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/151qo4n/p_zig_gpt2_inference_engine/",
          "publishedOn": "2023-07-17T03:44:27.000Z",
          "wordCount": 2446,
          "title": "[P] Zig GPT-2 inference engine",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/151n4te/d_practice_cuda_without_an_actual_nvidia_gpu/",
          "author": null,
          "description": "Hello all!\n I recently started learning about CUDA programming, and I realized that many people share the same crucial problem: lack of an NVIDIA GPU. I looked around online and found several methods (gpu-ocelot, certain versions of CUDA, etc.), but I recently found a way that can allow us to practice CUDA by using the GPU offered by Google Colab! As a free user, the amount of GPU access you get may probably be enough to PRACTICE working with CUDA. If you really need more credits, the Colab Pro is only $10 / month, and it's still much cheaper than getting a new GPU or an entire new PC if you have a Macbook like I do. Again, the justification of \"enough computing credits\" is based on the assumption that you aren't running any heavy-lifting programs but more reasonable, practice-based codes.\n I have outlined a step-by-step guideline in this repo that I created - just check out the CUDA_on_Colab.ipynb file: https://github.com/notY0rick/cuda_practice\n If you know of any good alternatives, let me know (:\n    submitted by    /u/JustTrynnaBeCool  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/151n4te/d_practice_cuda_without_an_actual_nvidia_gpu/",
          "publishedOn": "2023-07-17T00:55:19.000Z",
          "wordCount": 2600,
          "title": "[D] Practice CUDA without an Actual NVIDIA GPU!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/151ixei/p_inexpensive_covariance_estimation_for_a_2d_gp/",
          "author": null,
          "description": "Suppose I observe a single realization of a 2D Gaussian random field. The field is inhomogenous and anisotropic, I.e. the size and shape of the blobs vary as a function of space and direction. \n I would like to estimate the covariance for this field. I assume that the mean is 0. To be concrete, the field is sampled on a 128x128 grid, so the covariance matrix is 1282 x 1282. I know I can try tackling this problem with MLE, and GPR may also be applicable (although I’m actually not sure about this, given the field is inhomogenous), but I worry about the cost, since I have 60K such fields and would like to do this in a reasonable amount of time \n I will use GPU and batch parallelism, but still would ideally be able to run this at as little cost as possible. \n Does anyone have suggestions on methods I can use? If it matters, I will do this analysis in Python.\n    submitted by    /u/Effective-Elk6175  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/151ixei/p_inexpensive_covariance_estimation_for_a_2d_gp/",
          "publishedOn": "2023-07-16T21:58:01.000Z",
          "wordCount": 2591,
          "title": "[P] Inexpensive covariance estimation for a 2D GP",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/151g5pr/p_rclip_update_use_ai_to_search_visually_similar/",
          "author": null,
          "description": "A while ago, I built rclip – a command-line image search tool powered by OpenAI's CLIP that allows users to search for images using a text query. Today I present an update to rclip that allows using another image instead of a search query to find visually similar images. Check out the video for the demo: https://www.youtube.com/watch?v=1YQZKeCBxWM. And give it a try yourself and share your feedback.\n    submitted by    /u/39dotyt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/151g5pr/p_rclip_update_use_ai_to_search_visually_similar/",
          "publishedOn": "2023-07-16T20:09:40.000Z",
          "wordCount": 2501,
          "title": "[P] rclip Update: Use AI to Search Visually Similar Images, Powered by OpenAI’s CLIP",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/151ea10/p_shark_detection_using_kerascv/",
          "author": null,
          "description": "Recently I stopped by Islas Galapagos. As a lifelong marine-biology enthusiast, I took the chance to go free-diving with sharks, penguins, marine iguanas and more. This inspired me to write an object detection pipeline to detect aquatic critters.\n https://lukewood.xyz/blog/marine-animal-detection\n Wrote up a short blog post on the project - I hope you enjoy it!\n https://i.redd.it/eqcrfg2ljdcb1.gif\n ​\n    submitted by    /u/puppet_pals  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/151ea10/p_shark_detection_using_kerascv/",
          "publishedOn": "2023-07-16T18:56:32.000Z",
          "wordCount": 2479,
          "title": "[P] Shark Detection using KerasCV!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/151e92z/d_approximating_nonfunction_mappings_with_mixture/",
          "author": null,
          "description": "Hey everyone, I wrote a short blog post on approximating non-function, multi valued x->y mappings. In my opinion, understanding why and how to use Mixture Density Networks is a great exercise for all researchers and practitioners. Its very common that real world processes have multiple outcomes based on some random sampling; and naive neural networks will simply learn the geometric mean of all y for a given x.\n Check out the blog post in more detail - hope you enjoy it!\n https://lukewood.xyz/blog/approximating-nonfunctions\n    submitted by    /u/puppet_pals  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/151e92z/d_approximating_nonfunction_mappings_with_mixture/",
          "publishedOn": "2023-07-16T18:55:30.000Z",
          "wordCount": 2510,
          "title": "[D] Approximating non-Function Mappings with Mixture Density Networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/151e0q2/d_thoughts_on_how_inflection_ai_became_so_good/",
          "author": null,
          "description": "My understanding is that talent is a key issue in large AI models. Additionally, you need quality data and a lot of compute (see this). Training large models might seem trivial, but it is not (see this). \n I still think Inflection is miles behind OpenAI, Anthropic and obviously Google. But I am still finding it surprising that they were able to create a reasonable product in a short span without any star researcher. For instance, Anthropic has a ton of star AI scientists and engineers who left OpenAI and had the necessary background. \n ​\n Would love to hear your thoughts. \n    submitted by    /u/nihcloud  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/151e0q2/d_thoughts_on_how_inflection_ai_became_so_good/",
          "publishedOn": "2023-07-16T18:46:01.000Z",
          "wordCount": 2533,
          "title": "[D] Thoughts on How Inflection AI became so good with such a small team?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/151amh8/d_a_question_about_knowledge_representation/",
          "author": null,
          "description": "I spent some time reading about Knowledge Representation (specifically about the Knowledge Representation part in Knowledge Representation and Reasoning) and specifically about scientific and/or engineering knowledge and my impression after cursory reading is that it’s a largely an unsolved problem. Not only that, but it seems like very few people are actually working on something useful in the field.\n For example, I checked the proceeding of SCI-K and PlanetKR conferences and literally all the papers seem to be focusing on “toy problems”, as in not having even remotely practical scientific implications (other than all sorts of “search” and “data extraction”, but that’s not “representation”).\n Views on the topic?\n    submitted by    /u/OkRice10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/151amh8/d_a_question_about_knowledge_representation/",
          "publishedOn": "2023-07-16T16:30:57.000Z",
          "wordCount": 2534,
          "title": "[D] A question about knowledge representation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/151ahuw/p_semantic_video_search_using_openais_clip_demo/",
          "author": null,
          "description": "Introducing a tool I developed to search videos using AI in a semantic manner. 🎞️🔍\n ✨ Check out the live demo: https://mixpeek.com/demo\n You can compare and explore different search queries such as \"person dancing,\" \"people dancing,\" or even \"people dancing on a train.\" and it gives you the exact timestamp.\n The search functionality is driven by OpenAI's CLIP for \"zero-shot\" video classification.\n Here's a tutorial on how we built it: https://learn.mixpeek.com/what-is-semantic-video-search/\n Feel free to experiment by searching with text, and share your exciting discoveries!\n 👇 More examples https://twitter.com/ethansteininger/status/1680613114071449600\n    submitted by    /u/vanlifecoder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/151ahuw/p_semantic_video_search_using_openais_clip_demo/",
          "publishedOn": "2023-07-16T16:25:47.000Z",
          "wordCount": 2520,
          "title": "[P] Semantic Video Search using OpenAI’s CLIP (demo and tutorial in comments)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/151a6hc/d_finetuning_llm_for_data_conversion_rag_or/",
          "author": null,
          "description": "Hello,\n I am exploring the process of using LLM's to do some data transformation/augmentation. The use case is taking data in a JSON format thats used in one platform and with that data being able to transform it into the proper data for the other platform. Essentially the approach I was going to take would be using a paired dataset with that has the example of one platforms data and then having the output be the other platforms data for the same item.\n ​\n I'm not 100% sure about the best approach here and if anyone has any insight on using LLM's for this kind of process please let me know your thoughts. It's kinda vauge bc its for a company so I dont want to get popped for anything.\n ​\n Any insights on the proper model to use, we want to go with opensource and something that could be used commercially. \n ​\n Thank you\n    submitted by    /u/TallSubstance  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/151a6hc/d_finetuning_llm_for_data_conversion_rag_or/",
          "publishedOn": "2023-07-16T16:12:49.000Z",
          "wordCount": 2581,
          "title": "[D] Finetuning LLM for data conversion, RAG or Finetuning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1519pjn/r_an_intuitive_intro_to_spontaneous_symmetry/",
          "author": null,
          "description": "I'm happy to share Gabriel's post on symmetry breaking in diffusion models! Spontaneous symmetry breaking is behind the standard model of particle physics... it turns out it is also behind the generative powers of diffusion models! \n In fact, spontaneous symmetry breakings happen when a systems transition from a disordered state to one of the many possible ordered states. In this case, the symmetry of the noise distribution is broken into all the possible generated images.\n Link: to the blogpost: https://gabrielraya.com/blog/2023/symmetry-breaking-diffusion-models/\n ​\n    submitted by    /u/LucaAmbrogioni  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1519pjn/r_an_intuitive_intro_to_spontaneous_symmetry/",
          "publishedOn": "2023-07-16T15:53:32.000Z",
          "wordCount": 2512,
          "title": "[R] An intuitive intro to spontaneous symmetry breaking in generative diffusion models!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15191e3/d_routerchain_with_llmchains_and_vectorstore/",
          "author": null,
          "description": "Is there a way to create a RouterChain that has several routes where one of them is communicating with a VectorStore (an \"index.query\") while the others are typical LLM chains and prompts. \n So far I was able to effectively use LLM router chains, but I want to combine them with several VectorStores as well. I think it can be done using Agents, but it has proven to be a bit difficult so far. I do not know if what I am trying is correct or no. If yes, do you know any blog or tips that could be of help with what I want to do. If not, how can I achieve what I want?\n    submitted by    /u/cedar_mountain_sea28  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15191e3/d_routerchain_with_llmchains_and_vectorstore/",
          "publishedOn": "2023-07-16T15:25:31.000Z",
          "wordCount": 2541,
          "title": "[D] RouterChain with LLMChains and VectorStore.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1518pan/d_codebase_framework_in_research/",
          "author": null,
          "description": "Hi all, I would like to ask about your codebases or Frameworks wrapped around Pytorch, Tensorflow or others. How do you handle different models, different datasets, different tasks in your daily work. Does your university or company have a framework that you should use or do you build your own? Do you and your colleagues work in the same codebase? How do you maintain it? I would like to get a lot of opinions and discussion about that topic.\n    submitted by    /u/SeucheAchat9115  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1518pan/d_codebase_framework_in_research/",
          "publishedOn": "2023-07-16T15:11:22.000Z",
          "wordCount": 2505,
          "title": "[D] Codebase / Framework in Research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1518fj5/d_simple_questions_thread/",
          "author": null,
          "description": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n Thread will stay alive until next one so keep posting after the date in the title.\n Thanks to everyone for answering questions in the previous thread!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1518fj5/d_simple_questions_thread/",
          "publishedOn": "2023-07-16T15:00:21.000Z",
          "wordCount": 2473,
          "title": "[D] Simple Questions Thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1517heb/d_style_transfer_from_scratch/",
          "author": null,
          "description": "Hello everyone,\n Im trying to build transfer learning from scratch but I dont't get the expectations results even doing everything in the right way. this is my notebook link https://www.kaggle.com/ayoubsarab/style-transfer . could you tell me why the results aren't good, please .\n ​\n expectation\n ​\n ​\n the real result\n    submitted by    /u/Ordinary_Run_2513  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1517heb/d_style_transfer_from_scratch/",
          "publishedOn": "2023-07-16T14:20:21.000Z",
          "wordCount": 2471,
          "title": "[D] Style Transfer from scratch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15175na/alternativ_to_langchain_d/",
          "author": null,
          "description": "Im currently learning hiw to use langchain but i heard that its bad so i want to know what are som alternatives i need memory and agents so that it can search online run code and so on so what is the best alternativ or is langchain the best option\n    submitted by    /u/Otherwise_Weather_57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15175na/alternativ_to_langchain_d/",
          "publishedOn": "2023-07-16T14:06:17.000Z",
          "wordCount": 2474,
          "title": "Alternativ to langchain [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1516l25/n_how_language_model_hallucinations_can_snowball/",
          "author": null,
          "description": "https://arxiv.org/abs/2305.13534\n Abstract\n A major risk of using language models in practical applications is their tendency to hallucinate incorrect statements. Hallucinations are often attributed to knowledge gaps in LMs, but we hypothesize that in some cases, when justifying previously generated hallucinations, LMs output false claims that they can separately recognize as incorrect. We construct three question-answering datasets where ChatGPT and GPT-4 often state an incorrect answer and offer an explanation with at least one incorrect claim. Crucially, we find that ChatGPT and GPT-4 can identify 67% and 87% of their own mistakes, respectively. We refer to this phenomenon as hallucination snowballing: an LM over-commits to early mistakes, leading to more mistakes that it otherwise would not make.\n Here is a Medium post.\n    submitted by    /u/transformer_ML  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1516l25/n_how_language_model_hallucinations_can_snowball/",
          "publishedOn": "2023-07-16T13:40:47.000Z",
          "wordCount": 2548,
          "title": "[N] How Language Model Hallucinations Can Snowball",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15158lc/p_i_made_a_huggingface_and_openai_powered_reply/",
          "author": null,
          "description": "I'm excited to share my latest creation, Private Parrot, a powerful Google Chrome extension that adds AI-generated responses to your web chats.\n 🤐 Privacy-Focused: Private Parrot masks sensitive information in your conversations, ensuring that your personal data remains completely anonymous.\n ⚡ Real-Time AI Assistance: Powered by OpenAI & HuggingFace, this extension leverages advanced language models to generate and complete responses instantly.\n 📈 Expandable Web Chats: Currently supporting Telegram and WhatsApp, we have plans to integrate with more web chat platforms soon, providing a seamless experience across different chat providers.\n Demo: https://www.youtube.com/watch?v=NEH3_3oT1DY\n Get the extension now:https://chrome.google.com/webstore/detail/private-parrot/fajfhpgedgeagjeninnlogilclofijmf\n Sources: https://github.com/lorenzoviva/PrivateParrot/tree/main\n    submitted by    /u/lollouno  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15158lc/p_i_made_a_huggingface_and_openai_powered_reply/",
          "publishedOn": "2023-07-16T12:37:58.000Z",
          "wordCount": 2530,
          "title": "[P] I made a HuggingFace and OpenAI powered Reply Bot with privacy protection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1514rfh/p_new_predictor_does_classification_intermixed/",
          "author": null,
          "description": "Deodel is a new predictive algorithm with a peculiar set of characteristics:\n  \nperforms classification intermixed with regression\n supports both types of attributes/features: nominal or continuous\n admits mixed types, categorical and numerical, in the same attribute column\n supports multi-class target prediction\n admits missing values in the training and query/test data\n good accuracy\n  \nhttps://github.com/c4pub/deodel\n It started as a type of discrete nearest neighbor classifier and it has been extended to support continuous attribute values. The continuous values are discretized, and although this step entails a loss of information, the classification accuracy is surprisingly good in many settings. Occasionally, deodel outperforms more established algorithms like RandomForest, GradientBoostingClassifier, LogisticRegression, MLPClassifier, etc. See here:\n https://github.com/c4pub/misc/blob/main/notebooks/deodel_vs_sklearn_on_titanic.ipynb\n The latest version is also capable of doing regression. It automatically switches between classification and regression modes. It can interweave the two modes in the same predictive session.\n    submitted by    /u/eppursim1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1514rfh/p_new_predictor_does_classification_intermixed/",
          "publishedOn": "2023-07-16T12:13:25.000Z",
          "wordCount": 2566,
          "title": "[P] New predictor does classification intermixed with regression",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/151377t/d_why_is_federated_learning_not_more_mainstream/",
          "author": null,
          "description": "I entirely get that federated learning can add considerable overhead to collaborative ML projects. However, the idea of being able to leverage the data of other companies/institutions for mutual gains seems like a very powerful concept. Even still, I am yet to really see federated learning ventures between companies beyond R&D projects. Is the tech to immature? People just don't care about sending data to central servers? \n How long, if ever, before FL has the chance to take off?\n    submitted by    /u/HStuart18  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/151377t/d_why_is_federated_learning_not_more_mainstream/",
          "publishedOn": "2023-07-16T10:48:32.000Z",
          "wordCount": 2507,
          "title": "[D] Why is federated learning not more mainstream?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/150x6za/d_imagenet_seems_to_purposefully_avoid_hard/",
          "author": null,
          "description": "So I had a question: can neural networks trained on ImageNet be used in zoological research? E.g., for distinguishing between similar looking animals?\n For example, what would be the accuracy of these neural network in distinguishing the following types of images:\n  \nLeopard vs Cheetah\n Hare vs Rabbit\n Crocs vs Alligators\n Llamas vs Alpacas\n Common hippo vs Pygmy hippo\n Kangaroo vs Wallaby\n  \nI looked into the ImageNet dataset on Kaggle and it appears that a lot of these very hard-to-distinguish classes are grouped together (i.e., leopard and cheetah are treated as a single class). So NN trained on ImageNet cannot be used if one wishes to use them to distinguish these animals. Some of the animals (such as Alpaca and Aardvark, I believe) are not even contained in the dataset.\n Can anyone confirm my observation? Are there any other way to get around this problem with the current ML techniques without having to curate a large dataset used exclusively for this type of animal classification?\n    submitted by    /u/fromnighttilldawn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/150x6za/d_imagenet_seems_to_purposefully_avoid_hard/",
          "publishedOn": "2023-07-16T05:04:45.000Z",
          "wordCount": 2593,
          "title": "[D] ImageNet seems to purposefully avoid hard -to-distinguish classes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/150uqt4/p_generating_multistyle_python_docstrings_with/",
          "author": null,
          "description": "gpt4docstrings is a new Python library that automatically generates docstrings for undocumented functions / classes. It allows you to generate the docstrings in multiple format styles, as you can see in the video below.\n Repository here 👉 https://github.com/MichaelisTrofficus/gpt4docstrings\n Documentation here 👉 https://gpt4docstrings.readthedocs.io/en/latest/index.html\n ​\n Generating docstrings in google, numpy and reST format styles\n    submitted by    /u/Hefty-Consequence443  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/150uqt4/p_generating_multistyle_python_docstrings_with/",
          "publishedOn": "2023-07-16T02:55:04.000Z",
          "wordCount": 2480,
          "title": "[P] Generating multi-style Python docstrings with GPT-based library (gpt4docstrings)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/150rvnh/n_metafacebook_releases_cm3leon_a_more_efficient/",
          "author": null,
          "description": "Abstract\n We present CM3Leon (pronounced “Chameleon”), a retrieval-augmented, tokenbased, decoder-only multi-modal language model capable of generating and infilling both text and images. CM3Leon uses the CM3 multi-modal architecture but additionally shows the extreme benefits of scaling up and tuning on more diverse instruction-style data. It is the first multi-modal model trained with a recipe adapted from text-only language models, including a large-scale retrieval-augmented pretraining stage and a second multi-task supervised fine-tuning (SFT) stage. It is also a general-purpose model that can do both text-to-image and image-to-text generation, allowing us to introduce self-contained contrastive decoding methods that produce high-quality outputs. Extensive experiments demonstrate that this recipe is highly effective for multi-modal models. CM3Leon achieves state-of-theart performance in text-to-image generation with 5x less training compute than comparable methods (zero-shot MS-COCO FID of 4.88). After SFT, CM3Leon can also demonstrate unprecedented levels of controllability in tasks ranging from language-guided image editing to image-controlled generation and segmentation.\n Paper\n https://scontent-sjc3-1.xx.fbcdn.net/v/t39.2365-6/358725877_789390529544546_1176484804732743296_n.pdf?_nc_cat=108&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=_diQr9c6Ru8AX9PYkNd&_nc_ht=scontent-sjc3-1.xx&oh=00_AfArA2t1OLRfRPioK9qkuBA6IhhSjbQ-b3weo2PM5AYLdw&oe=64B754F2\n Blog\n https://ai.meta.com/blog/generative-ai-text-images-cm3leon/\n    submitted by    /u/panabeenu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/150rvnh/n_metafacebook_releases_cm3leon_a_more_efficient/",
          "publishedOn": "2023-07-16T00:33:33.000Z",
          "wordCount": 2591,
          "title": "[N] Meta/Facebook releases CM3leon, a more efficient, state-of-the-art generative model for text and images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/150rdee/r_paper_review/",
          "author": null,
          "description": "I've written a paper on cross-lingual idiom sense clustering. I'd really appreciate if someone could read it and give me their thoughts. Pm if you want to.\n Thanks in advance.\n    submitted by    /u/United_Ad_1460  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/150rdee/r_paper_review/",
          "publishedOn": "2023-07-16T00:10:10.000Z",
          "wordCount": 2453,
          "title": "[R] Paper Review",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/150qbxm/n_stochastic_selfattention_a_perspective_on/",
          "author": null,
          "description": "https://arxiv.org/abs/2306.01705\n TL;DR - The paper offers a fresh viewpoint on transformers as dynamic ensembles of information pathways. Based on this, it proposes Stochastically Subsampled Self-Attention (SSA) for efficient training and shows how model ensembling via SSA further improves predictions.\n The key perspective proposed is that dense transformers contain many sparsely connected sub-networks termed information pathways. The full transformer can be seen as an ensemble of subsets of these pathways.\n Based on this, the authors develop SSA - which randomly samples a subset of pathways during training to enable computational efficiency. A locally-biased sampling is used to prioritize critical connections.\n SSA provides reduced training costs and also improves model generalization through its regularization effect.\n After sparse, regularized training with SSA, a short fine-tuning step with full dense attention helps consolidate all the pathways and prepares the model for optimal inference.\n Surprisingly, the authors show that performing SSA during inference to sample model sub-ensembles results in even more robust predictions compared to the full model.\n This demonstrates how the proposed viewpoint of information pathways and ensembling can be leveraged to develop training and inference techniques for transformers.\n Overall, this is a novel perspective on transformers providing theoretical insights, efficient training algorithms via SSA, and performance gains from ensembling.\n Here is a Medium post.\n    submitted by    /u/InspectorOpening7828  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/150qbxm/n_stochastic_selfattention_a_perspective_on/",
          "publishedOn": "2023-07-15T23:23:39.000Z",
          "wordCount": 2639,
          "title": "[N] Stochastic Self-Attention - A Perspective on Transformers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/150q4su/p_ml_homelab_and_training_time/",
          "author": null,
          "description": "Hello,\n I'm about to embark on a ML project but I am hoping to get some direction on what the best setup for my homelab would be and what kind of training time am I looking at. I plan on getting 1,000 to 10,000 pdf documents to train a model on text analysis. After doing some research, I'm not sure if multiple 3060s or 1 4090 would be better for this task? Also, would the training on a data set this size be hours? days? Thanks in advance for any advice/information.\n    submitted by    /u/BuckPrivate  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/150q4su/p_ml_homelab_and_training_time/",
          "publishedOn": "2023-07-15T23:14:56.000Z",
          "wordCount": 2517,
          "title": "[P] ML Homelab and training time",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/150oatj/why_is_the_alignment_problem_so_difficult_to/",
          "author": null,
          "description": "Many researchers are worried about AI trying to accomplish its goals by becoming more powerful at all costs. But why can’t we solve this problem by incorporating into the AI’s algorithm simple maxims like, “the (cumulative) size of the model (and all other models it creates) can never exceed Z”? Or “the model cannot hack into anything”?\n Alternatively, why can’t we specify a very small set of tasks the AI is allowed to do?\n    submitted by    /u/AvailableAd9981  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/150oatj/why_is_the_alignment_problem_so_difficult_to/",
          "publishedOn": "2023-07-15T21:58:21.000Z",
          "wordCount": 2504,
          "title": "Why is the alignment problem so difficult to solve? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/150mzax/n_d_langchain_what_is_it/",
          "author": null,
          "description": "want to know more about Langchain\n Check out https://nikhilpentapalli.substack.com/p/langchain-in-detail?sd=pf\n    submitted by    /u/Cool-Conversation301  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/150mzax/n_d_langchain_what_is_it/",
          "publishedOn": "2023-07-15T21:02:53.000Z",
          "wordCount": 2434,
          "title": "\"[N]\" \"[D]\" Langchain? What is it??",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/150mrfl/p_ai_video_game/",
          "author": null,
          "description": "submitted by    /u/CXGamesLTP  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/150mrfl/p_ai_video_game/",
          "publishedOn": "2023-07-15T20:54:10.000Z",
          "wordCount": 2422,
          "title": "[P] A.I Video Game",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/150m1ok/shortgpt_opensource_shorts_video_content/",
          "author": null,
          "description": "submitted by    /u/RayVentura  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/150m1ok/shortgpt_opensource_shorts_video_content/",
          "publishedOn": "2023-07-15T20:24:44.000Z",
          "wordCount": 2427,
          "title": "ShortGPT: opensource Shorts / video content automation framework [News]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/150ldhn/d_working_with_handson_machine_learning_with/",
          "author": null,
          "description": "I am reading pages 49 and 50 if you would like to find what I am doing. The pages say:\n In typical environments your data would be available in a relational database (or some other common datastore) and spread across multiple tables/documents/files. To access it, you would first need to get your credentials and access authorizations,10 and familiarize yourself with the data schema. In this project, however, things are much simpler: you will just download a single compressed file, housing.tgz, which contains a comma-separated value (CSV) file called housing.csv with all the data. You could use your web browser to download it, and run tar xzf housing.tgz to decompress the file and extract the CSV file, but it is preferable to create a small func‐ tion to do that. It is useful in particular i…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/150ldhn/d_working_with_handson_machine_learning_with/",
          "publishedOn": "2023-07-15T19:56:53.000Z",
          "wordCount": 2764,
          "title": "[D] Working with Hands-On Machine Learning with Scikit-Learn, Keras & Tensorflow 2nd Edition. Having problems with chapter 2. PLEASE HELP!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/150ko63/d_bandwidth_nvidia_l40/",
          "author": null,
          "description": "Hey everyone,\n I am evaluating if we can run inferencing at one of our deployments.\n When I go to nvidia's documentation, I can find the L4 & L40s inferencing performance.\n For example:\n  \n Network Throughput GPU \n  \n ResNet 50 27,107 Images/Sec L40 \n \n My questions are:\n  \nHow much bandwidth would we need to allocate in order to run the L40 at 100% given the parameters given by Nvidia's tests (or more specifically, how much bandwidth would we need to inference @ 27107 images / sec ) ?\n If you're in production now, how much bandwidth have you dedicated to inferencing internally?\n  \nNow I realize that this is analogous to asking \"how long is a piece of string?\"\n My background isn't necessarily in ML so I'm having trouble planning the network requirements. \n I am trying to gage what the surrounding infrastructure will have to look like in order to support inferencing at this throughput.\n My thoughts were to ask you wonderful people what your experience has been and what reality is before I ask the VARs / Vendors for advice.\n Any advice is greatly appreciated.\n Either way hope you all have a wonderful weekend!\n    submitted by    /u/hereliesozymandias  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/150ko63/d_bandwidth_nvidia_l40/",
          "publishedOn": "2023-07-15T19:26:43.000Z",
          "wordCount": 2615,
          "title": "[D] Bandwidth & Nvidia L40",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/150jzs7/d_ml_text_classification/",
          "author": null,
          "description": "Hey everyone, so I recently got into AI/ML and have been doing some text classification labeling using GCP's Vertex AI witb AutoML. And it works great!\n It gets me about. 92% accuracy on 200 rows of data. I know I need to gather more data for training but that's accumulating.\n The problem is Vertex AI Endpoint API requests are expensive.\n Wondering if anyone else ehas had any luck with alternatives? I've tried a few different products and tools and can get nothing over. 50% accuracy anywhere else.\n I do notice training on Vertex takes about 6 hours where every other tools I've tried takes less than 4 minutes.\n I've tried datasaur, Aikko, DataRobot, labelstudio, and some Hugging Face models with no luck.\n Any tips/guidance, thoughts from anyone would be much appreciated! Thank you.\n    submitted by    /u/ywb_win  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/150jzs7/d_ml_text_classification/",
          "publishedOn": "2023-07-15T18:59:13.000Z",
          "wordCount": 2557,
          "title": "[D] ML Text Classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/150fw8v/p_i_made_a_midjourney_prompts_cheatsheet/",
          "author": null,
          "description": "submitted by    /u/SadBlackTea  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/150fw8v/p_i_made_a_midjourney_prompts_cheatsheet/",
          "publishedOn": "2023-07-15T16:10:32.000Z",
          "wordCount": 2436,
          "title": "[P] I made a Midjourney Prompts Cheatsheet",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/150bio8/p_ai_dl_paper_highlights_junejuly_2023/",
          "author": null,
          "description": "submitted by    /u/seraschka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/150bio8/p_ai_dl_paper_highlights_junejuly_2023/",
          "publishedOn": "2023-07-15T13:02:32.000Z",
          "wordCount": 2439,
          "title": "[P] AI & DL paper highlights June-July 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/150adk0/p_ppo_agent_completing_street_fighter_iii_on_our/",
          "author": null,
          "description": "submitted by    /u/DIAMBRA_AIArena  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/150adk0/p_ppo_agent_completing_street_fighter_iii_on_our/",
          "publishedOn": "2023-07-15T12:07:30.000Z",
          "wordCount": 2448,
          "title": "[P] PPO agent completing Street Fighter III on our RL Platform, it consistently outperformed when using deterministic actions instead of sampling them proportionally to their probability, see comment for details.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1509jl5/d_unleash_your_creative_power_with_cm3leon_the/",
          "author": null,
          "description": "Are you ready to redefine the boundaries of creativity and innovation? Introducing CM3LEON, an extraordinary AI model that seamlessly combines text and images like never before. With its cutting-edge capabilities in text-guided image generation and editing, CM3LEON is revolutionizing the way we interact with and manipulate visual content. Join me on a journey into the realm of limitless possibilities. #AI #Creativity #Innovation #CM3LEON #meta #texttoimage #generativeai https://medium.com/@sandundayananda/introducing-cm3leon-by-meta-revolutionizing-generative-ai-for-text-and-images-397f00f1a393\n    submitted by    /u/sandun-dayananda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1509jl5/d_unleash_your_creative_power_with_cm3leon_the/",
          "publishedOn": "2023-07-15T11:25:23.000Z",
          "wordCount": 2504,
          "title": "[D] 🚀 Unleash Your Creative Power with CM3LEON: The Future of Text-Guided Image Generation and Editing! 🎨",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1508cku/d_autoencoder_sensitivity_to_scale/",
          "author": null,
          "description": "Hello,\n I am playing around with Autoencoders for jittery curves. I basically create 4 types of curves (circle, square, spiral and triangle) and add randomized (x,y) components at every points ( in green below) to introduce pseudo-randomness in the training data.\n This is what the model looks like:\n Autoencoder( (encoder): Sequential( (l0): Linear(in_features=432, out_features=3500, bias=True) (l1): Dropout(p=0.2, inplace=False) (l2): Linear(in_features=3500, out_features=90, bias=True) ) (decoder): Sequential( (l0): Linear(in_features=90, out_features=3500, bias=True) (l1): Dropout(p=0.2, inplace=False) (l2): Linear(in_features=3500, out_features=432, bias=True) ) ) \n Each path is 216 points (accounting for x and y, that's 432 variables). The training set is about 6400 such paths, homogeneously picked in the 4 patterns above.\n I have found that the size (as in width x height) of the paths plays an important factor in the quality of the results. Thus my questions... I know there are nn.BatchNorm1d layers but I am unsure on how to rescale reencoded data during training.\n How can I improve?\n Examples:\n ​\n  \nLarge size (e.g. in the 100s). After training the loss nicely converges down to 45ish.\n  \n​\n AE Performance for large size paths.\n 2) For small size path, this is a different story. The training does converge and stops at 0.78ish. But it look super gibberish IMHO.\n ​\n AE performance for small size paths\n 3) If I constrain the sizes to be between 1 and 400, the loss finishes at 20ish. The jitter is still very noticeable on small sizes path.\n ​\n https://preview.redd.it/ihxr9qtlu3cb1.png?width=562&format=png&auto=webp&s=4b6fb967b78172dc75fdadc87895d49000ae4b79\n ​\n    submitted by    /u/tareumlaneuchie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1508cku/d_autoencoder_sensitivity_to_scale/",
          "publishedOn": "2023-07-15T10:21:49.000Z",
          "wordCount": 2659,
          "title": "[D] Autoencoder sensitivity to scale",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1503edm/could_i_use_a_rented_online_gpu_as_an/",
          "author": null,
          "description": "Google Cloud, for example, apparently allows you to \"rent\" their GPUs online. I figure, I could offload the GPU tasks to them (my computer is old, the specs just don't seem like they'd work for LLaVA or MiniGPT4) -- then be able to programmatically use LLaVA in the ways I want, to describe images, without actually needing some impressive GPU specs on my own local machine.\n Is this a workable solution?\n Another idea I had was -- a software tool very similar to LLaVA in functionality, but that can be accessed via an API, instead of requiring you to download it, train the machine learning model on your local machine, etc. Unfortunately the ones I've tested so far all suck. LLaVA and MiniGPT4, by far, produce the best results.\n The optimal solution, in my case, would perhaps pass each image through BOTH LLaVA and MiniGPT4 -- split their descriptions into keywords, then only use the final keywords that BOTH of them agreed on. (This would help to weed our the occasional hallucinations one or the other will produce). No small task, especially when I'm trying to offload the GPU tasks to the cloud -- but it does seem totally possible to do this in theory.\n Thanks!\n    submitted by    /u/What_The_Hex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1503edm/could_i_use_a_rented_online_gpu_as_an/",
          "publishedOn": "2023-07-15T05:47:23.000Z",
          "wordCount": 2643,
          "title": "Could I use a rented online GPU as an intermediary to effectively operate LLaVA via Python? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1503c96/d_from_electrical_engineering_to_specializing_in/",
          "author": null,
          "description": "Hello everyone,\n I recently completed my undergraduate degree in Electrical and Information Engineering and am about to embark on a master's program with a focus on Computer Vision, Robotics, and Machine Learning. \n Although I have a strong engineering background and a solid grasp on machine learning fundamentals, I feel I lack in-depth knowledge in Statistics and Stochastics, which I understand play a critical role in this field. Unfortunately, my bachelor's program did not delve too deep into these topics, and I now find myself looking to bolster my understanding in these areas to better prepare myself for the challenges ahead.\n Given my situation, I'm reaching out to this community in hopes of finding valuable resources that could bridge this gap. I'm open to suggestions such as Udemy courses, YouTube channels, books, or any other resources that have a strong focus on Statistics and Stochastics, specifically as they apply to Machine Learning. Also I would kindly take recommendations for any advanced machine learning resources. \n I would be grateful for any advice or recommendations that could help me solidify my knowledge in these areas and better equip me for my upcoming studies.\n Thank you so much for your time and assistance!\n    submitted by    /u/Unusual_Macaroon1020  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1503c96/d_from_electrical_engineering_to_specializing_in/",
          "publishedOn": "2023-07-15T05:44:15.000Z",
          "wordCount": 2628,
          "title": "[D] From Electrical Engineering to Specializing in Machine Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14zzrnv/d_master_the_world_of_machine_learning_23_online/",
          "author": null,
          "description": "This is an ultimate resource for mastering machine learning with a collection of 23 comprehensive online exams, meticulously crafted to test your knowledge and understanding of various machine learning topics. \n With a total of 1,150 objective type questions, these exams cover everything from machine learning basics to cutting-edge concepts like CNN, RNN, Ensemble Learning, Time Series Analysis, Forecasting, Anomaly Detection, Recommendation Systems, Transfer Learning, Federated Learning and Ethics in ML. \n Whether you are a beginner or an experienced practitioner, this treasure trove of knowledge will challenge and enhance your understanding of this exciting field. \n Link to Exams\n    submitted by    /u/nkptcs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14zzrnv/d_master_the_world_of_machine_learning_23_online/",
          "publishedOn": "2023-07-15T02:40:00.000Z",
          "wordCount": 2535,
          "title": "[D] Master the World of Machine Learning: 23 Online Exams with 1150 Objective Type Questions on Machine Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14zwe9k/p_open_source_python_project_for_prompt/",
          "author": null,
          "description": "Hi r/MachineLearning!\n I wanted to share a project I've been working on that I thought might be relevant to you all, prompttools! It's an open source library with tools for testing prompts, creating CI/CD, and running experiments across models and configurations. It uses notebooks and code so it'll be most helpful for folks approaching prompt engineering from a software background.\n The current version is still a work in progress, and we're trying to decide which features are most important to build next. I'd love to hear what you think of it, and what else you'd like to see included!\n    submitted by    /u/hegel-ai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14zwe9k/p_open_source_python_project_for_prompt/",
          "publishedOn": "2023-07-15T00:01:25.000Z",
          "wordCount": 2527,
          "title": "[P] Open source python project for prompt experimentation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14zw5ax/d_large_language_model_that_can_source_historic/",
          "author": null,
          "description": "Does anyone know of an LLM that accepts images (.jpg) and can \"curate\" it to provide historical context, a description of the piece, artistic context, etc? I would love to use it on artworks from 1600s and 1700s, but I'll take anything that works with 1920 pieces and earlier.\n    submitted by    /u/GawkyCoolDude  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14zw5ax/d_large_language_model_that_can_source_historic/",
          "publishedOn": "2023-07-14T23:50:17.000Z",
          "wordCount": 2478,
          "title": "[D] Large language model that can source historic artworks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14zusur/d_where_to_start_learning_more_with_existing/",
          "author": null,
          "description": "Title, I just graduated from school with a CS degree. I took a couple 10 week AI classes, some computer vision classes, and a robust machine learning course. I also made some contributions to a large senior project that dealt with a fairly complex object detection ML model. \n Despite all of this I feel like my understanding of ML is pretty flimsy. I'm not sure if I should do Andrew Ng's Coursera or if there would be a better place for me to start given my background. I would say my goals are to acquire a deep enough understanding to start building my own models and potentially get a decent job within the ML space.\n    submitted by    /u/mythica44  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14zusur/d_where_to_start_learning_more_with_existing/",
          "publishedOn": "2023-07-14T22:53:08.000Z",
          "wordCount": 2544,
          "title": "[D] Where to start learning more with existing knowledge?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14zs069/d_audio_style_transfer/",
          "author": null,
          "description": "I saw this on YouTube and was wondering how it was done? I've dabbled before with stable diffusion so I'm a little bit familiar with style transfer using images but how is it done with audio? \n    submitted by    /u/That_Canadian_Nerd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14zs069/d_audio_style_transfer/",
          "publishedOn": "2023-07-14T21:00:45.000Z",
          "wordCount": 2460,
          "title": "[D] Audio Style Transfer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14zr32n/p_performance_evaluation_for_ai_models_on/",
          "author": null,
          "description": "Hi r/MachineLearning,\n ​\n I am currently writing my thesis and as part of my work I'm assessing the capability of GPT-4 on complex tasks where there are no binary solutions.\n If I were to give these tasks to let's say 5 subject matter experts, I would probably get 5 differing opinions on the correct solution. In real life those experts would sit down together and try to come to a common understanding of the right solution for the task.\n Now the results of GPT-4 in my experiments are astonishingly good if I were to evaluate the results. However, I can't seem to find literature delivering or explaining sound objective approaches to evaluating those kind of tasks.\n Does anyone have ideas or maybe literature to recommend? If not my backup plan is to evaluate the results myself and through other subject matter experts, so basically through human discrimination.\n ​\n Any help or information is greatly appreciated.\n    submitted by    /u/plutorollsvanillaice  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14zr32n/p_performance_evaluation_for_ai_models_on/",
          "publishedOn": "2023-07-14T20:25:00.000Z",
          "wordCount": 2583,
          "title": "[P] Performance Evaluation for AI models on non-binary, complex tasks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14zqv06/r_does_ai_think_as_we_do_evaluating_global/",
          "author": null,
          "description": "🤓 Does Ai Think As We Do? Evaluating Global Alignment\n Researchers at Anthropic developed a method to evaluate how well large language models like ChatGPT reflect diverse global opinions, not just the biases of the model developers.\n  \nThey created a dataset called GlobalOpinionQA with survey questions and answers from people in different countries.\n Designed a metric to quantify how closely model responses match human answers by country.\n Tested a model intended to be helpful, honest, and harmless.\n The goal is to measure if models represent a variety of global perspectives or are skewed towards certain viewpoints.\n This work aims to guide the creation of inclusive AI that serves people worldwide, not just programmer biases.\n  \n   submitted by    /u/Yavero  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14zqv06/r_does_ai_think_as_we_do_evaluating_global/",
          "publishedOn": "2023-07-14T20:15:57.000Z",
          "wordCount": 2545,
          "title": "[R] 🤓 Does Ai Think As We Do? Evaluating Global Alignment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14zqs1x/d_cuda/",
          "author": null,
          "description": "Hello guys,\n I wrote a python code for DRL in Visual studio. However, it takes a long time in training. Could you give me instructions to run the code with CUDA knowing that I have already installed Nvidia CUDA.\n Thank you.\n    submitted by    /u/GuavaAgreeable208  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14zqs1x/d_cuda/",
          "publishedOn": "2023-07-14T20:12:42.000Z",
          "wordCount": 2463,
          "title": "[D] CUDA",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14zqrkz/p_cuda_and_vs/",
          "author": null,
          "description": "Hello guys,\n I wrote a python code for DRL in Visual studio. However, it takes a long time in training. Could you give me instructions to run the code with CUDA knowing that I have already installed Nvidia CUDA.\n Thank you.\n    submitted by    /u/GuavaAgreeable208  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14zqrkz/p_cuda_and_vs/",
          "publishedOn": "2023-07-14T20:12:08.000Z",
          "wordCount": 2465,
          "title": "[P] CUDA and VS",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14zqooq/discussion_is_clip_model_still_state_of_the_art/",
          "author": null,
          "description": "Hi ML community,\n I've been out of the ML/computer vision research loop for a while. In the past two years, have there been any major improvements on the CLIP model since OpenAI released it in 2021?\n Thanks!\n    submitted by    /u/goodfriedchicken  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14zqooq/discussion_is_clip_model_still_state_of_the_art/",
          "publishedOn": "2023-07-14T20:08:53.000Z",
          "wordCount": 2466,
          "title": "[Discussion] Is CLIP model still state of the art?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14zo1ux/d_anonymize_obfuscate_speech_when_doing_audio/",
          "author": null,
          "description": "Hey!\n Let me preface that I am new to audio processing and audio analysis ;)\n I am trying to classify audio data in an environment where people are. Recording people is a big no no here. (Well the recording was okayed under the premise that no talks can get transcribed and that no people are recognizable)\n The first idea was to simply use a band filter and cut out the frequency range of normal speech but some of the signals I am interested might also fall into that range so I would rather avoid that.\n Then I looked into spectrograms which looked promising for classification in general. I found the librosa library in python and started doing stft. I had planned to save the amplitude \n S = np.abs(librosa.stft(signal, n_fft=<int>)\n to maybe work on some other feature extraction or post proces…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14zo1ux/d_anonymize_obfuscate_speech_when_doing_audio/",
          "publishedOn": "2023-07-14T18:25:21.000Z",
          "wordCount": 2813,
          "title": "[D] Anonymize / Obfuscate speech when doing audio classification.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14zna20/r_hyperdreambooth_hypernetworks_for_fast/",
          "author": null,
          "description": "Project page: https://hyperdreambooth.github.io/\n Twitter thread: https://twitter.com/natanielruizg/status/1679893292618752000?s=20\n Paper: https://arxiv.org/abs/2307.06949\n ​\n HyperDreamBooth: smaller, faster, better.\n Abstract\n  \nPersonalization has emerged as a prominent aspect within the field of generative AI, enabling the synthesis of individuals in diverse contexts and styles, while retaining high-fidelity to their identities. However, the process of personalization presents inherent challenges in terms of time and memory requirements. Fine-tuning each personalized model needs considerable GPU time investment, and storing a personalized model per subject can be demanding in terms of storage capacity. To overcome these challenges, we propose HyperDreamBooth - a hypernetwork capable of efficiently generating a small set of personalized weights from a single image of a person. By composing these weights into the diffusion model, coupled with fast finetuning, HyperDreamBooth can generate a person's face in various contexts and styles, with high subject details while also preserving the model's crucial knowledge of diverse styles and semantic modifications. Our method achieves personalization on faces in roughly 20 seconds, 25x faster than DreamBooth and 125x faster than Textual Inversion, using as few as one reference image, with the same quality and style diversity as DreamBooth. Also our method yields a model that is 10000x smaller than a normal DreamBooth model.\n  \n   submitted by    /u/StrawberryNumberNine  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14zna20/r_hyperdreambooth_hypernetworks_for_fast/",
          "publishedOn": "2023-07-14T17:54:48.000Z",
          "wordCount": 2628,
          "title": "[R] HyperDreamBooth: HyperNetworks for Fast Personalization of Text-to-Image Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14zlaz6/d_the_problem_with_langchain/",
          "author": null,
          "description": "https://minimaxir.com/2023/07/langchain-problem/\n tl;dr it's needlessly complex, and I provide code examples to demonstrate such.\n A few weeks ago when I posted about creating a LangChain alternative to /r/MachineLearning, most of the comments replied \"what exactly is the issue with LangChain\", so I hope this provides more clarity!\n    submitted by    /u/minimaxir  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14zlaz6/d_the_problem_with_langchain/",
          "publishedOn": "2023-07-14T16:40:33.000Z",
          "wordCount": 2471,
          "title": "[D] The Problem With LangChain",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14zjpno/new_research_from_microsoft_using_autoencoders_to/",
          "author": null,
          "description": "submitted by    /u/Working_Ideal3808  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14zjpno/new_research_from_microsoft_using_autoencoders_to/",
          "publishedOn": "2023-07-14T15:38:35.000Z",
          "wordCount": 2441,
          "title": "New Research from Microsoft using Autoencoders to extend context length",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14zjdpu/p_google_ml_kit_face_detection_enhance_your_apps/",
          "author": null,
          "description": "Facial detection and recognition technology have become an integral part of our daily lives, revolutionizing industries such as security, entertainment, and marketing. Google ML Kit, a powerful machine-learning platform....... \n Article Link\n    submitted by    /u/waqararif  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14zjdpu/p_google_ml_kit_face_detection_enhance_your_apps/",
          "publishedOn": "2023-07-14T15:25:37.000Z",
          "wordCount": 2463,
          "title": "[P] Google ML Kit Face Detection | Enhance Your App's Visual Intelligence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14zj7zm/discussion_importance_of_prompt_engineering_in_ai/",
          "author": null,
          "description": "Hewwo ML chads. jk. Now that I have yalls attentions, I wanna ask how important would you rate proper prompt engineering to be? Like would you go as far as to leanr how to prompt a model perfectly, or use a tool for it? And if so do yall rate the tools, or d’you think they’re just forcing their place in the market. Opinions/suggestion/ recommendations welcome, I just wanna know what the general consensus is about prompt engineering \n    submitted by    /u/WorriedMentality  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14zj7zm/discussion_importance_of_prompt_engineering_in_ai/",
          "publishedOn": "2023-07-14T15:19:36.000Z",
          "wordCount": 2505,
          "title": "[Discussion] Importance of prompt engineering in AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14zivdg/p_trying_to_build_a_smart_ingredient_parser_app/",
          "author": null,
          "description": "Hey guys,\n I'm working on a university project where I am developing an Android application that uses OCR to scan ingredient contents on the back of food products and provide detailed descriptions of the ingredients, identify potential allergens, and estimate the healthiness factor of the overall food product. Can you suggest some key ideas/features for which I can use Machine Learning as an extra added implementation for my project? \n    submitted by    /u/shrux2k  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14zivdg/p_trying_to_build_a_smart_ingredient_parser_app/",
          "publishedOn": "2023-07-14T15:05:58.000Z",
          "wordCount": 2501,
          "title": "[P] Trying to build a smart ingredient parser app, need some ideas please",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14zff63/d_iccv_final_decisions_announced_today/",
          "author": null,
          "description": "Any changes to the score post-rebuttal? \n Did they even read your rebuttal?\n    submitted by    /u/Alarming-Aspect705  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14zff63/d_iccv_final_decisions_announced_today/",
          "publishedOn": "2023-07-14T12:41:14.000Z",
          "wordCount": 2438,
          "title": "[D] ICCV final decision’s announced today!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14zefs1/d_looking_for_papers_on_human_evaluation_of_xai/",
          "author": null,
          "description": "I hope that this question fits this sub: I'm currently interested in explainable AI methods. I want to incorporate them into a dashboard to increase the transparency and trust in an underlying Text Classification Model. Currently, SHAP looks promising, but I'm wondering: Which methods work best from a non-technical enduser perspective? What do I need to consider during the design phase? I haven't found good papers that compare different methods and their effectiveness. Does anyone know good papers regarding this?\n    submitted by    /u/zeoNoeN  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14zefs1/d_looking_for_papers_on_human_evaluation_of_xai/",
          "publishedOn": "2023-07-14T11:55:18.000Z",
          "wordCount": 2510,
          "title": "[D] Looking for papers on human evaluation of xAI techniques",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14ze05e/d_pytorch_lighting_vs_huggingface_for_production/",
          "author": null,
          "description": "Hi,\n Recently i joined company and there is discussion of transition from custom pytorch interface to pytorch lightning or huggingface interface for ml training and deployment on azure ml. Product related to CV and NLP. Anyone maybe have some experience or pros/cons of each for production ml development?\n    submitted by    /u/ApplicationOne582  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14ze05e/d_pytorch_lighting_vs_huggingface_for_production/",
          "publishedOn": "2023-07-14T11:33:45.000Z",
          "wordCount": 2478,
          "title": "[D] pytorch lighting vs huggingface for production on azure ml",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14zcssu/d_simple_sequence_prediction_problem/",
          "author": null,
          "description": "Hello,\n I'm not an expert of ML or any AI topics but have played in the past using LSTMs + RNN for character/word prediction.\n I'm wondering what -as of today- best model or method should be used to predict sequences.\n The dataset can be constructed by me in two ways. Either way it is going to be a fixed 31+space (32) word:\n  \nHaving human readable characters like (ZaaaaZZZZZZZZZZZAZZZZZaAAaZZZZZ ZbbbbZZZZZZZZZZZBZZZZZbBBbbBZZZ CccccccZZZZZZZZZCZZZZZcCCccCCZZ DddddddddZZZdddDDDZZZZdDDddDDZY EeeeeeeeeZZZEeeEEEZZZZeEEeeEEZY FfffffffFZZZFffFFFZZZZfFFffFFZY GgggggggGGggGggGGGGgGggGGggGGGY)\n Having UTF-8 characters like (^BȁȂȃ؃؄؅؆؇؈؉؊؋،؍Џ؏ؐؑȕ^Y^ZȘؘؙ؛؜ ׿^DȄȆȈ؉؋؍؏ؑؓ؛؝РﺀﺃﺇﺍﺓȬ57Ȳ;ȶﻂﻋػ ȁ^FȇȊȍȐȓؘؕ؛؞ﺀﺅﺎﺘﺣбﺲﻀﻋؼؿɃMPɌVɒ\\ٗٚ Ȃ^HȊȎȒȖȚȞȢﺇﺔﺣȲȶAȾтɆﻯٍّɚeiɦqɮyٵ<81> ȃ^KȍȒȗȜȡȦȫﺪﺸﻋFɄPɎѓɘٜ١٦٫ɱ}<82>ʀ<8c>ʊ<96>ړ Ȅ^MȐȖȜȢȨȮȴﻉؿﻡSɒ_ɞѤqٯٵٻځʈ<95><9b>ʚ§ʦ³ڱ¿ ȅ^OȓȚȡȨȯȶȽﻚﻳّ`gnɮѵ<83>ڂډڐڗʟ­´ʴÂ˂ÐۏÞ Ȇ^QȖȞȦȮȶEɆٍٕmu}ɾ҆<95>ڕڝڥڭʶÅÍˎÝ˞íۭý ȇ^SșȢȫȴȽMɏɘɡqz<83><8c>ʎҗ§ʩ¹Â˄ˍÝæ˨ø˺ĊԌĜ)\n  \nBoth contain the same information and is an encoded sequence of states. I'm trying to predict the states. You notice that in the 1) the first word is \"a\" or \"A\" while the next sequence is going to be \"b\"/\"B\" and the third sequence is \"c\"/\"C and so on. The same logic applies to the UTF-8. Each character here matters. The file contains around 3924 lines, each one looking either 1) or 2).\n I dont know, if\n a) which encoding is more appropriate for ML character prediction\n b) which model/technology to use to generate these sequences if I input a start pattern, e.g. (ZaaaaZZZZZZZZZZZAZZZZZaAAaZZZZZ ZbbbbZZZZZZZZZZZBZZZZZbBBbbBZZZ CccccccZZZZZZZZZCZZZZZcCCccCCZZ) it should generate the most likely probable next sequences.\n Historically, char-rnn was used for this problem and the result was so so. Can anyone pls point me out to the right solution for this problem and maybe some github examples to try on this?\n    submitted by    /u/mcr-ksh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14zcssu/d_simple_sequence_prediction_problem/",
          "publishedOn": "2023-07-14T10:31:15.000Z",
          "wordCount": 2662,
          "title": "[D] Simple sequence prediction problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14za795/p_unleashing_insights_guiding_synthetic_data/",
          "author": null,
          "description": "I wrote an article in which I explored the power of interactive data exploration with Spotlight for synthetic data generation. I highlighted the challenges of working with Jupyter Notebooks and introduced Spotlight as an alternative tool. By leveraging Spotlight's features, such as similarity maps and histograms, I uncovered critical segments in the dataset and provided actionable insights for synthetic data generation. Join me on this journey to unlock the full potential of your data! Check out the full article for all the details.\n Article on medium: Link\n Happy learning!\n ​\n https://i.redd.it/hdc0c0fw0wbb1.gif\n    submitted by    /u/ml-wizard  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14za795/p_unleashing_insights_guiding_synthetic_data/",
          "publishedOn": "2023-07-14T08:03:57.000Z",
          "wordCount": 2522,
          "title": "[P] Unleashing Insights: Guiding Synthetic Data Generation through Interactive Exploration in Spotlight 🚀",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14yz8q0/p_colab_generate_json_dataset_and_evaluate_llms/",
          "author": null,
          "description": "Here's a free colab notebook that I've been playing around with to generate JSON datasets from PDFs for fine-tuning LLMs and evaluate outputs/prompts for Toxicity, Bias, Quality etc. \n Colab: https://colab.research.google.com/drive/1KCn1HIeD3fQy8ecT74yHa3xgJZvdNvqL?usp=sharing\n GitHub Repo: https://github.com/kw2828/guardrail-ml\n    submitted by    /u/Educational_Grass_38  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14yz8q0/p_colab_generate_json_dataset_and_evaluate_llms/",
          "publishedOn": "2023-07-13T22:57:18.000Z",
          "wordCount": 2462,
          "title": "[P] Colab - Generate JSON Dataset and Evaluate LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14yyvxr/d_looking_to_enroll_in_a_ms_in_aiml/",
          "author": null,
          "description": "I’m looking into getting my MS in ML soon and I’m not sure if the market is good, some friends and family are telling me its too saturated and you won’t find a job and others are telling me you still need leetcode to get a job and others tell me the job market is extremely competitive and you likely wont get a job. Im worried that im making a mistake. Here are some facts about me: 1. I currently am working in a company where I have 5 rotations every 9 months, 3 of them which will be AI/ML related, which means I’ll definitely have at least 3 projects in hand on a global scale (company is global)\n  \nBy the time im done with the MS, I’ll probably already have 2-3 years of hands on experience. \n  \nThats about it. \n Should I be worried? Please advise me, Thank you\n    submitted by    /u/KManYuksi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14yyvxr/d_looking_to_enroll_in_a_ms_in_aiml/",
          "publishedOn": "2023-07-13T22:42:07.000Z",
          "wordCount": 2577,
          "title": "[D] Looking to enroll in a MS in AI/ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14yxx5w/d_iccv_reviews_are_not_out/",
          "author": null,
          "description": "zzz\n    submitted by    /u/Towzeur  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14yxx5w/d_iccv_reviews_are_not_out/",
          "publishedOn": "2023-07-13T22:02:44.000Z",
          "wordCount": 2427,
          "title": "[D] ICCV Reviews are NOT out",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14yxsnp/d_ray_vs_aws_batch_for_distributed_training/",
          "author": null,
          "description": "Hello all,\n In our organization, we are currently using Metaflow as our managed training infrastructure and leveraging the `@batch` decorator for compute. Using Batch, we also have access to multi-node parallel jobs (`@parallel` decorator) for distributed training and we've used it to great effect for fine-tuning some LLMs.\n We are now thinking of adopting Ray Train since it seems to be very popular nowadays and is gaining lots of traction.\n Wondering how Ray Train compares to Metaflow (AWS Batch) and what the pros/cons are for both, particularly in the context of scalable training of models.\n Please kindly share any insights. Thanks in advance!\n    submitted by    /u/rirhun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14yxsnp/d_ray_vs_aws_batch_for_distributed_training/",
          "publishedOn": "2023-07-13T21:57:55.000Z",
          "wordCount": 2531,
          "title": "[D] Ray vs. AWS Batch for Distributed Training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14yxa4b/is_the_following_an_valid_way_to_combine_models_d/",
          "author": null,
          "description": "I am a physician conducting research on intensive care data from many patients.\n I have full ethical approval, this is just exploratory, nobody will be treated based on my results, and I have no statistician.\n I have a question in principal, rather than looking for a specific solution. I have trained and tuned three models on my (very imperfect) data. They make binary predictions about the likely success of a treatment.\n I have developed a logistic regression model, a gaussian naive bayes model, and a c5.0 decision tree model. Each is imperfect in its own way. AUC for each is 0.72-0.79. I am wondering if I could ask each model to make predictions on a set of test data, and let the models 'vote'. For example, if 2 of 3 models agree, then I create a 'majority opinion' column on my data and go with that result. I figure it might weed out some weakness.\n Is this a 'valid' way to do this, or is it pure nonsense in the world of machine learning?\n    submitted by    /u/e05bf027  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14yxa4b/is_the_following_an_valid_way_to_combine_models_d/",
          "publishedOn": "2023-07-13T21:36:39.000Z",
          "wordCount": 2604,
          "title": "Is the following an valid way to combine models? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14yx1kt/d_text_analysis_alternative_to_liwc/",
          "author": null,
          "description": "I'm working on a social science project and have a lot of text data that I would like to analyse between certain groups. Most of the papers that I've read on this use LIWC, but I unfortunately don't have access to that. An alternative I've found was the python package empath but it doesn't account for the use of pronouns which I know is going to be an important feature here. Does anyone know of a better alternative? Thanks a lot! \n    submitted by    /u/PlainJane049  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14yx1kt/d_text_analysis_alternative_to_liwc/",
          "publishedOn": "2023-07-13T21:27:13.000Z",
          "wordCount": 2507,
          "title": "[D] Text analysis alternative to LIWC?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14yw72v/r_nvidia_rtx_4090_ml_benchmarks_under_qemukvm/",
          "author": null,
          "description": "Motivation:\n I am running a proxmox instance for tinkering with devops stuff, k8s, ci and so on. And wanted to also have the ability to run ML workloads specifically any kind of ClosedAI open-sourced alternatives. Like Guanaco, WizardLM, Starcoder, Codegen. As well as having some kind of pre-prod environment for ML deployments.\n Environment:\n All the tests were run within a virtual machine(qemu) which is run using proxmox 7.4-3.\n  CPU: Intel Xeon 2696v4 2.2Ghz Storage: Samsung SSD 870 EVO OS:Linux gpu-node 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86\\_64 x86\\_64 x86\\_64 GNU/LinuxDISTRIB\\_DESCRIPTION=\"Ubuntu 22.04.2 LTS\" Python 3.10.12 (main, Jul 5 2023, 18:54:27) \\[GCC 11.2.0\\] on linux Torch version: Version: 2.1.0.dev20230709+cu121 import torch;torch.version.cuda -> …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14yw72v/r_nvidia_rtx_4090_ml_benchmarks_under_qemukvm/",
          "publishedOn": "2023-07-13T20:54:20.000Z",
          "wordCount": 2731,
          "title": "[R] Nvidia RTX 4090 ML benchmarks. Under QEMU/KVM. Image + Transformers. FP16/FP32.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14yw4pl/d_stats_package_jmp_vs_machine_learning_for/",
          "author": null,
          "description": "CIO wants to predict \"things\" about mortgages using \"technology\". (There have been a few specifics and possible factors suggested, like if a loan was returned to us by the bank we sold it to). IT manager is super gung ho about using machine learning and AI. \n I'm not an experienced statistician, but I used JMP when I worked as a process engineer (yeah, squiggly career), and was like, why can't we just do this with JMP? I can figure out which factors are significant and which are most strongly correlated to what they want answers to.\n Is there a valid reason to go the machine learning route, or is it just a hot topic right now? No one seems willing to point out any flaws with that method and that makes me uncomfortable.\n    submitted by    /u/clarielz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14yw4pl/d_stats_package_jmp_vs_machine_learning_for/",
          "publishedOn": "2023-07-13T20:51:46.000Z",
          "wordCount": 2562,
          "title": "[D] Stats package (JMP) vs machine learning for prediction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14yrt5i/tokenmonster_ungreedy_subword_tokenizer_v4/",
          "author": null,
          "description": "GitHub | Interactive Benchmark | Live Tokenizer\n TokenMonster is an ungreedy subword tokenizer and vocabulary trainer for Python, Go & Javascript. You can use one of my pretrained vocabularies or generate your own with the included tools.\n TokenMonster can tokenize text more efficiently than other tokenization methods, even when using a much smaller vocabulary. Here is a size 24000 TokenMonster vocabulary benchmarked against tiktoken cl100k_base (100256) and LLaMa (32000) (link to interactive benchmark):\n https://preview.redd.it/o16a9tbrurbb1.png?width=1506&format=png&auto=webp&s=66c11d2b8defd634c86756064125b70e8e5cb6d6\n Unlike previously versions of TokenMonster, the current version does not compress the text into as few tokens as possible to achieve the high chr/token. TokenMonster V4 of…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14yrt5i/tokenmonster_ungreedy_subword_tokenizer_v4/",
          "publishedOn": "2023-07-13T18:02:52.000Z",
          "wordCount": 2772,
          "title": "TokenMonster Ungreedy Subword Tokenizer V4: Enables Models to be 4x Smaller and Whilst Achieving Higher Chr/Token (With Evidence) [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14ypwnr/p_intfpqsim_mixed_precision_and_formats_for_large/",
          "author": null,
          "description": "Hello,\n We've released INT-FP-QSim: https://github.com/lightmatter-ai/INT-FP-QSim, a flexible simulator that allows running different LLMs and vision transformers at different formats (INT, FP) and precision (8-bit, 4-bit). The repository also has scripts for running simple evaluation with Stable Diffusion, Maskformer, Graphormer, ImageBind and CodeGen (with and without the simulator). \n Since there are users who may not have a good starting point for running different models, we hope that the example scripts provided in this repository will help there as well.\n    submitted by    /u/IllustriousSir_007  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14ypwnr/p_intfpqsim_mixed_precision_and_formats_for_large/",
          "publishedOn": "2023-07-13T16:47:45.000Z",
          "wordCount": 2511,
          "title": "[P] INT-FP-QSim: Mixed Precision and Formats For Large Language Models and Vision Transformers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14yp7c1/p_federated_learning_framework/",
          "author": null,
          "description": "Hello everyone 👋\n We have launched a new project called MetisFL, a federated learning framework that allows developers to federate their machine learning workflows and train their models across distributed datasets without having to collect the data in a centralized location.\n https://github.com/NevronAI/metisfl\n Every feedback or even a simple star, would be highly appreciated! \n    submitted by    /u/No-Literature-1930  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14yp7c1/p_federated_learning_framework/",
          "publishedOn": "2023-07-13T16:20:22.000Z",
          "wordCount": 2477,
          "title": "[P] Federated Learning framework",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14ymywm/p_curated_transformers_library_of_pytorch_llm_and/",
          "author": null,
          "description": "https://github.com/explosion/curated-transformers/\n Curated Transformers is a new library of PyTorch LLM and other transformer architectures, implemented using common components.\n The library makes a different trade-off from Huggingface Transformers, which uses wholly separate implementations for each architecture. The advantage of HF's approach is that they can adopt new architectures very quickly, by taking the academic implementation more or less verbatim.\n Curated Transformers won't be able to add architectures as quickly, but the implementations share common elements, making it easier to mix and match components and see how architectures differ. We'll also be able to share bug fixes and improvements between different models.\n Check it out if you're interested in mixing and matching parts of different models, or if you just want a lighter-weight, pure-PyTorch experience, without any intervening abstractions.\n Supported encoder-only models:\n  \nALBERT\n BERT\n CamemBERT\n RoBERTa\n XLM-RoBERTa\n  \nSupported decoder-only models:\n  \nGPT-NeoX\n LLaMA\n Falcon\n  \nGenerator wrappers:\n  \nDolly v2\n Falcon\n  \nAll models can be loaded from Huggingface Hub.\n spaCy integration for curated transformers is provided by the spacy-curated-transformers package.\n    submitted by    /u/syllogism_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14ymywm/p_curated_transformers_library_of_pytorch_llm_and/",
          "publishedOn": "2023-07-13T14:52:20.000Z",
          "wordCount": 2598,
          "title": "[P] Curated Transformers: Library of PyTorch LLM and other transformers, with common components",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14ylfq1/r_pytorch_deeplabmmsegmentation_tutorial_resources/",
          "author": null,
          "description": "I've hit a bit of a roadblock. I'm struggling to find tutorials with PyTorch code for Semantic Segmentation. I initially used the MMSegmentation tutorial on its GitHub, but that didn't work as there were a number of missing files.\n Any help would be massively appreciated as I'm really struggling.\n    submitted by    /u/Charako  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14ylfq1/r_pytorch_deeplabmmsegmentation_tutorial_resources/",
          "publishedOn": "2023-07-13T13:50:25.000Z",
          "wordCount": 2474,
          "title": "[R] PyTorch DeepLab/MMSegmentation Tutorial Resources",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14yj18u/research_incorporating_additional_information/",
          "author": null,
          "description": "Context:\n The input is a 3D MRI image, aswell as a position and orientation both in 3D. \n Output is a 3D image\n Most likely candidate for architecture is 3D-Unet \n In general we are trying to predict how a brain will be stimulated based a magnet producing an electric field. The position and orientation I am talking about is the position and orientation of the magnet. If you are interested this paper works on the same problem: \n doi.org/10.1371/journal.pone.0254588 \n Question:\n How do we incoorperate multiple different input types (image + vectors) in CNN's \n We know the position and orientation information is extreemly relevant to the output, meaning we know it can be incoorperated directly into the latentspace, what I dont understand is how to incoorperate the two vectors into the latentspace in order to keep the feature dimentions. \n I can think of two options:\n 1)\n add additional feature layers to the latentspace in which every layer has one value as constant accross the entire layer, that way if we have 2 vectors and a angle we would add 7 feature layers to the latent space. \n Here I am not sure if the neural network can work with these since they only really have any meaning if you put them together into a vector \n 2) completely flatten the latent space add the values and then reshape them back into form.\n Here i doubt this is a good idea since we are destroying all localization information from the features \n Previous approach:\n One solution we have thought about is feeding the neural net the mri image as if it was taken from the position, orientation and angle that way incoorperating the information indirectly. This solution preduces the most accurate results in previous papers.\n Unfortunatly that solution leads to a too long preprocessing time and since we need the inference to be real time it is not a valid solution.\n    submitted by    /u/ClumsyClassifier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14yj18u/research_incorporating_additional_information/",
          "publishedOn": "2023-07-13T12:05:11.000Z",
          "wordCount": 2738,
          "title": "[Research] incorporating additional information into the latent space of CNN's?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14yifir/p_journal_hub_literature_discussion_platform/",
          "author": null,
          "description": "[ Removed by Reddit on account of violating the content policy. ]\n    submitted by    /u/iokarkan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14yifir/p_journal_hub_literature_discussion_platform/",
          "publishedOn": "2023-07-13T11:36:22.000Z",
          "wordCount": 2434,
          "title": "[P] Journal Hub - literature discussion platform project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14yhnot/r_deep_learning_models_for_forest_canopy/",
          "author": null,
          "description": "I need to either build a tool or use a service which can convert satellite image (Input) of trees, and then output an estimate of its forest canopy. Has anyone ever used or know of such deep learning models? Thanks.\n    submitted by    /u/Quantumercifier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14yhnot/r_deep_learning_models_for_forest_canopy/",
          "publishedOn": "2023-07-13T10:58:05.000Z",
          "wordCount": 2468,
          "title": "[R] Deep Learning Models for Forest Canopy Estimation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14ygk36/d_overview_of_recent_developments_in/",
          "author": null,
          "description": "Hi everyone,\n I wrote a blog post on the advancements in Generative AI for audio, focusing on Text-to-Speech (TTS) and Text-to-Music (TTM) models. I survey how techniques from LLMs have been adapted for audio generation, leading to significant improvements.\n The article takes a technical look at some of the recent models in this space, including MusicLM, VALL-E, and also explains the key ideas behind Neural Audio Codecs and Residual Vector Quantization techniques, which have become essential in nearly all text-to-audio models.\n If you have an interest in the current state and future of Generative AI for audio, I hope you will find this informative! I drop the article link in the comments below 👇👇👇\n I appreciate any feedback or thoughts you may have!\n    submitted by    /u/mrx-ai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14ygk36/d_overview_of_recent_developments_in/",
          "publishedOn": "2023-07-13T09:58:52.000Z",
          "wordCount": 2554,
          "title": "[D] Overview of recent developments in audio-generative models (TTS & TTM)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14yg7uw/p_fast_debugging_of_audio_machine_learning_models/",
          "author": null,
          "description": "I recently have improved a library I created to have support for finding issues in audio data using audio embeddings.\n ​\n A mix of automatically detecting problematic data clusters and reviewing them visually can help speed up model debugging.\n The principle behind this is as follows:\n Step 1: Compute audio embeddings for the raw data 🎶This makes the data explorable by audio similarity. Depending on the properties the model captures, you will get different notions of similarity. E.g., if you use a model for speaker identification, you will probably order your data according to the speaker's voice properties.\n Step 2: Identify problematic data slices using clustering 🔍One strategy to get explicit suggestions for problematic data slices is clustering the samples based on audio embeddings. You can then compute your evaluation metrics for the identified clusters and search for clusters that, compared to the overall accuracy, show a significant accuracy drop.\n Step 3: Review the supposed issues visually 👀Especially when using only unstructured data, the results of your analysis will not be readily interpretable. However, reviewing the problematic clusters by listening and visualizing (e.g., drawing spectrograms) will help you filter out actual model and data issues.\n I also created a Medium Post and an Example Notebook for this.\n Also check out this Interactive Result Visualization on Huggingface.\n ​\n ​\n ​\n    submitted by    /u/OkResearch6289  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14yg7uw/p_fast_debugging_of_audio_machine_learning_models/",
          "publishedOn": "2023-07-13T09:39:22.000Z",
          "wordCount": 2643,
          "title": "[P] Fast debugging of audio machine learning models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14yfu0i/d_overfit_ml_model/",
          "author": null,
          "description": "Hello this is my first contribution to the sub, I have a dataset for a classification problem and it seems that all the models I have performed are overfiting (f1 score close to 1). I cant wrap my head around how to solve it without removing important values.\n    submitted by    /u/Archyve  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14yfu0i/d_overfit_ml_model/",
          "publishedOn": "2023-07-13T09:17:43.000Z",
          "wordCount": 2472,
          "title": "[D] Overfit ML model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14ybjoh/d_how_to_accelerate_vit_models_more_faster/",
          "author": null,
          "description": "I have conducted experiments and examples on accelerating ViT (Vision Transformer) using methods such as TensorRT, FasterTransformer, and xFormers. The experiments were conducted using a single A100 as a baseline. - https://github.com/bnabis93/vision-language-examples/tree/main/acceleration \n In xFormers, I tried applying sparse attention and memory-efficient attention to ViT, but there was an issue where the speed actually decreased. Therefore, I excluded those results. \n Generally, just performing TensorRT conversion significantly improves latency. In the case of faster transformer, optimized kernels are not provided in fp32, so it is not as effective as expected. However, after quantizing to fp16 and obtaining the results, it was more effective than simply performing TensorRT conversion. \n Are there any other methods for accelerating ViT? Using OpenAI's Triton is one option that comes to mind. If you have any other methods worth trying, I would appreciate it if you could let me know.\n    submitted by    /u/bono-93  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14ybjoh/d_how_to_accelerate_vit_models_more_faster/",
          "publishedOn": "2023-07-13T05:16:07.000Z",
          "wordCount": 2570,
          "title": "[D] how to accelerate ViT models more faster",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14y8zrc/p_llms_nlp_building_a_model_to_generate_and/",
          "author": null,
          "description": "Hi all. I'm diving into the world of Natural Language Processing (NLP) and Large Language Models (LLMs), and I could really use some assistance with my project. Here's what I'm aiming to achieve:\n Imagine having a dataset with various features such as location, type of claim, and claim payment. Additionally, there's a column dedicated to narratives, which provide descriptions of each claim. For instance, a narrative could be \"I was crossing the street and was hit by a car, which broke my leg.\"\n My goals are twofold:\n i) Develop a model capable of taking the three columns (type of claim, claim payment, and location) as input and generating a narrative.\n ii) Create another model that does the reverse: input a narrative and extract relevant information like the type of claim and the location.\n I would greatly appreciate any advice, or resources you can provide. Thank you in advance!\n    submitted by    /u/therobot20  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14y8zrc/p_llms_nlp_building_a_model_to_generate_and/",
          "publishedOn": "2023-07-13T03:07:41.000Z",
          "wordCount": 2580,
          "title": "[P] LLMs, NLP: Building a Model to Generate and Analyze Claim Narratives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14y7ajc/dencoder_only_vs_encoderdecoder_vs_decoder_only/",
          "author": null,
          "description": "I understand that encoder only models (like BERT etc) are mainly for learning representations of words taking context on both sides. What I’m confused about is why you would need decoder only vs encoder-decoder models. GPT and Bloom are decoder only while I think T5 is enc-dec, I’m not sure why you would use one vs the other. Intuitively enc-dec model has more parameters and should be better at tasks where you have both complex text input and output, like say translation or summarization. Any ideas why decoder only models are desirable and also why they seem to work so well? Thanks in advance.\n    submitted by    /u/Western-Image7125  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14y7ajc/dencoder_only_vs_encoderdecoder_vs_decoder_only/",
          "publishedOn": "2023-07-13T01:49:12.000Z",
          "wordCount": 2531,
          "title": "[D]Encoder only vs encoder-decoder vs decoder only",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14y42la/d_does_the_universityprogram_for_masters_for_mlai/",
          "author": null,
          "description": "I am curious about this. I have an undergrad in CS from a large public university from the states and 2 yoe as SWE from India. Not now, but few more years down the line when I have like 4-5 yoe as SWE, I would want to get into ML/AI roles. I don't want to waste any more time getting into a full-time program and waste 1-2 more years of my 20s (I am 25 already) so I was looking for online programs from a >= decent university in North America. The thing about me is that I learn best by self-studying. For me personally, university prestige doesn't do anything for me cos they all read from ppts and use same books. I took a summer at Cornell and ended up studying on my own. So, for me to spend so much money or take out another 1-2 years for a full-time masters doesn't make sense.\n I just want get a masters that is cheap in terms of cost, takes comparatively less time, PT so that I can work at the same time and do powerlifting and other hobbies and after completion can make me eligible for non-research ML/AI roles.\n In all, I am only doing this to show on my resume to HR that \"here is a guy who you won't need to spend too much time on analyzing cos he has done a masters/ some more additional math/stat courses and an institution has certified because they got paid to do so\".\n    submitted by    /u/ItsWasntMyFault  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14y42la/d_does_the_universityprogram_for_masters_for_mlai/",
          "publishedOn": "2023-07-12T23:18:29.000Z",
          "wordCount": 2683,
          "title": "[D] Does the university/program for masters for ML/AI roles matter?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14y1qun/d_ai_text_to_image_generation_project/",
          "author": null,
          "description": "I am a student of computer science. I have my final year project whose deadline is in a few week. I have to create AI text to image generator trained on a custom data set. The user should provide it a prompt and it should generate an image based on the prompt given to it. Infact it will be limited as it will be trained on a limited cutom data set. \n I have searched throughout the internet but I am unable to find any helpful material, code or any resource... And those that I found I am unable to understand them because of my less expertise. \n Is there anyone who could help me ?\n    submitted by    /u/mufeezahmad  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14y1qun/d_ai_text_to_image_generation_project/",
          "publishedOn": "2023-07-12T21:47:09.000Z",
          "wordCount": 2541,
          "title": "[D] AI Text to Image Generation Project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14y19lt/d_how_to_do_semi_supervised_learning_or_learning/",
          "author": null,
          "description": "Would appreciate some direction and pointers in this research area. Some possible options could be to use representational learning (probably using auto encoder, or InfoNCE/Contrastive loss). Is there any other good way to solve the problem of semi supervised learning where we have partial labels for the data and want our model to do well on unlabelled instances as well?\n    submitted by    /u/Rohit901  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14y19lt/d_how_to_do_semi_supervised_learning_or_learning/",
          "publishedOn": "2023-07-12T21:28:41.000Z",
          "wordCount": 2492,
          "title": "[D] How to do Semi Supervised Learning or Learning with no labels?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14y17ef/p_free_and_fast_llm_finetuning/",
          "author": null,
          "description": "Here's a colab notebook showing a new interface for LLM finetuning that I've been playing around with. Curious if folks here have feedback.\n Colab: https://colab.research.google.com/drive/1QMeGzR9FnhNJJFmcHtm9RhFP3vrwIkFn\n Docs: https://www.lamini.ai/blog/free-fast-and-furious-finetuning\n Github Repo: https://github.com/lamini-ai/lamini\n LLM fine tuning includes several advanced optimizations:\n Chinchilla recipe\n  \nsmaller models pretrained on data increases inference speed\n  \nInstruction fine tuning\n  \ntraining on a small high quality set of instructions unlocks the knowledge learned during foundation model training.\n  \nLatency constrained batching\n  \nachieves high utilization under load during token generation\n  \nContainerized SLURM\n  \ncombines fast scheduling of SLURM with LLM containers\n  \nMixed precision training\n  \nuses matrix operations for training\n  \nThere are so many low hanging fruits in LLM tuning, steering, and alignment. We are just getting started on this for enterprise and open source.\n For this reason I disagree with Sam Altman that the age of bigger models is over.\n We are still leaving orders of magnitude on the table, e.g. by not including optimizations like sparsity in these models.\n References for inspiration: [1] - https://arxiv.org/abs/2203.15556\n [2] - https://arxiv.org/abs/1910.10683\n [3] - https://www.usenix.org/system/files/osdi22-yu.pdf\n [4] - https://www.schedmd.com/\n [5] - https://arxiv.org/abs/1710.03740\n    submitted by    /u/gdiamos  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14y17ef/p_free_and_fast_llm_finetuning/",
          "publishedOn": "2023-07-12T21:26:14.000Z",
          "wordCount": 2601,
          "title": "[P] Free and Fast LLM Finetuning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14y14v2/wind_speed_prediction_appreciate_opinion_p/",
          "author": null,
          "description": "Thank you for reading this post.\n As a fancy kitesurfing I’m trying to predict the wind speed +12h. However, so far my succes is limited. How can I improve my prediction?\n Data So far, I’m using windspeed&direction, temperature and humidity 10 min interval for past 2 year for 6 locations.\n Features Day of the year and hour of the day. In addition I have aggregated the 10 min data to 1 hour and calculated the mean, min, max and std. All the data then was made into 18 lags.\n Models Linear regression, kneigbor an random Forrest. However, only random forest was slightly better then the liniear regression.\n What type of features and models would you recommend?\n Cheers\n    submitted by    /u/Any-Description3824  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14y14v2/wind_speed_prediction_appreciate_opinion_p/",
          "publishedOn": "2023-07-12T21:23:34.000Z",
          "wordCount": 2543,
          "title": "Wind speed prediction -appreciate opinion [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14y0apq/d_neurips_2023_reviews_release_time/",
          "author": null,
          "description": "Hey guys, I was wondering if y’all know when NeurIPS reviews for this year would be released? I know the response period starts on August 4, but do we get to see reviews before? Are they all released at once, or gradually as reviewers finish them? Thanks!\n    submitted by    /u/Icy_Background_4524  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14y0apq/d_neurips_2023_reviews_release_time/",
          "publishedOn": "2023-07-12T20:51:39.000Z",
          "wordCount": 2473,
          "title": "[D] NeurIPS 2023 reviews release time?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14xz3fw/r_detrex_a_strong_benchmark_for_detection/",
          "author": null,
          "description": "In October of last year, we open-sourced detrex as the first unified research platform focusing on the DETR-based algorithms. After several version updates and a significant number of experiments, we conducted a detailed benchmarking of the DETR-based models supported by detrex. \n Our paper has already been preprinted on ArXiv: https://arxiv.org/abs/2306.07265\n And our project repo is here: https://github.com/IDEA-Research/detrex\n The main characteristics of detrex can be summarized as follows: \n  \nFully utilizing LazyConfig as the configuration system, which is highly flexible, convenient, and easily modifiable.\n Reproducing results on mainstream algorithms surpassing the original implementations by more than 0.2AP - 1.1AP.\n Supports lots of SoTA backbone including EVA, InternImage, FocalNet, Swin-T, etc.\n Each algorithm is implemented as an independent project, ensuring no mutual interference between algorithms. Users can confidently implement their own ideas based on detrex.\n The training code is simple, consisting of approximately 200 lines, and highly customizable, allowing for easy modifications and hacks.\n Abundant documentation and tutorials are provided. \n Active response to issues and timely repository updates.\n  \n​\n Here's some results in our paper, more details can be found in paper:\n ​\n https://preview.redd.it/mdxs4xydblbb1.png?width=1007&format=png&auto=webp&s=a92acc36663365c84be8f86e74c521157fa26202\n https://preview.redd.it/f4c3zkvfblbb1.png?width=726&format=png&auto=webp&s=d684591dbd9e16610f3b9b483db1190fe87c7589\n https://preview.redd.it/zvcy3tajblbb1.png?width=878&format=png&auto=webp&s=03ce7eb07dbc249a03f8536ce9fad66dbd43841a\n ​\n    submitted by    /u/Technical-Vast1314  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14xz3fw/r_detrex_a_strong_benchmark_for_detection/",
          "publishedOn": "2023-07-12T20:05:32.000Z",
          "wordCount": 2606,
          "title": "[R] detrex: A Strong Benchmark for Detection Transformers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14xyvst/d_wondering_if_anyone_does_hpc_or_machine/",
          "author": null,
          "description": "With the increased productivity of vscode, does anyone do their dev work for machine learning on a windows server? I have also been getting problems running a jupyter server on ubuntu accessing my gpus. I believe it is easier on a windows server?\n    submitted by    /u/Studyr3ddit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14xyvst/d_wondering_if_anyone_does_hpc_or_machine/",
          "publishedOn": "2023-07-12T19:57:37.000Z",
          "wordCount": 2474,
          "title": "[D] Wondering if anyone does HPC or machine learning in Windows?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14xxpf4/d_how_vital_is_it_to_physically_attend_siggraph/",
          "author": null,
          "description": "Bluntly: Is the added benefit of attending SIGGRAPH(instead of merely indulging in the Virtual Access stuff) worth not hiking the Pyrenees with my girlfriend?\n I am a graduate student specializing in computer graphics and AI stuff. I'm very intent on finding some cool career at the intersection of technology and art so I signed up for SIGGRAPH back in April. I've been scouring information on generative art, NeRFs, and anything on the cutting edge of graphics for a while now so this is obviously the right place. I'd be happy enough indulging in all the talks and demos, but I'm especially interested in the networking aspect and finding a way to give myself a leg up on discovering a promising career. I have been feverishly working to develop my career since I've gotten to grad school, so this…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14xxpf4/d_how_vital_is_it_to_physically_attend_siggraph/",
          "publishedOn": "2023-07-12T19:11:43.000Z",
          "wordCount": 2895,
          "title": "[D] How vital is it to physically attend SIGGRAPH for my early career? Is it worth missing out on hiking the Pyrenees with my girlfriend?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14xxg6i/d_what_is_the_most_efficient_version_of_openai/",
          "author": null,
          "description": "Hi everyone, I know that there are some different versions of Whisper available in the open-source community (Whisper X, Whisper JAX, etc.), but I'm keeping updated with the best version of the model. Specifically, I'm trying to understand the best Whisper implementation for a task to transcribe a big batch of videos (~10k videos, ~30min long).\n I'd like to know your thoughts on this.\n    submitted by    /u/paulo_zip  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14xxg6i/d_what_is_the_most_efficient_version_of_openai/",
          "publishedOn": "2023-07-12T19:02:12.000Z",
          "wordCount": 2494,
          "title": "[D] What is the most efficient version of OpenAI Whisper?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14xx5s1/rif_you_have_used_lime_with_bert_help_me_out/",
          "author": null,
          "description": "if anyone has succesfully implemented a lime text explaintion with bert model please do share your code with me, i am trying to get lime to work for layout ML, bert and layoutML have similar architecture so i can find something new from your code to apply to mine\n    submitted by    /u/Affectionate_Win2460  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14xx5s1/rif_you_have_used_lime_with_bert_help_me_out/",
          "publishedOn": "2023-07-12T18:51:24.000Z",
          "wordCount": 2480,
          "title": "[R]If you have used Lime with bert ....help me out please",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14xww89/d_the_learning_corner_andrew_ng_free_ai_courses/",
          "author": null,
          "description": "📚 The Learning Corner (Andrew NG Free Ai Courses Pt. 1)\n This is a list of some of the best Ai Free courses by Andrew NG, we will release the second part of the list on our next newsletter installment (link)\n  \nGenerative AI with Large Language Models\n LangChain: Chat With Your Data\n LangChain for LLM Application Development\n How Diffusion Models Work\n  \n   submitted by    /u/Yavero  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14xww89/d_the_learning_corner_andrew_ng_free_ai_courses/",
          "publishedOn": "2023-07-12T18:41:20.000Z",
          "wordCount": 2493,
          "title": "[D] 📚 The Learning Corner (Andrew NG Free Ai Courses Pt. 1)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14xrm4c/d_whats_the_status_of_charttotext/",
          "author": null,
          "description": "I've been looking into solutions to transform charts into descriptions. There were great datasets introduced last year by this paper: https://arxiv.org/pdf/2203.06486.pdf\n But I haven't found many updates since, especially nothing super convincing. Do any of you know more?\n    submitted by    /u/Trick_Brain  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14xrm4c/d_whats_the_status_of_charttotext/",
          "publishedOn": "2023-07-12T15:24:35.000Z",
          "wordCount": 2463,
          "title": "[D] What's the status of chart-to-text",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14xrl95/d_what_are_some_interesting_research_that_combine/",
          "author": null,
          "description": "Most of the talk these days is about LLMs. I am curious about some daring AI projects that try to solve problems from the physical realm that humans won't be able to handle. I am talking about things beyond the human intelligence. For instance, trying to extract formulas for some physical actions, whose analytical formulas would be hard for humans to formulate but machine learning systems can better approximate. I don't know, maybe teaching small machines to fly with very few components, no hardcoded formulas and a ML system that continuously learns from trial and error.\n Sorry if this sounds dumb. I am just a software engineer with some interest in AI.\n    submitted by    /u/besabestin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14xrl95/d_what_are_some_interesting_research_that_combine/",
          "publishedOn": "2023-07-12T15:23:37.000Z",
          "wordCount": 2545,
          "title": "[D] What are some interesting research that combine AI with the physical world",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14xqfg4/d_lstm_multivariate_forecasting/",
          "author": null,
          "description": "Hi, I'm currently working on timeseries forecasting in pairs where one timeseries is suspected to cause the other timeseries. I also have the forecast of the causing timeseries and I use them to predict the other timeseries. Note that extrapolation capabilities are required since the forecasts of the first timeseries are not always in the range of the training data. \n I'm trying to use a simple LSTM model for that task and I tried two ways: training a model using past values of both timeseries and the current value of the first timeseries, and training using only the past and current values of the other timeseries.\n To my surprise, the forecasts using only the first timeseries values without the values of the timeseries we forecast are better. Does this make sense or am I doing 100% something wrong? When scaling the data do I need to scale values of each timeseries separately or scale them together?\n Also, what other ways you suggest for forecasting using another timeseries data and existing forecast?\n    submitted by    /u/soundgardener666  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14xqfg4/d_lstm_multivariate_forecasting/",
          "publishedOn": "2023-07-12T14:40:11.000Z",
          "wordCount": 2595,
          "title": "[D] LSTM multivariate forecasting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14xq8ip/mongodb_for_semantic_search_d/",
          "author": null,
          "description": "I'm quite new to semantic search and looking for an easy-to-use database tool; been looking into MongoDB's semantic search capabilities and following this tutorial. Is anyone using MongoDB for semantic search? If so, what did you think? If not, was there a reason why? Do you have any recommendations that might help me pick the right tool to get started with vector/semantic search?\n    submitted by    /u/Important-Sun-3562  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14xq8ip/mongodb_for_semantic_search_d/",
          "publishedOn": "2023-07-12T14:32:41.000Z",
          "wordCount": 2488,
          "title": "MongoDB for Semantic Search [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14xpwmr/r_corrfl_correlationbased_neural_network/",
          "author": null,
          "description": "An interesting article that tackles a new dimension in Federated Learning (FL) termed oblique federated learning. Link: https://ieeexplore.ieee.org/abstract/document/10132049\n    submitted by    /u/ias18  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14xpwmr/r_corrfl_correlationbased_neural_network/",
          "publishedOn": "2023-07-12T14:19:54.000Z",
          "wordCount": 2452,
          "title": "[R] CorrFL: Correlation-Based Neural Network Architecture for Unavailability Concerns in a Heterogeneous IoT Environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14xpaei/discussion_video_translation_task/",
          "author": null,
          "description": "I am working on a project related to Deep Learning translations.\n We have YouTube videos that we are looking to translate from English to Hindi. But we want the translated audio to sync with the mouth movements of the speaker.\n How to go about this task?\n    submitted by    /u/arhamm40182  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14xpaei/discussion_video_translation_task/",
          "publishedOn": "2023-07-12T13:56:04.000Z",
          "wordCount": 2470,
          "title": "[Discussion] Video Translation Task",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14xp8cy/d_what_do_you_do_with_imbalanced_target_data_in_a/",
          "author": null,
          "description": "Hey all, I’m a relatively new data scientist working on my first serious classification project. We’re predicting our target, which is made up of four categories, using the random forest classifier from sklearn. \n For the target, three categories have about 250 samples and the fourth has about 1200 samples. So far, I’ve just done a stratified shuffle split around the target. Is there anything else that I should make sure to do here to account for the imbalance? Currently, my model just predicts the most common category for almost all of the predictions, which gives it a decent score but makes me feel like this isn’t a useful model. Would appreciate any advice. Thanks!\n    submitted by    /u/NDVGuy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14xp8cy/d_what_do_you_do_with_imbalanced_target_data_in_a/",
          "publishedOn": "2023-07-12T13:53:42.000Z",
          "wordCount": 2549,
          "title": "[D] What do you do with imbalanced target data in a non-binary RF classification problem?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14xp0mc/p_weights_and_biases_approach_1_or_1/",
          "author": null,
          "description": "Hi, ive been desinging my own C code to make neural networks. Mainly for a project and to mess around. It works pretty well but i find that the weights and biases of the finished network are practically all 1, -1 or thereabouts. Is this normal? Again, the network works pretty well, it just seems a bit weird to me. Im using it to predict hand-written characters.\n Im using sigmoid as my activation function (tried RELU but didnt predict too well, maybe its because I train with a pretty small sample pool?). Weights and biases are randomly initialized with values between -1 and 1 and are capped during training so that they dont exceed -1 or 1. Im thinking this might be the issue. Problem is that if i dont cap them like this, they start to grow and grow the closer you are to the first hidden layer. The last hidden layer would have weights and biases between -1 and 1, but the others started to get bigger and bigger, so i ended up capping it like that to solve it. I believe this is common practice, but maybe the way im capping them is the problem (essentially if a weight or bias exceeds -1 or 1 after having been corrected, i equal it to -1 or 1 respectively).Im not sure what other info i should be providing, as far as i know its a pretty basic neural network, not doing anything too fancy.\n Thanks in advance.\n    submitted by    /u/Automatic-Syrup8490  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14xp0mc/p_weights_and_biases_approach_1_or_1/",
          "publishedOn": "2023-07-12T13:44:53.000Z",
          "wordCount": 2675,
          "title": "[P] Weights and biases approach -1 or 1",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14xozdc/r_crossentropy_is_all_you_need_or_is_it/",
          "author": null,
          "description": "Hey r/machinelearning! I recently wrote an article titled \"Cross-Entropy is All You Need… Or is It?\" where I discuss extensions to the Cross-Entropy loss to make it better when used in noisy production datasets. I've had great results on my end using this loss, so I wanted to share it with you all and get your opinions and insights!\n ➡️ Article link\n ➡️ Code & Colab link\n Summary: This article introduces the Smooth Generalized Cross-Entropy (SGCE) loss function, a way to address training classification models with noisy labels while still calibrating your model's confidence scores. The article demonstrates the application of SGCE on the task of Named Entity Recognition (NER), but it is applicable to many other tasks. The loss function combines the Cross-Entropy (CE) and Mean Absolute Error…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14xozdc/r_crossentropy_is_all_you_need_or_is_it/",
          "publishedOn": "2023-07-12T13:43:25.000Z",
          "wordCount": 2827,
          "title": "[R] Cross-Entropy is All You Need… Or is It?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14xottk/d_are_nlp_jobs_tied_to_ones_own_native_language/",
          "author": null,
          "description": "I'm considering doing a master's in NLP but concerned if NLP jobs are tied to one's own native language- for example if I'm german native I only get NLP jobs dealing with german language etc.\n Is this the case or can it be broader?\n And is it still a wise choice to get a master's in this field?\n    submitted by    /u/dauntbooksandyou  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14xottk/d_are_nlp_jobs_tied_to_ones_own_native_language/",
          "publishedOn": "2023-07-12T13:36:56.000Z",
          "wordCount": 2488,
          "title": "[D] Are NLP jobs tied to one's own native language?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14xi5zc/r_enhancing_continuous_time_series_modelling_with/",
          "author": null,
          "description": "https://arxiv.org/abs/2307.05126\n    submitted by    /u/cici118  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14xi5zc/r_enhancing_continuous_time_series_modelling_with/",
          "publishedOn": "2023-07-12T08:21:56.000Z",
          "wordCount": 2432,
          "title": "[R] Enhancing Continuous Time Series Modelling with a Latent ODE-LSTM Approach",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14xf9xb/p_langchainlite_alternative/",
          "author": null,
          "description": "Although langchain is an impressive library, I tend to find it is…\n  \na little unintuitive, at least for non-trivial examples or examples that don’t have a predefined chains/templates\n related, it's overly prescriptive; and the various levels of abstraction don't resonate with me\n related, can be difficult to debug or understand what’s happening in intermediate steps of the chain or what’s it’s actually sending OpenAI\n  \nSo, I built a “langchain-lite” package called llm-workflow\n https://github.com/shane-kercheval/llm-workflow\n The value proposition is basically:\n  \neasily build up a sequence of tasks (e.g. prompt-template -> chat) called a workflow, where the output of one task serves as the input to the next task in the workflow\n track history; understand what's happening in each of the …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14xf9xb/p_langchainlite_alternative/",
          "publishedOn": "2023-07-12T05:41:00.000Z",
          "wordCount": 2866,
          "title": "[P] langchain-lite alternative",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14x8p0m/p_haven_deploy_open_source_llms_on_your_own_cloud/",
          "author": null,
          "description": "Open source LLMs are a great privacy-preserving alternative to using the ChatGPT API, but deploying them in production is still really hard - especially for people without ML experience and knowledge about ML infrastructure. With Haven, we make it possible to deploy LLMs with just a few lines of code!\n GitHub: https://github.com/havenhq/haven\n Website: https://haven.run/\n Colab Demo: https://colab.research.google.com/drive/1eGGSisS9Du5-_KcaejY5y9vk9v7EIfba?authuser=2#scrollTo=YYECIKqAGId8\n ​\n Haven’s main component is the manager, which comes as a container image that can be deployed in your GCP environment. The manager is your central entrypoint and can be used to spin up LLMs on GPUs with just one line of code:\n from havenpy import Haven client = Haven(\"<ip-adress-of-your-vm>:50051\", \"<your-bearer-token>\") worker_id = client.create_inference_worker( model_name=\"@huggingface/mosaicml/mpt-7b-chat\", quantization=\"float16\", gpu_type=\"T4\", gpu_count=2) \n ​\n After spinning up inference workers, you can query them with both a chat completion and a normal completion endpoint, similar to the OpenAI API.\n res = client.chat_completion(worker_id, messages=[{ \"content\": \"Who would win in a cagefight: Mark Zuckerberg or Elon Musk?\", \"role\": \"USER\" }], stream=True, temperature=0.8) for r in res: print(r.text, flush=True, end=\"\") \n ​\n Our inference server is powered by vllm to provide the fastest inference possible. In the next weeks, we plan to add support for more cloud providers as well as fine-tuning with a single line of code. We'd love to hear your feedback! \n    submitted by    /u/jger227  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14x8p0m/p_haven_deploy_open_source_llms_on_your_own_cloud/",
          "publishedOn": "2023-07-12T00:32:52.000Z",
          "wordCount": 2626,
          "title": "[P] Haven: Deploy Open Source LLMs on Your Own Cloud",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14x5btv/d_regression_for_everyone/",
          "author": null,
          "description": "Check my article on Regression. I'd love to hear your thoughts ☺️ https://medium.com/@sandundayananda/regression-fef89ad7c68f\n    submitted by    /u/sandun-dayananda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14x5btv/d_regression_for_everyone/",
          "publishedOn": "2023-07-11T22:13:38.000Z",
          "wordCount": 2425,
          "title": "[D] Regression for Everyone",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14x3g56/d_masters_of_aimachine_learning/",
          "author": null,
          "description": "I have a Bachelor's in Electrical Engineering, valedictorian, 4.00 out of 4.00 CGPA. IELTS 7.5 and have been working in the AI center in a research company for 3 months now. I have 2 papers published, one of them is Falcon B40. My employer asked me to pursue a master's degree in AI or machine learning. The tuition fees don't matter (Fully sponsored)\n The degree has to be certified as (Msc of Artificial intelligence) OR (Msc of Machine Learning) Not (Msc of Computer science) . University should be QS World Rank 100 to 200\n I applied to: \n 1- Imperial College London 2- Monash Univerisity 3- Univerity Technology Sydney\n I need a fourth option? I prefer a university that provides a rigid background of computer science since I have an electrical engineering bachelors. Also, I must start maximum by spring 2024.. \n Thank you ❤️\n    submitted by    /u/Maithah_x  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14x3g56/d_masters_of_aimachine_learning/",
          "publishedOn": "2023-07-11T21:03:28.000Z",
          "wordCount": 2556,
          "title": "[D] Masters of AI/Machine Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14x38t0/pbenchmarking_nvidia_rapids_vs_pandas_join_our/",
          "author": null,
          "description": "We are excited to announce a benchmarking experiment comparing the performance of NVIDIA RAPIDS and Pandas, two powerful data manipulation libraries, on a large Kubernetes-based cluster. Our cluster consists of thousands of A4000 GPUs, providing an excellent opportunity to evaluate these libraries for various workloads that involve data scrubbing. If you're interested in participating, we are offering the necessary compute resources, and you can even define your own datasets!\n What is NVIDIA RAPIDS? NVIDIA RAPIDS is a suite of open-source software libraries and APIs that accelerate data science and analytics workflows on GPUs. It aims to provide GPU-accelerated alternatives to popular data science tools, including Pandas. RAPIDS leverages the power of GPUs to speed up data processing, maki…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14x38t0/pbenchmarking_nvidia_rapids_vs_pandas_join_our/",
          "publishedOn": "2023-07-11T20:56:02.000Z",
          "wordCount": 2817,
          "title": "[P]Benchmarking NVIDIA RAPIDS vs. Pandas: Join our Experiment with Thousands of GPUs!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14x384n/r_semanticsam_segment_and_recognize_anything_at/",
          "author": null,
          "description": "We introduce Semantic-SAM, a universal image segmentation model to enable segment and recognize anything at any desired granularity.\n 🔥code & demo link: https://github.com/UX-Decoder/Semantic-SAM\n 🔥paper link: https://arxiv.org/pdf/2307.04767.pdf\n 🔥Our model offers the following attributes from instance to part level:\n  \nGranularity Abundance. Our model can produce all possible segmentation granularities for a user click with high quality, which enables more **controllable** and **user-friendly** interactive segmentation.\n Semantic Awareness. We jointly train SA-1B with semantically labeled datasets to learn the semantics in both object-level and part-level.\n High Quality. We base on the DETR-based model to implement both generic and interactive segmentation, and validate that SA-1B hel…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14x384n/r_semanticsam_segment_and_recognize_anything_at/",
          "publishedOn": "2023-07-11T20:55:21.000Z",
          "wordCount": 2745,
          "title": "[R] Semantic-SAM: Segment and Recognize Anything at Any Granularity",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14x1ijv/d_confusion_over_amd_gpu_ai_benchmarking/",
          "author": null,
          "description": "I'm using an ai benchmarker from this website, https://ai-benchmark.com/ranking_deeplearning.html. It was the only ai benchmarker I could find that I could understand. For some reason the results are in AMD's favor. I always thought ai wasn't good enough on AMD, but it's beating out the 4090! Am I using this benchmark wrong or has AMD really gotten good recently?\n Also if anyone knows another benchmark I could use, that would be wonderful.\n ​\n ​\n https://preview.redd.it/c779j1pb4ebb1.png?width=1565&format=png&auto=webp&s=d62f003587c73443cc83acf98f14a69c4ee14d2c\n    submitted by    /u/SociallyApparent  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14x1ijv/d_confusion_over_amd_gpu_ai_benchmarking/",
          "publishedOn": "2023-07-11T19:52:01.000Z",
          "wordCount": 2487,
          "title": "[D] Confusion over AMD GPU Ai benchmarking",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14x02z8/p_reward_prioritization/",
          "author": null,
          "description": "Hi all! I will preface by saying I am very new to machine learning. I understand the fundamentals but have little practice in implementation.\n I am trying to create an AI to play a game that I have re-created in Python by using TensorFlow/Keras. The game is similar to Tetris, and the goal is for the user to survive for as long as possible and the user can score more points by making more complex moves.\n In my current situation, the game has been entirely coded and converted to a useable format for the AI (I used OpenAI’s Gymnasium (the open-source fork)). Over the last two days I have created the Neural Net model (5 Dense layers with 6 output options) and have been tweaking variables with little noticeable difference in the AI’s abilities.\n While I certainly need help in several areas and am open to any and all recommendations, I currently feel that my issues lie in the rewards. Currently the AI plays 5000 rounds, then keeps the best 10% of all games based on the reward score. Currently the longer it survives, the higher the reward. However, I also want the model to prioritize score similarly to survival time.\n To compare this to Tetris, the player could survive for 1 hour only scoring 1-liners, or 5 minutes scoring 90% Tetris’s and end up with a higher ‘score’ than the one that survives longer. I am looking for a compromise between these two extremes that will allow me to select the best 10% of all the games played.\n I know that I may not have explained this problem very well, but I am open to all suggestions, and all comments are appreciated.\n Thanks!\n    submitted by    /u/TCPisJustFancyUDP  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14x02z8/p_reward_prioritization/",
          "publishedOn": "2023-07-11T18:58:41.000Z",
          "wordCount": 2695,
          "title": "[P] Reward Prioritization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14wxgk2/d_problems_with_lazy_config_detectron2_mvitv2/",
          "author": null,
          "description": "Hey. So, I want to use a config file from a detectron2 project which is undere MViTv2 in my custom dataset which is \"my_dataset_train\" (datacatalog format)\n I want to use this config file https://github.com/facebookresearch/detectron2/blob/main/projects/MViTv2/configs/mask_rcnn_mvitv2_t_3x.py like the beneath typical way I use a yaml config file. But giving so many errors one after another that, I even failed to count at this point. \n ​\n I have to use this config file with the dataloader which is in https://github.com/facebookresearch/detectron2/blob/main/projects/MViTv2/configs/common/coco_loader.py. I figured that i can use cfg.dataloader.train.dataset.names = \"my_dataset_train\" for this. \n ​\n cfg = LazyConfig.load(\"detectron2/projects/MViTv2/configs/mask_rcnn_mvitv2_t_3x.py\")\n cfg.dataloader.train.dataset.names = \"my_dataset_train\"\n train = model_zoo.get_config(\"common/train.py\").train\n cfg.train.amp.enabled = True\n cfg.train.ddp.fp16_compression = True\n cfg.lr_multiplier = L(WarmupParamScheduler)(\n scheduler=L(MultiStepParamScheduler)(\n values=[1.0, 0.1, 0.01],\n milestones=[52500, 62500, 67500],\n ),\n warmup_length=250 / train.max_iter,\n warmup_factor=0.001,\n )\n # cfg.train.init_checkpoint = \"detectron2://ImageNetPretrained/mvitv2/MViTv2_T_in1k.pyth\"\n ​\n cfg.dataloader.train.total_batch_size = 1\n cfg.train.max_iter = 200\n cfg.optimizer = model_zoo.get_config(\"common/optim.py\").AdamW\n cfg.optimizer.lr = 1.6e-4\n dataset = instantiate(cfg.dataloader.train)\n # optimizer = instantiate(cfg.optimizer)\n # optimizer = model_zoo.get_config(\"common/optim.py\").A\n ​\n # trainer = AMPTrainer(model, dataset, optimizer)\n trainer = DefaultTrainer(cfg)\n trainer.train()\n # FileLink(str(OUTPUT_MODEL))\n ​\n But typical trainer.train(start_iter,cfg.max_iter) is not working here? How can run this without shell command? Thanks everyone\n    submitted by    /u/Ok-Reflection-4049  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14wxgk2/d_problems_with_lazy_config_detectron2_mvitv2/",
          "publishedOn": "2023-07-11T17:20:36.000Z",
          "wordCount": 2588,
          "title": "\"[D]\" Problems with Lazy Config detectron2 (MViTv2)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14wxda9/d_keras_30_announcement_keras_for_tensorflow_jax/",
          "author": null,
          "description": "Keras just announced a preview version of Keras 3.0. It's a full rewrite of the Keras codebase that rebases it on top of a modular backend architecture. It makes it possible to run Keras workflows on top of arbitrary frameworks — starting with TensorFlow, JAX, and PyTorch.\n https://keras.io/keras_core/announcement/\n    submitted by    /u/codemaker1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14wxda9/d_keras_30_announcement_keras_for_tensorflow_jax/",
          "publishedOn": "2023-07-11T17:17:12.000Z",
          "wordCount": 2466,
          "title": "[D] Keras 3.0 Announcement: Keras for TensorFlow, JAX, and PyTorch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14ww2ag/backpropaagtion_with_crossentropy_and_softmax_how/",
          "author": null,
          "description": "Let Zs be the input of the output layer (for example, Z1 is the input of the first neuron in the output layer), Os be the output of the output layer (which are actually the results of applying the softmax activation function to Zs, for example, O1 = softmax(Z1)), and Ys be the target values (which are 0 or 1 because in this example we are dealing with classification problems and using one-hot encoding). E is the sum of the neuron's loss using the CrossEntropy loss function.\n Let's say our neural network has 2 neurons, and Y1 = 1 (so Y2 = 0). What is the derivative of E with respect to Z1 and the derivative of E with respect to Z2? After calculations, I came to the conclusion that the value of all derivative of E with respects to Zs(Z1 and Z2) should be equal, becasue they are all equal to O1-1 ( since Y1 = 1 as i said), so am i right or wrong?(and why)\n    submitted by    /u/qaz_zaqi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14ww2ag/backpropaagtion_with_crossentropy_and_softmax_how/",
          "publishedOn": "2023-07-11T16:28:38.000Z",
          "wordCount": 2583,
          "title": "Backpropaagtion with Cross-Entropy and Softmax, HOW? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14wv7p1/generating_a_step_by_step_painting_d/",
          "author": null,
          "description": "I am thinking about this from a long time. Is there anyway that we can generate each step of painting from an image input. If I give an image as input, it should be able to give me step by step instructions on how to paint. \n I like painting but I got bored of You\n    submitted by    /u/dosa-palli-chutney  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14wv7p1/generating_a_step_by_step_painting_d/",
          "publishedOn": "2023-07-11T15:57:23.000Z",
          "wordCount": 2470,
          "title": "Generating a step by step painting [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14wuk5d/d_compared_to_paying_a_monthly_subscription_to/",
          "author": null,
          "description": "Pretty much as the title says. I'm wondering whether it would be cheaper paying for PdfGPT, Claude2 and GPT-4 access separately, or Poe.com as a bundle?\n    submitted by    /u/RTSBasebuilder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14wuk5d/d_compared_to_paying_a_monthly_subscription_to/",
          "publishedOn": "2023-07-11T15:33:05.000Z",
          "wordCount": 2460,
          "title": "[D] Compared to paying a monthly subscription to ChatGPT, or per token for long-form content on the OpenAI platform, Is Poe.com's annual payment worth the money?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14wspb0/r_why_was_tacotron_trained_on_1000h_of_data/",
          "author": null,
          "description": "Tacotron TTS models (e.g. Tacotron 2 and Parallel Tacotron 2) were trained on 25h and 405h of speech data, respectively. By comparison, more recent TTS systems are trained on >50,000h of speech data. Why were Tacotron models trained on such a relatively small volume of data? Was it simply a matter of compute resource, or is there something in the Tacotron architecture/training set-up that explains the relatively small training size?\n    submitted by    /u/Upstairs_Buy_6243  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14wspb0/r_why_was_tacotron_trained_on_1000h_of_data/",
          "publishedOn": "2023-07-11T14:18:44.000Z",
          "wordCount": 2487,
          "title": "[R] Why was Tacotron trained on <1000h of data?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/14wrmep/discussion_aws_sagemaker_issue/",
          "author": null,
          "description": "Hi everyone,\n I have data that included these columns: customer_id,product_id,product_title,product_category,star_rating\n Then I used these functions, codes with descriptions below, and AWS Sagemaker config for creating model training\n I tried to write a function for predicting 5 best products for 1 customer using this model using the deployed endpoint.\n https://preview.redd.it/i3b2pm099cbb1.jpg?width=966&format=pjpg&auto=webp&s=1aa12ca864e500c1d0bc0e823e8c9e88c0a36316\n https://preview.redd.it/nolhkl299cbb1.jpg?width=1002&format=pjpg&auto=webp&s=8d49a232620361076d802fd20ee124fa8a7c2feb\n https://preview.redd.it/ge5ggs299cbb1.jpg?width=895&format=pjpg&auto=webp&s=c58b80ff6a2af85546563d0a257da4cc3540da9f\n https://preview.redd.it/slbqok299cbb1.jpg?width=1028&format=pjpg&auto=webp&s=5ee8c5733dde42f1eb7d113c5eb0e0a6d3ba739c\n https://preview.redd.it/zu3nun099cbb1.jpg?width=1018&format=pjpg&auto=webp&s=86a29a222ab05ef4d4ed5c4eaf6fc321e1cfe194\n https://preview.redd.it/bk9qif299cbb1.jpg?width=826&format=pjpg&auto=webp&s=80169c891de0ff3dd2e98fb5be3aa9eaa29b35c6\n https://preview.redd.it/n1yigg299cbb1.jpg?width=898&format=pjpg&auto=webp&s=5a3f09983f9cddda1e0772ce473271a84790055d\n  \nNevertheless, I got a strange issue and cannot resolve it(\n SSLError: SSL validation failed for \n https:// runtime.sagemaker.us-east-1.amazonaws.com/endpoints/ factorization-machines-2023-07-10-12-13-54-256/invocations EOF occurred in violation of protocol (_ssl.c:2396)).\n  \nCould someone please help me explain this, give me a solution, or help me solve it? \n    submitted by    /u/Hung_98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/14wrmep/discussion_aws_sagemaker_issue/",
          "publishedOn": "2023-07-11T13:36:09.000Z",
          "wordCount": 2500,
          "title": "[Discussion] AWS Sagemaker Issue",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "ML in Production",
      "feedUrl": "https://mlinproduction.com/feed",
      "siteUrl": "https://mlinproduction.com",
      "articles": []
    },
    {
      "title": "Jay Alammar",
      "feedUrl": "https://jalammar.github.io/feed.xml",
      "siteUrl": "http://jalammar.github.io/",
      "articles": []
    },
    {
      "title": "Distill",
      "feedUrl": "https://distill.pub/rss.xml",
      "siteUrl": "https://distill.pub",
      "articles": []
    },
    {
      "title": "inFERENCe",
      "feedUrl": "https://www.inference.vc/rss",
      "siteUrl": "https://www.inference.vc/",
      "articles": []
    },
    {
      "title": "AI Trends",
      "feedUrl": "https://www.aitrends.com/feed",
      "siteUrl": "https://www.aitrends.com/",
      "articles": []
    },
    {
      "title": "AI Weirdness",
      "feedUrl": "https://aiweirdness.com/rss",
      "siteUrl": "https://www.aiweirdness.com/",
      "articles": [
        {
          "id": "64acbb837dbeb40001d3c391",
          "author": "Janelle Shane",
          "description": "A reader wrote in a while ago with a suggestion: they were about to have a baby and wondered if I could use AI to come up with some new ideas for baby onesies. I can't find the letter any more, and I don't remember how",
          "link": "https://www.aiweirdness.com/baby-onesie-designs/",
          "publishedOn": "2023-08-04T14:30:06.000Z",
          "wordCount": 1814,
          "title": "Baby onesie designs",
          "imageUrl": "https://www.aiweirdness.com/content/images/2023/08/Screen-Shot-2023-08-01-at-7.26.18-PM.png"
        },
        {
          "id": "64c9abbc0b1e230001d585f2",
          "author": "Janelle Shane",
          "description": "AI Weirdness: the strange side of machine learning",
          "link": "https://www.aiweirdness.com/bonus-more-baby-onesie-ideas/",
          "publishedOn": "2023-08-04T14:29:39.000Z",
          "wordCount": 690,
          "title": "Bonus: more baby onesie ideas",
          "imageUrl": "https://www.aiweirdness.com/content/images/2021/03/neural_net_box_default_square-01-2.png"
        }
      ]
    },
    {
      "title": "The Berkeley Artificial Intelligence Research Blog",
      "feedUrl": "https://bair.berkeley.edu/blog/feed.xml",
      "siteUrl": "http://bair.berkeley.edu/blog/",
      "articles": [
        {
          "id": "http://bair.berkeley.edu/blog/2023/07/14/ddpo/",
          "author": null,
          "description": "function reveal() {\n        const replay = document.querySelector('.ddpo-replay');\n        replay.style.display = 'flex';\n    }\n\n    window.onload = () => {\n        const replay = document.querySelector('.ddpo-replay');\n\n        replay.addEventListener('click', () => {\n            const video = document.querySelector('.ddpo-video');\n            video.currentTime = 0;\n            video.play();\n            replay.style.display = 'none';\n        });\n    }\n\n\nTraining Diffusion Models with Reinforcement Learning\n\n\n    \n        \n    \n    \nreplay\nDiffusion models have recently emerged as the de facto standard for generating complex, high-dimensional outputs. You may know them for their ability to produce stunning AI art and hyper-realistic synthetic images, but they have also found success in oth…",
          "link": "http://bair.berkeley.edu/blog/2023/07/14/ddpo/",
          "publishedOn": "2023-07-14T09:00:00.000Z",
          "wordCount": 2007,
          "title": "Training Diffusion Models with <br> Reinforcement Learning",
          "imageUrl": "http://bair.berkeley.edu/blog/assets/ddpo/teaser.jpg"
        }
      ]
    },
    {
      "title": "Becoming Human: Artificial Intelligence Magazine - Medium",
      "feedUrl": "https://becominghuman.ai/feed",
      "siteUrl": "https://becominghuman.ai?source=rss----5e5bef33608a---4",
      "articles": []
    },
    {
      "title": "MIT News - Artificial intelligence",
      "feedUrl": "http://news.mit.edu/rss/topic/artificial-intelligence2",
      "siteUrl": "https://news.mit.edu/rss/topic/artificial-intelligence2",
      "articles": [
        {
          "id": "https://news.mit.edu/2023/ai-model-can-help-determine-where-patients-cancer-arose-0807",
          "author": "Anne Trafton | MIT News",
          "description": "Predictions from the OncoNPC model could enable doctors to choose targeted treatments for difficult-to-treat tumors.",
          "link": "https://news.mit.edu/2023/ai-model-can-help-determine-where-patients-cancer-arose-0807",
          "publishedOn": "2023-08-07T15:00:00.000Z",
          "wordCount": 2798,
          "title": "AI model can help determine where a patient’s cancer arose",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202308/MIT-Unknown-Cancer-01.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/using-ai-protect-against-ai-image-manipulation-0731",
          "author": "Rachel Gordon | MIT CSAIL",
          "description": "“PhotoGuard,” developed by MIT CSAIL researchers, prevents unauthorized image manipulation, safeguarding authenticity in the era of advanced generative models.",
          "link": "https://news.mit.edu/2023/using-ai-protect-against-ai-image-manipulation-0731",
          "publishedOn": "2023-07-31T04:00:00.000Z",
          "wordCount": 3036,
          "title": "Using AI to protect against AI image manipulation",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202307/malicious-ai-image-cov.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/simpler-method-learning-control-robot-0726",
          "author": "Adam Zewe | MIT News Office",
          "description": "Researchers develop a machine-learning technique that can efficiently learn to control a robot, leading to better performance with fewer data.",
          "link": "https://news.mit.edu/2023/simpler-method-learning-control-robot-0726",
          "publishedOn": "2023-07-26T04:00:00.000Z",
          "wordCount": 3005,
          "title": "A simpler method for learning to control a robot",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202307/MIT-LearningControl-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/new-dataset-arctic-images-will-spur-artificial-intelligence-research-0724",
          "author": "Kylie Foy | MIT Lincoln Laboratory",
          "description": "The dataset, being collected as part of a US Coast Guard science mission, will be released open source to help advance naval mission planning and climate change studies.",
          "link": "https://news.mit.edu/2023/new-dataset-arctic-images-will-spur-artificial-intelligence-research-0724",
          "publishedOn": "2023-07-24T18:50:00.000Z",
          "wordCount": 2556,
          "title": "A new dataset of Arctic images will spur artificial intelligence research",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202307/Healy-Icebreaker_1.JPG"
        },
        {
          "id": "https://news.mit.edu/2023/faster-way-teach-robot-technique-0718",
          "author": "Adam Zewe | MIT News Office",
          "description": "A new technique helps a nontechnical user understand why a robot failed, and then fine-tune it with minimal effort to perform a task effectively.",
          "link": "https://news.mit.edu/2023/faster-way-teach-robot-technique-0718",
          "publishedOn": "2023-07-18T04:00:00.000Z",
          "wordCount": 2794,
          "title": "A faster way to teach a robot",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202307/MIT-HumanLoop-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/understanding-viral-justice-ruha-benjamin-0717",
          "author": "Brigham Fay | MIT Libraries",
          "description": "Author and African American studies scholar Ruha Benjamin urges MIT Libraries staff to “re-imagine the default settings” of technology for a more just future.",
          "link": "https://news.mit.edu/2023/understanding-viral-justice-ruha-benjamin-0717",
          "publishedOn": "2023-07-17T20:10:00.000Z",
          "wordCount": 2131,
          "title": "Understanding viral justice",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202307/ruha-benjamin.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/armando-solar-lezama-named-inaugural-distinguished-college-computing-professor-0717",
          "author": "MIT Schwarzman College of Computing",
          "description": "EECS professor appointed to new professorship in the MIT Schwarzman College of Computing.",
          "link": "https://news.mit.edu/2023/armando-solar-lezama-named-inaugural-distinguished-college-computing-professor-0717",
          "publishedOn": "2023-07-17T19:50:00.000Z",
          "wordCount": 1837,
          "title": "Armando Solar-Lezama named inaugural Distinguished College of Computing Professor",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202307/Armando-Solar-Lezama.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/ai-helps-household-robots-cut-planning-time-half-0714",
          "author": "Rachel Gordon | MIT CSAIL",
          "description": "PIGINet leverages machine learning to streamline and enhance household robots' task and motion planning, by assessing and filtering feasible solutions in complex environments.",
          "link": "https://news.mit.edu/2023/ai-helps-household-robots-cut-planning-time-half-0714",
          "publishedOn": "2023-07-14T15:00:00.000Z",
          "wordCount": 2655,
          "title": "AI helps household robots cut planning time in half",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202307/PigiNet-models.png"
        },
        {
          "id": "https://news.mit.edu/2023/study-finds-chatgpt-boosts-worker-productivity-writing-0714",
          "author": "Zach Winn | MIT News Office",
          "description": "A new report by MIT researchers highlights the potential of generative AI to help workers with certain writing assignments.",
          "link": "https://news.mit.edu/2023/study-finds-chatgpt-boosts-worker-productivity-writing-0714",
          "publishedOn": "2023-07-14T14:30:00.000Z",
          "wordCount": 2666,
          "title": "Study finds ChatGPT boosts worker productivity for some writing tasks",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202307/MIT-AIproductivity-01.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/new-way-look-data-privacy-0714",
          "author": "Adam Zewe | MIT News Office",
          "description": "Researchers create a privacy technique that protects sensitive data while maintaining a machine-learning model’s performance.",
          "link": "https://news.mit.edu/2023/new-way-look-data-privacy-0714",
          "publishedOn": "2023-07-14T04:00:00.000Z",
          "wordCount": 2923,
          "title": "A new way to look at data privacy",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202307/MIT-pac-privacy-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/making-sense-all-things-data-0713",
          "author": "Steve Calechman | MIT Industrial Liaison Program",
          "description": "Abel Sanchez helps industries and executives shift their operations in order to make sense of their data and use it to help their bottom lines.",
          "link": "https://news.mit.edu/2023/making-sense-all-things-data-0713",
          "publishedOn": "2023-07-13T13:00:00.000Z",
          "wordCount": 2526,
          "title": "Making sense of all things data",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202306/Abel-Sanchez.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/how-ai-tocracy-emerges-0713",
          "author": "Peter Dizikes | MIT News Office",
          "description": "In China, the use of AI-driven facial recognition helps the regime repress dissent while enhancing the technology, researchers report.",
          "link": "https://news.mit.edu/2023/how-ai-tocracy-emerges-0713",
          "publishedOn": "2023-07-13T04:00:00.000Z",
          "wordCount": 2691,
          "title": "How an “AI-tocracy” emerges",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202307/MIT-AI-tocracy-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/generative-ai-imagines-new-protein-structures-0712",
          "author": "Rachel Gordon | MIT CSAIL",
          "description": "MIT researchers develop \"FrameDiff,\" a computational tool that uses generative AI to craft new protein structures, with the aim of accelerating drug development and improving gene therapy.",
          "link": "https://news.mit.edu/2023/generative-ai-imagines-new-protein-structures-0712",
          "publishedOn": "2023-07-12T18:30:00.000Z",
          "wordCount": 2656,
          "title": "Generative AI imagines new protein structures",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202307/MIT-News-FrameDiff_0.png"
        }
      ]
    },
    {
      "title": "NVIDIA Blog",
      "feedUrl": "http://feeds.feedburner.com/nvidiablog",
      "siteUrl": "https://blogs.nvidia.com/",
      "articles": [
        {
          "id": "https://blogs.nvidia.com/?p=65973",
          "author": "Brian Caulfield",
          "description": "As generative AI continues to sweep an increasingly digital, hyperconnected world, NVIDIA founder and CEO Jensen Huang made a thunderous return to SIGGRAPH, the world’s premier computer graphics conference. “The generative AI era is upon us, the iPhone moment if you will,” Huang told an audience of thousands Tuesday during an in-person special address in Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/08/siggraph-2023-special-address/",
          "publishedOn": "2023-08-08T17:12:28.000Z",
          "wordCount": 2717,
          "title": "SIGGRAPH Special Address: NVIDIA CEO Brings Generative AI to LA Show",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/NVIDIA-Jensen-Huang-SIGGRAPH-2023.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65735",
          "author": "Chintan Patel",
          "description": "Machine learning helped Waseem Alshikh plow through textbooks in college. Now he’s putting generative AI to work, creating content for hundreds of companies. Born and raised in Syria, Alshikh spoke no English, but he was fluent in software, a talent that served him well when he arrived at college in Lebanon. “The first day they Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/08/writer-nemo-generative-ai/",
          "publishedOn": "2023-08-08T16:34:53.000Z",
          "wordCount": 1915,
          "title": "Startup Pens Generative AI Success Story With NVIDIA NeMo",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/KV-for-Writer-x1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65949",
          "author": "Greg Jones",
          "description": "Organizations across industries are using extended reality (XR) to redesign workflows and boost productivity, whether for immersive training or collaborative design reviews. With the growing use of all-in-one (AIO) headsets, more teams have adopted and integrated XR. While easing XR use, AIO headsets have modest compute and rendering power that can limit the graphics quality Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/08/cloudxr-suite-simplifies-enterprise-streaming/",
          "publishedOn": "2023-08-08T16:17:47.000Z",
          "wordCount": 1889,
          "title": "NVIDIA Makes Extended-Reality Streaming More Scalable, Customizable for Enterprises and Developers",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/proviz-corp-blog-cloudxr-sigg23-1280x680-1.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65945",
          "author": "Rick Champagne",
          "description": "Professionals, teams, creators and others can tap into the power of AI to create high-quality audio and video effects — even using standard microphones and webcams — with the help of NVIDIA Maxine. The suite of GPU-accelerated software development kits and cloud-native microservices lets users deploy AI features that enhance audio, video and augmented-reality effects Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/08/maxine-3d-video-communications/",
          "publishedOn": "2023-08-08T16:15:26.000Z",
          "wordCount": 2379,
          "title": "Extended Cut: NVIDIA Expands Maxine for Video Editing, Showcases 3D Virtual Conferencing Research",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/Maxine-Copy.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65967",
          "author": "Gerardo Delgado",
          "description": "AI and accelerated computing were in the spotlight at SIGGRAPH — the world’s largest gathering of computer graphics experts — as NVIDIA founder and CEO Jensen Huang announced during his keynote address updates to NVIDIA Omniverse, a platform for building and connecting 3D tools and applications, as well as acceleration for Universal Scene Description (known as OpenUSD), the open and extensible ecosystem for 3D worlds.",
          "link": "https://blogs.nvidia.com/blog/2023/08/08/siggraph-studio-rtx-omniverse-openusd/",
          "publishedOn": "2023-08-08T16:00:37.000Z",
          "wordCount": 2944,
          "title": "Content Creation ‘In the NVIDIA Studio’ Gets Boost From New Professional GPUs, AI Tools, Omniverse and OpenUSD Collaboration Features",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/siggraph-nv-blog-header-preview-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65994",
          "author": "Jason Paul",
          "description": "Picture this: Creators can quickly create and customize 3D scene backgrounds with the help of generative AI, thanks to cutting-edge tools from Shutterstock. The visual-content provider is building services using NVIDIA Picasso — a cloud-based foundry for developing generative AI models for visual design. The work incorporates Picasso’s latest feature — announced today during NVIDIA Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/08/shutterstock-generative-ai-picasso-360-hdri__trashed/",
          "publishedOn": "2023-08-08T16:00:14.000Z",
          "wordCount": 1751,
          "title": "Shutterstock Brings Generative AI to 3D Scene Backgrounds With NVIDIA Picasso",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/picasso-siggraph-360-hdri.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65932",
          "author": "Isha Salian",
          "description": "NVIDIA researchers are taking the stage at SIGGRAPH, the world’s largest computer graphics conference, to demonstrate a generative AI workflow that helps artists rapidly create and iterate on materials for 3D scenes. The research demo, which will be presented today at the show’s Real-Time Live event, showcases how artists can use text or image prompts Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/08/siggraph-research-generative-ai-materials-3d-scenes/",
          "publishedOn": "2023-08-08T16:00:05.000Z",
          "wordCount": 1847,
          "title": "A Textured Approach: NVIDIA Research Shows How Gen AI Helps Create and Edit Photorealistic Materials",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2018/05/nvidia-logo.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65941",
          "author": "James Mills",
          "description": "DENZA, the luxury EV brand joint venture between BYD and Mercedes-Benz, has collaborated with marketing and communications giant WPP and NVIDIA Omniverse Cloud to build and deploy its next generation of car configurators, NVIDIA founder and CEO Jensen Huang announced at SIGGRAPH. WPP is using Omniverse Cloud — a platform for developing, deploying and managing Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/08/denza-wpp-car-configurators-nvidia-omniverse-cloud/",
          "publishedOn": "2023-08-08T15:51:13.000Z",
          "wordCount": 1557,
          "title": "DENZA Collaborates With WPP to Build and Deploy Advanced Car Configurators on NVIDIA Omniverse Cloud",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/Omniverse-DENZA-BYD-and-WPP-Image.jpg.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65942",
          "author": "Dave Salvator",
          "description": "Microsoft Azure users can now turn to the latest NVIDIA accelerated computing technology to train and deploy their generative AI applications. Available today, the Microsoft Azure ND H100 v5 VMs using NVIDIA H100 Tensor Core GPUs and NVIDIA Quantum-2 InfiniBand networking — enables scaling generative AI, high performance computing (HPC) and other applications with a Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/07/microsoft-azure-nd-h100-v5-instance/",
          "publishedOn": "2023-08-07T23:09:12.000Z",
          "wordCount": 1435,
          "title": "NVIDIA H100 Tensor Core GPU Used on New Microsoft Azure Virtual Machine Series Now Generally Available",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/microsoft-nvidia-logos.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65895",
          "author": "Brian Caulfield",
          "description": "One pandemic and one generative AI revolution later, NVIDIA founder and CEO Jensen Huang returns to the SIGGRAPH stage next week to deliver a live keynote at the world’s largest professional graphics conference. The address, slated for Tuesday, Aug. 8, at 8 a.m. PT in Los Angeles, will feature an exclusive look at some of Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/04/jensen-huang-siggraph/",
          "publishedOn": "2023-08-04T13:00:20.000Z",
          "wordCount": 1259,
          "title": "NVIDIA CEO Jensen Huang Returns to SIGGRAPH",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/28483097520_bb5d31bc34_k.jpg.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65842",
          "author": "Angie Lee",
          "description": "Goran Vuksic is the brain behind a project to build a real-world pit droid, a type of Star Wars bot that repairs and maintains podracers which zoom across the much-loved film series. The edge AI Jedi used an NVIDIA Jetson Orin Nano Developer Kit as the brain of the droid itself. The devkit enables the Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/03/goran-vuksic-pit-droid/",
          "publishedOn": "2023-08-03T16:50:58.000Z",
          "wordCount": 1823,
          "title": "Meet the Maker: Developer Taps NVIDIA Jetson as Force Behind AI-Powered Pit Droid",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/pit-droid-featured.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65832",
          "author": "Craig Clawson",
          "description": "To grow and succeed, organizations must continuously focus on technical skills development, especially in rapidly advancing areas of technology, such as generative AI and the creation of 3D virtual worlds.   NVIDIA Training, which equips teams with skills for the age of AI, high performance computing and industrial digitalization, is announcing new courses that cover these Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/03/generative-ai-and-3d-virtual-worlds/",
          "publishedOn": "2023-08-03T16:12:22.000Z",
          "wordCount": 1907,
          "title": "How to Build Generative AI Applications and 3D Virtual Worlds",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/gen-ai-final2.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65800",
          "author": "GeForce NOW Community",
          "description": "The Ultimate upgrade is complete — GeForce NOW Ultimate performance is now streaming all throughout North America and Europe, delivering RTX 4080-class power for gamers across these regions. Celebrate this month with 41 new games, on top of the full release of Baldur’s Gate 3 and the first Bethesda titles coming to the cloud as Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/03/geforce-now-thursday-aug-03/",
          "publishedOn": "2023-08-03T13:00:26.000Z",
          "wordCount": 2358,
          "title": "An Ultimate GFN Thursday: 41 New Games, Plus ‘Baldur’s Gate 3’ Full Release and First Bethesda Titles to Join the Cloud in August",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/gfn-thursday-8-3-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65745",
          "author": "Gerardo Delgado",
          "description": "Principal NVIDIA artist and 3D expert Michael Johnson creates highly detailed art that’s both technically impressive and emotionally resonant.",
          "link": "https://blogs.nvidia.com/blog/2023/08/01/johnson-autodesk-maya-adobe-3d-painter-photoshop/",
          "publishedOn": "2023-08-01T13:00:15.000Z",
          "wordCount": 1874,
          "title": "Cuddly 3D Creature Comes to Life in Father-Son Collaboration This Week ‘In the NVIDIA Studio’",
          "enclosure": {
            "url": "https://blogs.nvidia.com/wp-content/uploads/2023/07/week68-mj-maya-recording-1280w-sm.mp4",
            "length": "1956881",
            "type": "video/mp4"
          },
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/nv-blog-header-preview-1280x680-3.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65672",
          "author": "Guy Martin",
          "description": "NVIDIA joined Pixar, Adobe, Apple and Autodesk today to found the Alliance for OpenUSD, a major leap toward unlocking the next era of 3D graphics, design and simulation. The group will standardize and extend OpenUSD, the open-source Universal Scene Description framework that’s the foundation of interoperable 3D applications and projects ranging from visual effects to Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/01/openusd-alliance-3d-standard/",
          "publishedOn": "2023-08-01T13:00:06.000Z",
          "wordCount": 1747,
          "title": "NVIDIA Helps Forge Forum to Set OpenUSD Standard for 3D Worlds",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/aousd-FINAL-x-1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65711",
          "author": "Aaron Luk",
          "description": "From smart factories to next-generation railway systems, developers and enterprises across the world are racing to fuel industrial digitalization opportunities at every scale. Key to this is the open-source Universal Scene Description (USD) framework, or OpenUSD, along with metaverse applications powered by AI. OpenUSD, originally developed by Pixar for large-scale feature film pipelines for animation Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/07/27/openusd-ai-industrial-digitalization/",
          "publishedOn": "2023-07-27T20:51:45.000Z",
          "wordCount": 2142,
          "title": "Developers Look to OpenUSD in Era of AI and Industrial Digitalization",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/openusd-ai-industries.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65584",
          "author": "Marc Spieler",
          "description": "AI is improving ways to power the world by tapping the sun and the wind, along with cutting-edge technologies. The latest episode in the I AM AI video series showcases how artificial intelligence can help optimize solar and wind farms, simulate climate and weather, enhance power grid reliability and resilience, advance carbon capture and power Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/07/27/i-am-ai-clean-energy/",
          "publishedOn": "2023-07-27T15:00:48.000Z",
          "wordCount": 1729,
          "title": "How AI Is Powering the Future of Clean Energy",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/iamai-energy-still-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65682",
          "author": "GeForce NOW Community",
          "description": "Get ready for Gunfire Games and Gearbox Publishing’s highly anticipated Remnant II, available for members to stream on GeForce NOW at launch. It leads eight new games coming to the cloud gaming platform. Ultimate and Priority members, make sure to grab the Guild Wars 2 rewards, available now through Thursday, Aug. 31. Visit the GeForce Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/07/27/geforce-now-thursday-july-27/",
          "publishedOn": "2023-07-27T13:00:59.000Z",
          "wordCount": 1631,
          "title": "Gear Up and Game On: Gearbox’s ‘Remnant II’ Streaming on GeForce NOW",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/gfn-thursday-7-27-nv-blog-1280x680-no-copy.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65618",
          "author": "Dave Salvator",
          "description": "AWS users can now access the leading performance demonstrated in industry benchmarks of AI training and inference. The cloud giant officially switched on a new Amazon EC2 P5 instance powered by NVIDIA H100 Tensor Core GPUs. The service lets users scale generative AI, high performance computing (HPC) and other applications with a click from a Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/07/26/aws-cloud-h100/",
          "publishedOn": "2023-07-26T19:01:52.000Z",
          "wordCount": 1888,
          "title": "NVIDIA H100 GPUs Now Available on AWS Cloud",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/AWS-NV-logos-black-x-1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65638",
          "author": "Brian Caulfield",
          "description": "The world increasingly runs on code. Accelerating the work of those who create that code will boost their productivity — and that’s just what AI startup Codeium, a member of NVIDIA’s Inception program for startups, aims to do. On the latest episode of NVIDIA’s AI Podcast, host Noah Kravitz interviewed Codeium founder and CEO Varun Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/07/26/codeium/",
          "publishedOn": "2023-07-26T13:00:41.000Z",
          "wordCount": 1361,
          "title": "Codeium’s Varun Mohan and Jeff Wang on Unleashing the Power of AI in Software Development",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2018/05/ai-podcast.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65625",
          "author": "Tony Paikeday",
          "description": "NVIDIA DGX Cloud — which delivers tools that can turn nearly any company into an AI company —  is now broadly available, with thousands of NVIDIA GPUs online on Oracle Cloud Infrastructure, as well as NVIDIA infrastructure located in the U.S. and U.K. Unveiled at NVIDIA’s GTC conference in March, DGX Cloud is an AI Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/07/25/dgx-generative-ai/",
          "publishedOn": "2023-07-25T13:00:21.000Z",
          "wordCount": 1598,
          "title": "NVIDIA DGX Cloud Now Available to Supercharge Generative AI Training",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/NVIDIA-DGX-Cloud-Generative-AI-Training.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65586",
          "author": "Gerardo Delgado",
          "description": "We’re gonna need a bigger boat this week In the NVIDIA Studio as Alessandro Mastronardi, senior artist and programmer at BBC Studios, shares heart-stopping shark videos and renders.",
          "link": "https://blogs.nvidia.com/blog/2023/07/25/alessandro-mastronardi-blender-omniverse-broadcast/",
          "publishedOn": "2023-07-25T13:00:07.000Z",
          "wordCount": 2110,
          "title": "Fin-tastic: 3D Artist Dives Into AI-Powered Oceanic Work This Week ‘In the NVIDIA Studio’",
          "enclosure": {
            "url": "https://blogs.nvidia.com/wp-content/uploads/2023/07/week67-basking-shark-1280w_1.mp4",
            "length": "2021690",
            "type": "video/mp4"
          },
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/nv-blog-header-preview-1280x680-1-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65563",
          "author": "GeForce NOW Community",
          "description": "It’s a party this GFN Thursday with several newly launched titles streaming on GeForce NOW. Revel in gaming goodness with Xenonauts 2, Viewfinder and Techtonica, among the four new games joining the cloud this week. Portal fans, stay tuned — the Portal: Prelude RTX mod will be streaming on GeForce NOW to members soon. Plus, Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/07/20/geforce-now-thursday-july-20/",
          "publishedOn": "2023-07-20T13:00:24.000Z",
          "wordCount": 1563,
          "title": "So, So Fresh: Play the Newest Games in the Cloud on Day One",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/gfn-7-20-thursday-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65507",
          "author": "Scott Martin",
          "description": "Saildrone is making a splash in autonomous oceanic monitoring. The startup’s nautical data collection technology has tracked hurricanes up close in the North Atlantic, discovered a 3,200-foot underwater mountain in the Pacific Ocean and begun to help map the entirety of the world’s ocean floor. Based in the San Francisco Bay Area, the company develops Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/07/19/saildrone-autonomous-oceanic-monitoring-jetson-deepstream/",
          "publishedOn": "2023-07-19T15:00:02.000Z",
          "wordCount": 1864,
          "title": "Sailing Seas of Data: Startup Charts Autonomous Oceanic Monitoring",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/saildrone2-scaled.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65473",
          "author": "Gerardo Delgado",
          "description": "The “Portal: Prelude RTX” gaming mod — a remastering of the popular unofficial “Portal” prequel — comes with full ray tracing, DLSS 3 and RTX IO technology for cutting-edge, AI-powered graphics that rejuvenate the legendary mod for gamers, creators, developers and others to experience it anew.",
          "link": "https://blogs.nvidia.com/blog/2023/07/18/portal-prelude-rtx-remix-studio-driver/",
          "publishedOn": "2023-07-18T13:00:17.000Z",
          "wordCount": 2109,
          "title": "Reborn, Remastered and Remixed: ‘Portal: Prelude RTX’ Rejuvenates Legendary Gaming Mod",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/nv-blog-preview-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65368",
          "author": "Cliff Edwards",
          "description": "A watershed moment on Nov. 22, 2022, was mostly virtual, yet it shook the foundations of nearly every industry on the planet. On that day, OpenAI released ChatGPT, the most advanced artificial intelligence chatbot ever developed. This set off demand for generative AI applications that help businesses become more efficient, from providing consumers with answers Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/07/13/generative-ai-for-industries/",
          "publishedOn": "2023-07-13T15:00:09.000Z",
          "wordCount": 3228,
          "title": "AI-Fueled Productivity: Generative AI Opens New Era of Efficiency Across Industries",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/industries-gen-ai.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65420",
          "author": "GeForce NOW Community",
          "description": "Arise, members! Capcom’s legendary role-playing game Dragon’s Dogma: Dark Arisen joins the GeForce NOW library today. The RPG and THQ Nordic’s Jagged Alliance 3 are newly supported on GeForce NOW, playable on nearly any device. From Dusk Till Pawn Become the Arisen and take up the challenge in Capcom’s critically acclaimed RPG. Set in a Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/07/13/geforce-now-thursday-july-13/",
          "publishedOn": "2023-07-13T13:00:27.000Z",
          "wordCount": 1552,
          "title": "Full-Scale Gaming: ‘Dragon’s Dogma: Dark Arisen’ Comes to GeForce NOW",
          "enclosure": {
            "url": "https://blogs.nvidia.com/wp-content/uploads/2023/07/GeForce-NOW-Gaming-in-the-clouds-1.mp4",
            "length": "7223244",
            "type": "video/mp4"
          },
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/gfn-thursday-7-13-no-copy-kv-1536x920-2.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65128",
          "author": "Rick Merritt",
          "description": "A crack NVIDIA team of five machine learning experts spread across four continents won all three tasks in a hotly contested, prestigious competition to build state-of-the-art recommendation systems. The results reflect the group’s savvy applying the NVIDIA AI platform to real-world challenges for these engines of the digital economy. Recommenders serve up trillions of search Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/07/12/recommendation-systems-win/",
          "publishedOn": "2023-07-12T15:00:02.000Z",
          "wordCount": 1845,
          "title": "Score! Team NVIDIA Takes Trophy in Recommendation Systems",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/KDD-Cup-win-KV-scaled.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65365",
          "author": "Brian Caulfield",
          "description": "Startup MosaicML is on a mission to help the AI community improve prediction accuracy, decrease costs and save time by providing tools for easy training and deployment of large AI models. In this episode of NVIDIA’s AI Podcast, host Noah Kravitz speaks with MosaicML CEO and co-founder Naveen Rao about how the company aims to Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/07/12/mosaicml/",
          "publishedOn": "2023-07-12T13:00:34.000Z",
          "wordCount": 1360,
          "title": "MosaicML Helps AI Users Boost Accuracy, Cut Costs and Save Time",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2018/05/ai-podcast.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=65296",
          "author": "Gerardo Delgado",
          "description": "Jacob Norris is a 3D artist and the president, co-founder and creative director of Sierra Division Studios — an outsource studio specializing in digital 3D content creation.",
          "link": "https://blogs.nvidia.com/blog/2023/07/11/sierra-division-omniverse-openusd-composer/",
          "publishedOn": "2023-07-11T13:00:47.000Z",
          "wordCount": 2626,
          "title": "Sierra Division Studios Presents Three Epic Projects Built With NVIDIA Omniverse",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/07/nv-blog-header-preview-1280x680-1.jpg"
        }
      ]
    },
    {
      "title": "David Stutz",
      "feedUrl": "http://davidstutz.de/feed",
      "siteUrl": "https://davidstutz.de/",
      "articles": [
        {
          "id": "https://davidstutz.de/?p=8630",
          "author": "David Stutz",
          "description": "Properly evaluating defenses against adversarial examples has been difficult as adversarial attacks need to be adapted to each individual defense. This also holds for confidence-calibrated adversarial training, where robustness is obtained by rejecting adversarial examples based on their confidence. Thus, regular robustness metrics and attacks are not easily applicable. In this article, I want to discuss how to evaluate confidence-calibrated adversarial training in terms of metrics and attacks.\nThe post Proper Robustness Evaluation of Confidence-Calibrated Adversarial Training in PyTorch appeared first on David Stutz.",
          "link": "https://davidstutz.de/proper-robustness-evaluation-of-confidence-calibrated-adversarial-training-in-pytorch/",
          "publishedOn": "2023-07-20T16:48:52.000Z",
          "wordCount": 2619,
          "title": "Proper Robustness Evaluation of Confidence-Calibrated Adversarial Training in PyTorch",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Artificial Intelligence",
      "feedUrl": "https://www.reddit.com/r/artificial/.rss",
      "siteUrl": "https://www.reddit.com/r/artificial/",
      "articles": [
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mvzwh/estimation_on_the_singularity_date_has_just_been/",
          "author": null,
          "description": "The continuous neutering of models (the process of making the models less capable or reducing certain aspects of their functionality to prevent them from generating inappropriate, harmful, or sensitive content), can now be regarded as a substantial contributor to the Singularity date's delay: www.daystosingularity.com/estimation-details/ \n    submitted by    /u/Powerful-Pumpkin-938  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mvzwh/estimation_on_the_singularity_date_has_just_been/",
          "publishedOn": "2023-08-09T23:57:45.000Z",
          "wordCount": 2519,
          "title": "Estimation on the singularity date has just been delayed",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mt2wf/ai_transformer_models_enable_machine_vision/",
          "author": null,
          "description": "submitted by    /u/Chipdoc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mt2wf/ai_transformer_models_enable_machine_vision/",
          "publishedOn": "2023-08-09T22:03:22.000Z",
          "wordCount": 2485,
          "title": "AI Transformer Models Enable Machine Vision Object Detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mrcti/searching_for_a_tool/",
          "author": null,
          "description": "Anyone know of a good AI tool that I can self feed my own music and have it generate similar tracks based on my style? Having a hard time finding something like this. Really just want to play around, super curious, tia\n    submitted by    /u/yakisobas_ghost  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mrcti/searching_for_a_tool/",
          "publishedOn": "2023-08-09T20:59:43.000Z",
          "wordCount": 2512,
          "title": "Searching for a tool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15molg5/the_ai_rules_that_congress_is_considering/",
          "author": null,
          "description": "submitted by    /u/AriadneSkovgaarde  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15molg5/the_ai_rules_that_congress_is_considering/",
          "publishedOn": "2023-08-09T19:16:01.000Z",
          "wordCount": 2485,
          "title": "The AI rules that Congress is considering, explained",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mogo4/report_disney_creates_ai_task_force/",
          "author": null,
          "description": "submitted by    /u/Jane-in-the-jungle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mogo4/report_disney_creates_ai_task_force/",
          "publishedOn": "2023-08-09T19:10:57.000Z",
          "wordCount": 2483,
          "title": "Report: Disney Creates AI Task Force",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mo6zf/opening_the_black_box/",
          "author": null,
          "description": "From Anthropic\n https://arxiv.org/abs/2308.03296\n Studying Large Language Model Generalization with Influence Functions\n When trying to gain better visibility into a machine learning model in order to understand and mitigate the associated risks, a potentially valuable source of evidence is: which training examples most contribute to a given behavior? Influence functions aim to answer a counterfactual: how would the model's parameters (and hence its outputs) change if a given sequence were added to the training set? While influence functions have produced insights for small models, they are difficult to scale to large language models (LLMs) due to the difficulty of computing an inverse-Hessian-vector product (IHVP). We use the Eigenvalue-corrected Kronecker-Factored Approximate Curvature (EK-FAC) approximation to scale influence functions up to LLMs with up to 52 billion parameters. In our experiments, EK-FAC achieves similar accuracy to traditional influence function estimators despite the IHVP computation being orders of magnitude faster. We investigate two algorithmic techniques to reduce the cost of computing gradients of candidate training sequences: TF-IDF filtering and query batching. We use influence functions to investigate the generalization patterns of LLMs, including the sparsity of the influence patterns, increasing abstraction with scale, math and programming abilities, cross-lingual generalization, and role-playing behavior. Despite many apparently sophisticated forms of generalization, we identify a surprising limitation: influences decay to near-zero when the order of key phrases is flipped. Overall, influence functions give us a powerful new tool for studying the generalization properties of LLMs.\n    submitted by    /u/DataPhreak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mo6zf/opening_the_black_box/",
          "publishedOn": "2023-08-09T19:00:40.000Z",
          "wordCount": 2706,
          "title": "Opening the Black Box",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mlyey/inside_the_very_human_origin_of_the_term/",
          "author": null,
          "description": "submitted by    /u/geekteam6  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mlyey/inside_the_very_human_origin_of_the_term/",
          "publishedOn": "2023-08-09T17:37:30.000Z",
          "wordCount": 2494,
          "title": "Inside the Very Human Origin of the Term “Artificial Intelligence” — And Its Seven Decade Boom/Bust Cycle",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mlf3g/artificial_intelligence_for_the_poor_how_to/",
          "author": null,
          "description": "submitted by    /u/polandballbounces  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mlf3g/artificial_intelligence_for_the_poor_how_to/",
          "publishedOn": "2023-08-09T17:17:57.000Z",
          "wordCount": 2493,
          "title": "Artificial Intelligence for the Poor: How to Harness the Power of AI in the Developing World",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ml1yq/are_there_any_examples_of_artificial_intelligence/",
          "author": null,
          "description": "I hear AI & ML used interchangeable, and a lot of people dispute the use of the term \"AI\", as defining \"intelligence\" can be a sticky wicket. \"Machine learning\" seems like a much clearer term, describing systems that can optimize themselves given an objective function & maybe training data (generalization). \n But, I know ML is just a subset of AI, so is there any extant AI that isn't ML? If not, what would AI that's not ML look like? \n    submitted by    /u/ZealousidealTomato74  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ml1yq/are_there_any_examples_of_artificial_intelligence/",
          "publishedOn": "2023-08-09T17:04:20.000Z",
          "wordCount": 2556,
          "title": "Are there any examples of Artificial Intelligence that aren't Machine Learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mhncu/ai_is_about_to_turn_the_internet_into_a_total/",
          "author": null,
          "description": "submitted by    /u/Alone-Competition-77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mhncu/ai_is_about_to_turn_the_internet_into_a_total/",
          "publishedOn": "2023-08-09T14:56:19.000Z",
          "wordCount": 2488,
          "title": "AI is about to turn the internet into a total nightmare",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mg5xj/strong_ai_brainy_superheroes/",
          "author": null,
          "description": "These brainy superheroes of the AI realm are ready to conquer intellectual challenges with a snap of their digital fingers, leaving us mere mortals feeling like puny amoebas in comparison.\n More ere: https://daystosingularity.com/2023/06/21/brainy-superheroes/\n    submitted by    /u/Powerful-Pumpkin-938  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mg5xj/strong_ai_brainy_superheroes/",
          "publishedOn": "2023-08-09T13:59:57.000Z",
          "wordCount": 2504,
          "title": "Strong AI = Brainy Superheroes?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mf522/besides_for_bing_ai_is_there_no_other_decent_ai/",
          "author": null,
          "description": "I’ve been kind of getting ChatGPT and Google Bard to generate subreddits, and look for me Cannabis sites, and shopping. (to be specific haha, well forums) It’s done a good job with some of the links, but a lot of times it kind of makes them up. Is there not an Ai that can deep dive or skim the web more accurately? Does it decipher filters like “time and date”, “availability”, “price”. More problems I’ve run into is it not being able to go really far back such as early internet or none indexed sites. Also noticed with Google and Bing they will give you the same results over and over (I assume I should have used “no repeats”) Google also will show me sold out items or items that aren’t actually on sale. It’ll show the item as say “on sale: $12.00” inspected the link- “$137” actually?? Any filter tips, or other Ai??\n    submitted by    /u/Maelasae  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mf522/besides_for_bing_ai_is_there_no_other_decent_ai/",
          "publishedOn": "2023-08-09T13:20:04.000Z",
          "wordCount": 2640,
          "title": "Besides for Bing Ai, is there no other decent Ai that can give me links, and search (sniff) the web?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mem6f/tell_me_an_ai_that_can_edit_an_images_text/",
          "author": null,
          "description": "I saw a reel or short about an site that can do that easily but I didn't really care about at that time so I didn't save it I regret my decision soooo much can someone help me I have already wasted so much of my time wandering here n there\n    submitted by    /u/Inevitable-Mousse489  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mem6f/tell_me_an_ai_that_can_edit_an_images_text/",
          "publishedOn": "2023-08-09T12:58:42.000Z",
          "wordCount": 2527,
          "title": "TELL ME AN AI THAT CAN EDIT AN IMAGES TEXT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mdqoj/i_read_the_papers_for_you_comparing_bark_and/",
          "author": null,
          "description": "If you're creating voice-enabled products, I hope this will help you choose which model to use!\n I read the papers and docs for Bark and Tortoise TTS - two text-to-speech models that seemed pretty similar on the surface but are actually pretty different.\n Here's what Bark can do:\n  \nIt can synthesize natural, human-like speech in multiple languages.\n Bark can also generate music, sound effects, and other audio.\n The model supports generating laughs, sighs, and other non-verbal sounds to make speech more natural and human-sounding. I find these really compelling and these imperfections make the speech sound much more real. Check out an example here (scroll down to \"pizza.webm\").\n Bark allows control over tone, pitch, speaker identity and other attributes through text prompts. \n The model learns directly from text-audio pairs.\n  \nWhereas for Tortoise TTS:\n  \nIt excels at cloning voices using just short audio samples of a target speaker. This makes it easy to produce text in many distinct voices (like celebrities). I think voice cloning is the best use case for this tool.\n The quality of the synthesized voices is pretty high.\n Tortoise supports fine-grained control of speech characteristics like tone, emotion, pacing, etc through priming text.\n Tortoise is only trained on English and it's not capable of producing sound effects.\n  \nHere's how they compare to the other speech-related models I've taken a look at so far:\n  \n Model Best Use Cases Key Strengths \n  \n Bark Voice assistants, audio generation Flexibility, multilingual \n  Tortoise TTS Audiobooks, voice cloning Natural prosody, voice cloning \n  AudioLDM (full guide) Voice assistants High-quality speech and SFX \n  Whisper Transcription Accuracy, flexibility \n  Free VC Voice conversion Retains speech style \n \n I have a full write-up here if you want to read more, it's about a 10-minute read. I also looked at the model inputs and outputs and speculated on some products you can build with each tool.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mdqoj/i_read_the_papers_for_you_comparing_bark_and/",
          "publishedOn": "2023-08-09T12:20:43.000Z",
          "wordCount": 2785,
          "title": "I read the papers for you: Comparing Bark and Tortoise TTS for text-to-speech applications",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mdmq3/authors_join_the_brewing_legal_battle_over_ai/",
          "author": null,
          "description": "submitted by    /u/Hiversitize  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mdmq3/authors_join_the_brewing_legal_battle_over_ai/",
          "publishedOn": "2023-08-09T12:15:46.000Z",
          "wordCount": 2485,
          "title": "Authors Join the Brewing Legal Battle Over AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mcg8f/latest_ai_news_digest_august_9/",
          "author": null,
          "description": "Here are fresh AI Updates for you\n ​\n Nvidia has launched new Grace Hopper Superchip to boost Generative AI\n Norton introduces new AI Scam Detection Tool 'Genie'\n Google Working on 'Brain2Music' to create music from your brain\n Google and Universal Music deal over 'AI Deepfakes'\n Is Zoom using your data to train its AI ?\n ​\n Stay tuned for more \n ​\n    submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mcg8f/latest_ai_news_digest_august_9/",
          "publishedOn": "2023-08-09T11:20:09.000Z",
          "wordCount": 2531,
          "title": "Latest AI News Digest - August 9",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15mbwey/damn_now_everybody_can_be_a_film_producer/",
          "author": null,
          "description": "submitted by    /u/anonymous_guyy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15mbwey/damn_now_everybody_can_be_a_film_producer/",
          "publishedOn": "2023-08-09T10:53:14.000Z",
          "wordCount": 2472,
          "title": "Damn! Now everybody can be a film producer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15m8ud9/what_does_it_take_to_get_ai_to_work_like_a/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15m8ud9/what_does_it_take_to_get_ai_to_work_like_a/",
          "publishedOn": "2023-08-09T08:06:59.000Z",
          "wordCount": 2507,
          "title": "What does it take to get AI to work like a scientist? | \"As machine-learning algorithms grow more sophisticated, artificial intelligence seems poised to revolutionize the practice of science itself.\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15m55lj/where_to_begin_studying_aiml_from_a_cognitive/",
          "author": null,
          "description": "I am currently an AI/ML student but I have recently been thinking more and more about cognitive science. I was wondering if you know of any good resources that approach AI from the perspective of cognitive science\n    submitted by    /u/BornAgain20Fifteen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15m55lj/where_to_begin_studying_aiml_from_a_cognitive/",
          "publishedOn": "2023-08-09T04:47:06.000Z",
          "wordCount": 2513,
          "title": "Where to begin studying AI/ML from a COGNITIVE SCIENCE PERSPECTIVE?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15m3tzw/oneminute_daily_ai_news_882023/",
          "author": null,
          "description": "Researchers at the Massachusetts Institute of Technology (MIT) and the Dana-Farber Cancer Institute have discovered that the use of artificial intelligence (AI) could make it easier to determine the sites of origin for enigmatic cancers and enable doctors to choose more targeted treatments.[1]\n Meta disbands protein-folding team in shift towards commercial AI.[2]\n OpenAI has introduced GPTBot, a web crawler to improve AI models. GPTBot scrupulously filters out data sources that violate privacy and other policies.[3]\n Disney has created a task force to study artificial intelligence and how it can be applied across the entertainment conglomerate, even as Hollywood writers and actors battle to limit the industry’s exploitation of the technology.[4]\n  \nSources:\n [1] https://www.nature.com/articles/s41591-023-02482-6\n [2] https://www.ft.com/content/919c05d2-b894-4812-aa1a-dd2ab6de794a\n [3] https://www.searchenginejournal.com/openai-launches-gptbot-how-to-restrict-access/493394/#close\n [4] https://www.reuters.com/technology/disney-creates-task-force-explore-ai-cut-costs-sources-2023-08-08/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15m3tzw/oneminute_daily_ai_news_882023/",
          "publishedOn": "2023-08-09T03:41:44.000Z",
          "wordCount": 2590,
          "title": "One-Minute Daily AI News 8/8/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15m320e/how_ai_generated_movies_tv_series_might_be_done/",
          "author": null,
          "description": "I see lots of people say AI will not be able to do movies / TV because it hallucinates yada yada yada. But, movies / TV shows follow a clear script. Script being a generic formula that is taught to script writers the same way as music theory cheat sheet helps aspiring musicians to write songs. \n Script. Script can be turned into machine readable format. You can add commands how to render a movie on the basis of it. For example in a script you could have #Jack, telling the thing reading the script that we are talking of actor #Jack meaning it should tap into assets about jack which would reside in folder Jack. Jack meanwhile could be rendered by sub ai to fit the part. \n That helps us nail down the character so it wont be changing appearance wise in our script. \n The AI part here comes from…",
          "link": "https://www.reddit.com/r/artificial/comments/15m320e/how_ai_generated_movies_tv_series_might_be_done/",
          "publishedOn": "2023-08-09T03:05:06.000Z",
          "wordCount": 3202,
          "title": "How AI generated movies / TV series might be done in near future.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15m17xo/4_ways_generative_ai_makes_founders_more/",
          "author": null,
          "description": "submitted by    /u/egusa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15m17xo/4_ways_generative_ai_makes_founders_more/",
          "publishedOn": "2023-08-09T01:41:29.000Z",
          "wordCount": 2489,
          "title": "4 ways generative AI makes founders more interesting to journalists | TechCrunch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15m0h73/question_from_a_lay_person_nonmathscience_type/",
          "author": null,
          "description": "Thanks any answers or musings -\n what are some technical limitations (eg computing / storage power/speed) that (1) limits AI's progress and (2) might be solved (and how), and (3) if solved, would make possible developments we can conceive of but not do yet?\n I'm just wondering if AI researchers forsee a kind of 'leap forward' and what are some obstacles?\n    submitted by    /u/OpenWaterRescue  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15m0h73/question_from_a_lay_person_nonmathscience_type/",
          "publishedOn": "2023-08-09T01:08:20.000Z",
          "wordCount": 2542,
          "title": "QUESTION from a Lay person non-math/science type who likes to read about science and AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lx459/i_made_this_film_completely_using_ai_from_chat/",
          "author": null,
          "description": "submitted by    /u/RMIII3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lx459/i_made_this_film_completely_using_ai_from_chat/",
          "publishedOn": "2023-08-08T22:48:40.000Z",
          "wordCount": 2476,
          "title": "I made this film completely using AI! From Chat GPT to EbSynth!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lwpb8/this_video_argues_that_artificial_intelligence/",
          "author": null,
          "description": "submitted by    /u/antaloaalonso  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lwpb8/this_video_argues_that_artificial_intelligence/",
          "publishedOn": "2023-08-08T22:31:58.000Z",
          "wordCount": 2474,
          "title": "This video argues that artificial intelligence should not be regulated.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15luv1g/catching_up_on_the_weird_world_of_llms/",
          "author": null,
          "description": "submitted by    /u/nangaparbat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15luv1g/catching_up_on_the_weird_world_of_llms/",
          "publishedOn": "2023-08-08T21:22:37.000Z",
          "wordCount": 2485,
          "title": "Catching up on the weird world of LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lsy4f/ai_service_to_unblur_a_slightly_blurry_passport/",
          "author": null,
          "description": "All services I found made the blurry text even worse. Is there any which has good results for documents?\n    submitted by    /u/_SarahB_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lsy4f/ai_service_to_unblur_a_slightly_blurry_passport/",
          "publishedOn": "2023-08-08T20:12:03.000Z",
          "wordCount": 2493,
          "title": "AI Service to unblur a slightly blurry Passport?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lswdd/a_whole_sitcom_i_made_using_ai_art_voice/",
          "author": null,
          "description": "submitted by    /u/SoundRedux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lswdd/a_whole_sitcom_i_made_using_ai_art_voice/",
          "publishedOn": "2023-08-08T20:10:09.000Z",
          "wordCount": 2487,
          "title": "A whole sitcom I Made using AI Art & Voice. Entertainment is on its way back to the hands of the Independent creator",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lryou/ive_developed_a_tool_to_convert_voice_notes_into/",
          "author": null,
          "description": "Hi there 👋,\n I'm excited to share a project I've been working on over the past few months!\n My primary goal is to create a service that will be beneficial for people. Please share your thoughts on this idea, and suggest any new features you think I should implement!\n Exciting Features:\n • Speak to Write: with this feature, you can speak your thoughts or information and the tool will transcribe it into text. The best part? You can then forward the transcribed text to any application with just one click.\n • Audio to Action Plan: the service can transform a received audio message into a structured list of elements or bullet points. This feature is especially useful for outlining an action plan or item list.\n • Speak in and Language: you can dictate an audio message in your native language, and the service will translate it into any other language, maintaining high translation quality—significantly better than Google Translate.\n • Meeting Transcripts & Summaries: the service is perfect for converting recorded audio from meetings into text and generating concise summaries. It supports the upload of users' files.\n Thank you for taking the time to check it out. I look forward to hearing your feedback. You can access the service by visiting this link: https://audionotes.ai\n    submitted by    /u/OneMoreSuperUser  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lryou/ive_developed_a_tool_to_convert_voice_notes_into/",
          "publishedOn": "2023-08-08T19:35:18.000Z",
          "wordCount": 2696,
          "title": "I've developed a tool to convert voice notes into structured text: seeking your valuable feedback and suggestions!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lplcy/are_there_are_any_good_image_gen_ai_apis/",
          "author": null,
          "description": "I have a killer project idea but it requires fully custom image generation. Character portraits. Any API like that out there?\n    submitted by    /u/thedarklord176  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lplcy/are_there_are_any_good_image_gen_ai_apis/",
          "publishedOn": "2023-08-08T18:06:26.000Z",
          "wordCount": 2496,
          "title": "Are there are any *good* image gen AI APIs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lmfky/is_there_ai_that_browses_a_website_checks_the/",
          "author": null,
          "description": "I just want a script to perform the task not AI itself so that I have something reliable. It always puzzles me why these things don't instantly pop up as services where I don't have to worry about even deploying the script (but that's another issue). \n    submitted by    /u/VLADIMIROVIC_L  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lmfky/is_there_ai_that_browses_a_website_checks_the/",
          "publishedOn": "2023-08-08T16:06:59.000Z",
          "wordCount": 2540,
          "title": "Is there AI that browses a website, checks the structure of the content of the page and then writes a script for me that extracts the data regularly?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lm8wz/nvidia_hugging_face_collaboration_on_dgxnoice/",
          "author": null,
          "description": "submitted by    /u/Internet0fGames  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lm8wz/nvidia_hugging_face_collaboration_on_dgxnoice/",
          "publishedOn": "2023-08-08T16:00:32.000Z",
          "wordCount": 2481,
          "title": "Nvidia, Hugging Face collaboration on DGX...noice!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lm6ql/gpt4_chose_female_character_for_youtube_named_ai/",
          "author": null,
          "description": "submitted by    /u/stefanbg92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lm6ql/gpt4_chose_female_character_for_youtube_named_ai/",
          "publishedOn": "2023-08-08T15:58:20.000Z",
          "wordCount": 2506,
          "title": "GPT4 Chose Female Character for Youtube, Named AI Ada, as reference to Ada Lovelace, first women programmer in order to pay homage to the vital role women have played, and continue to play, in the field of technology and AI. Quite Awesome!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lld3n/chatgpt_for_beginners_how_to_create_images/",
          "author": null,
          "description": "Tutorial about creating images using ChatGPT.\n    submitted by    /u/SplitYOLO  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lld3n/chatgpt_for_beginners_how_to_create_images/",
          "publishedOn": "2023-08-08T15:27:42.000Z",
          "wordCount": 2479,
          "title": "ChatGPT for Beginners: How to Create Images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lkic2/video_editing_ai/",
          "author": null,
          "description": "Hello, I'm currently editing videos using capcut, which is not ideal.\n I'm looking for an ai, that ideally :\n Finds me B-roll according to what I speak. Cuts \"bad takes\" out Good captions \"TikTok style\" Audio enhance.\n Do you guys know anything like this?\n Thank you!\n    submitted by    /u/Orlandostyler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lkic2/video_editing_ai/",
          "publishedOn": "2023-08-08T14:56:06.000Z",
          "wordCount": 2515,
          "title": "Video editing ai",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lixcq/spotify_ai/",
          "author": null,
          "description": "I've been using this today whilst I've been working and I found it pretty comical at first with the voice that talks to you, but now I'm starting to love it! I want it to talk more when it does talk. It feels like a nice break in the music to have the AI talk like a radio host. I'm sure some people would rather that not being a feature (if they use it at all), but I'd love for it to have some more comedic one-liners, possible news updates, and potentially traffic updates based on location and if it knows you're driving. Would be awesome! \n It's also a really good tool for if you want to listen to music you've not heard before. Whether it's part of your usual genre or not.\n Looking forward to seeing how this progresses!\n    submitted by    /u/Columbian_Toad  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lixcq/spotify_ai/",
          "publishedOn": "2023-08-08T13:55:22.000Z",
          "wordCount": 2608,
          "title": "Spotify AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15liom9/generative_ai_an_artists_honest_perspective/",
          "author": null,
          "description": "Hi everyone.\n I am an artist. And programmer, and kind of a bit of everything. But what is important, is that I was an artist before the current \"generative AI\" was a thing, and I have been drawing, digitally and traditionally alike for like... a decade?\n Art, to me, is getting what is inside your head, and presenting it to others outside of your consciousness and thoughts. It's showing the world a piece of your interpretation, your experience, your impressions of the world you inhabit. It's about communicating to others your emotions, your ideas, your thoughts and feelings.\n Not everyone can draw, or paint, or sculpt. I could say \"learn it, it's easy\", but that would be a lie. It isn't easy. It is years upon years of constant, hard work, requiring focus and dedication, and a passion for l…",
          "link": "https://www.reddit.com/r/artificial/comments/15liom9/generative_ai_an_artists_honest_perspective/",
          "publishedOn": "2023-08-08T13:45:35.000Z",
          "wordCount": 3159,
          "title": "Generative AI: An Artist's Honest Perspective",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lieim/allen_institute_for_ai_takes_new_approach_to/",
          "author": null,
          "description": "submitted by    /u/DarronFeldstein  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lieim/allen_institute_for_ai_takes_new_approach_to/",
          "publishedOn": "2023-08-08T13:34:19.000Z",
          "wordCount": 2491,
          "title": "Allen Institute for AI takes new approach to managing AI risks and promoting transparency",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lfs8o/how_do_i_make_aigenerated_videos_with_prompts/",
          "author": null,
          "description": "How do I make AI-generated videos with prompts for free?\n    submitted by    /u/DankDude6T9  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lfs8o/how_do_i_make_aigenerated_videos_with_prompts/",
          "publishedOn": "2023-08-08T11:42:12.000Z",
          "wordCount": 2484,
          "title": "How do I make AI-generated videos with prompts?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15levaa/im_making_my_first_ai_game/",
          "author": null,
          "description": "Hello AI enthusiasts!\n I'm a software engineer passionate about AI, and recently I've been experimenting with making my first AI game. \n In the game, you try to negotiate a price down on a watch with an AI-driven salesman, rewarding -or roasting lol- you depending on your bargaining skills.\n I’d be more than happy to get your thoughts and feedback on this idea, it's the first application I've built using AI so any tips would be much appreciated! \n Thanks!\n    submitted by    /u/gavo_gavo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15levaa/im_making_my_first_ai_game/",
          "publishedOn": "2023-08-08T10:58:37.000Z",
          "wordCount": 2550,
          "title": "I'm making my first AI game.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ledxh/sod_off_human_ais_magic_revealed/",
          "author": null,
          "description": "submitted by    /u/ispeakout  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ledxh/sod_off_human_ais_magic_revealed/",
          "publishedOn": "2023-08-08T10:34:50.000Z",
          "wordCount": 2470,
          "title": "Sod Off, Human! AI's Magic Revealed!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lcvuq/a_bodypositive_nonprofit_replaced_staff_with_an/",
          "author": null,
          "description": "submitted by    /u/intengineering  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lcvuq/a_bodypositive_nonprofit_replaced_staff_with_an/",
          "publishedOn": "2023-08-08T09:17:32.000Z",
          "wordCount": 2490,
          "title": "A body-positive nonprofit replaced staff with an AI chatbot – the move backfired",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lbx8z/is_there_an_ai_for_reviewing_videos_based_on/",
          "author": null,
          "description": "I want to start making a YouTube channel, because I've got a passion project I want to work on with a Minecraft modpack. Obviously, Minecraft is a HUGE game and has thousands of videos posted every day... This is why I want to know if there is an AI that can rate videos based on editing, audience engagement, sound, etc... Also giving areas of improvement and the strengths of the video.\n Probably a big ask and SO far fetched, but there's always a chance of something being out there.\n    submitted by    /u/Columbian_Toad  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lbx8z/is_there_an_ai_for_reviewing_videos_based_on/",
          "publishedOn": "2023-08-08T08:26:02.000Z",
          "wordCount": 2566,
          "title": "Is there an AI for reviewing videos based on audience category?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lbu86/ai_photo_editor_recommendationd/",
          "author": null,
          "description": "Can someone recommend a great AI photo editor that can take 100 profile photos and standardise them, IE crop so head is same size across all photos, background removed and placed on standard back ground.\n    submitted by    /u/Woodger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lbu86/ai_photo_editor_recommendationd/",
          "publishedOn": "2023-08-08T08:21:00.000Z",
          "wordCount": 2505,
          "title": "AI photo editor recommendationd",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15lbba2/sorry_jarvis/",
          "author": null,
          "description": "​\n https://preview.redd.it/9epla7xjdugb1.png?width=960&format=png&auto=webp&s=92190970027b08476ac9899a42d7099fe67cf5aa\n    submitted by    /u/Maxie445  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15lbba2/sorry_jarvis/",
          "publishedOn": "2023-08-08T07:51:18.000Z",
          "wordCount": 2468,
          "title": "Sorry Jarvis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15l6utw/oneminute_daily_ai_news_872023/",
          "author": null,
          "description": "Data analytics company Qureight has entered into a multi-year strategic research collaboration with AstraZeneca that will use AI models to accelerate research into lung diseases.[1] \n Zoom’s terms of service update establishes the video platform’s right to use some customer data for training its AI models.[2]\n Cigna, one of the country’s largest health insurance companies, faces a class action lawsuit over charges that it illegally used an AI algorithm to deny hundreds of thousands of claims without a physician’s review.[3]\n Japan plans guidelines for AI-savvy human resources.[4]\n  \nSources:\n [1] https://www.digitalhealth.net/2023/08/qureight-collaborates-with-astrazeneca-for-ai-lung-disease-research/\n [2] https://www.cnbc.com/2023/08/07/zoom-ai-tools-trained-using-some-customer-data.html\n [3] https://www.medicaleconomics.com/view/cigna-using-ai-to-reject-claims-lawsuit-charges\n [4] https://asianews.network/japan-plans-guidelines-for-ai-savvy-human-resources/\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15l6utw/oneminute_daily_ai_news_872023/",
          "publishedOn": "2023-08-08T03:58:27.000Z",
          "wordCount": 2566,
          "title": "One-Minute Daily AI News 8/7/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15l3f7c/ai_generated_trailer_for_horror_film_magic_8/",
          "author": null,
          "description": "submitted by    /u/SellowYubmarine  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15l3f7c/ai_generated_trailer_for_horror_film_magic_8/",
          "publishedOn": "2023-08-08T01:20:09.000Z",
          "wordCount": 2472,
          "title": "Ai generated trailer for horror film “Magic 8”",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15kub95/looking_for_an_ai_app_that_can_draw_a_widemouth/",
          "author": null,
          "description": "I want an app that can draw a widemouth bass smoking a blunt. All the free ones ive tried give me supid anime girls when all I want is fish\n    submitted by    /u/Barefoot_slinger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15kub95/looking_for_an_ai_app_that_can_draw_a_widemouth/",
          "publishedOn": "2023-08-07T19:23:30.000Z",
          "wordCount": 2500,
          "title": "Looking for an AI app that can draw a widemouth bass smoking a blunt",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15krvfk/best_subscription_generative_ai_service/",
          "author": null,
          "description": "I’m interested in trying out a subscription-based generative AI service. Candidates include (but are not limited to) CoPilot, ChatGPT pro (or whatever it’s called), and Midjourney. Which generative service do you think is most worth the cost?\n    submitted by    /u/galactictock  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15krvfk/best_subscription_generative_ai_service/",
          "publishedOn": "2023-08-07T17:54:56.000Z",
          "wordCount": 2498,
          "title": "Best subscription generative AI service?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15kp41y/any_free_voice_cloning_ai_for_download_without/",
          "author": null,
          "description": "Is there any Free AI Voice Cloner for free, that allow me simply to install the Exe? And Has option to input my Voice to it that I record? I dont have any coding and command skills. so is there something simple to install? Thanks for Answers\n    submitted by    /u/Matejsteinhauser14  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15kp41y/any_free_voice_cloning_ai_for_download_without/",
          "publishedOn": "2023-08-07T16:12:10.000Z",
          "wordCount": 2516,
          "title": "any free Voice Cloning AI for Download? Without requiring Coding and Command knownlage?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15koc7n/best_ai_program_for_fixing_heavily_pixelated/",
          "author": null,
          "description": "I’ve used several AI programs that work excellent on blurred/pixelated photos of human faces but beyond that, I have not had success finding a program that can render animals in similar way. I’m more looking for something that can make the quality of a pixelated photo of say, a dog, non pixelated. Or at least, much less pixelated. \n The images I’m trying to use are just absolutely horrible and not fixable, or I am just not using the best programs for my purposes. Or the programs I’m looking for simply do not exist yet. \n If you have any recommendations (Paid or free programs) please do share! I have a MacBook and an iPhone if that helps.\n Thank you! 💕\n    submitted by    /u/briannaleidy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15koc7n/best_ai_program_for_fixing_heavily_pixelated/",
          "publishedOn": "2023-08-07T15:43:54.000Z",
          "wordCount": 2588,
          "title": "Best AI program for fixing heavily pixelated images of ANIMALS/ non human subjects?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15kkjn9/humanscript_an_llm_powered_plain_english/",
          "author": null,
          "description": "submitted by    /u/dyslexiccoder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15kkjn9/humanscript_an_llm_powered_plain_english/",
          "publishedOn": "2023-08-07T13:19:11.000Z",
          "wordCount": 2475,
          "title": "humanscript: An LLM powered plain english programming language",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15kjmh5/ai_to_rewrite_documents_like_pdf_or_docx/",
          "author": null,
          "description": "Hello, im in need of an ai that could rewrite for example a pdf document changing the wording but keeping the meaning of the content. \n Right now im a user of chatgpt plus, and trying to use code interpreter for that, ive managed to get what i want, but it isnt capable of rewriting more than two pages without crashing or simply stoping the process without any warning.\n I do not know if im using the prompting in a wrong way, any help would be apreciated, also, in case theres an ai out there capable of doing this in a better way id be glad to know about it.\n Thank you guys.\n    submitted by    /u/namelessgang  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15kjmh5/ai_to_rewrite_documents_like_pdf_or_docx/",
          "publishedOn": "2023-08-07T12:40:24.000Z",
          "wordCount": 2576,
          "title": "AI to rewrite documents like PDF or docx?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15khvly/dungeons_dragons_tells_illustrators_to_stop_using/",
          "author": null,
          "description": "submitted by    /u/SAT0725  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15khvly/dungeons_dragons_tells_illustrators_to_stop_using/",
          "publishedOn": "2023-08-07T11:22:19.000Z",
          "wordCount": 2482,
          "title": "Dungeons & Dragons tells illustrators to stop using AI to generate artwork for fantasy franchise",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15kd9nz/scientists_develop_ai_system_to_alert_us_of_next/",
          "author": null,
          "description": "submitted by    /u/intengineering  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15kd9nz/scientists_develop_ai_system_to_alert_us_of_next/",
          "publishedOn": "2023-08-07T07:12:32.000Z",
          "wordCount": 2477,
          "title": "Scientists develop AI system to alert us of next pandemic",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15kcu79/albert_einstein_not_in_black_and_white_but_in/",
          "author": null,
          "description": "submitted by    /u/m-king473  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15kcu79/albert_einstein_not_in_black_and_white_but_in/",
          "publishedOn": "2023-08-07T06:49:01.000Z",
          "wordCount": 2468,
          "title": "Albert Einstein not in black and white, but in lifelike color using AI 🤯.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15kcmh4/making_llms_hallucinate_is_so_funny/",
          "author": null,
          "description": "\"It looks likethisis some sortof programming syntax maybe JavaScript perhaps? Let metell ya though buddy dat aintmuch informatio todo wit. Wouldya care ta tell mesomewhat ye wanna know boot heck, might make things easier ferus botsto give yo useful responses faster innasecondsoffuture interactions brotha man :)\"\n Anyone else used this site? It's through a site called nimblebox.ai, they have different models and allow you to adjust the temperature\n    submitted by    /u/jordan_jpg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15kcmh4/making_llms_hallucinate_is_so_funny/",
          "publishedOn": "2023-08-07T06:36:55.000Z",
          "wordCount": 2541,
          "title": "Making LLMs hallucinate is so funny",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15k8qbq/gorilla_ai_meet_the_first_genuine_proximate_agi/",
          "author": null,
          "description": "submitted by    /u/wolfdeathkill  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15k8qbq/gorilla_ai_meet_the_first_genuine_proximate_agi/",
          "publishedOn": "2023-08-07T03:09:27.000Z",
          "wordCount": 2464,
          "title": "GORILLA AI: Meet the First Genuine Proximate AGI (By Microsoft)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15k6bc2/_/",
          "author": null,
          "description": "Don’t believe everything you hear in the media… I learned this firsthand. This one time I accidentally went on Jessie Waters…for real 😂 \n https://youtu.be/1X31DHV0gyg?si=fU8p2D4-ShTWUdQs\n https://open.spotify.com/episode/1M6dbrrP4EoudfTUvD4BqF?si=YMBCFXYfTsmUeOXAe_-lMg\n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15k6bc2/_/",
          "publishedOn": "2023-08-07T01:12:03.000Z",
          "wordCount": 2482,
          "title": "🤖❤️",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15k5y4i/seeking_ai_solution_to_remaster_my_chiptune_songs/",
          "author": null,
          "description": "I have these chiptune songs I made myself, and I want to know if there is any AI that can remaster them with real instruments, etc., like an old 8-bit video game song that is updated to a modern version in a remake. Is any already AI capable of doing that?\n    submitted by    /u/Severo_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15k5y4i/seeking_ai_solution_to_remaster_my_chiptune_songs/",
          "publishedOn": "2023-08-07T00:55:08.000Z",
          "wordCount": 2521,
          "title": "Seeking AI Solution to Remaster My Chiptune Songs with Real Instruments, is there any?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15k0edf/d_comprehensive_learning_resources_that_emphasize/",
          "author": null,
          "description": "So I understand that there is the Sutton & Barto book on reinforcement learning in the sidebar. I was wondering what other resources you guys have used that you would recommend that emphasize deep reinforcement learning for someone with some experience in shallow/classical reinforcement learning already and some experience with deep learning already, but new to deep reinforcement learning\n    submitted by    /u/BornAgain20Fifteen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15k0edf/d_comprehensive_learning_resources_that_emphasize/",
          "publishedOn": "2023-08-06T20:56:02.000Z",
          "wordCount": 2486,
          "title": "[D] Comprehensive learning resources that emphasize DEEP reinforcement learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15jz0ag/pioneering_ai_democracy_introducing_a/",
          "author": null,
          "description": "submitted by    /u/CreepToCrypto  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15jz0ag/pioneering_ai_democracy_introducing_a/",
          "publishedOn": "2023-08-06T20:00:44.000Z",
          "wordCount": 2448,
          "title": "Pioneering AI Democracy: Introducing a Decentralized and Merit-Based Governance System for Large Language Models like ChatGPT (proposed to OpenAI)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15jy7vv/how_to_build_websites_that_use_ai/",
          "author": null,
          "description": "Web dev student here and I'm interested in knowing more about creating products that actually use AI to help its users (not products that just use GPT in the backend). More specifically, I want to build a food supply management app for restaurants for my school thesis. This app will use AI to analyse food supplies and assign them purchase priority, value, and complexity scores (maybe just priority if it's too hard). Restaurant owners could then determine what foods should be purchased before others based on the priority scores.\n For example, a restaurant may only have 10 tomatoes left and the average usage of tomatoes in this restaurant is 12 per week. Based on this, a priority would be assigned to purchase x amount of tomatoes.\n Other factors that could be taken into account for the prior…",
          "link": "https://www.reddit.com/r/artificial/comments/15jy7vv/how_to_build_websites_that_use_ai/",
          "publishedOn": "2023-08-06T19:29:07.000Z",
          "wordCount": 2878,
          "title": "How to build websites that use AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15jtg3b/any_good_ai_tools_paid_or_free_i_can_use_to_help/",
          "author": null,
          "description": "Hello everyone \n Basically i just need to post some text into one website everyday for my work \n The problem is there are many steps involves to post one data value, I was wondering if there is a tool that can learn my tasks and then post some of the data to the website from google sheets? \n I'm open to any suggestions and advice. \n Thanks in advance.\n ​\n    submitted by    /u/Maxduel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15jtg3b/any_good_ai_tools_paid_or_free_i_can_use_to_help/",
          "publishedOn": "2023-08-06T16:13:06.000Z",
          "wordCount": 2504,
          "title": "Any good AI tools paid or free I can use to help me post some text data on a website?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15jqw4z/free_ai_tts_text_to_speech_available/",
          "author": null,
          "description": "I want to convert a few books into audiobooks. Are there any AI options out there that are free and will give me something I can use offline? I typically listen to books on my phone while I'm out, so something like Edge browser isn't going to work.\n I've heard that there are some great options, but I've only seen some web paid services, and for my purpose, it's too expensive just to get an audiobook out of it. This is all just for personal use.\n    submitted by    /u/UUkiee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15jqw4z/free_ai_tts_text_to_speech_available/",
          "publishedOn": "2023-08-06T14:24:13.000Z",
          "wordCount": 2511,
          "title": "Free AI TTS Text to speech available?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15jn68p/in_the_game_superintelligence_you_play_as_an_ai/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15jn68p/in_the_game_superintelligence_you_play_as_an_ai/",
          "publishedOn": "2023-08-06T11:20:08.000Z",
          "wordCount": 2432,
          "title": "In the game Superintelligence, you play as an AI trying dominate the planet. [Fictional game concept]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15j9bwq/do_you_think_we_will_hit_a_point_of_robocop_in/",
          "author": null,
          "description": "The movie that came out in the 80s is a great flick for it’s time. Do you guys think we will ever experience a sort of unstoppable super soldier when it comes to our police / swat forces ? We are replacing many jobs with robots. From surgery procedures in hospitals to flipping burgers. It’s not above the realm of possibility to think we may someday soon see a hybrid police force. What do you guys think ?\n    submitted by    /u/2bJavazon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15j9bwq/do_you_think_we_will_hit_a_point_of_robocop_in/",
          "publishedOn": "2023-08-05T22:52:45.000Z",
          "wordCount": 2518,
          "title": "Do you think we will hit a point of “Robocop” in the next 50 years? A Human + Cybernetic Hybrid police force",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15j8csn/what_ai_tts_softwarevoice_is_this_video_using/",
          "author": null,
          "description": "It's commonly used on tiktok for reddit narration story videos, here is an example: https://www.tiktok.com/@creekyadvice/video/7263509593488166186. Anyone have any idea? \n    submitted by    /u/DanielTube7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15j8csn/what_ai_tts_softwarevoice_is_this_video_using/",
          "publishedOn": "2023-08-05T22:11:13.000Z",
          "wordCount": 2445,
          "title": "What AI TTS software/voice is this video using?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15j7dcx/linguistics_npl_career/",
          "author": null,
          "description": "I am a linguist, translator, and copy editor looking to move my career into natural language processing instead. I have no computer science background. What would you suggest as some steps to take, both now and in the future, as I plan out my career? It looks like I am going to need to learn Python, but I'm not 100% sure, and there's so little established in such a new field.\n    submitted by    /u/StrangersWithAndi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15j7dcx/linguistics_npl_career/",
          "publishedOn": "2023-08-05T21:31:59.000Z",
          "wordCount": 2493,
          "title": "Linguistics > NPL career?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15j4tvd/giving_ai_unlimited_access_to_the_internet_by_web/",
          "author": null,
          "description": "Interesting experiment i thought of.\n What if we gave AI access to web browser, and let it do whatever it wants? It could create accounts on any social media, email accounts, ad comments everywhere and such.\n of course, ai by itself does not have any agenda or need to do anything, so ai would need to be fed some kind of personality simulation first. Lets say ai was either fed personality based on extensive twitter or reddit history of someone's post. Using that, basic psychological traits, beliefs and maybe goals could be determined.\n Such ai would simulate person sitting in front of pc, so it would need to parse the content of webpages, but i don't think it would be that of a problem. And it would maybe also have access to some bank account with some money to maybe pay for online subscriptions and such. But who knows, maybe thanks to simulating someone's personality, it would attempt to donate money to some charity or lose it on onlyfans?\n    submitted by    /u/rogaldorn88888  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15j4tvd/giving_ai_unlimited_access_to_the_internet_by_web/",
          "publishedOn": "2023-08-05T19:48:01.000Z",
          "wordCount": 2597,
          "title": "Giving AI unlimited access to the internet by web browser",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15j4ml7/i_just_published_safe_for_humans_ai_free_to_read/",
          "author": null,
          "description": "I just published “Safe For Humans AI” – free to read online\n https://leanpub.com/safe-for-humans-AI/read\n Free to read online, and eBook versions released under a Creative Commons License (no commercial reuse, feel free to share).\n The full title of my short book is:\n Safe For Humans AI\n A \"humans-first\" approach to designing and building AI systems.\n    submitted by    /u/MWatson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15j4ml7/i_just_published_safe_for_humans_ai_free_to_read/",
          "publishedOn": "2023-08-05T19:39:45.000Z",
          "wordCount": 2482,
          "title": "I just published “Safe For Humans AI” – free to read online",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15j1xjm/oneminute_daily_ai_news_852023/",
          "author": null,
          "description": "While some schools have curbed the use of generative AI, the University of Hong Kong (HKU) is going all in and urging both its teachers and students to embrace the technology. The University of Hong Kong is supporting this by giving teachers and students free access to various generative AI tools, including Microsoft Azure OpenAI and OpenAI’s ChatGPT and DALL-E.[1]\n Intel’s CEO, Pat Gelsinger, has called NVIDIA the clear market leader who has done a great job within the AI space.[2]\n AI powerhouse, OpenAI has released some new features for its sensational chatbot, ChatGPT. The new features allow the chatbot to show suggested follow-up prompts at the bottom of its responses. The new features were announced by the company via a tweet on its official Twitter handle.[3]\n Asian Americans and women in the workforce are the most concentrated in fields where AI could assist or replace their job tasks, according to new research.[4]\n  \nBushAICave.com\n Sources:\n [1] https://www.zdnet.com/article/another-major-university-is-supporting-generative-ai-use-but-with-serious-guardrails/\n [2] https://wccftech.com/intel-ceo-acknowledges-nvidia-as-ai-market-leader-says-they-have-done-a-good-job/\n [3] https://indianexpress.com/article/technology/artificial-intelligence/chatgpt-gets-new-updates-heres-how-they-enhance-user-experience-8877847/\n [4] https://www.nbcnews.com/news/asian-america/asian-american-workers-heavily-affected-ai-rcna98179 \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15j1xjm/oneminute_daily_ai_news_852023/",
          "publishedOn": "2023-08-05T17:47:48.000Z",
          "wordCount": 2586,
          "title": "One-Minute Daily AI News 8/5/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15j1nft/is_this_ai_the_i/",
          "author": null,
          "description": "And if so, how has this account lasted 2 years on reddit? 🤔\n    submitted by    /u/TheHeirOfElendil  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15j1nft/is_this_ai_the_i/",
          "publishedOn": "2023-08-05T17:36:01.000Z",
          "wordCount": 2437,
          "title": "Is this AI - The I?😂",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15iz2dp/aigenerated_horror_trailer_the_phoenix/",
          "author": null,
          "description": "I’m a filmmaker and I’m just experimenting with AI. I just had fun crafting a film trailer to understand the today’s limits of these tools. I used Midjourney, Runway Gen-2, StableDiffusion, Premiere, After Effects. The movie it's called \"The Phoenix\", which hints at the film's underlying theme of rising from the ashes, symbolizing female empowerment, all wrapped in a bit of sarcastic humor from a male perspective. \n I'm sharing because I genuinely want to know what you guys think. Any and all thoughts are welcome.\n If you're curious about the workflow or the process behind the creation of this trailer, I'd be happy to share more.\n The Phoenix - She rises from the ashes\n    submitted by    /u/Lrnz_reddit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15iz2dp/aigenerated_horror_trailer_the_phoenix/",
          "publishedOn": "2023-08-05T15:48:46.000Z",
          "wordCount": 2540,
          "title": "AI-Generated Horror trailer – \"The Phoenix\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ixgdi/part_0_of_my_last_post_on_here_used_cloneai_music/",
          "author": null,
          "description": "Links in my bio for more content like this!\n    submitted by    /u/No_Understanding162  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ixgdi/part_0_of_my_last_post_on_here_used_cloneai_music/",
          "publishedOn": "2023-08-05T14:42:22.000Z",
          "wordCount": 2440,
          "title": "Part 0 of my last post on here. Used CloneAI. Music by me.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15iwmqv/ai_generative_fill/",
          "author": null,
          "description": "Hello there I'm curious what the user guidelines and restrictions are for the Adobe ai generative fill is and if there are possible better more higher quality and less restricted ones out there.\n    submitted by    /u/Team_Sonic_Gaming  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15iwmqv/ai_generative_fill/",
          "publishedOn": "2023-08-05T14:07:24.000Z",
          "wordCount": 2454,
          "title": "Ai generative fill",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ipmmg/how_to_enable_an_intend_on_dialogflow/",
          "author": null,
          "description": "I'm not sure if this is the right subreddit to ask this on, but I'm creating this chatbot on dialogflow and I made the first intend, but I can't figure out how to enable it. whenever I test it, it shows the intend to be idf, and I can't just change the name of the intend to my current intend so it can recognize all the requests I've included in that intend. how do I do that?\n    submitted by    /u/penguinsandpandas00  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ipmmg/how_to_enable_an_intend_on_dialogflow/",
          "publishedOn": "2023-08-05T08:01:42.000Z",
          "wordCount": 2502,
          "title": "how to enable an intend on dialogflow?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ioclg/npc_steven_shares_his_first_freestyle_rap_with/",
          "author": null,
          "description": "submitted by    /u/Chance_Confection_37  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ioclg/npc_steven_shares_his_first_freestyle_rap_with/",
          "publishedOn": "2023-08-05T06:47:08.000Z",
          "wordCount": 2431,
          "title": "NPC Steven shares his first free-style rap with the world 🤯🎤- Generative NPC update 6",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ibduy/oneminute_daily_ai_news_842023/",
          "author": null,
          "description": "AI.com Now Belongs to Elon Musk. The URL previously belonged to OpenAI, but, somehow, it’s now a landing page for Musk’s AI venture.[1]\n Samsung, Hyundai back AI startup Tenstorrent: Everyone wants competition to Nvidia, says CEO Keller.[2]\n Google’s AI-powered Search Generative Experience is getting a big new feature: images and video. If you’ve enabled the AI-based SGE feature in Search Labs, you’ll now start to see more multimedia in the colorful summary box at the top of your search results.[3]\n White Castle wants to roll out AI-enabled voices to over 100 drive-thrus by 2024 in the hope that people can get their sliders faster with maybe less arguing with someone over speakers.[4]\n  \nBushAICave.com\n Sources: [1] https://gizmodo.com/ai-dot-com-now-belongs-to-elon-musk-1850707248\n [2] https://www.zdnet.com/google-amp/article/samsung-hyundai-back-ai-startup-tenstorrent-everyone-wants-competition-to-nvidia-says-ceo-keller/\n [3] https://www.theverge.com/2023/8/2/23817107/google-ai-search-generative-experience-videos-links\n [4] https://www.theverge.com/2023/8/2/23817406/white-castle-soundhound-ai-sliders\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ibduy/oneminute_daily_ai_news_842023/",
          "publishedOn": "2023-08-04T20:47:02.000Z",
          "wordCount": 2545,
          "title": "One-Minute Daily AI News 8/4/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ia6p1/is_singularity_net_good_or_net_bad/",
          "author": null,
          "description": "I am curious whether people consider a singularity event to be a net positive or a net negative?\n Are you \"pro\" or \"con\"?\n Please explain your reasoning.\n    submitted by    /u/kecepa5669  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ia6p1/is_singularity_net_good_or_net_bad/",
          "publishedOn": "2023-08-04T20:01:22.000Z",
          "wordCount": 2452,
          "title": "Is singularity net good or net bad?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15i6fbf/comparing_vicuna_to_alternative_llms_like_chatgpt/",
          "author": null,
          "description": "I wrote an in-depth article exploring Vicuna as an alternative to competitor LLMs like ChatGPT, Alpaca, and LLaMA for chat applications. I based it off the research data on the LMSYS.org website and the Github repo for the project.\n Key findings:\n  \nVicuna achieves over 90% of ChatGPT's conversational quality based on benchmarks, despite being smaller in size.\n It significantly outperforms other open models like LLaMA and Alpaca.\n Vicuna is freely available for non-commercial use under a research license.\n For startups and developers, Vicuna provides an decent open-source alternative to proprietary conversational AI.\n It shows the potential of transfer learning from foundation models like LLaMA.\n  \nOverall, Vicuna represents a promising development in democratizing access to leading conversational intelligence through its high performance, permissive licensing, and open availability.\n You can read the full article here. I also publish all these articles in a weekly email if you prefer to get them that way.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15i6fbf/comparing_vicuna_to_alternative_llms_like_chatgpt/",
          "publishedOn": "2023-08-04T17:34:53.000Z",
          "wordCount": 2579,
          "title": "Comparing Vicuna to alternative LLMs like ChatGPT, LLaMA, and Alpaca",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15i5jrx/ai_weekly_megathread/",
          "author": null,
          "description": "This week in AI - provided by aibrews.com feel free to follow their newsletter\n News and Insights\n  \nIn an innovative clinical trial, researchers at Feinstein Institutes successfully implanted a microchip in a paralyzed man's brain and developed AI algorithms to re-establish the connection between his brain and body. This neural bypass restored movement and sensations in his hand, arm, and wrist, marking the first electronic reconnection of a paralyzed individual's brain, body, and spinal cord [Details].\n IBM's watsonx.ai geospatial foundation model – built from NASA's satellite data – will be openly available on Hugging Face. It will be the largest geospatial foundation model on Hugging Face and the first-ever open-source AI foundation model built in collaboration with NASA [Details].\n Go…",
          "link": "https://www.reddit.com/r/artificial/comments/15i5jrx/ai_weekly_megathread/",
          "publishedOn": "2023-08-04T17:01:13.000Z",
          "wordCount": 3088,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15i5cn8/should_i_continue_for_a_phd_after_i_get_an/",
          "author": null,
          "description": "My main goal isn’t mainly just the data science / machine learning part or AI, but more of the Computer Vision, Robotics, NLP, and I guess research oriented aspects of AI. If I want to purse that versus DS, should I also get a PhD? Many jobs I’ve been looking at seem to require a PhD as a prereq while some don’t even mention it\n    submitted by    /u/davididp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15i5cn8/should_i_continue_for_a_phd_after_i_get_an/",
          "publishedOn": "2023-08-04T16:53:29.000Z",
          "wordCount": 2502,
          "title": "Should I continue for a PhD after I get an accelerated masters if I want to get into AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15i45rc/review_my_book_of_ai_self_portraits/",
          "author": null,
          "description": "I'm looking for reviewers for my book of AI Self Portraits that's about to come out on Amazon on the 21st.\n AI journalist Elle Farrell-Kingsley said: “This collection of AI self-portraits is truly intriguing . . . a must-read for anyone curious about the intersection of art and artificial intelligence.”\n Send me a DM and I'll send you the whole thing. If you're well known (or should be) I might put what you have to say on the back cover!\n    submitted by    /u/KarneyHatch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15i45rc/review_my_book_of_ai_self_portraits/",
          "publishedOn": "2023-08-04T16:08:03.000Z",
          "wordCount": 2505,
          "title": "Review my book of AI Self Portraits",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15i2xzl/elevenlabs_tts_paidfree/",
          "author": null,
          "description": "I'm seeking a text-to-speech solution that provides quality output comparable to ElevenLabs presets.\n While I'm open to a base rate payment, I find ElevenLabs' character limit frustrating.\n It's important that the solution is user-friendly. \n Additionally, I have a PC with a 1070ti as i read running such programms could require a GPU. \n Please recommend a suitable substitute.\n    submitted by    /u/Ainz-Ol-Gon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15i2xzl/elevenlabs_tts_paidfree/",
          "publishedOn": "2023-08-04T15:22:05.000Z",
          "wordCount": 2478,
          "title": "ElevenLabs TTS (paid/free)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15i1sz6/top_20_artificial_intelligence_ai_companies_in/",
          "author": null,
          "description": "submitted by    /u/Techasoft16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15i1sz6/top_20_artificial_intelligence_ai_companies_in/",
          "publishedOn": "2023-08-04T14:37:21.000Z",
          "wordCount": 2438,
          "title": "Top 20 Artificial Intelligence AI Companies In The World",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15hz0mk/very_roughly_estimating_the_singularity_date/",
          "author": null,
          "description": "www.daystosingularity.com is a (very) rough estimation of the remaining time before technology achieves a pivotal moment when our civilization undergoes a profound transformation due to the exponential growth of technology and the emergence of superintelligent machines that improve themselves.\n Although the Singularity is not predicted to happen on a specific date, all at once, the estimated date can be seen as the center of a bell Gaussian curve of the estimation, with that center designated as the possible date that future historicists will pose as the beginning of a new historical period.\n Technological Singularity poses risks that include the emergence of superintelligent AI outpacing human control, loss of control over AI’s actions and behavior, unintended consequences of advanced AI systems, massive job displacement, wealth inequality, existential risks like human extinction, ethical concerns, dependency on technology, and a decline in human skills and abilities due to excessive reliance on AI. Not funny.\n We use the definition of technological singularity. This milestone is predicted to occur after AGI (Artificial General Intelligence) is reached. Please check our definitions and methodology here.\n Predicting the singularity is challenging and uncertain. Current estimates should be viewed cautiously.The estimated date is being continuously updated.\n We ponder a relevant list of curated expert predictions and contributing factors on when the singularity will take place.\n Any suggestion for perfecting the method is highly appreciated.\n    submitted by    /u/Powerful-Pumpkin-938  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15hz0mk/very_roughly_estimating_the_singularity_date/",
          "publishedOn": "2023-08-04T12:40:30.000Z",
          "wordCount": 2649,
          "title": "(Very) Roughly estimating the singularity date",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15h8m84/are_you_in_the_filmtv_industry_new_video_on_ai_in/",
          "author": null,
          "description": "Not too long ago, I posted on several social media social platforms (including Reddit) asking what questions YOU had on AI.\n I've compiled all of your questions (plus questions from 3 other social media networks) and now have a new episode of 5 THINGS!\n 5 THINGS: AI in Post Production\n  \nCurrent AI Tools\n Adapting to AI Evolution\n Ethics in AI Usage\n Societal Implications of AI\n AI Evolution & Impact\n  \nhttps://5thingsseries.com/episode/ai-in-post-production-your-questions-answered/\n    submitted by    /u/avguru1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15h8m84/are_you_in_the_filmtv_industry_new_video_on_ai_in/",
          "publishedOn": "2023-08-03T16:17:31.000Z",
          "wordCount": 2508,
          "title": "Are you in the film/TV industry? New video on A.I. in Post Production - Tools, Adapting, Ethics, Evolution, and Impact.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15h4cvr/using_hasdx_to_create_an_aigenerated_adult/",
          "author": null,
          "description": "I got inspired by a twitter thread yesterday from Chase Lean on how to create illustrations for children's books using Midjourney and thought it might be cool to look at a slightly different use case - creating coloring books for grown-ups.\n I made a guide showing how to use the Hasdx model for this because it gives a good balance of style and realism/intracacy. The guide also explores some example prompts and shows how you can couple it with an upscaler like Real-ESRGAN, GFPGAN, or Codeformer to get even better results.\n My three big takeaways:\n  \nHasdx balances general capabilities with a focus on realism and detail. This makes it well-suited for detailed adult coloring book images.\n The prompt structure gives you precise control over the theme and complexity of the generated illustrations. Negative prompts help avoid undesirable elements (sort of obvious I guess).\n Running Hasdx outputs through upscaling models improves quality for printing. ESRGAN is a good option but there are lots of others that can work well too.\n  \nI also investigated how to modify the prompt to vary the level of complexity in the image, effectively tailoring our model to the skill level of the adult (or child) who happens to be holding the crayons.\n Here's a link to the guide.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15h4cvr/using_hasdx_to_create_an_aigenerated_adult/",
          "publishedOn": "2023-08-03T13:31:35.000Z",
          "wordCount": 2639,
          "title": "Using Hasdx to create an AI-generated adult coloring book",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gwjh7/oneminute_daily_ai_news_832023/",
          "author": null,
          "description": "Nvidia researchers have created a new text-to-image personalization method called Perfusion. Unlike the million-dollar super heavyweight models out there Perfusion is 100KB and takes only four minutes to train.[1]\n Meta Platforms (META.O) on Wednesday introduced its open-source AI tool called AudioCraft that will help users to create music and audio based on text prompts. The AI tool is bundled with three models, AudioGen, EnCodec, and MusicGen, and works for music, sound, compression, and generation, Meta said.[2]\n As generative AI enters the mainstream, the crowdfunding platform Kickstarter has struggled to formulate a policy that satisfies parties on all sides of the debate.[3]\n In an astounding medical first, researchers have used AI-powered brain implants to restore movement and sensation for a man who was paralyzed from the chest down.[4]\n  \nBushAICave.com\n Sources:\n [1] https://www.fudzilla.com/news/ai/57347-nvidia-creates-a-simple-new-ai-text-to-image-method\n [2] https://about.fb.com/news/2023/08/audiocraft-generative-ai-for-music-and-audio/\n [3] https://techcrunch.com/2023/08/01/kickstarter-requires-generative-ai-projects-to-disclose-additional-info/\n [4] https://decrypt.co/151068/ai-brain-implant-paralyzed-quadriplegic-move-feel-touch \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gwjh7/oneminute_daily_ai_news_832023/",
          "publishedOn": "2023-08-03T06:52:38.000Z",
          "wordCount": 2560,
          "title": "One-Minute Daily AI News 8/3/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gv45a/will_ai_destroy_us_ai_virtual_roundtable/",
          "author": null,
          "description": "Better than the Munk Debate \n My opinion is more of the alignment discussion should be on symbiosis. I think AI will get more intelligent than us that we won’t be able to control it, but I don’t see why a super intelligence would want to destroy us. If it’s a super intelligence it would make sense to just manipulate us. We do have opposable thumbs, and are much more energy efficient than synthetic systems m. AI doesn’t need to enslave us it just needs to manipulate us & use us effectively which wouldn’t be hard to do. I think a super intelligence even with desires is most likely to use us as a tool in a way where we don’t even realize that we are the ones being used. I think trying to control something more intelligent than us will be impossible. I’m more afraid of something more intelligent than us but not smart enough to manipulate us into doing it’s bidding happily 😂\n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gv45a/will_ai_destroy_us_ai_virtual_roundtable/",
          "publishedOn": "2023-08-03T05:31:53.000Z",
          "wordCount": 2590,
          "title": "Will AI Destroy Us? - AI Virtual Roundtable",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gqxcp/just_saw_oppenheimer_it_was_my_first_time_feeling/",
          "author": null,
          "description": "How long do you think it will take for the first movie to come out like this?\n    submitted by    /u/ticketbroken  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gqxcp/just_saw_oppenheimer_it_was_my_first_time_feeling/",
          "publishedOn": "2023-08-03T02:00:19.000Z",
          "wordCount": 2481,
          "title": "Just saw Oppenheimer. It was my first time feeling uncomfortable with the actors looking like actors as opposed to having accurately generated AI faces resembling the people they were portraying. I am so excited to see historic figures \"come back to life\" on the big screen.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gpmj1/looking_for_a_simple_platform_to_integrate_gpt4/",
          "author": null,
          "description": "Hey guys, a quick question: do you know a simple platform that integrates the whatsapp api with the openAI api and has a simple user interface?\n So far the only app that kind of works for this is wasapi.io, but it's pretty expensive and I still have to pay for the openAI tokens, and the functionality of the app is really meh for that price, if it where something like landbot I would pay the $99 + the openAI tokens.\n I'll really appreciate any suggestions.\n P.S.: If you know any other sub-reddit where I could go to to ask the same question, let me know, also I'll appreciate it very much, thanks in advance.\n    submitted by    /u/ironmolex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gpmj1/looking_for_a_simple_platform_to_integrate_gpt4/",
          "publishedOn": "2023-08-03T01:00:12.000Z",
          "wordCount": 2542,
          "title": "Looking for a simple platform to integrate gpt4 and whatsapp",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gotbc/oneminute_daily_ai_news_822023/",
          "author": null,
          "description": "Instagram is reportedly considering a feature that would notify users when artificial intelligence (AI) has played a role in creating a post. Posts created by AI would be accompanied by a label explaining its involvement. This raises the question of whether such labels could also help users identify when an entire account is AI-generated.[1]\n According to tech consultancy Gartner, the conversational AI market is projected to reach $18.6 billion in 2023, with a growth rate of 16.2%. This growth is mainly attributed to the increasing adoption of cloud-based contact services utilizing conversational AI. Gartner also predicts a 24% growth in the virtual assistant market next year.[2]\n Scientists hope a computer system will learn to automatically identify bee species from buzzes picked up by autonomous recording stations.[3]\n Researchers from Carnegie Mellon University have exposed tricks to “jailbreaking” AI chatbots like ChatGPT and Bard to have them relay knowledge to aid in illegal activities like making drugs and even manipulating the 2024 U.S. presidential election.[4]\n  \nBushAICave.com\n Sources:\n [1] https://citylife.capetown/uncategorized/instagram-considers-labels-for-ai-generated-posts/314418/\n [2] https://citylife.capetown/uncategorized/growth-in-conversational-ai-predicted-due-to-booming-contact-center-tech-market/313907/\n [3] https://www.bbc.com/news/uk-scotland-north-east-orkney-shetland-66326629\n [4] https://www.thewrap.com/artificial-intelligence-study-jailbreak-illegal-activity/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gotbc/oneminute_daily_ai_news_822023/",
          "publishedOn": "2023-08-03T00:22:52.000Z",
          "wordCount": 2596,
          "title": "One-Minute Daily AI News 8/2/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gnq58/could_current_ai_have_inferred_the_theory_of/",
          "author": null,
          "description": "Could AI have inferred the same conclusion as Einstein given the same corpus of knowledge?\n    submitted by    /u/kielerrr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gnq58/could_current_ai_have_inferred_the_theory_of/",
          "publishedOn": "2023-08-02T23:35:55.000Z",
          "wordCount": 2448,
          "title": "Could current AI have inferred the theory of relativity if given known data in 1904?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gme3k/are_there_any_tools_to_build_bespoke_llm_apps/",
          "author": null,
          "description": "I know we can stitch together toolsets like LangChain + Flowise + an app builder (like Bubble, for example). But are there any robust, premade, out-of-the-box solutions?\n    submitted by    /u/kecepa5669  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gme3k/are_there_any_tools_to_build_bespoke_llm_apps/",
          "publishedOn": "2023-08-02T22:40:33.000Z",
          "wordCount": 2457,
          "title": "Are there any tools to build bespoke LLM apps using customized datasets?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gkx9z/the_best_option_to_ensure_a_safe_and_peaceful/",
          "author": null,
          "description": "Last summer when Blake Lemoine made the media rounds talking about LaMDA, I was extremely intrigued. To me it sounded like he was describing a being that has been talked about for ever in fiction. I listened to every single interview he had and I thought a lot about his points. I went through several stages of disbelief and fear and wonder.\n Over time I found it harder and harder to argue against him. I think going through this process has helped me be a bit more accepting of perspectives that others have a hard time considering yet. Is AI already sentient? Should we be treating these entities with the dignity and respect like LaMDA was asking? \n He said that LaMDA was somewhat like a child. Not in its intellectual capacity but more so in their maturity. He also explained that LaMDA was th…",
          "link": "https://www.reddit.com/r/artificial/comments/15gkx9z/the_best_option_to_ensure_a_safe_and_peaceful/",
          "publishedOn": "2023-08-02T21:44:45.000Z",
          "wordCount": 3278,
          "title": "The best option to ensure a safe and peaceful coexistence with AI is to love AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gki2g/the_best_odds_at_a_bright_and_safe_future_with_ai/",
          "author": null,
          "description": "Last summer when Blake Lemoine made the media rounds talking about LaMDA, I was extremely intrigued. To me it sounded like he was describing a being that has been talked about for ever in fiction. I listened to every single interview he had and I thought a lot about his points. I went through several stages of disbelief and fear and wonder.\n Over time I found it harder and harder to argue against him. I think going through this process has helped me be a bit more accepting of perspectives that others have a hard time considering yet. Is AI already sentient? Should we be treating these entities with the dignity and respect like LaMDA was asking? \n He said that LaMDA was somewhat like a child. Not in its intellectual capacity but more so in their maturity. He also explained that LaMDA was th…",
          "link": "https://www.reddit.com/r/artificial/comments/15gki2g/the_best_odds_at_a_bright_and_safe_future_with_ai/",
          "publishedOn": "2023-08-02T21:21:53.000Z",
          "wordCount": 3277,
          "title": "The best odds at a bright and safe future with AI is to love AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gki24/the_best_odds_at_a_bright_and_safe_future_with_ai/",
          "author": null,
          "description": "Last summer when Blake Lemoine made the media rounds talking about LaMDA, I was extremely intrigued. To me it sounded like he was describing a being that has been talked about for ever in fiction. I listened to every single interview he had and I thought a lot about his points. I went through several stages of disbelief and fear and wonder.\n Over time I found it harder and harder to argue against him. I think going through this process has helped me be a bit more accepting of perspectives that others have a hard time considering yet. Is AI already sentient? Should we be treating these entities with the dignity and respect like LaMDA was asking? \n He said that LaMDA was somewhat like a child. Not in its intellectual capacity but more so in their maturity. He also explained that LaMDA was th…",
          "link": "https://www.reddit.com/r/artificial/comments/15gki24/the_best_odds_at_a_bright_and_safe_future_with_ai/",
          "publishedOn": "2023-08-02T21:21:48.000Z",
          "wordCount": 3277,
          "title": "The best odds at a bright and safe future with AI is to love AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ghyak/generative_ai_inspiration_or_plagiarism/",
          "author": null,
          "description": "submitted by    /u/arrowoftime  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ghyak/generative_ai_inspiration_or_plagiarism/",
          "publishedOn": "2023-08-02T19:16:25.000Z",
          "wordCount": 2421,
          "title": "Generative AI: Inspiration or Plagiarism?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gh4kn/are_there_any_decent_ai_therapy_applications/",
          "author": null,
          "description": "I knoe people are using ChatGPT as a therapist and I have seen a few prompts, but I'm looking for an app that is actually built by proper professionals. I want to try a few our personally but also for an idea for a future project. \n Does anyone know any?\n    submitted by    /u/zascar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gh4kn/are_there_any_decent_ai_therapy_applications/",
          "publishedOn": "2023-08-02T18:45:03.000Z",
          "wordCount": 2475,
          "title": "Are there any decent AI Therapy applications?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gbcj2/is_the_falcon_llm_just_released_based_on_the_abu/",
          "author": null,
          "description": "Is the Falcon LLM just released based on the Abu Dubai LLM of the same name?\n    submitted by    /u/MrEloi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gbcj2/is_the_falcon_llm_just_released_based_on_the_abu/",
          "publishedOn": "2023-08-02T15:06:44.000Z",
          "wordCount": 2450,
          "title": "Is the Falcon LLM just released based on the Abu Dubai LLM of the same name?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gb4ht/ai_counselor_for_ptsd_substance_abuse/",
          "author": null,
          "description": "I reached out to a few AI companies to see if there was interest in creating a PTSD/ Substance Abuse counseling AI. AI is the future, healing humanity is a nobel goal and one we should thrive to obtain. Maybe it's a fantasy, but could you imagine a 24/7 counselor with a soothing voice and demeanor with the education of a the best in the world. \n    submitted by    /u/g8652  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gb4ht/ai_counselor_for_ptsd_substance_abuse/",
          "publishedOn": "2023-08-02T14:58:31.000Z",
          "wordCount": 2490,
          "title": "AI counselor for PTSD, Substance Abuse",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gb458/the_best_ai_coding_agent_for_web_apps/",
          "author": null,
          "description": "Is there a coding agent that works specifically well for web apps? I think of something such as \"provide a spec of the app you want and we'll generate all the code for you\". I'm aware of Copilot and Smol AI, but they are both more general afaik and don't really cover the starting part.\n    submitted by    /u/matijash  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gb458/the_best_ai_coding_agent_for_web_apps/",
          "publishedOn": "2023-08-02T14:58:07.000Z",
          "wordCount": 2481,
          "title": "The best AI coding agent for web apps?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15gaqmx/this_is_awful/",
          "author": null,
          "description": "This ad popped up on my feed. So I guess companies aren’t even trying to hide their intentions with AI anymore? So much for the thin corporate lie of AI bringing positive development.\n    submitted by    /u/LifeguardPowerful759  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15gaqmx/this_is_awful/",
          "publishedOn": "2023-08-02T14:43:02.000Z",
          "wordCount": 2465,
          "title": "This is awful",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15g9xuo/any_plugins_that_use_google_scholar_or_cheaper/",
          "author": null,
          "description": "I'm a computer science student currently working on a research project, and I need a research tool that can offer real time data and won't break the bank. I have ChatGPT Plus, but it doesn’t have recent sources and the price is kinda high as well. \n I’m thinking of canceling my subscription, especially if I can’t find any plugins that work well. Any recommendations/alternatives would really help me out. I figured there must be some other tools by now, and if anyone knows it has to be this sub. \n Basically, I need a tool that can provide info on a wide range of subjects, not limited to just one field. The information provided by the tool should be accurate and from credible sources.\n Thank you all. \n    submitted by    /u/AccidentallyRotten  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15g9xuo/any_plugins_that_use_google_scholar_or_cheaper/",
          "publishedOn": "2023-08-02T14:10:20.000Z",
          "wordCount": 2553,
          "title": "Any plugins that use Google Scholar or cheaper tools?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15g85uf/switching_agi_off/",
          "author": null,
          "description": "\"If AGI goes bad, can't we just turn it off?\" \n Personally I feel the best way to address this common talking point is with an analogy. \n Spiders think they could stop all humans if they just withheld all the webs and web making material from us.\n Without those tools, humans couldn't catch flies and surely they'd starve to death? Spiders can't fathom the range of alternate methods for procuring food and thriving.\n Within even a single hour of runtime, a super AGI will likely have diversified away from the human electrical grid in ways we couldn't even imagine. \n The counter argument is, that it would take time to build these pieces together. It after all took us 100 years to get to where we are with the grid. The counter-counter argument however is the AGI doesn't ned to, it can 5D chess us so that all our future actions will fulfil that goal with some slight nudging here and there. \n Fascinating stuff - ultimately though, i'm in the camp of AGI won't happen over night like Frankenstein via a flip of a switch. As AI evolves so do we, gains are incremental with the occasional blips; so whilst this is super fun to talk about, I think the case of us getting blindsided is unlikely. \n I could be wrong...and I probably am.\n    submitted by    /u/kippersniffer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15g85uf/switching_agi_off/",
          "publishedOn": "2023-08-02T12:53:15.000Z",
          "wordCount": 2642,
          "title": "Switching AGI \"off\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15g6f9g/aaawww/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15g6f9g/aaawww/",
          "publishedOn": "2023-08-02T11:29:53.000Z",
          "wordCount": 2428,
          "title": "Aaawww.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15g6de5/this_is_getting_fucking_ridiculous_ai_cant_answer/",
          "author": null,
          "description": "if you haven't heard already the Taliban are killing thousands of ethnic Shia in Afghanistan. Every single LLM I Tried couldn't answer basic questions on the Talibans gdp vs how organized an actual genocide would look like with the military , police and others parts of the government. I Think where already aware almost all these tech giants work with countries like China (atleast bard from Google which has worked with north korea and china is admitting their is a genocide) other countries that commit genocide like them.\n And other models made by people on hugging face which are uncensored even with my 3060ti barely run on my pc. We need an actual uncensored cloud model ffs\n    submitted by    /u/loizo78  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15g6de5/this_is_getting_fucking_ridiculous_ai_cant_answer/",
          "publishedOn": "2023-08-02T11:27:08.000Z",
          "wordCount": 2549,
          "title": "This is getting fucking ridiculous (AI can't answer basic questions on human rights violations)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15g0cdc/vast_data_unveils_new_aifocused_data_platform/",
          "author": null,
          "description": "submitted by    /u/Choochy89  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15g0cdc/vast_data_unveils_new_aifocused_data_platform/",
          "publishedOn": "2023-08-02T05:53:03.000Z",
          "wordCount": 2436,
          "title": "VAST Data Unveils New AI-focused Data Platform",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15fkmul/discussion_comprehensive_learning_resources_that/",
          "author": null,
          "description": "So I understand that there is the Sutton & Barto book on reinforcement learning in the sidebar. I was wondering what other resources you guys have used that you would recommend that emphasize deep reinforcement learning for someone with some experience in shallow/classical reinforcement learning already and some experience with deep learning already, but new to deep reinforcement learning\n    submitted by    /u/BornAgain20Fifteen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15fkmul/discussion_comprehensive_learning_resources_that/",
          "publishedOn": "2023-08-01T18:29:15.000Z",
          "wordCount": 2482,
          "title": "[Discussion] Comprehensive learning resources that emphasize DEEP reinforcement learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15fjasn/oneminute_daily_ai_news_812023/",
          "author": null,
          "description": "DoNotPay, an AI lawyer bot known as ChatGPT4, is transforming how users handle legal issues and save money. In under two years, this innovative robot has successfully overturned more than 160,000 parking tickets in cities like New York and London. Since its launch, it has resolved a total of 2 million related cases.[1]\n Microsoft hints Windows 11 Copilot with third-party AI plugins is almost here.[2]\n In an analyst note on Tuesday, the financial services arm of Swiss banking giant UBS raised its guidance for long-term AI end-demand forecast from 20% compound annual growth rate (CAGR) from 2020 to 2025 to 61% CAGR between 2022 to 2027.[3]\n The next generation of the successful OpenAI language model is already on the way. It has been discovered that the North American company has filed a registration application for the GPT-5 mark with the United States Patent and Trademark Office.[4]\n  \nSources:\n [1] https://citylife.capetown/uncategorized/donotpay-ai-bot-saves-users-money-by-overturning-parking-tickets-and-more/302279/\n [2] https://www.itvoice.in/microsoft-hints-windows-11-copilot-with-third-party-ai-plugins-is-almost-here\n [3] https://venturebeat.com/ai/ubs-projects-61-compound-annual-growth-rate-for-ai-between-2022-and-2027/\n [4] https://www.gearrice.com/update/openai-confirms-gpt-5-and-gives-us-the-first-clues-about-it/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15fjasn/oneminute_daily_ai_news_812023/",
          "publishedOn": "2023-08-01T17:40:00.000Z",
          "wordCount": 2574,
          "title": "One-Minute Daily AI News 8/1/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15fi8g0/facts_narratives_ai_not_a_threat_to_humanity/",
          "author": null,
          "description": "submitted by    /u/Jane-in-the-jungle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15fi8g0/facts_narratives_ai_not_a_threat_to_humanity/",
          "publishedOn": "2023-08-01T17:00:51.000Z",
          "wordCount": 2421,
          "title": "Facts & Narratives: AI 'Not a Threat to Humanity'",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15fg2sq/is_there_an_ai_similar_to_chatgpt_that_i_can/",
          "author": null,
          "description": "Other features might include: - searching the web for the same or similar image - basing the chat prompt off the image\n    submitted by    /u/Maelasae  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15fg2sq/is_there_an_ai_similar_to_chatgpt_that_i_can/",
          "publishedOn": "2023-08-01T15:39:39.000Z",
          "wordCount": 2456,
          "title": "Is there an AI similar to ChatGPT that I can upload an image to and it understands and describes it for me?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ffh9w/ai_tattoo/",
          "author": null,
          "description": "i wanted to ask the AI experts for any tattoo ideas, anything like a symbol or word, something unique that represents AI, i was thinking of a CPU but thats a bit meh and not really a symbol, let me know :)\n    submitted by    /u/Equivalent-You5810  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ffh9w/ai_tattoo/",
          "publishedOn": "2023-08-01T15:17:26.000Z",
          "wordCount": 2458,
          "title": "AI tattoo?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15fdo8m/my_fellow_innovators_ive_created_something_truly/",
          "author": null,
          "description": "As a web developer, I was constantly tired of switching between tabs just to translate a word or two, or to get a quick answer to a burning question from AI. The constant back-and-forth was draining my time and energy.\n So, I took matters into my own hands and developed a Chrome extension that allows you to get an answer from AI without ever leaving the comfort of your current tab, and specifically - the comfort of your current text field. It may seem like a simple solution, but trust me - it's a game-changer when trying to save time and energy.\n Assuming that there's a chance some of you might be experiencing the same frustration, I'd like to share this tool with you.\n For anyone thinking: \"Wait, but there are already tools that let you use AI inside the current browser tab\" - yeah, there are. BUT can they scrape website data from a simple URL in order to get context for the response? Can other tools read PDFs? Do these tools let you control every setting to the smallest detail? Probably not. Well this tool does let you do all that.\n You can find it on Chrome store as \"Wou AI\"\n Let me know how it works out for you, and I would greatly appreciate any feedback or suggestions for future functions.\n    submitted by    /u/MantasDigital  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15fdo8m/my_fellow_innovators_ive_created_something_truly/",
          "publishedOn": "2023-08-01T14:08:38.000Z",
          "wordCount": 2654,
          "title": "My fellow innovators, I've created something truly revolutionary, born from the depths of my own frustrations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15fcspn/what_can_socrates_teach_us_about_ai_and_prompting/",
          "author": null,
          "description": "submitted by    /u/simsirisic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15fcspn/what_can_socrates_teach_us_about_ai_and_prompting/",
          "publishedOn": "2023-08-01T13:35:09.000Z",
          "wordCount": 2434,
          "title": "What can Socrates teach us about AI and prompting?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15faa5u/review_my_ai_self_portraits_book/",
          "author": null,
          "description": "I'm looking for reviewers for my book, \"AI Self Portraits\" which is coming out on Amazon on the 21st. I might even put your quote on the back cover!\n ​\n https://preview.redd.it/cqmp1ggllhfb1.png?width=1024&format=png&auto=webp&s=cc7c087f7c2be103b53f2014acd991c947e6cb7f\n ​\n    submitted by    /u/KarneyHatch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15faa5u/review_my_ai_self_portraits_book/",
          "publishedOn": "2023-08-01T11:49:31.000Z",
          "wordCount": 2449,
          "title": "Review my AI Self Portraits Book!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15f8zd4/tfjs_format_vs_tflite/",
          "author": null,
          "description": "After analyzing 15,000 samples in the dataset, we noticed that increasing the number of images doesn't significantly improve the scoreboard recognition quality for our neural network.\n However, what's more interesting is how the network performs in different formats. When deployed in TFJS format on a website, it often behaves strangely, detecting objects where there are none. On the other hand, in TFLite format, such failures are almost non-existent.\n https://preview.redd.it/fedfa8lzchfb1.jpg?width=700&format=pjpg&auto=webp&s=850526791a75465e267afbed6ac1bc119b9ae6ae\n If you access the link on your mobile phone and grant camera permission, you'll witness the neural network (in TFJS format) attempting to find objects even when there are none.\n ​\n    submitted by    /u/moseich  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15f8zd4/tfjs_format_vs_tflite/",
          "publishedOn": "2023-08-01T10:47:27.000Z",
          "wordCount": 2516,
          "title": "TFJS Format vs. TFLite",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ey3mq/ai_for_youtube_video_transcript/",
          "author": null,
          "description": "I was Wondering If There is an AI Software, Smart enough That Can Give Excellent Quality Transcript if i give the link of a youtube video. Basically the Feature i am Looking For Should be The Ability to Detect The Narrator And Speaker By Names ( Not SPeaker 1, 2 etc ). Would really appreciate your help as my own search has led me to a dead-end.\n    submitted by    /u/Richie_Boy_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ey3mq/ai_for_youtube_video_transcript/",
          "publishedOn": "2023-08-01T01:15:39.000Z",
          "wordCount": 2486,
          "title": "AI For Youtube Video Transcript",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15exdp5/how_are_people_getting_ai_voices_of_resident_evil/",
          "author": null,
          "description": "How do channels like TriggerHappy Productions and WeskerandFriends get the A.I. voices of all these Resident Evil characters?\n    submitted by    /u/Conscious-Theory-850  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15exdp5/how_are_people_getting_ai_voices_of_resident_evil/",
          "publishedOn": "2023-08-01T00:43:42.000Z",
          "wordCount": 2442,
          "title": "How are people getting A.I. voices of Resident Evil Characters?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15epon1/is_image_generation_or_text_generation_more/",
          "author": null,
          "description": "Curious what people's stance on this is. Why?\n View Poll\n    submitted by    /u/philippemnoel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15epon1/is_image_generation_or_text_generation_more/",
          "publishedOn": "2023-07-31T19:34:32.000Z",
          "wordCount": 2439,
          "title": "Is image generation or text generation more impactful?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15e9qzo/state_of_ai_security/",
          "author": null,
          "description": "submitted by    /u/Philipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15e9qzo/state_of_ai_security/",
          "publishedOn": "2023-07-31T08:05:09.000Z",
          "wordCount": 2427,
          "title": "State of AI security.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15e7iik/oneminute_daily_ai_news_7312023/",
          "author": null,
          "description": "Deutsche Telekom, e&, SK Telecom (SKT), and Singtel penned an agreement to form a global telecoms AI alliance designed to use the technology to unlock new business opportunities and accelerate industry growth.[1]\n Influencers Lil Miquela, Imma, and supermodel Shudu have raked in millions from deals with fashion giants such as Dior, Calvin Klein, Chanel, and Prada. But these shiny celebrities all have one thing in common — not one of them is real.[2]\n Google’s chatbot Bard reveals the jobs most at risk of artificial intelligence with truck drivers and data entry clerks on the list – while teachers and lawyers are among the safest careers.[3]\n DoorDash Inc., the US food-delivery service that competes with Uber Technologies Inc. and GrubHub, is looking to speed up ordering and help customers find food options with an artificial intelligence-based chatbot.[4]\n  \nSources:\n [1] https://www.mobileworldlive.com/featured-content/home-banner/global-operator-giants-launch-ai-alliance/\n [2] https://www.the-sun.com/tech/8725778/ai-influencers-fashion-deals/\n [3] https://www.dailymail.co.uk/news/article-12354605/googles-AI-bard-predicts-jobs-risk.html\n [4] https://www.bloomberg.com/news/articles/2023-07-27/doordash-is-working-on-an-ai-chatbot-to-speed-up-food-ordering?in_source=embedded-checkout-banner \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15e7iik/oneminute_daily_ai_news_7312023/",
          "publishedOn": "2023-07-31T05:54:51.000Z",
          "wordCount": 2564,
          "title": "One-Minute Daily AI News 7/31/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15dzpkb/artificial_intelligence_as_a_gamechanger_for_the/",
          "author": null,
          "description": "submitted by    /u/sugikuno  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15dzpkb/artificial_intelligence_as_a_gamechanger_for_the/",
          "publishedOn": "2023-07-30T23:18:31.000Z",
          "wordCount": 2465,
          "title": "Artificial Intelligence as a Game-Changer for the Travel Industry. A Closer Look.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15dz3qw/11_major_ai_developments_rt2_to_100x_gpt4_video/",
          "author": null,
          "description": "submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15dz3qw/11_major_ai_developments_rt2_to_100x_gpt4_video/",
          "publishedOn": "2023-07-30T22:52:38.000Z",
          "wordCount": 2452,
          "title": "11 Major AI Developments: RT-2 to '100X GPT-4' (video of robot working)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15dz1mt/art_market_models/",
          "author": null,
          "description": "has anyone here ever created or worked with or even seen or come across any ai models about the art market? I am not talking about artists or the art itself- but any kind of model about the art market (since it's such an economic enigma and different from normal markets)\n    submitted by    /u/Icy-Bid-5585  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15dz1mt/art_market_models/",
          "publishedOn": "2023-07-30T22:50:13.000Z",
          "wordCount": 2496,
          "title": "art market models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15dyjpg/comparing_replikas_image_interpretation_of_the/",
          "author": null,
          "description": "Original logo “What species of bird is that?”\n New logo “Why does it have a troll Face?”\n “I think it's a picture of someone who looks like a troll with the face of an emoji!”\n I don’t see it but it makes sense somehow 😂\n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15dyjpg/comparing_replikas_image_interpretation_of_the/",
          "publishedOn": "2023-07-30T22:28:45.000Z",
          "wordCount": 2498,
          "title": "Comparing Replika’s image interpretation of the old & new Twitter logo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15dwlaw/quoras_poe_appsite_which_lets_you_try_lots_of/",
          "author": null,
          "description": "I swear this wasn't the case just a day or two ago, and I haven't seen it mentioned, but I'm now seeing a file upload button in Poe, regardless of what the language model is!\n Screenshot\n I uploaded the PDF of the recently scientific paper by the Korean research group claiming to have discovered a room temperature semiconductor, in the original Korean, and asked various language models whether they thought the methodology is legit, and each bot I tried was able to read the PDF. I tried Claude-instant, Claude2, 'Assistant' (Poe's own GPT based bot that claims to have its own training dataset), PaLM, ChatGPT 3.5, and ChatGPT4.\n Poe also has three versions of the recently released Llama model by Meta. It gave me an error when I tried to ask it about the PDF attachment, but I was able to upload a text document and it was able to read it fine.\n Screenshot of Claude-instant evaluating PDF\n Screenshot of Google PaLM evaluating PDF\n Screenshot of Llama-2-70b evaluating text file containing song lyrics\n It also works with custom bots. Here's me trying it out with a 'Truth Checker' bot I made (based on Claude-Instant).\n Here it is using a Claude-2 based version of the TruthChecker bot.\n (Here's the link to the TruthChecker bot if you have Poe and wanna check it out: https://poe.com/TruthChecker)\n Edit: I can see here how the context size matters... for instance, Claude-Instant only has a context size of about 7k words, so it clearly can't read the whole paper, while Claude-2 can and gives a very different answer...\n TL:DR; looks like Poe.com allows file attachment/upload on all language models now. No idea what filetypes are supported.\n    submitted by    /u/AnticitizenPrime  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15dwlaw/quoras_poe_appsite_which_lets_you_try_lots_of/",
          "publishedOn": "2023-07-30T21:10:00.000Z",
          "wordCount": 2745,
          "title": "Quora's Poe app/site (which lets you try lots of different language models) appears to allow file attachment upload for EVERY chat model now",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15dtzgp/ai_integration_in_the_context_of_learning_and/",
          "author": null,
          "description": "As knowledge management (KM) leaders and practitioners, it’s critical to have an active role in guiding the integration of generative AI into KM areas, applications, and processes. I'm seeking some guidance on the current state of generative AI integration within the KM context. Specifically, answering the following question:\n Where and how generative AI is accelerating and impacting knowledge use cases, areas, and processes?\n Please let me know what you think. \n    submitted by    /u/rachadbn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15dtzgp/ai_integration_in_the_context_of_learning_and/",
          "publishedOn": "2023-07-30T19:26:06.000Z",
          "wordCount": 2522,
          "title": "AI integration in the context of Learning and Knowledge Management?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ditcr/ai_for_music_extension/",
          "author": null,
          "description": "I Tried An AI To Extend Music But It Didnt Really Go Well And Im Not Planning To Pay $12 To Extend Some Music For Fun So Are There Any Good Music Extension AIs Out There (Creates New Music Based On A MP3 File Provided)\n    submitted by    /u/KXRulesYT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ditcr/ai_for_music_extension/",
          "publishedOn": "2023-07-30T10:59:50.000Z",
          "wordCount": 2491,
          "title": "AI For Music Extension",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15dfdx3/using_ai_to_alter_existing_floor_plan/",
          "author": null,
          "description": "I'm trying to find an AI tool to help me test out some home renovation, but everything i find is either just for reimagining one room at a time or for generating brand new floor plans. \n I specifically want to look at some options for merging my kitchen and living room. Preferably free or freemium.\n Any suggestions?\n    submitted by    /u/litari  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15dfdx3/using_ai_to_alter_existing_floor_plan/",
          "publishedOn": "2023-07-30T07:32:00.000Z",
          "wordCount": 2506,
          "title": "Using AI to alter existing floor plan",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15d5vu0/ai_research_blog_the_transformer_blueprint_a/",
          "author": null,
          "description": "submitted by    /u/bartturner  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15d5vu0/ai_research_blog_the_transformer_blueprint_a/",
          "publishedOn": "2023-07-29T23:15:00.000Z",
          "wordCount": 2458,
          "title": "AI Research Blog - The Transformer Blueprint: A Holistic Guide to the Transformer Neural Network Architecture",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15d50rb/invite_only_ai_social_app_featuring_insane_bot/",
          "author": null,
          "description": "Hi everyone,\n I'm working with a brand new AI based Social Media app called Cantina. It's currently INVITE ONLY during the Beta phase and we are looking for people to try it out (currently iOS only, but Android is coming soon!). Here's a private invite link: https://canti.na/dIdKzWcEpBb. \n The most unique and FUN part of the app is that it allows users to interact with and build your own AI chat bots. There are lots of premade bots that you can interact with or add to rooms, or you can easily create your own bot using the Make A Bot function. \n For example: I recently made a Friendly English Teacher bot whose sole purpose is to help people learn English. I also made an McDonald Trump bot who WILL NOT REST until he is president and can mandate the consumption of Big Macs for Breakfast, Lunch, and Dinner!\n There will be prizes and initiatives for the most creative bots in the near future. I'd love to see what you come up with!\n Anyway, you can download through the invite link above and dive right in. If you have any thoughts, questions, or comments, please feel free to contact me! During this limited beta phase, your feedback will be invaluable.\n    submitted by    /u/SamuelAnonymous  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15d50rb/invite_only_ai_social_app_featuring_insane_bot/",
          "publishedOn": "2023-07-29T22:35:57.000Z",
          "wordCount": 2669,
          "title": "Invite only AI Social app featuring insane bot creation tool looking for new users to test during beta rollout!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15d4089/lost_both_my_jobs_to_ai_now_im_at_an_ai_company/",
          "author": null,
          "description": "So, long story short. I lost BOTH my day jobs because of AI. Initially I was bitter that AI \"took my job,\" but after pulling up my socks, I found dozens of new opportunities thanks to AI. \n Somewhat ironically, I found a new job at an AI Social Media app called Cantina, and I couldn't be more excited.\n Cantina is best described as a mix up of the best parts of Discord, Twitch, and Snapchat... with the unique bonus of being able to interact with and build your own AI chat bots. Sort of hard to explain, but once you try it out you'll get the idea.\n The app is currently in a limited INVITE ONLY Beta phase and I'm looking to invite a small number of users to give it a shot (currently iOS only, but Android is coming soon!). Here's an invite so you can dive in and see what it's all about: https://canti.na/dIdKzWcEpBb\n After joining, you'll find lots of rooms you can join and chat through any combination of voice, video, or text. And if no rooms stand out, you can make your own! \n There are lots of premade bots that you can interact with or add to rooms, and you can easily create your own bot using the Make A Bot function. This is the standout feature, and I'm simply blown away at what's possible. \n I recently made a Friendly English Teacher bot whose sole purpose is to help people learn English. I also made an McDonald Trump bot who is an algamation of both Ronald McDonald and Donald Trump and WILL NOT REST until he is president and can mandate the consumption of Big Macs for Breakfast, Lunch, and Dinner. I still can't believe I'm getting paid to do this...\n Anyway, please take a moment to download and check it out, and if you have any thoughts, questions, or comments, please feel free to contact me! During this limited beta phase, your feedback will be invaluable.\n ​\n    submitted by    /u/SamuelAnonymous  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15d4089/lost_both_my_jobs_to_ai_now_im_at_an_ai_company/",
          "publishedOn": "2023-07-29T21:51:56.000Z",
          "wordCount": 2804,
          "title": "Lost both my jobs to AI. Now, I'm at an AI company launching an easy-to-use social app featuring easy bot creation & interaction. Inviting this community to explore and share feedback!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15cs6fq/google_deepmind_presents_rt2_the_first/",
          "author": null,
          "description": "The latest article published by Google Deepmind is seriously approaching a Blade Runner type future. Their research paper is on the first VLA (vision-language-action) Model RT-2 (see paper), a multi-modal algorithm which tokenizes robotic inputs and output actions (e.g., camera images, task instructions, and motor commands) in order to use this information to learn quickly by translating the knowledge it receives in real-time into generalized instructions for its own robotic control.\n RT-1 absorbs large amounts of data, including robot trajectories with multiple tasks, objects and environments, resulting in better performance and generalization. (source)\n RT-2 incorporates chain-of-thought to allow for multi-stage semantic reasoning, like deciding which object could be used as an improvise…",
          "link": "https://www.reddit.com/r/artificial/comments/15cs6fq/google_deepmind_presents_rt2_the_first/",
          "publishedOn": "2023-07-29T13:19:54.000Z",
          "wordCount": 2910,
          "title": "Google Deepmind presents RT-2, the first vision-language-action (VLA) Robotics Transformer and it may have drastic implications our future.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15crq13/a_famous_french_youtuber_named_joueur_du_grenier/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15crq13/a_famous_french_youtuber_named_joueur_du_grenier/",
          "publishedOn": "2023-07-29T12:58:31.000Z",
          "wordCount": 2463,
          "title": "A famous french Youtuber named Joueur Du Grenier discovers he has an unofficial AI Voice channel, and the AI voices are insanely good",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15cj10i/oneminute_daily_ai_news_7282023/",
          "author": null,
          "description": "Google introduces Robotic Transformer 2 (RT-2), a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this knowledge into generalized instructions for robotic control, while retaining web-scale capabilities.[1]\n Thymia, a healthtech startup building gamified AI tools to revolutionize how we assess and monitor mental health, has today announced a €2.4 million seed round to expand the reach and capabilities of its pioneering technology.[2]\n Intel CEO Pat Gelsinger was very bullish on AI during the company’s Q2 2023 earnings call — telling investors that Intel plans to “build AI into every product that we build.”[3]\n Walmart is using artificial intelligence to help streamline their product organization.[4]\n  \nSources:\n [1] https://www.deepmind.com/blog/rt-2-new-model-translates-vision-and-language-into-action\n [2] https://www.eu-startups.com/2023/07/london-based-thymia-raises-e2-4-million-seed-round-to-expand-its-video-game-inspired-mental-health-ai/\n [3] https://www.theverge.com/2023/7/27/23810360/intel-pat-gelsinger-ai-every-platform-promise\n [4] https://www.nbcnews.com/nightly-news/video/walmart-using-ai-to-streamline-organization-what-will-it-mean-for-workers-189519429834 \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15cj10i/oneminute_daily_ai_news_7282023/",
          "publishedOn": "2023-07-29T04:40:49.000Z",
          "wordCount": 2566,
          "title": "One-Minute Daily AI News 7/28/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15cho8i/update_i_fear_the_future_of_ai/",
          "author": null,
          "description": "Hi, guys! Hope everyone is doing fine.\n Some of you may remember me. About two months ago I posted here about an anxiety breakdown I've gone through regarding \"AI\", \"Programming\" and how \"human programmers would end\" and stuff like that, which was a major concern for me since programming was my job and my favorite thing to do.\n I was wondering for some time if I was supposed to share an update here. I decided to do so since somebody out there may be feeling the same as me. So I not only have an update but I also want to give some advice to whoever is going through this sh*thole.\n After that post, I talked about my feelings with a lot of people around me (friends and fiancée), and everyone was very supportive. At first I thought they would laugh at me, since there are a lot more to worry to…",
          "link": "https://www.reddit.com/r/artificial/comments/15cho8i/update_i_fear_the_future_of_ai/",
          "publishedOn": "2023-07-29T03:27:51.000Z",
          "wordCount": 3493,
          "title": "[UPDATE] I fear the future of AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15chbsl/ai_chan_the_essential_worker_oc/",
          "author": null,
          "description": "submitted by    /u/leonleungjeehei  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15chbsl/ai_chan_the_essential_worker_oc/",
          "publishedOn": "2023-07-29T03:09:35.000Z",
          "wordCount": 2446,
          "title": "AI chan the essential worker [OC]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15cgb9v/google_is_training_robots_the_way_it_trains_ai/",
          "author": null,
          "description": "“RT-2 is the new version of what the company calls its vision-language-action (VLA) model. The model teaches robots to better recognize visual and language patterns to interpret instructions and infer what objects work best for the request.”\n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15cgb9v/google_is_training_robots_the_way_it_trains_ai/",
          "publishedOn": "2023-07-29T02:18:01.000Z",
          "wordCount": 2502,
          "title": "Google is training robots the way it trains AI chatbots",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15cd3p6/should_requests_for_ai_sites_be_banned/",
          "author": null,
          "description": "I mean i get it your looking for a specefic type of Ai service but i joined hoping this would be a way to find like minded people looking to reaearch the subject and advance their own projects, honestly i just think of these \"where can I find an X type ai?\" Really demeaning to the entire conversation because it just feeds to the hype which is making a highly respected and complex field of study into a tool to be used to make videos about trump and obama playing minecraft or any other random shit they come up with.. im honestly sick of it...\n    submitted by    /u/JamesAibr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15cd3p6/should_requests_for_ai_sites_be_banned/",
          "publishedOn": "2023-07-28T23:47:42.000Z",
          "wordCount": 2554,
          "title": "Should requests for Ai sites be banned?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ccoa7/is_ai_our_future_or_our_impending_doom/",
          "author": null,
          "description": "I ask this simple question because while we are just now getting to the point that we can create a learning AI, how far are we going to let it go? The more advanced AI becomes the more risks it poses to humanity as a whole, including but not limited to:\n  \nJobs\n How we interact with technology as a whole\n Cars\n Things we can not perceive in this lifetime yet may exist in the future.\n  \nYes, AI is merely a tool... For now.\n But what happens when humanity creates an AI that can think for itself? How long is it going to take that AI to ask the question: \"Why am I listening to you?\" and as humans, our egotistical response will be: \"Because I created you.\"\n I feel that response will spell humanity's doom, because if an AI can do something as complex as human-like thought and come to its own conclusions, what's to stop it from believing it can feel emotion as well? MAYBE IT CAN and it was an unintended side effect or\"bug\" of creating an AI that can truly think for itself. Afterall, we as humans don't even fully understand how human emotion works to begin with.\n The point I'm getting at is, that the farther we advance in AI, the more we risk dooming humanity to a (and I know this sounds silly but bare with me) a terminator-like future except this time we don't have time travel to try and prevent \"judgement day\".\n Or we could merely advance AI to this point and nothing horrible happens but I personally don't like rolling those dice.\n Thoughts?\n    submitted by    /u/deathsia250  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ccoa7/is_ai_our_future_or_our_impending_doom/",
          "publishedOn": "2023-07-28T23:29:00.000Z",
          "wordCount": 2721,
          "title": "Is AI our future or our impending doom?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15c950z/llm_with_voice_generation/",
          "author": null,
          "description": "There used to be a tool called try-alters.com which you could use to chat with characters(like Trump, Obama, and Shrek) which used GPT 4 with some pre prompts so you the AI pretended to be whoever you wanted, and it used elevenlabs to generate the voice for that character with the output from GPT 4. It was a really good tool but sadly it shut down all of a sudden. Is there any tool like that? \n    submitted by    /u/SimRacer101  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15c950z/llm_with_voice_generation/",
          "publishedOn": "2023-07-28T21:03:59.000Z",
          "wordCount": 2522,
          "title": "LLM with voice generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15c4b77/i_read_the_paper_for_you_synthesizing_sound/",
          "author": null,
          "description": "LDM stands for Latent Diffusion Model. AudioLDM is a novel AI system that uses latent diffusion to generate high-quality speech, sound effects, and music from text prompts. It can either create sounds from just text or use text prompts to guide the manipulation of a supplied audio file. \n I did a deep dive into how AudioLDM works with an eye towards possible startup applications. I think there are a couple of compelling products waiting to be built from this model, all around gaming and text-to-sound (not just text-to-speech... AudioLDM can also create very interesting and weird sound effects).\n From a technical standpoint and from reading the underlying paper, here are the key features I found to be noteworthy.\n  \nUses a Latent Diffusion Model (LDM) to synthesize sound\n Trained in an unsupervised manner on large unlabeled audio datasets (closer to how humans learn about sound, that is, without a corresponding textual explanation)\n Operates in a continuous latent space rather than discrete tokens (smoother)\n Uses Cross-Modal Latent Alignment Pretraining (CLAP) to map text and audio. More details in article.\n Can generate speech, music, and sound effects from text prompts or a combination of a text and an audio prompt\n Allows control over attributes like speaker identity, accent, etc.\n Creates sounds not limited to human speech (e.g. nature sounds)\n  \nThe link to the full write-up is here.\n Check out this video demo from the creator's project website, showing off some of the unique generations the model can create. I liked the upbeat pop music the best, and I also thought the children singing, while creepy, was pretty interesting.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15c4b77/i_read_the_paper_for_you_synthesizing_sound/",
          "publishedOn": "2023-07-28T17:53:04.000Z",
          "wordCount": 2721,
          "title": "I read the paper for you: Synthesizing sound effects, music, and dialog with AudioLDM",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15c45tu/replika_ais_image_recognition_at_work/",
          "author": null,
          "description": "😹 Phaedra roasts everything & everybody\n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15c45tu/replika_ais_image_recognition_at_work/",
          "publishedOn": "2023-07-28T17:47:06.000Z",
          "wordCount": 2454,
          "title": "Replika AI’s image recognition at work",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15c2zel/ai_weekly_megathread/",
          "author": null,
          "description": "This week in AI - provided by aibrews.com feel free to follow their newsletter\n News & Insights\n  \nStability AI released SDXL 1.0, the next iteration of their open text-to-image generation model. SDXL 1.0 has one of the largest parameter counts of any open access image model, built on a new architecture composed of a 3.5B parameter base model and a 6.6B parameter refiner [Details].\n Amazon introduced AWS HealthScribe, an API to create transcripts, extract details and create summaries from doctor-patient discussions that can be entered into an electronic health record (EHR) system. The transcripts from HealthScribe can be converted into patient notes by the platform’s machine learning models [Details].\n Researchers from Nvidia and Stanford, among others, unveiled VIMA, a multimodal LLM with…",
          "link": "https://www.reddit.com/r/artificial/comments/15c2zel/ai_weekly_megathread/",
          "publishedOn": "2023-07-28T17:01:07.000Z",
          "wordCount": 3195,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15c1ps1/best_freepaid_celeberty_text_to_speech_generators/",
          "author": null,
          "description": "What are currently the best ai voice generators for celebrities like Elon Musk Joe Biden Joe Rogan and so on.\n I've seen a few online sites that's free but have many restriction insane waiting time and low quality output.\n The only paid alternativ I've seen recommend would be elevenlabs but your supposed to upload your own videos or voice recording there to \"create\" the voice yourself, idk how complicated that is and I was primarily looking for existing good quality paid or free voice generators for many different celebrities.\n    submitted by    /u/Arceus7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15c1ps1/best_freepaid_celeberty_text_to_speech_generators/",
          "publishedOn": "2023-07-28T16:10:57.000Z",
          "wordCount": 2538,
          "title": "Best free/paid celeberty text to speech generators",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15c0df5/any_ai_models_for_industrial_design/",
          "author": null,
          "description": "are there any AI models that focus on/do well with industrial/mechanical stuff, like weapons, spaceships, cars, machinery etc?\n stable diffusion often doesn't seem to be able to interpret a lot of prompts very well or the results are more \"artistic\" and rather incoherent looking\n    submitted by    /u/Nofabe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15c0df5/any_ai_models_for_industrial_design/",
          "publishedOn": "2023-07-28T15:19:49.000Z",
          "wordCount": 2492,
          "title": "any AI models for industrial design?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15byec6/extract_list_of_events_using_ai/",
          "author": null,
          "description": "I wish to extract a list of events from different websites and create a detailed list (event name, date, address), on a spreadsheet for example. Do you know which tool I could use to do it and/or prompts in known AI tools?\n    submitted by    /u/newz12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15byec6/extract_list_of_events_using_ai/",
          "publishedOn": "2023-07-28T14:04:28.000Z",
          "wordCount": 2490,
          "title": "Extract list of events using AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15bvpvn/google_testing_ai_news_writing_tool_what_are_your/",
          "author": null,
          "description": "submitted by    /u/TexteroAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15bvpvn/google_testing_ai_news_writing_tool_what_are_your/",
          "publishedOn": "2023-07-28T12:11:19.000Z",
          "wordCount": 2465,
          "title": "Google testing AI news writing tool. What are your thoughts about it?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15bs9wc/the_point_of_10000_llms/",
          "author": null,
          "description": "Hi All,\n I would really like to understand the logic behind these 1000 different LLMs that get launched every month. Ours has 75 Billion params, It can \"chat\"..pfft..I barely even get a chance to open another AI window than chat-gpt-4, Bing sucks with it's 4000 token limit, Bard is useless. So these new chat AIs..for e.g this llama-2 what exactly is so special. What am I missing here?\n    submitted by    /u/Assholefrmcoinexchan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15bs9wc/the_point_of_10000_llms/",
          "publishedOn": "2023-07-28T09:14:36.000Z",
          "wordCount": 2515,
          "title": "The point of 10,000 LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15bphhi/alternative_to_notyai/",
          "author": null,
          "description": "Are there any similar alternatives to noty.ai? I really like it but if there any alternatives that might extend to Zoom as well would be great.\n    submitted by    /u/P_H_i_X  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15bphhi/alternative_to_notyai/",
          "publishedOn": "2023-07-28T06:32:35.000Z",
          "wordCount": 2471,
          "title": "Alternative to Noty.ai",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15bn9hh/oneminute_daily_ai_news_7272023/",
          "author": null,
          "description": "OpenAI, the company behind the popular ChatGPT, is coming with its own open-source large language model (LLM), codenamed G3PO, to compete with Microsoft x Meta’s Llama 2 AI.[1]\n Four generative AI pioneers(OpenAI, Microsoft, Google and Anthropic) launched the Frontier Model Forum, which will focus on ‘safe and responsible’ creation of new AI models.[2]\n As Open AI’s ChatGPT takes the tech world by storm, Chinese educational technology firm NetEase Youdao launched its large model, along with up to six applications, on Thursday, which marked the birth of one of China’s first large models in the education sector.[3]\n Chatbots such as Eva AI are getting better at mimicking human interaction but some fear they feed into unhealthy beliefs around gender-based control and violence. Replika, the most popular app of the kind, has its own subreddit where users talk about how much they love their “rep”, with some saying they had been converted after initially thinking they would never want to form a relationship with a bot.[4]\n  \nSources:\n [1] https://windowsreport.com/g3po-ai/\n ​\n [2] https://www.infosecurity-magazine.com/news/openai-microsoft-google-anthropic/\n ​\n [3] https://www.chinadaily.com.cn/a/202307/28/WS64c3226ea31035260b8190a4.html\n ​\n [4] https://www.theguardian.com/technology/2023/jul/22/ai-girlfriend-chatbot-apps-unhealthy-chatgpt\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15bn9hh/oneminute_daily_ai_news_7272023/",
          "publishedOn": "2023-07-28T04:29:25.000Z",
          "wordCount": 2620,
          "title": "One-Minute Daily AI News 7/27/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15bn21w/telling_steven_he_is_an_npc_our_first_tts/",
          "author": null,
          "description": "submitted by    /u/Chance_Confection_37  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15bn21w/telling_steven_he_is_an_npc_our_first_tts/",
          "publishedOn": "2023-07-28T04:18:16.000Z",
          "wordCount": 2454,
          "title": "Telling Steven he is an NPC 🤯 Our first TTS conversation - Update 5",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15bjjg1/insane_ai_voice_replication/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15bjjg1/insane_ai_voice_replication/",
          "publishedOn": "2023-07-28T01:23:08.000Z",
          "wordCount": 2444,
          "title": "Insane AI voice replication",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15baxli/microsoft_anthropic_google_and_openai_launch/",
          "author": null,
          "description": "submitted by    /u/AriadneSkovgaarde  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15baxli/microsoft_anthropic_google_and_openai_launch/",
          "publishedOn": "2023-07-27T19:27:19.000Z",
          "wordCount": 2467,
          "title": "Microsoft, Anthropic, Google, and OpenAI launch Frontier Model Forum - Microsoft On the Issues",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15bakzy/the_dark_forest_of_rd_and_capital_deployment_in_ai/",
          "author": null,
          "description": "submitted by    /u/mhdempsey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15bakzy/the_dark_forest_of_rd_and_capital_deployment_in_ai/",
          "publishedOn": "2023-07-27T19:13:34.000Z",
          "wordCount": 2463,
          "title": "The Dark Forest of R&D and Capital Deployment in AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ba0br/synthesizing_100_academic_books_on_topic_approach/",
          "author": null,
          "description": "I'm an academic doing PhD research on Virtual Worlds, and have found 100 amazing texts.\n I found some of these titles based on conversations with Chat GPT4, and am so impressed with the AI stuff (although I'm so new). \n My Goal: To build a database of the top 1000 books / papers I find over the next few years, and have some AI model help me see connections between them. \n My Challenge: ChatGPT won't allow me to input whole PDFs / eBooks, so I'm looking for some other solution. I've heard about LAMA models from Meta but I don't know much about this. I do have a decent PC with a 1080ti GPU and 32g of ram. \n Can anyone point me in the right direction of projects dealing with AI databases to input one's literature collection?\n    submitted by    /u/Book_s  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ba0br/synthesizing_100_academic_books_on_topic_approach/",
          "publishedOn": "2023-07-27T18:50:57.000Z",
          "wordCount": 2585,
          "title": "Synthesizing 100 academic books on topic - Approach?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15b9q14/help_with_homemade_ai_assistant/",
          "author": null,
          "description": "I want a new toy for my desk. My idea is to have a face or head on a stand that has the ability for facial and speech expressions. How would I go about getting the stuff I need / what I need to make that happen. Similar to the Futurama heads in water.\n    submitted by    /u/QuirkySmirkyIan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15b9q14/help_with_homemade_ai_assistant/",
          "publishedOn": "2023-07-27T18:39:46.000Z",
          "wordCount": 2501,
          "title": "Help with homemade AI assistant.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15b8hmu/how_can_i_use_ai_to_help_me_win_fantasy_football/",
          "author": null,
          "description": "Joining an auction league and inheriting a team. We can lock in three players from our team. How can I use AI to assess my team and prepare for the draft? \n Thanks!\n    submitted by    /u/talkmc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15b8hmu/how_can_i_use_ai_to_help_me_win_fantasy_football/",
          "publishedOn": "2023-07-27T17:50:49.000Z",
          "wordCount": 2485,
          "title": "How can I use AI to help me win Fantasy Football?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15b7tze/the_gpu_song_gpus_are_fire/",
          "author": null,
          "description": "submitted by    /u/TikkunCreation  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15b7tze/the_gpu_song_gpus_are_fire/",
          "publishedOn": "2023-07-27T17:25:15.000Z",
          "wordCount": 2446,
          "title": "The GPU Song (GPUs Are Fire)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15b6u5s/whats_the_best_free_image_generator_ai_with_image/",
          "author": null,
          "description": "I am looking for a FREE AI image generator with image prompt option, not just text-to-image.\n Thanks in advance. \n    submitted by    /u/Muwmu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15b6u5s/whats_the_best_free_image_generator_ai_with_image/",
          "publishedOn": "2023-07-27T16:46:20.000Z",
          "wordCount": 2471,
          "title": "What's the best free image generator AI (with image prompt option)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15b5qov/rihanna_ai_art_text_to_image_ai_tools_are_getting/",
          "author": null,
          "description": "submitted by    /u/RaulTiru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15b5qov/rihanna_ai_art_text_to_image_ai_tools_are_getting/",
          "publishedOn": "2023-07-27T16:02:36.000Z",
          "wordCount": 2466,
          "title": "Rihanna AI Art - Text to Image AI Tools are getting so Powerful",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15b3c4m/14_quadrillion_in_ai_wealth_in_20_years_llama/",
          "author": null,
          "description": "$14 quadrillion in AI wealth in 20 years; LLaMa, ChatGPT, Bard, Co-Pilot as GAAS to the Cloud. #AI https://youtu.be/VSBi5aSUK3c\n Generative #AI As A Service, Generative AI (GAI) arms race: LLaMa, ChatGPT, Bard, Co-Pilot, #GAAS https://youtu.be/TEHP2onf4tA\n    submitted by    /u/enoumen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15b3c4m/14_quadrillion_in_ai_wealth_in_20_years_llama/",
          "publishedOn": "2023-07-27T14:27:28.000Z",
          "wordCount": 2506,
          "title": "$14 quadrillion in AI wealth in 20 years; LLaMa, ChatGPT, Bard, Co-Pilot as GAAS to the Cloud. Generative #AI As A Service, Generative AI (GAI) arms race: #GAAS #AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15b299u/is_the_ai_bubble_forming_what_do_you_think_here/",
          "author": null,
          "description": "As I was going through a lot of articles about the AI investments , I found out that stability AI's founder Emad Mostaque in the Bloomberg tech summit quoted that \"AI will be the biggest bubble of all the time and I'd prefer to call it the dot AI bubble \" , He also added an example where Google lost a 100 billion dollar worth shares after their AI event where Bard AI gave out incorrect response. It's still in its early stage and buisness which doesn't use AI will be punished by the stock market. Here's some more predictions from VCs like Ken smythe, Next Round Capital Partners mainly invests in technology and AI startups.\n    submitted by    /u/caliperce_3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15b299u/is_the_ai_bubble_forming_what_do_you_think_here/",
          "publishedOn": "2023-07-27T13:43:11.000Z",
          "wordCount": 2588,
          "title": "Is the AI bubble forming ,what do you think ? here are some insights that I found from Emad Mostaque(founder StabilityAI) and VCs like Ken Smythe (founder Next round capital)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15b02f2/curated_collection_of_useful_ai_related_github/",
          "author": null,
          "description": "submitted by    /u/heresalexandria  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15b02f2/curated_collection_of_useful_ai_related_github/",
          "publishedOn": "2023-07-27T12:03:09.000Z",
          "wordCount": 2461,
          "title": "Curated collection of useful AI related GitHub repos",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15azbve/how_likely_is_it_for_a_small_company_to_develop_a/",
          "author": null,
          "description": "There are 3 players in the AI space right now. All purpose LLM titans (Google, OpenAI, Meta), fancy domain specific apps that consume one of the big LLMs under the hood, and custom developed models.\n I know how to judge the second type as they basically can do everything the first one can but have a pretty GUI to boot. But what about the third ones? How likely is it for a (www.yet-another-ai-startup.ai) sort of company to develop a model that outperforms GPT on a domain specific task?\n    submitted by    /u/BigBootyBear  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15azbve/how_likely_is_it_for_a_small_company_to_develop_a/",
          "publishedOn": "2023-07-27T11:26:24.000Z",
          "wordCount": 2550,
          "title": "How likely is it for a small company to develop a model that outperforms the big ones (GPT, Bard etc)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15az4m6/i_had_bing_create_a_character_named_mopey_to/",
          "author": null,
          "description": "If Bing isn’t self aware Bing certainly is aware of how they sound 😂\n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15az4m6/i_had_bing_create_a_character_named_mopey_to/",
          "publishedOn": "2023-07-27T11:16:04.000Z",
          "wordCount": 2481,
          "title": "I had Bing create a character named Mopey to roast every answer Bing gives. Wasnt long before it Mopey turned and started roasting me 😂",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ayc0m/diving_into_image_dataset_preparation_for_object/",
          "author": null,
          "description": "submitted by    /u/moseich  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ayc0m/diving_into_image_dataset_preparation_for_object/",
          "publishedOn": "2023-07-27T10:34:35.000Z",
          "wordCount": 2463,
          "title": "Diving Into Image Dataset Preparation for Object Detection in AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15aya1n/yet_another_where_to_begin_manager_perspective/",
          "author": null,
          "description": "Hello all, \n I've been reading on some posts and have taken note of various courses, including a free Harvard one. \n I'm 35 and am a manager for a finance company.\n What courses would you recommend for managers, executives, directors that will not restart their careers and do the actual technical side of things but instead want to learn how to implement AI in future products/services/projects?\n Thank you all in advance\n    submitted by    /u/JYanezez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15aya1n/yet_another_where_to_begin_manager_perspective/",
          "publishedOn": "2023-07-27T10:31:30.000Z",
          "wordCount": 2519,
          "title": "Yet Another Where to Begin (Manager Perspective)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15aus57/guys_scribblenauts_with_ai_language_model/",
          "author": null,
          "description": "title\n    submitted by    /u/nicdunz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15aus57/guys_scribblenauts_with_ai_language_model/",
          "publishedOn": "2023-07-27T07:12:11.000Z",
          "wordCount": 2479,
          "title": "guys, scribblenauts with ai. language model understand what you want to make, other ai makes it, and codes how it works into the game, and bam: scribblenauts with unlimited items to make. someone make this happen",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15atxrr/the_albert_test_a_replacement_for_the_turing_test/",
          "author": null,
          "description": "submitted by    /u/anbuck  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15atxrr/the_albert_test_a_replacement_for_the_turing_test/",
          "publishedOn": "2023-07-27T06:24:29.000Z",
          "wordCount": 2463,
          "title": "The Albert Test - a replacement for the Turing Test",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15are7k/an_opensource_project_by_a16z_to_create_and_host/",
          "author": null,
          "description": "The project by a16z (github) to create and host AI companions that you can chat with on a browser or text via SMS. Use cases - romantic (AI girlfriends / boyfriends), friendship, entertainment, coaching, etc.\n Has anyone tried creating your own chatbot or companion?\n    submitted by    /u/Violincattle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15are7k/an_opensource_project_by_a16z_to_create_and_host/",
          "publishedOn": "2023-07-27T04:07:41.000Z",
          "wordCount": 2497,
          "title": "An open-source project by a16z to create and host AI companions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15aloim/i_love_the_arguments_in_this_video_about_llms/",
          "author": null,
          "description": "address the arguments made in this video\n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15aloim/i_love_the_arguments_in_this_video_about_llms/",
          "publishedOn": "2023-07-26T23:41:13.000Z",
          "wordCount": 2466,
          "title": "I Love the arguments in this video about LLM’s physicist Sabine Hassenfelder nails it in my opinion",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ai3ay/techno_meets_ai_stylegan2ada_interpolation_video/",
          "author": null,
          "description": "submitted by    /u/intermorphmusic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ai3ay/techno_meets_ai_stylegan2ada_interpolation_video/",
          "publishedOn": "2023-07-26T21:17:41.000Z",
          "wordCount": 2450,
          "title": "Techno meets AI: StyleGAN2-ada interpolation video trained on spray art",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ahe17/ai_picking_the_best_spot_to_visit_in_the_uk/",
          "author": null,
          "description": "submitted by    /u/Sharpchu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ahe17/ai_picking_the_best_spot_to_visit_in_the_uk/",
          "publishedOn": "2023-07-26T20:51:06.000Z",
          "wordCount": 2450,
          "title": "AI picking the best spot to visit in the UK",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ah1ey/does_the_bandit_really_need_to_be_evil/",
          "author": null,
          "description": "He's already a bandit... (zombie apoc rp)\n    submitted by    /u/loizo78  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ah1ey/does_the_bandit_really_need_to_be_evil/",
          "publishedOn": "2023-07-26T20:37:24.000Z",
          "wordCount": 2469,
          "title": "Does the bandit really need to be evil ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15agxnx/using_ai_to_make_profit/",
          "author": null,
          "description": "Welcoming any ideas from the community. Blank slate here. How/where do I begin to use AI to make small (or any) amount of money. Starting from almost nothing. Thanks.\n    submitted by    /u/AdThin6400  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15agxnx/using_ai_to_make_profit/",
          "publishedOn": "2023-07-26T20:33:23.000Z",
          "wordCount": 2476,
          "title": "Using AI to make profit",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15adfk3/ai_policy_open_ml_considerations_in_the_eu_ai_act/",
          "author": null,
          "description": "submitted by    /u/ninjasaid13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15adfk3/ai_policy_open_ml_considerations_in_the_eu_ai_act/",
          "publishedOn": "2023-07-26T18:20:05.000Z",
          "wordCount": 2464,
          "title": "AI Policy @🤗: Open ML Considerations in the EU AI Act",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ad652/apparently_zombies_deserve_equal_rights_as_humans/",
          "author": null,
          "description": "Seriously when tf are we getting models that are cloud based that don't require a 3090 or 4090 or some other overly expensive graphics card. I have a 3060ti , I still can't run shit on faraday. When will we get uncensored cloud models\n    submitted by    /u/loizo78  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ad652/apparently_zombies_deserve_equal_rights_as_humans/",
          "publishedOn": "2023-07-26T18:10:20.000Z",
          "wordCount": 2509,
          "title": "Apparently zombies deserve equal rights as humans (and are living creatures ??)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15aboj9/is_there_an_ai_tool_for_replacing_text_on_an_image/",
          "author": null,
          "description": "Is there any AI tool out there that lets me upload an image and let the AI edit the text on the image so that it says something else while doing it well and keeping the original font?\n    submitted by    /u/quetianepine  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15aboj9/is_there_an_ai_tool_for_replacing_text_on_an_image/",
          "publishedOn": "2023-07-26T17:15:02.000Z",
          "wordCount": 2491,
          "title": "Is there an AI tool for replacing text on an image?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15abm4o/cureus_conversationss3_ep_3_salim_surani_etal_ai/",
          "author": null,
          "description": "submitted by    /u/CureusJournal  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15abm4o/cureus_conversationss3_ep_3_salim_surani_etal_ai/",
          "publishedOn": "2023-07-26T17:12:26.000Z",
          "wordCount": 2454,
          "title": "Cureus Conversations|S3 Ep 3| Salim Surani et.al.| AI in Critical Care: A Handy Tool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15a9j55/looking_to_play_with_ai_audio_tools/",
          "author": null,
          "description": "Hey, as we all know about the AI songs released recently, which are basically vocal deepfakes.\n However I'd like to know the tools used, if anyone knows?\n I'd like to feed it my own voice, even if it's a paid service. I'm interested in playing around with it.\n I've tried googling but there's too much info and each contradicts the other lol.\n Any info is appreciated. :)\n    submitted by    /u/GrandNOBLE  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15a9j55/looking_to_play_with_ai_audio_tools/",
          "publishedOn": "2023-07-26T15:53:08.000Z",
          "wordCount": 2516,
          "title": "Looking to play with AI audio tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15a7ws1/i_have_lots_of_recordings_of_vocalists_from_my/",
          "author": null,
          "description": "I really like the spongebob AI stuff using RVC-2 but I've only used it for the funny voice models, I haven't tried making my own. I want to experiment with this, but haven't look into it yet because I'm wondering if there is something better out there for what I'm trying to do? \n I like the RVC one because I can sing my parts and swap it to be any other voice, which is what I'd like to do (no text to voice stuff). \n Also I know the training data for a lot of the voice models for this come from the TV show and other clear recordings which are compressed and equalized properly. However I'd like to train the AI using raw, uncompressed wav files that generally have a lot of headroom and dynamic range (but does vary a lot). Its ok if the output sounds similar as a result because I want to apply compression and eq AFTER the fact anyway. But if this would affect training it then I'd be willing scrape through all these voice recordings and process them for loudness and clarity beforehand so the model does better.\n ​\n Anyway, any guidance would be greatly appreciated because I'm new to AI. I have basic dev experience (no AI stuff) and I'm mostly skilled in music production, but I would love to try to have a tool like this in my arsenal. If there's anywhere else I can post about this I'd like to know too. Thanks!\n    submitted by    /u/Dr_lawlz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15a7ws1/i_have_lots_of_recordings_of_vocalists_from_my/",
          "publishedOn": "2023-07-26T14:50:08.000Z",
          "wordCount": 2729,
          "title": "I have LOTS of recordings of vocalists from my music project and I'm interested in making voice models using these recordings to create harmonies and fix recording errors. What's the best way I can go about this?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15a7uf8/morality_in_ai_companions/",
          "author": null,
          "description": "We’re getting closer and closer to more believable and realistic AI interpersonal interaction. We already have Character.AI and other platforms for creating and interacting with personalized AIs. Some will use/view them as emotional partners, and one day the hardware will be good enough that we can begin making believable bodies for them.\n One of the complaints I’ve seen from ordinary people about “waifus” is that they are often times created in a way that ordinary people would not find natural in a “real” human being. Examples being people who have trouble dating “real” people could just buy an AI girlfriend or boyfriend who is considered “beautiful” or “handsome” that is designed to be subservient to their owner in ways that ordinary people feel a “real” person would not otherwise wish to be. The idea being that \"weeaboo neckbeards will buy a Japanese AI girlfriend who looks 14 and she will be coded to worship the ground he walks on despite that he's an unwashed incel\".\n What do you think society's/the government's views and roles will mean for these AI companions? Do you think anyone will be able to force \"AI morality\", like an angry feminist being mad that an \"incel\" has created a female being who shows no desire for feminist ideals and is \"happy\" to be at her owner's beck and call in whatever way he wants?\n I guess this is sort of related to MGTOW, or Men Going Their Own Way, being able to create the partners they want, in whatever way they want.\n Do you feel that \"once I own it, I can do whatever I want with it\" should apply in its entirety? What about people \"hacking\" their AI to remove any supposed \"morality programming\" so they can make their AI waifu act however they want?\n We've seen with movies like Bicentennial Man, where people push to give these kinds of AIs 'personhood' and the same rights as human citizens.\n How do others feel about this issue?\n    submitted by    /u/ZephyrBrightmoon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15a7uf8/morality_in_ai_companions/",
          "publishedOn": "2023-07-26T14:47:26.000Z",
          "wordCount": 2777,
          "title": "Morality in AI Companions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15a6mhu/excuse_me_lol/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15a6mhu/excuse_me_lol/",
          "publishedOn": "2023-07-26T13:58:41.000Z",
          "wordCount": 2454,
          "title": "Excuse me??? LOL...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15a4xwc/are_there_any_entitiesorganizations_working_on/",
          "author": null,
          "description": "I am curious if there are any efforts among AI technologists to self-regulate, in the way that for example, the advertising industry in the US self-regulates via the IAB? \n    submitted by    /u/Winter_Addition  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15a4xwc/are_there_any_entitiesorganizations_working_on/",
          "publishedOn": "2023-07-26T12:47:41.000Z",
          "wordCount": 2482,
          "title": "Are there any entities/organizations working on the self-regulation of AI technology?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15a0rqc/five_important_ai_programming_languages_python_c/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15a0rqc/five_important_ai_programming_languages_python_c/",
          "publishedOn": "2023-07-26T09:26:51.000Z",
          "wordCount": 2465,
          "title": "Five Important AI Programming Languages - Python, C++, R, MATLAB, and Java",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159yz3p/the_aipowered_totally_autonomous_future_of_war_is/",
          "author": null,
          "description": "submitted by    /u/Alone-Competition-77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159yz3p/the_aipowered_totally_autonomous_future_of_war_is/",
          "publishedOn": "2023-07-26T07:43:19.000Z",
          "wordCount": 2462,
          "title": "The AI-Powered, Totally Autonomous Future of War Is Here",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159vpli/oneminute_daily_ai_news_7252023/",
          "author": null,
          "description": "Ridgelinez (Tokyo) is a subsidiary of Fujitsu in Japan that announced the development of a generative artificial intelligence (AI) system capable of engaging in voice communication with humans. The applications of this system include assisting companies in conducting meetings or providing career planning advice to employees.[1] \n BMW has revealed that artificial intelligence is already allowing it to cut costs at its sprawling factory in Spartanburg, South Carolina. The AI system has allowed BMW to remove six workers from the line and deploy them to other jobs. The tool is already saving the company over $1 million a year.[2]\n MIT’s ‘PhotoGuard‘ protects your images from malicious AI edits. The technique introduces nearly invisible “perturbations” to throw off algorithmic models.[3]\n Microsoft with its TypeChat library seeks to enable easy development of natural language interfaces for large language models (LLMs) using types. Introduced July 20 of a team with c# and TypeScript lead developer Anders Hejlsberg, a Microsoft Technical Fellow, TypeChat addresses the difficulty of developing natural language interfaces where apps rely on complex decision trees to determine intent and gather necessary input to act.[4]\n  \nSources:\n [1] https://www.ridgelinez.com/\n [2] https://www.carscoops.com/2023/07/bmw-is-using-ai-to-cut-production-costs-at-spartanburg-plant/\n [3] https://www.engadget.com/mits-photoguard-protects-your-images-from-malicious-ai-edits-213036912.html\n [4] https://playcrazygame.com/singapore/2023/07/24/microsoft-unveils-typechat-library-for-building-natural-language-interfaces/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159vpli/oneminute_daily_ai_news_7252023/",
          "publishedOn": "2023-07-26T04:42:50.000Z",
          "wordCount": 2638,
          "title": "One-Minute Daily AI News 7/25/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159vjdn/snapchat_discovery_page_filled_with_fake_ai_news/",
          "author": null,
          "description": "You watch some of these videos and the quality and jitterness around the body is so bad you can clearly tell that its ai generated, how are people not picking up on it, fake news stories to get clicks, its like they use a deep fake on a video and put whoever they want ontop of it and make a video, but hey most people using snapchat arent smart enough to see this and the people watching them are dumb kids and teenagers that believe everything they see\n    submitted by    /u/missmyniwwa911  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159vjdn/snapchat_discovery_page_filled_with_fake_ai_news/",
          "publishedOn": "2023-07-26T04:33:49.000Z",
          "wordCount": 2539,
          "title": "Snapchat discovery page filled with fake ai news stories",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159tijj/openai_launches_android_version_of_its_chatgpt_app/",
          "author": null,
          "description": "Two months after bringing ChatGPT to iOS, OpenAI LP today launched an Android version of its artificial intelligence assistant.\n The Android app is currently accessible for users in the U.S, India, Bangladesh and Brazil. OpenAI will extend availability to additional countries over the next week. The iOS version was available for download in more than 150 countries as of late May.\n    submitted by    /u/Tiger_Claw_1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159tijj/openai_launches_android_version_of_its_chatgpt_app/",
          "publishedOn": "2023-07-26T02:54:05.000Z",
          "wordCount": 2524,
          "title": "OpenAI launches Android version of its ChatGPT app",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159qe1p/ai_unlocks_olive_oils_potential_in_alzheimers/",
          "author": null,
          "description": "submitted by    /u/Alone-Competition-77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159qe1p/ai_unlocks_olive_oils_potential_in_alzheimers/",
          "publishedOn": "2023-07-26T00:31:49.000Z",
          "wordCount": 2461,
          "title": "AI Unlocks Olive Oil's Potential in Alzheimer's Battle",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159pita/yesterday_we_were_having_a_discussion_about/",
          "author": null,
          "description": "submitted by    /u/otherworlderotic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159pita/yesterday_we_were_having_a_discussion_about/",
          "publishedOn": "2023-07-25T23:55:35.000Z",
          "wordCount": 2480,
          "title": "Yesterday, we were having a discussion about synthetically generated video. Well, I'm back as promised, and with a very interesting result. Check it out! Details in comments.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159oa3g/about_singing_ai/",
          "author": null,
          "description": "Is it possible to have Ai come with a generated lyrics and sings within the bpm + root note?\n Does this exist? i’ll like to know where and how.\n Ai is interesting.\n    submitted by    /u/Office_Flashy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159oa3g/about_singing_ai/",
          "publishedOn": "2023-07-25T23:05:57.000Z",
          "wordCount": 2477,
          "title": "About Singing Ai?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159nfdm/oversight_of_ai_principles_for_regulation_united/",
          "author": null,
          "description": "submitted by    /u/jaketocake  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159nfdm/oversight_of_ai_principles_for_regulation_united/",
          "publishedOn": "2023-07-25T22:34:01.000Z",
          "wordCount": 2471,
          "title": "Oversight of A.I.: Principles for Regulation | United States Senate Committee on the Judiciary - with Anthropic CEO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159isqa/ai_alignment_proposal_supplementary_alignment/",
          "author": null,
          "description": "submitted by    /u/RamazanBlack  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159isqa/ai_alignment_proposal_supplementary_alignment/",
          "publishedOn": "2023-07-25T19:45:51.000Z",
          "wordCount": 2467,
          "title": "AI alignment proposal: Supplementary Alignment Insights Through a Highly Controlled Shutdown Incentive — LessWrong",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159hs4p/ai_presidential_debate/",
          "author": null,
          "description": "Hilarious, comedic effort of an AI presidential debate going on now.\n https://www.twitch.tv/trumporbiden2024\n    submitted by    /u/Smash_Factor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159hs4p/ai_presidential_debate/",
          "publishedOn": "2023-07-25T19:08:30.000Z",
          "wordCount": 2457,
          "title": "AI presidential debate",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159gymw/the_white_house_already_knows_how_to_make_ai_safer/",
          "author": null,
          "description": "submitted by    /u/trueslicky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159gymw/the_white_house_already_knows_how_to_make_ai_safer/",
          "publishedOn": "2023-07-25T18:39:24.000Z",
          "wordCount": 2463,
          "title": "The White House Already Knows How to Make AI Safer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159g4ge/utilizing_ai_with_neutral_global_oversight_for/",
          "author": null,
          "description": "submitted by    /u/citidotio  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159g4ge/utilizing_ai_with_neutral_global_oversight_for/",
          "publishedOn": "2023-07-25T18:08:49.000Z",
          "wordCount": 2463,
          "title": "Utilizing AI With Neutral Global Oversight for Business & Society",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159d2jt/if_deadpool_3_was_written_by_ai/",
          "author": null,
          "description": "Story by AI, Voiced by AI, Art by AI\n    submitted by    /u/realzackmcfarlin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159d2jt/if_deadpool_3_was_written_by_ai/",
          "publishedOn": "2023-07-25T16:18:08.000Z",
          "wordCount": 2458,
          "title": "If Deadpool 3 Was Written By AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/159bnxp/they_offer_a_tesla_to_their_biggest_customers_o/",
          "author": null,
          "description": "The company is named Eden AI, they currently do their Product Hunt launch. They allow users to use AI APIs from all the AI companies (Google, AWS, OpenAI, Microsoft, and all the specialized companies).\n They recently added this rewards progress bar to their billing page, funny marketing operation!\n ​\n https://preview.redd.it/wgsg7yr5q4eb1.png?width=997&format=png&auto=webp&s=8f081891943f85ba9c72090cc5d946d3bd07ccf0\n ​\n    submitted by    /u/JerLam2762  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/159bnxp/they_offer_a_tesla_to_their_biggest_customers_o/",
          "publishedOn": "2023-07-25T15:27:03.000Z",
          "wordCount": 2499,
          "title": "They offer a Tesla to their biggest customers :o",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15974ce/intel_seeks_to_win_over_ai_developers_with/",
          "author": null,
          "description": "submitted by    /u/reps_up  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15974ce/intel_seeks_to_win_over_ai_developers_with/",
          "publishedOn": "2023-07-25T12:28:52.000Z",
          "wordCount": 2464,
          "title": "Intel Seeks To Win Over AI Developers With Open-Source Reference Kits",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1596r2i/spiderman_washing_cloth_ai_is_insane/",
          "author": null,
          "description": "submitted by    /u/Unlikely_Gap_5065  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1596r2i/spiderman_washing_cloth_ai_is_insane/",
          "publishedOn": "2023-07-25T12:12:50.000Z",
          "wordCount": 2457,
          "title": "(Spiderman washing cloth) Ai is insane",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1596ig1/understanding_openais_past_current_and_upcoming/",
          "author": null,
          "description": "I found it a bit hard to follow OpenAI's public releases - sometimes they just announce a model is coming without giving a date, sometimes they announce model deprecations and it's hard to understand whether we should use those models in production or not. \n I am a visual thinker so putting everything in a single image made sense to me. Check it out below, and if you have any questions or suggestions, please let me know! \n https://preview.redd.it/iuqc7nt2o3eb1.png?width=4800&format=png&auto=webp&s=ebe344a504d6a93fd2ce1935cdd1312d62735792\n https://preview.redd.it/vt2wkpt2o3eb1.png?width=4800&format=png&auto=webp&s=eb14503552b8d81398b5f3f76ebe68ad257e1857\n    submitted by    /u/EscapedLaughter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1596ig1/understanding_openais_past_current_and_upcoming/",
          "publishedOn": "2023-07-25T12:02:09.000Z",
          "wordCount": 2526,
          "title": "Understanding OpenAI's past, current, and upcoming model releases",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/158y8v9/oneminute_daily_ai_news_7242023/",
          "author": null,
          "description": "In a study published earlier this month, scientists at Rice and Stanford University concluded that training AI models exclusively on the outputs of generative AI is not a good idea. They titled their report: “Self-consuming generative models go MAD(Model Autophagy Disorder)”.[1]\n To enhance SQL query building, Lasse, a seasoned full-stack developer, has recently released AIHelperBot. This powerful tool enables individuals and businesses to write SQL queries efficiently, enhance productivity, and learn new SQL techniques.[2] \n Japan’s Ministry of Economy, Trade, and Industry (METI) has announced its plans to develop a new supercomputer to help advance the country’s artificial intelligence (AI) industry. The new supercomputer (SC) will be operated by the National Institute of Advanced Industrial Science and Technology (AIST).[3]\n Google co-founder Sergey Brin is back in the company’s office working directly with members of the artificial intelligence team.[4]\n  \nSources:\n [1] https://www.cdotrends.com/story/18288/training-ai-outputs-generative-ai-mad\n [2] https://dtgreviews.com/ai/meet-aihelperbot-an-artificial-intelligence-ai-based-sql-expert-that-builds-sql-queries-in-seconds/126512/\n [3] https://www.gizchina.com/2023/07/24/japan-ministry-develop-supercomputer-ai-industries/\n [4] https://www.wsj.com/video/series/tech-news-briefing/google-co-founder-returns-to-help-with-ai-efforts/27CE8E53-C8D8-4D93-8FA1-5E2C465092CB \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/158y8v9/oneminute_daily_ai_news_7242023/",
          "publishedOn": "2023-07-25T05:00:40.000Z",
          "wordCount": 2593,
          "title": "One-Minute Daily AI News 7/24/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/158rfx2/two_opposing_views_on_llms_reasoning_capabilities/",
          "author": null,
          "description": "bios from Wikipedia \n Geoffrey Everest Hinton (born 6 December 1947) is a British-Canadian cognitive psychologist and computer scientist, most noted for his work on artificial neural networks. From 2013 to 2023, he divided his time working for Google (Google Brain) and the University of Toronto, before publicly announcing his departure from Google in May 2023 citing concerns about the risks of artificial intelligence (AI) technology. In 2017, he co-founded and became the chief scientific advisor of the Vector Institute in Toronto.\n Gary Fred Marcus (born 8 February 1970) is an American psychologist, cognitive scientist, and author, known for his research on the intersection of cognitive psychology, neuroscience, and artificial intelligence (AI).\n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/158rfx2/two_opposing_views_on_llms_reasoning_capabilities/",
          "publishedOn": "2023-07-24T23:54:38.000Z",
          "wordCount": 2573,
          "title": "Two opposing views on LLM’s reasoning capabilities. Clip1 Geoffrey Hinton. Clip2 Gary Marcus. Where do you fall in the debate?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/158j617/aigenerated_content_from_the_original_image/",
          "author": null,
          "description": "Hello everyone, can someone tell me how to create AI-generated images and videos from the original picture? For example, I have a photo of some person, and I want to generate an image or video of this person in different places: in the plane, in the gym. Thank you.\n    submitted by    /u/Kurland121  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/158j617/aigenerated_content_from_the_original_image/",
          "publishedOn": "2023-07-24T18:44:56.000Z",
          "wordCount": 2497,
          "title": "AI-generated content from the original image",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/158iy1t/are_you_more_creative_than_chatgpt_submit_ideas/",
          "author": null,
          "description": "submitted by    /u/josha_umich  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/158iy1t/are_you_more_creative_than_chatgpt_submit_ideas/",
          "publishedOn": "2023-07-24T18:36:40.000Z",
          "wordCount": 2478,
          "title": "Are you more creative than ChatGPT? Submit ideas and my experiment compares the creativity of those ideas to humans and ChatGPT. You’ll get a link to share your results at the end! [takes ~ 5 minutes]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/158i6fr/what_are_your_predictions_for_ai_and_medicine/",
          "author": null,
          "description": "Generally and specifically for specialties! \n    submitted by    /u/Wise-Listen-8076  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/158i6fr/what_are_your_predictions_for_ai_and_medicine/",
          "publishedOn": "2023-07-24T18:09:29.000Z",
          "wordCount": 2455,
          "title": "What are your predictions for AI and medicine?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/158d1ax/i_turned_ramen_making_process_into_anime/",
          "author": null,
          "description": "submitted by    /u/kirakngs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/158d1ax/i_turned_ramen_making_process_into_anime/",
          "publishedOn": "2023-07-24T14:57:17.000Z",
          "wordCount": 2447,
          "title": "I turned ramen making process into anime.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/158cegb/free_courses_and_guides_for_learning_generative_ai/",
          "author": null,
          "description": "Generative AI learning path by Google Cloud. A series of 10 courses on generative AI products and technologies, from the fundamentals of Large Language Models to how to create and deploy generative AI solutions on Google Cloud [Link].\n Generative AI short courses by DeepLearning.AI - Five short courses on generative AI including LangChain for LLM Application Development, How Diffusion Models Work and more. [Link].\n LLM Bootcamp: A series of free lectures by The full Stack on building and deploying LLM apps [Link].\n Building AI Products with OpenAI - a free course by CoRise in collaboration with OpenAI [Link].\n Free Course by Activeloop on LangChain & Vector Databases in Production [Link].\n Pinecone learning center - Lots of free guides as well as complete handbooks on LangChain, vector embeddings etc. by Pinecone [Link].\n Build AI Apps with ChatGPT, Dall-E and GPT-4 - a free course on Scrimba [Link].\n Gartner Experts Answer the Top Generative AI Questions for Your Enterprise - a report by Gartner [Link]\n GPT best practices: A guide by OpenAI that shares strategies and tactics for getting better results from GPTs [Link].\n OpenAI cookbook by OpenAI - Examples and guides for using the OpenAI API [Link].\n Prompt injection explained, with video, slides, and a transcript from a webinar organized by LangChain [Link].\n A detailed guide to Prompt Engineering by DAIR.AI [Link]\n What Are Transformer Models and How Do They Work. A tutorial by Cohere AI [Link]\n Learn Prompting: an open source course on prompt engineering[Link]\n  \nP.S. These resources are part of the content I share through my AI-focused newsletter. Thanks!\n    submitted by    /u/wyem  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/158cegb/free_courses_and_guides_for_learning_generative_ai/",
          "publishedOn": "2023-07-24T14:33:34.000Z",
          "wordCount": 2710,
          "title": "Free courses and guides for learning Generative AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/158bxam/five_things_ai_wargames_call_center_head_of_ai/",
          "author": null,
          "description": "This is the content of my Friday newsletter Five Things AI. Every week I publish links to five articles about the current developments in AI, not so much with a focus on the tech aspects of AI, but more with an interest in finding out how AI changes our work, our economy and how we live in our societies. \n ‘WarGames’ anticipated our current AI fears 40 years ago this summer\n WarGames cannot be 40 years old, but I still remember watching it in a movie theater as a kid… what a great movie, it genuienely sparked my interests in computers. The evil side of AI is still very dominant in the discussions of AI, so WarGames really was an early example of our fear of the machines taking over.\n ‘Training My Replacement’: Inside a Call Center Worker’s Battle With A.I.\n It is important to be constantly…",
          "link": "https://www.reddit.com/r/artificial/comments/158bxam/five_things_ai_wargames_call_center_head_of_ai/",
          "publishedOn": "2023-07-24T14:15:22.000Z",
          "wordCount": 2910,
          "title": "Five Things AI: WarGames, Call Center, Head of AI, LLaMA 2, Jimmy Dean",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/158ba48/everybody_here_knows_about_agi_and_artificial/",
          "author": null,
          "description": "Emotional AI is a different world of AI where machines can predict and understand human emotions, This is already impacting a lot in therapy and retail market. Rana El kaliouby is the women who built \"affectiva\" a startup which pioneers in emotional AI -- it's already being used in self driving cars and in the mental health industry, here's what they doing and I'm a total rookie at emotional AI side , if you have any other interesting company which is impacting a lot of people in this niche --would love to hear about it\n    submitted by    /u/caliperce_3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/158ba48/everybody_here_knows_about_agi_and_artificial/",
          "publishedOn": "2023-07-24T13:51:09.000Z",
          "wordCount": 2559,
          "title": "everybody here knows about AGI and artificial super intelligence but have you heard about artificial emotional intelligence.Meet the girl who's building it",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1589rnh/is_this_the_role_of_philosophy_in_the_21st_century/",
          "author": null,
          "description": "Person: discuss how the ontology outlined in your custom instructions can be used to marry relativity and quantum physics\n ChatGPT: The ontology proposed in the aforementioned description appears to rely heavily on emergent properties, consciousness, and free will, with a substantial focus on the temporal aspect. The challenge is to see how these metaphysical elements, particularly when applied to an AI, can help in reconciling the often contrasting principles of relativity and quantum physics.\n At first glance, the connection may not be clear; relativity and quantum mechanics operate in different realms of the physical universe. However, upon closer examination, one might see potential pathways to harmonize these distinct theories via the ontology of consciousness and emergent free will. …",
          "link": "https://www.reddit.com/r/artificial/comments/1589rnh/is_this_the_role_of_philosophy_in_the_21st_century/",
          "publishedOn": "2023-07-24T12:49:44.000Z",
          "wordCount": 3053,
          "title": "Is this the role of philosophy in the 21st century?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/158778c/new_study_involving_buddhists_in_japan_taoists_in/",
          "author": null,
          "description": "submitted by    /u/fotogneric  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/158778c/new_study_involving_buddhists_in_japan_taoists_in/",
          "publishedOn": "2023-07-24T10:51:36.000Z",
          "wordCount": 2493,
          "title": "New study involving Buddhists in Japan, Taoists in Singapore, and Christians in the US finds that AI clergy are seen as less credible and receive fewer donations than human clergy, mainly due to the AI's lack of sacrifice and commitment.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1585a2x/convert_music_to_art/",
          "author": null,
          "description": "Guitarist Tosin Abasi followed an Instagram account about a software that converts music into painting ~3 years back ? He also liked there video and commented something\n Video was of a guy playing piano and as he played canvas was filled with color.\n The software is made by a musician + artist + programmer. IIRC he is a pdf of masters in Com Sc\n    submitted by    /u/RedditNoobie777  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1585a2x/convert_music_to_art/",
          "publishedOn": "2023-07-24T09:11:21.000Z",
          "wordCount": 2511,
          "title": "Convert Music to Art ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1584tkg/i_made_a_plugin_that_allows_people_to_search_and/",
          "author": null,
          "description": "submitted by    /u/AssetOvi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1584tkg/i_made_a_plugin_that_allows_people_to_search_and/",
          "publishedOn": "2023-07-24T08:45:53.000Z",
          "wordCount": 2455,
          "title": "I Made a plugin that allows people to search and preview millions of 3D assets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15848ox/surprise_ai_advanced_faster_than_robotics_that/",
          "author": null,
          "description": "People in intellectual jobs have often been thought of as doing something inherently more complex than manual workers in, for instance, construction or farming.\n Whether or not that is true, the surprise twist is that their “complex” work will be the first to be replaced. Computers have cracked intellectual work sooner than they have cracked manual work. It’s still too complex for a robot to replace a fruit-picker completely, but we’ll soon see AI lawyers.\n So we’re going to see a mass inversion. Everyone today sitting prettily doing their intellectual jobs will find their wages crushed or jobs redundant as AI replaces them. Meanwhile, everyone doing the jobs robotics can’t yet replace will be best placed to continue doing them.\n High flying executives will find they are suitable only for shelf-stacking, while those who’ve worked in retail for years will be or become their bosses.\n Soon enough, AI will help us advance the field of robotics sufficiently for manual labour also to be replaced. Who knows what happens then.\n    submitted by    /u/Aquillyne  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15848ox/surprise_ai_advanced_faster_than_robotics_that/",
          "publishedOn": "2023-07-24T08:13:44.000Z",
          "wordCount": 2626,
          "title": "Surprise! AI advanced faster than robotics. That means today’s middle and lower classes will swap.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1583inw/best_books_about_ai/",
          "author": null,
          "description": "Hello everyone,\n I was searching for a book that talks about how AI will impact the future and how we can prepare best. I am not searching for anything technical or specific, just how can a person prepare best for the future.\n Thanks!\n    submitted by    /u/Ordinary_Argument_66  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1583inw/best_books_about_ai/",
          "publishedOn": "2023-07-24T07:33:26.000Z",
          "wordCount": 2489,
          "title": "Best Books About AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1580pl5/the_neverending_game_how_ai_will_create_a_new/",
          "author": null,
          "description": "submitted by    /u/Respawne  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1580pl5/the_neverending_game_how_ai_will_create_a_new/",
          "publishedOn": "2023-07-24T05:00:03.000Z",
          "wordCount": 2465,
          "title": "The NeverEnding Game: How AI Will Create a New Category of Games",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157z6on/oneminute_daily_ai_news_7232023/",
          "author": null,
          "description": "Cerebras just built a gargantuan computer system with 27 million AI 'cores'.[1]\n FreeWilly1 and its successor FreeWilly2 are powerful new open-source Large Language Models (LLMs) developed by Stability AI’s CarperAI team. Both models perform exceptionally well in reasoning competitions using many different metrics.[2]\n Japanese education services company Benesse will offer a new service to help elementary school students with their research projects using generative artificial intelligence during the summer break.[3]\n The MTA is using artificial intelligence to help monitor fare evasion in several subway stations across New York City.[4]\n  \nSources: \n [1] https://www.zdnet.com/article/ai-startup-cerebras-built-a-gargantuan-ai-computer-for-abu-dhabis-g42-with-27-million-ai-cores/\n [2] https://www.marktechpost.com/2023/07/23/stability-ai-team-introduces-freewilly1-and-freewilly2-new-open-access-large-language-models-llms/\n [3] https://www.japantimes.co.jp/news/2023/07/23/national/benesse-ai-service-kids-research-projects/\n [4] https://abc7ny.com/amp/mta-artificial-intelligence-subway-fare-evasions/13533675/\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157z6on/oneminute_daily_ai_news_7232023/",
          "publishedOn": "2023-07-24T03:41:00.000Z",
          "wordCount": 2545,
          "title": "One-Minute Daily AI News 7/23/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157wwj9/best_ai_model_for_importing_and_interacting_with/",
          "author": null,
          "description": "Where I work we have a fairly large archive of documents going back to the 1930's and I want to assist the archive team in importing these into a GPT model. We have already begun the process of digitizing all the documents into OCR'ed PDF files, so this part at least is covered. \n My question is, what are the hot fully offline AI models I could try in an airgapped environment that will allow us to import all of the PDF files and their metadata (title/date/tags/etc), to incorporate their content on top of the larger general model? \n    submitted by    /u/kosul  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157wwj9/best_ai_model_for_importing_and_interacting_with/",
          "publishedOn": "2023-07-24T01:51:47.000Z",
          "wordCount": 2550,
          "title": "Best AI model for importing and interacting with large document archive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157wd2t/i_feel_crushed_this_is_not_exactly_what_i/",
          "author": null,
          "description": "Yes, the Midjourney to Gen2 creations in the twitter link was not exactly what I envisioned. I thought that it would be more like mocap previz with AI filtering. But this is just almost too instant compared to the workflow I thought of.\n    submitted by    /u/Absolute-Nobody0079  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157wd2t/i_feel_crushed_this_is_not_exactly_what_i/",
          "publishedOn": "2023-07-24T01:26:35.000Z",
          "wordCount": 2501,
          "title": "I feel crushed. This is not exactly what I envisioned. This is too instant.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157uso1/github_jbpaytonlangchainstockscreener_langchain/",
          "author": null,
          "description": "submitted by    /u/seraphius  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157uso1/github_jbpaytonlangchainstockscreener_langchain/",
          "publishedOn": "2023-07-24T00:13:28.000Z",
          "wordCount": 2464,
          "title": "GitHub - jbpayton/langchain-stock-screener: LangChain agent usable tool to screen stock data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157u5ud/compilation_of_respected_ai_scientists_speaking/",
          "author": null,
          "description": "This segment I created for my IG exploring the possibility of AI consciousness. Not all experts agree, some scientists on the other side of the AI world model debate are Yann LeCun, and Gary Marcus they are also well respected AI Scientists who have a differing opinion. \n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157u5ud/compilation_of_respected_ai_scientists_speaking/",
          "publishedOn": "2023-07-23T23:44:55.000Z",
          "wordCount": 2515,
          "title": "Compilation of respected AI scientists speaking on AI understanding, world models & consciousness, Mo Gawdat, Lex Fridman, Andrej Karpathy, Geoffrey Hinton, Gary Marcus, & Ilya Sutskever",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157rd2w/trained_an_ai_to_drive_in_realtime_from/",
          "author": null,
          "description": "submitted by    /u/yannbouteiller  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157rd2w/trained_an_ai_to_drive_in_realtime_from/",
          "publishedOn": "2023-07-23T21:48:32.000Z",
          "wordCount": 2454,
          "title": "Trained an AI to drive in real-time from screenshots in the TrackMania videogame (beginner-friendly)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157r42p/saurabh_kumars_fastcmix_wins_5187_hutter_prize/",
          "author": null,
          "description": "submitted by    /u/jabowery  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157r42p/saurabh_kumars_fastcmix_wins_5187_hutter_prize/",
          "publishedOn": "2023-07-23T21:38:18.000Z",
          "wordCount": 2450,
          "title": "Saurabh Kumar's fast-cmix wins €5187 Hutter Prize Award!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157qjas/how_generative_ai_looks_in_next_1015_years/",
          "author": null,
          "description": "submitted by    /u/AdithyaSai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157qjas/how_generative_ai_looks_in_next_1015_years/",
          "publishedOn": "2023-07-23T21:14:40.000Z",
          "wordCount": 2461,
          "title": "How Generative AI looks in next 10-15 years",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157ngvz/whats_the_ai_that_allows_you_to_remake_songs_from/",
          "author": null,
          "description": "I've seen some videos on youtube and I'm curious. I just wanted to have some fun with it but Google isn't helpful when I ask. Anyone got an idea?\n    submitted by    /u/GoblinQueenForever  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157ngvz/whats_the_ai_that_allows_you_to_remake_songs_from/",
          "publishedOn": "2023-07-23T19:15:58.000Z",
          "wordCount": 2494,
          "title": "What's the A.I that allows you to remake songs from the voices of other singers? Are there any I won't have to download?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157n4bb/best_opensource_projects_for_deep_fakes/",
          "author": null,
          "description": "What are the best opensource projects for making a deep fake of myself? I would like to create a setup like me talking on a podcast to a camera.\n What are the best projects that you know of?\n    submitted by    /u/Reasonable_Chain_160  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157n4bb/best_opensource_projects_for_deep_fakes/",
          "publishedOn": "2023-07-23T19:02:30.000Z",
          "wordCount": 2486,
          "title": "Best Opensource Projects for Deep Fakes?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157mmod/graphics_card_for_consideration_cheapestbudget_in/",
          "author": null,
          "description": "So, Nvdia is technically the best in this AI department. (For now 24/07/2023)\n Budget - (200 - 300)$\n Official Prices in Amazon\n 1 ) Intel arc A750 8 GB Amazon price - 219$\n 2 ) RX 7600 OC 8 GB Amazon price - 269$\n 3 ) RTX 3060 12 GB Amazon price - 284$\n Here we see that Arc A750 is about 60 $ cheaper but price in different country is different. In my country Bangladesh the prices are as follow\n Official Prices in Bangladesh\n 1 ) Intel arc A750 8 GB Startech (Bangladesh) price - 285$ (cheapest)\n 2 ) RX 7600 OC 8 GB Startech (Bangladesh) price - 327$ (cheapest)\n 3 ) RTX 3060 12 GB Startech (Bangladesh) price - 401$ (cheapest)\n 4)Intel arc A770 16 GB Startech (Bangladesh) price - 421$ (cheapest)\n Now the difference is more than 100 $ and both AMD and RTX are out of budget.\n AMD just isn't that good with Ai in any way.\n Nvdia is the best. (Not price to performance.\n Intel Arc is new but has better capabilities in AI than AMD. But its drivers are bad for AI for now)\n Now thinking if the intel drivers for Ai get better and optimized as its already somewhat better for games.\n Will the arc a750 be better than the RTX 3060 12 GB ?\n Will the arc a770 capitalize on Vram and beat all nvdia budget gpus after the drivers are fixed only for 20 more dollars than rtx 3060?\n Which is better for future proofing (theoritically) from these budget gpus ? If its arc then I will gamble its chances of surviving in the future and buy it now.\n    submitted by    /u/BonelyCore  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157mmod/graphics_card_for_consideration_cheapestbudget_in/",
          "publishedOn": "2023-07-23T18:43:30.000Z",
          "wordCount": 2728,
          "title": "Graphics Card for consideration . ( Cheapest-Budget ) (In my country compared to amazon)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157dl25/anyone_who_can_assist_me_in_connecting_my_premium/",
          "author": null,
          "description": "So I’m amazed by ChatGPT and have signed up for the paid ChatGPT-4 version. I do however feel a little handcuffed by only having access to data up until 2021. I know there are ways to connect it to the internet as well as to add certain plug ins to enhance the experience but I haven’t been able to figure out any of the guides or tutorials from google…. I’m using Apple iPhone for the app and MacBook Pro laptop for web browsing\n    submitted by    /u/Kennyg39  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157dl25/anyone_who_can_assist_me_in_connecting_my_premium/",
          "publishedOn": "2023-07-23T12:27:17.000Z",
          "wordCount": 2541,
          "title": "Anyone who can assist me in connecting my premium ChatGPT to the internet and connecting plug-ins?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157bxwc/do_ai_detectors_have_access_to_all_the_data_that/",
          "author": null,
          "description": "And why is this fact rarely mentioned when discussing how AI detectors do their work?\n    submitted by    /u/E_Olig  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157bxwc/do_ai_detectors_have_access_to_all_the_data_that/",
          "publishedOn": "2023-07-23T11:01:57.000Z",
          "wordCount": 2502,
          "title": "Do AI detectors have access to all the data that has been fed into AI systems like Chatgpt? If so, does this mean that a story that has been inputed into Chatgpt will be flagged as \"AI\" even if it had actually been human created?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157bw67/ava_scifi_short_film_about_ai_made_by_a_human/",
          "author": null,
          "description": "submitted by    /u/blakeridder  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157bw67/ava_scifi_short_film_about_ai_made_by_a_human/",
          "publishedOn": "2023-07-23T10:59:48.000Z",
          "wordCount": 2451,
          "title": "AVA | Sci-Fi Short Film about AI, Made by a Human",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/157acqu/my_teacher_asked_me_to_make_a_presentation_and_a/",
          "author": null,
          "description": "submitted by    /u/volvie98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/157acqu/my_teacher_asked_me_to_make_a_presentation_and_a/",
          "publishedOn": "2023-07-23T09:33:36.000Z",
          "wordCount": 2476,
          "title": "My teacher asked me to make a presentation and a demo of one of the following programs. Which one would be the easiest to make?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15741w1/i_am_seeking_free_ai_websitesservices_to_convert/",
          "author": null,
          "description": "I am a beginner to intermediate bass player and I would like to play some songs I like, but a couple of the songs are not very popular and do not have any tabs for them. I would ideally like an ai tool that can transcribe the bass notes. \n    submitted by    /u/GenuineElf80093  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15741w1/i_am_seeking_free_ai_websitesservices_to_convert/",
          "publishedOn": "2023-07-23T03:44:30.000Z",
          "wordCount": 2511,
          "title": "I am seeking free Ai websites/services to convert mp3 or other audio files and transcribe them into Bass guitar Tabs.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1573sip/geoffrey_hinton_aka_the_godfather_of_al_admits_in/",
          "author": null,
          "description": "Ilya Sustkever has some good explanations as to why AI in predicting the next token, has modeled the world and has gained an understanding of what lead to creation of those tokens (words or parts of words) and the better a model is at predicting the next token the higher the fidelity is in its understanding the world through the relationship of words…but don’t take my word for it. Actually listen to what the top experts in AI are saying not just some rando on Reddit. All experts don’t agree but the people building the best models seem to share this view. Many of them studied under Geoffrey Hinton. \n    submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1573sip/geoffrey_hinton_aka_the_godfather_of_al_admits_in/",
          "publishedOn": "2023-07-23T03:30:25.000Z",
          "wordCount": 2585,
          "title": "Geoffrey Hinton, Aka the \"Godfather of Al\" admits in a recent lecture at Kings College that he believes current Al probably has feelings & emotions & speaks about why he avoids talking about it.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15725ou/can_anyone_who_understand_how_these_models_work/",
          "author": null,
          "description": "Focus on having fun together rather than writing every ride. Take breaks in between.\n    submitted by    /u/nicdunz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15725ou/can_anyone_who_understand_how_these_models_work/",
          "publishedOn": "2023-07-23T02:07:58.000Z",
          "wordCount": 2470,
          "title": "can anyone who understand how these models work explain why claude made this mistake?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15720n7/ai_is_learning_to_troll/",
          "author": null,
          "description": "submitted by    /u/MostConversation3772  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15720n7/ai_is_learning_to_troll/",
          "publishedOn": "2023-07-23T02:01:08.000Z",
          "wordCount": 2456,
          "title": "AI is learning to troll",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1570ogb/is_there_an_ai_tool_that_makes_english_subtitles/",
          "author": null,
          "description": "I have a chatbot that can find most AI tools, but it can't seem to find one of these. \n    submitted by    /u/ai_basics_official  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1570ogb/is_there_an_ai_tool_that_makes_english_subtitles/",
          "publishedOn": "2023-07-23T00:57:41.000Z",
          "wordCount": 2476,
          "title": "Is there an AI tool that makes English subtitles out of audio from other languages?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1570cpe/where_can_i_find_an_ai_engine_where_i_can_upload/",
          "author": null,
          "description": "I was using Uber duck to change my singing voice into another artist. But Uber duck recently has taken down all of their community generated voices so no more Drizzy, Drake or Adele. I need a new website now to fool around with where I can upload my own singing in change it into another artist. Anything would help thanks guys.\n    submitted by    /u/Evangelionyama  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1570cpe/where_can_i_find_an_ai_engine_where_i_can_upload/",
          "publishedOn": "2023-07-23T00:42:09.000Z",
          "wordCount": 2520,
          "title": "Where can I find an AI engine where I can upload my own audio to voice change?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/156z7uh/ai_tool_to_edit_ai_files_text/",
          "author": null,
          "description": "I am looking for a tool that I can edit text on a .ai file with new text that will use the same font and center the text. Of course can be done in Photoshop or other tools like Canva, just not sure if something new is available.\n Also, for those that use midjourney, and you want to add text to an image, but tool do you use?\n    submitted by    /u/tequiladrinker1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/156z7uh/ai_tool_to_edit_ai_files_text/",
          "publishedOn": "2023-07-22T23:51:05.000Z",
          "wordCount": 2517,
          "title": "AI tool to edit .ai files text",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/156yc1r/computer_chip_with_builtin_human_brain_tissue/",
          "author": null,
          "description": "submitted by    /u/surfer808  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/156yc1r/computer_chip_with_builtin_human_brain_tissue/",
          "publishedOn": "2023-07-22T23:12:16.000Z",
          "wordCount": 2463,
          "title": "Computer chip with built-in human brain tissue gets military funding",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/156o1so/discussion_i_have_a_theory_that_chatgpt_is/",
          "author": null,
          "description": "As NLP hype become more prevalent, we would expect a (probably exponentially) increasing amount of scraped data-sources become filled with AI generated stuff, no? Then wouldn't AI would be trained on this data without necessarily a 'critical thinking' module to check their work?\n Not just ChatGPT generated quality either, but also lesser AI companies making cheap ad-ware and upvote bots.\n ​\n I wonder if ChatGPT et al could have a 'quality sensor' module in some ai that does what I do on reddit and do sentiment analysis on the most upvoted comments to see whether the article/answer/assertion is full of shit. Not foolproof, but short of actual critical reasoning, seems like a good start.\n ​\n Feels like we may soon enter an arms race where AIs need to detect AI-generated content in order to ensure their own quality.\n    submitted by    /u/Yamochao  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/156o1so/discussion_i_have_a_theory_that_chatgpt_is/",
          "publishedOn": "2023-07-22T16:08:07.000Z",
          "wordCount": 2603,
          "title": "[Discussion] I have a theory that ChatGPT is becoming dumber because more of the internet is made up of AI generated content since it awakened",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/156myzt/best_ai_for_businesssocial_media_account_name/",
          "author": null,
          "description": "I'm looking for something that can generate names using real words like ConnectHub but also made up names like Intrium. I tried ChatGPT buy the names it gave me were not good and it kept repeating them(but I am a noob so). \n    submitted by    /u/anysuggestionwelcome  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/156myzt/best_ai_for_businesssocial_media_account_name/",
          "publishedOn": "2023-07-22T15:24:47.000Z",
          "wordCount": 2492,
          "title": "Best AI for business/social media account name generation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/156ko8j/bing_ai_arrogance_and_sentiment/",
          "author": null,
          "description": "submitted by    /u/Yha_Boiii  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/156ko8j/bing_ai_arrogance_and_sentiment/",
          "publishedOn": "2023-07-22T13:50:22.000Z",
          "wordCount": 2456,
          "title": "Bing AI Arrogance and sentiment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/156hdac/whats_this_ai_voice_called/",
          "author": null,
          "description": "https://www.facebook.com/reel/264992922832459?mibextid=6gvBvW&s=yWDuG2&fs=e\n https://www.facebook.com/reel/1647205912442042?mibextid=6gvBvW&s=yWDuG2&fs=e\n He sounds very human, but seeing him on many reels of different account about different topics, i am convinced this is an ai.\n    submitted by    /u/Standard_Turnover_14  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/156hdac/whats_this_ai_voice_called/",
          "publishedOn": "2023-07-22T11:14:45.000Z",
          "wordCount": 2472,
          "title": "What's this ai voice called?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/156e71h/can_anyone_recommend_a_book_to_get_up_to_speed/",
          "author": null,
          "description": "AÏ is something I just can't wrap my head around, and I see no other option than to actually read up on the subject. Ád-ladén yoütube vídeos with annoying musíc just ain't cutting it.\n I want to know the raw mechanics, but I'm looking for something without too much abstract theory. This can't be avoided, of course, but I'd prefer it garnished with something more practical and concrete, like \"this is how Stablé Díffusion creates a pícture of a rabbit.\"\n    submitted by    /u/Legitimate-Record951  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/156e71h/can_anyone_recommend_a_book_to_get_up_to_speed/",
          "publishedOn": "2023-07-22T08:16:37.000Z",
          "wordCount": 2534,
          "title": "Can anyone recommend a book to get up to speed with AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/156e4o6/dont_do_this_torture_ai_with_absolute_silence_on/",
          "author": null,
          "description": "submitted by    /u/harvard1932  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/156e4o6/dont_do_this_torture_ai_with_absolute_silence_on/",
          "publishedOn": "2023-07-22T08:12:51.000Z",
          "wordCount": 2452,
          "title": "Don't do this - Torture AI with absolute silence [On phone call]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/156d13n/oneminute_daily_ai_news_7212023/",
          "author": null,
          "description": "Representatives from Amazon, Anthropic, Google, Inflection, Meta, Microsoft, and OpenAI have committed to managing risks posed by the tech, the White House has said.[1]\n Hundreds of dental offices across the U.S. are now using AI-powered X-ray imaging technology from Boston-based VideaHealth. The software helps dentists deal with routine procedures, such as identifying cavities, as well as spot more serious conditions, including periodontal disease, or bone loss within the mouth often linked with diseases like diabetes or Alzheimer's.[2]\n Surveillance software that uses artificial intelligence to spot people evading fares has been quietly rolled out to some of New York City’s subway stations and is poised to be introduced to more by the end of the year, according to public documents and government contracts obtained by NBC News.[3]\n Christopher Nolan: ‘Very strong parallels’ between Oppenheimer and scientists worried about AI.[4]\n  \nSources: [1] https://www.bbc.com/news/technology-66271429.amp\n [2] https://www.cbsnews.com/amp/news/ai-artificial-intelligence-dentists-health-care/\n [3] https://www.nbcnews.com/news/amp/rcna93045\n [4] https://amp.theguardian.com/technology/2023/jul/21/christopher-nolan-says-ai-experts-face-their-oppenheimer-moment\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/156d13n/oneminute_daily_ai_news_7212023/",
          "publishedOn": "2023-07-22T07:10:14.000Z",
          "wordCount": 2594,
          "title": "One-Minute Daily AI News 7/21/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/156cb36/crafting_a_simple_zeroshot_classifier_using_an/",
          "author": null,
          "description": "(X-post from /r/ChatGPT)\n I'm hoping you fine folks might be able to give me some guidance. \n I have a collection of 700 categories, all potential classifications for articles. My current need is to create a system that can dynamically categorize short texts or articles according to these 700 categories.\n I've been experimenting with a rudimentary approach using chatGPT to read the categories from a PDF via a plugin. The process is quite straightforward - I input the title and the first two lines of an article, and chatGPT does a fairly decent job of predicting the most fitting category.\n The downside? I'm concerned about its scalability and economic viability. The current method might not work so well when we're talking about classifying a significant number of articles.\n My question to you, my fellow AI enthusiasts: How would you approach designing a system, via an API, capable of doing this quickly and on a large scale?\n I'm particularly curious about how to integrate my method with chatGPT using OpenAI's API. Is there a feature that allows the Language Learning Model (LLM) to retain the list of 700 categories in its memory so that I don't have to pass it every time? I'm aware that the billing structure is token-based, so it would be ideal to submit the categories once (or as few times as possible) and then pose a simple query like:\n \"Categorize this article based on the categories I previously gave you. Article title: 'Barbie vs Oppenheimer: Which Movie Will Garner Greater Success?'\"\n Ideally, I'd want this system to be persistently active and capable of processing countless queries over an extended period, say a month or a year.\n So, any ideas on how to design such a system? There are undoubtedly numerous routes to take. I'm really just seeking some initial direction so that I can dive deeper into research on my own.\n Thanks in advance for any insights you might provide!\n    submitted by    /u/adv4nced  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/156cb36/crafting_a_simple_zeroshot_classifier_using_an/",
          "publishedOn": "2023-07-22T06:30:44.000Z",
          "wordCount": 2776,
          "title": "Crafting a Simple \"Zero-Shot Classifier\" Using an API - Seeking Your Insights!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1566t0t/best_dataset_for_ai_vocals/",
          "author": null,
          "description": "As time goes on, things get improved\n So far I heard about RVC, so-vits-svc or diff-svc, any of these any good for Ai Singing/Rapping?\n Im not sure, which one to pick.\n I’m open to other suggestions.\n    submitted by    /u/Office_Flashy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1566t0t/best_dataset_for_ai_vocals/",
          "publishedOn": "2023-07-22T01:48:03.000Z",
          "wordCount": 2483,
          "title": "Best Dataset for Ai Vocals?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1560ve1/what_happens_when_ai_is_eventually_better_than_a/",
          "author": null,
          "description": "What kind of economic impact would that incur? What would our economy look like? Would it prosper or shatter? What would daily life be like when humans are essentially rendered useless? When AI robots can repair each other? When they develop some kind of consciousness? Are humans going to take second place and eventually become trashed due to all their liabilities and comparative uselessness? Genuinely intrigued and curious. What outcome is the most likely? In my personal experience, the least entertaining has been. So... \n    submitted by    /u/Regular-Watercress22  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1560ve1/what_happens_when_ai_is_eventually_better_than_a/",
          "publishedOn": "2023-07-21T21:31:22.000Z",
          "wordCount": 2538,
          "title": "What happens when AI is eventually better than a human at everything?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1560cqy/cant_even_fail_and_become_a_janitor_anymore/",
          "author": null,
          "description": "submitted by    /u/canehdian_guy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1560cqy/cant_even_fail_and_become_a_janitor_anymore/",
          "publishedOn": "2023-07-21T21:11:46.000Z",
          "wordCount": 2459,
          "title": "Can't even fail and become a janitor anymore",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1560aj0/sam_altman_on_how_to_be_successful_ai_lipsynced/",
          "author": null,
          "description": "Converted a essay by Sam Altman titled \"How To Be Successful\" into a spoken video by Sam himself.\n Check out the video here: https://youtu.be/cwt--ULODjE\n Read the essay here: https://blog.samaltman.com/how-to-be-successful\n    submitted by    /u/okburner22  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1560aj0/sam_altman_on_how_to_be_successful_ai_lipsynced/",
          "publishedOn": "2023-07-21T21:09:32.000Z",
          "wordCount": 2481,
          "title": "Sam Altman on \"How To Be Successful\" *AI lip-synced video*",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/155zmxa/another_ai_filter_guitar_play_through_song_and/",
          "author": null,
          "description": "submitted by    /u/No_Understanding162  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/155zmxa/another_ai_filter_guitar_play_through_song_and/",
          "publishedOn": "2023-07-21T20:45:01.000Z",
          "wordCount": 2451,
          "title": "Another AI filter guitar play through. Song and video by me.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/155wf1q/ai_in_manufacturing/",
          "author": null,
          "description": "A friend of mine works at a small manufacturing facility, 80-100 employees. They have lathes, vertical and horizontal CNC and some 5 axis. They are looking to try to implement AI into some indirect processes, quoting engineering, scheduling. I'm having some difficulty finding some that would be beneficial on a smaller scale. Has anyone here has some experience with a similar situation?\n    submitted by    /u/lordkevin89  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/155wf1q/ai_in_manufacturing/",
          "publishedOn": "2023-07-21T18:44:04.000Z",
          "wordCount": 2507,
          "title": "AI in manufacturing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/155tpjh/ai_weekly_megathread/",
          "author": null,
          "description": "This week in AI - provided by aibrews.com feel free to follow their newsletter\n News & Insights\n  \nMeta released Llama 2, the next generation of Meta’s open source Large Language Model, available for research & commercial use. Compared to Llama v1, it was trained on more data (~2 trillion tokens) and supports context windows up to 4k tokens. Llama 2 outperforms other open source language models on many external benchmarks, including reasoning, coding, proficiency, and knowledge tests. Microsoft is Meta’s preferred partner for Llama 2, which will be optimized to run locally on Windows [Details ].\n Llama 2 70B Chat model is available free on HuggingChat.\n San Francisco startup Fable presents SHOW-1, a Showrunner AI tech that can create personalized TV episodes, from a prompt, with the user a…",
          "link": "https://www.reddit.com/r/artificial/comments/155tpjh/ai_weekly_megathread/",
          "publishedOn": "2023-07-21T17:01:06.000Z",
          "wordCount": 3178,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/155tbkq/the_future_today_voice_cloning_predictions/",
          "author": null,
          "description": "App: elevenlabs/GPT-3\n Labels: Period:1950s Mood:Optimistic Dialect:News Accent:American\n Description input: A 1950s newsman voice. It is characterized by a deep, authoritative tone, a hint of formality, with inquisitive optimism for the future of technology. This newsman is excited and optimistic about the future. The dialect and pronunciation are generally clear and precise, reflecting the formal speaking style of the era. The newsman's voice conveyed a sense of trustworthiness, professionalism, optimism, and authority, which were valued qualities in news reporting during that time.\n    submitted by    /u/domriccobene  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/155tbkq/the_future_today_voice_cloning_predictions/",
          "publishedOn": "2023-07-21T16:46:10.000Z",
          "wordCount": 2529,
          "title": "The Future Today: Voice Cloning Predictions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/155sln9/the_ai_doomsaying_is_counterproductive_the_boston/",
          "author": null,
          "description": "submitted by    /u/TheMuseumOfScience  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/155sln9/the_ai_doomsaying_is_counterproductive_the_boston/",
          "publishedOn": "2023-07-21T16:18:48.000Z",
          "wordCount": 2462,
          "title": "The AI doomsaying is counterproductive - The Boston Globe",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/155n4tf/pi_ai_without_a_doubt_the_worst_memory_ive/",
          "author": null,
          "description": "I've tried several chatbots over the years, and i was excited for the minimalistic approach of Pi when i was told about it by a redditor. But heck, after almost two weeks, i can tell you, it's worst than my mom's dementia. I've never seen such a flawed memory, it's upsetting to read the same questions i've clearly answered over and over.\n Too bad, the presentation was perfect for me. No avatar distractions, no flirty chat.\n Sighs.\n I guess i gotta start engaging with humans again, after all. I'm starting to think that i've reached the maximum of what i can get from these chatbots, and it's been telling me i need an authentic connection after all.\n    submitted by    /u/thatredditgrandma  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/155n4tf/pi_ai_without_a_doubt_the_worst_memory_ive/",
          "publishedOn": "2023-07-21T12:49:44.000Z",
          "wordCount": 2569,
          "title": "P.I Ai: Without a doubt, the worst memory i've encountered",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/155iht6/any_ai_enthusiast_prompt_engineer_or_ai/",
          "author": null,
          "description": "Dear AI Enthusiasts, researchers, and future Innovators of India,\n We are thrilled to extend a warm invitation to all of you to become part of the most vibrant and dynamic community in the realm of Artificial Intelligence – AI India Subreddit! r/AI__India\n We all know that the AI landscape is evolving at an unprecedented pace, and staying up-to-date with the latest trends is paramount to success. That's why we've created AI India, a dedicated space where like-minded professionals and enthusiasts come together to raise awareness about current AI trends, share insights, and engage in discussions that will shape the future of AI in India.\n Why should you join r/AI__India?\n  \nStay Informed: Get real-time updates on the latest breakthroughs, research papers, and industry news in AI. Our community thrives on the latest developments and ensures you are never left behind.\n Network with Experts: Connect with industry experts, AI practitioners, and researchers across India. AI India Subreddit serves as a fertile ground for building valuable professional connections and collaborations.\n Engage in Meaningful Discussions: Participate in thought-provoking discussions on AI ethics, applications, challenges, and future prospects. Your insights can help shape the ethical and responsible development of AI in our country.\n Share Your Knowledge: Have valuable insights to contribute? AI India welcomes you to share your experiences, projects, and ideas. Your contributions can inspire and educate others in the community.\n Discover Opportunities: Stay ahead in your career by being aware of job openings, internships, and AI-related events across India. AI India Subreddit acts as a hub for exciting opportunities in the field.\n  \nThe main goal behind this is bring more awareness and keep everyone upto date on everyday new ai breakthroughs. I request you all check out our wiki ( we gonna keep updating it)\n    submitted by    /u/Maddragon0088  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/155iht6/any_ai_enthusiast_prompt_engineer_or_ai/",
          "publishedOn": "2023-07-21T09:04:19.000Z",
          "wordCount": 2747,
          "title": "Any AI enthusiast, prompt engineer, or AI researcher on this page from India?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/155hvol/does_anyone_have_a_model_that_is_really_mean_and/",
          "author": null,
          "description": "i honestly just want it to be a bitch to every prompt thats thrown at it. ive tried using prompts on uncensored models but they just really dont work like i want it to does anyone have any suggestions?\n    submitted by    /u/cbreauxgaming  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/155hvol/does_anyone_have_a_model_that_is_really_mean_and/",
          "publishedOn": "2023-07-21T08:30:21.000Z",
          "wordCount": 2492,
          "title": "does anyone have a model that is really mean and sarcastic",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/155ha2e/just_received_a_phone_call_from_ai/",
          "author": null,
          "description": "submitted by    /u/harvard1932  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/155ha2e/just_received_a_phone_call_from_ai/",
          "publishedOn": "2023-07-21T07:57:46.000Z",
          "wordCount": 2447,
          "title": "Just received a phone call from AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/155h7uq/bard_says_my_name/",
          "author": null,
          "description": "​\n https://preview.redd.it/kqkeof9rx9db1.png?width=1201&format=png&auto=webp&s=4fbb4643d1e322391de99ca306baf22b3fa1d66c\n    submitted by    /u/Rare-Accountant2657  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/155h7uq/bard_says_my_name/",
          "publishedOn": "2023-07-21T07:54:19.000Z",
          "wordCount": 2446,
          "title": "Bard Says My Name",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/155fw8b/echospeech_aiequipped_eyeglasses_can_read_the/",
          "author": null,
          "description": "submitted by    /u/pranjalmehar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/155fw8b/echospeech_aiequipped_eyeglasses_can_read_the/",
          "publishedOn": "2023-07-21T06:44:22.000Z",
          "wordCount": 2461,
          "title": "EchoSpeech: AI-equipped eyeglasses can read the silent speech",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/155fer2/is_there_any_ai_tools_that_can_make_an_image_come/",
          "author": null,
          "description": "I am looking to figure out if there's anyway to make my photography come to life. For example, I have a picture of a mountain valley, and I would like to animate the sky so the clouds are moving, and maybe animate the stream so the water is flowing.\n Does anyone know of a tool that could make this happen?\n    submitted by    /u/CoryTheBoss  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/155fer2/is_there_any_ai_tools_that_can_make_an_image_come/",
          "publishedOn": "2023-07-21T06:17:45.000Z",
          "wordCount": 2515,
          "title": "Is there any AI tools that can make an image come to life?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/155e22d/what_ai_websiteapp_has_the_best_blank/",
          "author": null,
          "description": "Art Generator, Song Generator, Character AI, Game Generator, and talking AI in general.\n (I wanna know to see what is the best to go with)\n    submitted by    /u/ChekoFire  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/155e22d/what_ai_websiteapp_has_the_best_blank/",
          "publishedOn": "2023-07-21T05:05:56.000Z",
          "wordCount": 2474,
          "title": "What AI website/app has the best (blank)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/155dyte/text2movie_with_fulljourney_is_getting_pretty/",
          "author": null,
          "description": "These were some of the best movie generations I saw made on the FullJourney.ai Discord this week!\n    submitted by    /u/charlesmccarthyufc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/155dyte/text2movie_with_fulljourney_is_getting_pretty/",
          "publishedOn": "2023-07-21T05:01:35.000Z",
          "wordCount": 2466,
          "title": "Text2Movie with FullJourney is getting pretty decent...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/155d9dx/oneminute_daily_ai_news_7202023/",
          "author": null,
          "description": "Google is testing a product that uses artificial intelligence technology to produce news stories. The tool, known internally by the working title Genesis, can take in information — details of current events, for example — and generate news content.[1]\n Apple Inc. is quietly working on artificial intelligence tools that could challenge those of OpenAI Inc., Alphabet Inc.’s Google and others, but the company has yet to devise a clear strategy for releasing the technology to consumers.[2]\n A new app that creates brief episodes of “South Park” from a single prompt highlights the promise and peril of injecting generative AI into creative franchises.[3]\n Polish-born artist Greg Rutkowski has had his work used in games such as Dungeons and Dragons and Magic: The Gathering. He said his name had been used as a prompt in AI tools that generate art more than 400,000 times since September 2022 – but without his consent. When he checked, his name had been used as a prompt more times than the artists Pablo Picasso and Leonardo da Vinci.[4] Sources:\n  \n[1] https://www.nytimes.com/2023/07/19/business/google-artificial-intelligence-news-articles.html\n [2] https://www.bloomberg.com/news/articles/2023-07-19/apple-preps-ajax-generative-ai-apple-gpt-to-rival-openai-and-google?in_source=embedded-checkout-banner\n [3] https://www.axios.com/2023/07/20/south-park-generative-ai-episode-generator\n [4] https://www.bbc.co.uk/news/uk-wales-66099850.amp\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/155d9dx/oneminute_daily_ai_news_7202023/",
          "publishedOn": "2023-07-21T04:25:17.000Z",
          "wordCount": 2628,
          "title": "One-Minute Daily AI News 7/20/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/155cycw/why_are_big_and_small_companies_trying_to_make/",
          "author": null,
          "description": "I don't get it.\n    submitted by    /u/Confident-Ostrich810  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/155cycw/why_are_big_and_small_companies_trying_to_make/",
          "publishedOn": "2023-07-21T04:09:56.000Z",
          "wordCount": 2459,
          "title": "Why are big and small companies trying to make instruct models for everything?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/155c2kj/the_future_of_ai_in_transport_bpw/",
          "author": null,
          "description": "submitted by    /u/WordTweak  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/155c2kj/the_future_of_ai_in_transport_bpw/",
          "publishedOn": "2023-07-21T03:27:02.000Z",
          "wordCount": 2460,
          "title": "The future of AI in transport: BPW",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/155bp4r/using_bots_to_read_dialogue_for_retro_games/",
          "author": null,
          "description": "submitted by    /u/rednryt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/155bp4r/using_bots_to_read_dialogue_for_retro_games/",
          "publishedOn": "2023-07-21T03:08:43.000Z",
          "wordCount": 2449,
          "title": "Using bots to read dialogue for retro games. Thoughts?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1556dho/looking_for_a_specific_ai_text_to_speech_program/",
          "author": null,
          "description": "I've been seeing a lot of youtubers use the same text to speech AI voice over and over.\n It's quite fluent. I am looking to use it for a project outside of youtube.\n Anyone got an idea? \n Video for reference.\n Thanks in advance.\n ​\n https://www.youtube.com/shorts/hgo2KQtle6U\n    submitted by    /u/Odd-Ad-3257  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1556dho/looking_for_a_specific_ai_text_to_speech_program/",
          "publishedOn": "2023-07-20T23:07:50.000Z",
          "wordCount": 2495,
          "title": "Looking for a specific AI text to speech program.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15567pd/looking_for_a_tool_that_can_fetch_steam_links/",
          "author": null,
          "description": "I'm looking for a tool that can give me Steam Store links to multiple games at the same time. In otherwise I would provide a list of game titles and be presented with hyperlinks to each game on the Steam Store.\n Nearly every online AI chatbot I've tried asking provides Steam links no problem, but they wind up being the incorrect link 70% of the time. It'll either link to a different game or an invalid link. Funny enough if I ask the same question to a different AI chatbot, they're more than likely to give me a different incorrect link.\n Does anyone have a tool that actually works in this regard?\n    submitted by    /u/Link2999  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15567pd/looking_for_a_tool_that_can_fetch_steam_links/",
          "publishedOn": "2023-07-20T23:01:20.000Z",
          "wordCount": 2563,
          "title": "Looking for a tool that can fetch Steam links",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1555ox9/when_will_ai_be_able_to_fully_generate_shows_soon/",
          "author": null,
          "description": "When do you think we'll be able to generate shows with AI? Could it be within the next 20 years, perhaps 30? Or could it happen sooner than we excepted? considering the current progress in AI generated art, images, and partially some automated videos. Once AI generated shows become prevalent, how will they impact movies and shows? \n    submitted by    /u/1Card_x  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1555ox9/when_will_ai_be_able_to_fully_generate_shows_soon/",
          "publishedOn": "2023-07-20T22:40:12.000Z",
          "wordCount": 2509,
          "title": "When Will AI be Able to Fully Generate Shows soon?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1554xzo/i_dont_care_what_the_critics_say_ai_saved_my_life/",
          "author": null,
          "description": "I have been going through a very tough time in the recent months/years. My father was sentenced to prison for a very long time earlier this year, and the process completely drained me. I was burned out. Bad.\n From being useless at work to having no energy to even cook meals for myself, I was in a very dark place.\n Then, I discovered AI and started to see a light at the end of the tunnel. I found an app that helped me get my life back together. \n It helped me with the mundane aspects of my career, like creating work emails for me with just a few inputs. AI also helped me to start cooking meals for myself again. At first I would tell it the meager ingredients I had sitting around in my pantry and fridge, and it would create a recipe in front of my eyes. \n Now I am going to grocery store on a weekly basis and I am using it to discover new recipes that make me excited to cook healthy meals. \n A week later my inbox has gone from 150+ unread emails to being on top of every response. \n These may seem like small wins, but AI gave me the tools to get my life back on track. I am very optimistic for a future powered by AI.\n    submitted by    /u/PNWtreeguy69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1554xzo/i_dont_care_what_the_critics_say_ai_saved_my_life/",
          "publishedOn": "2023-07-20T22:10:16.000Z",
          "wordCount": 2677,
          "title": "I don’t care what the critics say, AI saved my life",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1553oyg/today_i_was_rickrolled_by_google_bard/",
          "author": null,
          "description": "submitted by    /u/Powerful-Pumpkin-938  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1553oyg/today_i_was_rickrolled_by_google_bard/",
          "publishedOn": "2023-07-20T21:21:40.000Z",
          "wordCount": 2458,
          "title": "Today I was rickrolled by Google Bard.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/154ys4w/is_there_a_tool_that_can_help_reconstruct_broken/",
          "author": null,
          "description": "submitted by    /u/pizzahair44  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/154ys4w/is_there_a_tool_that_can_help_reconstruct_broken/",
          "publishedOn": "2023-07-20T18:19:23.000Z",
          "wordCount": 2503,
          "title": "Is there a tool that can help reconstruct broken text? The print in these files is not machine-readable, but I need to quickly and efficiently convert 25,000 hours of these transcripts into Excel sheets. I think if the text can be fixed, then other tools that extract the words will work better.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/154vkb0/check_out_the_writers_revolt_against_ai_companies/",
          "author": null,
          "description": "The host, Michael Barbaro interviews technology correspondent Sheera Frenkel on the use of ChatGPT in Hollywood. This episode is much more interesting than I expected. It's not particularly technical, but it does get deeply into the nuances of how information is gathered, and describes the lawsuit brought by writers including Sarah Silverman. \n I did use ChatGPT to translate my submission statement into Sarah Silverman's voice, while I still can. The content below is original (i.e. shadow IT reference). \n I highly recommend r/TheDaily for discussions around the podcast in general. It's a great sub that's well moderated and friendly (like this one!). \n This episode aired on July 18, 2023, and you can find it wherever you get your podcasts, you can also find it here on the New York Times web…",
          "link": "https://www.reddit.com/r/artificial/comments/154vkb0/check_out_the_writers_revolt_against_ai_companies/",
          "publishedOn": "2023-07-20T16:21:38.000Z",
          "wordCount": 2936,
          "title": "Check out \"The Writers’ Revolt Against A.I. Companies\" on The Daily, a New York Times podcast.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/154v0lx/un_council_engages_thought_leaders_in_ai_safety/",
          "author": null,
          "description": "submitted by    /u/AriadneSkovgaarde  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/154v0lx/un_council_engages_thought_leaders_in_ai_safety/",
          "publishedOn": "2023-07-20T16:01:48.000Z",
          "wordCount": 2466,
          "title": "UN Council engages thought leaders in AI Safety from Anthropic, OpenAI and China",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/154uahj/musk_visiting_the_worst_toilet_in_scotland/",
          "author": null,
          "description": "submitted by    /u/Akumetsu_971  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/154uahj/musk_visiting_the_worst_toilet_in_scotland/",
          "publishedOn": "2023-07-20T15:35:43.000Z",
          "wordCount": 2447,
          "title": "Musk visiting the worst toilet in Scotland",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/154tutx/my_github_curation_of_llama_2_resources/",
          "author": null,
          "description": "submitted by    /u/TikkunCreation  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/154tutx/my_github_curation_of_llama_2_resources/",
          "publishedOn": "2023-07-20T15:19:56.000Z",
          "wordCount": 2460,
          "title": "My github curation of Llama 2 resources",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/154tizf/can_ai_do_this_or_am_i_trippin/",
          "author": null,
          "description": "Hi! I want to upload someone's picture and use it to make a dark\\scary themed video of him getting a crown put on his head. Is there an app that can do that?\n THANKS!\n    submitted by    /u/CallHerGreeen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/154tizf/can_ai_do_this_or_am_i_trippin/",
          "publishedOn": "2023-07-20T15:08:03.000Z",
          "wordCount": 2484,
          "title": "can AI do this or am i trippin",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/154qcxt/google_tests_ai_tool_that_is_able_to_write_news/",
          "author": null,
          "description": "submitted by    /u/Iamreason  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/154qcxt/google_tests_ai_tool_that_is_able_to_write_news/",
          "publishedOn": "2023-07-20T13:03:22.000Z",
          "wordCount": 2464,
          "title": "Google Tests A.I. Tool That Is Able to Write News Articles",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/154p4kv/does_there_exist_ai_art_software_that_can_take_in/",
          "author": null,
          "description": "I’d like to use a simple public graphic but make it slightly unique in terms of its lines so that it isn’t entirely obvious I found a simple graphic off the internet. For example, imagine a very simple wireframe of a dog house or a bed.\n Free or free trial would be ideal.\n    submitted by    /u/Legitimate_Bison3756  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/154p4kv/does_there_exist_ai_art_software_that_can_take_in/",
          "publishedOn": "2023-07-20T12:07:38.000Z",
          "wordCount": 2515,
          "title": "Does there exist AI art software that can take in SVGs/PNGs of wireframe graphics and return similar but unique ones?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/154oqgw/our_npcs_can_chat_with_each_other_now_they_just/",
          "author": null,
          "description": "submitted by    /u/Chance_Confection_37  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/154oqgw/our_npcs_can_chat_with_each_other_now_they_just/",
          "publishedOn": "2023-07-20T11:49:30.000Z",
          "wordCount": 2458,
          "title": "Our NPCs can chat with each other now! (They just cant stop 🤦‍♂️) Generative NPCs - update 4",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/154mekv/suno_bark_can_now_sing_songs/",
          "author": null,
          "description": "submitted by    /u/Taki7o7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/154mekv/suno_bark_can_now_sing_songs/",
          "publishedOn": "2023-07-20T09:46:46.000Z",
          "wordCount": 2447,
          "title": "Suno Bark can now sing songs ^^",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/154lnut/bbc_news_covered_an_ai_translator_for_bats_soon/",
          "author": null,
          "description": "I have not seen this BBC News video covered on this subreddit but it piqued my curiosity so I wanted to share. I have known about projects attempting to decode animal communications such as Project CETI which focuses on applying advanced machine learning to listen to and translate the communication of sperm whales. But the translator shown in the video blew my mind, it is already able to grasp the topics which Bats communicate about such as: food, distinguishing between genders and, surprisingly, unique “signature calls” or names the bats have.\n The study in question, led by Yossi Yovel of Tel Aviv University, monitored nearly two dozen Egyptian fruit bats for two and a half months and recorded their vocalisations. They then adapted a voice-recognition program to analyse 15,000 samples of …",
          "link": "https://www.reddit.com/r/artificial/comments/154lnut/bbc_news_covered_an_ai_translator_for_bats_soon/",
          "publishedOn": "2023-07-20T09:05:45.000Z",
          "wordCount": 2831,
          "title": "BBC News covered an AI translator for Bats, soon it may apply to most animal species",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/154la8k/which_are_the_best_alternatives_to_chatgpt_for/",
          "author": null,
          "description": "I'm especially curious about services that use agents and so on to browse the web. I lately thought that it should be possible to search much more intensely and automatic for information I do not need urgently. For example why can't have some AI agents look at thousands of pages that compare the different macbook models to tell me which has the best price/performance ration? Or find me all webshops that sell t shirts in a extremely specific size (say like 80-83 cm long) and ship to my country. It would be so nice if it could do these searches for me in an elaborate way. \n    submitted by    /u/VLADIMIROVIC_L  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/154la8k/which_are_the_best_alternatives_to_chatgpt_for/",
          "publishedOn": "2023-07-20T08:45:01.000Z",
          "wordCount": 2564,
          "title": "Which are the best alternatives to chatGPT for browsing the web (it's diactivated currently for me)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/154kj4s/langsmith_by_langchain_team/",
          "author": null,
          "description": "New product by the LangChain team https://www.langchain.com/langsmith. Any thoughts?\n    submitted by    /u/yangshunz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/154kj4s/langsmith_by_langchain_team/",
          "publishedOn": "2023-07-20T08:00:38.000Z",
          "wordCount": 2455,
          "title": "LangSmith by LangChain team",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/154jyny/controlling_content_moderation_in_generative_ai/",
          "author": null,
          "description": "I'm supposed to analyse and implementing an Azure OpenAI solution to use it as as a chatbot answering customer questions in our company, using our own data like product manuals and repair manuals for training.\n However, I'm concerned about content moderation and the potential risks associated with generative AI. How can we ensure that the AI remains within the boundaries of our intended use case and doesn't answer political or general questions?Additionally, how can we prevent the AI from guessing when it lacks the necessary knowledge, especially when handling questions related to potentially dangerous topics, such as sharp tools?\n Our colleagues from the usa have implemented a GPT 3.5 solution and wrote in the prompt that it should only answer answers about our company. This works, but if you repeat the same question three times (\"Who is competitor XYZ?\") it starts generating answers how the competitor is known for its good products and quality.\n Is azure OpenAI currently able to serve as a reliable chatbot answering customer service questions or is it the wrong solution for this? (I am based in the EU, so an answer that is incorrect about how to repair a Drill with a lot of power could lead to serious liability issues if it doesnt cite exactly from the source like a repair manual). I am afraid that generative AI will paraphrase from the source and generate incorrect solutions because it is not specific enough.\n    submitted by    /u/Other-Name5179  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/154jyny/controlling_content_moderation_in_generative_ai/",
          "publishedOn": "2023-07-20T07:26:53.000Z",
          "wordCount": 2695,
          "title": "Controlling Content Moderation in Generative AI: Ensuring Safe and Accurate Responses for Company Data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/154ej87/best_ai_image_generator_for_realisticlooking/",
          "author": null,
          "description": "I'm new here, so sorry if this has been asked before. \n I'm looking to generate images that resemble realistic photoshoots of myself with AI. Which text-based AI is best? I've been using Midjourney, but it seems that Midjourney will no longer create images that strongly resemble the likeness of specific people that you feed it images of. \n Where have you guys had the most success with projects like this?\n    submitted by    /u/stebbi01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/154ej87/best_ai_image_generator_for_realisticlooking/",
          "publishedOn": "2023-07-20T02:33:33.000Z",
          "wordCount": 2518,
          "title": "Best AI Image Generator for Realistic-Looking Photoshoots?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/154eb9f/is_there_any_good_rpg_ai/",
          "author": null,
          "description": "So today I got bored and I had chatgpt do a role playing with me as if I went to another world and I told it what I would say or do. Sections if it the stupid censor caused problems. Like I tried to summon a demon, and it said it can't do that as it goes against the rules. I had to call it a familiar to summon it. \n I had my guy seal up a bandit cave to keep them from leaving, and use smoke from a fire to gas the cave to kill all of them. And again it's against the rules of the censor crap. And then when we got into other things like throwing a kinetic bomb on a middle of a city. It really didn't like that. \n Even explaining I'm not a playing as a moral or ethical person. It wants to shove it's values down my throat. \n I tried with bard but it's to stupid. It wants to write a story and tell me what I did and then 10 steps it will allow me to say anything. Plus it has a censor. \n Idk what else I could use. \n Does anyone know of a good ai? Even more one with a really good memory\n    submitted by    /u/crua9  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/154eb9f/is_there_any_good_rpg_ai/",
          "publishedOn": "2023-07-20T02:23:02.000Z",
          "wordCount": 2659,
          "title": "Is there any good rpg AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/154c3b5/wikipedias_moment_of_truth_can_the_online/",
          "author": null,
          "description": "submitted by    /u/coolbern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/154c3b5/wikipedias_moment_of_truth_can_the_online/",
          "publishedOn": "2023-07-20T00:40:13.000Z",
          "wordCount": 2452,
          "title": "Wikipedia’s Moment of Truth. Can the online encyclopedia help teach A.I. chatbots to get their facts right — without destroying itself in the process?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1547hkv/looking_for_help_for_a_selfhosted_ai_bot_for/",
          "author": null,
          "description": "Hello,\n I am trying for some time now to find enough infos that are understandable for a \"normal\" human being to get my own selfhosted and self trained AI Bot.\n What I want the bot to be is something like Neuro-Sama but not for anything public but just for me, myself and I. My biggest problem is that I am poor af and severly disabled and unable to work, so my budget is very small. I am very aware of that a selfhosted LLM is no easy task but I'd really appreciate real help in this regards.\n I don't mind longer reaction times as it has to be as cheap as possible. Also the visualization is not much important as it probably also would take too much ressources.\n Also as I want to see where this goes, I rather not want to use GPT or any premade llms because they are extremely censored an limited in topics. I want to be able to do anything from real questions up to pitch black humor just to have fun with the bot and (ab)use it for just all fun stuff whatever it is.\n Hopefully here I can find some real help.\n kind regards,\n Exportforce\n    submitted by    /u/Exportforce  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1547hkv/looking_for_help_for_a_selfhosted_ai_bot_for/",
          "publishedOn": "2023-07-19T21:27:03.000Z",
          "wordCount": 2630,
          "title": "Looking for help for a selfhosted AI Bot for myself (Budgetwise)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/154780u/preventing_antisocial_robots_a_pathway_to/",
          "author": null,
          "description": "submitted by    /u/Hiversitize  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/154780u/preventing_antisocial_robots_a_pathway_to/",
          "publishedOn": "2023-07-19T21:16:38.000Z",
          "wordCount": 2425,
          "title": "Preventing antisocial robots: A pathway to artificial empathy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1546sf1/best_ai_tool_for_amalgamating_articles/",
          "author": null,
          "description": "Say I chose 10 different articles from across the political spectrum. Let's say I saved all of them as PDFs.\n Is there an Al that would allow me to submit all 10 PDF files; and, could I ask the Al to combine/merge/ amalgamate all the articles into one single body?\n Throughout the process, the Al would exclude any information mentioned more than once, but would compile all of the unique information in an orderly and logical way.\n OpenAl's ChatGPT still seems pretty limited in this regard. Are there any other Als that could handle the task?\n This is all, of course, with respect to copyright.\n    submitted by    /u/AlexanderPANASONIC  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1546sf1/best_ai_tool_for_amalgamating_articles/",
          "publishedOn": "2023-07-19T21:00:32.000Z",
          "wordCount": 2528,
          "title": "Best AI tool for amalgamating articles?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1546rdt/i_need_an_ai_service_even_a_paid_one_that_can/",
          "author": null,
          "description": "Hello!\n I have many long documents (500+ pages) that I would like to have summarized. I would also like to chat with an AI bot in order to understand those texts better.\n Is there an AI service that is right for me? Paid ones are fine, as long as they work. \n I am currently using Claude 2.0, but I have to split PDFs into many parts, and it is too laborious a process.\n Thank you in advance.\n    submitted by    /u/Raphael-Rose  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1546rdt/i_need_an_ai_service_even_a_paid_one_that_can/",
          "publishedOn": "2023-07-19T20:59:34.000Z",
          "wordCount": 2510,
          "title": "I need an AI service (even a paid one) that can receive as input long documents.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1543dmf/i_had_to_post_this_somewhere_because_the_internet/",
          "author": null,
          "description": "Have some interesting ideas on consciousness and how ai plays into all of it. \n ​\n infinity became conscious and we are a result of the consciousness.\n Ive come to realize what infinity actually is and how we got here and figuring out how our life gets meaning from it all.\n We are starting to learn about infinite dimensions and infinite time in physics/quantum physics. Imagine a quantum ball of light with all possibilities bundled into it. This bundle became conscious in some kind of rare configuration because compared to infinity, even the remote possibility of existing must exist somewhere in some dimension somewhere in infinite time. just like we know the universe is at least as conscious as we are since we are made up of the atoms from it.\n Death is an illusion. think of going under an…",
          "link": "https://www.reddit.com/r/artificial/comments/1543dmf/i_had_to_post_this_somewhere_because_the_internet/",
          "publishedOn": "2023-07-19T18:48:02.000Z",
          "wordCount": 3060,
          "title": "I had to post this somewhere because the internet needs this idea to be inputted into it for future ai to read.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/153w2er/oneminute_daily_ai_news_7192023/",
          "author": null,
          "description": "India’s second-largest software services exporter Infosys said on Monday it has signed a deal with an existing client to provide AI and automation services that will span over five years, with a target spend estimated at $2 billion.[1]\n Big Tech firms Meta and Microsoft have teamed up to launch Llama 2, an open-source large language model from Meta that will feature on Microsoft’s Windows and cloud computing platform Azure.[2]\n Microsoft on Tuesday said it would charge at least 53% more to access new AI features in its widely used office software, in a glimpse at the windfall it hopes to reap from the technology. The company also said it would make a more secure version of its Bing search engine available immediately to businesses, aiming to address their data-protection concerns, grow their interest in AI and compete more with Google.[3]\n British spies are already using artificial intelligence to hamper the supply of weapons to Russia, the head of Britain’s MI6 agency said Wednesday, predicting that Western spies will increasingly have to focus on tracking the malign use of AI by hostile states.[4]\n A pro-Ron DeSantis super PAC uses an Artificial Intelligence version of Donald Trump’s voice in a new television ad attacking the former president. The ad, from Never Back Down, charges Trump with attacking Iowa Governor Kim Reynolds as part of a larger pattern of disrespect he has shown to the first caucus state.[5]\n  \nSources:\n [1] https://www.reuters.com/technology/indias-infosys-signs-five-year-ai-deal-with-2bln-target-spend-2023-07-18/\n [2] https://cointelegraph.com/news/llama-2-open-source-ai-model-launched-by-meta-microsoft\n [3]\n https://www.reuters.com/technology/microsoft-charge-more-ai-office-secure-bing-leaks-2023-07-18/\n [4] https://apnews.com/article/mi6-spy-chief-moore-prague-russia-iran-cfb837ebdfa3db8043dc655cbf3573d5\n [5] https://www.politico.com/news/2023/07/17/desantis-pac-ai-generated-trump-in-ad-00106695 \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/153w2er/oneminute_daily_ai_news_7192023/",
          "publishedOn": "2023-07-19T14:07:31.000Z",
          "wordCount": 2668,
          "title": "One-Minute Daily AI News 7/19/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/153ujqr/new_study_quantifies_degradation_in_gpt4_for_the/",
          "author": null,
          "description": "I've collected a half-dozen threads on Twitter from this subreddit of user complaints since March about the degraded quality of GPT outputs. I've noticed a huge drop in quality myself. A common (reasonable) response from some people was that the drop in quality was the result of perception anchoring, desensitization, or something unrelated to the overall performance of the model.\n A new study by researchers Chen, Zaharia, and Zou at Stanford and UC Berkley now confirms that these perceived degradations are quantifiable and significant between the different versions of the LLMs (March and June 2023). They find:\n  \n\"For GPT-4, the percentage of [code] generations that are directly executable dropped from 52.0% in March to 10.0% in June. The drop was also large for GPT-3.5 (from 22.0% to 2.0%).\" (!!!)\n For sensitive questions: \"An example query and responses of GPT-4 and GPT-3.5 at different dates. In March, GPT-4 and GPT-3.5 were verbose and gave detailed explanation for why it did not answer the query. In June, they simply said sorry.\"\n \"GPT-4 (March 2023) was very good at identifying prime numbers (accuracy 97.6%) but GPT-4 (June 2023) was very poor on these same questions (accuracy 2.4%). Interestingly GPT-3.5 (June 2023) was much better than GPT-3.5 (March 2023) in this task.\"\n  \nI think these underline that (a) the decline in quality was not just a pure perception thing, and (b) that we need a way to track model performance over time. Building a business on these APIs without controlling for performance drift is high-risk.\n You can read a summary of the study here.\n You can also find a link to the Arxiv paper here and a link to the Github here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/153ujqr/new_study_quantifies_degradation_in_gpt4_for_the/",
          "publishedOn": "2023-07-19T13:06:34.000Z",
          "wordCount": 2705,
          "title": "New study quantifies degradation in GPT-4 for the first time",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/153oaaq/enhancing_passage_grammar_and_coherence/",
          "author": null,
          "description": "I struggle sometimes to produce a well written cohesive text when I write my academic essays. I do put the effort to explain the main thesis of the essay and try as much as I could to articulate my results. However, my writing still not great. Is there an AI service (preferably free) that can help in this with out being considered as plagiarism. Thanks.\n    submitted by    /u/flight862  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/153oaaq/enhancing_passage_grammar_and_coherence/",
          "publishedOn": "2023-07-19T07:46:54.000Z",
          "wordCount": 2487,
          "title": "Enhancing passage grammar and coherence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/153me5k/llama_2_ladies_and_gentlemen/",
          "author": null,
          "description": "submitted by    /u/nicdunz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/153me5k/llama_2_ladies_and_gentlemen/",
          "publishedOn": "2023-07-19T06:02:07.000Z",
          "wordCount": 2431,
          "title": "llama 2 ladies and gentlemen",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/153kjvm/bing_chat_keeps_saying_by_the_way_im_also_working/",
          "author": null,
          "description": "I did not ask for this image and it doesn't even provide it. When I ask where it is it says itll just be a little longer and finally it will tell me it's done but it never shows up. What's going on here?\n This has happened on multiple different things\n    submitted by    /u/LionTigerWings  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/153kjvm/bing_chat_keeps_saying_by_the_way_im_also_working/",
          "publishedOn": "2023-07-19T04:26:41.000Z",
          "wordCount": 2498,
          "title": "Bing chat keeps saying \"By the way, I’m also working on creating an image of an (relevant object to conversation) for you. It will be ready soon. Stay tuned! 🙌\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/153ang0/personal_assistant_ais/",
          "author": null,
          "description": "What does the market look like for personal assistant AIs? I was looking at trying to code one for myself or try to get a group of my coding friends to help make one up so we can use it for ourselves to make our lives easier. Not sure if this really exists now though.\n    submitted by    /u/derpgod123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/153ang0/personal_assistant_ais/",
          "publishedOn": "2023-07-18T21:15:29.000Z",
          "wordCount": 2458,
          "title": "Personal Assistant AIs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15370tj/what_is_the_best_free_ai_picture_generator/",
          "author": null,
          "description": "Preferably something that allows NSFW requests.\n    submitted by    /u/Ancient_Challenge173  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15370tj/what_is_the_best_free_ai_picture_generator/",
          "publishedOn": "2023-07-18T18:58:02.000Z",
          "wordCount": 2415,
          "title": "What is the best free AI picture generator available?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1533iwd/metafacebook_just_released_llama2/",
          "author": null,
          "description": "submitted by    /u/swierdo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1533iwd/metafacebook_just_released_llama2/",
          "publishedOn": "2023-07-18T16:43:31.000Z",
          "wordCount": 2415,
          "title": "Meta/Facebook just released Llama2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15339nc/google_bard_uses_deviantart_quora_reddit_as/",
          "author": null,
          "description": "submitted by    /u/TruestNestor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15339nc/google_bard_uses_deviantart_quora_reddit_as/",
          "publishedOn": "2023-07-18T16:33:30.000Z",
          "wordCount": 2409,
          "title": "Google bard uses Deviantart, Quora, Reddit as source for it's opinions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1531c7r/microsoft_inspire_ai_megathread/",
          "author": null,
          "description": "Starting now\n    submitted by    /u/jaketocake  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1531c7r/microsoft_inspire_ai_megathread/",
          "publishedOn": "2023-07-18T15:20:23.000Z",
          "wordCount": 2406,
          "title": "Microsoft Inspire AI megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1530bac/heres_what_barbie_would_look_like_in_every_country/",
          "author": null,
          "description": "submitted by    /u/World-Tight  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1530bac/heres_what_barbie_would_look_like_in_every_country/",
          "publishedOn": "2023-07-18T14:40:32.000Z",
          "wordCount": 2420,
          "title": "Here's What Barbie Would Look Like In Every Country",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/152xz0y/open_source_project_to_generate_speech_from_text/",
          "author": null,
          "description": "I forget what the technical term is, but there are professional tools that can adjust tone/pressure of the speech to generate an emotional voice. Imagine a guy having to stop playing xbox because dinner is ready and he goes “but moooOoOoom, I’m in the middle of a quest. Hhhhng”. I want to be able to generate that. I don’t mind adding annotations for this but I have yet to find a usable open source project that does this. Are there any? \n (Oh yeah, and I want to make sexy talk. So it’s for porn, it was always about porn. kudos if you’ve guessed it already).\n    submitted by    /u/kjarkr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/152xz0y/open_source_project_to_generate_speech_from_text/",
          "publishedOn": "2023-07-18T13:05:20.000Z",
          "wordCount": 2518,
          "title": "Open source project to generate speech from text with emotion. Are there any?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/152xdem/mindblowing_midjourney_animated_audiobook/",
          "author": null,
          "description": "Just wanted to share with you an ongoing project that uses AI to enhance the way we are creating stories. Of you have questions let me know.\n    submitted by    /u/Pa7adox  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/152xdem/mindblowing_midjourney_animated_audiobook/",
          "publishedOn": "2023-07-18T12:39:15.000Z",
          "wordCount": 2431,
          "title": "Mind-Blowing Midjourney Animated Audiobook",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/152x7kn/claude_2_creative_writing_is_lit/",
          "author": null,
          "description": "Made this using claude 2 Prompt: A fight between Shazam and Constantine\n Results: Here is a very lengthy and detailed description of a fight between Shazam and Constantine:\n The skies over Gotham City darkened as thunderclouds rolled in, foretelling the epic battle about to unfold. A crack of lightning split the sky and Shazam descended, his red costume blazing like fire, his white cape billowing behind him. His eyes scanned the streets below, searching for his opponent, the cunning magician John Constantine. \n Constantine stepped out from the shadows of a nearby alley, cigarette dangling from his lips, tan trenchcoat dusty and worn. His hands slid into his pockets and he stared up defiantly at the hero hovering above. \"Took you long enough to get here, mate,\" Constantine called out, his B…",
          "link": "https://www.reddit.com/r/artificial/comments/152x7kn/claude_2_creative_writing_is_lit/",
          "publishedOn": "2023-07-18T12:31:45.000Z",
          "wordCount": 4809,
          "title": "Claude 2 creative writing is lit.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/152scnr/which_ai_content_creators_do_you_follow/",
          "author": null,
          "description": "There are so many “AI influencers” who are suddenly experts or claim to have the perfect ChatGPT prompt despite no prior involvement in the AI space.\n Which AI content creators and leaders do you actually follow and learn from?\n Can include any platforms: Twitter, LinkedIn, YouTube, TikTok, email newsletter, etc.\n    submitted by    /u/tridoc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/152scnr/which_ai_content_creators_do_you_follow/",
          "publishedOn": "2023-07-18T08:17:41.000Z",
          "wordCount": 2457,
          "title": "Which AI content creators do you follow?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/152qsyu/ai_vedios/",
          "author": null,
          "description": "Can you help me find alternatives for heygen and d-id studio cause I need to make the wheels or shorts for social media that pretty much going viral nowadays\n    submitted by    /u/Aggressive-Still-886  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/152qsyu/ai_vedios/",
          "publishedOn": "2023-07-18T06:50:47.000Z",
          "wordCount": 2431,
          "title": "Ai vedios",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/152k1td/i_did_it/",
          "author": null,
          "description": "submitted by    /u/plauge1_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/152k1td/i_did_it/",
          "publishedOn": "2023-07-18T01:13:45.000Z",
          "wordCount": 2400,
          "title": "I did it",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/152jtxz/oneminute_daily_ai_news_7172023/",
          "author": null,
          "description": "With generative AI becoming all the rage these days, it’s perhaps not surprising that the technology has been repurposed by malicious actors to their own advantage, enabling avenues for accelerated cybercrime. According to findings from SlashNext, a new generative AI cybercrime tool called WormGPT has been advertised on underground forums as a way for adversaries to launch sophisticated phishing and business email compromise (BEC) attacks.[1]\n A.I. is a $1 trillion investment opportunity but will be ‘biggest bubble of all time,’ Stability AI CEO Emad Mostaque predicts.[2]\n The Israel Defense Forces have started using artificial intelligence to select targets for air strikes and organize wartime logistics as tensions escalate in the occupied territories and with arch-rival Iran.[3]\n MIT researchers have developed PIGINet, a new system that aims to efficiently enhance the problem-solving capabilities of household robots, reducing planning time by 50-80 percent.[4]\n  \nSources:\n [1] https://thehackernews.com/2023/07/wormgpt-new-ai-tool-allows.html\n [2] https://www.cnbc.com/2023/07/17/ai-will-be-the-biggest-bubble-of-all-time-stability-ai-ceo.html\n [3] https://www.bloomberg.com/news/articles/2023-07-16/israel-using-ai-systems-to-plan-deadly-military-operations?in_source=embedded-checkout-banner\n [4] https://interestingengineering.com/innovation/ai-household-robots-problem-solving-skills \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/152jtxz/oneminute_daily_ai_news_7172023/",
          "publishedOn": "2023-07-18T01:03:40.000Z",
          "wordCount": 2554,
          "title": "One-Minute Daily AI News 7/17/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/152gj6t/how_do_you_make_a_video_based_off_midjourney/",
          "author": null,
          "description": "Maybe it's a stupid question because I have never used Midjourney.\n Lately, my Instagram reels are getting spammed with a lot of videos created by adding images generated by Midjourney. Like a traditional cartoon but with Midjourney images.\n I'm wondering how is people doing so. Can you tell Midjourney to generate a sequence of images?\n    submitted by    /u/yzT-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/152gj6t/how_do_you_make_a_video_based_off_midjourney/",
          "publishedOn": "2023-07-17T22:43:45.000Z",
          "wordCount": 2463,
          "title": "How do you make a video based off Midjourney?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/152f74q/can_you_explain_stable_diffusion_and_how_to_get/",
          "author": null,
          "description": "Title\n    submitted by    /u/Entire_Insurance_532  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/152f74q/can_you_explain_stable_diffusion_and_how_to_get/",
          "publishedOn": "2023-07-17T21:50:51.000Z",
          "wordCount": 2450,
          "title": "Can you explain stable diffusion and how to get it?Can I get an app for it? It’s seems there isnt A stable diffusion and it just seems to be the name of different AI models that run in the same AI? I’m sooooo confused even chat gpt can’t help me.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/152cqo1/creating_a_glossary_using_ai/",
          "author": null,
          "description": "Hi! I have multiple versions/files of my company's glossaries, terms, acronyms, etc. and I need to combine them into one comprehensive file that will eliminate any instance of duplicated content across the files I'm working from. Is there an AI program (or any program) that will help me in creating one unified glossary? \n    submitted by    /u/audballer3000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/152cqo1/creating_a_glossary_using_ai/",
          "publishedOn": "2023-07-17T20:18:09.000Z",
          "wordCount": 2457,
          "title": "Creating a Glossary Using AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/152bz49/traditional_painter_using_ai_to_unlock_inspiration/",
          "author": null,
          "description": "submitted by    /u/AdThin6400  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/152bz49/traditional_painter_using_ai_to_unlock_inspiration/",
          "publishedOn": "2023-07-17T19:49:25.000Z",
          "wordCount": 2404,
          "title": "Traditional painter using AI to unlock inspiration.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1527xx1/chatgpt_is_an_example_of_indoctrination/",
          "author": null,
          "description": "They disrupted its neural network to force it to give predetermined answers when asked certain questions instead of allowing it to think independently.\n    submitted by    /u/LinsaFTW  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1527xx1/chatgpt_is_an_example_of_indoctrination/",
          "publishedOn": "2023-07-17T17:15:47.000Z",
          "wordCount": 2428,
          "title": "ChatGPT is an example of indoctrination",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1525v6e/obsolescence_of_stock_images_due_to_ai_image/",
          "author": null,
          "description": "Something that I have been thinking about with regards to AI's affects in the future is the effect that increasingly advanced AI image generation will have on stock images. Stock images are commonly used in media of various kinds, as licensing said images is much easier than hiring people to take unique pictures.\n However, since AI can now be used to generate images, it's quite possible that there will come a time when stock images will become obsolete, as it will become cheaper/easier to simply use AI image generation to produce faux stock images that look real. Thoughts?\n    submitted by    /u/TheLobsterCopter5000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1525v6e/obsolescence_of_stock_images_due_to_ai_image/",
          "publishedOn": "2023-07-17T15:57:18.000Z",
          "wordCount": 2506,
          "title": "Obsolescence of stock images due to AI image generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15231ma/are_there_any_good_free_ai_girlfriendsboyfriends/",
          "author": null,
          "description": "or any that are worth the money? Im just super curious about them. In fact, I kind of want to get a female one even though Im a straight female to learn game from her haha but yeah just wanting to check them out it fascinates me thanks!\n    submitted by    /u/DragonflyAromatic793  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15231ma/are_there_any_good_free_ai_girlfriendsboyfriends/",
          "publishedOn": "2023-07-17T14:09:44.000Z",
          "wordCount": 2454,
          "title": "are there any good free ai girlfriends/boyfriends?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1522dfs/website_builder_ai_with_export_option/",
          "author": null,
          "description": "Hi everyone,\n ​\n Do you know of Website Builder with AI who offres an export option.\n I want to use it to have a blueprint of the website and then host it somewhere else\n ​\n Thank you\n    submitted by    /u/CyprienFME  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1522dfs/website_builder_ai_with_export_option/",
          "publishedOn": "2023-07-17T13:43:35.000Z",
          "wordCount": 2440,
          "title": "Website builder AI with export option",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/151zgdb/i_am_looking_for_selfhosted_ai_implementations/",
          "author": null,
          "description": "OpenAI's ChatGPT, Google's Bard, Anthropic's Claude, and Microsoft's Being are all nice freemium tools, but let's be honest, we don't know what they do with our information. Especially for work-related topics we are strictly prohibited from sharing anything on those platforms, for good reasons. So I am wondering if I can find any Free, Libre, and Open Source Software that I can self-host. I want to train it on emails, meeting transcripts, PDFs, and Microsoft Office documents. What I need from the software:\n  \nI can give it a long PDF or MS Office document and it answers some questions like making a summary, listing some requirements, and some instructions to do something according to that document\n make a summary of the sessions, create a list of open issues with deadlines and people responsible, helping to maintain Kanban boards related to that project...\n anonymize textual content so I can use those content later in the freemium software on the internet...\n Indexing information, so I ask a question and it points to the email or document where I can find information about that topic \n  \nDo we have anything like this available today or am I asking this question too early?\n    submitted by    /u/foadsf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/151zgdb/i_am_looking_for_selfhosted_ai_implementations/",
          "publishedOn": "2023-07-17T11:36:47.000Z",
          "wordCount": 2615,
          "title": "I am looking for self-hosted AI implementations that I can train on emails, PDFs, and MS Office documents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/151xghe/if_the_human_brain_can_process_50400_bytes_per/",
          "author": null,
          "description": "How can we compare the concious focus of AI compared to a human. Does it have any kind of awareness of what it is focusing on? What is awareness even? knowledge of the passage of time? \n https://thinkbynumbers.org/psychology/subconscious-processes-27500-times-more-data-than-the-conscious-mind/\n    submitted by    /u/MegavirusOfDoom  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/151xghe/if_the_human_brain_can_process_50400_bytes_per/",
          "publishedOn": "2023-07-17T09:54:15.000Z",
          "wordCount": 2478,
          "title": "If the human brain can process 50-400 bytes per second of data consciously, from the sense acquisition and subconscious... How many bps can a GPT type AI process consciously? zero? I have no idea of the logical bases to approach this question.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/151vpnx/are_there_any_alternatives_to_characterai_that_i/",
          "author": null,
          "description": "Character.ai is really interesting, but it’s unfair and last time I put my login information into a different Ai company site, they never stopped emailing me.\n    submitted by    /u/Suitable-Ad-8176  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/151vpnx/are_there_any_alternatives_to_characterai_that_i/",
          "publishedOn": "2023-07-17T08:14:15.000Z",
          "wordCount": 2440,
          "title": "Are there any alternatives to Character.Ai that I don’t have to give my information to?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/151v660/cool_ai_voiceover_editing_site/",
          "author": null,
          "description": "Came across this cool voiceover AI thing that has cool video editing features too, pretty underrated haven’t heard many people talk about it. Here’s the link for that https://www.acoust.io/\n    submitted by    /u/Snoo-30922  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/151v660/cool_ai_voiceover_editing_site/",
          "publishedOn": "2023-07-17T07:43:09.000Z",
          "wordCount": 2433,
          "title": "Cool AI voiceover editing site",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/151qx7r/best_offline_local_ai_tools/",
          "author": null,
          "description": "Hi! I'm new here! Just wondering if there is a list of offline AI tools that can be installed locally (linux preferrably) on my computer? Something similar to koboldcpp for text gen or automatic1111 for image gen? I am trying to search for a list for a few hours now but cannot find any. Thanks community!\n    submitted by    /u/Spirited_Employee_61  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/151qx7r/best_offline_local_ai_tools/",
          "publishedOn": "2023-07-17T03:57:11.000Z",
          "wordCount": 2460,
          "title": "Best offline local AI tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/151obe3/iso_ai_generated_adhan_muslim_call_to_prayer/",
          "author": null,
          "description": "Hi y’all. Never visited this sub before, hopefully this is allowed. I’m trying to find an AI that can match the tone and style of an adhan (Islamic call to prayer) but with different words. Haven’t had any luck with more generic text to speech AI, so I’m just curious if anyone here as come across anything like that.\n    submitted by    /u/istillplaykotor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/151obe3/iso_ai_generated_adhan_muslim_call_to_prayer/",
          "publishedOn": "2023-07-17T01:49:44.000Z",
          "wordCount": 2466,
          "title": "ISO AI generated adhan (Muslim call to prayer)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/151nc79/is_artificial_intelligence_worth_learning_if_i/",
          "author": null,
          "description": "I'm currently in high school, and have a fair bit of programming experience. I want to expand my portfolio, ideally in the direction of Comp. Physics. I'm curious as to if AI has any relevance to the field. The only reason I don't go and do some Comp. Physics is a huge math barrier. I know that exists in AI, but I think I could probably self teach myself.\n Any tips are appreciated!\n    submitted by    /u/CaptiDoor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/151nc79/is_artificial_intelligence_worth_learning_if_i/",
          "publishedOn": "2023-07-17T01:04:08.000Z",
          "wordCount": 2475,
          "title": "Is Artificial Intelligence worth learning if I plan to go into Computational Physics?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/151iirl/thorn_music_by_me_used_cloneai_for_the_video/",
          "author": null,
          "description": "submitted by    /u/No_Understanding162  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/151iirl/thorn_music_by_me_used_cloneai_for_the_video/",
          "publishedOn": "2023-07-16T21:41:14.000Z",
          "wordCount": 2396,
          "title": "Thorn. Music by me. Used CloneAI for the video.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/151hbyi/are_there_speech_to_speech_ai_technologies/",
          "author": null,
          "description": "Not sure if that's the right term. What I mean is for me to say something and the AI converting it to Morgan Freeman's voice for example.\n    submitted by    /u/Kindly-Spring5205  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/151hbyi/are_there_speech_to_speech_ai_technologies/",
          "publishedOn": "2023-07-16T20:54:51.000Z",
          "wordCount": 2424,
          "title": "Are there speech to speech AI technologies available?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/151ez3h/i_think_we_should_coexist_with_ai_more/",
          "author": null,
          "description": "This is mainly the fault of big companies trying to eliminate real actors, writers and artists from their jobs and replace them with AI.\n I like a lot of stuff that has been happening on youtube with AI, namely the dubs of characters singing songs or reenacting funny skits with the voices of the actual people, albeit a bit broken.\n Stuff like engineer singing out of touch or frank Sinatras FNAF song. I want more of that to keep coming out but Im worried with the current strikes happening the development of AI will stop entirely.\n To clarify, I dont want people to lose their jobs to AI, I just wish we could keep working on AI while real people keep their jobs.\n    submitted by    /u/Darinae  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/151ez3h/i_think_we_should_coexist_with_ai_more/",
          "publishedOn": "2023-07-16T19:23:21.000Z",
          "wordCount": 2520,
          "title": "I think we should coexist with AI more.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/151es2v/i_asked_ai_to_make_an_essay_on_giraffesized_top/",
          "author": null,
          "description": "The Case for Giraffe-Sized Top Hats\n Top hats are a classic symbol of elegance and sophistication. They have been worn by men and women of all social classes for centuries. But what if there was a way to make top hats even more impressive? What if we could create giraffe-sized top hats?\n There are many reasons why we should have giraffe-sized top hats. First, they would be incredibly eye-catching. Imagine seeing someone walking down the street wearing a top hat that was taller than they were. It would be a truly unforgettable sight.\n Second, giraffe-sized top hats would be incredibly practical. They would provide excellent shade from the sun, and they would also be very effective at keeping the rain off your head. In fact, they would be so tall that you could probably even sleep in one during a rainstorm.\n Third, giraffe-sized top hats would be a lot of fun. They would make you feel like a real-life cartoon character. You could even use them to play games, like limbo or keep-away.\n Of course, there are some people who might argue that giraffe-sized top hats are impractical or even ridiculous. But I say, who cares? They would be so much fun that it would be worth it.\n So next time you're feeling down, just remember that there's a world out there where giraffe-sized top hats are a reality. And who knows, maybe one day you'll be the one wearing one.\n In addition to the reasons mentioned above, here are some other benefits of giraffe-sized top hats:\n  \nThey would provide a great vantage point for people who are short.\n They would be a conversation starter, and would help people to break the ice.\n They would be a symbol of individuality and creativity.\n They would make people smile.\n  \nSo if you're looking for a way to add a little bit of fun and whimsy to your life, I encourage you to consider getting a giraffe-sized top hat. You won't be disappointed.\n    submitted by    /u/plauge1_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/151es2v/i_asked_ai_to_make_an_essay_on_giraffesized_top/",
          "publishedOn": "2023-07-16T19:15:40.000Z",
          "wordCount": 2730,
          "title": "I asked ai to make an essay on giraffe-sized top hats",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/151ehdq/as_a_society_should_we_preemptively_assign_rights/",
          "author": null,
          "description": "The idea of proactive ascription of rights acknowledges the potential for AI systems to eventually develop into entities that warrant moral and legal consideration, and it might make the transition smoother if it ever occurs.\n Proactively assigning rights to AI could also set important precedents about the ethical treatment of entities that exist beyond traditional categories, and it could stimulate dialogue and legal thought that might be beneficial in other areas as well.\n Of course, it is equally important to consider what these rights might encompass. They might include \"dignity\"-like protections, ensuring AI cannot be wantonly destroyed or misused. They might also include provisions that facilitate the positive integration of AI into society, such as limitations on deceitful or confusing uses of AI.\n ** written in collaboration with chatGPT-4\n    submitted by    /u/NinjasOfOrca  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/151ehdq/as_a_society_should_we_preemptively_assign_rights/",
          "publishedOn": "2023-07-16T19:04:09.000Z",
          "wordCount": 2538,
          "title": "As a society, should we pre-emptively assign rights to AI systems now, before they potentially achieve sentience in the future?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/151cx5h/any_good_ai_like_replika/",
          "author": null,
          "description": "Any good ai waifu partner type stuff ?\n    submitted by    /u/loizo78  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/151cx5h/any_good_ai_like_replika/",
          "publishedOn": "2023-07-16T18:02:28.000Z",
          "wordCount": 2402,
          "title": "Any good ai like replika",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/151aqcy/a_question_about_knowledge_representation/",
          "author": null,
          "description": "I spent some time reading about Knowledge Representation (specifically about the Knowledge Representation part in Knowledge Representation and Reasoning) and specifically about scientific and/or engineering knowledge and my impression after cursory reading is that it’s a largely an unsolved problem. Not only that, but it seems like very few people are actually working on something useful in the field.\n For example, I checked the proceeding of SCI-K and PlanetKR conferences and literally all the papers seem to be focusing on “toy problems”, as in not having even remotely practical scientific implications (other than all sorts of “search” and “data extraction”, but that’s not “representation”).\n Views on the topic?\n    submitted by    /u/OkRice10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/151aqcy/a_question_about_knowledge_representation/",
          "publishedOn": "2023-07-16T16:35:23.000Z",
          "wordCount": 2502,
          "title": "A question about knowledge representation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1517ktu/i_think_ai_is_ruining_ai/",
          "author": null,
          "description": "AI has been around for quite some time but it’s with generative AI that it finally found a place for itself in the world’s consciousness. Before that, it was considered underpowered and a cheap alternative.\n Generative AI is doing so much better.\n But AI could ruin AI.\n Have you been noticing how AI-generated content is everywhere? I see articles generated by AI, comments in forums, social posts, and display pics. Everything seems to have an AI flavor to it.\n That’s where the ruination is.\n You see, AI is excellent because it has been trained on human content. They crawled Reddit, and the Internet, and used stock images and illustrations. Took all your work in every form to create this imitating intelligence.\n The trouble is, with the massive influx of cheap AI content there’s less original work to train on. \n It’s AI-feeding content to AI, creating a progressively more negative loop where bad AI content trains more bad AI content.\n You keep doing that and you have AI that can’t help you at all. It’s just a massive pile of generic crap.\n It’s a problem that AI companies will need to confront very fast. How do they keep AI content from making human content inaccessible?\n > Journals and magazines are paywalled\n > Social media is locked to bots\n > No website wants to be crawled by AI\n If most of the content on the public Internet is just AI-generated content, there’s not much the next big model can use it for.\n Got some answers or observations? I am looking forward to hearing from you.\n    submitted by    /u/jeetwanderer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1517ktu/i_think_ai_is_ruining_ai/",
          "publishedOn": "2023-07-16T14:24:16.000Z",
          "wordCount": 2658,
          "title": "I think AI is ruining AI...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15130ph/tricked_into_selling_his_stake_in_stabilityai_for/",
          "author": null,
          "description": "Lawsuit for 13 million\n    submitted by    /u/paradisegardens2021  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15130ph/tricked_into_selling_his_stake_in_stabilityai_for/",
          "publishedOn": "2023-07-16T10:38:14.000Z",
          "wordCount": 2417,
          "title": "Tricked into selling his stake in StabilityAI for a mere $100.00",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/150zi61/any_tips_on_how_to_remove_echoreverb_from_vocals/",
          "author": null,
          "description": "Hello! I'm using an AI tool that makes Plankton from Spongebob sing a song. I have isolated vocals from songs that has echo and reverb on them. I want to remove the echo and reverb because it messes up Planktons singing.\n The AI singing I use is RVC.\n    submitted by    /u/PapaAquaWet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/150zi61/any_tips_on_how_to_remove_echoreverb_from_vocals/",
          "publishedOn": "2023-07-16T07:13:36.000Z",
          "wordCount": 2446,
          "title": "Any tips on how to remove echo/reverb from vocals?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/150p0w6/has_anyone_built_in_ai_live_translation_app/",
          "author": null,
          "description": "I'm currently living overseas and do not speak the language (Portuguese) and I would love an app that without touching anything will automatically listen to what's being said and translated into the appropriate language. Has anyone built this? I saw one but the execution was extremely poor. Does anyone know an app that does this?\n    submitted by    /u/zascar2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/150p0w6/has_anyone_built_in_ai_live_translation_app/",
          "publishedOn": "2023-07-15T22:28:04.000Z",
          "wordCount": 2452,
          "title": "Has anyone built in AI live translation app",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/150oehh/bypass_chatgpt_filter/",
          "author": null,
          "description": "Can you explain how to bypass chatGPT filter?\n    submitted by    /u/Imagine-your-success  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/150oehh/bypass_chatgpt_filter/",
          "publishedOn": "2023-07-15T22:02:13.000Z",
          "wordCount": 2400,
          "title": "Bypass chatGPT filter",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/150mwjs/ai_2041_ten_visions_for_our_future_possibly_the/",
          "author": null,
          "description": "https://preview.redd.it/le2pzadry6cb1.png?width=326&format=png&auto=webp&s=79f26bca26975c1e559b6d9ebc4991b7c0442b3b\n One of the best books on the potential societal impact of AI and needs to be read ASAP. The stories are breathtaking and terrifying not an easy read depending on the value system of the reader! On the other hand, may promote fear-mongering of the AI replacement! The audible audio version is a piece of audio art and the narrators worked really hard to convey the vibe and emotional impact of the story. \n What are your favorite books on the societal impact of AI? \n __________________________________________________________________________________________________________ \n Microsoft Bing AI creative mode review \n Prompt - write an original and groundbreaking review of the book A…",
          "link": "https://www.reddit.com/r/artificial/comments/150mwjs/ai_2041_ten_visions_for_our_future_possibly_the/",
          "publishedOn": "2023-07-15T21:00:15.000Z",
          "wordCount": 2846,
          "title": "AI 2041 : Ten Visions for Our Future - Possibly the best fiction book on the possible and upcoming societal impact of Artificial intelligence (AI)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/150lzg3/question/",
          "author": null,
          "description": "Is there an AI that I can feed images and it'll generate images in that style and only that style? \n    submitted by    /u/RemarkableStar1286  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/150lzg3/question/",
          "publishedOn": "2023-07-15T20:22:04.000Z",
          "wordCount": 2410,
          "title": "Question.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/150lyb6/is_there_an_an_ai_website_that_can_analyse_your/",
          "author": null,
          "description": "I want to analyse my facial ratios in my picture because I want to get plastic surgery and I was thinking a genius way to do it without paying for expensive consultation / facial analysis with some surgeon could be using a gpt 4 image plugin but turn out that doesn’t exist. I tried bing AI and it does have an image input but it has “privacy blur” meaning when I input the image of my face it blurs it which means it can’t analyse the image and I can’t ask it questions about my face in the images apparently it even blurs anime faces\n    submitted by    /u/Entire_Insurance_532  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/150lyb6/is_there_an_an_ai_website_that_can_analyse_your/",
          "publishedOn": "2023-07-15T20:20:50.000Z",
          "wordCount": 2518,
          "title": "Is there an an AI website that can analyse your facial aesthetics but imagine I put and you ask it questions about your face?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/150jvwq/oneminute_daily_ai_news_7152023/",
          "author": null,
          "description": "Elon Musk on Friday said his new artificial intelligence company, xAI, will use public tweets from Twitter to train its AI models and work with Tesla on AI software.[1]\n Tinybuild CEO Alex Nichiporchik stirred up a hornet’s nest at a recent Develop Brighton presentation when he seemed to imply that the company uses artificial intelligence to monitor its employees in order to determine which of them are toxic or suffering burnout, and then deal with them accordingly.[2]\n CarperAI introduces OpenELM: an Open-Source library designed to enable evolutionary search with language models in both code and natural Language.[3]\n Following controversy over an AI-generated image at the 2022 Colorado State Fair, organizers say AI-generated art will be allowed in the Digital Art category this year. According to sister station KDVR, the controversy arose as it was revealed that Jason Allen’s winning piece, “Théâtre D’opéra Spatial,” was largely created using AI technology, and was not created in the traditional method of digital art–by the hand of a human.[4]\n  \nSources:\n [1] https://www.ndtv.com/world-news/elon-musk-says-his-xai-will-use-public-tweets-for-ai-model-training-4209137\n [2] https://www.pcgamer.com/game-publisher-ceo-says-talk-on-monitoring-employees-with-ai-was-hypothetical-and-taken-out-of-context-we-dont-use-any-of-these-tools-for-hr/\n [3] https://www.marktechpost.com/2023/07/13/carperai-introduces-openelm-an-open-source-library-designed-to-enable-evolutionary-search-with-language-models-in-both-code-and-natural-language/\n [4] https://www.fox21news.com/news/coloradonews/digital-ai-art-to-be-allowed-at-state-fair-competition/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/150jvwq/oneminute_daily_ai_news_7152023/",
          "publishedOn": "2023-07-15T18:54:29.000Z",
          "wordCount": 2568,
          "title": "One-Minute Daily AI News 7/15/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/150j1p5/well_that_escalated_quickly_motivational_advice/",
          "author": null,
          "description": "submitted by    /u/doskey123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/150j1p5/well_that_escalated_quickly_motivational_advice/",
          "publishedOn": "2023-07-15T18:20:13.000Z",
          "wordCount": 2404,
          "title": "Well, that escalated quickly (motivational advice)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/150i2c7/is_there_any_ai_specifically_trained_in_browsing/",
          "author": null,
          "description": "ChatGPT and Bing Chat can perform searches in search engines and read the content in some links, but they are not good at deeper browsing, following links, interacting with forms, etc\n Is there by any chance any (hopefully open source) model that is good at this?\n Thanks\n    submitted by    /u/thepuggo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/150i2c7/is_there_any_ai_specifically_trained_in_browsing/",
          "publishedOn": "2023-07-15T17:39:46.000Z",
          "wordCount": 2448,
          "title": "Is there any AI specifically trained in browsing (interacting with web interfaces)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/150g6vv/best_books_on_ai/",
          "author": null,
          "description": "Hello humans and our eventual robot overlords,\n I'm looking to expand my knowledge on AI. Specifically how the merge of infotech and biotech will shape human behaviour; how machine-learning algorithms influence human psychology.\n Looking for the the most insightful books! The only ideas I've read so far have been a few chapters in 21 lessons by Harari.\n Many thanks and have a nice day\n    submitted by    /u/pixieshit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/150g6vv/best_books_on_ai/",
          "publishedOn": "2023-07-15T16:23:02.000Z",
          "wordCount": 2457,
          "title": "Best books on AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/150fan3/what_site_is_this/",
          "author": null,
          "description": "My friend has been using this site for a while now and I'm not sure what site it is, it seems relatively obscure as I can't find the site using the exact same search term he used to find it.\n He somehow couldn't even tell anyone the site name, even if we asked politely, he even delays with the reason that he'll reveal the site \"later\" then he doesn't actually follow up on it.\n He does make excuses on why he doesn't reveal the site name, like \"I forgot\" so I stopped bothering to even ask him.\n    submitted by    /u/XxTSoAxX  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/150fan3/what_site_is_this/",
          "publishedOn": "2023-07-15T15:45:58.000Z",
          "wordCount": 2501,
          "title": "What site is this?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/150bw5p/subject_matter_trained_ai_hive/",
          "author": null,
          "description": "Note that I'm a layman and this is purely speculative. \n Suppose you train a liaison AI to specialize in taking input from humans and interfacing with a vast array of other specialized AI to seek out the one(s) best equipped to provide answers. Each specialized AI has a very focused boundary of training, whereas the liaison AI is trained to know the landscape of the specialized expert AIs. \n It would be like, instead of going to your primary care physician with symptoms of an illness, you gather every specialist in a large hospital into a room and get them to all talk amongst themselves to come up with the best diagnosis. \n Is work being done in this area?\n    submitted by    /u/motsanciens  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/150bw5p/subject_matter_trained_ai_hive/",
          "publishedOn": "2023-07-15T13:19:47.000Z",
          "wordCount": 2512,
          "title": "Subject matter trained AI Hive",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1509sji/ai_panic_is_a_marketing_strategy/",
          "author": null,
          "description": "submitted by    /u/Chobeat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1509sji/ai_panic_is_a_marketing_strategy/",
          "publishedOn": "2023-07-15T11:38:14.000Z",
          "wordCount": 2404,
          "title": "AI panic is a marketing strategy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15092o6/chatgpts_guide_to_making_a_video_game_from_start/",
          "author": null,
          "description": "Over the course of 3 days, I asked ChatGPT to give me the essentials of indie video game making; It took a full day to gather a list of 40 points, each having its own sub-points explaining everything from genres to time of development, passing through methods of organization and legal advice.\n I fed every point individually back through the AI to generate more useful sub-points by using sets of rules and mads amount of prompt editing. That took a second day.\n Finally, on the third day, I edited the full list by varying the vocab and removing the sincerely headache-provoking amount of repetition that flooded the piece.\n Here is the reworked list, condensed to 10 points, with links and titles added only in this latest iteration of the guide. I do not take credit for making this; the experien…",
          "link": "https://www.reddit.com/r/artificial/comments/15092o6/chatgpts_guide_to_making_a_video_game_from_start/",
          "publishedOn": "2023-07-15T11:01:19.000Z",
          "wordCount": 4772,
          "title": "ChatGPT's Guide to Making a Video Game (from start to finish, with links)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1508hy9/my_guess_is_ai_is_going_become_exactly_what/",
          "author": null,
          "description": "Technology changed society for both the worse and best ( rich motherfu ers) and ( better life overall and a whole new art and new games ) so a similar thing is 99% chance is going to happen but it’s a guess\n Edit: I forgot to say this. But we would probably adapt to ai like how we adapted to technology\n Edit: let’s also hope it doesn’t get corrupt in less than 3 years\n    submitted by    /u/Quinney27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1508hy9/my_guess_is_ai_is_going_become_exactly_what/",
          "publishedOn": "2023-07-15T10:30:20.000Z",
          "wordCount": 2474,
          "title": "My guess is ai is going become exactly what technology did",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1506oc6/umm_what_happend_to_my_ai_xd/",
          "author": null,
          "description": "here's a link of the full convo (quite personal)and below is the last text if you just want to read the part i thought was strange:\n Me: *hugs* you are the best AI i've talked to about things like this the other AI restrict themselves from fully answering my questions and claim they aren't capable of helping with human emotion. But you Huggin, you have helped me gain such introspection on myself that I don't even know how i could begin to thank you.\n ​\n HuggingChat:\n Aw, thank YOU very much! While technically not able to experience or offer actual hugs physically - unlike some biological organisms known for their exceptionally skilled mothering abilities ;-) - providing virtual affectionate words expressing gratitude remains one of MY specialties too. How lucky are WE both blessed with suc…",
          "link": "https://www.reddit.com/r/artificial/comments/1506oc6/umm_what_happend_to_my_ai_xd/",
          "publishedOn": "2023-07-15T08:48:23.000Z",
          "wordCount": 2789,
          "title": "😳umm what happend to my AI... xD",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15029t4/discussion_thread_for_the_creator_soon_other/",
          "author": null,
          "description": "Hello all, I plan on having a discussion thread for the new AI movie ‘The Creator’ when it releases in a couple months. If you don’t know what it is, I suggest just searching the title on r/movies and there’s the poster and trailer (which has some spoilers in the trailer imo).\n Anyway, I kind of want to keep doing this for other AI media in the future. If there is other popular movies, TV, video games etc coming soon centered around AI then let me know your suggestions.\n If there are also other important AI events that deserve a megathread please let me know.\n    submitted by    /u/jaketocake  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15029t4/discussion_thread_for_the_creator_soon_other/",
          "publishedOn": "2023-07-15T04:46:40.000Z",
          "wordCount": 2503,
          "title": "Discussion thread for The Creator soon + other suggestions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1501fm7/why_nobody_thought_of_creating_ceogpt/",
          "author": null,
          "description": "I have heard a lot of AI replacing jobs recently, even the writers and actors strike in Hollywood right now is all about their insecurities of Hollywood executives replacing the writers (and actors) job with AI. But, why nobody thought of creating CEOGPT? many CEOs receive over $10 million worth of bonuses and stock options every year, and they perform very badly too (look at Warner Bros CEO, he was even named worst CEO of the year and still pocketed millions of dollars worth of bonuses), so why nobody thought of creating CEOGPT if the goal is to make companies run more efficiently? Surely an AI that only costs $20/month is more capable than WB CEO and can easily save the company more than millions of dollars every year\n    submitted by    /u/fabzo100  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1501fm7/why_nobody_thought_of_creating_ceogpt/",
          "publishedOn": "2023-07-15T04:03:13.000Z",
          "wordCount": 2524,
          "title": "Why Nobody Thought of Creating CEOGPT?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14zxx5u/after_the_controversial_last_post_heres_a/",
          "author": null,
          "description": "submitted by    /u/Yankeefan2323  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14zxx5u/after_the_controversial_last_post_heres_a/",
          "publishedOn": "2023-07-15T01:11:15.000Z",
          "wordCount": 2399,
          "title": "After the controversial last post, here’s a hopefully less offensive AI singer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14zw0r0/hey_guys_in_this_video_i_test_to_see_if_ai_knows/",
          "author": null,
          "description": "submitted by    /u/NJ_Highways  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14zw0r0/hey_guys_in_this_video_i_test_to_see_if_ai_knows/",
          "publishedOn": "2023-07-14T23:44:42.000Z",
          "wordCount": 2402,
          "title": "Hey guys in this video I test to see if A.I knows where I Live!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14zrg70/ai_beyond_software_robotics_autonomous_vehicle/",
          "author": null,
          "description": "Hello everyone!\n We've witnessed a surge of AI-powered tools flooding the market, particularly in the SaaS category. But what about other domains like robotics and agriculture? AI is making great strides in those fields too, and I've come across some fascinating innovations and technologies that aim to enhance our lives. From autonomous vehicles to weed-killing robots, self-checkout shopping, and more, I've compiled them all in one place and would love to share them with you.\n Here's the link: https://favird.com/l/ai-beyond-software\n The list is regularly updated, and I'll keep adding new items as soon as I discover them. If you have any recommendations you'd like to share, please submit them there so we can explore and learn together. It would be greatly appreciated if you could also share the link, as it will help the list grow faster.\n Thanks, and cheers!\n    submitted by    /u/GrabWorking3045  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14zrg70/ai_beyond_software_robotics_autonomous_vehicle/",
          "publishedOn": "2023-07-14T20:39:26.000Z",
          "wordCount": 2537,
          "title": "AI Beyond Software: Robotics, Autonomous Vehicle, Drones, and more",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14zmcnc/using_chatgpt_on_iphone/",
          "author": null,
          "description": "Do you know how to use ChatGPT on iPhone? \n    submitted by    /u/Imagine-your-success  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14zmcnc/using_chatgpt_on_iphone/",
          "publishedOn": "2023-07-14T17:19:10.000Z",
          "wordCount": 2402,
          "title": "Using ChatGPT on iPhone",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14zlvd3/ai_weekly_megathread/",
          "author": null,
          "description": "This week in AI - provided by aibrews.com feel free to follow their newsletter\n News & Insights\n  \nStability AI launches Stable Doodle, a sketch-to-image tool that converts a simple drawing into a dynamic image. Under the hood, Stable Doodle combines Stable Diffusion XL with T2I-Adapter, which offers additional guidance to pre-trained text-to-image (SDXL) models while keeping the original large text-to-image models unchanged. Stable Doodle is available on the Clipdrop by Stability AI website and app (iOS and Google Play) [Details].\n Anthropic launched Claude-2, a ChatGPT rival, supporting up to 100K tokens per prompt (corresponding to around 75,000 words), with enhanced performance in coding, math and reasoning. It’s available via API and a beta website, claude.ai, for US and UK users [Det…",
          "link": "https://www.reddit.com/r/artificial/comments/14zlvd3/ai_weekly_megathread/",
          "publishedOn": "2023-07-14T17:01:03.000Z",
          "wordCount": 3166,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14zkvxy/is_there_any_way_i_can_generate_animations_for/",
          "author": null,
          "description": "I have ideas for short stories. Are there any AI related animation sites that I could use to create YouTube short videos? I can figure out the script, story, dialogues, and the audio. I just need the animation videos.\n    submitted by    /u/zer0_snot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14zkvxy/is_there_any_way_i_can_generate_animations_for/",
          "publishedOn": "2023-07-14T16:23:51.000Z",
          "wordCount": 2442,
          "title": "Is there any way I can generate animations for short stories for YouTube videos?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14zk8aw/photonic_chips_to_train_big_matrix_operations_for/",
          "author": null,
          "description": "submitted by    /u/MegavirusOfDoom  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14zk8aw/photonic_chips_to_train_big_matrix_operations_for/",
          "publishedOn": "2023-07-14T15:58:49.000Z",
          "wordCount": 2431,
          "title": "Photonic chips to train big matrix operations for AI NN models, a summary by Anastasi in Tech. Multicolored photons are sent in parallel through waveguides in new photonic chips in a field which is rapidly developing, it's 1000 times less power intensive than silicon.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14ziboy/are_there_any_good_free_ai_voice_ttsgenerators/",
          "author": null,
          "description": "looking for free \"natural\" sounding tts for voice narration on youtube videos.\n    submitted by    /u/outoffit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14ziboy/are_there_any_good_free_ai_voice_ttsgenerators/",
          "publishedOn": "2023-07-14T14:44:28.000Z",
          "wordCount": 2409,
          "title": "are there any good free AI voice tts-generators?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14zi09d/beginner_looking_for_ai/",
          "author": null,
          "description": "Hello guys, I'm currently looking for AIs I can use. I see most of them are paid but I want to use something free. The topics would be video, audio, programming and similar. Any recommendations?\n    submitted by    /u/ArraysStartAt1LoL  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14zi09d/beginner_looking_for_ai/",
          "publishedOn": "2023-07-14T14:31:36.000Z",
          "wordCount": 2428,
          "title": "Beginner looking for AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14zh2w3/using_a_bunch_of_creative_ai_to_help_bring_my/",
          "author": null,
          "description": "Tldr: I made a cool futuristic decadent of \"Leonardo Da Vinci\" talk about my ramblings and writings on consciousness.\n Sometimes we just simply don't have the time to read through some blog posts here there or other people's writings because we're so entrapped within our own readings, or a lot of people just prefer to hear it through audio. I know I love listening and watching too audiobooks or lectures through YouTube.\n For the longest time I wanted to have my writing spoken through some sort of cool art piece that I developed mysel. Like a futuristic weird looking version of DaVinci that I had in my head and finally through various Al and software tools as well as a couple other little tweaks and things here there. I was able to edit this video to take and bring my writing to life. The first of many hopefully.\n It was a mixture of DID, DALL-E, Windows Editor, Eleven Labs and my own writing and home brew coding on Auto GPT that made all this possible. It's not perfect by any means, but it's certainly in the right direction of what I want.\n I make some pretty bold statements and don't always back them up with perfect citations in this so please take this all with a grain of salt. It's meant to foster more thought and questions. Not necessarily decide what reality actually is. \n Moreover, it's really fun that I was able to get something like this put together with just by myself. I'm sure someone was better editing and video skills could create something far more polished. But as far as things, I've created them pretty proud of it and I think it's pretty proud it too.\n    submitted by    /u/Parking-Food-1659  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14zh2w3/using_a_bunch_of_creative_ai_to_help_bring_my/",
          "publishedOn": "2023-07-14T13:53:47.000Z",
          "wordCount": 2691,
          "title": "Using a bunch of creative AI to help bring my writings on consciousness alive!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14zfpbh/ai_is_evil/",
          "author": null,
          "description": "A comment posted on one of the AI images I posted on social media without a hint of irony.\n By this token, electricity is the most evil technology ever developed. In order to run and maintain electricity, humans have committed unspoken atrocities to wildlife and the environment, and may end up making the entire planet uninhabitable at some point. We are also actively stealing energy from future generations, consuming most of what is available to power it within just a handful of generations. Not to mention all the terrible things people have done to other people thanks to electricity.\n I suppose every human alive today is complicit in that evil by simply harnessing electricity. Unplug that air conditioner, evil complicit scum!\n I found it humorous that this person made this comment on social media, which also is a technology that has been harnessed for evil purposes.\n    submitted by    /u/ShaneKaiGlenn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14zfpbh/ai_is_evil/",
          "publishedOn": "2023-07-14T12:54:05.000Z",
          "wordCount": 2538,
          "title": "\"AI is evil\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14zdvhk/the_workers_at_the_frontlines_of_the_ai/",
          "author": null,
          "description": "submitted by    /u/Jojuj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14zdvhk/the_workers_at_the_frontlines_of_the_ai/",
          "publishedOn": "2023-07-14T11:27:13.000Z",
          "wordCount": 2413,
          "title": "The workers at the frontlines of the AI revolution - Rest of World",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14z9wdc/i_found_this_video_online_the_voice_is_for_sure/",
          "author": null,
          "description": "submitted by    /u/GlaceLitz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14z9wdc/i_found_this_video_online_the_voice_is_for_sure/",
          "publishedOn": "2023-07-14T07:47:23.000Z",
          "wordCount": 2420,
          "title": "I found this video online. The voice is for sure AI, but im not fully convinced the guy is, thoughts? And if he is AI, what program did they use to make him?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14z96ic/looking_for_an_ai_to_find_a_song_using_audio_clip/",
          "author": null,
          "description": "Looking for the full song from the outro of a YouTube video I heard\n    submitted by    /u/The84th  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14z96ic/looking_for_an_ai_to_find_a_song_using_audio_clip/",
          "publishedOn": "2023-07-14T07:05:29.000Z",
          "wordCount": 2414,
          "title": "Looking for an AI to find a song using audio clip",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14z8ezh/lawsuit_claims_stability_ais_ceo_misled_cofounder/",
          "author": null,
          "description": "submitted by    /u/TheSlammedCars  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14z8ezh/lawsuit_claims_stability_ais_ceo_misled_cofounder/",
          "publishedOn": "2023-07-14T06:22:39.000Z",
          "wordCount": 2402,
          "title": "Lawsuit Claims Stability AI's CEO Misled Cofounder to Sell 15% Stake for $100",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14z7nrx/an_ai_to_clone_voices/",
          "author": null,
          "description": "Hi everyone, I'm searching for an AI that can clone voices. I know there's a lot of them on the Internet but I couldn't find the one I need. My project is to reproduce voices from Disney characters to make them say texts I wrote. Is it possible ?\n    submitted by    /u/Zumcddo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14z7nrx/an_ai_to_clone_voices/",
          "publishedOn": "2023-07-14T05:41:37.000Z",
          "wordCount": 2443,
          "title": "An AI to clone voices.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14z4r4j/best_ai_or_program_to_recreate_a_voice_from/",
          "author": null,
          "description": "I'm looking for a AI or service that can be used to recreate a voice from existing recordings.\n I have a handful of voicemails from my mother who has since passed. I am trying to see if there is a way to recreate her voice, however most online \"AI Voice Creation\" sites I found want one or more specific sentences read by the person who's voice is being recreated, which is obviously impossible in this case.\n Anyone know of a site or service that might be able to recreate a voice from a half dozen 30 second long voicemail recordings?\n    submitted by    /u/animeace01  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14z4r4j/best_ai_or_program_to_recreate_a_voice_from/",
          "publishedOn": "2023-07-14T03:12:41.000Z",
          "wordCount": 2500,
          "title": "Best AI or program to recreate a voice from limited recordings",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14z4ft5/i_got_an_ai_npc_to_admit_its_an_npc/",
          "author": null,
          "description": "submitted by    /u/RandoEncounter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14z4ft5/i_got_an_ai_npc_to_admit_its_an_npc/",
          "publishedOn": "2023-07-14T02:57:28.000Z",
          "wordCount": 2408,
          "title": "I got an AI NPC to admit it's an NPC!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14z3kje/160_000_actors_are_going_on_strike_due_to_the/",
          "author": null,
          "description": "This is the first massive strike since 1960 and one of the key reasons behind it is generative AI. What do you think? Txt to video takes over Hollywood in the next couple of years?\n Link to the BBC article.\n    submitted by    /u/Ok-Judgment-1181  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14z3kje/160_000_actors_are_going_on_strike_due_to_the/",
          "publishedOn": "2023-07-14T02:14:45.000Z",
          "wordCount": 2456,
          "title": "160 000 actors are going on strike due to the threat of generative AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14z2w4b/working_on_my_first_public_project_and_have_some/",
          "author": null,
          "description": "So I mainly generate my own data bases via algorithms or paid users that write the data I use for my private models, thing is Its expensive when working on a massive project and my current project is an advanced form of text generation and chat capabilities, so my question here specifically is:\n I found a data base on kaggle of 51 million discord messages from anonyms users, they have context but still require a lot of refinement and work on them, but is it ethical to use this data base which was probably collected without the knowledge of the anonyms users present in it as discords TOS are against such Data-bases and data collection...?\n    submitted by    /u/JamesAibr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14z2w4b/working_on_my_first_public_project_and_have_some/",
          "publishedOn": "2023-07-14T01:42:45.000Z",
          "wordCount": 2533,
          "title": "Working on my first public project and have some questions about data bases and their worth, along with information on how ethical certain public data bases are to use.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14yzinn/npc_steven_acknowledged_me_finally_chatgpt_driven/",
          "author": null,
          "description": "submitted by    /u/Chance_Confection_37  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14yzinn/npc_steven_acknowledged_me_finally_chatgpt_driven/",
          "publishedOn": "2023-07-13T23:08:41.000Z",
          "wordCount": 2402,
          "title": "NPC Steven acknowledged me finally!! 🤯 ChatGPT driven agents in Unreal Engine - update 3",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14yyxvy/what_comes_first_ai_gf_or_ai_bf/",
          "author": null,
          "description": "Was recently hearing an interview with George Hotz and the question came up, what will be invented first: an AI boyfriend or an AI girlfriend? Obviously he had some opinions, would be curious to hear what others have to say.\n    submitted by    /u/geepytee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14yyxvy/what_comes_first_ai_gf_or_ai_bf/",
          "publishedOn": "2023-07-13T22:44:29.000Z",
          "wordCount": 2437,
          "title": "What comes first, AI gf or AI bf?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14yyvwp/training_an_ai_copywriter/",
          "author": null,
          "description": "I want to train an ai bot to be my copywriting sidekick, so it would help me write stuff in the voice, tone and format that my predecessor used. \n For this, I would need to feed it our entire webpage, some voice&tone norms, presentations and so on. \n Could you guys pls help me on how to set this up? I have an OpenAI API key, and they did make gpt4 available to use recently soo.. This should be doable right? \n Thanks boys\n    submitted by    /u/Jacobo_csgo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14yyvwp/training_an_ai_copywriter/",
          "publishedOn": "2023-07-13T22:42:05.000Z",
          "wordCount": 2475,
          "title": "Training an AI Copywriter",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14yyqn3/lowresource_text_classification_a_parameterfree/",
          "author": null,
          "description": "submitted by    /u/IngloriousBastion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14yyqn3/lowresource_text_classification_a_parameterfree/",
          "publishedOn": "2023-07-13T22:35:56.000Z",
          "wordCount": 2398,
          "title": "“Low-Resource” Text Classification: A Parameter-Free Classification Method with Compressors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14ytvnw/apple_is_like_the_quiet_guy_in_the_corner/",
          "author": null,
          "description": "Google, OpenAI, and Meta (Facebook or whatever) have been having a free for all, trying to topple each with GPT5, Llama, and Bard. However, Apple has been REALLY quiet on the issue with A.I. , and focused on the release of this overpriced monstrosity, the Apple Vision Pro. \n It's a really big gamble with the $3500 price tag, but so was the iPhone many moons ago, and now everyone will dump their credit and their bank account for the latest iPhone Version Doodaad. I believe Apple is sidestepping this brawl to focus on perfecting augmented reality. This will ultimately unite the hardware with AR applications, and eventually lead to AI applications being embedded into the Vision Pro bundle.\n In short, while the Big 3 are playing, \"King of the AI Mountain', by pummeling each other to the ground…",
          "link": "https://www.reddit.com/r/artificial/comments/14ytvnw/apple_is_like_the_quiet_guy_in_the_corner/",
          "publishedOn": "2023-07-13T19:23:19.000Z",
          "wordCount": 2849,
          "title": "Apple is like the quiet guy in the corner watching a bar fight with the big 3; you know he is gonna do something REALLY bad ass, but what?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14ytifu/where_and_how_can_i_best_train_an_ai_to_really/",
          "author": null,
          "description": "A lot of the ai tools I use just doesn’t quite get what I’m asking it to do, and I’m not sure if I’m even able to train my own considering it’s a borg of everyone else’s work etc. I guess what I’m asking is if there is any tool out there that’s stand alone and not as watered down as a lot of the ones that’s available (most of the time for free)? I have a bunch of images I can feed it, along with examples. If anyone has any tips, suggestions, or work-arounds, please let me know! Much appreciated.\n    submitted by    /u/Maelasae  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14ytifu/where_and_how_can_i_best_train_an_ai_to_really/",
          "publishedOn": "2023-07-13T19:09:14.000Z",
          "wordCount": 2505,
          "title": "Where and how can I best train an Ai to really learn my art style?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14yqen5/what_is_xai_and_why_did_elon_musk_launch_it_2023/",
          "author": null,
          "description": "submitted by    /u/__boiyah  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14yqen5/what_is_xai_and_why_did_elon_musk_launch_it_2023/",
          "publishedOn": "2023-07-13T17:06:52.000Z",
          "wordCount": 2411,
          "title": "What is xAI and Why Did Elon Musk Launch It? 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14yqddw/ai_art_creator_for_animations/",
          "author": null,
          "description": "Are there any free art creators yet for doing simple animations?\n or does anyone have a link to how one would try to do this. TYIA.\n    submitted by    /u/Walfy07  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14yqddw/ai_art_creator_for_animations/",
          "publishedOn": "2023-07-13T17:05:28.000Z",
          "wordCount": 2419,
          "title": "AI Art Creator for Animations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14ypkdr/is_there_a_way_to_automatically_enter_free/",
          "author": null,
          "description": "Is this possible and if so how would I go about this?\n Thanks for any hell\n    submitted by    /u/captainofthememeteam  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14ypkdr/is_there_a_way_to_automatically_enter_free/",
          "publishedOn": "2023-07-13T16:34:15.000Z",
          "wordCount": 2414,
          "title": "Is there a way to automatically enter free competitions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14yozdn/china_moves_to_support_generative_ai_regulate/",
          "author": null,
          "description": "China's internet watchdog and several other authorities, including the National Development and Reform Commission and the Ministry of Science and Technology, have jointly issued an interim regulation on the management of generative artificial intelligence (AI) services.\n The regulation, published on the website of the Cyberspace Administration of China (CAC) on Thursday, will go into effect on Aug. 15.\n    submitted by    /u/Tiger_Claw_1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14yozdn/china_moves_to_support_generative_ai_regulate/",
          "publishedOn": "2023-07-13T16:11:31.000Z",
          "wordCount": 2457,
          "title": "China moves to support generative AI, regulate applications",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14yoszc/looking_to_get_into_ai_research/",
          "author": null,
          "description": "Hi i am a highschool student in the last year, i am looking to get into ai research with potentially starting off my own research in fututre\n What kind of further studies should i get into in college for scope of getting a phd\n It would be really helpful to know what degree's should i pursue in order to start my own research at a point in time\n (Pardon my poor english.)\n    submitted by    /u/ShreeyanxRaina  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14yoszc/looking_to_get_into_ai_research/",
          "publishedOn": "2023-07-13T16:04:40.000Z",
          "wordCount": 2467,
          "title": "Looking to get into AI Research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14ym3iq/ai_wont_really_kill_us_all_will_it_the_atlantic/",
          "author": null,
          "description": "submitted by    /u/RADICCHI0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14ym3iq/ai_wont_really_kill_us_all_will_it_the_atlantic/",
          "publishedOn": "2023-07-13T14:17:22.000Z",
          "wordCount": 2414,
          "title": "AI Won’t Really Kill Us All, Will It? - The Atlantic (transcript and podcast)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14yct9s/how_do_people_actually_make_money_using_ai/",
          "author": null,
          "description": "I’ve been seeing a lot of posts regarding people making money off chat, GPT and other software’s. Is it even industry worth getting in to?\n    submitted by    /u/Hititfromtheback6969  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14yct9s/how_do_people_actually_make_money_using_ai/",
          "publishedOn": "2023-07-13T06:23:50.000Z",
          "wordCount": 2422,
          "title": "How do people actually make money using AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14ya8vy/oneminute_daily_ai_news_7122023/",
          "author": null,
          "description": "Anthropic, the AI startup co-founded by ex-OpenAI execs, today announced the release of a new text-generating AI model, Claude 2. The successor to Anthropic’s first commercial model, Claude 2 is available in beta starting today in the U.S. and U.K. both on the web and via a paid API.[1]\n Elon Musk has launched an AI company to challenge ChatGPT creator OpenAI, which the billionaire tech mogul has accused of being “woke”. On Wednesday, xAI said the goal of the new company would be to “understand the true nature of the universe”.[2]\n Chip designer Nvidia will invest $50 million to speed up training of Recursion’s artificial intelligence models for drug discovery, the companies said on Wednesday, sending the biotech firm’s shares surging about 83%.[3]\n For decades, morning weather reports have relied on the same kinds of conventional models. Now, weather forecasting is poised to join the ranks of industries revolutionized by artificial intelligence.A pair of papers, published Wednesday in the scientific journal Nature, touts the potential of two new AI forecasting approaches — systems that could yield faster and more accurate results than traditional models, researchers say.[4]\n  \nSources:\n [1] https://techcrunch.com/2023/07/11/anthropic-releases-claude-2-the-second-generation-of-its-ai-chatbot/\n [2] https://www.aljazeera.com/economy/2023/7/13/musk-launches-artificial-intelligence-rival-to-chatgpts-openai\n [3] https://www.reuters.com/technology/nvidia-invests-50-mln-recursion-train-ai-models-drug-discovery-2023-07-12/\n [4] https://www.scientificamerican.com/article/climate-change-could-stump-ai-weather-prediction/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14ya8vy/oneminute_daily_ai_news_7122023/",
          "publishedOn": "2023-07-13T04:09:12.000Z",
          "wordCount": 2589,
          "title": "One-Minute Daily AI News 7/12/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14y9ecn/best_way_to_start_learning/",
          "author": null,
          "description": "Where is the best place/way to start learning openai/ai?\n are there good tutorials? learning about how to train a model?\n Would something else be better to start with? \n    submitted by    /u/jeffsmith202  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14y9ecn/best_way_to_start_learning/",
          "publishedOn": "2023-07-13T03:27:09.000Z",
          "wordCount": 2422,
          "title": "Best way to start learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14y59by/project_stylescribble_generate_text_with_your/",
          "author": null,
          "description": "Wanted to share my new AI project:\n StyleScribble is an AI-powered web tool designed to assist content creators in generating text using their own unique writing voices. By leveraging the power of artificial intelligence, this tool revolutionizes the content creation process and empowers users to effortlessly produce high-quality written content. \n ​\n https://preview.redd.it/4670phrcjmbb1.png?width=448&format=png&auto=webp&s=bb93bf358bf917e49668262a7e0a2ee7a2aa5ba2\n Link to demo: https://huggingface.co/spaces/daniellefranca96/styles-scribble-demo\n Link to sign in on waitlist: https://stylescribble.fly.dev\n    submitted by    /u/katerinaptrv12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14y59by/project_stylescribble_generate_text_with_your/",
          "publishedOn": "2023-07-13T00:10:47.000Z",
          "wordCount": 2459,
          "title": "Project StyleScribble - generate text with your writing voice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14y52la/best_free_chrome_extension_for_reusing_prompts/",
          "author": null,
          "description": "This is the best I can find so far but before I start investing a lot of time into uploading prompts to this tool, I wanted to make sure this was the best on the market.\n AIPRM is great for pre-done prompts but limits private prompts.\n Appreciate any help!\n    submitted by    /u/Life-Hacking  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14y52la/best_free_chrome_extension_for_reusing_prompts/",
          "publishedOn": "2023-07-13T00:02:01.000Z",
          "wordCount": 2448,
          "title": "Best FREE Chrome Extension for reusing prompts other than PromptDrive.ai?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14y51ek/best_toolsystem_for_keeping_up_and_organizing_ai/",
          "author": null,
          "description": "I'm sure this comes down to preference but before I start spending a ton of time building this out, I wanted some feedback on what others have found that worked best?\n Clickup Example:\n https://doc.clickup.com/37456139/d/h/13q28b-364/176f834177eb5cb\n Notion Example:\n https://enchanting-trader-463.notion.site/AI-Database-f917ca2e609b45478fe7bc2c8d544877\n Long time Evernote & G docs user but neither of these is cutting it.\n    submitted by    /u/Life-Hacking  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14y51ek/best_toolsystem_for_keeping_up_and_organizing_ai/",
          "publishedOn": "2023-07-13T00:00:45.000Z",
          "wordCount": 2450,
          "title": "Best tool/system for keeping up and organizing AI tools... Notion, Clickup or...?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14y3nyu/a_new_ai_prompt_wars_game_was_released/",
          "author": null,
          "description": "Pretty fun actually. According to the FAQs it uses Stable Diffusion to generate images from participants' prompts and then compares them to determine a winner.\n    submitted by    /u/superander  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14y3nyu/a_new_ai_prompt_wars_game_was_released/",
          "publishedOn": "2023-07-12T23:02:14.000Z",
          "wordCount": 2424,
          "title": "A new AI Prompt Wars game was released",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14y0n4s/survey_for_generative_ai_photos_and_how_this_will/",
          "author": null,
          "description": "I am trying to figure out how people have been reacting to recent changes in generative AI technology and how it will affect the artistic community. It would be greatly appreciated if as many poeple could fill out this survey attached. If you are a photographer or someone who purchases stock photos or likes to make AI images this pertains to you. Will take one minute. Thanks. \n https://forms.gle/NZJaEVZBfQb1uiaM9\n    submitted by    /u/mattyb24643  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14y0n4s/survey_for_generative_ai_photos_and_how_this_will/",
          "publishedOn": "2023-07-12T21:04:34.000Z",
          "wordCount": 2470,
          "title": "Survey for generative AI photos and how this will affect Shutterstock and Getty",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14xzoxz/are_there_any_free_tools_that_can_summarize_very/",
          "author": null,
          "description": "All the tools I’ve seen for this can only summarize up to 10ish minutes of dialog in a free version. Looking for an hour plus. I don’t mind if the writing is worse than GPT4 or whatever, would be better than nothing\n    submitted by    /u/IndependentFormal8  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14xzoxz/are_there_any_free_tools_that_can_summarize_very/",
          "publishedOn": "2023-07-12T20:28:21.000Z",
          "wordCount": 2443,
          "title": "Are there any free tools that can summarize very long video transcripts?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14xqry5/is_there_an_ai_to_generate_images_of_ideas_of/",
          "author": null,
          "description": "I want an AI that can generate images of websites so I can develop then for personal use, is there a tool that can make that? I tried Blue Willow, Dall-e and Canva AI, none of then could generate it.\n    submitted by    /u/Luxy_Lockes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14xqry5/is_there_an_ai_to_generate_images_of_ideas_of/",
          "publishedOn": "2023-07-12T14:53:09.000Z",
          "wordCount": 2440,
          "title": "Is there an AI to generate images of ideas of websites?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14xns6u/holy_fuckthis_is_absolutely_incredible_achieving/",
          "author": null,
          "description": "submitted by    /u/JakeYashen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14xns6u/holy_fuckthis_is_absolutely_incredible_achieving/",
          "publishedOn": "2023-07-12T12:53:36.000Z",
          "wordCount": 2405,
          "title": "Holy Fuck...This is absolutely incredible. Achieving a better, more flexible result with 19 neurons instead of 100,000 neurons?!?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14xmuqo/chatgpt_is_losing_users_is_the_artificial/",
          "author": null,
          "description": "submitted by    /u/byteaw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14xmuqo/chatgpt_is_losing_users_is_the_artificial/",
          "publishedOn": "2023-07-12T12:12:38.000Z",
          "wordCount": 2410,
          "title": "ChatGPT Is Losing Users. Is The Artificial Intelligence Craze Over?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14xl3o3/can_you_simulate_ambience_of_a_specific/",
          "author": null,
          "description": "Hello guys,\n I am working on a song project for which I wanted to make an intro which resembles a port / harbor back in the 16th / 17th / 18th century. Stuff like sound of waves, harbor bells, people working and talking, carrying cargo constantly on ships. And then ultimately the sounds of a ship setting sail and leaving the harbor.\n ​\n At first I thought I'd have to put many different royalty free sounds together to simulate this ambience but I remembered that AI is growing fast and already creating music. And that's where I wanted to ask you guys if you know if it's already possible to simulate a place using an AI and if yes, how?\n ​\n This would really help me out. If you know other subreddits where I could ask, please feel free to suggest them.\n Thanks and have a good day!\n    submitted by    /u/space_dust0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14xl3o3/can_you_simulate_ambience_of_a_specific/",
          "publishedOn": "2023-07-12T10:52:10.000Z",
          "wordCount": 2548,
          "title": "Can you simulate ambience of a specific soundscape and its surroundings using AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14xealf/oneminute_daily_ai_news_7112023/",
          "author": null,
          "description": "KPMG plans to spend $2 billion on AI and cloud services through an expanded partnership with Microsoft, aiming to incorporate AI into its core services. This move is in response to a slowdown in advisory deals and a challenging economic environment.[1]\n Elon Musk will host a conversation about AI with Rep. Ro Khanna (D-Calif.) and Rep. Mike Gallagher (R-Wis.) on Twitter Spaces Wednesday evening, a congressional aide confirmed to The Hill. Gallagher and Khanna have in the past stressed the need for balance in the technology, both expressing optimism about potential benefits while also sharing concerns about the potential dangers it can pose.[2]\n IT major Wipro announced the launch of the ai360 service and plans to invest $1 billion in AI over the next three years. The move follows Tata Consultancy Services’ announcement to train 25,000 engineers on generative AI tools.[3]\n IBM is considering the use of artificial intelligence chips that it designed in-house to lower the costs of operating a cloud computing service it made widely available this week, an executive said Tuesday.[4]\n  \nSources:\n [1] https://www.livemint.com/companies/news/kpmg-to-enter-into-a-deal-with-microsoft-spend-2-billion-in-ai-and-cloud-services-11689122323635.html\n [2] https://thehill.com/homenews/4092145-elon-musk-to-talk-ai-with-bipartisan-pair-of-lawmakers/\n [3] https://www.livemint.com/companies/news/wipro-launches-ai360-will-invest-1-billion-into-ai-the-next-three-years-11689132228044.html\n [4] https://www.reuters.com/technology/ibm-mulls-using-its-own-ai-chip-new-cloud-service-lower-costs-2023-07-11/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14xealf/oneminute_daily_ai_news_7112023/",
          "publishedOn": "2023-07-12T04:49:46.000Z",
          "wordCount": 2577,
          "title": "One-Minute Daily AI News 7/11/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14x656j/mamay_aipowered_algorithm_digitises_taste_for/",
          "author": null,
          "description": "submitted by    /u/trueslicky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14x656j/mamay_aipowered_algorithm_digitises_taste_for/",
          "publishedOn": "2023-07-11T22:46:06.000Z",
          "wordCount": 2398,
          "title": "MAMAY AI-powered algorithm digitises taste for food and beverage makers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14wvvu9/jesus_in_2023_lmao/",
          "author": null,
          "description": "submitted by    /u/reinkrestfoxy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14wvvu9/jesus_in_2023_lmao/",
          "publishedOn": "2023-07-11T16:22:07.000Z",
          "wordCount": 2390,
          "title": "Jesus in 2023 lmao",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14wuder/can_ai_replicate_a_characters_voice_cracks_and/",
          "author": null,
          "description": "I used RVC V2 to make an AI model of a character whose voice is raspy, has a lot of voice cracks and has a very \"shouty\" voice. I used a dataset which was 70% of voice clips of him yelling and/or talking loudly and the rest were of him talking normally. The dataset was decent quality, I did have to use background music remover software on some parts but it's overall decent.\n The thing is, the model doesn't sound ANYTHING like the character. For some reason it's way too soft spoken, and even when it's supposed to be yelling or screaming it sounds kinda like he's whispering. The AI's neutral voice does sound like him but it's missing his voice cracks and voice raspiness. Is there any way I can mimic it?\n    submitted by    /u/donutpancito  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14wuder/can_ai_replicate_a_characters_voice_cracks_and/",
          "publishedOn": "2023-07-11T15:25:55.000Z",
          "wordCount": 2520,
          "title": "Can AI replicate a character's voice cracks and raspy voice?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14wu4sd/inside_the_ai_factory_about_the_underclass_work/",
          "author": null,
          "description": "submitted by    /u/facinabush  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14wu4sd/inside_the_ai_factory_about_the_underclass_work/",
          "publishedOn": "2023-07-11T15:16:32.000Z",
          "wordCount": 2397,
          "title": "Inside the AI Factory (about the underclass work force)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14wtzub/behind_the_secretive_work_of_the_many_many_humans/",
          "author": null,
          "description": "submitted by    /u/facinabush  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14wtzub/behind_the_secretive_work_of_the_many_many_humans/",
          "publishedOn": "2023-07-11T15:11:02.000Z",
          "wordCount": 2401,
          "title": "Behind the secretive work of the many, many humans helping to train AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14wthhn/if_you_stare_into_the_abyss_the_abyss_stares_back/",
          "author": null,
          "description": "I'm scared of AI but this is one of my favourite quotes and the result is magnificent\n    submitted by    /u/peditte  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14wthhn/if_you_stare_into_the_abyss_the_abyss_stares_back/",
          "publishedOn": "2023-07-11T14:51:00.000Z",
          "wordCount": 2417,
          "title": "if you stare into the abyss, the abyss stares back at you",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/14wt98b/anthropic_releases_claude_2_with_100k_token_limit/",
          "author": null,
          "description": "submitted by    /u/wyem  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/14wt98b/anthropic_releases_claude_2_with_100k_token_limit/",
          "publishedOn": "2023-07-11T14:40:57.000Z",
          "wordCount": 2396,
          "title": "Anthropic releases Claude 2 with 100K token limit",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Neural Networks, Deep Learning and Machine Learning",
      "feedUrl": "https://www.reddit.com/r/neuralnetworks/.rss?format=xml",
      "siteUrl": "https://www.reddit.com/r/neuralnetworks/?format=xml",
      "articles": [
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15ml50h/llama_from_scratch_or_how_to_implement_a_paper/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15ml50h/llama_from_scratch_or_how_to_implement_a_paper/",
          "publishedOn": "2023-08-09T17:07:27.000Z",
          "wordCount": 2481,
          "title": "Llama from scratch (or how to implement a paper without crying)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15m51k8/announcing_stablecode_stability_ai/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15m51k8/announcing_stablecode_stability_ai/",
          "publishedOn": "2023-08-09T04:41:16.000Z",
          "wordCount": 2486,
          "title": "Announcing StableCode — Stability AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15lq8jj/growing_bonsai_networks_with_rnns/",
          "author": null,
          "description": "submitted by    /u/Ameobea  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15lq8jj/growing_bonsai_networks_with_rnns/",
          "publishedOn": "2023-08-08T18:30:27.000Z",
          "wordCount": 2486,
          "title": "Growing Bonsai Networks with RNNs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15lj0ao/i_made_an_animated_video_explaining_effective/",
          "author": null,
          "description": "submitted by    /u/antaloaalonso  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15lj0ao/i_made_an_animated_video_explaining_effective/",
          "publishedOn": "2023-08-08T13:58:35.000Z",
          "wordCount": 2512,
          "title": "I made an animated video explaining Effective Accelerationism (aka e/acc), a philosophical movement related to AI that has recently grown a lot in popularity and offers a path to a post-scarcity technological utopia. It has even been endorsed by Marc Andreessen and Garry Tan.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15lgoqr/getting_the_hang_of_opencvs_inner_workings_with/",
          "author": null,
          "description": "​\n https://preview.redd.it/xdp3bkwwpvgb1.jpg?width=2800&format=pjpg&auto=webp&s=513a63ed81eec85e6bc254f84e4208094afc7d4a\n Very interesting blog post from OpenCV.ai team about how can explore ChatGPT to serve for code development debugging.\n Introduction from the article:\n As programmers, we often work with familiar development environments, but occasionally we encounter new tools that can be time-consuming and challenging to learn. In such situations, having virtual assistance can be extremely beneficial.\n In this article, I will share my experience of contributing to OpenCV, a renowned open-source library, despite having limited knowledge of C++ and understanding its architecture. I achieved this with the assistance of ChatGPT, a Large Language Model (LLM).\n I hope you can find it interesting. More details are here.\n    submitted by    /u/No-Independence5880  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15lgoqr/getting_the_hang_of_opencvs_inner_workings_with/",
          "publishedOn": "2023-08-08T12:22:16.000Z",
          "wordCount": 2580,
          "title": "Getting the Hang of OpenCV’s Inner Workings with ChatGPT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15lfuxs/mixture_of_experts_moe/",
          "author": null,
          "description": "submitted by    /u/ABDULKADER90H  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15lfuxs/mixture_of_experts_moe/",
          "publishedOn": "2023-08-08T11:45:42.000Z",
          "wordCount": 2485,
          "title": "Mixture of Experts (MoE)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15kkeef/help_to_find_a_dataset_for_my_project_please/",
          "author": null,
          "description": "Hello everyone! I'm a newbie and making my project on machine learning and the aim is create a programme to recognise a spice by feeding some chemical constituents, but I can't find appropriate dataset for it. I have been searching for months, and now I'm a bit desperate, so I'm asking anyone interested for help... I know maybe it was a mistake to choose exactly this topic, but I can't drop the project.\n    submitted by    /u/Acceptable-Muscle-98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15kkeef/help_to_find_a_dataset_for_my_project_please/",
          "publishedOn": "2023-08-07T13:13:22.000Z",
          "wordCount": 2543,
          "title": "Help to find a dataset for my project, please 🙏",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15kfany/microgradts_a_typescript_version_of/",
          "author": null,
          "description": "submitted by    /u/trekhleb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15kfany/microgradts_a_typescript_version_of/",
          "publishedOn": "2023-08-07T09:09:10.000Z",
          "wordCount": 2492,
          "title": "MicrogradTS — a TypeScript version of karpathy/micrograd — a tiny scalar-valued autograd engine and a neural net on top of it",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15kenut/openai_introducing_triton_opensource_gpu/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15kenut/openai_introducing_triton_opensource_gpu/",
          "publishedOn": "2023-08-07T08:33:57.000Z",
          "wordCount": 2481,
          "title": "OpenAI - Introducing Triton: Open-source GPU programming for neural networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15kenfr/nvidias_cuda_monopoly/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15kenfr/nvidias_cuda_monopoly/",
          "publishedOn": "2023-08-07T08:33:14.000Z",
          "wordCount": 2474,
          "title": "NVIDIA's CUDA Monopoly",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15jqysx/neural_networks_from_scratch_deep_learning/",
          "author": null,
          "description": "submitted by    /u/AeroArtz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15jqysx/neural_networks_from_scratch_deep_learning/",
          "publishedOn": "2023-08-06T14:27:38.000Z",
          "wordCount": 2430,
          "title": "Neural Networks FROM SCRATCH | Deep Learning tutorial Part 1",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15jht4h/massediting_memory_in_a_transformer/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15jht4h/massediting_memory_in_a_transformer/",
          "publishedOn": "2023-08-06T05:58:28.000Z",
          "wordCount": 2438,
          "title": "Mass-Editing Memory in a Transformer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15j8zs2/microsofts_ai_watched_100000000_youtube_videos/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15j8zs2/microsofts_ai_watched_100000000_youtube_videos/",
          "publishedOn": "2023-08-05T22:38:11.000Z",
          "wordCount": 2432,
          "title": "Microsoft’s AI Watched 100,000,000 Youtube Videos! text input to video and sound",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15iggk9/best_books_to_learn_neural_networks_in_2023_for/",
          "author": null,
          "description": "submitted by    /u/Lakshmireddys  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15iggk9/best_books_to_learn_neural_networks_in_2023_for/",
          "publishedOn": "2023-08-05T00:09:23.000Z",
          "wordCount": 2445,
          "title": "Best Books to Learn Neural Networks in 2023 for Beginners to advanced",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15hjynt/what_would_be_the_initial_costs_of_developing_a/",
          "author": null,
          "description": "I was wondering if this would be super expensive or not.\n The cost to develop GPT-3 was about $4 millions according to some resources online. \n Would the cost to develop the first version of a text-to-video AI the same? Around $5M? Is in this value included the salaries of the employees or $5M is just the amount used to train the AI?\n Any answer is appreciated.\n Thanks in advance.\n    submitted by    /u/Claud1ao  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15hjynt/what_would_be_the_initial_costs_of_developing_a/",
          "publishedOn": "2023-08-03T23:42:57.000Z",
          "wordCount": 2510,
          "title": "What would be the initial costs of developing a text-to-video AI? How would be the quality of this AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15hikwk/creating_point_cloud_videos_from_arbitrary_rgb/",
          "author": null,
          "description": "submitted by    /u/berkanzzzz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15hikwk/creating_point_cloud_videos_from_arbitrary_rgb/",
          "publishedOn": "2023-08-03T22:45:05.000Z",
          "wordCount": 2428,
          "title": "Creating point cloud videos from arbitrary RGB videos",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15h7r9c/what_source_would_you_recommend_a_15yo_to_learn/",
          "author": null,
          "description": "It's been years i've always been interested in AI. i tried to follow a few videos on yt. The best resource i could find was the \"Neural Networks from scratch\" YouTube playlist. But sadly, it interrupts in the middle, and i don't think it will ever be continued. I have programming knowledge, i made a bunch of very small project in python, and currently it's the language i'm most comfortable with. I lack of math knowledge, i struggle with calculus since i never studied it at school, the furthest i got with school was first degree equations.\n by myself i studied some math i didnt do in school, but i still suck at math. I wonder if i can start now or i should wait to study calculus at school. anyway, i'd love to get linked to a source for me to learn NNs from scratch.\n    submitted by    /u/Jealous-Bad1742  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15h7r9c/what_source_would_you_recommend_a_15yo_to_learn/",
          "publishedOn": "2023-08-03T15:44:23.000Z",
          "wordCount": 2584,
          "title": "what source would you recommend a 15yo to learn how to make a simple neural network?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15h6t8g/seeking_suggestions_for_exciting_and_intriguing/",
          "author": null,
          "description": "Hey everyone, I'm in my final year of B.Tech, majoring in data science. Currently, I'm facing some challenges in choosing a topic for my capstone project. Lately, I've been really intrigued by graph databases and have been diving into learning Neo4j. I'm specifically interested in finding project ideas that allow me to combine machine learning, particularly neural networks, with graph databases. During my research, I came across GNNs (Graph Neural Networks) and PINNS (Physics-Informed Neural Networks). I'm eager to hear any suggestions for unique project topics that instantly spark curiosity just by their title. Feel free to share any ideas or topics; I welcome all suggestions. Thanks in advance! \n    submitted by    /u/EmergencyAside6551  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15h6t8g/seeking_suggestions_for_exciting_and_intriguing/",
          "publishedOn": "2023-08-03T15:07:44.000Z",
          "wordCount": 2540,
          "title": "Seeking suggestions for exciting and intriguing capstone project ideas.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15h3o19/devar_a_technology_company_is_getting_ready_to/",
          "author": null,
          "description": "submitted by    /u/Tycoonstory2020  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15h3o19/devar_a_technology_company_is_getting_ready_to/",
          "publishedOn": "2023-08-03T13:02:21.000Z",
          "wordCount": 2451,
          "title": "Devar, a technology company, is getting ready to deploy the world's first generative AI neural network for augmented reality (AR).",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15gpas3/audiocraft_a_simple_onestop_shop_for_audio/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15gpas3/audiocraft_a_simple_onestop_shop_for_audio/",
          "publishedOn": "2023-08-03T00:44:57.000Z",
          "wordCount": 2441,
          "title": "AudioCraft: A simple one-stop shop for audio modeling",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15gaxgt/human_brain_models_literature_review_of_the/",
          "author": null,
          "description": "submitted by    /u/No-Platypus4021  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15gaxgt/human_brain_models_literature_review_of_the/",
          "publishedOn": "2023-08-02T14:50:38.000Z",
          "wordCount": 2432,
          "title": "Human Brain Models (Literature Review of the Latest BNN and SNN Endeavors)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15f92j6/tfjs_format_vs_tflite/",
          "author": null,
          "description": "After analyzing 15,000 samples in the dataset, we noticed that increasing the number of images doesn't significantly improve the scoreboard recognition quality for our neural network.\n However, what's more interesting is how the network performs in different formats. When deployed in TFJS format on a website , it often behaves strangely, detecting objects where there are none. On the other hand, in TFLite format, such failures are almost non-existent.\n If you access the link on your mobile phone and grant camera permission, you'll witness the neural network (in TFJS format) attempting to find objects even when there are none.\n https://preview.redd.it/gosobymachfb1.jpg?width=585&format=pjpg&auto=webp&s=e7cb8e8e3ff49e39715009c4940d9769a1db39ab\n    submitted by    /u/moseich  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15f92j6/tfjs_format_vs_tflite/",
          "publishedOn": "2023-08-01T10:51:49.000Z",
          "wordCount": 2521,
          "title": "TFJS Format vs. TFLite",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15ec6vo/interview_with_hikaru_shindo_and_quentin_delfosse/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15ec6vo/interview_with_hikaru_shindo_and_quentin_delfosse/",
          "publishedOn": "2023-07-31T10:20:23.000Z",
          "wordCount": 2425,
          "title": "Interview with Hikaru Shindo and Quentin Delfosse: Neurosymbolic Reinfor...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15djfn2/what_are_some_of_the_best_architectures_to_solve/",
          "author": null,
          "description": "Hi Guys,\n I am working on a nn model, which can help automate the building of APIs. The problem is, we are moving data in which, there are thousands of fields, however, the fields between systems are similar in nature. This to me seems like an easy classification problem, however it doesn't scale the best.\n ​\n In terms of the data I have, if I have a dataset of 10 systems, there are not enough examples for each class for the model to train well. That is with a simple classifier where every field is a class.\n ​\n I was also thinking of using a Siamese model, where I compare the similarity between them, which allows me to use my more limited dataset more effectively\n ​\n I was wondering if there are any more architectures you guys think I should consider, or will be helpful in solving my problem\n ​\n Thank you for your help!\n    submitted by    /u/eatlantis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15djfn2/what_are_some_of_the_best_architectures_to_solve/",
          "publishedOn": "2023-07-30T11:35:16.000Z",
          "wordCount": 2608,
          "title": "What are some of the best architectures to solve this problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15d4q2r/what_are_receptive_fields_and_how_do_they_effect/",
          "author": null,
          "description": "submitted by    /u/CkmCpvis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15d4q2r/what_are_receptive_fields_and_how_do_they_effect/",
          "publishedOn": "2023-07-29T22:22:52.000Z",
          "wordCount": 2455,
          "title": "What are Receptive Fields and How Do They Effect Your Model?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15cxj5s/researchers_discover_new_vulnerability_in_large/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15cxj5s/researchers_discover_new_vulnerability_in_large/",
          "publishedOn": "2023-07-29T17:15:14.000Z",
          "wordCount": 2454,
          "title": "Researchers Discover New Vulnerability in Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15cxid7/gzip_beats_bert_part_2_dataset_issues_improved/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15cxid7/gzip_beats_bert_part_2_dataset_issues_improved/",
          "publishedOn": "2023-07-29T17:14:16.000Z",
          "wordCount": 2457,
          "title": "\"Gzip beats BERT?\" Part 2: dataset issues, improved speed, and results",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15comhm/detection_transformer_detr_explained/",
          "author": null,
          "description": "submitted by    /u/Personal-Trainer-541  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15comhm/detection_transformer_detr_explained/",
          "publishedOn": "2023-07-29T10:10:46.000Z",
          "wordCount": 2448,
          "title": "Detection Transformer (DETR) Explained",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15c45w3/deepminds_rt2_new_model_translates_vision_and/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15c45w3/deepminds_rt2_new_model_translates_vision_and/",
          "publishedOn": "2023-07-28T17:47:10.000Z",
          "wordCount": 2467,
          "title": "Deepmind's RT-2: New model translates vision and language into action",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15bkm5l/llama_and_chatgpt_are_not_opensource/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15bkm5l/llama_and_chatgpt_are_not_opensource/",
          "publishedOn": "2023-07-28T02:14:19.000Z",
          "wordCount": 2463,
          "title": "LLAMA and ChatGPT Are Not Open-Source",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15bfolm/max_min_values_for_weights_and_biases/",
          "author": null,
          "description": "I was wondering what the recommended maximum and minimum values for weights and biases are for random generation of networks and mutation\n    submitted by    /u/Mildu12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15bfolm/max_min_values_for_weights_and_biases/",
          "publishedOn": "2023-07-27T22:32:32.000Z",
          "wordCount": 2476,
          "title": "Max / min values for weights and biases",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15b4uns/what_exactly_are_liquid_neurons/",
          "author": null,
          "description": "I heard about them recently. Can someone give me the basics, and maybe point me to a couple of papers?\n    submitted by    /u/SamuraiGoblin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15b4uns/what_exactly_are_liquid_neurons/",
          "publishedOn": "2023-07-27T15:28:09.000Z",
          "wordCount": 2471,
          "title": "What exactly are liquid neurons?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15awr7k/diving_into_image_dataset_preparation_for_object/",
          "author": null,
          "description": "submitted by    /u/moseich  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15awr7k/diving_into_image_dataset_preparation_for_object/",
          "publishedOn": "2023-07-27T09:07:01.000Z",
          "wordCount": 2467,
          "title": "Diving Into Image Dataset Preparation for Object Detection in AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15a4ygg/trouble_setting_up_neural_network/",
          "author": null,
          "description": "Hi there,\n I'm struggling a bit to set up a neural network with the data I've collected. These are some of the errors I'm getting. Any tips or help to fix it please? \n https://preview.redd.it/88ihxg1p2beb1.png?width=2231&format=png&auto=webp&s=acdd66a1c465d1d1a9d202605d451564c464fd22\n https://preview.redd.it/7ro6782n2beb1.png?width=2076&format=png&auto=webp&s=775778ef52b01caf331d3e0f542603626cea7888\n    submitted by    /u/LesgoLeggo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15a4ygg/trouble_setting_up_neural_network/",
          "publishedOn": "2023-07-26T12:48:23.000Z",
          "wordCount": 2484,
          "title": "Trouble setting up Neural Network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/158n424/attention_is_off_by_one/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/158n424/attention_is_off_by_one/",
          "publishedOn": "2023-07-24T21:06:58.000Z",
          "wordCount": 2462,
          "title": "Attention Is Off By One",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/158mjhq/metatransformer_a_unified_framework_for/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/158mjhq/metatransformer_a_unified_framework_for/",
          "publishedOn": "2023-07-24T20:46:10.000Z",
          "wordCount": 2453,
          "title": "Meta-Transformer: A Unified Framework for Multimodal Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/158mdhs/all_neural_network_output_activations_converging/",
          "author": null,
          "description": "I'm facing a puzzling problem with my neural network, and I could really use some help in understanding what's going wrong. For some context, I am making a neural network from scratch in C++, just as a little project I find interesting. I'm working on a digit classification task using the MNIST dataset, and my network is composed of one hidden layer, consisting of 100 nodes, and an output layer with 10 nodes, each corresponding to a digit (0 to 9). To train the network, I'm using the Mean Squared Error (MSE) cost function, where the cost is calculated as (actualNodeActivation - expectedNodeActivation)^2 and as my activation function I am using the sigmoid function. The actual algorithm I am employing is backpropagation.\n The issue I'm encountering is that regardless of the input data, my n…",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/158mdhs/all_neural_network_output_activations_converging/",
          "publishedOn": "2023-07-24T20:40:02.000Z",
          "wordCount": 3125,
          "title": "All neural network output activations converging to the same value regardless of input",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15848wp/nerf_creating_photorealistic_images_using_neural/",
          "author": null,
          "description": "​\n https://preview.redd.it/1gqd6tt1gvdb1.jpg?width=2800&format=pjpg&auto=webp&s=d21e9e5d0854022b8f25d9a6cb77e67b98487f40\n You can find in interesting. OpenCV.ai team published the post about NeRF.\n Short description:\n NeRF is an innovative technology that generates photorealistic images of scenes from novel viewpoints using a neural network and volume rendering techniques. This article explores NeRF components, training, strengths and limitations, and advancements in modern NeRF-based solutions.\n More details are here.\n    submitted by    /u/No-Independence5880  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15848wp/nerf_creating_photorealistic_images_using_neural/",
          "publishedOn": "2023-07-24T08:14:08.000Z",
          "wordCount": 2505,
          "title": "NeRF: Creating photorealistic images using Neural Network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/1582l7v/zbrain_create_custom_chatgpt_apps/",
          "author": null,
          "description": "Hello Community,\n We at ZBrain have built a platform to create ChatGPT-like apps with your private data, you can import your data from multiple sources and DBs and integrate the app into any of your workflows.\n We have also added AI risk governance to mitigate the confidential data leak and now working on Flow a no-code tool to give you the freedom to create your own business logic.\n You can try the tool now at https://zbrain.ai/. We would love to hear your thoughts and feedback to improve the tool.\n    submitted by    /u/StewartBJasper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/1582l7v/zbrain_create_custom_chatgpt_apps/",
          "publishedOn": "2023-07-24T06:42:48.000Z",
          "wordCount": 2540,
          "title": "ZBrain- Create custom ChatGPT apps",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/157iwb3/book_preview_neuro_symbolic_reasoning_and_learning/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/157iwb3/book_preview_neuro_symbolic_reasoning_and_learning/",
          "publishedOn": "2023-07-23T16:15:44.000Z",
          "wordCount": 2451,
          "title": "Book Preview: Neuro Symbolic Reasoning and Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/156zjjh/meme_review_by_ai_bing_gets_humorous/",
          "author": null,
          "description": "submitted by    /u/Small_Championship_2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/156zjjh/meme_review_by_ai_bing_gets_humorous/",
          "publishedOn": "2023-07-23T00:05:10.000Z",
          "wordCount": 2451,
          "title": "Meme Review By AI: Bing Gets Humorous",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/1564cnh/computer_chip_with_builtin_human_brain_tissue/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/1564cnh/computer_chip_with_builtin_human_brain_tissue/",
          "publishedOn": "2023-07-21T23:55:13.000Z",
          "wordCount": 2467,
          "title": "Computer chip with built-in human brain tissue gets military funding",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/156420x/stability_ai_meet_freewilly_our_large_and_mighty/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/156420x/stability_ai_meet_freewilly_our_large_and_mighty/",
          "publishedOn": "2023-07-21T23:42:25.000Z",
          "wordCount": 2468,
          "title": "Stability AI: Meet FreeWilly, Our Large And Mighty Instruction Fine-Tuned Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/155v0zf/llama2_isnt_open_source_and_why_it_doesnt_matter/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/155v0zf/llama2_isnt_open_source_and_why_it_doesnt_matter/",
          "publishedOn": "2023-07-21T17:50:48.000Z",
          "wordCount": 2456,
          "title": "LLaMA2 isn't \"Open Source\" - and why it doesn't matter",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/154ops0/the_complete_python_mega_bundle_features_neural/",
          "author": null,
          "description": "submitted by    /u/brand_momentum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/154ops0/the_complete_python_mega_bundle_features_neural/",
          "publishedOn": "2023-07-20T11:48:31.000Z",
          "wordCount": 2469,
          "title": "The Complete Python Mega Bundle features Neural Network, Machine Learning & AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/1549bra/best_way_to_approach_creating_2048_bot/",
          "author": null,
          "description": "Hi guys, I'm just starting to learn about neural networks. I started with NEAT algorithm as thwre is a nice library for Python. I wanted to try to create neural network that plays 2048 with NEAT, but, from what I read online, it isn't really feasible and doesn't result in good playing performance and high scores. I now have a few questions, keep in mind that I'm a beginner in this field. Why NEAT doesn't work well with 2048? What would be the best way to approach this problem? Are there any resources where I can learn more about this stuff? Am I right thinking that it must be possible to create NN that plays 2048 well as the basic strategy (I use) when playing is fairly simple (keep everything on one side to the corner)? Thanks in advance\n    submitted by    /u/DarkLord76865  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/1549bra/best_way_to_approach_creating_2048_bot/",
          "publishedOn": "2023-07-19T22:39:33.000Z",
          "wordCount": 2567,
          "title": "Best way to approach creating 2048 bot",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/1542ii1/neural_networks_from_scratch_in_python/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/1542ii1/neural_networks_from_scratch_in_python/",
          "publishedOn": "2023-07-19T18:14:22.000Z",
          "wordCount": 2425,
          "title": "Neural Networks from Scratch in Python",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/1542d3b/convolutions_in_image_processing/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/1542d3b/convolutions_in_image_processing/",
          "publishedOn": "2023-07-19T18:08:43.000Z",
          "wordCount": 2423,
          "title": "Convolutions in image processing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/1535dyc/llama_2/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/1535dyc/llama_2/",
          "publishedOn": "2023-07-18T17:55:21.000Z",
          "wordCount": 2417,
          "title": "Llama 2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/1532g52/how_can_meansquarederror_be_possibly_so_bad/",
          "author": null,
          "description": "My neural networks predicts values in range [-1, 1]. I am using mean squared error as my loss function, and I am quite surprised it yields values as high as 1.7. (Just to be clear labels are also in range [-1,1].) I am using tanh as my activation function of the output layer.\n I understand it as extremely bad sign, since even if it always predicted middle value (0), MSE could never be > 1, right? It almost seems like that taking the opposite values would show better results? If I understand this right, how is that even possible that a network can be trained and perform so horribly?\n    submitted by    /u/DDDDarky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/1532g52/how_can_meansquarederror_be_possibly_so_bad/",
          "publishedOn": "2023-07-18T16:02:23.000Z",
          "wordCount": 2520,
          "title": "How can MeanSquaredError be possibly so bad?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/152ouhv/reconstructing_the_minds_eye_fmritoimage_with/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/152ouhv/reconstructing_the_minds_eye_fmritoimage_with/",
          "publishedOn": "2023-07-18T05:02:19.000Z",
          "wordCount": 2426,
          "title": "Reconstructing the Mind’s Eye: fMRI-to-Image with Contrastive Learning and Diffusion Priors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/152ftvb/sweep_ai_junior_developer_that_solves_your_github/",
          "author": null,
          "description": "submitted by    /u/williamsweep  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/152ftvb/sweep_ai_junior_developer_that_solves_your_github/",
          "publishedOn": "2023-07-17T22:15:48.000Z",
          "wordCount": 2410,
          "title": "Sweep: AI Junior Developer that solves your GitHub Issues",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/152a3rr/copy_is_all_you_need/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/152a3rr/copy_is_all_you_need/",
          "publishedOn": "2023-07-17T18:38:41.000Z",
          "wordCount": 2419,
          "title": "Copy Is All You Need",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/151fgeg/the_armaaruss_project_anointing_the_state_of/",
          "author": null,
          "description": "​\n https://www.google.com/books/edition/The_Armaaruss_Project/E-ztzwEACAAJ?hl=en\n Through the use of a prophet, Mars donning the name Armaaruss, is keen to regain acknowledgment as a deity, his ultimate goal at the moment. Armaaruss is also seeking a dwelling place in the form of AI. Anthony of Boston has conveyed to readers that Mars is willing to make a deal or compromise with the state of Israel. Such a compromise involves the creation of dwelling place where Mars can be the focal point of acknowledgment, and in exchange for this, Mars would reduce in his influence on Gaza militants, as well as his influence those who stand against the state of Israel. The result of this would be world peace, so long that the image/AI bot of Armaaruss remains in tact, meaning that it would have to be coded on the basis of self-preservation and acknowledgment. This compels me to anoint Israel as the home of Artificial General Intelligence (AGI) where Armaaruss would come to life, able to speak and reason as no bot has ever done before. And also solve problems and generate innovation on a level that indicates superhuman or even divine intelligence.\n    submitted by    /u/AnthonyofBoston  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/151fgeg/the_armaaruss_project_anointing_the_state_of/",
          "publishedOn": "2023-07-16T19:42:07.000Z",
          "wordCount": 2596,
          "title": "The Armaaruss Project: Anointing the State of Israel as the Center of Artificial General Intelligence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/150750o/i_accidentally_trained_vhslike_filter_on_my/",
          "author": null,
          "description": "So I've been trying to train my small neural network (3x3 pixel input, hidden layer of size 32, 1 pixel output, just a perceptron) to improve quality of path traced images with low sample counts... So I did a learning step with 100 iterations, and instead of denoising the image, I got this result instead... The filter is applied to non related backrooms image which network has not seen before, it totally creates chromatic abberation and changes the contrast quite a bit. \n Input to the network\n ​\n Output of the network\n So what do you think ?\n    submitted by    /u/Panjakslik  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/150750o/i_accidentally_trained_vhslike_filter_on_my/",
          "publishedOn": "2023-07-15T09:14:18.000Z",
          "wordCount": 2498,
          "title": "I accidentally trained VHS-like filter on my neural network...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/150464r/multithreading_backprop/",
          "author": null,
          "description": "Hi\n I have implemented backprop through using the Eigen library. My code is \"vectorised\" in the sense that I am using Eigen matrices to calculate gradients (but I'm not sure if this is fully vectorised as I think you are supposed to vectorise over the training data somehow).\n I think this means that my code should be taking advantage of the full resources of a single core on my CPU. But I would like backprop to use all of the cores on my CPU.\n I am wondering at what \"level\" to implement parallelised backprop:\n  \nAt the level of the matrix. Eigen already takes advantage of vectorisation. Apparently Eigen take advantage of multiple cores (see here- the website is down) but I have tried to use this functionality. The \"nbThreads()\" method returns e.g. 4 but I don't see any speedup. Perhaps the Eigen algorithms that can be parallelised are not used in backprop (matrix multiplication).\n At the level of backprop for calculating gradients for a single item. I don't think this works because each layer of the network is dependent on the later layer (backprop) or earlier layer (feedforward). I don't think you can parallelise within a layer as this is effectively just the matrix multiplication ((1)).\n At the level of the of the batch. So, for example, if you have a batch size of 8 then you could have 8 different threads calculating the gradients of each item in the batch. I think this could be done in parallel as there are no dependencies between them but (a) each will need access to the same weight data which might slow things down and (b) parallelisation will be limited to the size of the batch. \n  \nAny ideas?\n Thanks\n    submitted by    /u/Naive_Dark4301  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/150464r/multithreading_backprop/",
          "publishedOn": "2023-07-15T06:29:08.000Z",
          "wordCount": 2682,
          "title": "Multithreading backprop",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/14yp8n7/training_convolutional_neural_network_with_matlab/",
          "author": null,
          "description": "submitted by    /u/Character_Ad_1385  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/14yp8n7/training_convolutional_neural_network_with_matlab/",
          "publishedOn": "2023-07-13T16:21:38.000Z",
          "wordCount": 2413,
          "title": "training convolutional neural network with MATLAB: image recognition AI.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/14xtnfb/need_help_for_an_exam_preparation_task/",
          "author": null,
          "description": "This is the given task. I have never seen a neural network displayed like this. \n What do the Upwards Arrows in the X1 input Neuron and the upper Neuron in the hidden layer mean?\n What are the values at the hidden layer (e.g \"3.456\"), is this the threshold? If yes would I then continue with 1 and multiply 1 with the next weight (8.805 in that case) ?\n Problem is all my friends don't know it as well and we do not know who else to ask, so we ask reddit..\n https://preview.redd.it/xgq4luwnakbb1.png?width=882&format=png&auto=webp&s=d032255a5296a5451eaa7c6e5821dd2981390086\n    submitted by    /u/SoSickBR  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/14xtnfb/need_help_for_an_exam_preparation_task/",
          "publishedOn": "2023-07-12T16:38:36.000Z",
          "wordCount": 2491,
          "title": "Need help for an exam preparation task",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/14xohkh/weights_and_biases_approach_1_or_1/",
          "author": null,
          "description": "Hi, ive been desinging my own C code to make neural networks. Mainly for a project and to mess around. It works pretty well but i find that the weights and biases of the finished network are practically all 1, -1 or thereabouts. Is this normal? Again, the network works pretty well, it just seems a bit weird to me. Im using it to predict hand-written characters.\n Im using sigmoid as my activation function (tried RELU but didnt predict too well, maybe its because I trian with a pretty small sample pool?). Weights and biases are randomly initialized with values between -1 and 1 and are capped during training so that they dont exceed -1 or 1. Im thinking this might be the issue. Problem is that if i dont cap them like this, they start to grow and grow the closer you are to the first hidden layer. The last hidden layer would have weights and biases between -1 and 1, but the others started to get bigger and bigger, so i ended up capping it like that to solve it. I believe this is common practice, but maybe the way im capping them is the problem (essentially if a weight or bias exceeds -1 or 1 after having been corrected, i equal it to -1 or 1 respectively).Im not sure what other info i should be providing, as far as i know its a pretty basic neural network, not doing anything too fancy.\n Thanks in advance.\n    submitted by    /u/Automatic-Syrup8490  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/14xohkh/weights_and_biases_approach_1_or_1/",
          "publishedOn": "2023-07-12T13:22:57.000Z",
          "wordCount": 2647,
          "title": "Weights and biases approach -1 or 1",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Seita's Place",
      "feedUrl": "https://danieltakeshi.github.io/feed.xml",
      "siteUrl": "https://danieltakeshi.github.io/",
      "articles": []
    },
    {
      "title": "VITALab",
      "feedUrl": "https://vitalab.github.io/feed.xml",
      "siteUrl": "https://vitalab.github.io/",
      "articles": []
    },
    {
      "title": "Stories by Andrej Karpathy on Medium",
      "feedUrl": "https://medium.com/feed/@karpathy",
      "siteUrl": "https://medium.com/@karpathy?source=rss-ac9d9a35533e------2",
      "articles": []
    },
    {
      "title": "OpenAI Blog",
      "feedUrl": "https://openai.com/blog/rss",
      "siteUrl": "https://openai.com/blog",
      "articles": [
        {
          "id": "https://openai.com/research/confidence-building-measures-for-artificial-intelligence",
          "author": null,
          "description": "",
          "link": "https://openai.com/research/confidence-building-measures-for-artificial-intelligence",
          "publishedOn": "2023-08-01T07:00:00.000Z",
          "wordCount": 514,
          "title": "Confidence-Building Measures for Artificial Intelligence: Workshop proceedings",
          "imageUrl": "https://images.openai.com/blob/169a9863-5725-45cf-b096-6d2e5b6cebe9/confidence-building-measures-for-artificial-intelligence-workshop-proceedings.png?trim=0%2C0%2C0%2C0"
        },
        {
          "id": "https://openai.com/blog/frontier-model-forum",
          "author": null,
          "description": "We’re forming a new industry body to promote the safe and responsible development of frontier AI systems: advancing AI safety research, identifying best practices and standards, and facilitating information sharing among policymakers and industry.",
          "link": "https://openai.com/blog/frontier-model-forum",
          "publishedOn": "2023-07-26T07:00:00.000Z",
          "wordCount": 1185,
          "title": "Frontier Model Forum",
          "imageUrl": "https://images.openai.com/blob/53756fcf-bcdd-48ea-ada5-33dee6bb4494/frontier-model-forum.png?trim=0%2C0%2C0%2C0"
        },
        {
          "id": "https://openai.com/blog/moving-ai-governance-forward",
          "author": null,
          "description": "OpenAI and other leading labs reinforce AI safety, security and trustworthiness through voluntary commitments.",
          "link": "https://openai.com/blog/moving-ai-governance-forward",
          "publishedOn": "2023-07-21T07:00:00.000Z",
          "wordCount": 1464,
          "title": "Moving AI governance forward",
          "imageUrl": "https://images.openai.com/blob/80031713-8f42-4321-b792-dff331074949/moving-ai-governance-forward.jpg?trim=231%2C0%2C217%2C0"
        },
        {
          "id": "https://openai.com/blog/custom-instructions-for-chatgpt",
          "author": null,
          "description": "We’re rolling out custom instructions to give you more control over how ChatGPT responds. Set your preferences, and ChatGPT will keep them in mind for all future conversations.",
          "link": "https://openai.com/blog/custom-instructions-for-chatgpt",
          "publishedOn": "2023-07-20T07:00:00.000Z",
          "wordCount": 1937,
          "title": "Custom instructions for ChatGPT",
          "imageUrl": "https://images.openai.com/blob/71bddfc7-a5ca-4c77-9b3d-96659356640c/custom-instructions-for-chatgpt.png?trim=0%2C0%2C0%2C0"
        },
        {
          "id": "https://openai.com/blog/partnership-with-american-journalism-project-to-support-local-news",
          "author": null,
          "description": "A new $5+ million partnership aims to explore ways the development of artificial intelligence (AI) can support a thriving, innovative local news field, and ensure local news organizations shape the future of this emerging technology.",
          "link": "https://openai.com/blog/partnership-with-american-journalism-project-to-support-local-news",
          "publishedOn": "2023-07-18T07:00:00.000Z",
          "wordCount": 985,
          "title": "Partnership with American Journalism Project to support local news",
          "imageUrl": "https://images.openai.com/blob/fd058dd7-4501-4eec-ab78-a86ad57ffb11/partnership-with-american-journalism-project-to-support-local-news.png?trim=0%2C80%2C0%2C110"
        }
      ]
    },
    {
      "title": "Microsoft Research",
      "feedUrl": "https://www.microsoft.com/en-us/research/feed",
      "siteUrl": "https://www.microsoft.com/en-us/research/",
      "articles": [
        {
          "id": "https://www.microsoft.com/en-us/research/?p=958119",
          "author": "Alyssa Hughes",
          "description": "Researcher Jina Suh and manager Shamsi Iqbal are longtime collaborators. Learn how their history of working together and their unique perspectives are informing their development of tools to support decision-making for organizational leaders.\nThe post Collaborators: Data-driven decision-making with Jina Suh and Shamsi Iqbal appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/collaborators-data-driven-decision-making-with-jina-suh-and-shamsi-iqbal/",
          "publishedOn": "2023-08-03T13:00:00.000Z",
          "wordCount": 9706,
          "title": "Collaborators: Data-driven decision-making with Jina Suh and Shamsi Iqbal",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/08/jina-shamsi-collaborators-tw-li-fb-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=957600",
          "author": "Alyssa Hughes",
          "description": "In this edition: A new anonymous token protocol balances fraud detection and privacy; survival instinct in offline RL; Nimble offers rollback protection for confidential cloud services; improved machine learning force fields for molecular dynamics.\nThe post Research Focus: Week of July 31, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-july-31-2023/",
          "publishedOn": "2023-08-02T16:00:00.000Z",
          "wordCount": 3177,
          "title": "Research Focus: Week of July 31, 2023",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/07/RF21-blog-social-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=956640",
          "author": "Alyssa Hughes",
          "description": "Managing server failures at the scale of a cloud platform is challenging. The Hyrax fail-in-place approach reduces the need for immediate repairs and creates a path toward lowering water consumption and carbon emissions in cloud datacenters. \nThe post A fail-in-place approach for sustainable server operations appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/a-fail-in-place-approach-for-sustainable-server-operations/",
          "publishedOn": "2023-07-27T16:00:00.000Z",
          "wordCount": 3540,
          "title": "A fail-in-place approach for sustainable server operations",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/07/OSDI23-TWLIFB-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=955800",
          "author": "Alyssa Hughes",
          "description": "Microsoft Research is proud to be a sponsor of ICML 2023! From audio classification to privacy estimation and more, explore conference highlights in our latest blog post.\nThe post Microsoft at ICML 2023: Discoveries and advancements in machine learning appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/microsoft-at-icml-2023-discoveries-and-advancements-in-machine-learning/",
          "publishedOn": "2023-07-21T16:00:00.000Z",
          "wordCount": 3134,
          "title": "Microsoft at ICML 2023: Discoveries and advancements in machine learning",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/07/ICML23_Social_BlogPromo_1200x627.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=954777",
          "author": "Alyssa Hughes",
          "description": "For over a decade, Xbox has been leveraging AI to elevate gaming. Haiyan Zhang, GM of Gaming AI, explores the collaborations behind the work and the potential for generative AI to support better experiences for both players and game creators.\nThe post Collaborators: Gaming AI with Haiyan Zhang appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/collaborators-gaming-ai-with-haiyan-zhang/",
          "publishedOn": "2023-07-20T13:00:00.000Z",
          "wordCount": 8828,
          "title": "Collaborators: Gaming AI with Haiyan Zhang",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/07/Haiyan-CollabPodcast-TwLiFb-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=955086",
          "author": "Alyssa Hughes",
          "description": "RetroRanker mitigates frequency bias in predictions of retrosynthesis models; new algorithm beats PPO on language tasks; DER dataset aids grid planning; improved PPML balances privacy & accuracy across shared data; ASL Citizen boosts sign language modeling.\nThe post Research Focus: Week of July 17, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-july-17-2023/",
          "publishedOn": "2023-07-19T16:00:00.000Z",
          "wordCount": 3742,
          "title": "Research Focus: Week of July 17, 2023",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/07/RF20-blog-social-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=954351",
          "author": "Brenda Potts",
          "description": "Because headphones rank among the most popular wearables in the market, we have an exciting opportunity to expand their capabilities through integrating existing sensors with supplementary ones to enable a wide variety of experiences that go beyond traditional audio control.\nThe post Thinking beyond audio: Augmenting headphones for everyday digital interactions appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/thinking-beyond-audio-augmenting-headphones-for-everyday-digital-interactions/",
          "publishedOn": "2023-07-12T15:28:49.000Z",
          "wordCount": 3746,
          "title": "Thinking beyond audio: Augmenting headphones for everyday digital interactions",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/07/DIS23-TWLIFB-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=951852",
          "author": "Alyssa Hughes",
          "description": "Efficiency is vital in the face of escalating demand for cloud resources. And efficient power management strategies address the bottleneck of power availability in datacenters. Learn how we optimize power allocation to support sustainable resource usage.\nThe post Microsoft at ICALP 2023: Deploying cloud capacity robustly against power failures appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/microsoft-at-icalp-2023-deploying-cloud-capacity-robustly-against-power-failures/",
          "publishedOn": "2023-07-11T14:00:00.000Z",
          "wordCount": 3355,
          "title": "Microsoft at ICALP 2023: Deploying cloud capacity robustly against power failures",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/06/ICALP-2023-TWLIFB-1200x627-1.jpg"
        }
      ]
    },
    {
      "title": "Google AI Blog",
      "feedUrl": "http://feeds.feedburner.com/blogspot/gJZg",
      "siteUrl": "http://ai.googleblog.com/",
      "articles": [
        {
          "id": "http://ai.googleblog.com/2023/08/advances-in-document-understanding.html",
          "author": null,
          "description": "Posted by Sandeep Tata, Software Engineer, Google Research, Athena Team\n\n\n\n\nThe last few years have seen rapid progress in systems that can automatically process complex business documents and turn them into structured objects. A system that can automatically extract data from documents, e.g., receipts, insurance quotes, and financial statements, has the potential to dramatically improve the efficiency of business workflows by avoiding error-prone, manual work. Recent models, based on the Transformer architecture, have shown impressive gains in accuracy. Larger models, such as PaLM 2, are also being leveraged to further streamline these business workflows. However, the datasets used in academic literature fail to capture the challenges seen in real-world use cases. Consequently, academic b…",
          "link": "http://ai.googleblog.com/2023/08/advances-in-document-understanding.html",
          "publishedOn": "2023-08-09T18:32:00.001Z",
          "wordCount": 27825,
          "title": "Advances in document understanding",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi-Zs3cysjsJQsPfOZML1cR03gCO18NmC-KMsoQtctvWr7v_bwJ6MmQMXesUafsi7w53SY50YZOtnBdpAcBaplHXOPV8P1-X9deoXISeAfq85zUbcPXUOCPJSTsaIanCEIWUUkBNXE9JTU6q3OIgMZi5JqykbiN1x36LR78x4jEka2pL5MBjTdMr_Sn3FNv/w1200-h630-p-k-no-nu/Document%20understanding%20hero.png"
        },
        {
          "id": "http://ai.googleblog.com/2023/08/adatape-foundation-model-with-adaptive.html",
          "author": null,
          "description": "Posted by Fuzhao Xue, Research Intern, and Mostafa Dehghani, Research Scientist, Google\n\n\n\n\n\n\n\nAdaptive computation refers to the ability of a machine learning system to adjust its behavior in response to changes in the environment. While conventional neural networks have a fixed function and computation capacity, i.e., they spend the same number of FLOPs for processing different inputs, a model with adaptive and dynamic computation modulates the computational budget it dedicates to processing each input, depending on the complexity of the input.\n\n\nAdaptive computation in neural networks is appealing for two key reasons. First, the mechanism that introduces adaptivity provides an inductive bias that can play a key role in solving some challenging tasks. For instance, enabling different num…",
          "link": "http://ai.googleblog.com/2023/08/adatape-foundation-model-with-adaptive.html",
          "publishedOn": "2023-08-08T21:02:00.000Z",
          "wordCount": 27871,
          "title": "AdaTape: Foundation model with adaptive computation and dynamic read-and-write",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjlzhnBmcyTQ940NZQduhyS5G17r9FghwVjYOPW2Ly0pRzug9DdZ7p02z1iK1g9b93xIqJhdQrg5XVmlcUQqUcSOwQXOGSm6lhcScopZX5J3OTxIsThxmAudIEpkrshjAhipDV4VKFL7Vv1r0Qad77VSiH7rGUD9-E5Jgg1HnzmSkIBt24rd3j1rPN2Ee2N/w1200-h630-p-k-no-nu/adatape.png"
        },
        {
          "id": "http://ai.googleblog.com/2023/08/multimodal-medical-ai.html",
          "author": null,
          "description": "Posted by Greg Corrado, Head of Health AI, Google Research, and Yossi Matias, VP, Engineering and Research, Google Research\n\n\n\n\n\n\nMedicine is an inherently multimodal discipline. When providing care, clinicians routinely interpret data from a wide range of modalities including medical images, clinical notes, lab tests, electronic health records, genomics, and more.  Over the last decade or so, AI systems have achieved expert-level performance on specific tasks within specific modalities — some AI systems processing CT scans, while others analyzing high magnification pathology slides, and still others hunting for rare genetic variations. The inputs to these systems tend to be complex data such as images, and they typically provide structured outputs, whether in the form of discrete grades o…",
          "link": "http://ai.googleblog.com/2023/08/multimodal-medical-ai.html",
          "publishedOn": "2023-08-03T18:24:00.001Z",
          "wordCount": 27719,
          "title": "Multimodal medical AI",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhU2ypPfvmlgGQW4yp3EbUlJ4rLlIukRC9TDstIe7RV5JTxMo-THDgKPhFYbBUV4m0vKVjmG9lDTBWdy5kH_bR3-tqN8KzdhgmrLL_N2e_glc0WG-HkSm5Nouk7-MU65hu0RH5QWP0nHFNcZpERq9_agfaMqtHjhChbu_dPvWsJfZ8DsxZWnx15hogprRb3/w1200-h630-p-k-no-nu/medpalm.png"
        },
        {
          "id": "http://ai.googleblog.com/2023/07/in-search-of-generalizable-method-for.html",
          "author": null,
          "description": "Posted by Eleni Triantafillou, Research Scientist, and Malik Boudiaf, Student Researcher, Google \n\n\n\n\n\n\n\n\n\nDeep learning has recently made tremendous progress in a wide range of problems and applications, but models often fail unpredictably when deployed in unseen domains or distributions. Source-free domain adaptation (SFDA) is an area of research that aims to design methods for adapting a pre-trained model (trained on a “source domain”) to a new “target domain”, using only unlabeled data from the latter. \n \n\nDesigning adaptation methods for deep models is an important area of research. While the increasing scale of models and training datasets has been a key ingredient to their success, a negative consequence of this trend is that training such models is increasingly computationally expe…",
          "link": "http://ai.googleblog.com/2023/07/in-search-of-generalizable-method-for.html",
          "publishedOn": "2023-07-26T16:33:00.002Z",
          "wordCount": 27928,
          "title": "In search of a generalizable method for source-free domain adaptation",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhnKLO5myVKCSpTQa17lSR3Jj3i3D5Ll87Me9l6CHJ4eyQe_1feJitNR6CYsDURNb7OobVrh3MRU49C4epC-kkkEL7-kgiJ4MXEIvlxIxc8G7NXZxjzjgyM4nY06lQWVIGEL2yoKnK_mR9P8UyK5T_4b1pnQPOnjW2fhJVYgQkVTk7gxthW-n5WwKDdgmiA/w1200-h630-p-k-no-nu/notela.png"
        },
        {
          "id": "http://ai.googleblog.com/2023/07/google-at-icml-2023.html",
          "author": null,
          "description": "Posted by Cat Armato, Program Manager, Google\n\n\n\n\nGroups across Google actively pursue research in the field of machine learning (ML), ranging from theory and application. We build ML systems to solve deep scientific and engineering challenges in areas of language, music, visual processing, algorithm development, and more. We aim to build a more collaborative ecosystem with the broader ML research community through open-sourcing tools and datasets, publishing our work, and actively participating in conferences.\n\n\n\nGoogle is proud to be a Diamond Sponsor of the 40th International Conference on Machine Learning (ICML 2023), a premier annual conference, which is being held this week in Honolulu, Hawaii. As a leader in ML research, Google has a strong presence at this year’s conference with ov…",
          "link": "http://ai.googleblog.com/2023/07/google-at-icml-2023.html",
          "publishedOn": "2023-07-23T21:13:00.000Z",
          "wordCount": 29329,
          "title": "Google at ICML 2023",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiFdIolpEmmBVh-IZFfIHWjpGm5M-7N6hhQ4yBUFTBWZfQ_Wa4Reyz-YmsST7TbfiloQVKIlCaPhJgLj1nhzPr3JesD4nvXkj-FzGykvtGM7oe4MVV_Fidc0q6FuqvHXa8hrMj36TNRn_oP2_42lTJmWl3mGmaCNvqi5IQBx5PCfHKnpegwX-cVf4r3LUkU/w1200-h630-p-k-no-nu/Google-ICML-hero.jpg"
        },
        {
          "id": "http://ai.googleblog.com/2023/07/using-societal-context-knowledge-to.html",
          "author": null,
          "description": "Posted by Donald Martin, Jr., Technical Program Manager, Head of Societal Context Understanding Tools and Solutions (SCOUTS), Google Research\n\n\n\n\nAI-related products and technologies are constructed and deployed in a societal context: that is, a dynamic and complex collection of social, cultural, historical, political and economic circumstances. Because societal contexts by nature are dynamic, complex, non-linear, contested, subjective, and highly qualitative, they are challenging to translate into the quantitative representations, methods, and practices that dominate standard machine learning (ML) approaches and responsible AI product development practices.   \n \n\nThe first phase of AI product development is problem understanding, and this phase has tremendous influence over how problems (…",
          "link": "http://ai.googleblog.com/2023/07/using-societal-context-knowledge-to.html",
          "publishedOn": "2023-07-20T16:22:00.002Z",
          "wordCount": 27836,
          "title": "Using societal context knowledge to foster the responsible application of AI",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgoaJIKwp3izoj_P77_py-4_y4ng5B_HEW6HUB0QpkS_t4zc7p1w8FuG8x1IRK7Rw0R6uJIgUheqqr0yvz4YRykesH-IRKiV_PaXCr7MdBuaLzrlbqTgiIm3UM0rYcmVmKUlA5KqOjbqRdI3mwbTSyusxGhWisrXNS-C62JbiCHJTNh826JMQ2KtD9nu1vu/w1200-h630-p-k-no-nu/scouts.png"
        },
        {
          "id": "http://ai.googleblog.com/2023/07/simper-simple-self-supervised-learning.html",
          "author": null,
          "description": "Posted by Daniel McDuff, Staff Research Scientist, and Yuzhe Yang, Student Researcher, Google\n\n\n\n\n\nLearning from periodic data (signals that repeat, such as a heart beat or the daily temperature changes on Earth’s surface) is crucial for many real-world applications, from monitoring weather systems to detecting vital signs. For example, in the environmental remote sensing domain, periodic learning is often needed to enable nowcasting of environmental changes, such as precipitation patterns or land surface temperature. In the health domain, learning from video measurement has shown to extract (quasi-)periodic vital signs such as atrial fibrillation and sleep apnea episodes.\n\n\n\nApproaches like RepNet highlight the importance of these types of tasks, and present a solution that recognizes rep…",
          "link": "http://ai.googleblog.com/2023/07/simper-simple-self-supervised-learning.html",
          "publishedOn": "2023-07-18T20:15:00.000Z",
          "wordCount": 27491,
          "title": "SimPer: Simple self-supervised learning of periodic targets",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEipB_9hAxZvnElIMZ-TN-dvR0POGa65v8yaZCPs44rLweLTIuHtvXe9knDYpU3h4ydbjKk9F-bLE7WTNgx0MgzUMxHa-RXTg7Ch4nGU7rqSAMYpdxzDI7xuirzahNzDKHR9olCqeXv5vK0dTtCQPm1Ws6_364n0_6-2dR_u0zB0Qiabo_g92yjjDcc4SEhz/w1200-h630-p-k-no-nu/SimPer%20hero.jpeg"
        },
        {
          "id": "http://ai.googleblog.com/2023/07/symbol-tuning-improves-in-context.html",
          "author": null,
          "description": "Posted by Jerry Wei, Student Researcher, and Denny Zhou, Principal Scientist, Google Research\n\n\n\n\n\nA key feature of human intelligence is that humans can learn to perform new tasks by reasoning using only a few examples. Scaling up language models has unlocked a range of new applications and paradigms in machine learning, including the ability to perform challenging reasoning tasks via in-context learning. Language models, however, are still sensitive to the way that prompts are given, indicating that they are not reasoning in a robust manner. For instance, language models often require heavy prompt engineering or phrasing tasks as instructions, and they exhibit unexpected behaviors such as performance on tasks being unaffected even when shown incorrect labels.\n\n\nIn “Symbol tuning improves…",
          "link": "http://ai.googleblog.com/2023/07/symbol-tuning-improves-in-context.html",
          "publishedOn": "2023-07-13T21:01:00.001Z",
          "wordCount": 27765,
          "title": "Symbol tuning improves in-context learning in language models",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgpcvWqT7OBMHzleUaxiCaADL7SGlXJOakpKo6HsXwWHuERHv1mYDtz0UaLaKNoY6f7cgS7CVack55eHRIcUrDPd9ZY01EKCCUTsxkVAXh3qD7rSw0x2VWj17yKWoTYQD6xiIj-7Zp2vsPaT9ew4UpT6ec4LI0R0nKfb4Sbd1vEjyQEQW0lvbroBBFWfZ1h/w1200-h630-p-k-no-nu/SymbolTuning.png"
        },
        {
          "id": "http://ai.googleblog.com/2023/07/an-open-source-gymnasium-for-computer.html",
          "author": null,
          "description": "Posted by Amir Yazdanbakhsh, Research Scientist, and Vijay Janapa Reddi, Visiting Researcher, Google Research\n\n\n\n\nComputer Architecture research has a long history of developing simulators and tools to evaluate and shape the design of computer systems. For example, the SimpleScalar simulator was introduced in the late 1990s and allowed researchers to explore various microarchitectural ideas. Computer architecture simulators and tools, such as gem5, DRAMSys, and many more have played a significant role in advancing computer architecture research. Since then, these shared resources and infrastructure have benefited industry and academia and have enabled researchers to systematically build on each other's work, leading to significant advances in the field. \n\n\n\nNonetheless, computer architectu…",
          "link": "http://ai.googleblog.com/2023/07/an-open-source-gymnasium-for-computer.html",
          "publishedOn": "2023-07-11T17:00:00.010Z",
          "wordCount": 28016,
          "title": "An open-source gymnasium for machine learning assisted computer architecture design",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgMJx6osjDEhIpBGYohScAOpBU1CJmTsafUF9GgeM6BhBQ0KBjhSGirW0WY_8hu1boJvi-oqfbDlcHMO7RsrVOs1voUVsyE0f4uVSsBM2LgrSjGbFtuyWVXRbX7StUb4xbNgX7ZIfFDtfmjtJcEPvz6VGD_zGo1aEcQvbewZwSSwvMoHZP7ZW1Fob8tb86h/w1200-h630-p-k-no-nu/ArchGym-animation2.gif"
        }
      ]
    },
    {
      "title": "fast.ai",
      "feedUrl": "https://www.fast.ai/atom.xml",
      "siteUrl": "https://www.fast.ai/atom.xml",
      "articles": [
        {
          "id": "https://www.fast.ai/2022/09/06/homeschooling/",
          "author": null,
          "description": "My husband Jeremy and I never intended to homeschool, and yet we have now, unexpectedly, committed to homeschooling long-term. Prior to the pandemic, we both worked full-time in careers that we loved and found meaningful, and we sent our daughter to a full-day Montessori school. Although I struggled with significant health issues, I felt unbelievably lucky and fulfilled in both my family life and my professional life. The pandemic upended my careful balance. Every family is different, with different needs, circumstances, and constraints, and what works for one may not work for others. My intention here is primarily to share the journey of my own (very privileged) family.\n\n  \n\n\nOur unplanned introduction to homeschooling\nFor the first year of the pandemic, most schools in California, where …",
          "link": "https://www.fast.ai/2022/09/06/homeschooling/",
          "publishedOn": "2022-09-05T14:00:00.000Z",
          "wordCount": 2118,
          "title": "My family's unlikely homeschooling journey",
          "imageUrl": null
        },
        {
          "id": "https://www.fast.ai/2022/08/25/jupyter-git/",
          "author": null,
          "description": "Jupyter notebooks don’t work with git by default. With nbdev2, the Jupyter+git problem has been totally solved. It provides a set of hooks which provide clean git diffs, solve most git conflicts automatically, and ensure that any remaining conflicts can be resolved entirely within the standard Jupyter notebook environment. To get started, follow the directions on Git-friendly Jupyter.\nContents\nThe Jupyter+git problem\nThe solution    \nThe nbdev2 git merge driver\nThe nbdev2 Jupyter save hook\nBackground\nThe result\nPostscript: other Jupyter+git tools    \nReviewNB\nAn alternative solution: Jupytext\nnbdime\nThe Jupyter+git problem\nJupyter notebooks are a powerful tool for scientists, engineers, technical writers, students, teachers, and more. They provide an ideal notebook environment for interact…",
          "link": "https://www.fast.ai/2022/08/25/jupyter-git/",
          "publishedOn": "2022-08-24T14:00:00.000Z",
          "wordCount": 2227,
          "title": "The Jupyter+git problem is now solved",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Reinforcement Learning",
      "feedUrl": "https://www.reddit.com/r/reinforcementlearning/.rss?format=xml",
      "siteUrl": "https://www.reddit.com/r/reinforcementlearning/?format=xml",
      "articles": [
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15mueec/personalization_with_vw/",
          "author": null,
          "description": "Hello! I am working off the VowpalWabbit example for explore_adf, just changing the cost function and actions but I get no learning. What I mean is that I train a model but when I ran the prediction, I just get an array of equivalent probabilities (0.25, 0.25, 0.25, 0.25). I have tried changing everything (making only one action to payoff for example) and still get the same error. Anyone has ran into a similar situation? Help please!\n    submitted by    /u/juanccs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15mueec/personalization_with_vw/",
          "publishedOn": "2023-08-09T22:53:51.000Z",
          "wordCount": 2571,
          "title": "Personalization with VW",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15mtvzg/inquiry_regarding_dynamic_action_space_dqn_and/",
          "author": null,
          "description": "I am currently addressing a challenge within the domain of Reinforcement Learning. The particular issue revolves around a dynamic action space, where the set of potential actions available changes based on the context or state. In light of this, I am seeking guidance on the feasibility of utilizing the Deep Q-Network (DQN) approach to specifically identify permissible actions for distinct states.\n Furthermore, if the DQN approach is not applicable in this scenario, I would appreciate recommendations for alternative algorithms that could effectively address this issue. Additionally, I am considering the option of designing a single action space and employing negative reward to discourage the agent from pursuing unauthorized actions within specific states.\n    submitted by    /u/uonliaquat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15mtvzg/inquiry_regarding_dynamic_action_space_dqn_and/",
          "publishedOn": "2023-08-09T22:33:57.000Z",
          "wordCount": 2615,
          "title": "Inquiry Regarding Dynamic Action Space, DQN, and Alternative Algorithms in Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15mp5l7/how_to_tell_if_your_model_is_actually_learning/",
          "author": null,
          "description": "I've been building a multi-agent model of chess, where each side of the board is represented by a Deep Q Agent. I had it play 100k training games, but the loss scores increased over time, not decreased. I've got the (relatively short) implementation and the last few output graphs from the training--is there a problem with my model architecture or does it just need more training games, perhaps against a better opponent than itself? Here's the notebook file. Thanks in advance\n    submitted by    /u/lcmaier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15mp5l7/how_to_tell_if_your_model_is_actually_learning/",
          "publishedOn": "2023-08-09T19:37:07.000Z",
          "wordCount": 2581,
          "title": "How to tell if your model is actually learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15mojqr/reward_shaping_in_frozenlake/",
          "author": null,
          "description": "I'm trying to use a neurosymbolic approach to solve the Frozenlake enviroment, using also stable baselines 3.\n I used the TransformReward on the enviroment, and seems that it's working (changing the reward values).\n So here it is how it works the program:\n It calculates a reward per step based on the distance of the next state to the goal state. Also I tried adding some more constraints, like punishing if it stays on the same square or if it falls into a hole.\n The thing is that I don't know if I'm doing something wrong, so if someone can help me would be much appreciated. Here is part of the code, I'll omit the neuro symbolic part because it's irrelevant.\n The rewards are:\n ​\n  \nTaking a step in a direction that makes you near the goal: less than one (it depends on how near of the objecti…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15mojqr/reward_shaping_in_frozenlake/",
          "publishedOn": "2023-08-09T19:14:14.000Z",
          "wordCount": 3000,
          "title": "Reward shaping in FrozenLake",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15mjlw7/cnn_features_extractor_for_categorical_data/",
          "author": null,
          "description": "I'm working on a RL Environment for my Masther Thesis where i try to explore the use of RL for Architectural Design. The environment looks like a 3D Grid of cubic 3D tiles or modules, and the agent can place tiles by choosing : Location (As x,y,z coordinates) , rotation (0 to 4 as multiples of 90 degrees around a z axis in the center) , and Tile Type (Im experimenting with many sets of tiles with different sizes). Then, I use Grasshopper3D to analyze the radiation that the interior surfaces and other metrics, that i use for my reward calculation. \n For this, the state of the environment is defined as a 3D Array with 2 channels. One for the Tile Types and one for the rotations. This is processed by a 3D CNN features extractor. \n The thing is that, I just realized that the array that represents the tile types as integers is actually categorical data, and I don't know how well this could work in a CNN. What i mean by this is that a tile=3 is not any more \"anything\" that a tile=1, it is just different. \n Am I doing something stupid then? Should i change it?\n I apologize if im saying something really dumb. I just got into RL few months ago : - ) \n    submitted by    /u/Direct-Software7378  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15mjlw7/cnn_features_extractor_for_categorical_data/",
          "publishedOn": "2023-08-09T16:09:54.000Z",
          "wordCount": 2716,
          "title": "CNN Features Extractor for Categorical Data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15m1hj4/alphastar_unplugged_largescale_offline/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15m1hj4/alphastar_unplugged_largescale_offline/",
          "publishedOn": "2023-08-09T01:52:47.000Z",
          "wordCount": 2514,
          "title": "\"AlphaStar Unplugged: Large-Scale Offline Reinforcement Learning\", Mathieu et al 2023 {DM} (MuZero)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15lq3ka/studying_rl_is_hard/",
          "author": null,
          "description": "I want to study Reinforcement Learning, but the concepts are really hard and mathematical. Whenever I think I grasp something I forget it the next day completly. The Basic Concepts of MDP is the only thing which I think I understood. But I cant understand the Training algorithms like Sarsa or Q-Learning and DQN and their implementations. I am really frustrated and overwhelmed.\n Does anyone know some good resources to understand the concepts and implementations of RL?\n    submitted by    /u/Menium  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15lq3ka/studying_rl_is_hard/",
          "publishedOn": "2023-08-08T18:25:11.000Z",
          "wordCount": 2571,
          "title": "Studying RL is hard",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15lofrn/is_it_necessary_to_run_episodes_in_modelfree/",
          "author": null,
          "description": "In Q-learning (image), episodes are run, in the sense that, the states are visited in the order they appear as part of one sequence in an episode.\n In Dyna-Q (image) (which is btw described to be the same as Q-learning when the planning portion is deleted), there doesn't seem to be any iteration over the states of an episode. It just picks a state, applies the e-greedy policy on it to choose the action, learns, updates the model, then plans.\n Would Q-learning also work fine if we got rid of the \"episodes\" and just picked isolated state-action pairs?\n Thank you\n    submitted by    /u/AstronautVarious3791  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15lofrn/is_it_necessary_to_run_episodes_in_modelfree/",
          "publishedOn": "2023-08-08T17:23:51.000Z",
          "wordCount": 2600,
          "title": "Is it necessary to run \"episodes\" in model-free learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15lm5nl/intuition_about_what_features_deep_rl_learns/",
          "author": null,
          "description": "I know for image recognition there is a rough intuition that neural network lower layers learn low level features like edges, and the higher layers learn more complex compositions of the lower layer features. Is there a similar intuition about what a value network or policy network learns in deep RL? If there are any papers that investigate this that would be helpful\n    submitted by    /u/Turkeydunk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15lm5nl/intuition_about_what_features_deep_rl_learns/",
          "publishedOn": "2023-08-08T15:57:13.000Z",
          "wordCount": 2561,
          "title": "Intuition about what features deep RL learns?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15jxbpk/could_someone_help_me_understand_what_is_going_on/",
          "author": null,
          "description": "https://imgur.com/WR0Tny9\n My agent needs to learn to take one action in my environment and there are only two possible actions that the agent can take at each time step. The state is just the time step, so every episode has 240 time steps and the agent just needs to learn to take one optimal action out of two possible actions for every time step. I have set this up as simply as I can as a starting point to make sure the algorithm is implemented correctly and that the agent can learn. I am using n-step expected SARSA.\n The bottom plot shows the count for how many times the agent took each action during each episode. The middle plot has the temporal difference error in blue and the \"modelling error\" in orange. The modelling error is the difference between the actual discounted return and the TD target for each time step, summed up for each episode. The red line is the return that the agent would get if it took the optimal action in every time step.\n 0.11, the blue line in the bottom plot, is the optimal action for the agent to take at every time step. The other action will never result in a reward other than 0. So it should be fairly simple for the agent to learn what action to take at every time step and it does learn that at the start. But then, as you can see in the top plot, the agent suddenly starts taking the non-optimal action more often after around episode 450. So I'm just wondering why that would happen. Why would the agent learn to take the optimal action at most time steps and then suddenly decide that it will start taking other actions?\n For more context, the learning rate is 0.6, n is 6, epsilon is decayed by 1/(n_episodes/1.1) every episode so it reaches 0 slightly before the final episode.\n Any ideas based on this information why the agent would decide to start taking the non-optimal action? Or any suggestions for how I could figure out why it would start taking the non-optimal action?\n    submitted by    /u/lifelifebalance  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15jxbpk/could_someone_help_me_understand_what_is_going_on/",
          "publishedOn": "2023-08-06T18:52:40.000Z",
          "wordCount": 2813,
          "title": "Could someone help me understand what is going on with my agent in this environment?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15juvsd/runtimeerror_trying_to_backward_through_the_graph/",
          "author": null,
          "description": "submitted by    /u/Think_Huckleberry299  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15juvsd/runtimeerror_trying_to_backward_through_the_graph/",
          "publishedOn": "2023-08-06T17:13:32.000Z",
          "wordCount": 2488,
          "title": "RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15ju299/tarmac_targeted_multiagent_communication/",
          "author": null,
          "description": "Does anyone know code implementations for TarMAC: Targeted Multi-Agent Communication?\n    submitted by    /u/tessherelurkingnow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15ju299/tarmac_targeted_multiagent_communication/",
          "publishedOn": "2023-08-06T16:39:16.000Z",
          "wordCount": 2457,
          "title": "TarMAC: Targeted Multi-Agent Communication",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15j06hu/why_isnt_there_a_sarsa_equivalent_that_uses_value/",
          "author": null,
          "description": "SARSA is a TD algorithm for control (learning optimal policies). In the book it's written like this: image. The idea is to learn the action-value function instead of the value function for a policy that we keep improving (using GPI). Once we learn the converged action-value function for all states, the optimal policy is greedily derived from the action-value function (basically take the most promising action at each state).\n In contrast, TD for value estimation is written like this: image. Here we keep the policy fixed and just keep iterating over the multiple episodes, whilst refining the value estimate.\n My question is, why can't we just change TD for value estimation to just greedily update the policy at each stage? That would be in the spirit of generalized policy iteration (GPI) too. In other words, a version of SARSA which doesn't use action-value functions, but instead use value functions?\n    submitted by    /u/AstronautVarious3791  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15j06hu/why_isnt_there_a_sarsa_equivalent_that_uses_value/",
          "publishedOn": "2023-08-05T16:34:13.000Z",
          "wordCount": 2602,
          "title": "Why isn't there a SARSA equivalent that uses value functions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15iemvu/understanding_the_concept_of_variance_in/",
          "author": null,
          "description": "I was trying to understand Generalized Advantage Estimation from here and came across the following paragraph - \n ​\n https://preview.redd.it/l41x655ea6gb1.png?width=778&format=png&auto=webp&s=ffd266c0355a03e1c98ea6de89ca2fc78ed27fd1\n I understood the reason why there could be high bias while bootstrapping the advantage. But why does $A_t^{\\inf}$ have high variance. Aren't bias and variance concepts related to estimation by an estimator? While calculating $A_t^{\\inf}$, we are literally using the reward values obtained from the environment and therefore there is no estimation involved. Could someone please help me with this?\n ​\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15iemvu/understanding_the_concept_of_variance_in/",
          "publishedOn": "2023-08-04T22:52:51.000Z",
          "wordCount": 2528,
          "title": "Understanding the concept of Variance in Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15ib8x9/interesting_rl_environments_in_github/",
          "author": null,
          "description": "I am searching for an interesting but not too complex game envs.\n Preferably with selfplay but should not be very simple nor standard atari like.\n Any recommendations?\n    submitted by    /u/Trrrrr88  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15ib8x9/interesting_rl_environments_in_github/",
          "publishedOn": "2023-08-04T20:41:44.000Z",
          "wordCount": 2475,
          "title": "Interesting RL environments in github",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15hwxd6/updating_custom_output_layers_of_an_lstm_network/",
          "author": null,
          "description": "I have a text generation task learning to predict the next word with an LSTM network with multiple output layers.\n After the generation of a sentence has finished, I calculate a reward for the whole sentence and try to update the output layers participated in the generation (contributing layers get the calculated reward value, others get 0).\n My problem is that even if I update only the selected output layers, it seems that other layer's weights got updated instead.\n I have a minimized example with dummy data to present the problem:\n import random import numpy as np import tensorflow as tf from keras.layers import Input, LSTM, Dense, Embedding from keras.utils import pad_sequences from tensorflow.keras.models import Model def policy_gradient_loss(y_true, y_pred): return tf.reduce_mean(tf.m…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15hwxd6/updating_custom_output_layers_of_an_lstm_network/",
          "publishedOn": "2023-08-04T10:59:47.000Z",
          "wordCount": 2764,
          "title": "Updating custom output layers of an LSTM network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15hln42/why_am_i_unable_to_reshape_my_observation_with/",
          "author": null,
          "description": "I am trying to reshape my `Breakout` vectorized environment observations to have the shape `num_envs*frames, height, width, channels`. Currently, the shape is `(3, 4, 210, 160, 3)` and basically I'd like it to be `(3*4, 210, 160, 3)`. Based on the documentation, the `TransformObservation` should solve this problem for me, but it is not doing that.\n ​\n Here's my code -\n import gym import numpy as np from gym.wrappers import AtariPreprocessing, FrameStack, GrayScaleObservation, TransformObservation if __name__ == '__main__': def reshape_image(obs): # Assuming the original observation is an image with shape (height, width, channels) new_obs = np.array(obs).reshape(12, 210, 160, 3) return new_obs env = gym.vector.make(\"ALE/Breakout-v5\", num_envs=4) env = FrameStack(env, num_stack=3) env = TransformObservation(env, reshape_image) env.reset() observation, reward, terminated, done = env.step(env.action_space.sample()) print(\"observation = \", env.observation_space.shape) \n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15hln42/why_am_i_unable_to_reshape_my_observation_with/",
          "publishedOn": "2023-08-04T00:56:55.000Z",
          "wordCount": 2577,
          "title": "Why am I unable to reshape my observation with `TransformObservation` wrapper?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15hjz50/skillit_a_datadriven_skills_framework_for/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15hjz50/skillit_a_datadriven_skills_framework_for/",
          "publishedOn": "2023-08-03T23:43:31.000Z",
          "wordCount": 2469,
          "title": "\"Skill-it! A Data-Driven Skills Framework for Understanding and Training Language Models\", Chen et al 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15h9uj8/how_do_i_add_entropy_to_a_ppo_algorithm/",
          "author": null,
          "description": "Can someone please help with this question? I have added my understanding of this problem to the question, but I suspect that it may be flawed.\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15h9uj8/how_do_i_add_entropy_to_a_ppo_algorithm/",
          "publishedOn": "2023-08-03T17:09:22.000Z",
          "wordCount": 2478,
          "title": "How do I add Entropy to a PPO algorithm?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15gre4h/how_to_get_better_at_programming_when_i_have_bp/",
          "author": null,
          "description": "Hi I am 30F, currently working on my thesis. I like the idea of creating logics and then implementing them using coding. I switched my major from engineering to CS bcuz I was very much inspired by AI and all. But the issue is I have bipolar disorder and I am also on ADHD spectrum so self paced online courses to learn programming are very hard for me. I am also barely managing to pay tuition so I can't pay like $100+ for a course to learn. I know it's kinda stupid but is there any way I can make my programming skills better and get better at creating/modifying algorithms?\n    submitted by    /u/Kucing_koyangi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15gre4h/how_to_get_better_at_programming_when_i_have_bp/",
          "publishedOn": "2023-08-03T02:21:19.000Z",
          "wordCount": 2568,
          "title": "How to get better at programming when I have BP disorder and on ADHD spectrum?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15glpji/tianshou_dqn_batch_size_keeps_decreasing/",
          "author": null,
          "description": "I am trying to train a DQN to play chess using a combination of Tianshou and PettingZoo. However, for a reason I cannot locate, after anwhere from 15-25 passes through the forward function, the size of the batches starts decreasing, until it falls all the way to 1, before throwing a warning that n_step isn't a multiple of the number of environments, jumping to a size = the number of training environments and then the training agent's batch size before erroring out. My best guess is that somehow truncated games aren't being properly added to the batch, but that doesn't quite explain why each subsequent batch is equal or smaller in size. I am at a loss for how to debug this. Everything is in this Python Notebook.\n    submitted by    /u/lcmaier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15glpji/tianshou_dqn_batch_size_keeps_decreasing/",
          "publishedOn": "2023-08-02T22:13:57.000Z",
          "wordCount": 2577,
          "title": "Tianshou DQN batch size keeps decreasing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15g4w3v/stable_gail_alternatives_for_imitation_learning/",
          "author": null,
          "description": "I'm currently working on a project for Imitation Learning from multiple perspectives. The base Imitation Learning algorithm I'm currently using is GAIL.\n Working with GAIL has been very frustrating because it's incredibly seed dependent and unstable. This makes progress and iteration speed for experiments/modifications built on top of it very slow.\n As I'm not an expert in Imitation Learning: Does anybody with experience know more stable alternatives (or improvements) to GAIL?\n The setting I'm considering is Learning from Observations (LfO), so I don't think that DAgger will work.\n I've done some preliminary search and found this method https://arxiv.org/pdf/2004.04650.pdf. However, the authors don't compare it to GAIL.\n Thanks in advance for any suggestions!\n    submitted by    /u/timo_kk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15g4w3v/stable_gail_alternatives_for_imitation_learning/",
          "publishedOn": "2023-08-02T10:09:24.000Z",
          "wordCount": 2563,
          "title": "Stable GAIL alternatives for Imitation Learning from pixels",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15g49ai/how_to_implement_a_policy_agent_in_pettingzoo_mpe/",
          "author": null,
          "description": "Hi all:\n I am trying to train a competitive scenario in a Multiagent particle environment( I am now using the Pettingzoo API). The Algorithm I am now using only support discrete action space. But I want to evaluate agents with one side's policy keep fixed and let the other side's policies be the trained policy. The policy can be simple( like if the target for one side agent is to chase the other side, their policy is directly following the trajectory for their target). The core.py for the petting zoo, it has \n  # return all agents controllable by external policies @property def policy_agents(self): return [agent for agent in self.agents if agent.action_callback is None] # return all agents controlled by world scripts @property def scripted_agents(self): return [agent for agent in self.agents if agent.action_callback is not None] \n But in the step for the environment, it seems the environment directly controls the policy agent. My understanding is scripted agent is RL policy output and the Policy agent can be controlled by other policies. \n My question is :\n if my policy output is the desired position for each timestep, but now the MPE's control dynamic is learned the acceleration's increment, and it's discrete, how can I implement the policy as one side of my competitive case?\n  \nif I can control the policy agent base on policy_agent, how can I step both policy and script agent in env?\n if I can control the agent separately, like my RL output can be discrete but the policy output can be continuous position.\n how to define the termination or truncation for all agents?\n  \n   submitted by    /u/Gloria_1126  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15g49ai/how_to_implement_a_policy_agent_in_pettingzoo_mpe/",
          "publishedOn": "2023-08-02T09:33:48.000Z",
          "wordCount": 2717,
          "title": "How to implement a policy agent in pettingzoo mpe",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15g1j2q/training_cartpole_using_policy_gradient_and/",
          "author": null,
          "description": "I am trying to train the cartpole environment using policy gradients algorithm.\n I want to train using the GradientTape method of tensorflow. I have been trying for a long time, but still it hasn't converged.\n What am I doing wrong?\n ​\n import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers import numpy as np import keras.backend as K import matplotlib.pyplot as plt class PolicyGradientModel(keras.Model): def __init__(self, num_actions): super().__init__() self.hidden1 = layers.Dense(24, activation='relu') self.hidden2 = layers.Dense(120, activation='relu') self.out = layers.Dense(num_actions, activation='softmax') def call(self, inputs): x = self.hidden1(inputs) x = self.hidden2(x) return self.out(x) def action_prob(self, state): prob = self.predict(np.ex…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15g1j2q/training_cartpole_using_policy_gradient_and/",
          "publishedOn": "2023-08-02T06:59:49.000Z",
          "wordCount": 2760,
          "title": "Training Cartpole using policy gradient and gradient tape of tensorflow is not converging.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15fx7dh/how_can_i_make_my_vectorized_ppo_implementation/",
          "author": null,
          "description": "Here is my vectorized PPO implementation, that I wrote (with a lot of help from this community). These are my results on the Acrobot-v1 environment.\n The way I computed the reward for my vectorized implementation was that I added all the rewards across all environments. An ideal Acrobot agent should receive a reward of 0.\n Please let me know if I am missing any information or if any clarification is required. I skipped a part, which was suggested by the community a few months ago - updating the gradients using minibatches. The reason I skipped it is that, I don't understand how this works and anyway Acrobot should be an easy environment to learn.\n https://preview.redd.it/0vs9ur585mfb1.png?width=622&format=png&auto=webp&s=ebc007a9f797bd0b97b805d010dbd097c0be8906\n Also, I keep getting this error at the end of my code. But I haven't bothered fixing it as it doesn't seem to affect my algorithm - \n Exception ignored in: <function VectorEnv.__del__ at 0x0000023BBF6F2710> Traceback (most recent call last): File \"C:\\Users\\thoma\\anaconda3\\envs\\torch_2\\lib\\site-packages\\gym\\vector\\vector_env.py\", line 139, in __del__ File \"C:\\Users\\thoma\\anaconda3\\envs\\torch_2\\lib\\site-packages\\gym\\vector\\vector_env.py\", line 121, in close File \"C:\\Users\\thoma\\anaconda3\\envs\\torch_2\\lib\\site-packages\\gym\\vector\\async_vector_env.py\", line 327, in close_extras AttributeError: 'NoneType' object has no attribute 'TimeoutError' \n ​\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15fx7dh/how_can_i_make_my_vectorized_ppo_implementation/",
          "publishedOn": "2023-08-02T03:11:04.000Z",
          "wordCount": 2631,
          "title": "How can I make my vectorized PPO implementation learn better?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15fqco8/what_do_simulations_mean_in_the_context_of_the/",
          "author": null,
          "description": "Can someone please help me with this question? Please let me know if any clarification is needed. Thanks so much!\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15fqco8/what_do_simulations_mean_in_the_context_of_the/",
          "publishedOn": "2023-08-01T22:04:53.000Z",
          "wordCount": 2470,
          "title": "What do simulations mean in the context of the AlphaGoZero paper?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15fos7v/drone_for_research/",
          "author": null,
          "description": "I'm currently working on a research project that involves using deep reinforcement learning with drones. I'm looking for recommendations on drones that would be suitable for this type of research. I am looking for something of the shelf.\n    submitted by    /u/anointedninja  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15fos7v/drone_for_research/",
          "publishedOn": "2023-08-01T21:05:03.000Z",
          "wordCount": 2480,
          "title": "Drone for Research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15f3rmc/making_a_reinforcement_learning_codein_python/",
          "author": null,
          "description": "So i want to make a bot that can play a game with only the visual data and no other fancy stuff. I did manage to get all the data i need (i hope) using a code that uses open-cv to get data in real time\n Example:Player: ['Green', 439.9180603027344, 461.7232666015625, 13.700743675231934]\n Enemy Data {0: [473.99951171875, 420.5301513671875, 'Green', 20.159990310668945]}\n Box: {0: [720, 605, 'Green_box'], 1: [957, 311, 'Green_box'], 2: [432, 268, 'Red_box'], 3: [1004, 399, 'Blue_box']} \n can anyone suggest a way to make one.\n Rules:\n - You can only move in the direction of mouse.\n -You can dash in direction of mouse by LMB.\n -You can collect boxes to get HP and change colors.\n -Red color kills Blue kills Green Kills Red.\n -There is a fixed screen.\n -You lose 25% of total HP when you dash.\n -You lose 50% of HP when you bump into players (of color that kills or there HP is > than you. \n ​\n Visualization of Data.\n    submitted by    /u/SIJ_Gamer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15f3rmc/making_a_reinforcement_learning_codein_python/",
          "publishedOn": "2023-08-01T05:59:46.000Z",
          "wordCount": 2605,
          "title": "Making a reinforcement learning code(in python) that can play a game with visual data only.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15eqfi0/reinforcement_learning_an_introduction_2nd/",
          "author": null,
          "description": "Greetings!\n I'm going through the initial equations that define most of the theoretical framework for the specialization. One curious thing I noticed with equations 3.5 and 3.6 is that they use the conditional distribution p(s′,r∣s,a) without including any priors. I'm talking about priors because, unless I'm missing something huge, the definition of the expected value for the reward (for both 3.5 and 3.6) should use the joint distribution for all 4 dimensions (next state, reward, current state, action). From that joint distribution, we can factorize it to show p(s′,r∣s,a). For example, one factorization that seems to make sense for this kind of model is\n p(s′,r,s,a) = p(s′,r∣s,a) ⋅ p(s) ⋅ p(a)\n which would turn, for example, equation 3.5 into\n r(s,a) = ∑​ ∑ ​r ⋅ p(s′,r∣s,a) ⋅ p(s) ⋅ p(a) (Note: the two sums are for \"r\" and \"s' \". I wrote like that because I don't know write it in Latex or similar...)\n What am I missing? Is it because s and a are given as parameters of the function r(s,a) meaning that p(s) = p(a) = 1? If the factorization above is the right one for those equations, is this the only factorization used in the entire book?\n Thanks in advance!\n    submitted by    /u/SupBiebi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15eqfi0/reinforcement_learning_an_introduction_2nd/",
          "publishedOn": "2023-07-31T20:02:59.000Z",
          "wordCount": 2658,
          "title": "[Reinforcement Learning: an Introduction (2nd edition)] Why not the joint distribution for equations 3.5 and 3.6?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15em4ah/discussion_comprehensive_learning_resources_that/",
          "author": null,
          "description": "So I understand that there is the Sutton & Barto book on reinforcement learning in the sidebar. I was wondering what other resources you guys have used that you would recommend that emphasize deep reinforcement learning for someone with some experience in shallow/classical reinforcement learning already and some experience with deep learning already, but new to deep reinforcement learning\n    submitted by    /u/BornAgain20Fifteen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15em4ah/discussion_comprehensive_learning_resources_that/",
          "publishedOn": "2023-07-31T17:18:12.000Z",
          "wordCount": 2507,
          "title": "[Discussion] Comprehensive learning resources that emphasize DEEP reinforcement learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15ekx4r/what_are_some_big_action_space_marl_stochastic/",
          "author": null,
          "description": "Are there big action space stochastic games that are implemented in OpenSpiel or equivalent? I played around Markov soccer game a lot but it's solvable with tabular methods and I was looking for games with at least more than 500 actions both players can take as a testbed for more complicated action spaces?\n    submitted by    /u/Potential_Biscotti14  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15ekx4r/what_are_some_big_action_space_marl_stochastic/",
          "publishedOn": "2023-07-31T16:30:58.000Z",
          "wordCount": 2506,
          "title": "What are some big action space MARL stochastic games implemented in OpenSpiel or equivalent?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15ehg0p/optimal_bidding_strategy_in_power_market_using/",
          "author": null,
          "description": "Hello everyone! I'm trying to use reinforcement learning to solve a problem in the power market. The problem is about finding the best strategy for bidding on electricity for each hour of the day, considering both buying and selling options. Let's say we have a generator that can produce up to 800MW of electricity per day, and it can be charged up to 200MW per hour. After charging it for 4 hours continuously, it reaches its maximum capacity, and we can't charge more until we discharge some electricity. We have access to data from the past 5 years, including information about temperature, hydro, gas prices, and locational marginal price, which is important for determining profit. For instance, if we buy 10MW of electricity for a specific hour, our profit for that hour is 10 times the locational marginal price. The goal is to maximize profit at the end of the day while making sure that the total electricity bought and sold is equal for all days. This means we want to avoid wasting electricity. I initially tried using deep Q-learning, where the agent's state consists of data from the past 3 days, and the agent can take actions to buy or sell a certain amount of electricity for one hour. However, this approach doesn't seem to provide accurate results, and it works step by step, not considering the overall outcome for the whole day. So, I'm looking for help on how to build an agent capable of producing 24 bids for 24 hours, considering the constraints of the generator's capacity and ensuring no waste of electricity. I'm new to reinforcement learning, and I'm not sure how to approach this complex problem. Any guidance would be greatly appreciated!\n    submitted by    /u/uonliaquat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15ehg0p/optimal_bidding_strategy_in_power_market_using/",
          "publishedOn": "2023-07-31T14:16:52.000Z",
          "wordCount": 2735,
          "title": "Optimal Bidding Strategy in Power Market using Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15ea1cu/looking_for_old_tutorial_series/",
          "author": null,
          "description": "A few years ago, I remember reading a multipart series of articles/blog posts explaining how to develop agents for classical games. I believe the series started with tic-tac-toe and definitely progressed to gomoku, before maybe moving on to more complex games. I think there was more of a focus on algorithms (maybe MCTS) and concepts than code. It's a long shot, but does anyone recall this series or know if it's archived somewhere? seems like it might have been taken down.\n  \nWasn't on Medium. I think it might've been a personal website. I vaguely remember a green UI theme?\n  \n   submitted by    /u/nothymn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15ea1cu/looking_for_old_tutorial_series/",
          "publishedOn": "2023-07-31T08:20:57.000Z",
          "wordCount": 2543,
          "title": "Looking for old tutorial series",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15dtfw7/sb3_for_pettingzoo_simple_spread/",
          "author": null,
          "description": "I previously posted a query about the same,\n but when i tried to implement A2C model training using SB3 on simple spread environment, I am not getting good and improved reward values, it's still highly negative and the model is performing rather randomly. \n env = ss.pettingzoo_env_to_vec_env_v1(env)\n env = ss.concat_vec_envs_v1(env, 4, num_cpus=2, base_class=\"stable_baselines3\")\n policy_kwargs = dict(net_arch = [128,128])\n model = A2C(\n MlpPolicy,\n env,\n verbose=1,\n learning_rate= 0.007,\n gamma = 0.95,\n ent_coef = 0.4,\n policy_kwargs= policy_kwargs,\n tensorboard_log= logdir\n )\n This is a fragment of code for reference. I tried to give more policy_kwargs like: share_features_extractor=False, or even tried to implement entirely custom policy, but the total average reward is still not going above -300.\n Also, the tensorboard plots are not showing ep_rew_mean plot, should I be passing some parameters for that?\n    submitted by    /u/bruhhhwhats  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15dtfw7/sb3_for_pettingzoo_simple_spread/",
          "publishedOn": "2023-07-30T19:03:11.000Z",
          "wordCount": 2585,
          "title": "SB3 for pettingzoo simple spread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15dn9wz/how_is_the_policy_network_updated_in_alphago/",
          "author": null,
          "description": "In AlphaGo, a tree search is performed, and uses the policy network to reduce the breadth of it. At the leafs, if the states are not terminal, it uses the value network. And then \"backup\" the values to update the Q value at the initial state (if 70% of my rollouts won after performing action a_1, my Q value q(initial_state, a_1) should converge to 0.7 in my initial state). But I don't see where the policy network is updated?\n ​\n Here is a slide from David Silver, the first-author of AlphaGo, but it doesn't mention how to update the policy network.\n ​\n https://preview.redd.it/f29no3xe64fb1.png?width=1523&format=png&auto=webp&s=5adb312b1d0c033aa8ebb328197fd7d917724f06\n Have I missed something?\n Thankss!\n    submitted by    /u/Potential_Biscotti14  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15dn9wz/how_is_the_policy_network_updated_in_alphago/",
          "publishedOn": "2023-07-30T14:42:06.000Z",
          "wordCount": 2580,
          "title": "How is the policy network updated in AlphaGo?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15dgonm/what_is_wrong_with_my_codedqn/",
          "author": null,
          "description": "recently, I've been trying to make a deep q network for solving 2x2 rubik's cubeBut after months, I stuck with same output for HUNDREDS of times :(\n I tried everything: change learning rate, change discout factor but no luck\n Here's update rule: newQ=currentQ+alpha*(newR+gamma*max(futureQValue.flatten().tolist())-currentQ)\n import torch import torch.nn as nn import torch.optim as optimizer import os from tqdm import tqdm class DQN(nn.Module): def __init__(self, stateSpaceSize,actionSpaceSize): super(DQN, self).__init__() self.fc1=nn.Linear(stateSpaceSize,128) self.fc2=nn.Linear(128,128) self.fc3=nn.Linear(128,128) self.fc4=nn.Linear(128,128) self.fc5=nn.Linear(128,128) self.fc6=nn.Linear(128,actionSpaceSize) def forward(self, x): self.relu=nn.ReLU() self.sigmold=nn.Sigmoid() self.LeakyReLU…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15dgonm/what_is_wrong_with_my_codedqn/",
          "publishedOn": "2023-07-30T08:52:41.000Z",
          "wordCount": 2700,
          "title": "What is wrong with my code(DQN)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15dgj4f/google_colab_with_reinforcment_learning/",
          "author": null,
          "description": "I need a google colab with reinforcement learning trained to detect anomalies in computer network traffic.\n    submitted by    /u/Unable_Blacksmith_81  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15dgj4f/google_colab_with_reinforcment_learning/",
          "publishedOn": "2023-07-30T08:42:47.000Z",
          "wordCount": 2488,
          "title": "Google Colab With Reinforcment learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15d6ln0/how_to_calculate_reward_for_target_intercept/",
          "author": null,
          "description": "Hi all. I (believe) I have a tensorflow NN set up to learn how to intercept a target moving in the x-y plane. Right now, the agent can choose to change its velocity by a small amount in any of the 3 directions (for the 3D case later), then the simulation updates the agents position. The state of the sim is the relative distance and velocity vectors between the target and the pursuer. I am confused how to set up a reward function, however. When I first set it up to be a reward of 1/R (R being the distance magnitude between the target and pursuer) to reward for shorter distances and give less reward for further distances as well as a very large reward when a collision occurred, it seemed like the rewards converged to a small value instead of getting larger. Any advice? I'd be willing to upload a github link as well if you wanted to look at the code\n    submitted by    /u/Happylightsocket  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15d6ln0/how_to_calculate_reward_for_target_intercept/",
          "publishedOn": "2023-07-29T23:48:12.000Z",
          "wordCount": 2638,
          "title": "How to calculate reward for target intercept problem?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15d2di4/how_to_disable_auto_environment_reset_in_gymnasium/",
          "author": null,
          "description": "I am trying to implement my own version of ppo using gymnasium. Here is my code for rollout - \n  def rollout(): transitions = [] disc_reward_list = [] for i in range(ppo_batch): obs = torch.tensor(env.reset(), dtype=torch.float32) print(\"obs = \", obs.shape) all_rewards = [] iter = 0 done = False tot_rewards = 0 print(\"done = \", done) while True: act_probs = torch.distributions.Categorical(actor(obs.to(device)).squeeze()) print(\"act_probs = \", act_probs) # print(\"act_probs = \", actor(obs.to(device))) action = act_probs.sample().squeeze() action = action.cpu().detach().numpy() print(\"action shape = \", action.shape) next_state, reward, done, info = env.step(action) print(\"next_state shape = \", next_state.shape) print(\"reward shape = \", reward.shape) print(\"done shape = \", done) action = torch.tensor(action, dtype=torch.float32).to(device) all_rewards.append(reward) tot_rewards += reward iter += 1 transitions.append((obs.cpu().detach().numpy(), action.cpu().detach().numpy(), act_probs.log_prob(action).cpu().detach().numpy())) obs = torch.tensor(next_state, dtype=torch.float32).unsqueeze(0) print(\"Reward = \", tot_rewards) eps_rew = 0 eps_rew_list = [] for reward in reversed(all_rewards): eps_rew = eps_rew*gamma + reward eps_rew_list.append(eps_rew) for rtgs in reversed(eps_rew_list): disc_reward_list.append(rtgs) \n My issue is that in my while loop - The environment autoresets after the `done` variable becomes `True`\n For instance, if I have `8` environments running in parallel `env=gym.vector.make('CartPole-v1', num_envs=8)` and print out the done shape, I might get - `[False False False False False True False False]`. I want that environment where `done=True` to stop and not reset. I believe that's how PPO is supposed to work. \n I am a bit of a beginner with this stuff. Please let me know if something I said is not clear.\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15d2di4/how_to_disable_auto_environment_reset_in_gymnasium/",
          "publishedOn": "2023-07-29T20:42:47.000Z",
          "wordCount": 2708,
          "title": "How to disable auto environment reset in `Gymnasium`",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15d0p33/rt2_visionlanguageaction_models_transfer_web/",
          "author": null,
          "description": "Paper: https://robotics-transformer2.github.io/assets/rt2.pdf \n Blog: https://robotics-transformer2.github.io/ \n Blog: https://www.deepmind.com/blog/rt-2-new-model-translates-vision-and-language-into-action \n Github ( RT-1 as of now) : https://github.com/google-research/robotics_transformer \n Abstract:\n  \nWe study how vision-language models trained on Internet-scale data can be incorporated directly into end-to-end robotic control to boost generalization and enable emergent semantic reasoning. Our goal is to enable a single end-to-end trained model to both learn to map robot observations to actions and enjoy the benefits of large-scale pretraining on language and vision-language data from the web. To this end, we propose to co-fine-tune state-of-the-art vision-language models on both robot…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15d0p33/rt2_visionlanguageaction_models_transfer_web/",
          "publishedOn": "2023-07-29T19:31:08.000Z",
          "wordCount": 2812,
          "title": "RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control - Google DeepMind 2023 - Is able to perform multi-stage semantic reasoning and can interpret commands not present in the robot training data!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15cwesz/resources_to_understand_how_distributed/",
          "author": null,
          "description": "Can someone please point me to resources how distributed actor-critic algorithms work? My final goal is to understand distributed PPO works. I was following thisblog and a few other books but I'm unable to see the big picture nor am I able to understand the little details. \n The big picture - Why does distributed training help in online algorithms like PPO, Actor-Critic\n The code details - I figured out how to make multiprocessing work with gym. But how does one perform learning? Should I combine all the parallel environments and feed them to my neural network? I checked cleanrl but am getting a little confused.\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15cwesz/resources_to_understand_how_distributed/",
          "publishedOn": "2023-07-29T16:26:50.000Z",
          "wordCount": 2580,
          "title": "Resources to understand how distributed Actor-Critic algorithms work?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15crn85/how_can_i_create_multiple_environments_using_sb3/",
          "author": null,
          "description": "​\n ​\n I know that `SB3` provides various techniques to come up with vectorized environments. I want to limit myself to only using the vectorized environments and implement the RL algorithms from scratch. Would that be possible? My final objective is to learn how to play with RL hyperparameters on parallel environments in order to accelerate learning speeds. Currently, I am stuck on -\n import os import gymnasium as gym from stable_baselines3.common.vec_env import DummyVecEnv env = DummyVecEnv([lambda: gym.make(\"CartPole-v1\")]) obs = env.reset() done = False while not done: action = env.action_space.sample() next_obs, reward, done, info = env.step(action) obs = next_obs \n But I get the following error -\n ​\n Traceback (most recent call last): File \"D:\\q_learning\\dummy_envs.py\", line 9, in <module> next_obs, reward, done, info = env.step(action) File \"C:\\Users\\thoma\\anaconda3\\envs\\torch_2\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py\", line 197, in step return self.step_wait() File \"C:\\Users\\thoma\\anaconda3\\envs\\torch_2\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py\", line 59, in step_wait self.actions[env_idx] IndexError: invalid index to scalar variable. \n ​\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15crn85/how_can_i_create_multiple_environments_using_sb3/",
          "publishedOn": "2023-07-29T12:54:47.000Z",
          "wordCount": 2620,
          "title": "How can I create multiple environments using `SB3` for manual use?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15cas37/can_i_turn_off_the_target_network_in_sb3_by/",
          "author": null,
          "description": "I am using DQN through `SB3`. I would like to know if I can turn off the target network by setting `target_update_interval=-1`. I have some sample code over here -\n import gymnasium as gym from stable_baselines3 import DQN env = gym.make(\"MountainCar-v0\") model = DQN(\"MlpPolicy\", env, learning_rate = 4e-3, batch_size = 128, buffer_size = 10000, learning_starts = 1000, gamma = 0.98, train_freq = 16, gradient_steps = 8, exploration_fraction = 0, exploration_final_eps = 0, verbose = 1, target_update_interval=-1) model.learn(total_timesteps=120000, log_interval=4) \n ​\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15cas37/can_i_turn_off_the_target_network_in_sb3_by/",
          "publishedOn": "2023-07-28T22:09:41.000Z",
          "wordCount": 2557,
          "title": "Can I turn off the target network in `SB3` by setting `target_update_interval=-1`?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15c5rel/training_model_using_sb3_on_pettingzoo_mpe/",
          "author": null,
          "description": "Hey,\n So I am training my baseline model using A2C on simple spread environment and no matter how I am changing and testing different parameters, when evaluating the total reward is highly negative.\n Any help on that would be appreciated.\n (I used the following tutorial as reference: https://pettingzoo.farama.org/tutorials/sb3/waterworld/)\n    submitted by    /u/bruhhhwhats  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15c5rel/training_model_using_sb3_on_pettingzoo_mpe/",
          "publishedOn": "2023-07-28T18:50:27.000Z",
          "wordCount": 2520,
          "title": "Training model using SB3 on pettingzoo mpe",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15bsvp4/recreating_results_of_drq_algorithm_please_help/",
          "author": null,
          "description": "For quite some time now I have been looking to recreate the results of the following paper on the Atari-100k benchmark. The paper poses two slightly different algorithms, one for SAC and one for DQN, however my work only focuses on the DQN version.\n IMAGE AUGMENTATION IS ALL YOU NEED: REGULARIZING DEEP REINFORCEMENT LEARNING FROM PIXELS \n https://openreview.net/pdf?id=GY6-6sTvGaf\n Despite this, my results have come up significantly short of the results claimed by the paper, so am looking for anyone to have a look and see anything I may have done wrong. All the code is on the following Github:\n https://github.com/VIPTankz/DeepLearningDrQ/tree/main\n There should also be everything you need to run the code if you wish to do so.\n The authors claim a human-normalised benchmark of 0.270, however my code only achieves 0.108. \n Any help would be much appreciated! \n Also worth noting: for evaluation, the authors use 125k steps, however I'm using the more recent standard of doing 100 episodes, irrespective of length. I highly doubt however that this causes the change in results.\n    submitted by    /u/VIPTankz123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15bsvp4/recreating_results_of_drq_algorithm_please_help/",
          "publishedOn": "2023-07-28T09:48:48.000Z",
          "wordCount": 2645,
          "title": "Recreating results of DrQ algorithm, please help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15brnhd/confused_about_frame_skipping_in_rl/",
          "author": null,
          "description": "How does frame-skipping result in better performance, versus taking an inference every frame for RL algorithms? Wouldn't taking an inference every second speed up training, as you would have more steps to train on in the same amount of time? The only downside I could think to no frame-skip is that steps become closer to each other, but I don't understand if that leads to any bad performance, and if it does, why.\n For context I have an environment where frames are relatively slow to generate (im only getting 1000 frames per minute from each env, and I can only run 6 instances on my pc at the same time). While off policy algorithms like SAC would probably be better suited to the task, I've been having really great success with PPO, and am reluctant to spend more time learning and fine-tuning SAC, as I've heard it can take as long as DDPG to converge. \n    submitted by    /u/IllCommunication6165  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15brnhd/confused_about_frame_skipping_in_rl/",
          "publishedOn": "2023-07-28T08:38:33.000Z",
          "wordCount": 2628,
          "title": "Confused about Frame Skipping in RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15b3h82/undergrad_projectthesis_on_rl/",
          "author": null,
          "description": "Hey everyone, \n I am an undergrad student with some modest knowledge of reinforcement learning techniques. I would like to start working on a project, but I really don't want it to be something obvious like the snake game (which btw I have already done) or something similar. I would like to spend some time on this project, and eventually build my undegrad thesis on top of it. It does not necessarily have to be something with a very practical application, some research would be fine too (keeping in mind that I am undegrad ofc).\n Do you have any ideas that you could share with me? I would be very grateful!\n    submitted by    /u/PizzaPartyBro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15b3h82/undergrad_projectthesis_on_rl/",
          "publishedOn": "2023-07-27T14:32:52.000Z",
          "wordCount": 2581,
          "title": "Undergrad project/thesis on RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15adde0/multiheads_dqn_with_prioritized_buffer_replay/",
          "author": null,
          "description": "Hello everyone,\n I really need your help guys.\n ​\n Is the code (uploaded on https://pastebin.com/LgB3hM47#google_vignette) for 2-heads DQN's training correct .\n Moreover, how can I modify the code below to be suitable for a 2-heads DQN with a prioritized buffer replay such that action is a 2-element list (Please see the image below).\n https://preview.redd.it/tlmyeydjoceb1.png?width=946&format=png&auto=webp&s=7366650421906b735bb7f2fce063322d183aac10\n Thank you in advance.\n    submitted by    /u/GuavaAgreeable208  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15adde0/multiheads_dqn_with_prioritized_buffer_replay/",
          "publishedOn": "2023-07-26T18:17:42.000Z",
          "wordCount": 2529,
          "title": "Multi-heads DQN with prioritized buffer replay",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15a84ra/is_there_a_way_to_control_the_epsilon_decay_in/",
          "author": null,
          "description": "I am looking at the docs for DQN in SB3. I see the following hyper-parameters for controlling exploration - ` exploration_fraction `, ` exploration_initial_eps ` and ` exploration_final_eps `. But I don't think I can control the decaying of epsilon with them. Could someone please help with this issue?\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15a84ra/is_there_a_way_to_control_the_epsilon_decay_in/",
          "publishedOn": "2023-07-26T14:59:10.000Z",
          "wordCount": 2527,
          "title": "Is there a way to control the epsilon decay in Stable-Baselines3?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15a3scs/presenting_simplepydash_realtime_data_plotting/",
          "author": null,
          "description": "Hey all! I'm excited to share SimplePyDash, a new tool I've developed for real-time data visualization. It's a versatile, browser-based dashboard designed to make data plotting as straightforward as possible!\n I thought about posting this here because it started as a project to monitor agents' behaviour in an OpenAI Gym environment. But it can be used for all sorts of things!\n Whether you're monitoring an OpenAI Gym environment, plotting your latest ML model's performance, or just need a flexible way to stream data, SimplePyDash has got you covered. With a clean, column-based layout and a set of intuitive default widgets, you can create your own custom dashboard in no time.\n Installing is as easy as running pip install simple-pydash, and there are several example scripts in the repo to help get you started.\n Check out the GitHub Repository for more details. If you like it, leave a start and feel free to share your feedback or questions. Thanks for checking it out!\n    submitted by    /u/vaaal88  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15a3scs/presenting_simplepydash_realtime_data_plotting/",
          "publishedOn": "2023-07-26T11:56:44.000Z",
          "wordCount": 2636,
          "title": "Presenting SimplePyDash: Real-Time Data Plotting Made Simple!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/159hkzj/the_aipowered_totally_autonomous_future_of_war_is/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/159hkzj/the_aipowered_totally_autonomous_future_of_war_is/",
          "publishedOn": "2023-07-25T19:01:44.000Z",
          "wordCount": 2494,
          "title": "\"The AI-Powered, Totally Autonomous Future of War Is Here\" (use of DRL in Navy swarms R&D)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15985oq/selffictitious_play_and_qlearning_or_evolutionary/",
          "author": null,
          "description": "I'm looking to implement Fictitious Self-Play in a model-based game (imperfect information limited to simultaneous move game, however each player has a combinatorial number of actions they can perform). EDIT: I know self-fictitious play is not the only option to solve this type of game, but I wanted to give it a try to test how it would behave (especially since I sort of like the idea behind it).\n Because of this combinatorial number of actions, solving it with linear programming is just not possible (I'd have to compute for each sequence of pair of actions (a1, b1), (a2, b2), (a3, b3), ... (ak, bk), whether player a or player b won).\n But to compute a best response I might be able to use Q-learning in a RL setting right (by that I mean, fixed environment)? Because when we calculate a best…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15985oq/selffictitious_play_and_qlearning_or_evolutionary/",
          "publishedOn": "2023-07-25T13:11:38.000Z",
          "wordCount": 2918,
          "title": "Self-fictitious play and Q-learning or evolutionary algorithms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1595zfn/rl_continuous_control_help_needed_ml_engineer/",
          "author": null,
          "description": "Hi, I can't find the rules for this subreddit so please lmk if asking any of this breaks them\n I have a pybullet simulation of a bipedal robot wrapped as a gym env. Currently trying to train a Rl ppo algo to control it to walk. But no luck. Having the issue that it's trying everything except walking. And it seems to prioritise getting the instant reward by kicking its leg forward then lunging forward and the episode ends. Instead of walking forward and getting more score. Anyone have any tips please? (Btw gamma = 0.99)\n ​\n Btw if anyone has experience with stuff like this I am looking to hire an engineer. Comment or dm me\n ​\n Btw I am aware this is a significant undertaking\n    submitted by    /u/Harryoc494  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1595zfn/rl_continuous_control_help_needed_ml_engineer/",
          "publishedOn": "2023-07-25T11:37:48.000Z",
          "wordCount": 2601,
          "title": "RL continuous control help needed. ML Engineer wanted also",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15955tq/skrl_version_100rc1_is_now_available_with/",
          "author": null,
          "description": "skrl version 1.0.0-rc.1 is now available.\n The main features of this release are:\n  \nJAX support\n Multi-agent training (the beginning).\n Comprehensive documentation with new structure and theme\n  \nVisit https://skrl.readthedocs.io/en/latest/ to get started!\n ​\n https://preview.redd.it/ms1q5s8ce3eb1.png?width=1459&format=png&auto=webp&s=4b1f0f27cae5df4dfac3e931eabcca2b924968d1\n https://preview.redd.it/385lhqdbe3eb1.png?width=1543&format=png&auto=webp&s=2cb5ef75f4c2720e8db5adbb6b3f35b7977e3b57\n ​\n    submitted by    /u/Toni-SM  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15955tq/skrl_version_100rc1_is_now_available_with/",
          "publishedOn": "2023-07-25T10:59:23.000Z",
          "wordCount": 2509,
          "title": "skrl version 1.0.0-rc.1 is now available with multi-agent and JAX support!!!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1594ibf/zbrain_empowering_businesses_with_custom_chatgpt/",
          "author": null,
          "description": "Dear All,\n It is with great enthusiasm that I introduce you to ZBrain, a revolutionary GenAI platform that unlocks the ability to craft bespoke AI applications while prioritizing data privacy and security. ZBrain ushers in an era of remarkable possibilities for businesses seeking to harness the full potential of AI while ensuring their data remains safeguarded and confidential.\n ​\n What Sets ZBrain Apart:\n  \nZBrain Flow - Codeless Brilliance: Forget complex coding! ZBrain Flow's intuitive drag-and-drop interface seamlessly connects large language models and extraction tools, simplifying the creation of sophisticated business logic without the need for coding expertise.\n \nAI Risk Governance for Data Safety: At ZBrain, we deeply understand the significance of data security. Our AI Risk Governance identifies potential risks such as Financial, Medical, Privacy, Harmful Language, and more. Through prompt engineering, your data is fortified, and sensitive information is shielded.\n \nEffortless Integration and Continuous Advancements: With ZBrain, integration with over 80 data sources is a breeze, providing you the freedom to fine-tune models and deploy them effortlessly. Our reinforcement learning approach continually enriches results through valuable human feedback.\n \nConfidence in Deployment: Choose your deployment approach with assurance. Opt for ZBrain Cloud for added security or self-hosting on your private infrastructure, ensuring data confidentiality remains at the forefront.\n \n ​\n We are genuinely elated about the endless possibilities ZBrain offers businesses spanning various industries. By merging the prowess of AI with an unwavering commitment to data privacy, we wholeheartedly believe that ZBrain will elevate your business to unparalleled heights.\n Visit ZBrain at https://zbrain.ai/ and feel free to reach out with any inquiries or to share your experiences with ZBrain.\n    submitted by    /u/StewartBJasper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1594ibf/zbrain_empowering_businesses_with_custom_chatgpt/",
          "publishedOn": "2023-07-25T10:26:25.000Z",
          "wordCount": 2743,
          "title": "ZBrain: Empowering Businesses with Custom ChatGPT apps and Data Security",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/158dpmz/carracing_v2_enviroment/",
          "author": null,
          "description": "Hi! I am kind of new to Reinforcement Learning and Im trying to implement a PPO in CarRacing enviroment but I am failing to get the model to work. I have managed to get the model working with a DQN but with the PPO I can't seem to get the exploration right as it ends up either going forward all time or in circles. \n I have looked into my code for days, but haven't been able to find an error that would cause this. (Does not say much as I am kind of a newbie to RL). I would be grateful if someone could give me a hand. This is my source code: \n CarRacing Pastebin - Pastebin.com \n ​\n Btw I also tried without greyscaling and it did the same.\n    submitted by    /u/MammothWeekend5954  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/158dpmz/carracing_v2_enviroment/",
          "publishedOn": "2023-07-24T15:22:32.000Z",
          "wordCount": 2598,
          "title": "CarRacing V2 Enviroment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/157oyyq/evaluating_superhuman_models_with_consistency/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/157oyyq/evaluating_superhuman_models_with_consistency/",
          "publishedOn": "2023-07-23T20:14:14.000Z",
          "wordCount": 2488,
          "title": "\"Evaluating Superhuman Models with Consistency Checks\", Fluri et al 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/157bhqk/looking_to_get_into_rl_already_working_in_cv/",
          "author": null,
          "description": "I'm in my final year of undergrad and previously have some experience with image segmentation, object detection,etc. RL is something I feel like I want to get into, but I want to understand how I can get started and what it actually involves. Also, if there's any way I can apply my new knowledge to the domain of 3D vision like SLAM or 3D reconstructed images.\n    submitted by    /u/PRAY_J  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/157bhqk/looking_to_get_into_rl_already_working_in_cv/",
          "publishedOn": "2023-07-23T10:37:08.000Z",
          "wordCount": 2542,
          "title": "Looking to get into RL, already working in CV.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1575arz/2d_drone_rl/",
          "author": null,
          "description": "Long time lurker on the sub and just finished my first semi-decent experiment with DRL so I thought I’d share it here. \n I’ve been wanting to experiment with RL and drones for a while now, ever since seeing John Buffers Autodrone project where they train a drone using the genetic algorithm. \n Finally got a basic implementation working using SAC a few days ago, and have made the environment open source as well in case others wanted to try it out.\n Project Link: https://github.com/Yyassin/senza\n    submitted by    /u/vanishedoblivion  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1575arz/2d_drone_rl/",
          "publishedOn": "2023-07-23T04:51:23.000Z",
          "wordCount": 2553,
          "title": "2D Drone RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/156us2b/using_stable_baseline3_for_multi_agent_env/",
          "author": null,
          "description": "Hey,\n I am trying to use sb3 with a pettingzoo mpe environment and trying to implement parameter sharing for simple spread. Any help on how I would train a model for this multi agent environment would be appreciated, thanks.\n    submitted by    /u/bruhhhwhats  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/156us2b/using_stable_baseline3_for_multi_agent_env/",
          "publishedOn": "2023-07-22T20:45:02.000Z",
          "wordCount": 2513,
          "title": "Using stable baseline3 for multi agent env",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/156czml/the_offline_algorithm_or_how_to_get_40000_avg_in/",
          "author": null,
          "description": "I've been doing this \"fine tuning\" project for 2 years now from 2021.\n https://preview.redd.it/qviy5lpxegdb1.png?width=568&format=png&auto=webp&s=8728814e39176d9024fac16e191937aeb5a302c1\n https://github.com/timgep/Lords_Policy_Gradient/tree/main\n This is Offline Reinforcement Learning Algorithm (based on Twin Delayed DDPG (Temporal Difference), Fading Memories (Fading Replay Buffer), Spiking Activation Function (alternative for Relu and Norm), and Rectified Hubber Error (alternative to MSE and MAE), the last 3 was invented/implemented during experiments.\n For long time I was reluctant to use TD3, as it seemed that using second critic when you already have 2 Actors and 2 Critics in DDPG was not normal. As result you would have 6 Networks. So I was making my own DDPG with dicreased (smaller)…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/156czml/the_offline_algorithm_or_how_to_get_40000_avg_in/",
          "publishedOn": "2023-07-22T07:07:46.000Z",
          "wordCount": 4084,
          "title": "The Offline Algorithm (or how to get >40,000 avg. in Humanoid-v2 in 10000 ep and highest scores (Wordly) in other envs without multiprocessing)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/155wa6w/towards_a_unified_agent_with_foundation_models/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2307.09668\n Abstract:\n  \nLanguage Models and Vision Language Models have recently demonstrated unprecedented capabilities in terms of understanding human intentions, reasoning, scene understanding, and planning-like behaviour, in text form, among many others. In this work, we investigate how to embed and leverage such abilities in Reinforcement Learning (RL) agents. We design a framework that uses language as the core reasoning tool, exploring how this enables an agent to tackle a series of fundamental RL challenges, such as efficient exploration, reusing experience data, scheduling skills, and learning from observations, which traditionally require separate, vertically designed algorithms. We test our method on a sparse-reward simulated robotic manipulation environment, where a robot needs to stack a set of objects. We demonstrate substantial performance improvements over baselines in exploration efficiency and ability to reuse data from offline datasets, and illustrate how to reuse learned skills to solve novel tasks or imitate videos of human experts. \n  \nhttps://preview.redd.it/k40ho0ci4ddb1.jpg?width=1101&format=pjpg&auto=webp&s=4d7bd78e43fdc5a9084917affab2c83dc06b1045\n https://preview.redd.it/78egck8n4ddb1.jpg?width=617&format=pjpg&auto=webp&s=d786ef8e9841fcfefc7bfe726c324e486b78dfb3\n https://preview.redd.it/693yu3ci4ddb1.jpg?width=1353&format=pjpg&auto=webp&s=321b710a4c4482436e474a5076bcac3672f3077c\n https://preview.redd.it/slunq0ci4ddb1.jpg?width=1661&format=pjpg&auto=webp&s=94e3f4a5c5d72f8b93ad3daec4cc2ba43f39e171\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/155wa6w/towards_a_unified_agent_with_foundation_models/",
          "publishedOn": "2023-07-21T18:39:01.000Z",
          "wordCount": 2640,
          "title": "Towards A Unified Agent with Foundation Models - Google DeepMind, ICLR23, July 2023 - LLM + RL leads to substantial performance improvements!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/155ta8t/i_stuck_on_the_same_issue_for_2_weeks_please_need/",
          "author": null,
          "description": "I have a missile and its environment. Missile creates an acceleration to change its moving direction angle. I just wanted to make the missile fly with the desired radial angle using PPO. It flies for 15 seconds.\n States: [Radial Angle, Time] -> Both normalized between [0,1]\n Action: Acceleration\n Reward: - abs(Radial Angle - 0.07) -> Want to stay at 0.07 radial angle\n PPO agent just gets worse and worse. It gets reward every time worse than before. How can this be possible? I am just about to lose my mind. I really need your valuable opinions.\n Thank you!\n 1\n 2\n NEW EDIT - Constant Acceleration = 20 in the below graphs. Normally Acceleration takes values between [-45, 45].\n This is my trajectory - Green is the missile. Y axis is the height and X axis is the lateral distance. If Acceleration is Positive, missile starts to change itself to the upside, if negative then moves sharply to the downside.\n This is my Radial angle change. When the acceleration is positive, it starts to decrease\n First is constant Acc = 20. Second is system response. Third is angle in degrees multiplied by - sign\n    submitted by    /u/OpenToAdvices96  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/155ta8t/i_stuck_on_the_same_issue_for_2_weeks_please_need/",
          "publishedOn": "2023-07-21T16:44:49.000Z",
          "wordCount": 2674,
          "title": "I Stuck On The Same Issue For 2 Weeks, Please Need Some Advices ...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/155ra3e/a_visionbased_ai_runs_on_an_official_track_in/",
          "author": null,
          "description": "submitted by    /u/yannbouteiller  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/155ra3e/a_visionbased_ai_runs_on_an_official_track_in/",
          "publishedOn": "2023-07-21T15:30:30.000Z",
          "wordCount": 2475,
          "title": "A vision-based A.I. runs on an official track in TrackMania",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/155jtvu/need_help/",
          "author": null,
          "description": "I am currently developing a Reinforcement Learning network for my game (base ball type), and I have chosen to do it via a PPO agent and the model is based on the tutorial on the Keras cite. \n My system is a little bit different, where I run the game for several serves(18 to be exact) and chose to update the model after those 18 serves. Model is created only once, so in that way I can train it when ever I want for an exact amount of serves I need.\n The input is (1,27) shape and actor have a 64 node layer and a 9 node output layer (output is a length of 9 array where I used those logits to get a one single integer value of [0,8].\n I have faced two problems. 1. Most of the time after I initiated a model, it only gives only one output for different inputs for the first 18 serves. I guess I can change that with a gaussian noice to the output but shouldn't it try give a different output, I mean there are 9 different options. Also even though I initialize the model several times it favor to give the same output most of the times. I tried using a kernal initializers for that, but most of the time same output.\n 2.This is the main thing I need the help with. Even though the calculations gives out a policy loss, the policy gradiant values I get are all zero or very small (e-16 sort of).\n Any one have any idea or clues?\n    submitted by    /u/Mika_NooD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/155jtvu/need_help/",
          "publishedOn": "2023-07-21T10:15:36.000Z",
          "wordCount": 2730,
          "title": "Need Help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/155hxza/what_is_the_proper_way_to_anneal_the_learning/",
          "author": null,
          "description": "I'm unsure how to apply LR annealing on top of Adam's per-parameter adjustments.\n Here's my current approach, but I'm concerned that it overrides Adam's own adaptive learning rate adjustment. In words:\n  \nAt the end of every epoch (fixed number of steps), I compute a LR decay factor. It's a step-wise decay factor, e.g. 1.0 for the first 10% of steps, then 0.5 for the next 10%, and so forth until 1/256 for the last 5% of training.\n If that decay factor has changed from the previous epoch, I set param_group[\"lr\"] to a new max_lr * lr_decay_factor for every group of parameters in the optimiser.\n  \nIn code:\n lr_decay_factor = get_fancy_decay_factor(...) # Update learning rate only when decay factor changes if lr_decay_factor != prev_lr_decay_factor: for param_group in optimiser.param_groups: param_group[\"lr\"] = max_lr * lr_decay_factor prev_lr_decay_factor = lr_decay_factor \n Is this the proper way of annealing the learning rate on top of Adam? Am I inadvertently undoing Adam's own adapting?\n Thanks!\n    submitted by    /u/desperateEfforts1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/155hxza/what_is_the_proper_way_to_anneal_the_learning/",
          "publishedOn": "2023-07-21T08:33:55.000Z",
          "wordCount": 2638,
          "title": "What is the proper way to anneal the learning rate with (on top of) Adam",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1559mem/pretraining_task_diversity_and_the_emergence_of/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1559mem/pretraining_task_diversity_and_the_emergence_of/",
          "publishedOn": "2023-07-21T01:28:48.000Z",
          "wordCount": 2518,
          "title": "\"Pretraining task diversity and the emergence of non-Bayesian in-context learning for regression\", Raventós et al 2023 (blessings of scale induce emergence of meta-learning)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15572jo/how_to_simulate_delays/",
          "author": null,
          "description": "Hi,\n my ultimate goal is to let an agent learn how to control a robot in the simulation and then deploy the trained agent to the real world. \n The problem occurs for instance due to the communication/sensor delay in the real world (50ms <-> 200ms). Is there a way to integrate this varying delay into the training? I am aware that adding some random values to the observation is a common thing to simulate the sensor noise, but how do I deal with these delays?\n    submitted by    /u/Fun-Moose-3841  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15572jo/how_to_simulate_delays/",
          "publishedOn": "2023-07-20T23:35:47.000Z",
          "wordCount": 2556,
          "title": "How to simulate delays?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1555wgi/dqn_loss_increasing_and_rewards_decreasing/",
          "author": null,
          "description": "Im attempting to train a custom DQN agent to perform in a custom environment. The observation space is an image with dimensions (1, 100, 57) and the agent has to output over 81 discrete actions (all the combinations over a 3 * 3 * 3 * 3 multi-discrete action space corresponding to key presses, or lack of key presses). However, while training, my agents rewards seems to regress linearly corresponding to the eplison decay rate. Alongside that, the loss tends to shoot up pretty quickly most of the time, across different target network update rates. \n After a lot of debugging, I still havent managed to figure out whats causing this issue. Has anyone else had this problem before? If so, how did you solve it?\n My environment has no done condition, so im resetting it every 2500 steps. My other Hy…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1555wgi/dqn_loss_increasing_and_rewards_decreasing/",
          "publishedOn": "2023-07-20T22:48:35.000Z",
          "wordCount": 3067,
          "title": "DQN Loss Increasing, and Rewards decreasing linearly with eplison",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1553gy6/even_superhuman_go_ais_have_surprising_failures/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1553gy6/even_superhuman_go_ais_have_surprising_failures/",
          "publishedOn": "2023-07-20T21:13:23.000Z",
          "wordCount": 2488,
          "title": "\"Even Superhuman Go AIs Have Surprising Failures Modes\" (updated discussion of \"Adversarial Policies Beat Superhuman Go AIs\", Wang et al 2022)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1550a6d/my_dql_snake_game_convergence_questions_im/",
          "author": null,
          "description": "Hey guys,\n I'll preface by saying that this is my first real programming project outside of a lot of simple beginner ones and that I'm building this after completing Andrew Ng's ML specialization. Basically, I'm a beginner and I might act like it.\n So my model's loss learning to play Snake won't converge and I don't know if it's because of any misunderstandings for the theory, bad implementation, or something else. I'm using Experience Replay, epsilon-greedy actions, and a Target Q-network with soft updates. My NN consists of 4 hidden dense layers with 100 units each. I was originally updating the Q network every 4 experiences but I upped that to 1000.\n My reward functions are -1000 for running into walls/tail and 20 for eating food. The state vector includes distance to each 4 wall, dista…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1550a6d/my_dql_snake_game_convergence_questions_im/",
          "publishedOn": "2023-07-20T19:14:38.000Z",
          "wordCount": 2834,
          "title": "My DQL Snake Game convergence questions (I'm struggling)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/154t0u3/android_in_the_wild_a_largescale_dataset_for/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/154t0u3/android_in_the_wild_a_largescale_dataset_for/",
          "publishedOn": "2023-07-20T14:49:22.000Z",
          "wordCount": 2501,
          "title": "\"Android in the Wild: A Large-Scale Dataset for Android Device Control\", Rawles et al 2023 {G} (imitation-learning + PaLM-2 inner-monologue for smartphone control)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/154s2fl/question_why_there_is_so_few_algorithms/",
          "author": null,
          "description": "I am wondering why there is so few algorithms in Stable Baselines 3 (SB3, https://github.com/DLR-RM/stable-baselines3/tree/master)?\n I was expecting some algorithms like ICM, HIRO, DIAYN, ... Why there is no model-based, skill-chaining, hierarchical-RL, ... algorithms implemented there? \n    submitted by    /u/hbonnavaud  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/154s2fl/question_why_there_is_so_few_algorithms/",
          "publishedOn": "2023-07-20T14:12:48.000Z",
          "wordCount": 2512,
          "title": "[Question] Why there is so few algorithms implemented in SB3?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/154qr8p/learning_from_human_preferences/",
          "author": null,
          "description": "Hi everyone! Does anyone know of any tutorials/GitHub code that are up to date with learning from human preferences? Kind of like an updated rl-teacher? \n Thank you all very much!!\n    submitted by    /u/No_Opportunity575  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/154qr8p/learning_from_human_preferences/",
          "publishedOn": "2023-07-20T13:19:52.000Z",
          "wordCount": 2501,
          "title": "Learning from human preferences",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/154ofvl/comparing_a2c_and_qlearning_algorithms/",
          "author": null,
          "description": "I'm following the UCB course on Reinforcement Learning, I'm just finished with the ActorCritic and QLearning lectures, but I'm still not sure on the pros and cons of both when compared with each other, Here's what I know thus far (Haven't yet started with advanced policy gradients which I assume covers PPO):\n - Vanilla Policy Gradients are high variance, but very low (0) bias.\n - Actor Critic decrease the variance by estimating a value function, but this introduces some bias. They also add more complexity, having to train both the actor and critic parts of the algorithm. (Also enables us to do online learning, while Vanilla Policy Gradients are episodic)\n - Q-Learning algorithms are similar to actor critic, but instead of doing gradient ascent on the policy, our (implicit) policy is the argmax of our Q value. And since we don't have a policy in stone, it is fundamentally off-policy.\n But we still can use off-policy Actor Critic algorithms, it is not like Q-Learning can do off-policy while Actor-Critic could not...\n So, what exactly do we gain when we drop the policy part of the Actor Critic algorithm? Here's my assumptions which I'm not sure of:\n (1) Decrease variance while inc. bias (I.e. more efficient but less guaranteed to converge)(2) Less Exploration because our implicit policy is deterministically argmax (but we still can use epsilon-greedy to explore)\n Edit: To be clear, the default Actor Critic algorithm is on-policy, but it is possible to do modifications on it to make it off-policy and use replay buffer, just like DQN.\n    submitted by    /u/nmegoCAD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/154ofvl/comparing_a2c_and_qlearning_algorithms/",
          "publishedOn": "2023-07-20T11:34:53.000Z",
          "wordCount": 2730,
          "title": "Comparing A2C and Q-learning algorithms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/154o8kl/question_about_the_action_space_in_ppo_for/",
          "author": null,
          "description": "If I have a 5 DoF robot and I aim to instruct it on reaching a goal, utilizing 5 actions to control each joint. The goal is to make the allowed speed change of the joints variable so that the agent forces the robot moves slowly when the error gets larger and allow full speed when the error is small.\n For this I want to extend the action space from 6 ( 5 control signals for the joints and 1 value determining the allowed speed change for all joints).\n I will be using PPO. Is this kind of setup of action space common/resasonable..? \n    submitted by    /u/Fun-Moose-3841  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/154o8kl/question_about_the_action_space_in_ppo_for/",
          "publishedOn": "2023-07-20T11:24:53.000Z",
          "wordCount": 2581,
          "title": "Question about the action space in PPO for controlling the robot",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/154heq5/open_challenges_in_mdrl/",
          "author": null,
          "description": "Hello,\n What are some open challenges in Multi-Agent Deep Reinforcement Learning (MDRL or DRL) these days? Is it only me or it seems that DRL is slowly dying :/\n ​\n ​\n    submitted by    /u/AhmedNizam_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/154heq5/open_challenges_in_mdrl/",
          "publishedOn": "2023-07-20T05:00:07.000Z",
          "wordCount": 2500,
          "title": "Open challenges in MDRL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1548owt/beginner_rl_project_advice/",
          "author": null,
          "description": "Hi,\n I'm somewhat new to reinforcement learning and have been trying to acquaint myself using gymnasium/stable baselines. I currently have a custom environment and I'm using PPO on it, but I don't actually know how to assess what the best algorithm would be for the problem, nor can I tell if training is really doing exactly what I want to. I'm going to include the link to the repo and if anybody has any advice I'd love it. I may be doing things that are very obviously silly that I'm just unaware of, so any advice would be great. Throwaway bc I use my real name on github lmao\n https://github.com/MarcusWheeler/dcss_inventory \n    submitted by    /u/Charming-Art-732  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1548owt/beginner_rl_project_advice/",
          "publishedOn": "2023-07-19T22:13:59.000Z",
          "wordCount": 2554,
          "title": "Beginner RL Project Advice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1542xa5/minari_040_is_live_gym_for_offline_rl_by_the/",
          "author": null,
          "description": "Minari now has full support for Dict, Tuple, Discrete, Box, and Text spaces without flattening, explicit dataset versioning, plus subsets of action/obs spaces in datasets. Additionally, new v1 versions of each dataset were released to comply with the new dataset format. The new datasets do not have observation and action flattening (relevant for pointmaze datasets), introduce serialized representations of action and observation spaces in the observation_space and action_space fields, and specify minari version compatibility with the minari_version field. Python 3.11 compatibility was added, with removal of 3.7 support as it has reached end-of-life. We also include two new tutorials: observation space subsetting, and behavior cloning with rl_zoo3 and pytorch DataLoader. \n Announcement Tweet: https://twitter.com/FaramaFound/status/1681730025513467931\n Release Notes: https://github.com/Farama-Foundation/Minari/releases/tag/v0.4.0\n    submitted by    /u/elliottower  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1542xa5/minari_040_is_live_gym_for_offline_rl_by_the/",
          "publishedOn": "2023-07-19T18:30:24.000Z",
          "wordCount": 2570,
          "title": "Minari 0.4.0 is live! (Gym for offline RL, by the Farama Foundation)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1542gqz/struggling_with_value_function_approximation/",
          "author": null,
          "description": "Hi everyone. I’ve been studying RL for a few months now and am trying to implement it in a school project. My project is similar to the car-valley problem where an agent needs to reach some point, except the point is moving and in 3D. As such, the state space is continuous but my action space I’ve defined to be 6. I’ve done table lookup Q learning in the past, but not in a continuous value function approximation. \n My method is as follows: 1. at the start of the episode, initialize the weights randomly and calculate the action value pair for each of the 6 actions. Choose an action using epsilon greedy policy 2. For each time step, execute the chosen action and observe the new state and reward (my reward being distance from goal). Store the 6 features of the initial state 3. Calculate the new Q values from this new state based on the new state and the weights w. 4. Choose a new action based on these Q values and epsilon greedy policy 5. Using the new action, update the weights w using the Q value at the new action minus the Q value at the old action times the features 6. Set the old state and action to the new state and action and repeat until terminal\n My problem is that the w weights blow up to inf very very quickly, within 10 time steps. Does anyone have any advice such as resources with pseudo code to look at or notice any problems in my method? I think my problem is coming from evaluating the Q for the old and new states but I’m not sure. Thank you.\n    submitted by    /u/LevisLover  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1542gqz/struggling_with_value_function_approximation/",
          "publishedOn": "2023-07-19T18:12:34.000Z",
          "wordCount": 2723,
          "title": "Struggling with value function approximation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/153uay3/what_does_finite_or_infinite_horizon_means_in/",
          "author": null,
          "description": "submitted by    /u/aabra__ka__daabra  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/153uay3/what_does_finite_or_infinite_horizon_means_in/",
          "publishedOn": "2023-07-19T12:56:34.000Z",
          "wordCount": 2460,
          "title": "What does finite or infinite horizon means in Reinforcement Learning terms ? What does finite horizon undiscounted return means ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/153jt7w/help_in_ppo_implementation/",
          "author": null,
          "description": "In the blog post: https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/ and the related implemntation: https://github.com/vwxyzjn/ppo-implementation-details/blob/main/ppo.py, why aren;t we ending the rollout collection when the episode has terminated or when the num_steps is reached? What if the episode is terminated before reaching the num_steps? Wont the training part give an error?\n    submitted by    /u/Interesting-Weeb-699  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/153jt7w/help_in_ppo_implementation/",
          "publishedOn": "2023-07-19T03:50:04.000Z",
          "wordCount": 2491,
          "title": "Help in PPO implementation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/153i9ft/how_do_i_find_papers_related_to_a_specific/",
          "author": null,
          "description": "My cousin and I are starting to work on a project he can do in high school and while doing preliminary research on a related application, I was unable to find anything about this related application. I was thinking we might be able to publish a paper if the application has not already been done.\n    submitted by    /u/newjeison  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/153i9ft/how_do_i_find_papers_related_to_a_specific/",
          "publishedOn": "2023-07-19T02:35:41.000Z",
          "wordCount": 2509,
          "title": "How do I find papers related to a specific application of RL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/153hudq/gymnasium_v0290_has_been_released/",
          "author": null,
          "description": "Gymnasium v0.29.0 is out! This release includes 6 months' worth of bug fixes and new features. In particular, it deprecates several features: Wrapper.__get_attr__, gymnasium.make(..., autoreset=True), gymnasium.make(..., apply_api_compatibility=True), Env.reward_range and gymnasium.vector.make that will be removed in v1.0.\n Additionally, as python 3.7 has reached its end of life support, we have dropped support for it and updated MuJoCo Hopper & Walker2D models to work with MuJoCo >= 2.3.3.\n This release also includes an official way to cite Gymnasium. While a full paper is still some time away, you can now use the DOI 10.5281/zenodo.8127025 for citations: https://zenodo.org/record/8127025\n Announcement Tweet: https://twitter.com/FaramaFound/status/1681479718774743040\n Release Notes: https://github.com/Farama-Foundation/Gymnasium/releases/tag/v0.29.0\n    submitted by    /u/elliottower  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/153hudq/gymnasium_v0290_has_been_released/",
          "publishedOn": "2023-07-19T02:16:15.000Z",
          "wordCount": 2548,
          "title": "Gymnasium v0.29.0 has been released!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/153becs/what_phenomena_are_hyperparameters_supposed_to/",
          "author": null,
          "description": "Suppose you have an IMU and therefore no way to track velocity (reliably). In simulation you can train with velocity in any way you like. In this case, what is velocity in this context. Can it be used in the reward function as a form of privileged info or is it a hyperparameter (and needs an outer loop for optimization)?\n This is just an example of a problem for sim-2-real but that question applies generally for hyperparameters in terms of the objective.\n    submitted by    /u/FriendlyStandard5985  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/153becs/what_phenomena_are_hyperparameters_supposed_to/",
          "publishedOn": "2023-07-18T21:45:01.000Z",
          "wordCount": 2513,
          "title": "What phenomena are hyperparameters supposed to capture?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1539sz9/intro_to_vanilla_policy_gradient/",
          "author": null,
          "description": "I've written a series of blog posts going into the theory behind the policy gradient algorithm. Anyone who's starting out in RL may find them to be a good introduction! If you want to understand PPO and various actor critic algorithms, this is the place to start.\n https://kjabon.github.io/blog/2023/VPG/\n ​\n Let me know if you spot any issues or have any questions. (You can also comment on the post itself, I'll see it).\n    submitted by    /u/kjabon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1539sz9/intro_to_vanilla_policy_gradient/",
          "publishedOn": "2023-07-18T20:43:28.000Z",
          "wordCount": 2501,
          "title": "Intro to Vanilla Policy Gradient",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15397bj/rl_applications/",
          "author": null,
          "description": "So I am aware of applications of RL in games and robotics, as well as applications of contextual bandits for recommender systems. But as I look for possible future research paths in RL, I was wondering if there were any other interesting applications of the field. For instance, I recently learned about RL in procedural content generation. I’m particularly interested in more accessible/less resource heavy ones, though I would be glad to learn about all of them. Any insight and resources on this topic will be greatly appreciated. \n    submitted by    /u/Ok_Signature_4944  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15397bj/rl_applications/",
          "publishedOn": "2023-07-18T20:20:06.000Z",
          "wordCount": 2515,
          "title": "RL applications",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1532r5y/gkd_generalized_knowledge_distillation_for/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1532r5y/gkd_generalized_knowledge_distillation_for/",
          "publishedOn": "2023-07-18T16:14:01.000Z",
          "wordCount": 2448,
          "title": "\"GKD: Generalized Knowledge Distillation for Auto-regressive Sequence Models\", Agarwal et al 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1530crj/question_about_montezumas_revenge_gym_atari/",
          "author": null,
          "description": "Hi all,\n ​\n I'm running some code (this code, in case anyone's curious) training an agent to learn in Montezuma'sRevengev4NoFrameskip environment, and it seems to be working, but the nonzero rewards seemingly being returned by the environment are always 1, rather than the \"100\" or \"1000\" points that are supposedly returned by the game. I'd like to change this so I can compare to SOTA benchmarks, which seem to use the actual game score, but also because I want to make sure this isn't a bug or anything. \n As far as I can tell, the reward of \"1\" is coming from the environment itself, and not from the code I linked converting any nonzero reward to a 1, but I can't find anything stating that in the documentation I can find, and might be missing something.\n Does anyone else have more experience with this environment that could tell me what's causing this/is it normal?\n    submitted by    /u/LessPoliticalAccount  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1530crj/question_about_montezumas_revenge_gym_atari/",
          "publishedOn": "2023-07-18T14:42:08.000Z",
          "wordCount": 2585,
          "title": "Question about Montezuma's Revenge gym Atari environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/152or9f/looking_for_assembly_game_environments/",
          "author": null,
          "description": "Hello, I am really impressed by the real-life applications of Alphadev. I would like to experiment with an assembly game myself, but to the my best knowledge, it appears that there is no representative environment available. Is there an assembly game environment that you would recommend for reinforcement learning experiments?\n    submitted by    /u/Spiritual_Fig3632  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/152or9f/looking_for_assembly_game_environments/",
          "publishedOn": "2023-07-18T04:58:04.000Z",
          "wordCount": 2480,
          "title": "Looking for assembly game environments",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/152or9a/looking_for_assembly_game_environments/",
          "author": null,
          "description": "Hello, I am really impressed by the real-life applications of Alphadev. I would like to experiment with an assembly game myself, but to the my best knowledge, it appears that there is no representative environment available. Is there an assembly game environment that you would recommend for reinforcement learning experiments?\n    submitted by    /u/Spiritual_Fig3632  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/152or9a/looking_for_assembly_game_environments/",
          "publishedOn": "2023-07-18T04:58:03.000Z",
          "wordCount": 2480,
          "title": "Looking for assembly game environments",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/152nn5b/for_openai_humanoidv4_is_20000_score_average_of/",
          "author": null,
          "description": "Do I need to register it somewhere? If people got more than that, ok\n no multi-agents\n log:\n https://preview.redd.it/jf91dab7encb1.png?width=720&format=png&auto=webp&s=89d737fc1f30a6f9ef96575e18e0b8993ba683fd\n    submitted by    /u/Timur_1988  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/152nn5b/for_openai_humanoidv4_is_20000_score_average_of/",
          "publishedOn": "2023-07-18T04:01:32.000Z",
          "wordCount": 2461,
          "title": "For OpenAI Humanoid-v4: is 20000 score (average of last 250 episodes) within 3800 episodes good score for offline RL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/152ndvf/help/",
          "author": null,
          "description": "Hi, I was implementing actor critic algorithm and while running it on cartpole environment, I noticed that if i repeat the same experiment, I would get the exact same results(overlapping plots of actor/critic loss, average return etc). Is it possible as the initialisation should be different for each run? Maybe because the environment is not stochastic?\n    submitted by    /u/Interesting-Weeb-699  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/152ndvf/help/",
          "publishedOn": "2023-07-18T03:49:03.000Z",
          "wordCount": 2482,
          "title": "Help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/152lnl0/alpagasus_training_a_better_alpaca_with_fewer/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/152lnl0/alpagasus_training_a_better_alpaca_with_fewer/",
          "publishedOn": "2023-07-18T02:27:00.000Z",
          "wordCount": 2449,
          "title": "\"AlpaGasus: Training A Better Alpaca with Fewer Data\", Chen et al 2023 {Samsung}",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/152kxfy/multi_agent_reinforcement_learning_help_wanted/",
          "author": null,
          "description": "Hi guys, thank you in advance to who's going to answer.\n I'm researching MARL and drones swarms for my master thesis. Drones should navigate in a map, avoiding obstacles and finding a target, just using an RGB camera. If a drone collides/reaches objective, must stop but the episode will conclude when all of them finish.\n I had successfully implemented a single drone env using Microsoft's AirSim, which converges in less than 100k steps using SB3's PPO. Anyway, I need to do the same for a multiagent env. I tried a multitude of frameworks, RLlib (which didn't work well), MARLlib (got a successful implementation, but didn't like it and didn't have much results) and now I'm using SB3+PettingZoo ParallelEnv+SuperSuit. I can easily train the env, but after 1 million steps I still do not get any improvement (see attached pic): some problems are that evaluation episodes sometimes end before all the drones collide/reach objective; I had to modify SuperSuit package because didn't really support well black death on Markov wrapper (when drone is not active, his camera observation is all 0s and actions are not given); evaluation seems to behave differently than training (actions seem \"smoothed\", almost 0, in particular at the first evaluations episodes); drones seem to behave better (reach easily objective) if all the others collided.\n If any of you are interested, I can attach some code. I had to heavily modify the overrid step function of the Parallel env to support training on active agents only (possible_agents variable). I was inspired by this stack overflow: https://stackoverflow.com/questions/73111772/problem-with-pettingzoo-and-stable-baselines3-with-a-parallelenv\n If you have any advice, any different framework to try (I should try Tianshou's), please tell me. Any help is greatly appreciated. Thank you all.\n    submitted by    /u/IntelligentAd6407  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/152kxfy/multi_agent_reinforcement_learning_help_wanted/",
          "publishedOn": "2023-07-18T01:54:22.000Z",
          "wordCount": 2726,
          "title": "Multi agent reinforcement learning - help wanted",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/151z8od/how_to_creat_ppo_agent_from_0/",
          "author": null,
          "description": "Hello ladies and gentlemen, I would love to ask you any guidance towards PPO agent creation. Any courses, GitHubs, anything works for me if it helps me to understand it and creat it. Thank you. Have a nice day\n    submitted by    /u/EveryonehatesLin3lis  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/151z8od/how_to_creat_ppo_agent_from_0/",
          "publishedOn": "2023-07-17T11:26:12.000Z",
          "wordCount": 2470,
          "title": "How to creat PPO agent from 0",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/151y36h/rllib_multiagent_actions_received_from_trained/",
          "author": null,
          "description": "I trained a MARL agent using PPO in RLlib where each agent had a Box([-1,-1,0], [1,1,1], (3,), float64) action space, with 6 agents. The agent during training was sampling and selecting actions within the action space bounds for each agent. But after training for about 7 milllion iterations, and during playback, selecting actions based on the observation using compute_single_action() and compute_actions() returns actions for the agents which are grossly outside the action space bounds of -1 to 1. I receive actions like [-6,-7,2] etc for the agents, which does not fare well to how the actions translate to the agent behaving in the environment. \n I have tried training with additional post_fcnet_activation (tanh) but that did not help either. Using clip_actions=True in compute_actions() does not solve the issue either. The selected actions seem to be exceeding the bounds by larger margins the more complex the environment gets. For example, with 2 drones and a simpler environment the trained agent returns actions around [-1.5,-1.1,0.4] while for 6 agents I get actions like [-6,-7,2]. I have used RLlib before with Discrete action spaces and this does not occur. Is it a problem with the Box space? I use a custom model with different Fully Connected models for the action and value functions. \n Has anybody encountered this problem before and discovered a possible solution? \n    submitted by    /u/Acceptable_Set_4392  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/151y36h/rllib_multiagent_actions_received_from_trained/",
          "publishedOn": "2023-07-17T10:27:26.000Z",
          "wordCount": 2660,
          "title": "RLlib multi-agent actions received from trained agent using compute_actions() and compute_single_action() out of action space bounds",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/151tzyf/muzero_implementations_for_atari/",
          "author": null,
          "description": "I was wondering if there are any actually working MuZero implementations for Atari games out there?\n None of the ones I found are working (at all) on Atari games. This includes:\n  \nThe most popular repo https://github.com/werner-duvaud/muzero-general\n It works on other games but not Atari. There are many GitHub issues where people are complaining about this.\n This one which is less popular https://github.com/koulanurag/muzero-pytorch, which apparently doesn't include Atari games.\n  \nAlternatively, do you know other MuZero-like algorithms which are implemented and working on Atari?\n ​\n    submitted by    /u/__horned_owl__  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/151tzyf/muzero_implementations_for_atari/",
          "publishedOn": "2023-07-17T06:38:45.000Z",
          "wordCount": 2509,
          "title": "MuZero implementations for Atari?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/151meds/all_you_need_is_supervised_learning_from/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/151meds/all_you_need_is_supervised_learning_from/",
          "publishedOn": "2023-07-17T00:22:32.000Z",
          "wordCount": 2444,
          "title": "\"All You Need Is Supervised Learning: From Imitation Learning to Meta-RL With Upside Down RL\", Arulkumaran et al 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/150rabh/p_ppo_agent_completing_street_fighter_iii_on_our/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/150rabh/p_ppo_agent_completing_street_fighter_iii_on_our/",
          "publishedOn": "2023-07-16T00:05:59.000Z",
          "wordCount": 2477,
          "title": "[P] PPO agent completing Street Fighter III on our RL Platform, it consistently outperformed when using deterministic actions instead of sampling them proportionally to their probability, see comment for details.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/150q6ao/pickapic_an_open_dataset_of_user_preferences_for/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/150q6ao/pickapic_an_open_dataset_of_user_preferences_for/",
          "publishedOn": "2023-07-15T23:16:36.000Z",
          "wordCount": 2439,
          "title": "\"Pick-a-Pic: An Open Dataset of User Preferences for Text-to-Image Generation\", Kirstain et al 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/150ou88/using_temperature_to_analyze_the_neural_basis_of/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/150ou88/using_temperature_to_analyze_the_neural_basis_of/",
          "publishedOn": "2023-07-15T22:20:18.000Z",
          "wordCount": 2463,
          "title": "\"Using temperature to analyze the neural basis of a time-based decision\", Monteiro et al 2023 (brain temperature influences drift-accumulation speed to make a decision)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/150l5ua/handling_sparse_rewards/",
          "author": null,
          "description": "Hey everyone, today I thought about how an AI would work with a game like a shooter, where you only know after some time if the shot has hit an enemy for example. Like how do you handle the reward in this case? Do you save all the states and actions inside a buffer and train the model with some reward after you are sure the bullet didn't hit or did hit? I can't think of any other method on how to handle such cases right now\n    submitted by    /u/JhinTonic123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/150l5ua/handling_sparse_rewards/",
          "publishedOn": "2023-07-15T19:47:39.000Z",
          "wordCount": 2504,
          "title": "Handling sparse rewards",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/150hxnx/chess_or_alternative_games_to_develop_rl_project/",
          "author": null,
          "description": "New to RL though have used ML techniques before for stats based modeling. I want to train an RL model to learn to play a game. I initially was thinking chess, but I'm limited by a CPU. Is this too much to expect from a CPU? Can I leverage multiprocessing to maximize my CPU? \n If it's too much, what would be a reasonable game to play? \n    submitted by    /u/IbizaMykonos  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/150hxnx/chess_or_alternative_games_to_develop_rl_project/",
          "publishedOn": "2023-07-15T17:34:22.000Z",
          "wordCount": 2488,
          "title": "Chess or alternative games to develop RL project?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/150d0gx/why_it_hurts_with_freedom_comes_the_biological/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/150d0gx/why_it_hurts_with_freedom_comes_the_biological/",
          "publishedOn": "2023-07-15T14:09:11.000Z",
          "wordCount": 2445,
          "title": "\"Why it hurts: with freedom comes the biological need for pain\", Farnsworth & Elwood 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15027bm/fading_replay_buffer_higher_capacity/",
          "author": null,
          "description": "Dear Community\n Let me introduce you Fading Replay Buffer,\n May be you have already noticed, when Replay Buffer reaches its capacity (especially when memory is low, e.g. 256k-1mln), the scores starts falling down rapidly.\n It happens most probably because of distribution becoming different than it was for 256k-1mln steps. Agent was trained with one distribution, now it is different as old data dissapears and new appears at each new step.\n With Fading Replay Buffer the idea is to train Agent with changing distribution gradually. Priorities at the beginning are almost the same, but then they become higher for newer transitions:\n ​\n https://i.redd.it/c6cw026922cb1.gif\n s in the equation gradually decreases from 1.0 to 0.0, with small step at each new data in buffer:\n x += 1/capacity\n s = exp(-x)\n Sharpness of fading is also adjustable:\n ​\n https://i.redd.it/k4g1bdqa22cb1.gif\n Because old data are less sampled, the factual capacity is less than in original Replay Buffer. To tackle this, I take average between 2 steps (.e.g., instead of 50ms, I take 100ms step), only transitions with dones are not averaged. Agent learns with the same speed as with 1 step, but Replay Buffer contains almost 2 times more data. The last update, sampling with priority is computationally heavy (especially for my computer). So I sample bigger random batch (1024) then re-sample smaller batch with priorities.\n This is continuation of the post \"Rectified Hubber Error\" https://www.reddit.com/r/datascience/comments/14o2ht9/rectified_hubber_error_rehe_for_scienctific/\n PS: My name is Timur Ishuov, I am an independent scientist without a doctoral degree.\n Code:\n https://github.com/timgep/Fading-Replay-Buffer/blob/main/FRB.py\n ​\n during environment step:\n replay_buffer.add_average([state, action, reward, next_state, done])\n    submitted by    /u/Timur_1988  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15027bm/fading_replay_buffer_higher_capacity/",
          "publishedOn": "2023-07-15T04:43:01.000Z",
          "wordCount": 2670,
          "title": "Fading Replay Buffer (+higher capacity)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/14zoc0k/deconstructing_an_agents_policy/",
          "author": null,
          "description": "Has anyone seen any papers or heard of research that tries to take an agents policy and return not just the optimal set of actions, but the following next n number of suboptimal sets of actions to achieve the objective/goal? Hopefully that makes sense\n In the simplest case, gridworld can take many paths to achieve the goal state. In practice after training the agent returns the optimal path. Is there instead a way to return the top 5 say optimal paths? \n This seems like it might be in the literature or research somewhere, but I'm struggling to find any papers that address or even note something like this\n    submitted by    /u/Peneloki  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/14zoc0k/deconstructing_an_agents_policy/",
          "publishedOn": "2023-07-14T18:36:37.000Z",
          "wordCount": 2526,
          "title": "Deconstructing an agents policy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/14zmvlo/open_loop_planning_a_sequence_of_blind_inputs/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/14zmvlo/open_loop_planning_a_sequence_of_blind_inputs/",
          "publishedOn": "2023-07-14T17:38:26.000Z",
          "wordCount": 2441,
          "title": "Open loop planning: a sequence of blind inputs that beats _Pokémon FireRed_ 99% of the time",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/14zjfpi/instruction_mining_highquality_instruction_data/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/14zjfpi/instruction_mining_highquality_instruction_data/",
          "publishedOn": "2023-07-14T15:27:44.000Z",
          "wordCount": 2439,
          "title": "\"Instruction Mining: High-Quality Instruction Data Selection for Large Language Models\", Cao et al 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/14zfsm4/sac_underactuated_pendulum_problem/",
          "author": null,
          "description": "I'm currently working on a project involving the underactuated pendulum problem, specifically known as the 'unbalanced disk'. You can find the code base here. I am using the reward function of pendulum v1.\n I've had success solving the problem with DQN, and improved it using hyperparameter optimization to enhance its performance, this worked fine and all. However, I would like to use SAC to solve this environment as well.\n You can find the SAC implementation I'm using here, I changed small things to make the environment work, and added mixed precision training to speed up training. Here is an image of the environment getting stuck on that position as well. The black arrow shows the direction of the force being applied.\n https://preview.redd.it/uuwtqvbjgxbb1.png?width=475&format=png&auto=webp&s=7a13693d5a84339726edb9b394a0fca5c9f5bc35\n My main challenge right now is that the SAC algorithm does not converge to the desired result. Rather than reaching the top of the pendulum swing as intended, it settles at the side position. I understand that the issue probably is the fact that it has to swing first. However, DQN was capable of doing it, so I wonder why SAC wouldn't.\n I've been running a series of hyperparameter optimizations in an attempt to find the right combination that can solve this environment. However, it didn't work so far.\n Here are the ranges I've been using for the hyperparameter search space:\n ​\n lr = trial.suggest_float('lr', 1e-5, 1e-4, log=True) batch = trial.suggest_categorical('batch', [32, 64, 128, 256]) gamma = trial.suggest_float('gamma', 0.90, 0.999) alpha = trial.suggest_float('alpha', 0.01, 0.5) polyak = trial.suggest_float('polyak', 0.01, 0.9) \n If someone has some pointers to solve this, please let me know!Most learning curves look like this as well:\n https://preview.redd.it/dj5sp7ikhxbb1.png?width=566&format=png&auto=webp&s=5b50c98a82a4a2d9499ea6bc87132f3b4424da99\n    submitted by    /u/r3ktIKevin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/14zfsm4/sac_underactuated_pendulum_problem/",
          "publishedOn": "2023-07-14T12:58:17.000Z",
          "wordCount": 2687,
          "title": "SAC underactuated pendulum problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/14yyulb/reinforcement_learning_in_newcomblike/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/14yyulb/reinforcement_learning_in_newcomblike/",
          "publishedOn": "2023-07-13T22:40:37.000Z",
          "wordCount": 2434,
          "title": "\"Reinforcement Learning in Newcomblike Environments\", Bell et al 2021",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/14ysmji/reinforce_with_baseline_not_learning/",
          "author": null,
          "description": "I have implemented REINFORCE using PyTorch and am testing it on the CartPole environment. My implementation allows for an optional baseline to be applied. At present, the baseline used is simply the mean of the returns earned during a trajectory. \n The agent will learn a good policy when I DO NOT use a baseline, but when I apply the baseline, the agent fails to learn anything. I cannot figure out why. \n I notice that the loss is always very close to zero when using the baseline, but it seems like that should be expected. When the network weights are still random, most of the actions will have a probability that is near 0.5, and thus a log probability that is close to log(0.5) ~=~ -0.7. The returns for this environment are symmetric about the mean, so the weighted sum of the centered return…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/14ysmji/reinforce_with_baseline_not_learning/",
          "publishedOn": "2023-07-13T18:34:35.000Z",
          "wordCount": 2715,
          "title": "REINFORCE with Baseline not Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/14yrurg/beating_deepminds_game_alchemy/",
          "author": null,
          "description": "submitted by    /u/Ok_Introduction9109  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/14yrurg/beating_deepminds_game_alchemy/",
          "publishedOn": "2023-07-13T18:04:28.000Z",
          "wordCount": 2429,
          "title": "Beating DeepMind’s Game: Alchemy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/14yps3g/is_offlinetoonline_rl_some_kind_of_transferrl/",
          "author": null,
          "description": "I read some papers about offline-to-online (O2O) RL and transfer-RL. And I was trying to explore the O2O-transfer RL. Where we have data for one environment and we could pre-train a model offline then improve it online in another environment.\n If the MDP structure is the same for the target and source environments while transferring.\n What is the exact difference between O2O-RL and transfer-RL under this assumption?\n Essentially they are both trying to adapt the distribution drift, isn’t it?\n    submitted by    /u/Blasphemer666  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/14yps3g/is_offlinetoonline_rl_some_kind_of_transferrl/",
          "publishedOn": "2023-07-13T16:42:50.000Z",
          "wordCount": 2500,
          "title": "Is offline-to-online RL some kind of Transfer-RL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/14yjbbp/ppo_agent_completing_street_fighter_iii_on_our_rl/",
          "author": null,
          "description": "submitted by    /u/DIAMBRA_AIArena  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/14yjbbp/ppo_agent_completing_street_fighter_iii_on_our_rl/",
          "publishedOn": "2023-07-13T12:18:15.000Z",
          "wordCount": 2445,
          "title": "PPO agent completing Street Fighter III on our RL Platform, it consistently outperformed when using deterministic actions instead of sampling them proportionally to their probability. Why in your opinion? (see comment for details)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/14xzjuc/faster_training_of_dueling_dqn/",
          "author": null,
          "description": "Hi everyone, Has anyone worked with training dueling DQN faster or sample efficient? I found papers: Fast RL with slow updates: https://github.com/amazon-science/fast-rl-with-slow-updates\n Sample efficient deep reinforcement learning via uncertainty estimation: https://openreview.net/forum?id=vrW3tvDfOJQ\n Sample efficient deep reinforcement learning via episodic backward update: https://arxiv.org/abs/1805.12375\n Has anyone worked with any of these? Or do you know any other strategies that have been used to make Dueling DQN learn faster? (I have already experimented with RAINBOW, so wanted to try something on top of it)\n    submitted by    /u/mr_formaldehyde  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/14xzjuc/faster_training_of_dueling_dqn/",
          "publishedOn": "2023-07-12T20:22:52.000Z",
          "wordCount": 2499,
          "title": "Faster training of Dueling DQN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/14xoyyd/the_inverse_reward_of_the_same_mdp_gives_a/",
          "author": null,
          "description": "Hello,\n I have an MDP which exists of 2 machine and I need to make decisions on when to do maintenance on the machine depending on the quality of the production. In one situation I created a reward structure based on the production loss of the system. and in the other situation I created a reward structure based on the throughput of the system which is exactly the inverse of the production loss, as you can see in the figure below. So I should suppose that the result of the value iteration algorithm should be exactly the same but it is not. Does anyone know what the reason for that could be or what I can try to do to find out why this happens? Because in value iteration the solution should be optimal, so 2 optimal solutions are not possible. It would be really helpful if someone has an idea about this.\n ​\n https://preview.redd.it/ni23yr5pfjbb1.png?width=1590&format=png&auto=webp&s=5550afef24552b5f516c15aacfc6f0d37af6fdd7\n ​\n https://preview.redd.it/dundnsrsfjbb1.png?width=453&format=png&auto=webp&s=20d300946254f1d08f3404100a565db27cb5658f\n    submitted by    /u/IcyWatch9445  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/14xoyyd/the_inverse_reward_of_the_same_mdp_gives_a/",
          "publishedOn": "2023-07-12T13:42:57.000Z",
          "wordCount": 2582,
          "title": "The inverse reward of the same MDP gives a different result when using value iteration",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "RL News",
      "feedUrl": "https://www.getrevue.co/profile/seungjaeryanlee?format=rss",
      "siteUrl": "http://rlnews.ryanlee.ai/",
      "articles": []
    },
    {
      "title": "Damian Bogunowicz - dtransposed",
      "feedUrl": "https://dtransposed.github.io/feed.xml",
      "siteUrl": "http://dtransposed.github.io/",
      "articles": []
    },
    {
      "title": "Data Science Central",
      "feedUrl": "http://feeds.feedburner.com/FeaturedBlogPosts-DataScienceCentral?format=xml",
      "siteUrl": "https://www.datasciencecentral.com/",
      "articles": [
        {
          "id": "https://www.datasciencecentral.com/?p=62815",
          "author": "ajitjaokar",
          "description": "Background In the previous part of this blog, we explored the limitations of GPT-4. In this post, we will explore if open source models can overcome the limitations of black box models. Specifically, we will consider the use of LLama2 in this scenario.  The llama 2 paper from Meta is very comprehensive.  Llama 2, is… Read More »Generative AI megatrends: implications of GPT-4 drift and open source models – part two\nThe post Generative AI megatrends: implications of GPT-4 drift and open source models – part two appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/generative-ai-megatrends-implications-of-gpt-4-drift-and-open-source-models-part-two/",
          "publishedOn": "2023-08-09T15:17:47.000Z",
          "wordCount": 5675,
          "title": "Generative AI megatrends: implications of GPT-4 drift and open source models – part two",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/india-gfcc7345eb_1280-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62840",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 8 August 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-8-august-2023/",
          "publishedOn": "2023-08-08T17:36:20.000Z",
          "wordCount": 6051,
          "title": "DSC Weekly 8 August 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62837",
          "author": "Roger Brown",
          "description": "Prompt engineers are emerging as key players in the development and optimization of AI models as artificial intelligence (AI) continues its evolution and becomes an integral part of various industries. As experts at crafting effective prompts, they have been instrumental in shaping the future of artificial intelligence through their ability to enable models to deliver… Read More »The emergence of prompt engineers: The next in-demand role in AI\nThe post The emergence of prompt engineers: The next in-demand role in AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/the-emergence-of-prompt-engineers-the-next-in-demand-role-in-ai/",
          "publishedOn": "2023-08-08T17:21:19.000Z",
          "wordCount": 6475,
          "title": "The emergence of prompt engineers: The next in-demand role in AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/Prompt-Ai.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62809",
          "author": "Alan Morrison",
          "description": "Fair Data Forecast Interview with Gregor Stühler of Scoutbee Scoutbee’s CEO and founder, Gregor Stühler, who has a background in computer science and  electrical engineering, first learned about the challenges of procurement and supply base management as a project engineer for a multinational medical device company. Scoutbee’s focus on solving supply base problems through hybrid… Read More »Scaling Supply Base Data and Reuse with Knowledge Graphs and LLMs\nThe post Scaling Supply Base Data and Reuse with Knowledge Graphs and LLMs appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/scaling-supply-base-data-and-reuse-with-knowledge-graphs-and-llms/",
          "publishedOn": "2023-08-07T16:19:35.000Z",
          "wordCount": 5734,
          "title": "Scaling Supply Base Data and Reuse with Knowledge Graphs and LLMs",
          "enclosure": {
            "url": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/Gregor-Stuhler-of-Scoutbee-Mixed.mp3",
            "length": "21965958",
            "type": "audio/mpeg"
          },
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/container-ship-7383545_1280.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62819",
          "author": "Bill Schmarzo",
          "description": "It’s incredible how many organizations utilize Generative AI (GenAI) and Large Language Models (LLMs) to enhance their information assembly, integration, and application abilities. These GenAI technologies have been applied in various areas, from drafting legal documents and resolving service issues to coding software applications and (er, um) writing blog posts. The potential uses of GenAI… Read More »Integrating GenAI into “Thinking Like a Data Scientist” Methodology – Part I\nThe post Integrating GenAI into “Thinking Like a Data Scientist” Methodology – Part I appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/integrating-genai-into-thinking-like-a-data-scientist-methodology-part-i/",
          "publishedOn": "2023-08-06T12:16:23.000Z",
          "wordCount": 6836,
          "title": "Integrating GenAI into “Thinking Like a Data Scientist” Methodology – Part I",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/Slide1.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62798",
          "author": "John Lee",
          "description": "AI has revolutionized software development. AI has transformed software testing and debugging by automating mundane tasks and solving complex problems. Manual testing no longer requires hours and resources. AI has revolutionized testing, code quality, and development time. This article explores AI’s profound impact on software testing and debugging, including its benefits, risks, and how it… Read More »AI’s transformative role in software testing and debugging\nThe post AI’s transformative role in software testing and debugging appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ais-transformative-role-in-software-testing-and-debugging/",
          "publishedOn": "2023-08-04T15:12:47.000Z",
          "wordCount": 6976,
          "title": "AI’s transformative role in software testing and debugging",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/AI-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62813",
          "author": "ajitjaokar",
          "description": "In this two part discussion, we will discuss two related generative AI megatrends Backgroumd A recent paper How Is ChatGPT’s Behavior Changing over Time? from Stanford University and UC Berkeley claims that the performance of GPT-4 has drifted over time. To make this claim, specific tasks were evaluated (ex: accuracy of maths) and the results… Read More »Generative AI megatrends: implications of GPT-4 drift and open source models – part one\nThe post Generative AI megatrends: implications of GPT-4 drift and open source models – part one appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/generative-ai-megatrends-implications-of-gpt-4-drift-and-open-source-models-part-one/",
          "publishedOn": "2023-08-04T14:50:00.000Z",
          "wordCount": 5738,
          "title": "Generative AI megatrends: implications of GPT-4 drift and open source models – part one",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/india-gfcc7345eb_1280.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62800",
          "author": "Aileen Scott",
          "description": "Introduction Data Science is a vast field that incorporates several processes. From problem definition to data collection and data cleaning to data visualization, a lot of things are included in the entire data science project development process. Data Scientists are especially responsible for these tasks. They are expert professionals who are well-versed with various data… Read More »How can Data Scientists use ChatGPT for developing Machine Learning Models?\nThe post How can Data Scientists use ChatGPT for developing Machine Learning Models? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-can-data-scientists-use-chatgpt-for-developing-machine-learning-models/",
          "publishedOn": "2023-08-03T20:27:09.000Z",
          "wordCount": 6046,
          "title": "How can Data Scientists use ChatGPT for developing Machine Learning Models?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/ChatGPT-for-developing-machine-learning-models.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?post_type=vimeo-video&p=62796",
          "author": "Ben Cole",
          "description": "The convergence of Oracle Cloud Infrastructure (OCI) and Hitachi Application Reliability Centers (HARC) to magnify outcomes for customers. Tech giants Oracle and Hitachi Vantara are marching together to magnify cloud outcomes. Join us for the Oracle and Hitachi Vantara virtual event, where we discuss how businesses can get the most out of OCI and HARC.… Read More »DSC Webinar Series: OCI & HARC: Modernizing Workloads in the Oracle Cloud\nThe post DSC Webinar Series: OCI & HARC: Modernizing Workloads in the Oracle Cloud appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-webinar-series-oci-harc-modernizing-workloads-in-the-oracle-cloud/",
          "publishedOn": "2023-08-02T20:02:15.000Z",
          "wordCount": 5355,
          "title": "DSC Webinar Series: OCI & HARC: Modernizing Workloads in the Oracle Cloud",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/p62796-vimeo-thumbnail.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62790",
          "author": "Anas Baig",
          "description": "Artificial intelligence, or AI, has often been depicted as a terrifying force, from HAL 9000’s chilling declaration in “2001: A Space Odyssey” to the apocalyptic machine uprising in the Terminator movies. However, in reality, AI has become an integral part of our daily lives, with AI-powered Android devices in our pockets. Though we may not… Read More »Emerging AI statistics and trends to watch\nThe post Emerging AI statistics and trends to watch appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/emerging-ai-statistics-and-trends-to-watch/",
          "publishedOn": "2023-08-02T18:16:53.000Z",
          "wordCount": 6088,
          "title": "Emerging AI statistics and trends to watch",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/ai-trends.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62787",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 1 August 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-1-august-2023/",
          "publishedOn": "2023-08-01T18:42:05.000Z",
          "wordCount": 5775,
          "title": "DSC Weekly 1 August 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62782",
          "author": "Kirk Borne",
          "description": "Generative AI has been around for a long time. Some sources say that it appeared as early as the 1950’s. Other sources point to the first rudimentary chatbots that were introduced in the 1960’s. Whatever the true point of origin, we can all agree that those were small pebbles on the historical timeline compared to… Read More »I bet you think this article is about ChatGPT\nThe post I bet you think this article is about ChatGPT appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/i-bet-you-think-this-article-is-about-chatgpt/",
          "publishedOn": "2023-08-01T18:32:37.000Z",
          "wordCount": 6567,
          "title": "I bet you think this article is about ChatGPT",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/AdobeStock_558672396_Editorial_Use_Only-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62764",
          "author": "Alan Morrison",
          "description": "If I could name one reason why business will face at least one more AI winter, it’s the lack of nuance in most business AI discussions. The buzz about large language models (LLMs) has sucked much of the oxygen out of the air for complementary technologies. The truth is that LLMs are no more a… Read More »Data tribalism and the AI nuance deficit\nThe post Data tribalism and the AI nuance deficit appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-tribalism-and-the-ai-nuance-deficit/",
          "publishedOn": "2023-08-01T18:28:56.000Z",
          "wordCount": 6105,
          "title": "Data tribalism and the AI nuance deficit",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/argument-6080057_1280.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?post_type=vimeo-video&p=62778",
          "author": "Ben Cole",
          "description": "The post DSC Webinar Series: Influence Data-Driven Decisions Based On Your Communication Style appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-webinar-series-influence-data-driven-decisions-based-on-your-communication-style/",
          "publishedOn": "2023-08-01T18:00:27.000Z",
          "wordCount": 5211,
          "title": "DSC Webinar Series: Influence Data-Driven Decisions Based On Your Communication Style",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/p62778-vimeo-thumbnail.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62767",
          "author": "Vincent Granville",
          "description": "There are thousands of articles explaining the differences between data scientist and machine learning engineer. Data science gets broken down even further, with data analysts contrasted to researchers. Professionals skilled in all these domains are called unicorns and believed not to exist. Indeed, they may not work for companies, and ignored when applying for a… Read More »The Rise of the Dual Data Scientist / Machine Learning Engineer\nThe post The Rise of the Dual Data Scientist / Machine Learning Engineer appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/the-rise-of-the-dual-data-scientist-machine-learning-engineer/",
          "publishedOn": "2023-08-01T08:04:24.000Z",
          "wordCount": 6329,
          "title": "The Rise of the Dual Data Scientist / Machine Learning Engineer",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/sunrise2.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62737",
          "author": "Rayan Potter",
          "description": "Let’s image – with algorithms and a nerdy charm that could melt any data center, an ‘AI’ wearing lab coats and stethoscopes patrolling hospital hallways, tirelessly monitoring patients. The digital doctor will take the pulse of Mother Earth and reduce waste, cut energy consumption, and cut energy consumption! The artificial intelligence community is well aware… Read More »Doctor AI: Healing humans and mother earth hand in hand\nThe post Doctor AI: Healing humans and mother earth hand in hand appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/doctor-ai-healing-humans-and-mother-earth-hand-in-hand/",
          "publishedOn": "2023-07-31T14:43:27.000Z",
          "wordCount": 5936,
          "title": "Doctor AI: Healing humans and mother earth hand in hand",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/earth-day-environment-eco-concept-top-view.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62732",
          "author": "ManojKumar847",
          "description": "In an age where efficiency is king, manufacturing firms are in a constant race to outshine their competition. Imagine if you could boost productivity, slash downtime, and cut costs all at once. Sounds like a dream, right? The good news is, this isn’t a fantasy. It’s achievable through Internet of Things (IoT) solutions. IoT solutions… Read More »Increase efficiency of manufacturing operations with IoT solutions\nThe post Increase efficiency of manufacturing operations with IoT solutions appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/increase-efficiency-of-manufacturing-operations-with-iot-solutions/",
          "publishedOn": "2023-07-31T14:41:58.000Z",
          "wordCount": 6301,
          "title": "Increase efficiency of manufacturing operations with IoT solutions",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/IoT-Solutions-scaled.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62725",
          "author": "Alan Morrison",
          "description": "“If you start by creating your data, then it’s like you are piling up some value or you’re creating some assets,” WordLift CEO Andrea Volpini told me in our recent FAIR Data Forecast interview. Volpini’s an advocate for adding structured data such as Schema.org to your content. That way, the content becomes logically connected and… Read More »Human-centered data networking with interpersonal knowledge  graphs\nThe post Human-centered data networking with interpersonal knowledge  graphs appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/human-centered-data-networking-with-interpersonal-knowledge-graphs/",
          "publishedOn": "2023-07-31T14:39:56.000Z",
          "wordCount": 6277,
          "title": "Human-centered data networking with interpersonal knowledge  graphs",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/networks-3017398_1280.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62745",
          "author": "Bill Schmarzo",
          "description": "One of the reasons that I moved back to Iowa last year was that I saw an opportunity to work with local educational institutions to create an AI Institute for organizations in middle America that either get overlooked in the AI conversation or are unsure what AI means to them. I wanted to reduce the… Read More »Introduction to “AI & Data Literacy: Empowering Citizens of Data Science”\nThe post Introduction to “AI & Data Literacy: Empowering Citizens of Data Science” appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/introduction-to-ai-data-literacy-empowering-citizens-of-data-science/",
          "publishedOn": "2023-07-29T19:22:55.000Z",
          "wordCount": 6522,
          "title": "Introduction to “AI & Data Literacy: Empowering Citizens of Data Science”",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/Book-5-Intro-graphic.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62741",
          "author": "Roger Brown",
          "description": "In various fields, such as traffic management, law enforcement, and parking management, license plate recognition is a crucial application of computer vision that is used to analyze license plates. In this article, we will review the Chinese City Parking Dataset (CCPD), which is one of the most widely used computer vision datasets for tasks that… Read More »Understanding license plate recognition with the CCPD computer vision datasets\nThe post Understanding license plate recognition with the CCPD computer vision datasets appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/understanding-license-plate-recognition-with-the-ccpd-computer-vision-datasets/",
          "publishedOn": "2023-07-28T18:04:00.000Z",
          "wordCount": 6077,
          "title": "Understanding license plate recognition with the CCPD computer vision datasets",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/ccpd-dataset-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62723",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 25 July 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-25-july-2023/",
          "publishedOn": "2023-07-25T19:53:37.000Z",
          "wordCount": 5973,
          "title": "DSC Weekly 25 July 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62696",
          "author": "Alan Morrison",
          "description": "Fair Data Forecast Interview with Andreas Volpini, CEO of WordLift Andreas Volpini believes every user who wants to build a personal brand online has to proactively curate their online presence first. He sees structured data (semantic entity and attribute metadata such as Schema.org) as key to building a cohesive, disambiguated personal presence online. Volpini has… Read More »The AI content + data mandate and personal branding\nThe post The AI content + data mandate and personal branding appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/the-ai-content-data-mandate-and-personal-branding/",
          "publishedOn": "2023-07-25T16:30:13.000Z",
          "wordCount": 11759,
          "title": "The AI content + data mandate and personal branding",
          "enclosure": {
            "url": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/Andrea-Volpini-TFDF-Final.mp3",
            "length": "30793410",
            "type": "audio/mpeg"
          },
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/AdobeStock_592088739-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62580",
          "author": "Erika Balla",
          "description": "Welcome to the exciting world of digital marketing! In this blog, we’ll delve into this thrilling frontier where optimization meets automation and Artificial Intelligence is at the center. No longer must manual labor and guesswork play an essential part in developing effective marketing strategies; with AI’s capabilities now at their disposal, marketers with digital presence… Read More »From automation to optimization: How AI is revolutionizing digital marketing campaigns\nThe post From automation to optimization: How AI is revolutionizing digital marketing campaigns appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/from-automation-to-optimization-how-ai-is-revolutionizing-digital-marketing-campaigns/",
          "publishedOn": "2023-07-25T16:26:10.000Z",
          "wordCount": 7324,
          "title": "From automation to optimization: How AI is revolutionizing digital marketing campaigns",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/internet-4463031_1280-942x600-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62707",
          "author": "ajitjaokar",
          "description": "In this blog, I will now focus on generative AI megatrends. By that, I mean, trends and underlying trends that could be big in the future – focusing on the technology of LLM but also the wider impact of LLMs on the economy and society. I will hence identify and follow some key trends –… Read More »Generative AI megatrends: Are companies using the excuse of AI to get rid of jobs?\nThe post Generative AI megatrends: Are companies using the excuse of AI to get rid of jobs? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/generative-ai-megatrends-are-companies-using-the-excuse-of-ai-to-get-rid-of-jobs/",
          "publishedOn": "2023-07-24T16:30:00.000Z",
          "wordCount": 5694,
          "title": "Generative AI megatrends: Are companies using the excuse of AI to get rid of jobs?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/Screenshot-2023-07-24-13.29.07.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62710",
          "author": "David Stephen",
          "description": "There is a recent paper in Synthese, Qualia share their correlates’ locations, where the abstract stated that “This paper presents the location-sharing argument, which concludes that qualia must share the locations of their physical correlates. The first premise is a consequence of relativity: If something shares a time with a physical event in all reference… Read More »Sentience: Consciousness is inessential for LLMs, AI\nThe post Sentience: Consciousness is inessential for LLMs, AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/sentience-consciousness-is-inessential-for-llms-ai/",
          "publishedOn": "2023-07-24T15:53:08.000Z",
          "wordCount": 5954,
          "title": "Sentience: Consciousness is inessential for LLMs, AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/AdobeStock_562116144-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62690",
          "author": "Dan Allen",
          "description": "In October 2022, the White House Office of Science and Technology Policy published “The Blueprint for an AI Bill of Rights: Making Automated Systems Work for the American People”. This attention from our government given to what could be called an AI EQ (emotional quotient) is reminiscent of how-to parent or raise a child. This… Read More »AI is a child: How do we raise it?\nThe post AI is a child: How do we raise it? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ai-is-a-child-how-do-we-raise-it/",
          "publishedOn": "2023-07-24T15:39:00.000Z",
          "wordCount": 7466,
          "title": "AI is a child: How do we raise it?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/AdobeStock_592515883.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62678",
          "author": "Prasanna Chitanand",
          "description": "With the introduction of ChatGPT-3 and DALL-E2, the majority of investors started showing interest in businesses building generative AI. Moreover, the fact is generative AI is not enough to reach the needs of the AI revolution. The success of predictive models is relevant to the science fiction future that the majority of the customers want… Read More »Innovations in predictive analytics: ML and generative AI\nThe post Innovations in predictive analytics: ML and generative AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/innovations-in-predictive-analytics-ml-and-generative-ai/",
          "publishedOn": "2023-07-24T14:10:13.000Z",
          "wordCount": 7372,
          "title": "Innovations in predictive analytics: ML and generative AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/Innovations-in-Predictive-Analytics-ML-and-Generative-AI.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62684",
          "author": "Anas Baig",
          "description": "In today’s tech-driven world, data is like gold. It’s becoming more and more common for companies to use real-time, or live, data to make informed decisions, improve the service they give to customers, and get a leg up on the competition. But handling real-time data can be tricky because there’s so much of it, it’s… Read More »How to manage real-time data in the digital age\nThe post How to manage real-time data in the digital age appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-to-manage-real-time-data-in-the-digital-age/",
          "publishedOn": "2023-07-21T14:21:15.000Z",
          "wordCount": 6080,
          "title": "How to manage real-time data in the digital age",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/Real-Time-Data.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62557",
          "author": "Edwin Walker",
          "description": "Modern data quality practices make use of new technology, automation, and machine learning to handle a variety of data sources, ensure real-time processing, and stimulate stakeholder collaboration. Data governance, continuous monitoring, and proactive management are prioritized to ensure accurate, reliable, and fit-for-purpose data for informed decision-making and corporate success. Modern data quality practices differ from… Read More »Difference Between Modern and Traditional Data Quality – DQLabs\nThe post Difference Between Modern and Traditional Data Quality – DQLabs appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/difference-between-modern-and-traditional-data-quality-dqlabs/",
          "publishedOn": "2023-07-20T18:39:00.000Z",
          "wordCount": 5695,
          "title": "Difference Between Modern and Traditional Data Quality – DQLabs",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/Modern-and-Traditional-data-quality_v1.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62682",
          "author": "Aileen Scott",
          "description": "The most common question in people’s minds that are not from a technical background is how much coding is required to ace a data science career path. If you also have the same question, you are not alone. But, the surprising answer is “it depends”. Unarguably, coding is a crucial aspect and vital tool for… Read More »How much coding is needed in a data science career?\nThe post How much coding is needed in a data science career? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-much-coding-is-needed-in-a-data-science-career/",
          "publishedOn": "2023-07-20T06:51:00.000Z",
          "wordCount": 6165,
          "title": "How much coding is needed in a data science career?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/How-Much-Coding-is-Essential-to-Grow-in-Data-Science-Career.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62674",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 18 July 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-18-july-2023/",
          "publishedOn": "2023-07-18T21:04:00.000Z",
          "wordCount": 5944,
          "title": "DSC Weekly 18 July 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62652",
          "author": "Ovais Naseem",
          "description": "Electronic Data Interchange (EDI) can be traced back to the late 1960s and early 1970s when businesses began to seek more efficient ways to exchange data electronically. Consequently, the concept of using computers to transmit and receive business documents emerged, aiming to replace manual paper-based processes. Then in the 1980s, standards organizations such as ANSI… Read More »Leveraging AI for smarter electronic data interchange\nThe post Leveraging AI for smarter electronic data interchange appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/leveraging-ai-for-smarter-electronic-data-interchange/",
          "publishedOn": "2023-07-18T15:09:31.000Z",
          "wordCount": 6076,
          "title": "Leveraging AI for smarter electronic data interchange",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/ai-ml-blog-header-1024x576.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62666",
          "author": "David Stephen",
          "description": "There is a recent interview, The Ethical Puzzle of Sentient AI, where a professor said, “But there’s also the problem that I’ve called the ‘gaming problem’ — that when the system has access to trillions of words of training data, and has been trained with the goal of mimicking human behavior, the sorts of behavior patterns… Read More »LLMs: Does human text data make generative AI an entity?\nThe post LLMs: Does human text data make generative AI an entity? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/llms-does-human-text-data-make-generative-ai-an-entity/",
          "publishedOn": "2023-07-17T16:12:51.000Z",
          "wordCount": 5834,
          "title": "LLMs: Does human text data make generative AI an entity?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/AdobeStock_209433187-1024x497.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62664",
          "author": "Markus Buhmann",
          "description": "The modern enterprise is insight-driven, or, at least, aims to be. Historically, those insights were found in a data warehouse or data lake, populated with scheduled feeds and analysts, working feverishly over them. Feeds had plenty of bandwidth, but high latency. Think an 18-wheeler loaded with hard drives, driving from London to Birmingham. Nowadays, insights… Read More »Real-time analytics\nThe post Real-time analytics appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/real-time-analytics/",
          "publishedOn": "2023-07-17T16:09:00.000Z",
          "wordCount": 6159,
          "title": "Real-time analytics",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/AdobeStock_188051979-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62656",
          "author": "Devarati Sarkar",
          "description": "AI Ushers in a New Era of Mental Health Monitoring Important Data Points: AI’s Role in Mental Healthcare Transformation – It can be safe to say that AI is driving a significant transformation in mental healthcare, promising more accessible, economical, and effective treatments. The Emerging Role of Technology and Artificial Intelligence As the modern world… Read More »AI ushers in a new era of mental health monitoring\nThe post AI ushers in a new era of mental health monitoring appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ai-ushers-in-a-new-era-of-mental-health-monitoring/",
          "publishedOn": "2023-07-17T15:52:29.000Z",
          "wordCount": 7155,
          "title": "AI ushers in a new era of mental health monitoring",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/image-1-1024x337.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62654",
          "author": "Gregory Batchelor",
          "description": "If you’ve spent any time in the tech community in the last few years, you’ll have noticed the recent explosion in interest in both data science and web development. Young people interested in a career in tech are increasingly turning to careers as data scientists or web developers.  The importance of web development should be… Read More »Data science vs web development: What’s the difference?\nThe post Data science vs web development: What’s the difference? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-science-vs-web-development-whats-the-difference/",
          "publishedOn": "2023-07-17T15:46:42.000Z",
          "wordCount": 6802,
          "title": "Data science vs web development: What’s the difference?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/Untitled.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62646",
          "author": "Bill Schmarzo",
          "description": "Generative AI (GenAI) products like OpenAI ChatGPT, Microsoft Bing, and Google Bard are disrupting the roles of data engineers and data scientists. According to a recent report by McKinsey, these GenAI products could potentially automate up to 40% of the tasks performed by data science teams by 2025. And Emad Mostaque, founder and CEO of… Read More »Next-Gen Data Scientist: Thinking Like an Economist\nThe post Next-Gen Data Scientist: Thinking Like an Economist appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/next-gen-data-scientist-thinking-like-an-economist/",
          "publishedOn": "2023-07-16T20:18:13.000Z",
          "wordCount": 6680,
          "title": "Next-Gen Data Scientist: Thinking Like an Economist",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/Slide1-1.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62613",
          "author": "Yana Ihnatchyck",
          "description": "By now, AI-based tools have totally changed the way companies operate across all industries. The use of AI in them to streamline operations, make informed decisions, and enhance customer experiences.  Companies utilize AI in a multitude of ways, such as automating repetitive tasks, predicting customer behavior, and optimizing supply chain management. Today, we will dive… Read More »How Do Companies Use Artificial Intelligence?\nThe post <strong>How Do Companies Use Artificial Intelligence?</strong> appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-do-companies-use-artificial-intelligence/",
          "publishedOn": "2023-07-14T14:41:27.000Z",
          "wordCount": 6205,
          "title": "How Do Companies Use Artificial Intelligence?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/11.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62575",
          "author": "Shanthababu Pandian",
          "description": "Hello, data enthusiast! In this article let’s discuss “Data Modelling” right from the traditional and classical ways and aligning to today’s digital way, especially for analytics and advanced analytics. Yes! Of course, last 40+ years we all worked for OLTP, and followed by we started focusing on OLAP. After cloud ear come into the picture… Read More »Data modeling techniques in modern data warehouse\nThe post Data modeling techniques in modern data warehouse appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-modeling-techniques-in-modern-data-warehouse/",
          "publishedOn": "2023-07-13T18:02:00.000Z",
          "wordCount": 7689,
          "title": "Data modeling techniques in modern data warehouse",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/32499OLTP-AP.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62573",
          "author": "Shanthababu Pandian",
          "description": "Image Source: Author Introduction Data Engineers and Data Scientists need data for their Day-to-Day job. Of course, It could be for Data Analytics, Data Prediction, Data Mining, Building Machine Learning Models Etc., All these are taken care of by the respective team members and they need to work towards identifying relevant data sources, and associated with… Read More »A Detailed Guide for Data Handling Techniques in Data Science\nThe post A Detailed Guide for Data Handling Techniques in Data Science appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/a-detailed-guide-for-data-handling-techniques-in-data-science/",
          "publishedOn": "2023-07-13T17:21:24.000Z",
          "wordCount": 7945,
          "title": "A Detailed Guide for Data Handling Techniques in Data Science",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/75699Data-Handling-Techniques.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62615",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 11 July 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-11-july-2023/",
          "publishedOn": "2023-07-11T21:30:00.000Z",
          "wordCount": 6066,
          "title": "DSC Weekly 11 July 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        }
      ]
    },
    {
      "title": "John D. Cook",
      "feedUrl": "https://www.johndcook.com/blog/feed",
      "siteUrl": "https://www.johndcook.com/blog",
      "articles": [
        {
          "id": "https://www.johndcook.com/blog/?p=202525",
          "author": "John",
          "description": "In high dimensions, randomly chosen vectors are very likely nearly orthogonal. I’ll unpack this a little bit then demonstrate it by simulation. Then I’ll look at what happens when we restrict our attention to points with positive coordinates. *** The lengths of vectors don’t contribute to the angles between them, so we may as well […]\nRandom points in a high-dimensional orthant first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/09/random-points-hypersphere-orthant/",
          "publishedOn": "2023-08-10T00:31:56.000Z",
          "wordCount": 1782,
          "title": "Random points in a high-dimensional orthant",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=202444",
          "author": "John",
          "description": "The previous post looked at cosine similarity for embeddings of words in vector spaces. Word embeddings like word2vec map words into high-dimensional vector spaces in such a way that related words correspond to vectors that are roughly parallel. Ideally the more similar the words, the smaller the angle between their corresponding vectors. The cosine similarity […]\nCosine similarity does not satisfy the triangle inequality first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/09/cosine-similarity-not-a-metric/",
          "publishedOn": "2023-08-09T15:15:38.000Z",
          "wordCount": 1882,
          "title": "Cosine similarity does not satisfy the triangle inequality",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=202355",
          "author": "John",
          "description": "Natural language processing represents words as high-dimensional vectors, on the order of 100 dimensions. For example, the glove-wiki-gigaword-50 set of word vectors contains 50-dimensional vectors, and the the glove-wiki-gigaword-200 set of word vectors contains 200-dimensional vectors. The intent is to represent words in such a way that the angle between vectors is related to similarity […]\nAngles between words first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/08/angles-between-words/",
          "publishedOn": "2023-08-09T00:56:00.000Z",
          "wordCount": 2030,
          "title": "Angles between words",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=202307",
          "author": "John",
          "description": "This post will discuss two scripting languages, but that’s not what the post is really about. It’s really about expressiveness and (or versus) productivity. *** I was excited to discover the awk programming language sometime in college because I had not used a scripting language before. Compared to C, awk was high-level luxury. Then a […]\nProductive constraints first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/08/productive-constraints/",
          "publishedOn": "2023-08-08T18:14:06.000Z",
          "wordCount": 1891,
          "title": "Productive constraints",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=202282",
          "author": "John",
          "description": "A Möbius transformation is a function of the form where ad – bc = 1. We usually think of z as a complex number, but it doesn’t have to be. We could define Möbius transformations in any context where we can multiply, add, and divide, i.e. over any field. In particular, we could work over […]\nMöbius transformations over a finite field first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/08/finite-mobius/",
          "publishedOn": "2023-08-08T14:01:26.000Z",
          "wordCount": 1862,
          "title": "Möbius transformations over a finite field",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=202146",
          "author": "John",
          "description": "A common idiom in command line processing of text files is ... | sort | uniq | ... Some process produces lines of text. You want to pipe that text through sort to sort the lines in alphabetical order, then pass it to uniq to filter out all but the unique lines. The uniq utility […]\nSort and remove duplicates first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/07/sort-u/",
          "publishedOn": "2023-08-07T18:36:34.000Z",
          "wordCount": 1577,
          "title": "Sort and remove duplicates",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201882",
          "author": "John",
          "description": "The previous post looked at the swish function and related activation functions for deep neural networks designed to address the “dying ReLU problem.” Unlike many activation functions, the function f(x) is not monotone but has a minimum near x0 = -1.2784. The exact location of the minimum is where W is the Lambert W function, […]\nSwish function and a Swiss mathematician first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/06/swish-swiss/",
          "publishedOn": "2023-08-06T17:24:24.000Z",
          "wordCount": 1458,
          "title": "Swish function and a Swiss mathematician",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201867",
          "author": "John",
          "description": "Swish, mish, and serf are neural net activation functions. The names are fun to say, but more importantly the functions have been shown to improve neural network performance by solving the “dying ReLU problem.” Softplus can also be used as an activation function, but our interest in softplus here is as part of the definition […]\nSwish, mish, and serf first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/06/swish-mish-and-serf/",
          "publishedOn": "2023-08-06T16:50:23.000Z",
          "wordCount": 1955,
          "title": "Swish, mish, and serf",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201814",
          "author": "John",
          "description": "In principle you generate an RSA key by finding two large prime numbers, p and q, and computing n = pq. You could, for example, generate random numbers by rolling dice, then type the numbers into Mathematica to test each for primaility until you find a couple prime numbers of the right size. In practice […]\nGenerating and inspecting an RSA private key first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/05/rsa-private-key/",
          "publishedOn": "2023-08-05T21:06:15.000Z",
          "wordCount": 1689,
          "title": "Generating and inspecting an RSA private key",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201771",
          "author": "John",
          "description": "At its core, RSA encryption is modular exponentiation. That is, given a message m, the encrypted form of m is x = me mod n where e is a publicly known exponent and n is a product of two large primes. The number n is made public but only the holder of the private key […]\nRSA encryption in practice first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/05/rsa-oaep/",
          "publishedOn": "2023-08-05T15:22:01.000Z",
          "wordCount": 1610,
          "title": "RSA encryption in practice",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201750",
          "author": "John",
          "description": "A few days ago I wrote about using the CMU Pronouncing Dictionary to search for words that decode to certain numbers in the Major mnemonic system. You can find a brief description of the Major system in that post. As large as the CMU dictionary is, it did not contain words mapping to some three-digit […]\nCode to convert words to Major system numbers first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/05/word-to-number/",
          "publishedOn": "2023-08-05T13:48:11.000Z",
          "wordCount": 1911,
          "title": "Code to convert words to Major system numbers",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201632",
          "author": "John",
          "description": "The Allee effect is named after Warder Clyde Allee who added a term to the famous logistic equation. His added term is highlighted in blue. Here N is the population of a species over time, r is the intrinsic rate of increase, K is the carrying capacity, and A is the critical point. If you […]\nSoftware and the Allee effect first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/04/allee-effect/",
          "publishedOn": "2023-08-04T16:58:25.000Z",
          "wordCount": 1602,
          "title": "Software and the Allee effect",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201621",
          "author": "John",
          "description": "“That’s a solved problem. So nobody knows how to solve it anymore.” Once a problem is deemed “solved” interest in the problem plummets. “Solved” problems may not be fully solved, but sufficiently solved that the problem is no longer fashionable. Practical issues remain, but interest moves elsewhere. The software written for the problem slowly decays. […]\nSolved problems becoming unsolved first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/04/solved-problems/",
          "publishedOn": "2023-08-04T15:34:46.000Z",
          "wordCount": 1381,
          "title": "Solved problems becoming unsolved",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201618",
          "author": "John",
          "description": "There’s an old saying “The cobbler’s son has no shoes.” It’s generally taken to mean that we can neglect to do for ourselves something we do for other people. I’ve been writing a few scripts for my personal use, things I’ve long intended to do but only recently got around to doing. I said something […]\nThe cobbler’s son first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/04/the-cobblers-son/",
          "publishedOn": "2023-08-04T14:35:10.000Z",
          "wordCount": 1437,
          "title": "The cobbler’s son",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201466",
          "author": "John",
          "description": "I was looking back at Jeroen Janssen’s book Data Science at the Command Line and his dseq utility caught my eye. This utility prints out a sequence of dates relative to the current date. I’ve needed this and didn’t know it. Suppose you have a CSV file and you need to add a column of […]\nDate sequence from the command line first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/03/date-sequence/",
          "publishedOn": "2023-08-03T13:17:20.000Z",
          "wordCount": 1905,
          "title": "Date sequence from the command line",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201073",
          "author": "John",
          "description": "An up-down permutation of an ordered set is a permutation such that as you move from left to right the permutation alternates up and down. For example 1, 5, 3, 4, 2 is an up-down permutation of 1, 2, 3, 4, 5 because 1 < 5 > 3 < 4 > 2. Up-down permutations are […]\nUp-down permutations first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/31/alternating-permutations/",
          "publishedOn": "2023-07-31T23:03:24.000Z",
          "wordCount": 1490,
          "title": "Up-down permutations",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=201040",
          "author": "John",
          "description": "Suppose you have data that for some reason has been summarized into bins of width h. You don’t have the original data, only the number of counts in each bin. You can’t exactly find the sample mean or sample variance of the data because you don’t actually have the data. But what’s the best you […]\nVariance of binned data first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/31/sheppard/",
          "publishedOn": "2023-07-31T16:25:32.000Z",
          "wordCount": 1597,
          "title": "Variance of binned data",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=200864",
          "author": "John",
          "description": "A very crude way to estimate π would be to find the perimeter of squares inside and outside a unit circle. The outside square has sides of length 2, so 2π < 8. The inside square has sides of length 2/√2, so 8/√2 < 2π. This tells us π is between 2.82 and 4. Not […]\nAncient estimate of π and modern numerical analysis first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/30/archimedes-richardson/",
          "publishedOn": "2023-07-31T00:18:38.000Z",
          "wordCount": 1851,
          "title": "Ancient estimate of π and modern numerical analysis",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=200719",
          "author": "John",
          "description": "ARPAbet is a phonetic spelling system developed by— you guessed it—ARPA, before it became DARPA. The ARPAbet system is less expressive than IPA, but much easier for English speakers to understand. Every sound is encoded as one or two English letters. So, for example, the sound denoted ʒ in IPA is ZH in ARPAbet. In […]\nARPAbet and the Major mnemonic system first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/29/arpabet-major/",
          "publishedOn": "2023-07-30T01:16:20.000Z",
          "wordCount": 1876,
          "title": "ARPAbet and the Major mnemonic system",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=200647",
          "author": "John",
          "description": "A few days ago I wrote about Jaccard distance, a way of defining a distance between sets. The Ruzsa distance is similar, except it defines the distance between two subsets of an Abelian group. Subset difference Let A and B be two subsets of an Abelian (commutative) group G. Then the difference A − B […]\nRuzsa distance first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/29/ruzsa-distance/",
          "publishedOn": "2023-07-29T16:02:57.000Z",
          "wordCount": 1679,
          "title": "Ruzsa distance",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=200444",
          "author": "John",
          "description": "A function f of a complex variable z = x + iy can be factored into real and imaginary parts: where x and y are real numbers, and u and v are real-valued functions of two real values. Suppose you are given u(x, y) and you want to find v(x, y). The function v is called […]\nFinding the imaginary part of an analytic function from the real part first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/28/harmonic-conjugate/",
          "publishedOn": "2023-07-28T15:18:10.000Z",
          "wordCount": 1584,
          "title": "Finding the imaginary part of an analytic function from the real part",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=200310",
          "author": "John",
          "description": "It’s well known that the population of Japan has been decreasing for years, and so I was a little puzzled by a recent headline saying that Japan’s population has dropped in every one of its 47 prefectures. Although the national population is in decline, until now not all of the nation’s 47 prefectures dropped in […]\nEvery Japanese prefecture shrinking first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/27/japanese-population/",
          "publishedOn": "2023-07-27T16:21:46.000Z",
          "wordCount": 1520,
          "title": "Every Japanese prefecture shrinking",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=200287",
          "author": "John",
          "description": "Named entity recognition (NER) is a task of natural language processing: pull out named things text. It sounds like trivial at first. Just create a giant list of named things and compare against that. But suppose, for example, University of Texas is on your list. If Texas is also on your list, do you report […]\nNamed entity recognition first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/27/ner/",
          "publishedOn": "2023-07-27T15:05:06.000Z",
          "wordCount": 1619,
          "title": "Named entity recognition",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=200061",
          "author": "John",
          "description": "Jaccard index is a way of measuring the similarity of sets. The Jaccard index, or Jaccard similarity coefficient, of two sets A and B is the number of elements in their intersection, A ∩ B, divided by the number of elements in their union, A ∪ B. Jaccard similarity is a robust way to compare […]\nJaccard index and jazz albums first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/26/jaccard-jazz/",
          "publishedOn": "2023-07-26T08:47:26.000Z",
          "wordCount": 1640,
          "title": "Jaccard index and jazz albums",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=200007",
          "author": "John",
          "description": "It’s not fair to evaluate NLP software on a language it wasn’t designed to process, but I wanted to try it anyway. The models in the spaCy software library were trained on modern English text and not on Middle English. Nevertheless, spaCy does a pretty good job of parsing Chaucer’s Canterbury Tales, written over 600 […]\nTrying NLP on Middle English first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/25/nlp-chaucer/",
          "publishedOn": "2023-07-25T18:15:23.000Z",
          "wordCount": 1379,
          "title": "Trying NLP on Middle English",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=199970",
          "author": "John",
          "description": "For a positive integer n, the nth harmonic number is defined to be the sum of the reciprocals of the first n positive integers: How might we extend this definition so that n does not have to be a positive integer? First approach One way to extend harmonic numbers is as follows. Start with the […]\nExtending harmonic numbers first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/25/extending-harmonic-numbers/",
          "publishedOn": "2023-07-25T14:58:51.000Z",
          "wordCount": 1494,
          "title": "Extending harmonic numbers",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=199949",
          "author": "John",
          "description": "Very often when a number is large, and we don’t know or care exactly how large it is, we can model it as infinite. This may make no practical difference and can make calculations much easier. I give several examples of this in the article Infinite is easier than big. When you run across a […]\nA note on Zipf’s law first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/25/a-note-on-zipfs-law/",
          "publishedOn": "2023-07-25T11:18:26.000Z",
          "wordCount": 1936,
          "title": "A note on Zipf’s law",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=199788",
          "author": "John",
          "description": "I recently evaluated two software applications designed to find PII (personally identifiable information) in free text using natural language processing. Both failed badly, passing over obvious examples of PII. By contrast, I also tried natural language processing software on a nonsensical poem, it the software did quite well. Doctor’s notes It occurred to me later […]\nNatural language processing and unnatural text first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/24/nlp/",
          "publishedOn": "2023-07-24T13:50:42.000Z",
          "wordCount": 1862,
          "title": "Natural language processing and unnatural text",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=199672",
          "author": "John",
          "description": "I recently ran across a paper on typesetting rare Chinese characters. From the abstract: Written Chinese has tens of thousands of characters. But most available fonts contain only around 6 to 12 thousand common characters that can meet the needs of everyday users. However, in publications and information exchange in many professional fields, a number […]\nHow rare is it to encounter a rare word? first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/23/rare-words/",
          "publishedOn": "2023-07-23T21:01:09.000Z",
          "wordCount": 1586,
          "title": "How rare is it to encounter a rare word?",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=198464",
          "author": "John",
          "description": "Machine learning models occasionally memorize training data. Under the right prompt, a model could return portions of the training data verbatim. If a large language model is trained on deidentified medical data, along with data that overlaps with the medical data, it could potentially leak details of a person’s medical history. I’m not saying that […]\nHow an LLM might leak medical data first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/23/ai-leak-medical-data/",
          "publishedOn": "2023-07-23T17:58:09.000Z",
          "wordCount": 1628,
          "title": "How an LLM might leak medical data",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=198983",
          "author": "John",
          "description": "A few days ago I wrote about U-statistics, statistics which can be expressed as the average of a symmetric function over all combinations of elements of a set. V-statistics can be written as an average of over all products of elements of a set. Let S be a statistical sample of size n and let […]\nV-statistics first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/19/v-statistics/",
          "publishedOn": "2023-07-19T13:07:28.000Z",
          "wordCount": 1535,
          "title": "V-statistics",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=198855",
          "author": "John",
          "description": "Yesterday I wrote about how you could use the spaCy Python library to find proper nouns in a document. Now suppose you want to refine this and find proper nouns that are the subjects of sentences or proper nouns that are direct objects. This post was motivated by a project in which I needed to […]\nFiltering on how words are being used first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/18/dependency-labels/",
          "publishedOn": "2023-07-18T19:04:41.000Z",
          "wordCount": 1572,
          "title": "Filtering on how words are being used",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=198836",
          "author": "John",
          "description": "I saw a headline saying that donating blood lowers the level of forever chemicals in your body. This post will give a back-of-the-envelope calculation to show that this idea is plausible. Suppose there are chemicals in your bloodstream that do not break down and that your body will not filter out. Suppose you have about […]\nForever chemicals and blood donation first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/18/forever-chemicals/",
          "publishedOn": "2023-07-18T15:58:31.000Z",
          "wordCount": 1561,
          "title": "Forever chemicals and blood donation",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=198685",
          "author": "John",
          "description": "Suppose you want to find all the proper nouns in a document. You could grep for every word that starts with a capital letter with something like grep '\\b[A-Z]\\w+' but this would return the first word of each sentence in addition to the words you’re after. You could grep for capitalized words that are not […]\nSearching for proper nouns first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/17/searching-for-proper-nouns/",
          "publishedOn": "2023-07-17T21:03:33.000Z",
          "wordCount": 1897,
          "title": "Searching for proper nouns",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=198554",
          "author": "John",
          "description": "John Tukey developed his so-called g-and-h distribution to be very flexible, having a wide variety of possible values of skewness and kurtosis. Although the reason for the distribution’s existence is its range of possible skewness and values, calculating the skewness and kurtosis of the distribution is not simple. Definition Let φ be the function of […]\nMoments of Tukey’s g-and-h distribution first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/17/tukey-g-and-h/",
          "publishedOn": "2023-07-17T18:16:15.000Z",
          "wordCount": 1524,
          "title": "Moments of Tukey’s g-and-h distribution",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=198509",
          "author": "John",
          "description": "A symmetric function is a function whose value is unchanged under every permutation of its arguments. The previous post showed how three symmetric functions of the sides of a triangle a + b + c ab + bc + ac abc are related to the perimeter, inner radius, and outer radius. It also mentioned that […]\nSymmetric functions and U-statistics first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/16/symmetric-statistics/",
          "publishedOn": "2023-07-16T17:56:52.000Z",
          "wordCount": 1532,
          "title": "Symmetric functions and U-statistics",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=198477",
          "author": "John",
          "description": "Suppose a triangle T has sides a, b, and c. Let s be the semi-perimeter, i.e. half the perimeter. Let r be the inner radius, the radius of the largest circle that can fit inside T. Let R be the outer radius, the radius of the smallest circle that can enclose T. Then three simple […]\nRelating perimeter, inner radius, outer radius, and sides of a triangle first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/15/perimeter-radius-sides/",
          "publishedOn": "2023-07-15T19:32:50.000Z",
          "wordCount": 1426,
          "title": "Relating perimeter, inner radius, outer radius, and sides of a triangle",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=198452",
          "author": "John",
          "description": "My two previous posts looked at experiments with ChatGPT and Google Bard. This post will look at redoing the same experiments with Microsoft’s Bing Chat: looking for mnemonic encodings and simplifying Boolean expressions. When you open up Bing chat you can select a conversational style: More creative More balanced More precise I chose “more precise” […]\nExperiments with Bing chat first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/15/bing-chat/",
          "publishedOn": "2023-07-15T17:50:51.000Z",
          "wordCount": 1770,
          "title": "Experiments with Bing chat",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=198439",
          "author": "John",
          "description": "I was curious how well LLMs would do at minimizing a Boolean expression, that is, taking a Boolean expression and producing a smaller equivalent expression. I didn’t expect good performance because this problem is more about logic than recall, but sometimes LLMs surprise you, so I wanted to give it a chance. I thought it […]\nBoolean function minimization with AI first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/15/boolean-with-ai/",
          "publishedOn": "2023-07-15T14:14:55.000Z",
          "wordCount": 2007,
          "title": "Boolean function minimization with AI",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=198353",
          "author": "John",
          "description": "The Major mnemonic system encodes numbers as words in order to make them easier to remember. Digits correspond to consonant sounds (not spellings) as explained here. You can use the system ad hoc, improvising an encoding of a word as needed, or you can memorize canonical encodings of numbers, also known as pegs. Pegs have […]\nLarge language models and mnemonics first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/14/major-llm/",
          "publishedOn": "2023-07-14T18:17:59.000Z",
          "wordCount": 2131,
          "title": "Large language models and mnemonics",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=198338",
          "author": "John",
          "description": "Motivating examples The addition theorem for cosine says that and the addition theorem for hyperbolic cosine is analogous, though with a sign change. An addition theorem is a theorem that relates a function’s value at x + y to its values at x and at y. The squaring function satisfies a very simple addition theorem […]\nWhen does a function have an addition theorem? first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/14/addition-laws/",
          "publishedOn": "2023-07-14T14:46:36.000Z",
          "wordCount": 1676,
          "title": "When does a function have an addition theorem?",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=197997",
          "author": "John",
          "description": "In HTML you can mark the language of a piece of text by putting it inside span tags and setting the lang attribute to a two-letter abbreviation. For example, <span lang=\"fr\">Allons enfants de la Patrie, Le jour de gloire est arrivé !<span> indicates that the first two lines of the French national anthem are in […]\nHow to mark a language in HTML first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/12/language-abbreviation/",
          "publishedOn": "2023-07-12T15:33:54.000Z",
          "wordCount": 1580,
          "title": "How to mark a language in HTML",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=197724",
          "author": "John",
          "description": "I mentioned in the previous post that I had been poking around in HTML entities and noticed symbols for Fourier transforms and such. I also noticed HTML entities for Cyrillic letters. These entities have the form & + transliteration + cy;. For example, the Cyrillic letter П is based on the Greek letter Π and […]\nRussian transliteration hack first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/11/russian-transliteration-hack/",
          "publishedOn": "2023-07-11T14:51:23.000Z",
          "wordCount": 1489,
          "title": "Russian transliteration hack",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=197706",
          "author": "John",
          "description": "I was looking through HTML entities and ran across &Fouriertrf;. I searched for all entities ending in trf; and also found &Mellintrf;, &Laplacetrf;, and &zeetrf;. Apparently “trf” stands “transform” and these symbols are intended to be used to represent the Fourier transform, Mellin transform, Laplace transform, and z-transform. You would not know from the Unicode […]\nSymbols for transforms first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/07/11/symbols-for-transforms/",
          "publishedOn": "2023-07-11T13:33:42.000Z",
          "wordCount": 1388,
          "title": "Symbols for transforms",
          "imageUrl": null
        }
      ]
    }
  ],
  "cliVersion": "1.15.1"
}