{
  "sources": [
    {
      "title": "ML in Production",
      "feedUrl": "https://mlinproduction.com/feed",
      "siteUrl": "https://mlinproduction.com",
      "articles": []
    },
    {
      "title": "Blog",
      "feedUrl": "http://machinelearningmastery.com/blog/feed",
      "siteUrl": "https://machinelearningmastery.com/blog/",
      "articles": [
        {
          "id": "https://machinelearningmastery.com/?p=14330",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "The gradient descent algorithm is one of the most popular techniques for training deep neural networks. It has many applications in fields such as computer vision, speech recognition, and natural language processing. While the idea of gradient descent has been around for decades, it’s only recently that it’s been applied to applications related to deep […]\nThe post Implementing Gradient Descent in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/implementing-gradient-descent-in-pytorch/",
          "publishedOn": "2022-11-26T20:28:14.000Z",
          "wordCount": 7592,
          "title": "Implementing Gradient Descent in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/michael-behrens-DA-iYgv8kjE-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14318",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Linear regression is a simple yet powerful technique for predicting the values of variables based on other variables. It is often used for modeling relationships between two or more continuous variables, such as the relationship between income and age, or the relationship between weight and height. Likewise, linear regression can be used to predict continuous […]\nThe post Training a Linear Regression Model in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/training-a-linear-regression-model-in-pytorch/",
          "publishedOn": "2022-11-24T17:24:24.000Z",
          "wordCount": 7119,
          "title": "Training a Linear Regression Model in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/ryan-tasto-chbXE4o0ryU-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14311",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Linear regression is a statistical technique for estimating the relationship between two variables. A simple example of linear regression is to predict the height of someone based on the square root of the person’s weight (that’s what BMI is based on). To do this, we need to find the slope and intercept of the line. […]\nThe post Making Linear Predictions in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/making-linear-predictions-in-pytorch/",
          "publishedOn": "2022-11-24T04:11:30.000Z",
          "wordCount": 6417,
          "title": "Making Linear Predictions in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/daryan-shamkhali-pMCbPPPBSkA-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14301",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Structuring the data pipeline in a way that it can be effortlessly linked to your deep learning model is an important aspect of any deep learning-based system. PyTorch packs everything to do just that. While in the previous tutorial, we used simple datasets, we’ll need to work with larger datasets in real world scenarios in […]\nThe post Loading and Providing Datasets in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/loading-and-providing-datasets-in-pytorch/",
          "publishedOn": "2022-11-19T01:57:22.000Z",
          "wordCount": 5933,
          "title": "Loading and Providing Datasets in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/uriel-sc-11KDtiUWRq4-unsplash-scaled.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14298",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "In machine learning and deep learning problems, a lot of effort goes into preparing the data. Data is usually messy and needs to be preprocessed before it can be used for training a model. If the data is not prepared correctly, the model won’t be able to generalize well. Some of the common steps required […]\nThe post Using Dataset Classes in PyTorch appeared first on MachineLearningMastery.com.",
          "link": "https://machinelearningmastery.com/using-dataset-classes-in-pytorch/",
          "publishedOn": "2022-11-17T01:55:54.000Z",
          "wordCount": 6445,
          "title": "Using Dataset Classes in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/nasa-1lfI7wkGWZ4-unsplash.jpg"
        },
        {
          "id": "https://35.82.237.216/?p=13195",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Derivatives are one of the most fundamental concepts in calculus. They describe how changes in the variable inputs affect the function outputs. The objective of this article is to provide a high-level introduction to calculating derivatives in PyTorch for those who are new to the framework. PyTorch offers a convenient way to calculate derivatives for […]\nThe post Calculating Derivatives in PyTorch appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/calculating-derivatives-in-pytorch/",
          "publishedOn": "2022-11-11T21:30:18.000Z",
          "wordCount": 6011,
          "title": "Calculating Derivatives in PyTorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/01/jossuha-theophile-H-CZjCQfsFw-unsplash.jpg"
        },
        {
          "id": "https://35.82.237.216/?p=13183",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "Two-dimensional tensors are analogous to two-dimensional metrics. Like a two-dimensional metric, a two-dimensional tensor also has $n$ number of rows and columns. Let’s take a gray-scale image as an example, which is a two-dimensional matrix of numeric values, commonly known as pixels. Ranging from ‘0’ to ‘255’, each number represents a pixel intensity value. Here, […]\nThe post Two-Dimensional Tensors in Pytorch appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/two-dimensional-tensors-in-pytorch/",
          "publishedOn": "2022-11-09T21:30:51.000Z",
          "wordCount": 6286,
          "title": "Two-Dimensional Tensors in Pytorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/01/dylan-nolte-NIrgENd0sAY-unsplash-scaled.jpg"
        },
        {
          "id": "https://35.82.237.216/?p=13157",
          "author": "Muhammad Asad Iqbal Khan",
          "description": "PyTorch is an open-source deep learning framework based on Python language. It allows you to build, train, and deploy deep learning models, offering a lot of versatility and efficiency. PyTorch is primarily focused on tensor operations while a tensor can be a number, matrix, or a multi-dimensional array. In this tutorial, we will perform some […]\nThe post One-Dimensional Tensors in Pytorch appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/one-dimensional-tensors-in-pytorch/",
          "publishedOn": "2022-11-07T21:30:13.000Z",
          "wordCount": 6633,
          "title": "One-Dimensional Tensors in Pytorch",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2021/12/jo-szczepanska-9OKGEVJiTKk-unsplash.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14064",
          "author": "MLM Team",
          "description": "Sponsored Post   The unlimited access initiative presents a risk-free way to break into data science.     The online educational platform 365 Data Science launches the #21DaysFREE campaign and provides 100% free unlimited access to all content for three weeks. From November 1 to 21, you can take courses from renowned instructors and earn […]\nThe post 365 Data Science courses free until November 21 appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/365-data-science-courses-free-until-november-21/",
          "publishedOn": "2022-11-02T15:50:51.000Z",
          "wordCount": 4628,
          "title": "365 Data Science courses free until November 21",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/11/mlm-365ds-20221102-1.jpg"
        },
        {
          "id": "https://machinelearningmastery.com/?p=14006",
          "author": "MLM Team",
          "description": "Sponsored Post      Attend the Data Science Symposium 2022 on November 8 The Center for Business Analytics at the University of Cincinnati will present its annual Data Science Symposium 2022 on November 8. This all day in-person event will have three featured speakers and two tech talk tracks with four concurrent presentations in each track. The […]\nThe post Attend the Data Science Symposium 2022, November 8 in Cincinnati appeared first on Machine Learning Mastery.",
          "link": "https://machinelearningmastery.com/uccsb-data-science-symposium-2022-cincinnati/",
          "publishedOn": "2022-11-01T15:16:00.000Z",
          "wordCount": 3115,
          "title": "Attend the Data Science Symposium 2022, November 8 in Cincinnati",
          "imageUrl": "https://machinelearningmastery.com/wp-content/uploads/2022/10/mlm-uccsb-221018.png"
        }
      ]
    },
    {
      "title": "Machine Learning Archives - Uber Engineering Blog",
      "feedUrl": "https://eng.uber.com/tag/machine-learning/feed",
      "siteUrl": null,
      "articles": []
    },
    {
      "title": "AWS Machine Learning Blog",
      "feedUrl": "https://aws.amazon.com/blogs/machine-learning/feed",
      "siteUrl": "https://aws.amazon.com/blogs/machine-learning/",
      "articles": [
        {
          "id": "1ec3e0ea3ef6c904f91e4c2db436ba1cfed7514b",
          "author": "Sovik Nath",
          "description": "Multi-modal data is a valuable component of the financial industry, encompassing market, economic, customer, news and social media, and risk data. Financial organizations generate, collect, and use this data to gain insights into financial operations, make better decisions, and improve performance. However, there are challenges associated with multi-modal data due to the complexity and lack […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/generative-ai-and-multi-modal-agents-in-aws-the-key-to-unlocking-new-value-in-financial-markets/",
          "publishedOn": "2023-09-19T16:23:49.000Z",
          "wordCount": 5051,
          "title": "Generative AI and multi-modal agents in AWS: The key to unlocking new value in financial markets",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/08/Picture1-6-1203x630.png"
        },
        {
          "id": "d50057e8a0398ec935e831448aff8cb436a18a1a",
          "author": "Adir Sharabi",
          "description": "This post is written in collaboration with Dima Zadorozhny and Fuad Babaev from VirtuSwap. VirtuSwap is a startup company developing innovative technology for decentralized exchange of assets on blockchains. VirtuSwap’s technology provides more efficient trading for assets that don’t have a direct pair between them. The absence of a direct pair leads to costly indirect trading, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/how-virtuswap-accelerates-their-pandas-based-trading-simulations-with-an-amazon-sagemaker-studio-custom-container-and-aws-gpu-instances/",
          "publishedOn": "2023-09-19T16:16:53.000Z",
          "wordCount": 2692,
          "title": "How VirtuSwap accelerates their pandas-based trading simulations with an Amazon SageMaker Studio custom container and AWS GPU instances",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/19/virtuswap-sagemaker-studio.jpg"
        },
        {
          "id": "a61e18b8cd9edd926ef8c8226f14bf98683b7024",
          "author": "Dhaval Shah",
          "description": "Amazon SageMaker Feature Store provides an end-to-end solution to automate feature engineering for machine learning (ML). For many ML use cases, raw data like log files, sensor readings, or transaction records need to be transformed into meaningful features that are optimized for model training. Feature quality is critical to ensure a highly accurate ML model. […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/unlock-ml-insights-using-the-amazon-sagemaker-feature-store-feature-processor/",
          "publishedOn": "2023-09-19T16:08:57.000Z",
          "wordCount": 3667,
          "title": "Unlock ML insights using the Amazon SageMaker Feature Store Feature Processor",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/19/unlock-ml-insights-feature-store.jpg"
        },
        {
          "id": "fc0e0e9bf65f563699ab2e3085fa359225a66db7",
          "author": "Raju Rangan",
          "description": "Machine learning (ML) is becoming increasingly complex as customers try to solve more and more challenging problems. This complexity often leads to the need for distributed ML, where multiple machines are used to train a single model. Although this enables parallelization of tasks across multiple nodes, leading to accelerated training times, enhanced scalability, and improved […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/orchestrate-ray-based-machine-learning-workflows-using-amazon-sagemaker/",
          "publishedOn": "2023-09-18T17:54:56.000Z",
          "wordCount": 3867,
          "title": "Orchestrate Ray-based machine learning workflows using Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/11/DBBLOG_15189_image1.jpng_-716x630.png"
        },
        {
          "id": "2037251e722b8f1a9d5985fbd064c9c71a7f93e7",
          "author": "Richard Alexander",
          "description": "This post is co-authored with Richard Alexander and Mark Hallows from Arup. Arup is a global collective of designers, consultants, and experts dedicated to sustainable development. Data underpins Arup consultancy for clients with world-class collection and analysis providing insight to make an impact. The solution presented here is to direct decision-making processes for resilient city […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/designing-resilient-cities-at-arup-using-amazon-sagemaker-geospatial-capabilities/",
          "publishedOn": "2023-09-18T17:52:40.000Z",
          "wordCount": 2804,
          "title": "Designing resilient cities at Arup using Amazon SageMaker geospatial capabilities",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/07/ml-11881_visualisation-1100x630.png"
        },
        {
          "id": "3078dbf5dded8b902326930cc4c8eaed55ce699b",
          "author": "John Hwang",
          "description": "Large language model (LLM) agents are programs that extend the capabilities of standalone LLMs with 1) access to external tools (APIs, functions, webhooks, plugins, and so on), and 2) the ability to plan and execute tasks in a self-directed fashion. Often, LLMs need to interact with other software, databases, or APIs to accomplish complex tasks. […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/learn-how-to-build-and-deploy-tool-using-llm-agents-using-aws-sagemaker-jumpstart-foundation-models/",
          "publishedOn": "2023-09-15T15:24:36.000Z",
          "wordCount": 3809,
          "title": "Learn how to build and deploy tool-using LLM agents using AWS SageMaker JumpStart Foundation Models",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/31/ML-15042-solution-overview.jpg"
        },
        {
          "id": "60ba0e07738ad3e7fc6a1a59aa323e2926cb5ba2",
          "author": "Yanyan Zhang",
          "description": "In first part of this multi-series blog post, you will learn how to create a scalable training pipeline and prepare training data for Comprehend Custom Classification models. We will introduce a custom classifier training pipeline that can be deployed in your AWS account with few clicks.",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-a-classification-pipeline-with-amazon-comprehend-custom-classification-part-i/",
          "publishedOn": "2023-09-14T16:58:16.000Z",
          "wordCount": 3113,
          "title": "Build a classification pipeline with Amazon Comprehend custom classification (Part I)",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/01/ML14789_1_image_1.jpg"
        },
        {
          "id": "79e9de80c1ca72d14b38bb721ea7c350683f1306",
          "author": "Bruno Pistone",
          "description": "Today, generative AI models cover a variety of tasks from text summarization, Q&A, and image and video generation. To improve the quality of output, approaches like n-short learning, Prompt engineering, Retrieval Augmented Generation (RAG) and fine tuning are used. Fine-tuning allows you to adjust these generative AI models to achieve improved performance on your domain-specific […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/fine-tune-falcon-7b-and-other-llms-on-amazon-sagemaker-with-remote-decorator/",
          "publishedOn": "2023-09-14T16:53:48.000Z",
          "wordCount": 2542,
          "title": "Fine-tune Falcon 7B and other LLMs on Amazon SageMaker with @remote decorator",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/14/fine-tune-falcon-7b-1260x630.jpg"
        },
        {
          "id": "f373585d90ca2452a8f575b61523a3b5d9993d14",
          "author": "Abhishek Maligehalli Shivalingaiah",
          "description": "This post takes you through the most common challenges that customers face when searching internal documents, and gives you concrete guidance on how AWS services can be used to create a generative AI conversational bot that makes internal information more useful. Unstructured data accounts for 80% of all the data found within organizations, consisting of […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/simplify-access-to-internal-information-using-retrieval-augmented-generation-and-langchain-agents/",
          "publishedOn": "2023-09-14T16:47:56.000Z",
          "wordCount": 4175,
          "title": "Simplify access to internal information using Retrieval Augmented Generation and LangChain Agents",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/14/DBSBLOG-14696_Image_10-1057x630.jpg"
        },
        {
          "id": "40be6ff2f4544c5a10bacc0b64db35ad113ba178",
          "author": "Clark Lefavour",
          "description": "Searching for insights in a repository of free-form text documents can be like finding a needle in a haystack. A traditional approach might be to use word counting or other basic analysis to parse documents, but with the power of Amazon AI and machine learning (ML) tools, we can gather deeper understanding of the content. […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/visualize-an-amazon-comprehend-analysis-with-a-word-cloud-in-amazon-quicksight/",
          "publishedOn": "2023-09-13T16:23:42.000Z",
          "wordCount": 2297,
          "title": "Visualize an Amazon Comprehend analysis with a word cloud in Amazon QuickSight",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/13/visualize-comprehend-wordcloud.jpg"
        },
        {
          "id": "c5176386a69be025f1a39037ff987ad3db274ed8",
          "author": "Vikesh Pandey",
          "description": "Today, we are excited to announce the simplified Quick setup experience in Amazon SageMaker. With this new capability, individual users can launch Amazon SageMaker Studio with default presets in minutes. SageMaker Studio is an integrated development environment (IDE) for machine learning (ML). ML practitioners can perform all ML development steps—from preparing their data to building, […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-simplifies-the-amazon-sagemaker-studio-setup-for-individual-users/",
          "publishedOn": "2023-09-12T16:43:16.000Z",
          "wordCount": 1700,
          "title": "Amazon SageMaker simplifies the Amazon SageMaker Studio setup for individual users",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/12/sagemaker-simplifies-studio-setup.jpg"
        },
        {
          "id": "d0725fec0786bb2853300d9d418b133d27b9b555",
          "author": "Xan Huang",
          "description": "This post addresses the challenge faced by developers and support teams when application logs are presented in languages other than English, making it difficult for them to debug and provide support. The proposed solution uses Amazon Translate to automatically translate non-English logs in CloudWatch, and provides step-by-step guidance on deploying the solution in your environment.",
          "link": "https://aws.amazon.com/blogs/machine-learning/unlocking-language-barriers-translate-application-logs-with-amazon-translate-for-seamless-support/",
          "publishedOn": "2023-09-12T16:09:35.000Z",
          "wordCount": 1705,
          "title": "Unlocking language barriers: Translate application logs with Amazon Translate for seamless support",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/12/unlocking-language-barriers.jpg"
        },
        {
          "id": "c5489b6f165eb2ac2631eadd90827f7f2ed24a2d",
          "author": "Dr. Sandra Schmid",
          "description": "In this post, we share how SageMaker facilitates the data science team at Scalable to manage the lifecycle of a data science project efficiently, namely the email classifier project. The lifecycle starts with the initial phase of data analysis and exploration with SageMaker Studio; moves on to model experimentation and deployment with SageMaker training, inference, and Hugging Face DLCs; and completes with a training pipeline with SageMaker Pipelines integrated with other AWS services",
          "link": "https://aws.amazon.com/blogs/machine-learning/accelerate-client-success-management-through-email-classification-with-hugging-face-on-amazon-sagemaker/",
          "publishedOn": "2023-09-12T16:05:21.000Z",
          "wordCount": 2904,
          "title": "Accelerate client success management through email classification with Hugging Face on Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/12/accelerate-client-success.jpg"
        },
        {
          "id": "22f7ed387fa055294a94c15144ec1400926ee545",
          "author": "Kyle Ulrich",
          "description": "Today, we are excited to announce that the Falcon 180B foundation model developed by Technology Innovation Institute (TII) is available for customers through Amazon SageMaker JumpStart to deploy with one-click for running inference. With a 180-billion-parameter size and trained on a massive 3.5-trillion-token dataset, Falcon 180B is the largest and one of the most performant models with openly accessible weights. You can try out this model with SageMaker JumpStart, a machine learning (ML) hub that provides access to algorithms, models, and ML solutions so you can quickly get started with ML. In this post, we walk through how to discover and deploy the Falcon 180B model via SageMaker JumpStart.",
          "link": "https://aws.amazon.com/blogs/machine-learning/falcon-180b-foundation-model-from-tii-is-now-available-via-amazon-sagemaker-jumpstart/",
          "publishedOn": "2023-09-11T19:33:38.000Z",
          "wordCount": 4094,
          "title": "Falcon 180B foundation model from TII is now available via Amazon SageMaker JumpStart",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/11/featured-images-ml-15533-1120x630.jpg"
        },
        {
          "id": "041be4159eafbea06f31ab34945de025a089c59c",
          "author": "Chen Yang",
          "description": "Amazon SageMaker Domain supports SageMaker machine learning (ML) environments, including SageMaker Studio and SageMaker Canvas. SageMaker Studio is a fully integrated development environment (IDE) that provides a single web-based visual interface where you can access purpose-built tools to perform all ML development steps, from preparing data to building, training, and deploying your ML models, improving […]",
          "link": "https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-domain-in-vpc-only-mode-to-support-sagemaker-studio-with-auto-shutdown-lifecycle-configuration-and-sagemaker-canvas-with-terraform/",
          "publishedOn": "2023-09-11T18:36:37.000Z",
          "wordCount": 2870,
          "title": "Amazon SageMaker Domain in VPC only mode to support SageMaker Studio with auto shutdown Lifecycle Configuration and SageMaker Canvas with Terraform",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/29/sagemaker_domain_vpc_only-927x630.png"
        },
        {
          "id": "fe976fb5a78788280176961909b8fbdcfedb0385",
          "author": "Martin Schade",
          "description": "In this post, we’ll take you on a journey to rapidly build and deploy a document search indexing solution that helps your organization to better harness and extract insights from documents. Whether you're in Human Resources looking for specific clauses in employee contracts, or a financial analyst sifting through a mountain of invoices to extract payment data, this solution is tailored to empower you to access the information you need with unprecedented speed and accuracy.",
          "link": "https://aws.amazon.com/blogs/machine-learning/implement-smart-document-search-index-with-amazon-textract-and-amazon-opensearch/",
          "publishedOn": "2023-09-08T16:49:31.000Z",
          "wordCount": 3440,
          "title": "Implement smart document search index with Amazon Textract and Amazon OpenSearch",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/08/featured-images-ML-14699-1120x630.jpg"
        },
        {
          "id": "32141e7ed8f1b05cfb1c03b7caa1e65b3a3cf005",
          "author": "Mark Watkins",
          "description": "Digital publishers are continuously looking for ways to streamline and automate their media workflows in order to generate and publish new content as rapidly as they can. Publishers can have repositories containing millions of images and in order to save money, they need to be able to reuse these images across articles. Finding the image that best matches an article in repositories of this scale can be a time-consuming, repetitive, manual task that can be automated. It also relies on the images in the repository being tagged correctly, which can also be automated (for a customer success story, refer to Aller Media Finds Success with KeyCore and AWS). In this post, we demonstrate how to use Amazon Rekognition, Amazon SageMaker JumpStart, and Amazon OpenSearch Service to solve this business problem.",
          "link": "https://aws.amazon.com/blogs/machine-learning/semantic-image-search-for-articles-using-amazon-rekognition-amazon-sagemaker-foundation-models-and-amazon-opensearch-service/",
          "publishedOn": "2023-09-08T16:38:41.000Z",
          "wordCount": 2864,
          "title": "Semantic image search for articles using Amazon Rekognition, Amazon SageMaker foundation models, and Amazon OpenSearch Service",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/08/featured-images-ML-13969-1120x630.jpg"
        },
        {
          "id": "28574ca0f68ab93372abddb01f00c7e75a49972b",
          "author": "Travis Bronson",
          "description": "Machine learning (ML) is transforming every industry, process, and business, but the path to success is not always straightforward. In this blog post, we demonstrate how Duke Energy, a Fortune 150 company headquartered in Charlotte, NC., collaborated with the AWS Machine Learning Solutions Lab (MLSL) to use computer vision to automate the inspection of wooden utility poles and help prevent power outages, property damage and even injuries.",
          "link": "https://aws.amazon.com/blogs/machine-learning/improving-asset-health-and-grid-resilience-using-machine-learning/",
          "publishedOn": "2023-09-08T16:27:38.000Z",
          "wordCount": 3954,
          "title": "Improving asset health and grid resilience using machine learning",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/08/featured-images-ML-14116-1120x630.jpg"
        },
        {
          "id": "ecca70c5e391cc3bd7c991bb1f05a56b1596d6f2",
          "author": "Walt Mayfield",
          "description": "In this post, we will build an end-to-end solution to find optimal control policies using only historical data on Amazon SageMaker using Ray’s RLlib library. To learn more about reinforcement learning, see Use Reinforcement Learning with Amazon SageMaker.",
          "link": "https://aws.amazon.com/blogs/machine-learning/optimize-equipment-performance-with-historical-data-ray-and-amazon-sagemaker/",
          "publishedOn": "2023-09-07T18:31:07.000Z",
          "wordCount": 2985,
          "title": "Optimize equipment performance with historical data, Ray, and Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/07/featured-images-ML-14215-1120x630.jpg"
        },
        {
          "id": "5e117253e88439ed033ed8e7c7b6b530a4f7afc0",
          "author": "Amr Ragab",
          "description": "This post details how to set up container-based GPU metrics and provides an example of collecting these metrics from EKS pods.",
          "link": "https://aws.amazon.com/blogs/machine-learning/enable-pod-based-gpu-metrics-in-amazon-cloudwatch/",
          "publishedOn": "2023-09-07T18:14:26.000Z",
          "wordCount": 4648,
          "title": "Enable pod-based GPU metrics in Amazon CloudWatch",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/07/featured-images-ML-14691-1120x630.jpg"
        },
        {
          "id": "1220c17c0fa90bbc145df3fde4359eec4fd06f4f",
          "author": "Pinak Panigrahi",
          "description": "In this post, we provide some best practices to maximize the value of SageMaker Pipelines and make the development experience seamless. We also discuss some common design scenarios and patterns when building SageMaker Pipelines and provide examples for addressing them.",
          "link": "https://aws.amazon.com/blogs/machine-learning/best-practices-and-design-patterns-for-building-machine-learning-workflows-with-amazon-sagemaker-pipelines/",
          "publishedOn": "2023-09-07T17:54:33.000Z",
          "wordCount": 3236,
          "title": "Best practices and design patterns for building machine learning workflows with Amazon SageMaker Pipelines",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/31/featured-images-ML-13407-1120x630.jpg"
        },
        {
          "id": "9aa7cd8a143cd30ea36fe403a9d7f4847c16b121",
          "author": "Jay Pillai",
          "description": "In this post, we build a secure enterprise application using AWS Amplify that invokes an Amazon SageMaker JumpStart foundation model, Amazon SageMaker endpoints, and Amazon OpenSearch Service to explain how to create text-to-text or text-to-image and Retrieval Augmented Generation (RAG). You can use this post as a reference to build secure enterprise applications in the Generative AI domain using AWS services.",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-a-secure-enterprise-application-with-generative-ai-and-rag-using-amazon-sagemaker-jumpstart/",
          "publishedOn": "2023-09-06T18:01:44.000Z",
          "wordCount": 2245,
          "title": "Build a secure enterprise application with Generative AI and RAG using Amazon SageMaker JumpStart",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/06/featured-images-ML-14330-1120x630.jpg"
        },
        {
          "id": "f693c8216a0964a906c8328754e29aeb7d5ef1eb",
          "author": "Praveen Edem",
          "description": "This post shows you how to configure the Amazon Kendra AEM connector to index your content and search your AEM assets and pages. The connector also ingests the access control list (ACL) information for each document. The ACL information is used to show search results filtered by what a user has access to.",
          "link": "https://aws.amazon.com/blogs/machine-learning/intelligently-search-adobe-experience-manager-content-using-amazon-kendra/",
          "publishedOn": "2023-09-06T17:28:14.000Z",
          "wordCount": 3292,
          "title": "Intelligently search Adobe Experience Manager content using Amazon Kendra",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/06/featured-images-ML-13597-1120x630.jpg"
        },
        {
          "id": "687bea7cc4ef4fd47346e32add3df8a4805f340c",
          "author": "Vivek Madan",
          "description": "Today, we are excited to announce the capability to fine-tune Llama 2 models by Meta using Amazon SageMaker JumpStart. The Llama 2 family of large language models (LLMs) is a collection of pre-trained and fine-tuned generative text models ranging in scale from 7 billion to 70 billion parameters. Fine-tuned LLMs, called Llama-2-chat, are optimized for dialogue use cases.",
          "link": "https://aws.amazon.com/blogs/machine-learning/fine-tune-llama-2-for-text-generation-on-amazon-sagemaker-jumpstart/",
          "publishedOn": "2023-09-06T17:19:16.000Z",
          "wordCount": 13946,
          "title": "Fine-tune Llama 2 for text generation on Amazon SageMaker JumpStart",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/05/featured-images-l-ml-15376-1120x630.jpg"
        },
        {
          "id": "ea25756e89b40718eb3b2122361b56ee1b6cc5dd",
          "author": "James Wu",
          "description": "Recently, generative AI applications have captured widespread attention and imagination. Customers want to deploy generative AI models on GPUs but at the same time are conscious of costs. SageMaker MMEs support GPU instances and is a great option for these types of applications. Today, we are excited to announce TorchServe support for SageMaker MMEs. This new model server support gives you the advantage of all the benefits of MMEs while still using the serving stack that TorchServe customers are most familiar with. In this post, we demonstrate how to host generative AI models, such as Stable Diffusion and Segment Anything Model, on SageMaker MMEs using TorchServe and build a language-guided editing solution that can help artists and content creators develop and iterate their artwork faster.",
          "link": "https://aws.amazon.com/blogs/machine-learning/run-multiple-generative-ai-models-on-gpu-using-amazon-sagemaker-multi-model-endpoints-with-torchserve-and-save-up-to-75-in-inference-costs/",
          "publishedOn": "2023-09-06T17:13:21.000Z",
          "wordCount": 3485,
          "title": "Run multiple generative AI models on GPU using Amazon SageMaker multi-model endpoints with TorchServe and save up to 75% in inference costs",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/05/featured-images-ml-14465-1120x630.jpg"
        },
        {
          "id": "e7a0694b3b6b2b57233a4c3ac9a1d8484e9b5b7f",
          "author": "Gordon Wang",
          "description": "In this post, we introduce a novel method to perform content moderation on image data with multi-modal pre-training and a large language model (LLM). With multi-modal pre-training, we can directly query the image content based on a set of questions of interest and the model will be able to answer these questions. This enables users to chat with the image to confirm if it contains any inappropriate content that violates the organization’s policies. We use the powerful generating capability of LLMs to generate the final decision including safe/unsafe labels and category type. In addition, by designing a prompt, we can make an LLM generate the defined output format, such as JSON format. The designed prompt template allows the LLM to determine if the image violates the moderation policy, identify the category of violation, explain why, and provide the output in a structured JSON format.",
          "link": "https://aws.amazon.com/blogs/machine-learning/build-a-generative-ai-based-content-moderation-solution-on-amazon-sagemaker-jumpstart/",
          "publishedOn": "2023-09-05T17:38:57.000Z",
          "wordCount": 3919,
          "title": "Build a generative AI-based content moderation solution on Amazon SageMaker JumpStart",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/05/featured-images-ML-14979-1120x630.jpg"
        },
        {
          "id": "263e0868397fe3edea37876397aa691be741e67f",
          "author": "Ravi Patankar",
          "description": "In this post, we show how the Carrier and AWS teams applied ML to predict faults across large fleets of equipment using a single model. We first highlight how we use AWS Glue for highly parallel data processing. We then discuss how Amazon SageMaker helps us with feature engineering and building a scalable supervised deep learning model.",
          "link": "https://aws.amazon.com/blogs/machine-learning/how-carrier-predicts-hvac-faults-using-aws-glue-and-amazon-sagemaker/",
          "publishedOn": "2023-09-05T17:25:12.000Z",
          "wordCount": 2971,
          "title": "How Carrier predicts HVAC faults using AWS Glue and Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/05/featured-images-ML-12208-1120x630.jpg"
        },
        {
          "id": "18bb146de8bb197fdbcb8b220a5e08e07928a1b4",
          "author": "Davide Gallitelli",
          "description": "In this post, we target these situations and solve the problem of risking high costs by deploying large foundation models to Amazon SageMaker asynchronous endpoints from Amazon SageMaker JumpStart. This can help cut costs of the architecture, allowing the endpoint to run only when requests are in the queue and for a short time-to-live, while scaling down to zero when no requests are waiting to be serviced. This sounds great for a lot of use cases; however, an endpoint that has scaled down to zero will introduce a cold start time before being able to serve inferences.",
          "link": "https://aws.amazon.com/blogs/machine-learning/optimize-deployment-cost-of-amazon-sagemaker-jumpstart-foundation-models-with-amazon-sagemaker-asynchronous-endpoints/",
          "publishedOn": "2023-09-05T17:13:21.000Z",
          "wordCount": 3099,
          "title": "Optimize deployment cost of Amazon SageMaker JumpStart foundation models with Amazon SageMaker asynchronous endpoints",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/05/featured-images-ML-14973-1120x630.jpg"
        },
        {
          "id": "a65ac66a876910f1f40afb807b4df51bb6f6b2cb",
          "author": "Raghu Ramesha",
          "description": "We’re excited to announce the availability of response streaming through Amazon SageMaker real-time inference. Now you can continuously stream inference responses back to the client when using SageMaker real-time inference to help you build interactive experiences for generative AI applications such as chatbots, virtual assistants, and music generators. With this new feature, you can start streaming the responses immediately when they’re available instead of waiting for the entire response to be generated. This lowers the time-to-first-byte for your generative AI applications. In this post, we’ll show how to build a streaming web application using SageMaker real-time endpoints with the new response streaming feature for an interactive chat use case. We use Streamlit for the sample demo application UI.",
          "link": "https://aws.amazon.com/blogs/machine-learning/elevating-the-generative-ai-experience-introducing-streaming-support-in-amazon-sagemaker-hosting/",
          "publishedOn": "2023-09-01T16:53:42.000Z",
          "wordCount": 3655,
          "title": "Elevating the generative AI experience: Introducing streaming support in Amazon SageMaker hosting",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/31/featured-images-ML-15289-1120x630.jpg"
        },
        {
          "id": "f57257f0a6ff9fa1d4563306a4444f6a524f2df8",
          "author": "Sokratis Kartakis",
          "description": "Nowadays, the majority of our customers is excited about large language models (LLMs) and thinking how generative AI could transform their business. However, bringing such solutions and models to the business-as-usual operations is not an easy task. In this post, we discuss how to operationalize generative AI applications using MLOps principles leading to foundation model operations (FMOps). Furthermore, we deep dive on the most common generative AI use case of text-to-text applications and LLM operations (LLMOps), a subset of FMOps. The following figure illustrates the topics we discuss.",
          "link": "https://aws.amazon.com/blogs/machine-learning/fmops-llmops-operationalize-generative-ai-and-differences-with-mlops/",
          "publishedOn": "2023-09-01T15:33:46.000Z",
          "wordCount": 6949,
          "title": "FMOps/LLMOps: Operationalize generative AI and differences with MLOps",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/01/featured-images-ML-14962-1120x630.jpg"
        },
        {
          "id": "24cf4b919072467da3f578e4887de32302095aa9",
          "author": "Vishal Naik",
          "description": "One of the tools available as part of the ML governance is Amazon SageMaker Model Cards, which has the capability to create a single source of truth for model information by centralizing and standardizing documentation throughout the model lifecycle. SageMaker model cards enable you to standardize how models are documented, thereby achieving visibility into the lifecycle of a model, from designing, building, training, and evaluation. Model cards are intended to be a single source of truth for business and technical metadata about the model that can reliably be used for auditing and documentation purposes. They provide a fact sheet of the model that is important for model governance.",
          "link": "https://aws.amazon.com/blogs/machine-learning/use-amazon-sagemaker-model-cards-sharing-to-improve-model-governance/",
          "publishedOn": "2023-08-31T18:11:14.000Z",
          "wordCount": 3101,
          "title": "Use Amazon SageMaker Model Cards sharing to improve model governance",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/09/06/featured-images-ML-15149-1-1120x630.jpg"
        },
        {
          "id": "24cf4b919072467da3f578e4887de32302095aa9",
          "author": "Vishal Naik",
          "description": "One of the tools available as part of the ML governance is Amazon SageMaker Model Cards, which has the capability to create a single source of truth for model information by centralizing and standardizing documentation throughout the model lifecycle. SageMaker model cards enable you to standardize how models are documented, thereby achieving visibility into the lifecycle of a model, from designing, building, training, and evaluation. Model cards are intended to be a single source of truth for business and technical metadata about the model that can reliably be used for auditing and documentation purposes. They provide a fact sheet of the model that is important for model governance.",
          "link": "https://aws.amazon.com/blogs/machine-learning/use-amazon-sagemaker-model-card-sharing-to-improve-model-governance/",
          "publishedOn": "2023-08-31T18:11:14.000Z",
          "wordCount": 3101,
          "title": "Use Amazon SageMaker Model Card sharing to improve model governance",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/31/featured-images-ML-15149-1120x630.jpg"
        },
        {
          "id": "9cc8f0ba3d8995c7b4ab2a55da7251a032afe12a",
          "author": "Clevester Teo",
          "description": "Powered by Amazon Lex, the QnABot on AWS solution is an open-source, multi-channel, multi-language conversational chatbot. QnABot allows you to quickly deploy self-service conversational AI into your contact center, websites, and social media channels, reducing costs, shortening hold times, and improving customer experience and brand sentiment. In this post, we introduce the new Generative AI features for QnABot and walk through a tutorial to create, deploy, and customize QnABot to use these features. We also discuss some relevant use cases.",
          "link": "https://aws.amazon.com/blogs/machine-learning/deploy-self-service-question-answering-with-the-qnabot-on-aws-solution-powered-by-amazon-lex-with-amazon-kendra-and-large-language-models/",
          "publishedOn": "2023-08-30T20:07:52.000Z",
          "wordCount": 3752,
          "title": "Deploy self-service question answering with the QnABot on AWS solution powered by Amazon Lex with Amazon Kendra and large language models",
          "enclosure": {
            "length": "117930224",
            "type": "video/mp4",
            "url": "https://d2908q01vomqb2.cloudfront.net/artifacts/DBSBlogs/ML-14990/qnabot540_v2.mp4"
          },
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/30/featured-images-ML-14990-1120x630.jpg"
        },
        {
          "id": "95c41f299d9321d375f39e16b69fcaa1025c9f6b",
          "author": "Adewale Akinfaderin",
          "description": "This post demonstrates a strategy for fine-tuning publicly available LLMs for the task of radiology report summarization using AWS services. LLMs have demonstrated remarkable capabilities in natural language understanding and generation, serving as foundation models that can be adapted to various domains and tasks. There are significant benefits to using a pre-trained model. It reduces computation costs, reduces carbon footprints, and allows you to use state-of-the-art models without having to train one from scratch.",
          "link": "https://aws.amazon.com/blogs/machine-learning/automatically-generate-impressions-from-findings-in-radiology-reports-using-generative-ai-on-aws/",
          "publishedOn": "2023-08-30T17:08:21.000Z",
          "wordCount": 3897,
          "title": "Automatically generate impressions from findings in radiology reports using generative AI on AWS",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/30/featured-images-ML-14850-1120x630.jpg"
        },
        {
          "id": "e388f6930b6f026b41beb934aafd7169802d2fed",
          "author": "Hasan Shojaei",
          "description": "In this post, we describe how to create an MLOps workflow for batch inference that automates job scheduling, model monitoring, retraining, and registration, as well as error handling and notification by using Amazon SageMaker, Amazon EventBridge, AWS Lambda, Amazon Simple Notification Service (Amazon SNS), HashiCorp Terraform, and GitLab CI/CD. The presented MLOps workflow provides a reusable template for managing the ML lifecycle through automation, monitoring, auditability, and scalability, thereby reducing the complexities and costs of maintaining batch inference workloads in production.",
          "link": "https://aws.amazon.com/blogs/machine-learning/mlops-for-batch-inference-with-model-monitoring-and-retraining-using-amazon-sagemaker-hashicorp-terraform-and-gitlab-ci-cd/",
          "publishedOn": "2023-08-29T16:33:31.000Z",
          "wordCount": 4422,
          "title": "MLOps for batch inference with model monitoring and retraining using Amazon SageMaker, HashiCorp Terraform, and GitLab CI/CD",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/29/featured-images-ML-10695-1120x630.jpg"
        },
        {
          "id": "a4982cd1c8551000d7dbd1307b1b0c6c7e220ab1",
          "author": "Neha Narwal",
          "description": "As part of the 2023 Data Science Conference (DSCO 23), AWS partnered with the Data Institute at the University of San Francisco (USF) to conduct a datathon. Participants, both high school and undergraduate students, competed on a data science project that focused on air quality and sustainability. The Data Institute at the USF aims to support cross-disciplinary research and education in the field of data science. The Data Institute and the Data Science Conference provide a distinctive fusion of cutting-edge academic research and the entrepreneurial culture of the technology industry in the San Francisco Bay Area.",
          "link": "https://aws.amazon.com/blogs/machine-learning/university-of-san-francisco-data-science-conference-2023-datathon-in-partnership-with-aws-and-amazon-sagemaker-studio-lab/",
          "publishedOn": "2023-08-28T18:10:34.000Z",
          "wordCount": 1430,
          "title": "University of San Francisco Data Science Conference 2023 Datathon in partnership with AWS and Amazon SageMaker Studio Lab",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/28/featured-images-ML-14400-1-1120x630.jpg"
        },
        {
          "id": "2b4ded6f5b3decbb9247693921a8e40f17fde6fe",
          "author": "Roy Allela",
          "description": "Today, we’re pleased to announce the preview of Amazon SageMaker Profiler, a capability of Amazon SageMaker that provides a detailed view into the AWS compute resources provisioned during training deep learning models on SageMaker. With SageMaker Profiler, you can track all activities on CPUs and GPUs, such as CPU and GPU utilizations, kernel runs on GPUs, kernel launches on CPUs, sync operations, memory operations across GPUs, latencies between kernel launches and corresponding runs, and data transfer between CPUs and GPUs. In this post, we walk you through the capabilities of SageMaker Profiler.",
          "link": "https://aws.amazon.com/blogs/machine-learning/announcing-the-preview-of-amazon-sagemaker-profiler-track-and-visualize-detailed-hardware-performance-data-for-your-model-training-workloads/",
          "publishedOn": "2023-08-24T21:34:39.000Z",
          "wordCount": 2837,
          "title": "Announcing the Preview of Amazon SageMaker Profiler: Track and visualize detailed hardware performance data for your model training workloads",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/24/featured-images-ml-15127-1120x630.jpg"
        },
        {
          "id": "34d1594b8be6e67eb30745071357836be7d14aaf",
          "author": "Dr. Pandurang Kamat",
          "description": "Persistent Systems, a global digital engineering provider, has run several pilots and formal studies with Amazon CodeWhisperer that point to shifts in software engineering, generative AI-led modernization, responsible innovation, and more. This post highlights four themes emerging from Persistent’s Amazon CodeWhisperer experiments that could change software engineering as we know it.",
          "link": "https://aws.amazon.com/blogs/machine-learning/persistent-systems-shapes-the-future-of-software-engineering-with-amazon-codewhisperer/",
          "publishedOn": "2023-08-23T17:16:59.000Z",
          "wordCount": 2285,
          "title": "Persistent Systems shapes the future of software engineering with Amazon CodeWhisperer",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/23/featured-images-ML-14925-1120x630.jpg"
        },
        {
          "id": "3b985f362fa8f28706d13cce62d783bd15ad0fef",
          "author": "Peter Chung",
          "description": "In this post, we walk you through importing data from, and exporting data to, an S3 access point in SageMaker Data Wrangler.",
          "link": "https://aws.amazon.com/blogs/machine-learning/announcing-amazon-s3-access-point-support-for-amazon-sagemaker-data-wrangler/",
          "publishedOn": "2023-08-22T20:33:48.000Z",
          "wordCount": 1927,
          "title": "Announcing Amazon S3 access point support for Amazon SageMaker Data Wrangler",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/21/featured-images-ML-14476-1120x630.jpg"
        },
        {
          "id": "62342054f1a915e3c40bd557c1f826d20e4032a9",
          "author": "Sherry Ding",
          "description": "In this post, we discuss how to implement federated learning on Amazon SageMaker to run ML with decentralized training data.",
          "link": "https://aws.amazon.com/blogs/machine-learning/machine-learning-with-decentralized-training-data-using-federated-learning-on-amazon-sagemaker/",
          "publishedOn": "2023-08-22T16:24:35.000Z",
          "wordCount": 4043,
          "title": "Machine learning with decentralized training data using federated learning on Amazon SageMaker",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/22/featured-images-ml-12904-1120x630.jpg"
        },
        {
          "id": "07305f1442a1ffa97ef72f97843df0adf14ec85c",
          "author": "Shamika Ariyawansa",
          "description": "In this post, we show how to improve model explainability in clinical settings using Amazon SageMaker Clarify. Explainability of machine learning (ML) models used in the medical domain is becoming increasingly important because models need to be explained from a number of perspectives in order to gain adoption. These perspectives range from medical, technological, legal, and the most important perspective—the patient’s. Models developed on text in the medical domain have become accurate statistically, yet clinicians are ethically required to evaluate areas of weakness related to these predictions in order to provide the best care for individual patients. Explainability of these predictions is required in order for clinicians to make the correct choices on a patient-by-patient basis.",
          "link": "https://aws.amazon.com/blogs/machine-learning/explain-medical-decisions-in-clinical-settings-using-amazon-sagemaker-clarify/",
          "publishedOn": "2023-08-21T18:15:44.000Z",
          "wordCount": 3114,
          "title": "Explain medical decisions in clinical settings using Amazon SageMaker Clarify",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/21/featured-images-ML-6756-1120x630.jpg"
        },
        {
          "id": "1f9bf46681cc00a1af8306d8d0880f7e3642c599",
          "author": "Ajjay Govindaram",
          "description": "We are happy to announce that SageMaker Data Wrangler now supports using Lake Formation with Amazon EMR to provide this fine-grained data access restriction.",
          "link": "https://aws.amazon.com/blogs/machine-learning/apply-fine-grained-data-access-controls-with-aws-lake-formation-in-amazon-sagemaker-data-wrangler/",
          "publishedOn": "2023-08-21T18:03:54.000Z",
          "wordCount": 3723,
          "title": "Apply fine-grained data access controls with AWS Lake Formation in Amazon SageMaker Data Wrangler",
          "imageUrl": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/21/featured-images-ML-14840-1120x630.jpg"
        }
      ]
    },
    {
      "title": "cs.LG updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/cs.LG",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2309.06604",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Esmaeili_A/0/1/0/all/0/1\">Ahmad Esmaeili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rayz_J/0/1/0/all/0/1\">Julia T. Rayz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matson_E/0/1/0/all/0/1\">Eric T. Matson</a>",
          "description": "Algorithm selection and hyperparameter tuning are critical steps in both\nacademic and applied machine learning. On the other hand, these steps are\nbecoming ever increasingly delicate due to the extensive rise in the number,\ndiversity, and distributedness of machine learning resources. Multi-agent\nsystems, when applied to the design of machine learning platforms, bring about\nseveral distinctive characteristics such as scalability, flexibility, and\nrobustness, just to name a few. This paper proposes a fully automatic and\ncollaborative agent-based mechanism for selecting distributedly organized\nmachine learning algorithms and simultaneously tuning their hyperparameters.\nOur method builds upon an existing agent-based hierarchical machine-learning\nplatform and augments its query structure to support the aforementioned\nfunctionalities without being limited to specific learning, selection, and\ntuning mechanisms. We have conducted theoretical assessments, formal\nverification, and analytical study to demonstrate the correctness, resource\nutilization, and computational efficiency of our technique. According to the\nresults, our solution is totally correct and exhibits linear time and space\ncomplexity in relation to the size of available resources. To provide concrete\nexamples of how the proposed methodologies can effectively adapt and perform\nacross a range of algorithmic options and datasets, we have also conducted a\nseries of experiments using a system comprised of 24 algorithms and 9 datasets.",
          "link": "http://arxiv.org/abs/2309.06604",
          "publishedOn": "2023-09-16T00:40:58.245Z",
          "wordCount": 761,
          "title": "Hybrid Algorithm Selection and Hyperparameter Tuning on Distributed Machine Learning Resources: A Hierarchical Agent-based Approach. (arXiv:2309.06604v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.12814",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cook_A/0/1/0/all/0/1\">Andrew Cook</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hammerlindl_A/0/1/0/all/0/1\">Andy Hammerlindl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tucker_W/0/1/0/all/0/1\">Warwick Tucker</a>",
          "description": "We define a family of $C^1$ functions which we call \"nowhere coexpanding\nfunctions\" that is closed under composition and includes all $C^3$ functions\nwith non-positive Schwarzian derivative. We establish results on the number and\nnature of the fixed points of these functions, including a generalisation of a\nclassic result of Singer.",
          "link": "http://arxiv.org/abs/2303.12814",
          "publishedOn": "2023-09-16T00:40:58.227Z",
          "wordCount": 570,
          "title": "Nowhere coexpanding functions. (arXiv:2303.12814v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.06800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mei_H/0/1/0/all/0/1\">Hao Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junxian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Z/0/1/0/all/0/1\">Zhiming Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guanjie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1\">Bin Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1\">Hua Wei</a>",
          "description": "Traffic prediction is a crucial topic because of its broad scope of\napplications in the transportation domain. Recently, various studies have\nachieved promising results. However, most studies assume the prediction\nlocations have complete or at least partial historical records and cannot be\nextended to non-historical recorded locations. In real-life scenarios, the\ndeployment of sensors could be limited due to budget limitations and\ninstallation availability, which makes most current models not applicable.\nThough few pieces of literature tried to impute traffic states at the missing\nlocations, these methods need the data simultaneously observed at the locations\nwith sensors, making them not applicable to prediction tasks. Another drawback\nis the lack of measurement of uncertainty in prediction, making prior works\nunsuitable for risk-sensitive tasks or involving decision-making. To fill the\ngap, inspired by the previous inductive graph neural network, this work\nproposed an uncertainty-aware framework with the ability to 1) extend\nprediction to missing locations with no historical records and significantly\nextend spatial coverage of prediction locations while reducing deployment of\nsensors and 2) generate probabilistic prediction with uncertainty\nquantification to help the management of risk and decision making in the\ndown-stream tasks. Through extensive experiments on real-life datasets, the\nresult shows our method achieved promising results on prediction tasks, and the\nuncertainty quantification gives consistent results which highly correlated\nwith the locations with and without historical data. We also show that our\nmodel could help support sensor deployment tasks in the transportation field to\nachieve higher accuracy with a limited sensor deployment budget.",
          "link": "http://arxiv.org/abs/2309.06800",
          "publishedOn": "2023-09-16T00:40:58.195Z",
          "wordCount": 791,
          "title": "Uncertainty-aware Traffic Prediction under Missing Data. (arXiv:2309.06800v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07158",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rossi_F/0/1/0/all/0/1\">Federico Rossi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cococcioni_M/0/1/0/all/0/1\">Marco Cococcioni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibanez_R/0/1/0/all/0/1\">Roger Ferrer Ib&#xe0;&#xf1;ez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labarta_J/0/1/0/all/0/1\">Jes&#xf9;s Labarta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mantovani_F/0/1/0/all/0/1\">Filippo Mantovani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casas_M/0/1/0/all/0/1\">Marc Casas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruffaldi_E/0/1/0/all/0/1\">Emanuele Ruffaldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saponara_S/0/1/0/all/0/1\">Sergio Saponara</a>",
          "description": "As recently demonstrated, Deep Neural Networks (DNN), usually trained using\nsingle precision IEEE 754 floating point numbers (binary32), can also work\nusing lower precision. Therefore, 16-bit and 8-bit compressed format have\nattracted considerable attention. In this paper, we focused on two families of\nformats that have already achieved interesting results in compressing binary32\nnumbers in machine learning applications, without sensible degradation of the\naccuracy: bfloat and posit. Even if 16-bit and 8-bit bfloat/posit are routinely\nused for reducing the storage of the weights/biases of trained DNNs, the\ninference still often happens on the 32-bit FPU of the CPU (especially if GPUs\nare not available). In this paper we propose a way to decompress a tensor of\nbfloat/posits just before computations, i.e., after the compressed operands\nhave been loaded within the vector registers of a vector capable CPU, in order\nto save bandwidth usage and increase cache efficiency. Finally, we show the\narchitectural parameters and considerations under which this solution is\nadvantageous with respect to the uncompressed one.",
          "link": "http://arxiv.org/abs/2309.07158",
          "publishedOn": "2023-09-16T00:40:58.094Z",
          "wordCount": 696,
          "title": "Compressed Real Numbers for AI: a case-study using a RISC-V CPU. (arXiv:2309.07158v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.00964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cho_M/0/1/0/all/0/1\">Minsik Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vahid_K/0/1/0/all/0/1\">Keivan A. Vahid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Q/0/1/0/all/0/1\">Qichen Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adya_S/0/1/0/all/0/1\">Saurabh Adya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mundo_C/0/1/0/all/0/1\">Carlo C Del Mundo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rastegari_M/0/1/0/all/0/1\">Mohammad Rastegari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naik_D/0/1/0/all/0/1\">Devang Naik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zatloukal_P/0/1/0/all/0/1\">Peter Zatloukal</a>",
          "description": "Since Large Language Models or LLMs have demonstrated high-quality\nperformance on many complex language tasks, there is a great interest in\nbringing these LLMs to mobile devices for faster responses and better privacy\nprotection. However, the size of LLMs (i.e., billions of parameters) requires\nhighly effective compression to fit into storage-limited devices. Among many\ncompression techniques, weight-clustering, a form of non-linear quantization,\nis one of the leading candidates for LLM compression, and supported by modern\nsmartphones. Yet, its training overhead is prohibitively significant for LLM\nfine-tuning. Especially, Differentiable KMeans Clustering, or DKM, has shown\nthe state-of-the-art trade-off between compression ratio and accuracy\nregression, but its large memory complexity makes it nearly impossible to apply\nto train-time LLM compression. In this paper, we propose a memory-efficient DKM\nimplementation, eDKM powered by novel techniques to reduce the memory footprint\nof DKM by orders of magnitudes. For a given tensor to be saved on CPU for the\nbackward pass of DKM, we compressed the tensor by applying uniquification and\nsharding after checking if there is no duplicated tensor previously copied to\nCPU. Our experimental results demonstrate that \\prjname can fine-tune and\ncompress a pretrained LLaMA 7B model from 12.6 GB to 2.5 GB (3bit/weight) with\nthe Alpaca dataset by reducing the train-time memory footprint of a decoder\nlayer by 130$\\times$, while delivering good accuracy on broader LLM benchmarks\n(i.e., 77.7% for PIQA, 66.1% for Winograde, and so on).",
          "link": "http://arxiv.org/abs/2309.00964",
          "publishedOn": "2023-09-16T00:40:57.913Z",
          "wordCount": 788,
          "title": "eDKM: An Efficient and Accurate Train-time Weight Clustering for Large Language Models. (arXiv:2309.00964v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.08841",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Savage_T/0/1/0/all/0/1\">Tom Savage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basha_N/0/1/0/all/0/1\">Nausheen Basha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McDonough_J/0/1/0/all/0/1\">Jonathan McDonough</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matar_O/0/1/0/all/0/1\">Omar K Matar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chanona_E/0/1/0/all/0/1\">Ehecatl Antonio del Rio Chanona</a>",
          "description": "Additive manufacturing has enabled the fabrication of advanced reactor\ngeometries, permitting larger, more complex design spaces. Identifying\npromising configurations within such spaces presents a significant challenge\nfor current approaches. Furthermore, existing parameterisations of reactor\ngeometries are low-dimensional with expensive optimisation limiting more\ncomplex solutions. To address this challenge, we establish a machine\nlearning-assisted approach for the design of the next-generation of chemical\nreactors, combining the application of high-dimensional parameterisations,\ncomputational fluid dynamics, and multi-fidelity Bayesian optimisation. We\nassociate the development of mixing-enhancing vortical flow structures in novel\ncoiled reactors with performance, and use our approach to identify key\ncharacteristics of optimal designs. By appealing to fluid mechanical\nprinciples, we rationalise the selection of novel design features that lead to\nexperimental performance improvements of ~60% over conventional designs. Our\nresults demonstrate that coupling advanced manufacturing techniques with\n`augmented-intelligence' approaches can lead to superior design performance\nand, consequently, emissions-reduction and sustainability.",
          "link": "http://arxiv.org/abs/2308.08841",
          "publishedOn": "2023-09-16T00:40:57.899Z",
          "wordCount": 678,
          "title": "Machine Learning-Assisted Discovery of Novel Reactor Designs. (arXiv:2308.08841v2 [cs.CE] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.01921",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ren_Y/0/1/0/all/0/1\">Yihui Ren</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Kagawa_A/0/1/0/all/0/1\">Ai Kagawa</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Carbone_M/0/1/0/all/0/1\">Matthew R. Carbone</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chen_S/0/1/0/all/0/1\">Samuel Yen-Chi Chen</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Qu_X/0/1/0/all/0/1\">Xiaohui Qu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Yoo_S/0/1/0/all/0/1\">Shinjae Yoo</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Clyde_A/0/1/0/all/0/1\">Austin Clyde</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ramanathan_A/0/1/0/all/0/1\">Arvind Ramanathan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Stevens_R/0/1/0/all/0/1\">Rick L. Stevens</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Dam_H/0/1/0/all/0/1\">Hubertus J. J. van Dam</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Liu_D/0/1/0/all/0/1\">Deyu Liu</a>",
          "description": "Fast screening of drug molecules based on the ligand binding affinity is an\nimportant step in the drug discovery pipeline. Graph neural fingerprint is a\npromising method for developing molecular docking surrogates with high\nthroughput and great fidelity. In this study, we built a COVID-19 drug docking\ndataset of about 300,000 drug candidates on 23 coronavirus protein targets.\nWith this dataset, we trained graph neural fingerprint docking models for\nhigh-throughput virtual COVID-19 drug screening. The graph neural fingerprint\nmodels yield high prediction accuracy on docking scores with the mean squared\nerror lower than $0.21$ kcal/mol for most of the docking targets, showing\nsignificant improvement over conventional circular fingerprint methods. To make\nthe neural fingerprints transferable for unknown targets, we also propose a\ntransferable graph neural fingerprint method trained on multiple targets. With\ncomparable accuracy to target-specific graph neural fingerprint models, the\ntransferable model exhibits superb training and data efficiency. We highlight\nthat the impact of this study extends beyond COVID-19 dataset, as our approach\nfor fast virtual ligand screening can be easily adapted and integrated into a\ngeneral machine learning-accelerated pipeline to battle future bio-threats.",
          "link": "http://arxiv.org/abs/2308.01921",
          "publishedOn": "2023-09-16T00:40:57.886Z",
          "wordCount": 795,
          "title": "Transferable Graph Neural Fingerprint Models for Quick Response to Future Bio-Threats. (arXiv:2308.01921v2 [q-bio.BM] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07398",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chenan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_J/0/1/0/all/0/1\">Jinhao Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chaowei Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_E/0/1/0/all/0/1\">Edward Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stamm_M/0/1/0/all/0/1\">Matthew Stamm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Kaidi Xu</a>",
          "description": "Traditional adversarial attacks concentrate on manipulating clean examples in\nthe pixel space by adding adversarial perturbations. By contrast, semantic\nadversarial attacks focus on changing semantic attributes of clean examples,\nsuch as color, context, and features, which are more feasible in the real\nworld. In this paper, we propose a framework to quickly generate a semantic\nadversarial attack by leveraging recent diffusion models since semantic\ninformation is included in the latent space of well-trained diffusion models.\nThen there are two variants of this framework: 1) the Semantic Transformation\n(ST) approach fine-tunes the latent space of the generated image and/or the\ndiffusion model itself; 2) the Latent Masking (LM) approach masks the latent\nspace with another target image and local backpropagation-based interpretation\nmethods. Additionally, the ST approach can be applied in either white-box or\nblack-box settings. Extensive experiments are conducted on CelebA-HQ and AFHQ\ndatasets, and our framework demonstrates great fidelity, generalizability, and\ntransferability compared to other baselines. Our approaches achieve\napproximately 100% attack success rate in multiple settings with the best FID\nas 36.61. Code is available at\nhttps://github.com/steven202/semantic_adv_via_dm.",
          "link": "http://arxiv.org/abs/2309.07398",
          "publishedOn": "2023-09-16T00:40:57.567Z",
          "wordCount": 695,
          "title": "Semantic Adversarial Attacks via Diffusion Models. (arXiv:2309.07398v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2205.11110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_N/0/1/0/all/0/1\">Ning Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Ruijie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vien_N/0/1/0/all/0/1\">Ngo Anh Vien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziesche_H/0/1/0/all/0/1\">Hanna Ziesche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1\">Gerhard Neumann</a>",
          "description": "Grasping inhomogeneous objects in real-world applications remains a\nchallenging task due to the unknown physical properties such as mass\ndistribution and coefficient of friction. In this study, we propose a\nmeta-learning algorithm called ConDex, which incorporates Conditional Neural\nProcesses (CNP) with DexNet-2.0 to autonomously discern the underlying physical\nproperties of objects using depth images. ConDex efficiently acquires physical\nembeddings from limited trials, enabling precise grasping point estimation.\nFurthermore, ConDex is capable of updating the predicted grasping quality\niteratively from new trials in an online fashion. To the best of our knowledge,\nwe are the first who generate two object datasets focusing on inhomogeneous\nphysical properties with varying mass distributions and friction coefficients.\nExtensive evaluations in simulation demonstrate ConDex's superior performance\nover DexNet-2.0 and existing meta-learning-based grasping pipelines.\nFurthermore, ConDex shows robust generalization to previously unseen real-world\nobjects despite training solely in the simulation. The synthetic and real-world\ndatasets will be published as well.",
          "link": "http://arxiv.org/abs/2205.11110",
          "publishedOn": "2023-09-16T00:40:57.474Z",
          "wordCount": 685,
          "title": "Meta-Learning Regrasping Strategies for Physical-Agnostic Objects. (arXiv:2205.11110v2 [cs.RO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2206.03420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tiehua Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuze Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zhishu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Rui Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiaowei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xi Zheng</a>",
          "description": "Spatial-temporal data contains rich information and has been widely studied\nin recent years due to the rapid development of relevant applications in many\nfields. For instance, medical institutions often use electrodes attached to\ndifferent parts of a patient to analyse the electorencephal data rich with\nspatial and temporal features for health assessment and disease diagnosis.\nExisting research has mainly used deep learning techniques such as\nconvolutional neural network (CNN) or recurrent neural network (RNN) to extract\nhidden spatial-temporal features. Yet, it is challenging to incorporate both\ninter-dependencies spatial information and dynamic temporal changes\nsimultaneously. In reality, for a model that leverages these spatial-temporal\nfeatures to fulfil complex prediction tasks, it often requires a colossal\namount of training data in order to obtain satisfactory model performance.\nConsidering the above-mentioned challenges, we propose an adaptive federated\nrelevance framework, namely FedRel, for spatial-temporal graph learning in this\npaper. After transforming the raw spatial-temporal data into high quality\nfeatures, the core Dynamic Inter-Intra Graph (DIIG) module in the framework is\nable to use these features to generate the spatial-temporal graphs capable of\ncapturing the hidden topological and long-term temporal correlation information\nin these graphs. To improve the model generalization ability and performance\nwhile preserving the local data privacy, we also design a relevance-driven\nfederated learning module in our framework to leverage diverse data\ndistributions from different participants with attentive aggregations of their\nmodels.",
          "link": "http://arxiv.org/abs/2206.03420",
          "publishedOn": "2023-09-16T00:40:57.474Z",
          "wordCount": null,
          "title": "An Adaptive Federated Relevance Framework for Spatial Temporal Graph Learning. (arXiv:2206.03420v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.04612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ying_W/0/1/0/all/0/1\">Wangyang Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dongjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kunpeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Leilei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yanjie Fu</a>",
          "description": "Feature generation aims to generate new and meaningful features to create a\ndiscriminative representation space.A generated feature is meaningful when the\ngenerated feature is from a feature pair with inherent feature interaction. In\nthe real world, experienced data scientists can identify potentially useful\nfeature-feature interactions, and generate meaningful dimensions from an\nexponentially large search space, in an optimal crossing form over an optimal\ngeneration path. But, machines have limited human-like abilities.We generalize\nsuch learning tasks as self-optimizing feature generation. Self-optimizing\nfeature generation imposes several under-addressed challenges on existing\nsystems: meaningful, robust, and efficient generation. To tackle these\nchallenges, we propose a principled and generic representation-crossing\nframework to solve self-optimizing feature generation.To achieve hashing\nrepresentation, we propose a three-step approach: feature discretization,\nfeature hashing, and descriptive summarization. To achieve reinforcement\ncrossing, we develop a hierarchical reinforcement feature crossing approach.We\npresent extensive experimental results to demonstrate the effectiveness and\nefficiency of the proposed method. The code is available at\nhttps://github.com/yingwangyang/HRC_feature_cross.git.",
          "link": "http://arxiv.org/abs/2309.04612",
          "publishedOn": "2023-09-16T00:40:57.469Z",
          "wordCount": 696,
          "title": "Self-optimizing Feature Generation via Categorical Hashing Representation and Hierarchical Reinforcement Crossing. (arXiv:2309.04612v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07808",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hongkuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_A/0/1/0/all/0/1\">Aifen Sui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_W/0/1/0/all/0/1\">Wei Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_L/0/1/0/all/0/1\">Letian Shi</a>",
          "description": "More research attention has recently been given to end-to-end autonomous\ndriving technologies where the entire driving pipeline is replaced with a\nsingle neural network because of its simpler structure and faster inference\ntime. Despite this appealing approach largely reducing the components in\ndriving pipeline, its simplicity also leads to interpretability problems and\nsafety issues arXiv:2003.06404. The trained policy is not always compliant with\nthe traffic rules and it is also hard to discover the reason for the\nmisbehavior because of the lack of intermediate outputs. Meanwhile, Sensors are\nalso critical to autonomous driving's security and feasibility to perceive the\nsurrounding environment under complex driving scenarios. In this paper, we\nproposed P-CSG, a novel penalty-based imitation learning approach with cross\nsemantics generation sensor fusion technologies to increase the overall\nperformance of End-to-End Autonomous Driving. We conducted an assessment of our\nmodel's performance using the Town 05 Long benchmark, achieving an impressive\ndriving score improvement of over 15%. Furthermore, we conducted robustness\nevaluations against adversarial attacks like FGSM and Dot attacks, revealing a\nsubstantial increase in robustness compared to baseline models.More detailed\ninformation, such as code-based resources, ablation studies and videos can be\nfound at https://hk-zh.github.io/p-csg-plus.",
          "link": "http://arxiv.org/abs/2309.07808",
          "publishedOn": "2023-09-16T00:40:57.464Z",
          "wordCount": 732,
          "title": "What Matters to Enhance Traffic Rule Compliance of Imitation Learning for Automated Driving. (arXiv:2309.07808v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07813",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Venkat_A/0/1/0/all/0/1\">Aarthi Venkat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chew_J/0/1/0/all/0/1\">Joyce Chew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_F/0/1/0/all/0/1\">Ferran Cardoso Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tape_C/0/1/0/all/0/1\">Christopher J. Tape</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perlmutter_M/0/1/0/all/0/1\">Michael Perlmutter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnaswamy_S/0/1/0/all/0/1\">Smita Krishnaswamy</a>",
          "description": "Directed graphs are a natural model for many phenomena, in particular\nscientific knowledge graphs such as molecular interaction or chemical reaction\nnetworks that define cellular signaling relationships. In these situations,\nsource nodes typically have distinct biophysical properties from sinks. Due to\ntheir ordered and unidirectional relationships, many such networks also have\nhierarchical and multiscale structure. However, the majority of methods\nperforming node- and edge-level tasks in machine learning do not take these\nproperties into account, and thus have not been leveraged effectively for\nscientific tasks such as cellular signaling network inference. We propose a new\nframework called Directed Scattering Autoencoder (DSAE) which uses a directed\nversion of a geometric scattering transform, combined with the non-linear\ndimensionality reduction properties of an autoencoder and the geometric\nproperties of the hyperbolic space to learn latent hierarchies. We show this\nmethod outperforms numerous others on tasks such as embedding directed graphs\nand learning cellular signaling networks.",
          "link": "http://arxiv.org/abs/2309.07813",
          "publishedOn": "2023-09-16T00:40:57.459Z",
          "wordCount": 670,
          "title": "Directed Scattering for Knowledge Graph-based Cellular Signaling Analysis. (arXiv:2309.07813v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07332",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhan_X/0/1/0/all/0/1\">Xianghao Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qinmei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yuanning Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1\">Guangming Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gevaert_O/0/1/0/all/0/1\">Olivier Gevaert</a>",
          "description": "Accurately labeling biomedical data presents a challenge. Traditional\nsemi-supervised learning methods often under-utilize available unlabeled data.\nTo address this, we propose a novel reliability-based training data cleaning\nmethod employing inductive conformal prediction (ICP). This method capitalizes\non a small set of accurately labeled training data and leverages ICP-calculated\nreliability metrics to rectify mislabeled data and outliers within vast\nquantities of noisy training data. The efficacy of the method is validated\nacross three classification tasks within distinct modalities: filtering\ndrug-induced-liver-injury (DILI) literature with title and abstract, predicting\nICU admission of COVID-19 patients through CT radiomics and electronic health\nrecords, and subtyping breast cancer using RNA-sequencing data. Varying levels\nof noise to the training labels were introduced through label permutation.\nResults show significant enhancements in classification performance: accuracy\nenhancement in 86 out of 96 DILI experiments (up to 11.4%), AUROC and AUPRC\nenhancements in all 48 COVID-19 experiments (up to 23.8% and 69.8%), and\naccuracy and macro-average F1 score improvements in 47 out of 48 RNA-sequencing\nexperiments (up to 74.6% and 89.0%). Our method offers the potential to\nsubstantially boost classification performance in multi-modal biomedical\nmachine learning tasks. Importantly, it accomplishes this without necessitating\nan excessive volume of meticulously curated training data.",
          "link": "http://arxiv.org/abs/2309.07332",
          "publishedOn": "2023-09-16T00:40:57.448Z",
          "wordCount": 803,
          "title": "Reliability-based cleaning of noisy training labels with inductive conformal prediction in multi-modal biomedical data mining. (arXiv:2309.07332v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07794",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Villegas_D/0/1/0/all/0/1\">Danae S&#xe1;nchez Villegas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preotiuc_Pietro_D/0/1/0/all/0/1\">Daniel Preo&#x163;iuc-Pietro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1\">Nikolaos Aletras</a>",
          "description": "Effectively leveraging multimodal information from social media posts is\nessential to various downstream tasks such as sentiment analysis, sarcasm\ndetection and hate speech classification. However, combining text and image\ninformation is challenging because of the idiosyncratic cross-modal semantics\nwith hidden or complementary information present in matching image-text pairs.\nIn this work, we aim to directly model this by proposing the use of two\nauxiliary losses jointly with the main task when fine-tuning any pre-trained\nmultimodal model. Image-Text Contrastive (ITC) brings image-text\nrepresentations of a post closer together and separates them from different\nposts, capturing underlying dependencies. Image-Text Matching (ITM) facilitates\nthe understanding of semantic correspondence between images and text by\npenalizing unrelated pairs. We combine these objectives with five multimodal\nmodels, demonstrating consistent improvements across four popular social media\ndatasets. Furthermore, through detailed analysis, we shed light on the specific\nscenarios and cases where each auxiliary task proves to be most effective.",
          "link": "http://arxiv.org/abs/2309.07794",
          "publishedOn": "2023-09-16T00:40:57.443Z",
          "wordCount": 675,
          "title": "Improving Multimodal Classification of Social Media Posts by Leveraging Image-Text Auxiliary tasks. (arXiv:2309.07794v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.16834",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1\">Hoang Viet Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Thinh Gia Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_C/0/1/0/all/0/1\">Chuong Dinh Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_A/0/1/0/all/0/1\">An Dinh Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vo_H/0/1/0/all/0/1\">Hien Bich Vo</a>",
          "description": "Innovative enhancement in embedded system platforms, specifically hardware\naccelerations, significantly influence the application of deep learning in\nreal-world scenarios. These innovations translate human labor efforts into\nautomated intelligent systems employed in various areas such as autonomous\ndriving, robotics, Internet-of-Things (IoT), and numerous other impactful\napplications. NVIDIA's Jetson platform is one of the pioneers in offering\noptimal performance regarding energy efficiency and throughput in the execution\nof deep learning algorithms. Previously, most benchmarking analysis was based\non 2D images with a single deep learning model for each comparison result. In\nthis paper, we implement an end-to-end video-based crime-scene anomaly\ndetection system inputting from surveillance videos and the system is deployed\nand completely operates on multiple Jetson edge devices (Nano, AGX Xavier, Orin\nNano). The comparison analysis includes the integration of Torch-TensorRT as a\nsoftware developer kit from NVIDIA for the model performance optimisation. The\nsystem is built based on the PySlowfast open-source project from Facebook as\nthe coding template. The end-to-end system process comprises the videos from\ncamera, data preprocessing pipeline, feature extractor and the anomaly\ndetection. We provide the experience of an AI-based system deployment on\nvarious Jetson Edge devices with Docker technology. Regarding anomaly\ndetectors, a weakly supervised video-based deep learning model called Robust\nTemporal Feature Magnitude Learning (RTFM) is applied in the system. The\napproach system reaches 47.56 frames per second (FPS) inference speed on a\nJetson edge device with only 3.11 GB RAM usage total. We also discover the\npromising Jetson device that the AI system achieves 15% better performance than\nthe previous version of Jetson devices while consuming 50% less energy power.",
          "link": "http://arxiv.org/abs/2307.16834",
          "publishedOn": "2023-09-16T00:40:57.436Z",
          "wordCount": 840,
          "title": "Benchmarking Jetson Edge Devices with an End-to-end Video-based Anomaly Detection System. (arXiv:2307.16834v3 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07187",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Ying Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongbo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_W/0/1/0/all/0/1\">Wenyang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xv_C/0/1/0/all/0/1\">Chongxuan Xv</a>",
          "description": "Chlorophyll concentration can well reflect the nutritional status and algal\nblooms of water bodies, and is an important indicator for evaluating water\nquality. The prediction of chlorophyll concentration change trend is of great\nsignificance to environmental protection and aquaculture. However, there is a\ncomplex and indistinguishable nonlinear relationship between many factors\naffecting chlorophyll concentration. In order to effectively mine the nonlinear\nfeatures contained in the data. This paper proposes a time-series decomposition\nadaptive graph-time convolutional network ( AGTCNSD ) prediction model.\nFirstly, the original sequence is decomposed into trend component and periodic\ncomponent by moving average method. Secondly, based on the graph convolutional\nneural network, the water quality parameter data is modeled, and a parameter\nembedding matrix is defined. The idea of matrix decomposition is used to assign\nweight parameters to each node. The adaptive graph convolution learns the\nrelationship between different water quality parameters, updates the state\ninformation of each parameter, and improves the learning ability of the update\nrelationship between nodes. Finally, time dependence is captured by time\nconvolution to achieve multi-step prediction of chlorophyll concentration. The\nvalidity of the model is verified by the water quality data of the coastal city\nBeihai. The results show that the prediction effect of this method is better\nthan other methods. It can be used as a scientific resource for environmental\nmanagement decision-making.",
          "link": "http://arxiv.org/abs/2309.07187",
          "publishedOn": "2023-09-16T00:40:57.431Z",
          "wordCount": 758,
          "title": "Multi-step prediction of chlorophyll concentration based on Adaptive Graph-Temporal Convolutional Network with Series Decomposition. (arXiv:2309.07187v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.09597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qiao_S/0/1/0/all/0/1\">Shuofei Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ou_Y/0/1/0/all/0/1\">Yixin Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yunzhi Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>",
          "description": "Reasoning, as an essential ability for complex problem-solving, can provide\nback-end support for various real-world applications, such as medical\ndiagnosis, negotiation, etc. This paper provides a comprehensive survey of\ncutting-edge research on reasoning with language model prompting. We introduce\nresearch works with comparisons and summaries and provide systematic resources\nto help beginners. We also discuss the potential reasons for emerging such\nreasoning abilities and highlight future research directions. Resources are\navailable at https://github.com/zjunlp/Prompt4ReasoningPapers (updated\nperiodically).",
          "link": "http://arxiv.org/abs/2212.09597",
          "publishedOn": "2023-09-16T00:40:57.424Z",
          "wordCount": 671,
          "title": "Reasoning with Language Model Prompting: A Survey. (arXiv:2212.09597v7 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leite_J/0/1/0/all/0/1\">Jo&#xe3;o A. Leite</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razuvayevskaya_O/0/1/0/all/0/1\">Olesya Razuvayevskaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bontcheva_K/0/1/0/all/0/1\">Kalina Bontcheva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scarton_C/0/1/0/all/0/1\">Carolina Scarton</a>",
          "description": "Credibility signals represent a wide range of heuristics that are typically\nused by journalists and fact-checkers to assess the veracity of online content.\nAutomating the task of credibility signal extraction, however, is very\nchallenging as it requires high-accuracy signal-specific extractors to be\ntrained, while there are currently no sufficiently large datasets annotated\nwith all credibility signals. This paper investigates whether large language\nmodels (LLMs) can be prompted effectively with a set of 18 credibility signals\nto produce weak labels for each signal. We then aggregate these potentially\nnoisy labels using weak supervision in order to predict content veracity. We\ndemonstrate that our approach, which combines zero-shot LLM credibility signal\nlabeling and weak supervision, outperforms state-of-the-art classifiers on two\nmisinformation datasets without using any ground-truth labels for training. We\nalso analyse the contribution of the individual credibility signals towards\npredicting content veracity, which provides new valuable insights into their\nrole in misinformation detection.",
          "link": "http://arxiv.org/abs/2309.07601",
          "publishedOn": "2023-09-16T00:40:57.411Z",
          "wordCount": 663,
          "title": "Detecting Misinformation with LLM-Predicted Credibility Signals and Weak Supervision. (arXiv:2309.07601v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07812",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yumeng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jayaraj_S/0/1/0/all/0/1\">Soumya Jayaraj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ludmir_E/0/1/0/all/0/1\">Ethan B Ludmir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_K/0/1/0/all/0/1\">Kirk Roberts</a>",
          "description": "Automatic identification of clinical trials for which a patient is eligible\nis complicated by the fact that trial eligibility is stated in natural\nlanguage. A potential solution to this problem is to employ text classification\nmethods for common types of eligibility criteria. In this study, we focus on\nseven common exclusion criteria in cancer trials: prior malignancy, human\nimmunodeficiency virus, hepatitis B, hepatitis C, psychiatric illness,\ndrug/substance abuse, and autoimmune illness. Our dataset consists of 764 phase\nIII cancer trials with these exclusions annotated at the trial level. We\nexperiment with common transformer models as well as a new pre-trained clinical\ntrial BERT model. Our results demonstrate the feasibility of automatically\nclassifying common exclusion criteria. Additionally, we demonstrate the value\nof a pre-trained language model specifically for clinical trials, which yields\nthe highest average performance across all criteria.",
          "link": "http://arxiv.org/abs/2309.07812",
          "publishedOn": "2023-09-16T00:40:57.405Z",
          "wordCount": 645,
          "title": "Text Classification of Cancer Clinical Trial Eligibility Criteria. (arXiv:2309.07812v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07716",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Valle_M/0/1/0/all/0/1\">Marcos Eduardo Valle</a>",
          "description": "Despite the many successful applications of deep learning models for\nmultidimensional signal and image processing, most traditional neural networks\nprocess data represented by (multidimensional) arrays of real numbers. The\nintercorrelation between feature channels is usually expected to be learned\nfrom the training data, requiring numerous parameters and careful training. In\ncontrast, vector-valued neural networks are conceived to process arrays of\nvectors and naturally consider the intercorrelation between feature channels.\nConsequently, they usually have fewer parameters and often undergo more robust\ntraining than traditional neural networks. This paper aims to present a broad\nframework for vector-valued neural networks, referred to as V-nets. In this\ncontext, hypercomplex-valued neural networks are regarded as vector-valued\nmodels with additional algebraic properties. Furthermore, this paper explains\nthe relationship between vector-valued and traditional neural networks.\nPrecisely, a vector-valued neural network can be obtained by placing\nrestrictions on a real-valued model to consider the intercorrelation between\nfeature channels. Finally, we show how V-nets, including hypercomplex-valued\nneural networks, can be implemented in current deep-learning libraries as\nreal-valued networks.",
          "link": "http://arxiv.org/abs/2309.07716",
          "publishedOn": "2023-09-16T00:40:57.401Z",
          "wordCount": 687,
          "title": "Understanding Vector-Valued Neural Networks and Their Relationship with Real and Hypercomplex-Valued Neural Networks. (arXiv:2309.07716v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07134",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Belyaev_M/0/1/0/all/0/1\">Maksim Belyaev</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Murugappan_M/0/1/0/all/0/1\">Murugappan Murugappan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Velichko_A/0/1/0/all/0/1\">Andrei Velichko</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Korzun_D/0/1/0/all/0/1\">Dmitry Korzun</a>",
          "description": "The study presents the concept of a computationally efficient machine\nlearning (ML) model for diagnosing and monitoring Parkinson's disease (PD) in\nan Internet of Things (IoT) environment using rest-state EEG signals (rs-EEG).\nWe computed different types of entropy from EEG signals and found that Fuzzy\nEntropy performed the best in diagnosing and monitoring PD using rs-EEG. We\nalso investigated different combinations of signal frequency ranges and EEG\nchannels to accurately diagnose PD. Finally, with a fewer number of features\n(11 features), we achieved a maximum classification accuracy (ARKF) of ~99.9%.\nThe most prominent frequency range of EEG signals has been identified, and we\nhave found that high classification accuracy depends on low-frequency signal\ncomponents (0-4 Hz). Moreover, the most informative signals were mainly\nreceived from the right hemisphere of the head (F8, P8, T8, FC6). Furthermore,\nwe assessed the accuracy of the diagnosis of PD using three different lengths\nof EEG data (150-1000 samples). Because the computational complexity is reduced\nby reducing the input data. As a result, we have achieved a maximum mean\naccuracy of 99.9% for a sample length (LEEG) of 1000 (~7.8 seconds), 98.2% with\na LEEG of 800 (~6.2 seconds), and 79.3% for LEEG = 150 (~1.2 seconds). By\nreducing the number of features and segment lengths, the computational cost of\nclassification can be reduced. Lower-performance smart ML sensors can be used\nin IoT environments for enhances human resilience to PD.",
          "link": "http://arxiv.org/abs/2309.07134",
          "publishedOn": "2023-09-16T00:40:57.396Z",
          "wordCount": 781,
          "title": "Entropy-based machine learning model for diagnosis and monitoring of Parkinson's Disease in smart IoT environment. (arXiv:2309.07134v1 [eess.SP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2202.07626",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frei_S/0/1/0/all/0/1\">Spencer Frei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterji_N/0/1/0/all/0/1\">Niladri S. Chatterji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1\">Peter L. Bartlett</a>",
          "description": "In this work, we provide a characterization of the feature-learning process\nin two-layer ReLU networks trained by gradient descent on the logistic loss\nfollowing random initialization. We consider data with binary labels that are\ngenerated by an XOR-like function of the input features. We permit a constant\nfraction of the training labels to be corrupted by an adversary. We show that,\nalthough linear classifiers are no better than random guessing for the\ndistribution we consider, two-layer ReLU networks trained by gradient descent\nachieve generalization error close to the label noise rate. We develop a novel\nproof technique that shows that at initialization, the vast majority of neurons\nfunction as random features that are only weakly correlated with useful\nfeatures, and the gradient descent dynamics 'amplify' these weak, random\nfeatures to strong, useful features.",
          "link": "http://arxiv.org/abs/2202.07626",
          "publishedOn": "2023-09-16T00:40:57.383Z",
          "wordCount": 697,
          "title": "Random Feature Amplification: Feature Learning and Generalization in Neural Networks. (arXiv:2202.07626v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07684",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Firoozsalari_A/0/1/0/all/0/1\">Ali Nosrati Firoozsalari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazraeh_H/0/1/0/all/0/1\">Hassan Dana Mazraeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aghaei_A/0/1/0/all/0/1\">Alireza Afzal Aghaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parand_K/0/1/0/all/0/1\">Kourosh Parand</a>",
          "description": "The primary goal of this research is to propose a novel architecture for a\ndeep neural network that can solve fractional differential equations\naccurately. A Gaussian integration rule and a $L_1$ discretization technique\nare used in the proposed design. In each equation, a deep neural network is\nused to approximate the unknown function. Three forms of fractional\ndifferential equations have been examined to highlight the method's\nversatility: a fractional ordinary differential equation, a fractional order\nintegrodifferential equation, and a fractional order partial differential\nequation. The results show that the proposed architecture solves different\nforms of fractional differential equations with excellent precision.",
          "link": "http://arxiv.org/abs/2309.07684",
          "publishedOn": "2023-09-16T00:40:57.362Z",
          "wordCount": 631,
          "title": "deepFDEnet: A Novel Neural Network Architecture for Solving Fractional Differential Equations. (arXiv:2309.07684v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.07097",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hagos_M/0/1/0/all/0/1\">Misgina Tsighe Hagos</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Belton_N/0/1/0/all/0/1\">Niamh Belton</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Killeen_R/0/1/0/all/0/1\">Ronan P. Killeen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Curran_K/0/1/0/all/0/1\">Kathleen M. Curran</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Namee_B/0/1/0/all/0/1\">Brian Mac Namee</a>",
          "description": "Alzheimer's Disease (AD) is a progressive disease preceded by Mild Cognitive\nImpairment (MCI). Early detection of AD is crucial for making treatment\ndecisions. However, most of the literature on computer-assisted detection of AD\nfocuses on classifying brain images into one of three major categories:\nhealthy, MCI, and AD; or categorizing MCI patients into (1) progressive: those\nwho progress from MCI to AD at a future examination time, and (2) stable: those\nwho stay as MCI and never progress to AD. This misses the opportunity to\naccurately identify the trajectory of progressive MCI patients. In this paper,\nwe revisit the brain image classification task for AD identification and\nre-frame it as an ordinal classification task to predict how close a patient is\nto the severe AD stage. To this end, we select progressive MCI patients from\nthe Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset and construct an\nordinal dataset with a prediction target that indicates the time to progression\nto AD. We train a Siamese network model to predict the time to onset of AD\nbased on MRI brain images. We also propose a Weighted variety of Siamese\nnetwork and compare its performance to a baseline model. Our evaluations show\nthat incorporating a weighting factor to Siamese networks brings considerable\nperformance gain at predicting how close input brain MRI images are to\nprogressing to AD. Moreover, we complement our results with an interpretation\nof the learned embedding space of the Siamese networks using a model\nexplainability technique.",
          "link": "http://arxiv.org/abs/2304.07097",
          "publishedOn": "2023-09-16T00:40:57.357Z",
          "wordCount": 828,
          "title": "Interpretable Weighted Siamese Network to Predict the Time to Onset of Alzheimer's Disease from MRI Images. (arXiv:2304.07097v2 [eess.IV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2211.10851",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ringstrom_T/0/1/0/all/0/1\">Thomas J. Ringstrom</a>",
          "description": "Reinforcement Learning views the maximization of rewards and avoidance of\npunishments as central to explaining goal-directed behavior. However, over a\nlife, organisms will need to learn about many different aspects of the world's\nstructure: the states of the world and state-vector transition dynamics. The\nnumber of combinations of states grows exponentially as an agent incorporates\nnew knowledge, and there is no obvious weighted combination of pre-existing\nrewards or costs defined for a given combination of states, as such a weighting\nwould need to encode information about good and bad combinations prior to an\nagent's experience in the world. Therefore, we must develop more naturalistic\naccounts of behavior and motivation in large state-spaces. We show that it is\npossible to use only the intrinsic motivation metric of empowerment, which\nmeasures the agent's capacity to realize many possible futures under a\ntransition operator. We propose to scale empowerment to hierarchical\nstate-spaces by using Operator Bellman Equations. These equations produce\nstate-time feasibility functions, which are compositional hierarchical\nstate-time transition operators that map an initial state and time when an\nagent begins a policy to the final states and times of completing a goal.\nBecause these functions are hierarchical operators we can define hierarchical\nempowerment measures on them. An agent can then optimize plans to distant\nstates and times to maximize its hierarchical empowerment-gain, allowing it to\ndiscover goals that bring about a more favorable coupling of its internal\nstructure (physiological states) to its external environment (world structure &\nspatial state). Life-long agents could therefore be primarily animated by\nprinciples of compositionality and empowerment, exhibiting self-concern for the\ngrowth & maintenance of their own structural integrity without recourse to\nreward-maximization.",
          "link": "http://arxiv.org/abs/2211.10851",
          "publishedOn": "2023-09-16T00:40:57.352Z",
          "wordCount": 816,
          "title": "Reward is not Necessary: How to Create a Compositional Self-Preserving Agent for Life-Long Learning. (arXiv:2211.10851v3 [cs.AI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07136",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhou_Y/0/1/0/all/0/1\">Ya Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Diao_X/0/1/0/all/0/1\">Xiaolin Diao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huo_Y/0/1/0/all/0/1\">Yanni Huo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fan_X/0/1/0/all/0/1\">Xiaohan Fan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_W/0/1/0/all/0/1\">Wei Zhao</a>",
          "description": "Electrocardiogram (ECG) is one of the most important diagnostic tools in\nclinical applications. With the advent of advanced algorithms, various deep\nlearning models have been adopted for ECG tasks. However, the potential of\nTransformers for ECG data is not yet realized, despite their widespread success\nin computer vision and natural language processing. In this work, we present a\nuseful masked Transformer method for ECG classification referred to as MTECG,\nwhich expands the application of masked autoencoders to ECG time series. We\nconstruct a dataset comprising 220,251 ECG recordings with a broad range of\ndiagnoses annoated by medical experts to explore the properties of MTECG. Under\nthe proposed training strategies, a lightweight model with 5.7M parameters\nperforms stably well on a broad range of masking ratios (5%-75%). The ablation\nstudies highlight the importance of fluctuated reconstruction targets, training\nschedule length, layer-wise LR decay and DropPath rate. The experiments on both\nprivate and public ECG datasets demonstrate that MTECG-T significantly\noutperforms the recent state-of-the-art algorithms in ECG classification.",
          "link": "http://arxiv.org/abs/2309.07136",
          "publishedOn": "2023-09-16T00:40:57.344Z",
          "wordCount": 668,
          "title": "Masked Transformer for Electrocardiogram Classification. (arXiv:2309.07136v1 [eess.SP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seraphim_M/0/1/0/all/0/1\">Mathieu Seraphim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lechervy_A/0/1/0/all/0/1\">Alexis Lechervy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yger_F/0/1/0/all/0/1\">Florian Yger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brun_L/0/1/0/all/0/1\">Luc Brun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Etard_O/0/1/0/all/0/1\">Olivier Etard</a>",
          "description": "In recent years, Transformer-based auto-attention mechanisms have been\nsuccessfully applied to the analysis of a variety of context-reliant data\ntypes, from texts to images and beyond, including data from non-Euclidean\ngeometries. In this paper, we present such a mechanism, designed to classify\nsequences of Symmetric Positive Definite matrices while preserving their\nRiemannian geometry throughout the analysis. We apply our method to automatic\nsleep staging on timeseries of EEG-derived covariance matrices from a standard\ndataset, obtaining high levels of stage-wise performance.",
          "link": "http://arxiv.org/abs/2309.07579",
          "publishedOn": "2023-09-16T00:40:57.321Z",
          "wordCount": null,
          "title": "Structure-Preserving Transformers for Sequences of SPD Matrices. (arXiv:2309.07579v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07888",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_D/0/1/0/all/0/1\">Davinder Pal Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ray_L/0/1/0/all/0/1\">Lala Shakti Swarup Ray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1\">Bo Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suh_S/0/1/0/all/0/1\">Sungho Suh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukowicz_P/0/1/0/all/0/1\">Paul Lukowicz</a>",
          "description": "We present a novel local-global feature fusion framework for body-weight\nexercise recognition with floor-based dynamic pressure maps. One step further\nfrom the existing studies using deep neural networks mainly focusing on global\nfeature extraction, the proposed framework aims to combine local and global\nfeatures using image processing techniques and the YOLO object detection to\nlocalize pressure profiles from different body parts and consider physical\nconstraints. The proposed local feature extraction method generates two sets of\nhigh-level local features consisting of cropped pressure mapping and numerical\nfeatures such as angular orientation, location on the mat, and pressure area.\nIn addition, we adopt a knowledge distillation for regularization to preserve\nthe knowledge of the global feature extraction and improve the performance of\nthe exercise recognition. Our experimental results demonstrate a notable 11\npercent improvement in F1 score for exercise recognition while preserving\nlabel-specific features.",
          "link": "http://arxiv.org/abs/2309.07888",
          "publishedOn": "2023-09-16T00:40:57.307Z",
          "wordCount": 677,
          "title": "A Novel Local-Global Feature Fusion Framework for Body-weight Exercise Recognition with Pressure Mapping Sensors. (arXiv:2309.07888v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.10848",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Boettcher_S/0/1/0/all/0/1\">Stefan Boettcher</a> (Emory U)",
          "description": "In Changjun Fan et al. [Nature Communications\nhttps://doi.org/10.1038/s41467-023-36363-w (2023)], the authors present a deep\nreinforced learning approach to augment combinatorial optimization heuristics.\nIn particular, they present results for several spin glass ground state\nproblems, for which instances on non-planar networks are generally NP-hard, in\ncomparison with several Monte Carlo based methods, such as simulated annealing\n(SA) or parallel tempering (PT). Indeed, those results demonstrate that the\nreinforced learning improves the results over those obtained with SA or PT, or\nat least allows for reduced runtimes for the heuristics before results of\ncomparable quality have been obtained relative to those other methods. To\nfacilitate the conclusion that their method is ''superior'', the authors pursue\ntwo basic strategies: (1) A commercial GUROBI solver is called on to procure a\nsample of exact ground states as a testbed to compare with, and (2) a\nhead-to-head comparison between the heuristics is given for a sample of larger\ninstances where exact ground states are hard to ascertain. Here, we put these\nstudies into a larger context, showing that the claimed superiority is at best\nmarginal for smaller samples and becomes essentially irrelevant with respect to\nany sensible approximation of true ground states in the larger samples. For\nexample, this method becomes irrelevant as a means to determine stiffness\nexponents $\\theta$ in $d>2$, as mentioned by the authors, where the problem is\nnot only NP-hard but requires the subtraction of two almost equal ground-state\nenergies and systemic errors in each of $\\approx 1\\%$ found here are\nunacceptable. This larger picture on the method arises from a straightforward\nfinite-size corrections study over the spin glass ensembles the authors employ,\nusing data that has been available for decades.",
          "link": "http://arxiv.org/abs/2302.10848",
          "publishedOn": "2023-09-16T00:40:57.259Z",
          "wordCount": null,
          "title": "Deep reinforced learning heuristic tested on spin-glass ground states: The larger picture. (arXiv:2302.10848v2 [cond-mat.dis-nn] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.00855",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_W/0/1/0/all/0/1\">Wei-Wei Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei-Yao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Wen-Chih Peng</a>",
          "description": "The marketplace system connecting demands and supplies has been explored to\ndevelop unbiased decision-making in valuing properties. Real estate appraisal\nserves as one of the high-cost property valuation tasks for financial\ninstitutions since it requires domain experts to appraise the estimation based\non the corresponding knowledge and the judgment of the market. Existing\nautomated valuation models reducing the subjectivity of domain experts require\na large number of transactions for effective evaluation, which is predominantly\nlimited to not only the labeling efforts of transactions but also the\ngeneralizability of new developing and rural areas. To learn representations\nfrom unlabeled real estate sets, existing self-supervised learning (SSL) for\ntabular data neglects various important features, and fails to incorporate\ndomain knowledge. In this paper, we propose DoRA, a Domain-based\nself-supervised learning framework for low-resource Real estate Appraisal. DoRA\nis pre-trained with an intra-sample geographic prediction as the pretext task\nbased on the metadata of the real estate for equipping the real estate\nrepresentations with prior domain knowledge. Furthermore, inter-sample\ncontrastive learning is employed to generalize the representations to be robust\nfor limited transactions of downstream tasks. Our benchmark results on three\nproperty types of real-world transactions show that DoRA significantly\noutperforms the SSL baselines for tabular data, the graph-based methods, and\nthe supervised approaches in the few-shot scenarios by at least 7.6% for MAPE,\n11.59% for MAE, and 3.34% for HR10%. We expect DoRA to be useful to other\nfinancial practitioners with similar marketplace applications who need general\nmodels for properties that are newly built and have limited records. The source\ncode is available at https://github.com/wwweiwei/DoRA.",
          "link": "http://arxiv.org/abs/2309.00855",
          "publishedOn": "2023-09-16T00:40:57.252Z",
          "wordCount": null,
          "title": "DoRA: Domain-Based Self-Supervised Learning Framework for Low-Resource Real Estate Appraisal. (arXiv:2309.00855v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.12876",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dumont_M/0/1/0/all/0/1\">Mathieu Dumont</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hector_K/0/1/0/all/0/1\">Kevin Hector</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moellic_P/0/1/0/all/0/1\">Pierre-Alain Moellic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dutertre_J/0/1/0/all/0/1\">Jean-Max Dutertre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pontie_S/0/1/0/all/0/1\">Simon Ponti&#xe9;</a>",
          "description": "Upcoming certification actions related to the security of machine learning\n(ML) based systems raise major evaluation challenges that are amplified by the\nlarge-scale deployment of models in many hardware platforms. Until recently,\nmost of research works focused on API-based attacks that consider a ML model as\na pure algorithmic abstraction. However, new implementation-based threats have\nbeen revealed, emphasizing the urgency to propose both practical and\nsimulation-based methods to properly evaluate the robustness of models. A major\nconcern is parameter-based attacks (such as the Bit-Flip Attack, BFA) that\nhighlight the lack of robustness of typical deep neural network models when\nconfronted by accurate and optimal alterations of their internal parameters\nstored in memory. Setting in a security testing purpose, this work practically\nreports, for the first time, a successful variant of the BFA on a 32-bit\nCortex-M microcontroller using laser fault injection. It is a standard fault\ninjection means for security evaluation, that enables to inject spatially and\ntemporally accurate faults. To avoid unrealistic brute-force strategies, we\nshow how simulations help selecting the most sensitive set of bits from the\nparameters taking into account the laser fault model.",
          "link": "http://arxiv.org/abs/2304.12876",
          "publishedOn": "2023-09-16T00:40:57.222Z",
          "wordCount": null,
          "title": "Evaluation of Parameter-based Attacks against Embedded Neural Networks with Laser Injection. (arXiv:2304.12876v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yafei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jianguo Liu</a>",
          "description": "Score-based methods for learning Bayesain networks(BN) aim to maximizing the\nglobal score functions. However, if local variables have direct and indirect\ndependence simultaneously, the global optimization on score functions misses\nedges between variables with indirect dependent relationship, of which scores\nare smaller than those with direct dependent relationship. In this paper, we\npresent an identifiability condition based on a determined subset of parents to\nidentify the underlying DAG. By the identifiability condition, we develop a\ntwo-phase algorithm namely optimal-tuning (OT) algorithm to locally amend the\nglobal optimization. In the optimal phase, an optimization problem based on\nfirst-order Hilbert-Schmidt independence criterion (HSIC) gives an estimated\nskeleton as the initial determined parents subset. In the tuning phase, the\nskeleton is locally tuned by deletion, addition and DAG-formalization\nstrategies using the theoretically proved incremental properties of high-order\nHSIC. Numerical experiments for different synthetic datasets and real-world\ndatasets show that the OT algorithm outperforms existing methods. Especially in\nSigmoid Mix model with the size of the graph being ${\\rm\\bf d=40}$, the\nstructure intervention distance (SID) of the OT algorithm is 329.7 smaller than\nthe one obtained by CAM, which indicates that the graph estimated by the OT\nalgorithm misses fewer edges compared with CAM.Source code of the OT algorithm\nis available at https://github.com/YafeiannWang/optimal-tune-algorithm.",
          "link": "http://arxiv.org/abs/2308.05969",
          "publishedOn": "2023-09-16T00:40:57.208Z",
          "wordCount": null,
          "title": "Learning nonparametric DAGs with incremental information via high-order HSIC. (arXiv:2308.05969v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07450",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Andrecut_M/0/1/0/all/0/1\">M. Andrecut</a>",
          "description": "Predicting the dynamics of chaotic systems is one of the most challenging\ntasks for neural networks, and machine learning in general. Here we aim to\npredict the spatiotemporal chaotic dynamics of a high-dimensional non-linear\nsystem. In our attempt we use the TensorFlow library, representing the state of\nthe art for deep neural networks training and prediction. While our results are\nencouraging, and show that the dynamics of the considered system can be\npredicted for short time, we also indirectly discovered an unexpected and\nundesirable behavior of the TensorFlow library. More specifically, the longer\nterm prediction of the system's chaotic behavior quickly deteriorates and blows\nup due to the nondeterministic behavior of the TensorFlow library. Here we\nprovide numerical evidence of the short time prediction ability, and of the\nlonger term predictability blow up.",
          "link": "http://arxiv.org/abs/2309.07450",
          "publishedOn": "2023-09-16T00:40:57.207Z",
          "wordCount": null,
          "title": "TensorFlow Chaotic Prediction and Blow Up. (arXiv:2309.07450v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.06724",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wangni_J/0/1/0/all/0/1\">Jianqiao Wangni</a>",
          "description": "We aim to provide a general framework of for computational photography that\nrecovers the real scene from imperfect images, via the Deep Nonparametric\nConvexified Filtering (DNCF). It is consists of a nonparametric deep network to\nresemble the physical equations behind the image formation, such as denoising,\nsuper-resolution, inpainting, and flash. DNCF has no parameterization dependent\non training data, therefore has a strong generalization and robustness to\nadversarial image manipulation. During inference, we also encourage the network\nparameters to be nonnegative and create a bi-convex function on the input and\nparameters, and this adapts to second-order optimization algorithms with\ninsufficient running time, having 10X acceleration over Deep Image Prior. With\nthese tools, we empirically verify its capability to defend image\nclassification deep networks against adversary attack algorithms in real-time.",
          "link": "http://arxiv.org/abs/2309.06724",
          "publishedOn": "2023-09-16T00:40:57.197Z",
          "wordCount": null,
          "title": "Deep Nonparametric Convexified Filtering for Computational Photography, Image Synthesis and Adversarial Defense. (arXiv:2309.06724v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07235",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xingfu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paramasivam_P/0/1/0/all/0/1\">Praveen Paramasivam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taylor_V/0/1/0/all/0/1\">Valerie Taylor</a>",
          "description": "Apache TVM (Tensor Virtual Machine), an open source machine learning compiler\nframework designed to optimize computations across various hardware platforms,\nprovides an opportunity to improve the performance of dense matrix\nfactorizations such as LU (Lower Upper) decomposition and Cholesky\ndecomposition on GPUs and AI (Artificial Intelligence) accelerators. In this\npaper, we propose a new TVM autotuning framework using Bayesian Optimization\nand use the TVM tensor expression language to implement linear algebra kernels\nsuch as LU, Cholesky, and 3mm. We use these scientific computation kernels to\nevaluate the effectiveness of our methods on a GPU cluster, called Swing, at\nArgonne National Laboratory. We compare the proposed autotuning framework with\nthe TVM autotuning framework AutoTVM with four tuners and find that our\nframework outperforms AutoTVM in most cases.",
          "link": "http://arxiv.org/abs/2309.07235",
          "publishedOn": "2023-09-16T00:40:57.196Z",
          "wordCount": null,
          "title": "Autotuning Apache TVM-based Scientific Applications Using Bayesian Optimization. (arXiv:2309.07235v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marconato_E/0/1/0/all/0/1\">Emanuele Marconato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Passerini_A/0/1/0/all/0/1\">Andrea Passerini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teso_S/0/1/0/all/0/1\">Stefano Teso</a>",
          "description": "Focus in Explainable AI is shifting from explanations defined in terms of\nlow-level elements, such as input features, to explanations encoded in terms of\ninterpretable concepts learned from data. How to reliably acquire such concepts\nis, however, still fundamentally unclear. An agreed-upon notion of concept\ninterpretability is missing, with the result that concepts used by both\npost-hoc explainers and concept-based neural networks are acquired through a\nvariety of mutually incompatible strategies. Critically, most of these neglect\nthe human side of the problem: a representation is understandable only insofar\nas it can be understood by the human at the receiving end. The key challenge in\nHuman-interpretable Representation Learning (HRL) is how to model and\noperationalize this human element. In this work, we propose a mathematical\nframework for acquiring interpretable representations suitable for both\npost-hoc explainers and concept-based neural networks. Our formalization of HRL\nbuilds on recent advances in causal representation learning and explicitly\nmodels a human stakeholder as an external observer. This allows us to derive a\nprincipled notion of alignment between the machine representation and the\nvocabulary of concepts understood by the human. In doing so, we link alignment\nand interpretability through a simple and intuitive name transfer game, and\nclarify the relationship between alignment and a well-known property of\nrepresentations, namely disentanglment. We also show that alignment is linked\nto the issue of undesirable correlations among concepts, also known as concept\nleakage, and to content-style separation, all through a general\ninformation-theoretic reformulation of these properties. Our conceptualization\naims to bridge the gap between the human and algorithmic sides of\ninterpretability and establish a stepping stone for new research on\nhuman-interpretable representations.",
          "link": "http://arxiv.org/abs/2309.07742",
          "publishedOn": "2023-09-16T00:40:57.048Z",
          "wordCount": null,
          "title": "Interpretability is in the Mind of the Beholder: A Causal Framework for Human-interpretable Representation Learning. (arXiv:2309.07742v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07835",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Sambharya_R/0/1/0/all/0/1\">Rajiv Sambharya</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hall_G/0/1/0/all/0/1\">Georgina Hall</a>, <a href=\"http://arxiv.org/find/math/1/au:+Amos_B/0/1/0/all/0/1\">Brandon Amos</a>, <a href=\"http://arxiv.org/find/math/1/au:+Stellato_B/0/1/0/all/0/1\">Bartolomeo Stellato</a>",
          "description": "We introduce a machine-learning framework to warm-start fixed-point\noptimization algorithms. Our architecture consists of a neural network mapping\nproblem parameters to warm starts, followed by a predefined number of\nfixed-point iterations. We propose two loss functions designed to either\nminimize the fixed-point residual or the distance to a ground truth solution.\nIn this way, the neural network predicts warm starts with the end-to-end goal\nof minimizing the downstream loss. An important feature of our architecture is\nits flexibility, in that it can predict a warm start for fixed-point algorithms\nrun for any number of steps, without being limited to the number of steps it\nhas been trained on. We provide PAC-Bayes generalization bounds on unseen data\nfor common classes of fixed-point operators: contractive, linearly convergent,\nand averaged. Applying this framework to well-known applications in control,\nstatistics, and signal processing, we observe a significant reduction in the\nnumber of iterations and solution time required to solve these problems,\nthrough learned warm starts.",
          "link": "http://arxiv.org/abs/2309.07835",
          "publishedOn": "2023-09-16T00:40:57.042Z",
          "wordCount": null,
          "title": "Learning to Warm-Start Fixed-Point Optimization Algorithms. (arXiv:2309.07835v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1906.00331",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1\">Tianyi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1\">Chi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>",
          "description": "We consider nonconvex-concave minimax problems, $\\min_{\\mathbf{x}}\n\\max_{\\mathbf{y} \\in \\mathcal{Y}} f(\\mathbf{x}, \\mathbf{y})$, where $f$ is\nnonconvex in $\\mathbf{x}$ but concave in $\\mathbf{y}$ and $\\mathcal{Y}$ is a\nconvex and bounded set. One of the most popular algorithms for solving this\nproblem is the celebrated gradient descent ascent (GDA) algorithm, which has\nbeen widely used in machine learning, control theory and economics. Despite the\nextensive convergence results for the convex-concave setting, GDA with equal\nstepsize can converge to limit cycles or even diverge in a general setting. In\nthis paper, we present the complexity results on two-time-scale GDA for solving\nnonconvex-concave minimax problems, showing that the algorithm can find a\nstationary point of the function $\\Phi(\\cdot) := \\max_{\\mathbf{y} \\in\n\\mathcal{Y}} f(\\cdot, \\mathbf{y})$ efficiently. To the best our knowledge, this\nis the first nonasymptotic analysis for two-time-scale GDA in this setting,\nshedding light on its superior practical performance in training generative\nadversarial networks (GANs) and other real applications.",
          "link": "http://arxiv.org/abs/1906.00331",
          "publishedOn": "2023-09-16T00:40:57.040Z",
          "wordCount": null,
          "title": "On Gradient Descent Ascent for Nonconvex-Concave Minimax Problems. (arXiv:1906.00331v9 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07703",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Simoes_F/0/1/0/all/0/1\">Francisco Nunes Ferreira Quialheiro Simoes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dastani_M/0/1/0/all/0/1\">Mehdi Dastani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ommen_T/0/1/0/all/0/1\">Thijs van Ommen</a>",
          "description": "Artificial intelligence models and methods commonly lack causal\ninterpretability. Despite the advancements in interpretable machine learning\n(IML) methods, they frequently assign importance to features which lack causal\ninfluence on the outcome variable. Selecting causally relevant features among\nthose identified as relevant by these methods, or even before model training,\nwould offer a solution. Feature selection methods utilizing information\ntheoretical quantities have been successful in identifying statistically\nrelevant features. However, the information theoretical quantities they are\nbased on do not incorporate causality, rendering them unsuitable for such\nscenarios. To address this challenge, this article proposes information\ntheoretical quantities that incorporate the causal structure of the system,\nwhich can be used to evaluate causal importance of features for some given\noutcome variable. Specifically, we introduce causal versions of entropy and\nmutual information, termed causal entropy and causal information gain, which\nare designed to assess how much control a feature provides over the outcome\nvariable. These newly defined quantities capture changes in the entropy of a\nvariable resulting from interventions on other variables. Fundamental results\nconnecting these quantities to the existence of causal effects are derived. The\nuse of causal information gain in feature selection is demonstrated,\nhighlighting its superiority over standard mutual information in revealing\nwhich features provide control over a chosen outcome variable. Our\ninvestigation paves the way for the development of methods with improved\ninterpretability in domains involving causation.",
          "link": "http://arxiv.org/abs/2309.07703",
          "publishedOn": "2023-09-16T00:40:57.038Z",
          "wordCount": null,
          "title": "Causal Entropy and Information Gain for Measuring Causal Control. (arXiv:2309.07703v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brecht_R/0/1/0/all/0/1\">R&#xfc;diger Brecht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popovych_D/0/1/0/all/0/1\">Dmytro R. Popovych</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bihlo_A/0/1/0/all/0/1\">Alex Bihlo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popovych_R/0/1/0/all/0/1\">Roman O. Popovych</a>",
          "description": "Current physics-informed (standard or operator) neural networks still rely on\naccurately learning the initial conditions of the system they are solving. In\ncontrast, standard numerical methods evolve such initial conditions without\nneeding to learn these. In this study, we propose to improve current\nphysics-informed deep learning strategies such that initial conditions do not\nneed to be learned and are represented exactly in the predicted solution.\nMoreover, this method guarantees that when a DeepONet is applied multiple times\nto time step a solution, the resulting function is continuous.",
          "link": "http://arxiv.org/abs/2309.07899",
          "publishedOn": "2023-09-16T00:40:57.037Z",
          "wordCount": null,
          "title": "Improving physics-informed DeepONets with hard constraints. (arXiv:2309.07899v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07860",
          "author": "<a href=\"http://arxiv.org/find/hep-ph/1/au:+Forestano_R/0/1/0/all/0/1\">Roy T. Forestano</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Matchev_K/0/1/0/all/0/1\">Konstantin T. Matchev</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Matcheva_K/0/1/0/all/0/1\">Katia Matcheva</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Roman_A/0/1/0/all/0/1\">Alexander Roman</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Unlu_E/0/1/0/all/0/1\">Eyup B. Unlu</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Verner_S/0/1/0/all/0/1\">Sarunas Verner</a>",
          "description": "Deep learning was recently successfully used in deriving symmetry\ntransformations that preserve important physics quantities. Being completely\nagnostic, these techniques postpone the identification of the discovered\nsymmetries to a later stage. In this letter we propose methods for examining\nand identifying the group-theoretic structure of such machine-learned\nsymmetries. We design loss functions which probe the subalgebra structure\neither during the deep learning stage of symmetry discovery or in a subsequent\npost-processing stage. We illustrate the new methods with examples from the\nU(n) Lie group family, obtaining the respective subalgebra decompositions. As\nan application to particle physics, we demonstrate the identification of the\nresidual symmetries after the spontaneous breaking of non-Abelian gauge\nsymmetries like SU(3) and SU(5) which are commonly used in model building.",
          "link": "http://arxiv.org/abs/2309.07860",
          "publishedOn": "2023-09-16T00:40:57.008Z",
          "wordCount": null,
          "title": "Identifying the Group-Theoretic Structure of Machine-Learned Symmetries. (arXiv:2309.07860v1 [hep-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07690",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Xu_X/0/1/0/all/0/1\">Xiran Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yan_Y/0/1/0/all/0/1\">Yujie Yan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1\">Xihong Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1\">Jing Chen</a>",
          "description": "Auditory spatial attention detection (ASAD) aims to decode the attended\nspatial location with EEG in a multiple-speaker setting. ASAD methods are\ninspired by the brain lateralization of cortical neural responses during the\nprocessing of auditory spatial attention, and show promising performance for\nthe task of auditory attention decoding (AAD) with neural recordings. In the\nprevious ASAD methods, the spatial distribution of EEG electrodes is not fully\nexploited, which may limit the performance of these methods. In the present\nwork, by transforming the original EEG channels into a two-dimensional (2D)\nspatial topological map, the EEG data is transformed into a three-dimensional\n(3D) arrangement containing spatial-temporal information. And then a 3D deep\nconvolutional neural network (DenseNet-3D) is used to extract temporal and\nspatial features of the neural representation for the attended locations. The\nresults show that the proposed method achieves higher decoding accuracy than\nthe state-of-the-art (SOTA) method (94.4% compared to XANet's 90.6%) with\n1-second decision window for the widely used KULeuven (KUL) dataset, and the\ncode to implement our work is available on Github:\n\nhttps://github.com/xuxiran/ASAD_DenseNet",
          "link": "http://arxiv.org/abs/2309.07690",
          "publishedOn": "2023-09-16T00:40:57.000Z",
          "wordCount": null,
          "title": "A DenseNet-based method for decoding auditory spatial attention with EEG. (arXiv:2309.07690v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.01996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1\">Ke Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mingjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouchen Lin</a>",
          "description": "Adversarial robustness, which primarily comprises sensitivity-based\nrobustness and spatial robustness, plays an integral part in achieving robust\ngeneralization. In this paper, we endeavor to design strategies to achieve\nuniversal adversarial robustness. To achieve this, we first investigate the\nrelatively less-explored realm of spatial robustness. Then, we integrate the\nexisting spatial robustness methods by incorporating both local and global\nspatial vulnerability into a unified spatial attack and adversarial training\napproach. Furthermore, we present a comprehensive relationship between natural\naccuracy, sensitivity-based robustness, and spatial robustness, supported by\nstrong evidence from the perspective of robust representation. Crucially, to\nreconcile the interplay between the mutual impacts of various robustness\ncomponents into one unified framework, we incorporate the \\textit{Pareto\ncriterion} into the adversarial robustness analysis, yielding a novel strategy\ncalled Pareto Adversarial Training for achieving universal robustness. The\nresulting Pareto front, which delineates the set of optimal solutions, provides\nan optimal balance between natural accuracy and various adversarial robustness.\nThis sheds light on solutions for achieving universal robustness in the future.\nTo the best of our knowledge, we are the first to consider universal\nadversarial robustness via multi-objective optimization.",
          "link": "http://arxiv.org/abs/2111.01996",
          "publishedOn": "2023-09-16T00:40:56.999Z",
          "wordCount": null,
          "title": "Pareto Adversarial Robustness: Balancing Spatial Robustness and Sensitivity-based Robustness. (arXiv:2111.01996v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07675",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zadem_M/0/1/0/all/0/1\">Mehdi Zadem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mover_S/0/1/0/all/0/1\">Sergio Mover</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_S/0/1/0/all/0/1\">Sao Mai Nguyen</a>",
          "description": "Open-ended learning benefits immensely from the use of symbolic methods for\ngoal representation as they offer ways to structure knowledge for efficient and\ntransferable learning. However, the existing Hierarchical Reinforcement\nLearning (HRL) approaches relying on symbolic reasoning are often limited as\nthey require a manual goal representation. The challenge in autonomously\ndiscovering a symbolic goal representation is that it must preserve critical\ninformation, such as the environment dynamics. In this paper, we propose a\ndevelopmental mechanism for goal discovery via an emergent representation that\nabstracts (i.e., groups together) sets of environment states that have similar\nroles in the task. We introduce a Feudal HRL algorithm that concurrently learns\nboth the goal representation and a hierarchical policy. The algorithm uses\nsymbolic reachability analysis for neural networks to approximate the\ntransition relation among sets of states and to refine the goal representation.\nWe evaluate our approach on complex navigation tasks, showing the learned\nrepresentation is interpretable, transferrable and results in data efficient\nlearning.",
          "link": "http://arxiv.org/abs/2309.07675",
          "publishedOn": "2023-09-16T00:40:56.985Z",
          "wordCount": null,
          "title": "Goal Space Abstraction in Hierarchical Reinforcement Learning via Set-Based Reachability Analysis. (arXiv:2309.07675v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07402",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1\">Jiaren Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Q/0/1/0/all/0/1\">Quanyu Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xiao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xiaochen Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1\">Jing Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_J/0/1/0/all/0/1\">James Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwok_K/0/1/0/all/0/1\">Ka-Wai Kwok</a>",
          "description": "Label scarcity in a graph is frequently encountered in real-world\napplications due to the high cost of data labeling. To this end,\nsemi-supervised domain adaptation (SSDA) on graphs aims to leverage the\nknowledge of a labeled source graph to aid in node classification on a target\ngraph with limited labels. SSDA tasks need to overcome the domain gap between\nthe source and target graphs. However, to date, this challenging research\nproblem has yet to be formally considered by the existing approaches designed\nfor cross-graph node classification. To tackle the SSDA problem on graphs, a\nnovel method called SemiGCL is proposed, which benefits from graph contrastive\nlearning and minimax entropy training. SemiGCL generates informative node\nrepresentations by contrasting the representations learned from a graph's local\nand global views. Additionally, SemiGCL is adversarially optimized with the\nentropy loss of unlabeled target nodes to reduce domain divergence.\nExperimental results on benchmark datasets demonstrate that SemiGCL outperforms\nthe state-of-the-art baselines on the SSDA tasks.",
          "link": "http://arxiv.org/abs/2309.07402",
          "publishedOn": "2023-09-16T00:40:56.981Z",
          "wordCount": null,
          "title": "Semi-supervised Domain Adaptation on Graphs with Contrastive Learning and Minimax Entropy. (arXiv:2309.07402v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07867",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mingyuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhendong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Huangjie Zheng</a>",
          "description": "We introduce beta diffusion, a novel generative modeling method that\nintegrates demasking and denoising to generate data within bounded ranges.\nUsing scaled and shifted beta distributions, beta diffusion utilizes\nmultiplicative transitions over time to create both forward and reverse\ndiffusion processes, maintaining beta distributions in both the forward\nmarginals and the reverse conditionals, given the data at any point in time.\nUnlike traditional diffusion-based generative models relying on additive\nGaussian noise and reweighted evidence lower bounds (ELBOs), beta diffusion is\nmultiplicative and optimized with KL-divergence upper bounds (KLUBs) derived\nfrom the convexity of the KL divergence. We demonstrate that the proposed KLUBs\nare more effective for optimizing beta diffusion compared to negative ELBOs,\nwhich can also be derived as the KLUBs of the same KL divergence with its two\narguments swapped. The loss function of beta diffusion, expressed in terms of\nBregman divergence, further supports the efficacy of KLUBs for optimization.\nExperimental results on both synthetic data and natural images demonstrate the\nunique capabilities of beta diffusion in generative modeling of range-bounded\ndata and validate the effectiveness of KLUBs in optimizing diffusion models,\nthereby making them valuable additions to the family of diffusion-based\ngenerative models and the optimization techniques used to train them.",
          "link": "http://arxiv.org/abs/2309.07867",
          "publishedOn": "2023-09-16T00:40:56.981Z",
          "wordCount": null,
          "title": "Beta Diffusion. (arXiv:2309.07867v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.03778",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kuijk_K/0/1/0/all/0/1\">Kristian van Kuijk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dirksen_M/0/1/0/all/0/1\">Mark Dirksen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seiler_C/0/1/0/all/0/1\">Christof Seiler</a>",
          "description": "UCI WorldTour races, the premier men's elite road cycling tour, are grueling\nevents that put physical fitness and endurance of riders to the test. The\ncoaches of Team Jumbo-Visma have long been responsible for predicting the\nenergy needs of each rider of the Dutch team for every race on the calendar.\nThose must be estimated to ensure riders have the energy and resources\nnecessary to maintain a high level of performance throughout a race. This task,\nhowever, is both time-consuming and challenging, as it requires precise\nestimates of race speed and power output. Traditionally, the approach to\npredicting energy needs has relied on judgement and experience of coaches, but\nthis method has its limitations and often leads to inaccurate predictions. In\nthis paper, we propose a new, more effective approach to predicting energy\nneeds for cycling races. By predicting the speed and power with regression\nmodels, we provide the coaches with calorie needs estimates for each individual\nrider per stage instantly. In addition, we compare methods to quantify\nuncertainty using conformal prediction. The empirical analysis of the\njackknife+, jackknife-minmax, jackknife-minmax-after-bootstrap, CV+, CV-minmax,\nconformalized quantile regression, and inductive conformal prediction methods\nin conformal prediction reveals that all methods achieve valid prediction\nintervals. All but minmax-based methods also produce sufficiently narrow\nprediction intervals for decision-making. Furthermore, methods computing\nprediction intervals of fixed size produce tighter intervals for low\nsignificance values. Among the methods computing intervals of varying length\nacross the input space, inductive conformal prediction computes narrower\nprediction intervals at larger significance level.",
          "link": "http://arxiv.org/abs/2304.03778",
          "publishedOn": "2023-09-16T00:40:56.981Z",
          "wordCount": null,
          "title": "Conformal Regression in Calorie Prediction for Team Jumbo-Visma. (arXiv:2304.03778v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07666",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Montesuma_E/0/1/0/all/0/1\">Eduardo Fernandes Montesuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mboula_F/0/1/0/all/0/1\">Fred Ngol&#xe8; Mboula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Souloumiac_A/0/1/0/all/0/1\">Antoine Souloumiac</a>",
          "description": "In this paper, we consider the intersection of two problems in machine\nlearning: Multi-Source Domain Adaptation (MSDA) and Dataset Distillation (DD).\nOn the one hand, the first considers adapting multiple heterogeneous labeled\nsource domains to an unlabeled target domain. On the other hand, the second\nattacks the problem of synthesizing a small summary containing all the\ninformation about the datasets. We thus consider a new problem called MSDA-DD.\nTo solve it, we adapt previous works in the MSDA literature, such as\nWasserstein Barycenter Transport and Dataset Dictionary Learning, as well as DD\nmethod Distribution Matching. We thoroughly experiment with this novel problem\non four benchmarks (Caltech-Office 10, Tennessee-Eastman Process, Continuous\nStirred Tank Reactor, and Case Western Reserve University), where we show that,\neven with as little as 1 sample per class, one achieves state-of-the-art\nadaptation performance.",
          "link": "http://arxiv.org/abs/2309.07666",
          "publishedOn": "2023-09-16T00:40:56.976Z",
          "wordCount": null,
          "title": "Multi-Source Domain Adaptation meets Dataset Distillation through Dataset Dictionary Learning. (arXiv:2309.07666v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07030",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nagai_J/0/1/0/all/0/1\">James S. Nagai</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Costa_I/0/1/0/all/0/1\">Ivan G. Costa</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Schaub_M/0/1/0/all/0/1\">Michael T. Schaub</a> (2) ((1) Institute for Computational Genomics, RWTH Aachen Medical Faculty, Germany, (2) Department of Computer Science, RWTH Aachen University, Germany)",
          "description": "Comparing graphs by means of optimal transport has recently gained\nsignificant attention, as the distances induced by optimal transport provide\nboth a principled metric between graphs as well as an interpretable description\nof the associated changes between graphs in terms of a transport plan. As the\nlack of symmetry introduces challenges in the typically considered\nformulations, optimal transport distances for graphs have mostly been developed\nfor undirected graphs. Here, we propose two distance measures to compare\ndirected graphs based on variants of optimal transport: (i) an earth movers\ndistance (Wasserstein) and (ii) a Gromov-Wasserstein (GW) distance. We evaluate\nthese two distances and discuss their relative performance for both simulated\ngraph data and real-world directed cell-cell communication graphs, inferred\nfrom single-cell RNA-seq data.",
          "link": "http://arxiv.org/abs/2309.07030",
          "publishedOn": "2023-09-16T00:40:56.976Z",
          "wordCount": null,
          "title": "Optimal transport distances for directed, weighted graphs: a case study with cell-cell communication networks. (arXiv:2309.07030v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.04100",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Dong_S/0/1/0/all/0/1\">Siyuan Dong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Feyter_H/0/1/0/all/0/1\">Henk M. De Feyter</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Thomas_M/0/1/0/all/0/1\">Monique A. Thomas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Graaf_R/0/1/0/all/0/1\">Robin A. de Graaf</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Duncan_J/0/1/0/all/0/1\">James S. Duncan</a>",
          "description": "Purpose: Common to most MRSI techniques, the spatial resolution and the\nminimal scan duration of Deuterium Metabolic Imaging (DMI) are limited by the\nachievable SNR. This work presents a deep learning method for sensitivity\nenhancement of DMI.\n\nMethods: A convolutional neural network (CNN) was designed to estimate the\n2H-labeled metabolite concentrations from low SNR and distorted DMI FIDs. The\nCNN was trained with synthetic data that represent a range of SNR levels\ntypically encountered in vivo. The estimation precision was further improved by\nfine-tuning the CNN with MRI-based edge-preserving regularization for each DMI\ndataset. The proposed processing method, PReserved Edge ConvolutIonal neural\nnetwork for Sensitivity Enhanced DMI (PRECISE-DMI), was applied to simulation\nstudies and in vivo experiments to evaluate the anticipated improvements in SNR\nand investigate the potential for inaccuracies.\n\nResults: PRECISE-DMI visually improved the metabolic maps of low SNR\ndatasets, and quantitatively provided higher precision than the standard\nFourier reconstruction. Processing of DMI data acquired in rat brain tumor\nmodels resulted in more precise determination of 2H-labeled lactate and\nglutamate + glutamine levels, at increased spatial resolution (from >8 to 2\n$\\mu$L) or shortened scan time (from 32 to 4 min) compared to standard\nacquisitions. However, rigorous SD-bias analyses showed that overuse of the\nedge-preserving regularization can compromise the accuracy of the results.\n\nConclusion: PRECISE-DMI allows a flexible trade-off between enhancing the\nsensitivity of DMI and minimizing the inaccuracies. With typical settings, the\nDMI sensitivity can be improved by 3-fold while retaining the capability to\ndetect local signal variations.",
          "link": "http://arxiv.org/abs/2309.04100",
          "publishedOn": "2023-09-16T00:40:56.973Z",
          "wordCount": null,
          "title": "Preserved Edge Convolutional Neural Network for Sensitivity Enhancement of Deuterium Metabolic Imaging (DMI). (arXiv:2309.04100v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07486",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Aghamolaei_S/0/1/0/all/0/1\">Sepideh Aghamolaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghodsi_M/0/1/0/all/0/1\">Mohammad Ghodsi</a>",
          "description": "Given a set of points labeled with $k$ labels, we introduce the heat map\nsorting problem as reordering and merging the points and dimensions while\npreserving the clusters (labels). A cluster is preserved if it remains\nconnected, i.e., if it is not split into several clusters and no two clusters\nare merged.\n\nWe prove the problem is NP-hard and we give a fixed-parameter algorithm with\na constant number of rounds in the massively parallel computation model, where\neach machine has a sublinear memory and the total memory of the machines is\nlinear. We give an approximation algorithm for a NP-hard special case of the\nproblem. We empirically compare our algorithm with k-means and density-based\nclustering (DBSCAN) using a dimensionality reduction via locality-sensitive\nhashing on several directed and undirected graphs of email and computer\nnetworks.",
          "link": "http://arxiv.org/abs/2309.07486",
          "publishedOn": "2023-09-16T00:40:56.972Z",
          "wordCount": null,
          "title": "Massively-Parallel Heat Map Sorting and Applications To Explainable Clustering. (arXiv:2309.07486v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.02048",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Muyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Ji Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1\">Chenlin Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1\">Stefano Ermon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Song Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun-Yan Zhu</a>",
          "description": "During image editing, existing deep generative models tend to re-synthesize\nthe entire output from scratch, including the unedited regions. This leads to a\nsignificant waste of computation, especially for minor editing operations. In\nthis work, we present Spatially Sparse Inference (SSI), a general-purpose\ntechnique that selectively performs computation for edited regions and\naccelerates various generative models, including both conditional GANs and\ndiffusion models. Our key observation is that users prone to gradually edit the\ninput image. This motivates us to cache and reuse the feature maps of the\noriginal image. Given an edited image, we sparsely apply the convolutional\nfilters to the edited regions while reusing the cached features for the\nunedited areas. Based on our algorithm, we further propose Sparse Incremental\nGenerative Engine (SIGE) to convert the computation reduction to latency\nreduction on off-the-shelf hardware. With about $1\\%$-area edits, SIGE\naccelerates DDPM by $3.0\\times$ on NVIDIA RTX 3090 and $4.6\\times$ on Apple M1\nPro GPU, Stable Diffusion by $7.2\\times$ on 3090, and GauGAN by $5.6\\times$ on\n3090 and $5.2\\times$ on M1 Pro GPU. Compared to our conference version, we\nextend SIGE to accommodate attention layers and apply it to Stable Diffusion.\nAdditionally, we offer support for Apple M1 Pro GPU and include more results\nwith large and sequential edits.",
          "link": "http://arxiv.org/abs/2211.02048",
          "publishedOn": "2023-09-16T00:40:56.941Z",
          "wordCount": null,
          "title": "Efficient Spatially Sparse Inference for Conditional GANs and Diffusion Models. (arXiv:2211.02048v4 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pepino_L/0/1/0/all/0/1\">Leonardo Pepino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riera_P/0/1/0/all/0/1\">Pablo Riera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrer_L/0/1/0/all/0/1\">Luciana Ferrer</a>",
          "description": "The goal of universal audio representation learning is to obtain foundational\nmodels that can be used for a variety of downstream tasks involving speech,\nmusic or environmental sounds. To approach this problem, methods inspired by\nself-supervised models from NLP, like BERT, are often used and adapted to\naudio. These models rely on the discrete nature of text, hence adopting this\ntype of approach for audio processing requires either a change in the learning\nobjective or mapping the audio signal to a set of discrete classes. In this\nwork, we explore the use of EnCodec, a neural audio codec, to generate discrete\ntargets for learning an universal audio model based on a masked autoencoder\n(MAE). We evaluate this approach, which we call EncodecMAE, on a wide range of\naudio tasks spanning speech, music and environmental sounds, achieving\nperformances comparable or better than leading audio representation models.",
          "link": "http://arxiv.org/abs/2309.07391",
          "publishedOn": "2023-09-16T00:40:56.940Z",
          "wordCount": null,
          "title": "EnCodecMAE: Leveraging neural codecs for universal audio representation learning. (arXiv:2309.07391v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.05928",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frei_S/0/1/0/all/0/1\">Spencer Frei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterji_N/0/1/0/all/0/1\">Niladri S. Chatterji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1\">Peter L. Bartlett</a>",
          "description": "Benign overfitting, the phenomenon where interpolating models generalize well\nin the presence of noisy data, was first observed in neural network models\ntrained with gradient descent. To better understand this empirical observation,\nwe consider the generalization error of two-layer neural networks trained to\ninterpolation by gradient descent on the logistic loss following random\ninitialization. We assume the data comes from well-separated class-conditional\nlog-concave distributions and allow for a constant fraction of the training\nlabels to be corrupted by an adversary. We show that in this setting, neural\nnetworks exhibit benign overfitting: they can be driven to zero training error,\nperfectly fitting any noisy training labels, and simultaneously achieve minimax\noptimal test error. In contrast to previous work on benign overfitting that\nrequire linear or kernel-based predictors, our analysis holds in a setting\nwhere both the model and learning dynamics are fundamentally nonlinear.",
          "link": "http://arxiv.org/abs/2202.05928",
          "publishedOn": "2023-09-16T00:40:56.940Z",
          "wordCount": null,
          "title": "Benign Overfitting without Linearity: Neural Network Classifiers Trained by Gradient Descent for Noisy Linear Data. (arXiv:2202.05928v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07261",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Du_J/0/1/0/all/0/1\">Jin-Hong Du</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wasserman_L/0/1/0/all/0/1\">Larry Wasserman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Roeder_K/0/1/0/all/0/1\">Kathryn Roeder</a>",
          "description": "Tens of thousands of simultaneous hypothesis tests are routinely performed in\ngenomic studies to identify differentially expressed genes. However, due to\nunmeasured confounders, many standard statistical approaches may be\nsubstantially biased. This paper investigates the large-scale hypothesis\ntesting problem for multivariate generalized linear models in the presence of\nconfounding effects. Under arbitrary confounding mechanisms, we propose a\nunified statistical estimation and inference framework that harnesses\northogonal structures and integrates linear projections into three key stages.\nIt first leverages multivariate responses to separate marginal and uncorrelated\nconfounding effects, recovering the confounding coefficients' column space.\nSubsequently, latent factors and primary effects are jointly estimated,\nutilizing $\\ell_1$-regularization for sparsity while imposing orthogonality\nonto confounding coefficients. Finally, we incorporate projected and weighted\nbias-correction steps for hypothesis testing. Theoretically, we establish\nvarious effects' identification conditions and non-asymptotic error bounds. We\nshow effective Type-I error control of asymptotic $z$-tests as sample and\nresponse sizes approach infinity. Numerical experiments demonstrate that the\nproposed method controls the false discovery rate by the Benjamini-Hochberg\nprocedure and is more powerful than alternative methods. By comparing\nsingle-cell RNA-seq counts from two groups of samples, we demonstrate the\nsuitability of adjusting confounding effects when significant covariates are\nabsent from the model.",
          "link": "http://arxiv.org/abs/2309.07261",
          "publishedOn": "2023-09-16T00:40:56.939Z",
          "wordCount": null,
          "title": "Simultaneous inference for generalized linear models with unmeasured confounders. (arXiv:2309.07261v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07147",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Fan_C/0/1/0/all/0/1\">Cunhang Fan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyu Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_W/0/1/0/all/0/1\">Wei Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xue_J/0/1/0/all/0/1\">Jun Xue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tao_J/0/1/0/all/0/1\">Jianhua Tao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yi_J/0/1/0/all/0/1\">Jiangyan Yi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lv_Z/0/1/0/all/0/1\">Zhao Lv</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1\">Xiaopei Wu</a>",
          "description": "Auditory Attention Detection (AAD) aims to detect target speaker from brain\nsignals in a multi-speaker environment. Although EEG-based AAD methods have\nshown promising results in recent years, current approaches primarily rely on\ntraditional convolutional neural network designed for processing Euclidean data\nlike images. This makes it challenging to handle EEG signals, which possess\nnon-Euclidean characteristics. In order to address this problem, this paper\nproposes a dynamical graph self-distillation (DGSD) approach for AAD, which\ndoes not require speech stimuli as input. Specifically, to effectively\nrepresent the non-Euclidean properties of EEG signals, dynamical graph\nconvolutional networks are applied to represent the graph structure of EEG\nsignals, which can also extract crucial features related to auditory spatial\nattention in EEG signals. In addition, to further improve AAD detection\nperformance, self-distillation, consisting of feature distillation and\nhierarchical distillation strategies at each layer, is integrated. These\nstrategies leverage features and classification results from the deepest\nnetwork layers to guide the learning of shallow layers. Our experiments are\nconducted on two publicly available datasets, KUL and DTU. Under a 1-second\ntime window, we achieve results of 90.0\\% and 79.6\\% accuracy on KUL and DTU,\nrespectively. We compare our DGSD method with competitive baselines, and the\nexperimental results indicate that the detection performance of our proposed\nDGSD method is not only superior to the best reproducible baseline but also\nsignificantly reduces the number of trainable parameters by approximately 100\ntimes.",
          "link": "http://arxiv.org/abs/2309.07147",
          "publishedOn": "2023-09-16T00:40:56.938Z",
          "wordCount": null,
          "title": "DGSD: Dynamical Graph Self-Distillation for EEG-Based Auditory Spatial Attention Detection. (arXiv:2309.07147v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07163",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+KN_V/0/1/0/all/0/1\">Vishnu KN</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gupta_C/0/1/0/all/0/1\">Cota Navin Gupta</a>",
          "description": "This article summarizes a systematic review of the electroencephalography\n(EEG)-based cognitive workload (CWL) estimation. The focus of the article is\ntwofold: identify the disparate experimental paradigms used for reliably\neliciting discreet and quantifiable levels of cognitive load and the specific\nnature and representational structure of the commonly used input formulations\nin deep neural networks (DNNs) used for signal classification. The analysis\nrevealed a number of studies using EEG signals in its native representation of\na two-dimensional matrix for offline classification of CWL. However, only a few\nstudies adopted an online or pseudo-online classification strategy for\nreal-time CWL estimation. Further, only a couple of interpretable DNNs and a\nsingle generative model were employed for cognitive load detection till date\nduring this review. More often than not, researchers were using DNNs as\nblack-box type models. In conclusion, DNNs prove to be valuable tools for\nclassifying EEG signals, primarily due to the substantial modeling power\nprovided by the depth of their network architecture. It is further suggested\nthat interpretable and explainable DNN models must be employed for cognitive\nworkload estimation since existing methods are limited in the face of the\nnon-stationary nature of the signal.",
          "link": "http://arxiv.org/abs/2309.07163",
          "publishedOn": "2023-09-16T00:40:56.937Z",
          "wordCount": null,
          "title": "Systematic Review of Experimental Paradigms and Deep Neural Networks for Electroencephalography-Based Cognitive Workload Detection. (arXiv:2309.07163v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07181",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mince_F/0/1/0/all/0/1\">Fraser Mince</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinh_D/0/1/0/all/0/1\">Dzung Dinh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kgomo_J/0/1/0/all/0/1\">Jonas Kgomo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thompson_N/0/1/0/all/0/1\">Neil Thompson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooker_S/0/1/0/all/0/1\">Sara Hooker</a>",
          "description": "Pushing the boundaries of machine learning often requires exploring different\nhardware and software combinations. However, the freedom to experiment across\ndifferent tooling stacks can be at odds with the drive for efficiency, which\nhas produced increasingly specialized AI hardware and incentivized\nconsolidation around a narrow set of ML frameworks. Exploratory research can be\nrestricted if software and hardware are co-evolving, making it even harder to\nstray away from mainstream ideas that work well with popular tooling stacks.\nWhile this friction increasingly impacts the rate of innovation in machine\nlearning, to our knowledge the lack of portability in tooling has not been\nquantified. In this work, we ask: How portable are popular ML software\nframeworks? We conduct a large-scale study of the portability of mainstream ML\nframeworks across different hardware types. Our findings paint an uncomfortable\npicture -- frameworks can lose more than 40% of their key functions when ported\nto other hardware. Worse, even when functions are portable, the slowdown in\ntheir performance can be extreme and render performance untenable.\nCollectively, our results reveal how costly straying from a narrow set of\nhardware-software combinations can be - and suggest that specialization of\nhardware impedes innovation in machine learning research.",
          "link": "http://arxiv.org/abs/2309.07181",
          "publishedOn": "2023-09-16T00:40:56.937Z",
          "wordCount": null,
          "title": "The Grand Illusion: The Myth of Software Portability and Implications for ML Progress. (arXiv:2309.07181v1 [cs.SE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07192",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Turrisi_R/0/1/0/all/0/1\">Rosanna Turrisi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Verri_A/0/1/0/all/0/1\">Alessandro Verri</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Barla_A/0/1/0/all/0/1\">Annalisa Barla</a>",
          "description": "Machine Learning (ML) has emerged as a promising approach in healthcare,\noutperforming traditional statistical techniques. However, to establish ML as a\nreliable tool in clinical practice, adherence to best practices regarding data\nhandling, experimental design, and model evaluation is crucial. This work\nsummarizes and strictly observes such practices to ensure reproducible and\nreliable ML. Specifically, we focus on Alzheimer's Disease (AD) detection,\nwhich serves as a paradigmatic example of challenging problem in healthcare. We\ninvestigate the impact of different data augmentation techniques and model\ncomplexity on the overall performance. We consider MRI data from ADNI dataset\nto address a classification problem employing 3D Convolutional Neural Network\n(CNN). The experiments are designed to compensate for data scarcity and initial\nrandom parameters by utilizing cross-validation and multiple training trials.\nWithin this framework, we train 15 predictive models, considering three\ndifferent data augmentation strategies and five distinct 3D CNN architectures,\neach varying in the number of convolutional layers. Specifically, the\naugmentation strategies are based on affine transformations, such as zoom,\nshift, and rotation, applied concurrently or separately. The combined effect of\ndata augmentation and model complexity leads to a variation in prediction\nperformance up to 10% of accuracy. When affine transformation are applied\nseparately, the model is more accurate, independently from the adopted\narchitecture. For all strategies, the model accuracy followed a concave\nbehavior at increasing number of convolutional layers, peaking at an\nintermediate value of layers. The best model (8 CL, (B)) is the most stable\nacross cross-validation folds and training trials, reaching excellent\nperformance both on the testing set and on an external test set.",
          "link": "http://arxiv.org/abs/2309.07192",
          "publishedOn": "2023-09-16T00:40:56.937Z",
          "wordCount": null,
          "title": "The effect of data augmentation and 3D-CNN depth on Alzheimer's Disease detection. (arXiv:2309.07192v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07481",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Baggenstoss_P/0/1/0/all/0/1\">Paul M Baggenstoss</a>",
          "description": "In this paper, we exploit the unique properties of a deterministic projected\nbelief network (D-PBN) to take full advantage of trainable compound activation\nfunctions (TCAs). A D-PBN is a type of auto-encoder that operates by \"backing\nup\" through a feed-forward neural network. TCAs are activation functions with\ncomplex monotonic-increasing shapes that change the distribution of the data so\nthat the linear transformation that follows is more effective. Because a D-PBN\noperates by \"backing up\", the TCAs are inverted in the reconstruction process,\nrestoring the original distribution of the data, thus taking advantage of a\ngiven TCA in both analysis and reconstruction. In this paper, we show that a\nD-PBN auto-encoder with TCAs can significantly out-perform standard\nauto-encoders including variational auto-encoders.",
          "link": "http://arxiv.org/abs/2309.07481",
          "publishedOn": "2023-09-16T00:40:56.931Z",
          "wordCount": null,
          "title": "Improved Auto-Encoding using Deterministic Projected Belief Networks. (arXiv:2309.07481v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chamma_A/0/1/0/all/0/1\">Ahmad Chamma</a> (1 and 2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Engemann_D/0/1/0/all/0/1\">Denis A. Engemann</a> (4), <a href=\"http://arxiv.org/find/cs/1/au:+Thirion_B/0/1/0/all/0/1\">Bertrand Thirion</a> (1 and 2 and 3) ((1) Inria, (2) Universite Paris Saclay, (3) CEA, (4) Roche Pharma Research and Early Development, Neuroscience and Rare Diseases, Roche Innovation Center Basel, F. Hoffmann-La Roche Ltd., Basel, Switzerland)",
          "description": "Variable importance assessment has become a crucial step in machine-learning\napplications when using complex learners, such as deep neural networks, on\nlarge-scale data. Removal-based importance assessment is currently the\nreference approach, particularly when statistical guarantees are sought to\njustify variable inclusion. It is often implemented with variable permutation\nschemes. On the flip side, these approaches risk misidentifying unimportant\nvariables as important in the presence of correlations among covariates. Here\nwe develop a systematic approach for studying Conditional Permutation\nImportance (CPI) that is model agnostic and computationally lean, as well as\nreusable benchmarks of state-of-the-art variable importance estimators. We show\ntheoretically and empirically that $\\textit{CPI}$ overcomes the limitations of\nstandard permutation importance by providing accurate type-I error control.\nWhen used with a deep neural network, $\\textit{CPI}$ consistently showed top\naccuracy across benchmarks. An empirical benchmark on real-world data analysis\nin a large-scale medical dataset showed that $\\textit{CPI}$ provides a more\nparsimonious selection of statistically significant variables. Our results\nsuggest that $\\textit{CPI}$ can be readily used as drop-in replacement for\npermutation-based methods.",
          "link": "http://arxiv.org/abs/2309.07593",
          "publishedOn": "2023-09-16T00:40:56.931Z",
          "wordCount": null,
          "title": "Statistically Valid Variable Importance Assessment through Conditional Permutations. (arXiv:2309.07593v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07778",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Vorontsov_E/0/1/0/all/0/1\">Eugene Vorontsov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bozkurt_A/0/1/0/all/0/1\">Alican Bozkurt</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Casson_A/0/1/0/all/0/1\">Adam Casson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shaikovski_G/0/1/0/all/0/1\">George Shaikovski</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zelechowski_M/0/1/0/all/0/1\">Michal Zelechowski</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_S/0/1/0/all/0/1\">Siqi Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mathieu_P/0/1/0/all/0/1\">Philippe Mathieu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Eck_A/0/1/0/all/0/1\">Alexander van Eck</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_D/0/1/0/all/0/1\">Donghun Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Viret_J/0/1/0/all/0/1\">Julian Viret</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Robert_E/0/1/0/all/0/1\">Eric Robert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1\">Yi Kan Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kun_J/0/1/0/all/0/1\">Jeremy D. Kun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Le_M/0/1/0/all/0/1\">Matthew C. H. Le</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bernhard_J/0/1/0/all/0/1\">Jan Bernhard</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Godrich_R/0/1/0/all/0/1\">Ran A. Godrich</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Oakley_G/0/1/0/all/0/1\">Gerard Oakley</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Millar_E/0/1/0/all/0/1\">Ewan Millar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hanna_M/0/1/0/all/0/1\">Matthew Hanna</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Retamero_J/0/1/0/all/0/1\">Juan Retamero</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moye_W/0/1/0/all/0/1\">William A. Moye</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yousfi_R/0/1/0/all/0/1\">Razik Yousfi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kanan_C/0/1/0/all/0/1\">Christopher Kanan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Klimstra_D/0/1/0/all/0/1\">David Klimstra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rothrock_B/0/1/0/all/0/1\">Brandon Rothrock</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fuchs_T/0/1/0/all/0/1\">Thomas J. Fuchs</a>",
          "description": "Computational pathology uses artificial intelligence to enable precision\nmedicine and decision support systems through the analysis of whole slide\nimages. It has the potential to revolutionize the diagnosis and treatment of\ncancer. However, a major challenge to this objective is that for many specific\ncomputational pathology tasks the amount of data is inadequate for development.\nTo address this challenge, we created Virchow, a 632 million parameter deep\nneural network foundation model for computational pathology. Using\nself-supervised learning, Virchow is trained on 1.5 million hematoxylin and\neosin stained whole slide images from diverse tissue groups, which is orders of\nmagnitude more data than previous works. When evaluated on downstream tasks\nincluding tile-level pan-cancer detection and subtyping and slide-level\nbiomarker prediction, Virchow outperforms state-of-the-art systems both on\ninternal datasets drawn from the same population as the pretraining data as\nwell as external public datasets. Virchow achieves 93% balanced accuracy for\npancancer tile classification, and AUCs of 0.983 for colon microsatellite\ninstability status prediction and 0.967 for breast CDH1 status prediction. The\ngains in performance highlight the importance of pretraining on massive\npathology image datasets, suggesting pretraining on even larger datasets could\ncontinue improving performance for many high-impact applications where limited\namounts of training data are available, such as drug outcome prediction.",
          "link": "http://arxiv.org/abs/2309.07778",
          "publishedOn": "2023-09-16T00:40:56.931Z",
          "wordCount": null,
          "title": "Virchow: A Million-Slide Digital Pathology Foundation Model. (arXiv:2309.07778v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07760",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Minh_A/0/1/0/all/0/1\">Anh Pham Thi Minh</a>",
          "description": "Large pre-trained vision-language models such as CLIP have demonstrated great\npotential in zero-shot transferability to downstream tasks. However, to attain\noptimal performance, the manual selection of prompts is necessary to improve\nalignment between the downstream image distribution and the textual class\ndescriptions. This manual prompt engineering is the major challenge for\ndeploying such models in practice since it requires domain expertise and is\nextremely time-consuming. To avoid non-trivial prompt engineering, recent work\nContext Optimization (CoOp) introduced the concept of prompt learning to the\nvision domain using learnable textual tokens. While CoOp can achieve\nsubstantial improvements over manual prompts, its learned context is worse\ngeneralizable to wider unseen classes within the same dataset. In this work, we\npresent Prompt Learning with Reparameterization Encoder (PRE) - a simple and\nefficient method that enhances the generalization ability of the learnable\nprompt to unseen classes while maintaining the capacity to learn Base classes.\nInstead of directly optimizing the prompts, PRE employs a prompt encoder to\nreparameterize the input prompt embeddings, enhancing the exploration of\ntask-specific knowledge from few-shot samples. Experiments and extensive\nablation studies on 8 benchmarks demonstrate that our approach is an efficient\nmethod for prompt learning. Specifically, PRE achieves a notable enhancement of\n5.60% in average accuracy on New classes and 3% in Harmonic mean compared to\nCoOp in the 16-shot setting, all achieved within a good training time.",
          "link": "http://arxiv.org/abs/2309.07760",
          "publishedOn": "2023-09-16T00:40:56.930Z",
          "wordCount": null,
          "title": "PRE: Vision-Language Prompt Learning with Reparameterization Encoder. (arXiv:2309.07760v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07412",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_T/0/1/0/all/0/1\">Ting-Han Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_T/0/1/0/all/0/1\">Ta-Chung Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudnicky_A/0/1/0/all/0/1\">Alexander I. Rudnicky</a>",
          "description": "In recent studies, linear recurrent neural networks (LRNNs) have achieved\nTransformer-level performance in natural language modeling and long-range\nmodeling while offering rapid parallel training and constant inference costs.\nWith the resurged interest in LRNNs, we study whether they can learn the hidden\nrules in training sequences, such as the grammatical structures of regular\nlanguage. We theoretically analyze some existing LRNNs and discover their\nlimitations on regular language. Motivated by the analysis, we propose a new\nLRNN equipped with a block-diagonal and input-dependent transition matrix.\nExperiments suggest that the proposed model is the only LRNN that can perform\nlength extrapolation on regular language tasks such as Sum, Even Pair, and\nModular Arithmetic.",
          "link": "http://arxiv.org/abs/2309.07412",
          "publishedOn": "2023-09-16T00:40:56.924Z",
          "wordCount": null,
          "title": "Advancing Regular Language Reasoning in Linear Recurrent Neural Networks. (arXiv:2309.07412v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07526",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Atienza_A/0/1/0/all/0/1\">Adrian Atienza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bardram_J/0/1/0/all/0/1\">Jakob Bardram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puthusserypady_S/0/1/0/all/0/1\">Sadasivan Puthusserypady</a>",
          "description": "By identifying similarities between successive inputs, Self-Supervised\nLearning (SSL) methods for time series analysis have demonstrated their\neffectiveness in encoding the inherent static characteristics of temporal data.\nHowever, an exclusive emphasis on similarities might result in representations\nthat overlook the dynamic attributes critical for modeling cardiovascular\ndiseases within a confined subject cohort. Introducing Distilled Encoding\nBeyond Similarities (DEBS), this paper pioneers an SSL approach that transcends\nmere similarities by integrating dissimilarities among positive pairs. The\nframework is applied to electrocardiogram (ECG) signals, leading to a notable\nenhancement of +10\\% in the detection accuracy of Atrial Fibrillation (AFib)\nacross diverse subjects. DEBS underscores the potential of attaining a more\nrefined representation by encoding the dynamic characteristics of time series\ndata, tapping into dissimilarities during the optimization process. Broadly,\nthe strategy delineated in this study holds the promise of unearthing novel\navenues for advancing SSL methodologies tailored to temporal data.",
          "link": "http://arxiv.org/abs/2309.07526",
          "publishedOn": "2023-09-16T00:40:56.924Z",
          "wordCount": null,
          "title": "Learning Beyond Similarities: Incorporating Dissimilarities between Positive Pairs in Self-Supervised Time Series Learning. (arXiv:2309.07526v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07277",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rosenberg_H/0/1/0/all/0/1\">Harrison Rosenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1\">Shimaa Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramesh_G/0/1/0/all/0/1\">Guruprasad V Ramesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vinayak_R/0/1/0/all/0/1\">Ramya Korlakai Vinayak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fawaz_K/0/1/0/all/0/1\">Kassem Fawaz</a>",
          "description": "Text-to-image diffusion models have achieved widespread popularity due to\ntheir unprecedented image generation capability. In particular, their ability\nto synthesize and modify human faces has spurred research into using generated\nface images in both training data augmentation and model performance\nassessments. In this paper, we study the efficacy and shortcomings of\ngenerative models in the context of face generation. Utilizing a combination of\nqualitative and quantitative measures, including embedding-based metrics and\nuser studies, we present a framework to audit the characteristics of generated\nfaces conditioned on a set of social attributes. We applied our framework on\nfaces generated through state-of-the-art text-to-image diffusion models. We\nidentify several limitations of face image generation that include faithfulness\nto the text prompt, demographic disparities, and distributional shifts.\nFurthermore, we present an analytical model that provides insights into how\ntraining data selection contributes to the performance of generative models.",
          "link": "http://arxiv.org/abs/2309.07277",
          "publishedOn": "2023-09-16T00:40:56.922Z",
          "wordCount": null,
          "title": "Unbiased Face Synthesis With Diffusion Models: Are We There Yet?. (arXiv:2309.07277v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07453",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Navarro_M/0/1/0/all/0/1\">Madeline Navarro</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Segarra_S/0/1/0/all/0/1\">Santiago Segarra</a>",
          "description": "The myriad complex systems with multiway interactions motivate the extension\nof graph-based pairwise connections to higher-order relations. In particular,\nthe simplicial complex has inspired generalizations of graph neural networks\n(GNNs) to simplicial complex-based models. Learning on such systems requires\nlarge amounts of data, which can be expensive or impossible to obtain. We\npropose data augmentation of simplicial complexes through both linear and\nnonlinear mixup mechanisms that return mixtures of existing labeled samples. In\naddition to traditional pairwise mixup, we present a convex clustering mixup\napproach for a data-driven relationship among several simplicial complexes. We\ntheoretically demonstrate that the resultant synthetic simplicial complexes\ninterpolate among existing data with respect to homomorphism densities. Our\nmethod is demonstrated on both synthetic and real-world datasets for simplicial\ncomplex classification.",
          "link": "http://arxiv.org/abs/2309.07453",
          "publishedOn": "2023-09-16T00:40:56.922Z",
          "wordCount": null,
          "title": "SC-MAD: Mixtures of Higher-order Networks for Data Augmentation. (arXiv:2309.07453v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07197",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Queyrut_S/0/1/0/all/0/1\">Simon Queyrut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schiavoni_V/0/1/0/all/0/1\">Valerio Schiavoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Felber_P/0/1/0/all/0/1\">Pascal Felber</a>",
          "description": "The main premise of federated learning (FL) is that machine learning model\nupdates are computed locally to preserve user data privacy. This approach\navoids by design user data to ever leave the perimeter of their device. Once\nthe updates aggregated, the model is broadcast to all nodes in the federation.\nHowever, without proper defenses, compromised nodes can probe the model inside\ntheir local memory in search for adversarial examples, which can lead to\ndangerous real-world scenarios. For instance, in image-based applications,\nadversarial examples consist of images slightly perturbed to the human eye\ngetting misclassified by the local model. These adversarial images are then\nlater presented to a victim node's counterpart model to replay the attack.\nTypical examples harness dissemination strategies such as altered traffic signs\n(patch attacks) no longer recognized by autonomous vehicles or seemingly\nunaltered samples that poison the local dataset of the FL scheme to undermine\nits robustness. Pelta is a novel shielding mechanism leveraging Trusted\nExecution Environments (TEEs) that reduce the ability of attackers to craft\nadversarial samples. Pelta masks inside the TEE the first part of the\nback-propagation chain rule, typically exploited by attackers to craft the\nmalicious samples. We evaluate Pelta on state-of-the-art accurate models using\nthree well-established datasets: CIFAR-10, CIFAR-100 and ImageNet. We show the\neffectiveness of Pelta in mitigating six white-box state-of-the-art adversarial\nattacks, such as Projected Gradient Descent, Momentum Iterative Method, Auto\nProjected Gradient Descent, the Carlini & Wagner attack. In particular, Pelta\nconstitutes the first attempt at defending an ensemble model against the\nSelf-Attention Gradient attack to the best of our knowledge. Our code is\navailable to the research community at https://github.com/queyrusi/Pelta.",
          "link": "http://arxiv.org/abs/2309.07197",
          "publishedOn": "2023-09-16T00:40:56.917Z",
          "wordCount": null,
          "title": "Mitigating Adversarial Attacks in Federated Learning with Trusted Execution Environments. (arXiv:2309.07197v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07172",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaoyan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hang Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horrocks_I/0/1/0/all/0/1\">Ian Horrocks</a>",
          "description": "This work investigates the applicability of recent generative Large Language\nModels (LLMs), such as the GPT series and Flan-T5, to ontology alignment for\nidentifying concept equivalence mappings across ontologies. To test the\nzero-shot performance of Flan-T5-XXL and GPT-3.5-turbo, we leverage challenging\nsubsets from two equivalence matching datasets of the OAEI Bio-ML track, taking\ninto account concept labels and structural contexts. Preliminary findings\nsuggest that LLMs have the potential to outperform existing ontology alignment\nsystems like BERTMap, given careful framework and prompt design.",
          "link": "http://arxiv.org/abs/2309.07172",
          "publishedOn": "2023-09-16T00:40:56.903Z",
          "wordCount": null,
          "title": "Exploring Large Language Models for Ontology Alignment. (arXiv:2309.07172v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07169",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhang_P/0/1/0/all/0/1\">Purui Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jian_X/0/1/0/all/0/1\">Xingchao Jian</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ji_F/0/1/0/all/0/1\">Feng Ji</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tay_W/0/1/0/all/0/1\">Wee Peng Tay</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wen_B/0/1/0/all/0/1\">Bihan Wen</a>",
          "description": "Topological signal processing (TSP) utilizes simplicial complexes to model\nstructures with higher order than vertices and edges. In this paper, we study\nthe transferability of TSP via a generalized higher-order version of graphon,\nknown as complexon. We recall the notion of a complexon as the limit of a\nsimplicial complex sequence [1]. Inspired by the integral operator form of\ngraphon shift operators, we construct a marginal complexon and complexon shift\noperator (CSO) according to components of all possible dimensions from the\ncomplexon. We investigate the CSO's eigenvalues and eigenvectors, and relate\nthem to a new family of weighted adjacency matrices. We prove that when a\nsimplicial complex sequence converges to a complexon, the eigenvalues of the\ncorresponding CSOs converge to that of the limit complexon. These results hint\nat learning transferability on large simplicial complexes or simplicial complex\nsequences, which generalize the graphon signal processing framework.",
          "link": "http://arxiv.org/abs/2309.07169",
          "publishedOn": "2023-09-16T00:40:56.890Z",
          "wordCount": null,
          "title": "Frequency Convergence of Complexon Shift Operators. (arXiv:2309.07169v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07183",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Casado_C/0/1/0/all/0/1\">Constantino &#xc1;lvarez Casado</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Canellas_M/0/1/0/all/0/1\">Manuel Lage Ca&#xf1;ellas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pedone_M/0/1/0/all/0/1\">Matteo Pedone</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1\">Xiaoting Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lopez_M/0/1/0/all/0/1\">Miguel Bordallo L&#xf3;pez</a>",
          "description": "In global healthcare, respiratory diseases are a leading cause of mortality,\nunderscoring the need for rapid and accurate diagnostics. To advance rapid\nscreening techniques via auscultation, our research focuses on employing one of\nthe largest publicly available medical database of respiratory sounds to train\nmultiple machine learning models able to classify different health conditions.\nOur method combines Empirical Mode Decomposition (EMD) and spectral analysis to\nextract physiologically relevant biosignals from acoustic data, closely tied to\ncardiovascular and respiratory patterns, making our approach apart in its\ndeparture from conventional audio feature extraction practices. We use Power\nSpectral Density analysis and filtering techniques to select Intrinsic Mode\nFunctions (IMFs) strongly correlated with underlying physiological phenomena.\nThese biosignals undergo a comprehensive feature extraction process for\npredictive modeling. Initially, we deploy a binary classification model that\ndemonstrates a balanced accuracy of 87% in distinguishing between healthy and\ndiseased individuals. Subsequently, we employ a six-class classification model\nthat achieves a balanced accuracy of 72% in diagnosing specific respiratory\nconditions like pneumonia and chronic obstructive pulmonary disease (COPD). For\nthe first time, we also introduce regression models that estimate age and body\nmass index (BMI) based solely on acoustic data, as well as a model for gender\nclassification. Our findings underscore the potential of this approach to\nsignificantly enhance assistive and remote diagnostic capabilities.",
          "link": "http://arxiv.org/abs/2309.07183",
          "publishedOn": "2023-09-16T00:40:56.889Z",
          "wordCount": null,
          "title": "Audio-Based Classification of Respiratory Diseases using Advanced Signal Processing and Machine Learning for Assistive Diagnosis Support. (arXiv:2309.07183v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07909",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zang_Z/0/1/0/all/0/1\">Zelin Zang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Hao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Panpan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Stan.Z Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1\">Yang You</a>",
          "description": "Unsupervised contrastive learning methods have recently seen significant\nimprovements, particularly through data augmentation strategies that aim to\nproduce robust and generalizable representations. However, prevailing data\naugmentation methods, whether hand designed or based on foundation models, tend\nto rely heavily on prior knowledge or external data. This dependence often\ncompromises their effectiveness and efficiency. Furthermore, the applicability\nof most existing data augmentation strategies is limited when transitioning to\nother research domains, especially science-related data. This limitation stems\nfrom the paucity of prior knowledge and labeled data available in these\ndomains. To address these challenges, we introduce DiffAug-a novel and\nefficient Diffusion-based data Augmentation technique. DiffAug aims to ensure\nthat the augmented and original data share a smoothed latent space, which is\nachieved through diffusion steps. Uniquely, unlike traditional methods, DiffAug\nfirst mines sufficient prior semantic knowledge about the neighborhood. This\nprovides a constraint to guide the diffusion steps, eliminating the need for\nlabels, external data/models, or prior knowledge. Designed as an\narchitecture-agnostic framework, DiffAug provides consistent improvements.\nSpecifically, it improves image classification and clustering accuracy by\n1.6%~4.5%. When applied to biological data, DiffAug improves performance by up\nto 10.1%, with an average improvement of 5.8%. DiffAug shows good performance\nin both vision and biological domains.",
          "link": "http://arxiv.org/abs/2309.07909",
          "publishedOn": "2023-09-16T00:40:56.888Z",
          "wordCount": null,
          "title": "Boosting Unsupervised Contrastive Learning Using Diffusion-Based Data Augmentation From Scratch. (arXiv:2309.07909v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07157",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chenhan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1\">Yizheng Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_Y/0/1/0/all/0/1\">Yang Weng</a>",
          "description": "Line outage identification in distribution grids is essential for sustainable\ngrid operation. In this work, we propose a practical yet robust detection\napproach that utilizes only readily available voltage magnitudes, eliminating\nthe need for costly phase angles or power flow data. Given the sensor data,\nmany existing detection methods based on change-point detection require prior\nknowledge of outage patterns, which are unknown for real-world outage\nscenarios. To remove this impractical requirement, we propose a data-driven\nmethod to learn the parameters of the post-outage distribution through gradient\ndescent. However, directly using gradient descent presents feasibility issues.\nTo address this, we modify our approach by adding a Bregman divergence\nconstraint to control the trajectory of the parameter updates, which eliminates\nthe feasibility problems. As timely operation is the key nowadays, we prove\nthat the optimal parameters can be learned with convergence guarantees via\nleveraging the statistical and physical properties of voltage data. We evaluate\nour approach using many representative distribution grids and real load\nprofiles with 17 outage configurations. The results show that we can detect and\nlocalize the outage in a timely manner with only voltage magnitudes and without\nassuming a prior knowledge of outage patterns.",
          "link": "http://arxiv.org/abs/2309.07157",
          "publishedOn": "2023-09-16T00:40:56.884Z",
          "wordCount": null,
          "title": "Distribution Grid Line Outage Identification with Unknown Pattern and Performance Guarantee. (arXiv:2309.07157v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.05735",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abrevaya_G/0/1/0/all/0/1\">Germ&#xe1;n Abrevaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramezanian_Panahi_M/0/1/0/all/0/1\">Mahta Ramezanian-Panahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gagnon_Audet_J/0/1/0/all/0/1\">Jean-Christophe Gagnon-Audet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polosecki_P/0/1/0/all/0/1\">Pablo Polosecki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1\">Irina Rish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dawson_S/0/1/0/all/0/1\">Silvina Ponce Dawson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cecchi_G/0/1/0/all/0/1\">Guillermo Cecchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dumas_G/0/1/0/all/0/1\">Guillaume Dumas</a>",
          "description": "Scientific Machine Learning (SciML) is a burgeoning field that\nsynergistically combines domain-aware and interpretable models with agnostic\nmachine learning techniques. In this work, we introduce GOKU-UI, an evolution\nof the SciML generative model GOKU-nets. GOKU-UI not only broadens the original\nmodel's spectrum to incorporate other classes of differential equations, such\nas Stochastic Differential Equations (SDEs), but also integrates attention\nmechanisms and a novel multiple shooting training strategy in the latent space.\nThese modifications have led to a significant increase in its performance in\nboth reconstruction and forecast tasks, as demonstrated by our evaluation of\nsimulated and empirical data. Specifically, GOKU-UI outperformed all baseline\nmodels on synthetic datasets even with a training set 16-fold smaller,\nunderscoring its remarkable data efficiency. Furthermore, when applied to\nempirical human brain data, while incorporating stochastic Stuart-Landau\noscillators into its dynamical core, our proposed enhancements markedly\nincreased the model's effectiveness in capturing complex brain dynamics. This\naugmented version not only surpassed all baseline methods in the reconstruction\ntask, but also demonstrated lower prediction error of future brain activity up\nto 15 seconds ahead. By training GOKU-UI on resting state fMRI data, we encoded\nwhole-brain dynamics into a latent representation, learning a low-dimensional\ndynamical system model that could offer insights into brain functionality and\nopen avenues for practical applications such as the classification of mental\nstates or psychiatric conditions. Ultimately, our research provides further\nimpetus for the field of Scientific Machine Learning, showcasing the potential\nfor advancements when established scientific insights are interwoven with\nmodern machine learning.",
          "link": "http://arxiv.org/abs/2307.05735",
          "publishedOn": "2023-09-16T00:40:56.884Z",
          "wordCount": null,
          "title": "Effective Latent Differential Equation Models via Attention and Multiple Shooting. (arXiv:2307.05735v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07159",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ouahidi_Y/0/1/0/all/0/1\">Yassine El Ouahidi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gripon_V/0/1/0/all/0/1\">Vincent Gripon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pasdeloup_B/0/1/0/all/0/1\">Bastien Pasdeloup</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bouallegue_G/0/1/0/all/0/1\">Ghaith Bouallegue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Farrugia_N/0/1/0/all/0/1\">Nicolas Farrugia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lioi_G/0/1/0/all/0/1\">Giulia Lioi</a>",
          "description": "We propose EEG-SimpleConv, a straightforward 1D convolutional neural network\nfor Motor Imagery decoding in BCI. Our main motivation is to propose a very\nsimple baseline to compare to, using only very standard ingredients from the\nliterature. We evaluate its performance on four EEG Motor Imagery datasets,\nincluding simulated online setups, and compare it to recent Deep Learning and\nMachine Learning approaches. EEG-SimpleConv is at least as good or far more\nefficient than other approaches, showing strong knowledge-transfer capabilities\nacross subjects, at the cost of a low inference time. We advocate that using\noff-the-shelf ingredients rather than coming with ad-hoc solutions can\nsignificantly help the adoption of Deep Learning approaches for BCI. We make\nthe code of the models and the experiments accessible.",
          "link": "http://arxiv.org/abs/2309.07159",
          "publishedOn": "2023-09-16T00:40:56.883Z",
          "wordCount": null,
          "title": "A Strong and Simple Deep Learning Baseline for BCI MI Decoding. (arXiv:2309.07159v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16874",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Wei_W/0/1/0/all/0/1\">Wei Wei</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gao_T/0/1/0/all/0/1\">Ting Gao</a>, <a href=\"http://arxiv.org/find/math/1/au:+Duan_J/0/1/0/all/0/1\">Jinqiao Duan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Chen_X/0/1/0/all/0/1\">Xiaoli Chen</a>",
          "description": "Many complex real world phenomena exhibit abrupt, intermittent or jumping\nbehaviors, which are more suitable to be described by stochastic differential\nequations under non-Gaussian L\\'evy noise. Among these complex phenomena, the\nmost likely transition paths between metastable states are important since\nthese rare events may have a high impact in certain scenarios. Based on the\nlarge deviation principle, the most likely transition path could be treated as\nthe minimizer of the rate function upon paths that connect two points. One of\nthe challenges to calculate the most likely transition path for stochastic\ndynamical systems under non-Gaussian L\\'evy noise is that the associated rate\nfunction can not be explicitly expressed by paths. For this reason, we\nformulate an optimal control problem to obtain the optimal state as the most\nlikely transition path. We then develop a neural network method to solve this\nissue. Several experiments are investigated for both Gaussian and non-Gaussian\ncases.",
          "link": "http://arxiv.org/abs/2203.16874",
          "publishedOn": "2023-09-16T00:40:56.883Z",
          "wordCount": null,
          "title": "An Optimal Control Method to Compute the Most Likely Transition Path for Stochastic Dynamical Systems with Jumps. (arXiv:2203.16874v2 [math.NA] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07149",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ferrante_M/0/1/0/all/0/1\">Matteo Ferrante</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Boccato_T/0/1/0/all/0/1\">Tommaso Boccato</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bargione_S/0/1/0/all/0/1\">Stefano Bargione</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Toschi_N/0/1/0/all/0/1\">Nicola Toschi</a>",
          "description": "Decoding visual representations from human brain activity has emerged as a\nthriving research domain, particularly in the context of brain-computer\ninterfaces. Our study presents an innovative method that employs to classify\nand reconstruct images from the ImageNet dataset using electroencephalography\n(EEG) data from subjects that had viewed the images themselves (i.e. \"brain\ndecoding\"). We analyzed EEG recordings from 6 participants, each exposed to 50\nimages spanning 40 unique semantic categories. These EEG readings were\nconverted into spectrograms, which were then used to train a convolutional\nneural network (CNN), integrated with a knowledge distillation procedure based\non a pre-trained Contrastive Language-Image Pre-Training (CLIP)-based image\nclassification teacher network. This strategy allowed our model to attain a\ntop-5 accuracy of 80%, significantly outperforming a standard CNN and various\nRNN-based benchmarks. Additionally, we incorporated an image reconstruction\nmechanism based on pre-trained latent diffusion models, which allowed us to\ngenerate an estimate of the images which had elicited EEG activity. Therefore,\nour architecture not only decodes images from neural activity but also offers a\ncredible image reconstruction from EEG only, paving the way for e.g. swift,\nindividualized feedback experiments. Our research represents a significant step\nforward in connecting neural signals with visual cognition.",
          "link": "http://arxiv.org/abs/2309.07149",
          "publishedOn": "2023-09-16T00:40:56.882Z",
          "wordCount": null,
          "title": "Decoding visual brain representations from electroencephalography through Knowledge Distillation and latent diffusion models. (arXiv:2309.07149v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07550",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jayjun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spiers_A/0/1/0/all/0/1\">Adam J. Spiers</a>",
          "description": "The integration of manipulator robots in household environments suggests a\nneed for more predictable and human-like robot motion. This holds especially\ntrue for wheelchair-mounted assistive robots that can support the independence\nof people with paralysis. One method of generating naturalistic motion\ntrajectories is via the imitation of human demonstrators. This paper explores a\nself-supervised imitation learning method using an autoregressive\nspatio-temporal graph neural network for an assistive drinking task. We address\nlearning from diverse human motion trajectory data that were captured via\nwearable IMU sensors on a human arm as the action-free task demonstrations.\nObserved arm motion data from several participants is used to generate natural\nand functional drinking motion trajectories for a UR5e robot arm.",
          "link": "http://arxiv.org/abs/2309.07550",
          "publishedOn": "2023-09-16T00:40:56.880Z",
          "wordCount": null,
          "title": "Naturalistic Robot Arm Trajectory Generation via Representation Learning. (arXiv:2309.07550v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07374",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akrami_H/0/1/0/all/0/1\">Haleh Akrami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zamzam_O/0/1/0/all/0/1\">Omar Zamzam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_A/0/1/0/all/0/1\">Anand Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aydore_S/0/1/0/all/0/1\">Sergul Aydore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leahy_R/0/1/0/all/0/1\">Richard Leahy</a>",
          "description": "Quantile Regression (QR) can be used to estimate aleatoric uncertainty in\ndeep neural networks and can generate prediction intervals. Quantifying\nuncertainty is particularly important in critical applications such as clinical\ndiagnosis, where a realistic assessment of uncertainty is essential in\ndetermining disease status and planning the appropriate treatment. The most\ncommon application of quantile regression models is in cases where the\nparametric likelihood cannot be specified. Although quantile regression is\nquite robust to outlier response observations, it can be sensitive to outlier\ncovariate observations (features). Outlier features can compromise the\nperformance of deep learning regression problems such as style translation,\nimage reconstruction, and deep anomaly detection, potentially leading to\nmisleading conclusions. To address this problem, we propose a robust solution\nfor quantile regression that incorporates concepts from robust divergence. We\ncompare the performance of our proposed method with (i) least trimmed quantile\nregression and (ii) robust regression based on the regularization of\ncase-specific parameters in a simple real dataset in the presence of outlier.\nThese methods have not been applied in a deep learning framework. We also\ndemonstrate the applicability of the proposed method by applying it to a\nmedical imaging translation task using diffusion models.",
          "link": "http://arxiv.org/abs/2309.07374",
          "publishedOn": "2023-09-16T00:40:56.879Z",
          "wordCount": null,
          "title": "Beta quantile regression for robust estimation of uncertainty in the presence of outliers. (arXiv:2309.07374v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07170",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hamad_R/0/1/0/all/0/1\">Rebeen Ali Hamad</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Woo_W/0/1/0/all/0/1\">Wai Lok Woo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wei_B/0/1/0/all/0/1\">Bo Wei</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_L/0/1/0/all/0/1\">Longzhi Yang</a>",
          "description": "Human activity recognition (HAR) is an essential research field that has been\nused in different applications including home and workplace automation,\nsecurity and surveillance as well as healthcare. Starting from conventional\nmachine learning methods to the recently developing deep learning techniques\nand the Internet of things, significant contributions have been shown in the\nHAR area in the last decade. Even though several review and survey studies have\nbeen published, there is a lack of sensor-based HAR overview studies focusing\non summarising the usage of wearable sensors and smart home sensors data as\nwell as applications of HAR and deep learning techniques. Hence, we overview\nsensor-based HAR, discuss several important applications that rely on HAR, and\nhighlight the most common machine learning methods that have been used for HAR.\nFinally, several challenges of HAR are explored that should be addressed to\nfurther improve the robustness of HAR.",
          "link": "http://arxiv.org/abs/2309.07170",
          "publishedOn": "2023-09-16T00:40:56.878Z",
          "wordCount": null,
          "title": "Overview of Human Activity Recognition Using Sensor Data. (arXiv:2309.07170v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07352",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Altmann_A/0/1/0/all/0/1\">Andre Altmann</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Aquila_A/0/1/0/all/0/1\">Ana C Lawry Aquila</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Jahanshad_N/0/1/0/all/0/1\">Neda Jahanshad</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Thompson_P/0/1/0/all/0/1\">Paul M Thompson</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lorenzi_M/0/1/0/all/0/1\">Marco Lorenzi</a>",
          "description": "A major challenge in imaging genetics and similar fields is to link\nhigh-dimensional data in one domain, e.g., genetic data, to high dimensional\ndata in a second domain, e.g., brain imaging data. The standard approach in the\narea are mass univariate analyses across genetic factors and imaging\nphenotypes. That entails executing one genome-wide association study (GWAS) for\neach pre-defined imaging measure. Although this approach has been tremendously\nsuccessful, one shortcoming is that phenotypes must be pre-defined.\nConsequently, effects that are not confined to pre-selected regions of interest\nor that reflect larger brain-wide patterns can easily be missed. In this work\nwe introduce a Partial Least Squares (PLS)-based framework, which we term\nCluster-Bootstrap PLS (CLUB-PLS), that can work with large input dimensions in\nboth domains as well as with large sample sizes. One key factor of the\nframework is to use cluster bootstrap to provide robust statistics for single\ninput features in both domains. We applied CLUB-PLS to investigating the\ngenetic basis of surface area and cortical thickness in a sample of 33,000\nsubjects from the UK Biobank. We found 107 genome-wide significant\nlocus-phenotype pairs that are linked to 386 different genes. We found that a\nvast majority of these loci could be technically validated at a high rate:\nusing classic GWAS or Genome-Wide Inferred Statistics (GWIS) we found that 85\nlocus-phenotype pairs exceeded the genome-wide suggestive (P<1e-05) threshold.",
          "link": "http://arxiv.org/abs/2309.07352",
          "publishedOn": "2023-09-16T00:40:56.878Z",
          "wordCount": null,
          "title": "Tackling the dimensions in imaging genetics with CLUB-PLS. (arXiv:2309.07352v1 [q-bio.GN])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07182",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ardeshir_H/0/1/0/all/0/1\">Hassan Ardeshir</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Araghi_M/0/1/0/all/0/1\">Mohammad Araghi</a>",
          "description": "One of the common human diseases is sleep disorders. The classification of\nsleep stages plays a fundamental role in diagnosing sleep disorders, monitoring\ntreatment effectiveness, and understanding the relationship between sleep\nstages and various health conditions. A precise and efficient classification of\nthese stages can significantly enhance our understanding of sleep-related\nphenomena and ultimately lead to improved health outcomes and disease\ntreatment.\n\nModels others propose are often time-consuming and lack sufficient accuracy,\nespecially in stage N1. The main objective of this research is to present a\nmachine-learning model called \"EEGMobile\". This model utilizes pre-trained\nmodels and learns from electroencephalogram (EEG) spectrograms of brain\nsignals. The model achieved an accuracy of 86.97% on a publicly available\ndataset named \"Sleep-EDF20\", outperforming other models proposed by different\nresearchers. Moreover, it recorded an accuracy of 56.4% in stage N1, which is\nbetter than other models. These findings demonstrate that this model has the\npotential to achieve better results for the treatment of this disease.",
          "link": "http://arxiv.org/abs/2309.07182",
          "publishedOn": "2023-09-16T00:40:56.877Z",
          "wordCount": null,
          "title": "Sleep Stage Classification Using a Pre-trained Deep Learning Model. (arXiv:2309.07182v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07679",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Pedicillo_E/0/1/0/all/0/1\">Edoardo Pedicillo</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Pasquale_A/0/1/0/all/0/1\">Andrea Pasquale</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Carrazza_S/0/1/0/all/0/1\">Stefano Carrazza</a>",
          "description": "Quantum computing is a growing field where the information is processed by\ntwo-levels quantum states known as qubits. Current physical realizations of\nqubits require a careful calibration, composed by different experiments, due to\nnoise and decoherence phenomena. Among the different characterization\nexperiments, a crucial step is to develop a model to classify the measured\nstate by discriminating the ground state from the excited state. In this\nproceedings we benchmark multiple classification techniques applied to real\nquantum devices.",
          "link": "http://arxiv.org/abs/2309.07679",
          "publishedOn": "2023-09-16T00:40:56.875Z",
          "wordCount": null,
          "title": "Benchmarking machine learning models for quantum state classification. (arXiv:2309.07679v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07141",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Shi_Z/0/1/0/all/0/1\">Zhuo-yong Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jia_Y/0/1/0/all/0/1\">Ye-tao Jia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_K/0/1/0/all/0/1\">Ke-xin Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_D/0/1/0/all/0/1\">Ding-han Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ji_L/0/1/0/all/0/1\">Long-meng Ji</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_Y/0/1/0/all/0/1\">Yong Wu</a>",
          "description": "With the rapid development of electronic science and technology, the research\non wearable devices is constantly updated, but for now, it is not comprehensive\nfor wearable devices to recognize and analyze the movement of specific sports.\nBased on this, this paper improves wearable devices of table tennis sport, and\nrealizes the pattern recognition and evaluation of table tennis players' motor\nskills through artificial intelligence. Firstly, a device is designed to\ncollect the movement information of table tennis players and the actual\nmovement data is processed. Secondly, a sliding window is made to divide the\ncollected motion data into a characteristic database of six table tennis\nbenchmark movements. Thirdly, motion features were constructed based on feature\nengineering, and motor skills were identified for different models after\ndimensionality reduction. Finally, the hierarchical evaluation system of motor\nskills is established with the loss functions of different evaluation indexes.\nThe results show that in the recognition of table tennis players' motor skills,\nthe feature-based BP neural network proposed in this paper has higher\nrecognition accuracy and stronger generalization ability than the traditional\nconvolutional neural network.",
          "link": "http://arxiv.org/abs/2309.07141",
          "publishedOn": "2023-09-16T00:40:56.872Z",
          "wordCount": null,
          "title": "Design of Recognition and Evaluation System for Table Tennis Players' Motor Skills Based on Artificial Intelligence. (arXiv:2309.07141v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07153",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Changan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Changjun Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhongzhi Zhang</a>",
          "description": "Maximizing influences in complex networks is a practically important but\ncomputationally challenging task for social network analysis, due to its NP-\nhard nature. Most current approximation or heuristic methods either require\ntremendous human design efforts or achieve unsatisfying balances between\neffectiveness and efficiency. Recent machine learning attempts only focus on\nspeed but lack performance enhancement. In this paper, different from previous\nattempts, we propose an effective deep reinforcement learning model that\nachieves superior performances over traditional best influence maximization\nalgorithms. Specifically, we design an end-to-end learning framework that\ncombines graph neural network as the encoder and reinforcement learning as the\ndecoder, named DREIM. Trough extensive training on small synthetic graphs,\nDREIM outperforms the state-of-the-art baseline methods on very large synthetic\nand real-world networks on solution quality, and we also empirically show its\nlinear scalability with regard to the network size, which demonstrates its\nsuperiority in solving this problem.",
          "link": "http://arxiv.org/abs/2309.07153",
          "publishedOn": "2023-09-16T00:40:56.870Z",
          "wordCount": null,
          "title": "Finding Influencers in Complex Networks: An Effective Deep Reinforcement Learning Approach. (arXiv:2309.07153v1 [cs.SI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07156",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sharma_S/0/1/0/all/0/1\">Shivam Sharma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Maiti_S/0/1/0/all/0/1\">Suvadeep Maiti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mythirayee_S/0/1/0/all/0/1\">S.Mythirayee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rajendran_S/0/1/0/all/0/1\">Srijithesh Rajendran</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Raju_B/0/1/0/all/0/1\">Bapi Raju</a>",
          "description": "Sleep, a fundamental physiological process, occupies a significant portion of\nour lives. Accurate classification of sleep stages serves as a crucial tool for\nevaluating sleep quality and identifying probable sleep disorders. This work\nintroduces a novel methodology that utilises a SE-Resnet-Bi-LSTM architecture\nto classify sleep into five separate stages. The classification process is\nbased on the analysis of single-channel electroencephalograms (EEGs). The\nframework that has been suggested consists of two fundamental elements: a\nfeature extractor that utilises SE-ResNet, and a temporal context encoder that\nuse stacks of Bi-LSTM units.The effectiveness of our approach is substantiated\nby thorough assessments conducted on three different datasets, namely\nSLeepEDF-20, SleepEDF-78, and SHHS. Significantly, our methodology attains\nnotable levels of accuracy, specifically 87.5\\%, 83.9\\%, and 87.8\\%, along with\nmacro-F1 scores of 82.5, 78.9, and 81.9 for the corresponding datasets.\nNotably, we introduce the utilization of 1D-GradCAM visualization to shed light\non the decision-making process of our model in the realm of sleep stage\nclassification. This visualization method not only provides valuable insights\ninto the model's classification rationale but also aligns its outcomes with the\nannotations made by sleep experts. One notable feature of our research is the\nintegration of an expedited training approach, which effectively preserves the\nmodel's resilience in terms of performance. The experimental evaluations\nconducted provide a comprehensive evaluation of the effectiveness of our\nproposed model in comparison to existing approaches, highlighting its potential\nfor practical applications.",
          "link": "http://arxiv.org/abs/2309.07156",
          "publishedOn": "2023-09-16T00:40:56.870Z",
          "wordCount": null,
          "title": "A Deep Dive into Sleep: Single-Channel EEG-Based Sleep Stage Classification with Model Interpretability. (arXiv:2309.07156v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07478",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mingote_V/0/1/0/all/0/1\">Victoria Mingote</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gimeno_P/0/1/0/all/0/1\">Pablo Gimeno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vicente_L/0/1/0/all/0/1\">Luis Vicente</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khurana_S/0/1/0/all/0/1\">Sameer Khurana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laurent_A/0/1/0/all/0/1\">Antoine Laurent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duret_J/0/1/0/all/0/1\">Jarod Duret</a>",
          "description": "This paper proposes a direct text to speech translation system using discrete\nacoustic units. This framework employs text in different source languages as\ninput to generate speech in the target language without the need for text\ntranscriptions in this language. Motivated by the success of acoustic units in\nprevious works for direct speech to speech translation systems, we use the same\npipeline to extract the acoustic units using a speech encoder combined with a\nclustering algorithm. Once units are obtained, an encoder-decoder architecture\nis trained to predict them. Then a vocoder generates speech from units. Our\napproach for direct text to speech translation was tested on the new CVSS\ncorpus with two different text mBART models employed as initialisation. The\nsystems presented report competitive performance for most of the language pairs\nevaluated. Besides, results show a remarkable improvement when initialising our\nproposed architecture with a model pre-trained with more languages.",
          "link": "http://arxiv.org/abs/2309.07478",
          "publishedOn": "2023-09-16T00:40:56.869Z",
          "wordCount": null,
          "title": "Direct Text to Speech Translation System using Acoustic Units. (arXiv:2309.07478v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.15679",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Memery_S/0/1/0/all/0/1\">Sean Memery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cedron_O/0/1/0/all/0/1\">Osmar Cedron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subr_K/0/1/0/all/0/1\">Kartic Subr</a>",
          "description": "Artistic authoring of 3D environments is a laborious enterprise that also\nrequires skilled content creators. There have been impressive improvements in\nusing machine learning to address different aspects of generating 3D content,\nsuch as generating meshes, arranging geometry, synthesizing textures, etc. In\nthis paper we develop a model to generate Bidirectional Reflectance\nDistribution Functions (BRDFs) from descriptive textual prompts. BRDFs are four\ndimensional probability distributions that characterize the interaction of\nlight with surface materials. They are either represented parametrically, or by\ntabulating the probability density associated with every pair of incident and\noutgoing angles. The former lends itself to artistic editing while the latter\nis used when measuring the appearance of real materials. Numerous works have\nfocused on hypothesizing BRDF models from images of materials. We learn a\nmapping from textual descriptions of materials to parametric BRDFs. Our model\nis first trained using a semi-supervised approach before being tuned via an\nunsupervised scheme. Although our model is general, in this paper we\nspecifically generate parameters for MDL materials, conditioned on natural\nlanguage descriptions, within NVIDIA's Omniverse platform. This enables use\ncases such as real-time text prompts to change materials of objects in 3D\nenvironments such as \"dull plastic\" or \"shiny iron\". Since the output of our\nmodel is a parametric BRDF, rather than an image of the material, it may be\nused to render materials using any shape under arbitrarily specified viewing\nand lighting conditions.",
          "link": "http://arxiv.org/abs/2306.15679",
          "publishedOn": "2023-09-16T00:40:56.868Z",
          "wordCount": null,
          "title": "Generating Parametric BRDFs from Natural Language Descriptions. (arXiv:2306.15679v2 [cs.GR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.10629",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>",
          "description": "In data-rich domains such as vision, language, and speech, deep learning\nprevails to deliver high-performance task-specific models and can even learn\ngeneral task-agnostic representations for efficient finetuning to downstream\ntasks. However, deep learning in resource-limited domains still faces multiple\nchallenges including (i) limited data, (ii) constrained model development cost,\nand (iii) lack of adequate pre-trained models for effective finetuning. This\npaper provides an overview of model reprogramming to bridge this gap. Model\nreprogramming enables resource-efficient cross-domain machine learning by\nrepurposing and reusing a well-developed pre-trained model from a source domain\nto solve tasks in a target domain without model finetuning, where the source\nand target domains can be vastly different. In many applications, model\nreprogramming outperforms transfer learning and training from scratch. This\npaper elucidates the methodology of model reprogramming, summarizes existing\nuse cases, provides a theoretical explanation of the success of model\nreprogramming, and concludes with a discussion on open-ended research questions\nand opportunities. A list of model reprogramming studies is actively maintained\nand updated at https://github.com/IBM/model-reprogramming.",
          "link": "http://arxiv.org/abs/2202.10629",
          "publishedOn": "2023-09-16T00:40:56.858Z",
          "wordCount": null,
          "title": "Model Reprogramming: Resource-Efficient Cross-Domain Machine Learning. (arXiv:2202.10629v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07193",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Forootani_A/0/1/0/all/0/1\">Ali Forootani</a>, <a href=\"http://arxiv.org/find/math/1/au:+Goyal_P/0/1/0/all/0/1\">Pawan Goyal</a>, <a href=\"http://arxiv.org/find/math/1/au:+Benner_P/0/1/0/all/0/1\">Peter Benner</a>",
          "description": "The discovery of governing equations from data has been an active field of\nresearch for decades. One widely used methodology for this purpose is sparse\nregression for nonlinear dynamics, known as SINDy. Despite several attempts,\nnoisy and scarce data still pose a severe challenge to the success of the SINDy\napproach. In this work, we discuss a robust method to discover nonlinear\ngoverning equations from noisy and scarce data. To do this, we make use of\nneural networks to learn an implicit representation based on measurement data\nso that not only it produces the output in the vicinity of the measurements but\nalso the time-evolution of output can be described by a dynamical system.\nAdditionally, we learn such a dynamic system in the spirit of the SINDy\nframework. Leveraging the implicit representation using neural networks, we\nobtain the derivative information -- required for SINDy -- using an automatic\ndifferentiation tool. To enhance the robustness of our methodology, we further\nincorporate an integral condition on the output of the implicit networks.\nFurthermore, we extend our methodology to handle data collected from multiple\ninitial conditions. We demonstrate the efficiency of the proposed methodology\nto discover governing equations under noisy and scarce data regimes by means of\nseveral examples and compare its performance with existing methods.",
          "link": "http://arxiv.org/abs/2309.07193",
          "publishedOn": "2023-09-16T00:40:56.811Z",
          "wordCount": null,
          "title": "A Robust SINDy Approach by Combining Neural Networks and an Integral Form. (arXiv:2309.07193v1 [math.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.11322",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiechen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sangwoo Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simeone_O/0/1/0/all/0/1\">Osvaldo Simeone</a>",
          "description": "Spiking neural networks (SNNs) process time-series data via internal\nevent-driven neural dynamics whose energy consumption depends on the number of\nspikes exchanged between neurons over the course of the input presentation. In\ntypical implementations of an SNN classifier, decisions are produced after the\nentire input sequence has been processed, resulting in latency and energy\nconsumption levels that are fairly uniform across inputs. Recently introduced\ndelay-adaptive SNNs tailor the inference latency -- and, with it, the energy\nconsumption -- to the difficulty of each example, by producing an early\ndecision when the SNN model is sufficiently ``confident''. In this paper, we\nstart by observing that, as an SNN processes input samples, its classification\ndecisions tend to be first under-confident and then over-confident with respect\nto the decision's ground-truth, unknown, test accuracy. This makes it difficult\nto determine a stopping time that ensures a desired level of accuracy. To\naddress this problem, we introduce a novel delay-adaptive SNN-based inference\nmethodology that, wrapping around any pre-trained SNN classifier, provides\nguaranteed reliability for the decisions produced at input-dependent stopping\ntimes. The approach entails minimal added complexity as compared to the\nunderlying SNN, requiring only thresholding and counting operations at run\ntime, and it leverages tools from conformal prediction (CP).",
          "link": "http://arxiv.org/abs/2305.11322",
          "publishedOn": "2023-09-16T00:40:56.809Z",
          "wordCount": null,
          "title": "SpikeCP: Delay-Adaptive Reliable Spiking Neural Networks via Conformal Prediction. (arXiv:2305.11322v3 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07694",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mo_S/0/1/0/all/0/1\">Shentong Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xin_M/0/1/0/all/0/1\">Miao Xin</a>",
          "description": "While the recently introduced Tree of Thoughts (ToT) has heralded\nadvancements in allowing Large Language Models (LLMs) to reason through\nforesight and backtracking for global decision-making, it has overlooked the\ninherent local uncertainties in intermediate decision points or \"thoughts\".\nThese local uncertainties, intrinsic to LLMs given their potential for diverse\nresponses, remain a significant concern in the reasoning process. Addressing\nthis pivotal gap, we introduce the Tree of Uncertain Thoughts (TouT) - a\nreasoning framework tailored for LLMs. Our TouT effectively leverages Monte\nCarlo Dropout to quantify uncertainty scores associated with LLMs' diverse\nlocal responses at these intermediate steps. By marrying this local uncertainty\nquantification with global search algorithms, TouT enhances the model's\nprecision in response generation. We substantiate our approach with rigorous\nexperiments on two demanding planning tasks: Game of 24 and Mini Crosswords.\nThe empirical evidence underscores TouT's superiority over both ToT and\nchain-of-thought prompting methods.",
          "link": "http://arxiv.org/abs/2309.07694",
          "publishedOn": "2023-09-16T00:40:56.806Z",
          "wordCount": null,
          "title": "Tree of Uncertain Thoughts Reasoning for Large Language Models. (arXiv:2309.07694v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07578",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pinneri_C/0/1/0/all/0/1\">Cristina Pinneri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bechtle_S/0/1/0/all/0/1\">Sarah Bechtle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wulfmeier_M/0/1/0/all/0/1\">Markus Wulfmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Byravan_A/0/1/0/all/0/1\">Arunkumar Byravan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whitney_W/0/1/0/all/0/1\">William F. Whitney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riedmiller_M/0/1/0/all/0/1\">Martin Riedmiller</a>",
          "description": "We present a novel approach to address the challenge of generalization in\noffline reinforcement learning (RL), where the agent learns from a fixed\ndataset without any additional interaction with the environment. Specifically,\nwe aim to improve the agent's ability to generalize to out-of-distribution\ngoals. To achieve this, we propose to learn a dynamics model and check if it is\nequivariant with respect to a fixed type of transformation, namely translations\nin the state space. We then use an entropy regularizer to increase the\nequivariant set and augment the dataset with the resulting transformed samples.\nFinally, we learn a new policy offline based on the augmented dataset, with an\noff-the-shelf offline RL algorithm. Our experimental results demonstrate that\nour approach can greatly improve the test performance of the policy on the\nconsidered environments.",
          "link": "http://arxiv.org/abs/2309.07578",
          "publishedOn": "2023-09-16T00:40:56.805Z",
          "wordCount": null,
          "title": "Equivariant Data Augmentation for Generalization in Offline Reinforcement Learning. (arXiv:2309.07578v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.00495",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1\">Xinglong Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dost_K/0/1/0/all/0/1\">Katharina Dost</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1\">Kaiqi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demontis_A/0/1/0/all/0/1\">Ambra Demontis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roli_F/0/1/0/all/0/1\">Fabio Roli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dobbie_G/0/1/0/all/0/1\">Gill Dobbie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wicker_J/0/1/0/all/0/1\">J&#xf6;rg Wicker</a>",
          "description": "Adversarial defenses protect machine learning models from adversarial\nattacks, but are often tailored to one type of model or attack. The lack of\ninformation on unknown potential attacks makes detecting adversarial examples\nchallenging. Additionally, attackers do not need to follow the rules made by\nthe defender. To address this problem, we take inspiration from the concept of\nApplicability Domain in cheminformatics. Cheminformatics models struggle to\nmake accurate predictions because only a limited number of compounds are known\nand available for training. Applicability Domain defines a domain based on the\nknown compounds and rejects any unknown compound that falls outside the domain.\nSimilarly, adversarial examples start as harmless inputs, but can be\nmanipulated to evade reliable classification by moving outside the domain of\nthe classifier. We are the first to identify the similarity between\nApplicability Domain and adversarial detection. Instead of focusing on unknown\nattacks, we focus on what is known, the training data. We propose a simple yet\nrobust triple-stage data-driven framework that checks the input globally and\nlocally, and confirms that they are coherent with the model's output. This\nframework can be applied to any classification model and is not limited to\nspecific attacks. We demonstrate these three stages work as one unit,\neffectively detecting various attacks, even for a white-box scenario.",
          "link": "http://arxiv.org/abs/2105.00495",
          "publishedOn": "2023-09-16T00:40:56.803Z",
          "wordCount": null,
          "title": "BAARD: Blocking Adversarial Examples by Testing for Applicability, Reliability and Decidability. (arXiv:2105.00495v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2105.06031",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Fan_Y/0/1/0/all/0/1\">Yifeng Fan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Khoo_Y/0/1/0/all/0/1\">Yuehaw Khoo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhizhen Zhao</a>",
          "description": "In the presence of heterogeneous data, where randomly rotated objects fall\ninto multiple underlying categories, it is challenging to simultaneously\nclassify them into clusters and synchronize them based on pairwise relations.\nThis gives rise to the joint problem of community detection and\nsynchronization. We propose a series of semidefinite relaxations, and prove\ntheir exact recovery when extending the celebrated stochastic block model to\nthis new setting where both rotations and cluster identities are to be\ndetermined. Numerical experiments demonstrate the efficacy of our proposed\nalgorithms and confirm our theoretical result which indicates a sharp phase\ntransition for exact recovery.",
          "link": "http://arxiv.org/abs/2105.06031",
          "publishedOn": "2023-09-16T00:40:56.803Z",
          "wordCount": null,
          "title": "Joint Community Detection and Rotational Synchronization via Semidefinite Programming. (arXiv:2105.06031v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.09960",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Hui Jiang</a>",
          "description": "Languages are not created randomly but rather to communicate information.\nThere is a strong association between languages and their underlying meanings,\nresulting in a sparse joint distribution that is heavily peaked according to\ntheir correlations. Moreover, these peak values happen to match with the\nmarginal distribution of languages due to the sparsity. With the advent of LLMs\ntrained on big data and large models, we can now precisely assess the marginal\ndistribution of languages, providing a convenient means of exploring the sparse\nstructures in the joint distribution for effective inferences. In this paper,\nwe categorize languages as either unambiguous or {\\epsilon}-ambiguous and\npresent quantitative results to demonstrate that the emergent abilities of\nLLMs, such as language understanding, in-context learning, chain-of-thought\nprompting, and effective instruction fine-tuning, can all be attributed to\nBayesian inference on the sparse joint distribution of languages.",
          "link": "http://arxiv.org/abs/2304.09960",
          "publishedOn": "2023-09-16T00:40:56.803Z",
          "wordCount": null,
          "title": "A Latent Space Theory for Emergent Abilities in Large Language Models. (arXiv:2304.09960v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Castellon_F/0/1/0/all/0/1\">Fabiola Espinosa Castellon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Montesuma_E/0/1/0/all/0/1\">Eduardo Fernandes Montesuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mboula_F/0/1/0/all/0/1\">Fred Ngol&#xe8; Mboula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mayoue_A/0/1/0/all/0/1\">Aur&#xe9;lien Mayoue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Souloumiac_A/0/1/0/all/0/1\">Antoine Souloumiac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gouy_Pallier_C/0/1/0/all/0/1\">C&#xe9;dric Gouy-Pallier</a>",
          "description": "In this article, we propose an approach for federated domain adaptation, a\nsetting where distributional shift exists among clients and some have unlabeled\ndata. The proposed framework, FedDaDiL, tackles the resulting challenge through\ndictionary learning of empirical distributions. In our setting, clients'\ndistributions represent particular domains, and FedDaDiL collectively trains a\nfederated dictionary of empirical distributions. In particular, we build upon\nthe Dataset Dictionary Learning framework by designing collaborative\ncommunication protocols and aggregation operations. The chosen protocols keep\nclients' data private, thus enhancing overall privacy compared to its\ncentralized counterpart. We empirically demonstrate that our approach\nsuccessfully generates labeled data on the target domain with extensive\nexperiments on (i) Caltech-Office, (ii) TEP, and (iii) CWRU benchmarks.\nFurthermore, we compare our method to its centralized counterpart and other\nbenchmarks in federated domain adaptation.",
          "link": "http://arxiv.org/abs/2309.07670",
          "publishedOn": "2023-09-16T00:40:56.798Z",
          "wordCount": null,
          "title": "Federated Dataset Dictionary Learning for Multi-Source Domain Adaptation. (arXiv:2309.07670v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.07260",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhouri_M/0/1/0/all/0/1\">Mohamed Aziz Bhouri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joly_M/0/1/0/all/0/1\">Michael Joly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1\">Robert Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1\">Soumalya Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perdikaris_P/0/1/0/all/0/1\">Paris Perdikaris</a>",
          "description": "Several fundamental problems in science and engineering consist of global\noptimization tasks involving unknown high-dimensional (black-box) functions\nthat map a set of controllable variables to the outcomes of an expensive\nexperiment. Bayesian Optimization (BO) techniques are known to be effective in\ntackling global optimization problems using a relatively small number objective\nfunction evaluations, but their performance suffers when dealing with\nhigh-dimensional outputs. To overcome the major challenge of dimensionality,\nhere we propose a deep learning framework for BO and sequential decision making\nbased on bootstrapped ensembles of neural architectures with randomized priors.\nUsing appropriate architecture choices, we show that the proposed framework can\napproximate functional relationships between design variables and quantities of\ninterest, even in cases where the latter take values in high-dimensional vector\nspaces or even infinite-dimensional function spaces. In the context of BO, we\naugmented the proposed probabilistic surrogates with re-parameterized Monte\nCarlo approximations of multiple-point (parallel) acquisition functions, as\nwell as methodological extensions for accommodating black-box constraints and\nmulti-fidelity information sources. We test the proposed framework against\nstate-of-the-art methods for BO and demonstrate superior performance across\nseveral challenging tasks with high-dimensional outputs, including a\nconstrained multi-fidelity optimization task involving shape optimization of\nrotor blades in turbo-machinery.",
          "link": "http://arxiv.org/abs/2302.07260",
          "publishedOn": "2023-09-16T00:40:56.798Z",
          "wordCount": null,
          "title": "Scalable Bayesian optimization with high-dimensional outputs using randomized prior networks. (arXiv:2302.07260v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2008.05558",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Ahmadi_A/0/1/0/all/0/1\">Amir Ali Ahmadi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_J/0/1/0/all/0/1\">Jeffrey Zhang</a>",
          "description": "We show that unless P=NP, there cannot be a polynomial-time algorithm that\nfinds a point within Euclidean distance $c^n$ (for any constant $c \\ge 0$) of a\nlocal minimizer of an $n$-variate quadratic function over a polytope. This\nresult (even with $c=0$) answers a question of Pardalos and Vavasis that\nappeared in 1992 on a list of seven open problems in complexity theory for\nnumerical optimization. Our proof technique also implies that the problem of\ndeciding whether a quadratic function has a local minimizer over an (unbounded)\npolyhedron, and that of deciding if a quartic polynomial has a local minimizer\nare NP-hard.",
          "link": "http://arxiv.org/abs/2008.05558",
          "publishedOn": "2023-09-16T00:40:56.789Z",
          "wordCount": null,
          "title": "On the complexity of finding a local minimizer of a quadratic function over a polytope. (arXiv:2008.05558v5 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07672",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1\">Mengge Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_L/0/1/0/all/0/1\">Longfeng Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_S/0/1/0/all/0/1\">Siyu Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chenc_Y/0/1/0/all/0/1\">Yuntian Chenc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongxiao Zhang</a>",
          "description": "Unveiling the underlying governing equations of nonlinear dynamic systems\nremains a significant challenge, especially when encountering noisy\nobservations and no prior knowledge available. This study proposes R-DISCOVER,\na framework designed to robustly uncover open-form partial differential\nequations (PDEs) from limited and noisy data. The framework operates through\ntwo alternating update processes: discovering and embedding. The discovering\nphase employs symbolic representation and a reinforcement learning (RL)-guided\nhybrid PDE generator to efficiently produce diverse open-form PDEs with tree\nstructures. A neural network-based predictive model fits the system response\nand serves as the reward evaluator for the generated PDEs. PDEs with superior\nfits are utilized to iteratively optimize the generator via the RL method and\nthe best-performing PDE is selected by a parameter-free stability metric. The\nembedding phase integrates the initially identified PDE from the discovering\nprocess as a physical constraint into the predictive model for robust training.\nThe traversal of PDE trees automates the construction of the computational\ngraph and the embedding process without human intervention. Numerical\nexperiments demonstrate our framework's capability to uncover governing\nequations from nonlinear dynamic systems with limited and highly noisy data and\noutperform other physics-informed neural network-based discovery methods. This\nwork opens new potential for exploring real-world systems with limited\nunderstanding.",
          "link": "http://arxiv.org/abs/2309.07672",
          "publishedOn": "2023-09-16T00:40:56.784Z",
          "wordCount": null,
          "title": "Physics-constrained robust learning of open-form PDEs from limited and noisy data. (arXiv:2309.07672v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.13049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1\">Mengxin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_Q/0/1/0/all/0/1\">Qian Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Lei Jiang</a>",
          "description": "Vision Transformers (ViTs) have demonstrated the state-of-the-art performance\nin various vision-related tasks. The success of ViTs motivates adversaries to\nperform backdoor attacks on ViTs. Although the vulnerability of traditional\nCNNs to backdoor attacks is well-known, backdoor attacks on ViTs are\nseldom-studied. Compared to CNNs capturing pixel-wise local features by\nconvolutions, ViTs extract global context information through patches and\nattentions. Na\\\"ively transplanting CNN-specific backdoor attacks to ViTs\nyields only a low clean data accuracy and a low attack success rate. In this\npaper, we propose a stealth and practical ViT-specific backdoor attack\n$TrojViT$. Rather than an area-wise trigger used by CNN-specific backdoor\nattacks, TrojViT generates a patch-wise trigger designed to build a Trojan\ncomposed of some vulnerable bits on the parameters of a ViT stored in DRAM\nmemory through patch salience ranking and attention-target loss. TrojViT\nfurther uses minimum-tuned parameter update to reduce the bit number of the\nTrojan. Once the attacker inserts the Trojan into the ViT model by flipping the\nvulnerable bits, the ViT model still produces normal inference accuracy with\nbenign inputs. But when the attacker embeds a trigger into an input, the ViT\nmodel is forced to classify the input to a predefined target class. We show\nthat flipping only few vulnerable bits identified by TrojViT on a ViT model\nusing the well-known RowHammer can transform the model into a backdoored one.\nWe perform extensive experiments of multiple datasets on various ViT models.\nTrojViT can classify $99.64\\%$ of test images to a target class by flipping\n$345$ bits on a ViT for ImageNet.Our codes are available at\nhttps://github.com/mxzheng/TrojViT",
          "link": "http://arxiv.org/abs/2208.13049",
          "publishedOn": "2023-09-16T00:40:56.784Z",
          "wordCount": null,
          "title": "TrojViT: Trojan Insertion in Vision Transformers. (arXiv:2208.13049v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07265",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nagib_A/0/1/0/all/0/1\">Ahmad M. Nagib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abou_Zeid_H/0/1/0/all/0/1\">Hatem Abou-Zeid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassanein_H/0/1/0/all/0/1\">Hossam S. Hassanein</a>",
          "description": "The open radio access network (O-RAN) architecture supports intelligent\nnetwork control algorithms as one of its core capabilities. Data-driven\napplications incorporate such algorithms to optimize radio access network (RAN)\nfunctions via RAN intelligent controllers (RICs). Deep reinforcement learning\n(DRL) algorithms are among the main approaches adopted in the O-RAN literature\nto solve dynamic radio resource management problems. However, despite the\nbenefits introduced by the O-RAN RICs, the practical adoption of DRL algorithms\nin real network deployments falls behind. This is primarily due to the slow\nconvergence and unstable performance exhibited by DRL agents upon deployment\nand when facing previously unseen network conditions. In this paper, we address\nthese challenges by proposing transfer learning (TL) as a core component of the\ntraining and deployment workflows for the DRL-based closed-loop control of\nO-RAN functionalities. To this end, we propose and design a hybrid TL-aided\napproach that leverages the advantages of both policy reuse and distillation TL\nmethods to provide safe and accelerated convergence in DRL-based O-RAN slicing.\nWe conduct a thorough experiment that accommodates multiple services, including\nreal VR gaming traffic to reflect practical scenarios of O-RAN slicing. We also\npropose and implement policy reuse and distillation-aided DRL and non-TL-aided\nDRL as three separate baselines. The proposed hybrid approach shows at least:\n7.7% and 20.7% improvements in the average initial reward value and the\npercentage of converged scenarios, and a 64.6% decrease in reward variance\nwhile maintaining fast convergence and enhancing the generalizability compared\nwith the baselines.",
          "link": "http://arxiv.org/abs/2309.07265",
          "publishedOn": "2023-09-16T00:40:56.766Z",
          "wordCount": null,
          "title": "Safe and Accelerated Deep Reinforcement Learning-based O-RAN Slicing: A Hybrid Transfer Learning Approach. (arXiv:2309.07265v1 [cs.NI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07138",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Webster_M/0/1/0/all/0/1\">Matthew B. Webster</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_J/0/1/0/all/0/1\">Joonnyong Lee</a>",
          "description": "The task of blind source separation (BSS) involves separating sources from a\nmixture without prior knowledge of the sources or the mixing system. This is a\nchallenging problem that often requires making restrictive assumptions about\nboth the mixing system and the sources. In this paper, we propose a novel\nmethod for addressing BSS of non-linear mixtures by leveraging the natural\nfeature subspace specialization ability of multi-encoder autoencoders with\nfully self-supervised learning without strong priors. During the training\nphase, our method unmixes the input into the separate encoding spaces of the\nmulti-encoder network and then remixes these representations within the decoder\nfor a reconstruction of the input. Then to perform source inference, we\nintroduce a novel encoding masking technique whereby masking out all but one of\nthe encodings enables the decoder to estimate a source signal. To this end, we\nalso introduce a so-called pathway separation loss that encourages sparsity\nbetween the unmixed encoding spaces throughout the decoder's layers and a\nso-called zero reconstruction loss on the decoder for coherent source\nestimations. In order to carefully evaluate our method, we conduct experiments\non a toy dataset and with real-world biosignal recordings from a\npolysomnography sleep study for extracting respiration.",
          "link": "http://arxiv.org/abs/2309.07138",
          "publishedOn": "2023-09-16T00:40:56.727Z",
          "wordCount": null,
          "title": "Self-Supervised Blind Source Separation via Multi-Encoder Autoencoders. (arXiv:2309.07138v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07663",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ichikawa_Y/0/1/0/all/0/1\">Yuma Ichikawa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hukushima_K/0/1/0/all/0/1\">Koji Hukushima</a>",
          "description": "In the Variational Autoencoder (VAE), the variational posterior often aligns\nclosely with the prior, which is known as posterior collapse and hinders the\nquality of representation learning. To mitigate this problem, an adjustable\nhyperparameter beta has been introduced in the VAE. This paper presents a\nclosed-form expression to assess the relationship between the beta in VAE, the\ndataset size, the posterior collapse, and the rate-distortion curve by\nanalyzing a minimal VAE in a high-dimensional limit. These results clarify that\na long plateau in the generalization error emerges with a relatively larger\nbeta. As the beta increases, the length of the plateau extends and then becomes\ninfinite beyond a certain beta threshold. This implies that the choice of beta,\nunlike the usual regularization parameters, can induce posterior collapse\nregardless of the dataset size. Thus, beta is a risky parameter that requires\ncareful tuning. Furthermore, considering the dataset-size dependence on the\nrate-distortion curve, a relatively large dataset is required to obtain a\nrate-distortion curve with high rates. Extensive numerical experiments support\nour analysis.",
          "link": "http://arxiv.org/abs/2309.07663",
          "publishedOn": "2023-09-16T00:40:56.725Z",
          "wordCount": null,
          "title": "Dataset Size Dependence of Rate-Distortion Curve and Threshold of Posterior Collapse in Linear VAE. (arXiv:2309.07663v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07339",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Chen_S/0/1/0/all/0/1\">Samuel Yen-Chi Chen</a>",
          "description": "Quantum reinforcement learning (QRL) has emerged as a framework to solve\nsequential decision-making tasks, showcasing empirical quantum advantages. A\nnotable development is through quantum recurrent neural networks (QRNNs) for\nmemory-intensive tasks such as partially observable environments. However, QRL\nmodels incorporating QRNN encounter challenges such as inefficient training of\nQRL with QRNN, given that the computation of gradients in QRNN is both\ncomputationally expensive and time-consuming. This work presents a novel\napproach to address this challenge by constructing QRL agents utilizing\nQRNN-based reservoirs, specifically employing quantum long short-term memory\n(QLSTM). QLSTM parameters are randomly initialized and fixed without training.\nThe model is trained using the asynchronous advantage actor-aritic (A3C)\nalgorithm. Through numerical simulations, we validate the efficacy of our\nQLSTM-Reservoir RL framework. Its performance is assessed on standard\nbenchmarks, demonstrating comparable results to a fully trained QLSTM RL model\nwith identical architecture and training settings.",
          "link": "http://arxiv.org/abs/2309.07339",
          "publishedOn": "2023-09-16T00:40:56.724Z",
          "wordCount": null,
          "title": "Efficient quantum recurrent reinforcement learning via quantum reservoir computing. (arXiv:2309.07339v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.07611",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Zheng_H/0/1/0/all/0/1\">Han Zheng</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Li_Z/0/1/0/all/0/1\">Zimu Li</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Liu_J/0/1/0/all/0/1\">Junyu Liu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Strelchuk_S/0/1/0/all/0/1\">Sergii Strelchuk</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kondor_R/0/1/0/all/0/1\">Risi Kondor</a>",
          "description": "We develop a theoretical framework for $S_n$-equivariant convolutional\nquantum circuits with SU$(d)$-symmetry, building on and significantly\ngeneralizing Jordan's Permutational Quantum Computing (PQC) formalism based on\nSchur-Weyl duality connecting both SU$(d)$ and $S_n$ actions on qudits. In\nparticular, we utilize the Okounkov-Vershik approach to prove Harrow's\nstatement (Ph.D. Thesis 2005 p.160) on the equivalence between\n$\\operatorname{SU}(d)$ and $S_n$ irrep bases and to establish the\n$S_n$-equivariant Convolutional Quantum Alternating Ans\\\"atze ($S_n$-CQA) using\nYoung-Jucys-Murphy (YJM) elements. We prove that $S_n$-CQA is able to generate\nany unitary in any given $S_n$ irrep sector, which may serve as a universal\nmodel for a wide array of quantum machine learning problems with the presence\nof SU($d$) symmetry. Our method provides another way to prove the universality\nof Quantum Approximate Optimization Algorithm (QAOA) and verifies that 4-local\nSU($d$) symmetric unitaries are sufficient to build generic SU($d$) symmetric\nquantum circuits up to relative phase factors. We present numerical simulations\nto showcase the effectiveness of the ans\\\"atze to find the ground state energy\nof the $J_1$--$J_2$ antiferromagnetic Heisenberg model on the rectangular and\nKagome lattices. Our work provides the first application of the celebrated\nOkounkov-Vershik's $S_n$ representation theory to quantum physics and machine\nlearning, from which to propose quantum variational ans\\\"atze that strongly\nsuggests to be classically intractable tailored towards a specific optimization\nproblem.",
          "link": "http://arxiv.org/abs/2112.07611",
          "publishedOn": "2023-09-16T00:40:56.720Z",
          "wordCount": null,
          "title": "Speeding up Learning Quantum States through Group Equivariant Convolutional Quantum Ans\\\"atze. (arXiv:2112.07611v3 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07548",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Akiyama_Y/0/1/0/all/0/1\">Yuki Akiyama</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Slavakis_K/0/1/0/all/0/1\">Konstantinos Slavakis</a>",
          "description": "This paper aims at the algorithmic/theoretical core of reinforcement learning\n(RL) by introducing the novel class of proximal Bellman mappings. These\nmappings are defined in reproducing kernel Hilbert spaces (RKHSs), to benefit\nfrom the rich approximation properties and inner product of RKHSs, they are\nshown to belong to the powerful Hilbertian family of (firmly) nonexpansive\nmappings, regardless of the values of their discount factors, and possess ample\ndegrees of design freedom to even reproduce attributes of the classical Bellman\nmappings and to pave the way for novel RL designs. An approximate\npolicy-iteration scheme is built on the proposed class of mappings to solve the\nproblem of selecting online, at every time instance, the \"optimal\" exponent $p$\nin a $p$-norm loss to combat outliers in linear adaptive filtering, without\ntraining data and any knowledge on the statistical properties of the outliers.\nNumerical tests on synthetic data showcase the superior performance of the\nproposed framework over several non-RL and kernel-based RL schemes.",
          "link": "http://arxiv.org/abs/2309.07548",
          "publishedOn": "2023-09-16T00:40:56.719Z",
          "wordCount": null,
          "title": "Proximal Bellman mappings for reinforcement learning and their application to robust adaptive filtering. (arXiv:2309.07548v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07344",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nasim_M/0/1/0/all/0/1\">Md Nasim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1\">Yexiang Xue</a>",
          "description": "Accelerating the learning of Partial Differential Equations (PDEs) from\nexperimental data will speed up the pace of scientific discovery. Previous\nrandomized algorithms exploit sparsity in PDE updates for acceleration. However\nsuch methods are applicable to a limited class of decomposable PDEs, which have\nsparse features in the value domain. We propose Reel, which accelerates the\nlearning of PDEs via random projection and has much broader applicability. Reel\nexploits the sparsity by decomposing dense updates into sparse ones in both the\nvalue and frequency domains. This decomposition enables efficient learning when\nthe source of the updates consists of gradually changing terms across large\nareas (sparse in the frequency domain) in addition to a few rapid updates\nconcentrated in a small set of \"interfacial\" regions (sparse in the value\ndomain). Random projection is then applied to compress the sparse signals for\nlearning. To expand the model applicability, Taylor series expansion is used in\nReel to approximate the nonlinear PDE updates with polynomials in the\ndecomposable form. Theoretically, we derive a constant factor approximation\nbetween the projected loss function and the original one with poly-logarithmic\nnumber of projected dimensions. Experimentally, we provide empirical evidence\nthat our proposed Reel can lead to faster learning of PDE models (70-98%\nreduction in training time when the data is compressed to 1% of its original\nsize) with comparable quality as the non-compressed models.",
          "link": "http://arxiv.org/abs/2309.07344",
          "publishedOn": "2023-09-16T00:40:56.671Z",
          "wordCount": null,
          "title": "Efficient Learning of PDEs via Taylor Expansion and Sparse Decomposition into Value and Fourier Domains. (arXiv:2309.07344v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07452",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qin_L/0/1/0/all/0/1\">Lianke Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1\">Baocheng Sun</a>",
          "description": "A rising trend in theoretical deep learning is to understand why deep\nlearning works through Neural Tangent Kernel (NTK) [jgh18], a kernel method\nthat is equivalent to using gradient descent to train a multi-layer\ninfinitely-wide neural network. NTK is a major step forward in the theoretical\ndeep learning because it allows researchers to use traditional mathematical\ntools to analyze properties of deep neural networks and to explain various\nneural network techniques from a theoretical view. A natural extension of NTK\non graph learning is \\textit{Graph Neural Tangent Kernel (GNTK)}, and\nresearchers have already provide GNTK formulation for graph-level regression\nand show empirically that this kernel method can achieve similar accuracy as\nGNNs on various bioinformatics datasets [dhs+19]. The remaining question now is\nwhether solving GNTK regression is equivalent to training an infinite-wide\nmulti-layer GNN using gradient descent. In this paper, we provide three new\ntheoretical results. First, we formally prove this equivalence for graph-level\nregression. Second, we present the first GNTK formulation for node-level\nregression. Finally, we prove the equivalence for node-level regression.",
          "link": "http://arxiv.org/abs/2309.07452",
          "publishedOn": "2023-09-16T00:40:56.645Z",
          "wordCount": null,
          "title": "Is Solving Graph Neural Tangent Kernel Equivalent to Training Graph Neural Network?. (arXiv:2309.07452v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07383",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bouland_A/0/1/0/all/0/1\">Ali Bouland</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Niu_S/0/1/0/all/0/1\">Shengyuan Niu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Paruchuri_S/0/1/0/all/0/1\">Sai Tej Paruchuri</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kurdila_A/0/1/0/all/0/1\">Andrew Kurdila</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Burns_J/0/1/0/all/0/1\">John Burns</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schuster_E/0/1/0/all/0/1\">Eugenio Schuster</a>",
          "description": "This paper studies convergence rates for some value function approximations\nthat arise in a collection of reproducing kernel Hilbert spaces (RKHS)\n$H(\\Omega)$. By casting an optimal control problem in a specific class of\nnative spaces, strong rates of convergence are derived for the operator\nequation that enables offline approximations that appear in policy iteration.\nExplicit upper bounds on error in value function approximations are derived in\nterms of power function $\\Pwr_{H,N}$ for the space of finite dimensional\napproximants $H_N$ in the native space $H(\\Omega)$. These bounds are geometric\nin nature and refine some well-known, now classical results concerning\nconvergence of approximations of value functions.",
          "link": "http://arxiv.org/abs/2309.07383",
          "publishedOn": "2023-09-16T00:40:56.643Z",
          "wordCount": null,
          "title": "Rates of Convergence in Certain Native Spaces of Approximations used in Reinforcement Learning. (arXiv:2309.07383v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.00923",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jingcai Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xiaocheng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Song Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_P/0/1/0/all/0/1\">Peiran Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiewei Zhang</a>",
          "description": "This paper investigates a challenging problem of zero-shot learning in the\nmulti-label scenario (MLZSL), wherein, the model is trained to recognize\nmultiple unseen classes within a sample (e.g., an image) based on seen classes\nand auxiliary knowledge, e.g., semantic information. Existing methods usually\nresort to analyzing the relationship of various seen classes residing in a\nsample from the dimension of spatial or semantic characteristics, and transfer\nthe learned model to unseen ones. But they ignore the effective integration of\nlocal and global features. That is, in the process of inferring unseen classes,\nglobal features represent the principal direction of the image in the feature\nspace, while local features should maintain uniqueness within a certain range.\nThis integrated neglect will make the model lose its grasp of the main\ncomponents of the image. Relying only on the local existence of seen classes\nduring the inference stage introduces unavoidable bias. In this paper, we\npropose a novel and effective group bi-enhancement framework for MLZSL, dubbed\nGBE-MLZSL, to fully make use of such properties and enable a more accurate and\nrobust visual-semantic projection. Specifically, we split the feature maps into\nseveral feature groups, of which each feature group can be trained\nindependently with the Local Information Distinguishing Module (LID) to ensure\nuniqueness. Meanwhile, a Global Enhancement Module (GEM) is designed to\npreserve the principal direction. Besides, a static graph structure is designed\nto construct the correlation of local features. Experiments on large-scale\nMLZSL benchmark datasets NUS-WIDE and Open-Images-v4 demonstrate that the\nproposed GBE-MLZSL outperforms other state-of-the-art methods with large\nmargins.",
          "link": "http://arxiv.org/abs/2309.00923",
          "publishedOn": "2023-09-16T00:40:56.615Z",
          "wordCount": null,
          "title": "GBE-MLZSL: A Group Bi-Enhancement Framework for Multi-Label Zero-Shot Learning. (arXiv:2309.00923v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07145",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Liu_C/0/1/0/all/0/1\">Che Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wan_Z/0/1/0/all/0/1\">Zhongwei Wan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_S/0/1/0/all/0/1\">Sibo Cheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_M/0/1/0/all/0/1\">Mi Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Arcucci_R/0/1/0/all/0/1\">Rossella Arcucci</a>",
          "description": "In the domain of cardiovascular healthcare, the Electrocardiogram (ECG)\nserves as a critical, non-invasive diagnostic tool. Although recent strides in\nself-supervised learning (SSL) have been promising for ECG representation\nlearning, these techniques often require annotated samples and struggle with\nclasses not present in the fine-tuning stages. To address these limitations, we\nintroduce ECG-Text Pre-training (ETP), an innovative framework designed to\nlearn cross-modal representations that link ECG signals with textual reports.\nFor the first time, this framework leverages the zero-shot classification task\nin the ECG domain. ETP employs an ECG encoder along with a pre-trained language\nmodel to align ECG signals with their corresponding textual reports. The\nproposed framework excels in both linear evaluation and zero-shot\nclassification tasks, as demonstrated on the PTB-XL and CPSC2018 datasets,\nshowcasing its ability for robust and generalizable cross-modal ECG feature\nlearning.",
          "link": "http://arxiv.org/abs/2309.07145",
          "publishedOn": "2023-09-16T00:40:56.604Z",
          "wordCount": null,
          "title": "ETP: Learning Transferable ECG Representations via ECG-Text Pre-training. (arXiv:2309.07145v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07137",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yashchuk_I/0/1/0/all/0/1\">Ivan Yashchuk</a>",
          "description": "Partial differential equations (PDEs) are used to describe a variety of\nphysical phenomena. Often these equations do not have analytical solutions and\nnumerical approximations are used instead. One of the common methods to solve\nPDEs is the finite element method. Computing derivative information of the\nsolution with respect to the input parameters is important in many tasks in\nscientific computing. We extend JAX automatic differentiation library with an\ninterface to Firedrake finite element library. High-level symbolic\nrepresentation of PDEs allows bypassing differentiating through low-level\npossibly many iterations of the underlying nonlinear solvers. Differentiating\nthrough Firedrake solvers is done using tangent-linear and adjoint equations.\nThis enables the efficient composition of finite element solvers with arbitrary\ndifferentiable programs. The code is available at\ngithub.com/IvanYashchuk/jax-firedrake.",
          "link": "http://arxiv.org/abs/2309.07137",
          "publishedOn": "2023-09-16T00:40:56.594Z",
          "wordCount": null,
          "title": "Bringing PDEs to JAX with forward and reverse modes automatic differentiation. (arXiv:2309.07137v1 [cs.MS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.07937",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Rittig_J/0/1/0/all/0/1\">Jan G. Rittig</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Felton_K/0/1/0/all/0/1\">Kobi C. Felton</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lapkin_A/0/1/0/all/0/1\">Alexei A. Lapkin</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mitsos_A/0/1/0/all/0/1\">Alexander Mitsos</a>",
          "description": "We propose Gibbs-Duhem-informed neural networks for the prediction of binary\nactivity coefficients at varying compositions. That is, we include the\nGibbs-Duhem equation explicitly in the loss function for training neural\nnetworks, which is straightforward in standard machine learning (ML) frameworks\nenabling automatic differentiation. In contrast to recent hybrid ML approaches,\nour approach does not rely on embedding a specific thermodynamic model inside\nthe neural network and corresponding prediction limitations. Rather,\nGibbs-Duhem consistency serves as regularization, with the flexibility of ML\nmodels being preserved. Our results show increased thermodynamic consistency\nand generalization capabilities for activity coefficient predictions by\nGibbs-Duhem-informed graph neural networks and matrix completion methods. We\nalso find that the model architecture, particularly the activation function,\ncan have a strong influence on the prediction quality. The approach can be\neasily extended to account for other thermodynamic consistency conditions.",
          "link": "http://arxiv.org/abs/2306.07937",
          "publishedOn": "2023-09-16T00:40:56.593Z",
          "wordCount": null,
          "title": "Gibbs-Duhem-Informed Neural Networks for Binary Activity Coefficient Prediction. (arXiv:2306.07937v2 [physics.chem-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07175",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Jafrasteh_B/0/1/0/all/0/1\">Bahram Jafrasteh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lopez_S/0/1/0/all/0/1\">Sim&#xf3;n Pedro Lubi&#xe1;n L&#xf3;pez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fernandez_I/0/1/0/all/0/1\">Isabel Benavente Fern&#xe1;ndez</a>",
          "description": "MELAGE, a pioneering Python-based neuroimaging software, emerges as a\nversatile tool for the visualization, processing, and analysis of medical\nimages. Initially conceived to address the unique challenges of processing 3D\nultrasound and MRI brain images during the neonatal period, MELAGE exhibits\nremarkable adaptability, extending its utility to the domain of adult human\nbrain imaging. At its core, MELAGE features a semi-automatic brain extraction\ntool empowered by a deep learning module, ensuring precise and efficient brain\nstructure extraction from MRI and 3D Ultrasound data. Moreover, MELAGE offers a\ncomprehensive suite of features, encompassing dynamic 3D visualization,\naccurate measurements, and interactive image segmentation. This transformative\nsoftware holds immense promise for researchers and clinicians, offering\nstreamlined image analysis, seamless integration with deep learning algorithms,\nand broad applicability in the realm of medical imaging.",
          "link": "http://arxiv.org/abs/2309.07175",
          "publishedOn": "2023-09-16T00:40:56.587Z",
          "wordCount": null,
          "title": "MELAGE: A purely python based Neuroimaging software (Neonatal). (arXiv:2309.07175v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15021",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mu_Y/0/1/0/all/0/1\">Yao Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qinglong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1\">Mengkang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenhai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Mingyu Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Jun Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1\">Jifeng Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1\">Ping Luo</a>",
          "description": "Embodied AI is a crucial frontier in robotics, capable of planning and\nexecuting action sequences for robots to accomplish long-horizon tasks in\nphysical environments. In this work, we introduce EmbodiedGPT, an end-to-end\nmulti-modal foundation model for embodied AI, empowering embodied agents with\nmulti-modal understanding and execution capabilities. To achieve this, we have\nmade the following efforts: (i) We craft a large-scale embodied planning\ndataset, termed EgoCOT. The dataset consists of carefully selected videos from\nthe Ego4D dataset, along with corresponding high-quality language instructions.\nSpecifically, we generate a sequence of sub-goals with the \"Chain of Thoughts\"\nmode for effective embodied planning. (ii) We introduce an efficient training\napproach to EmbodiedGPT for high-quality plan generation, by adapting a 7B\nlarge language model (LLM) to the EgoCOT dataset via prefix tuning. (iii) We\nintroduce a paradigm for extracting task-related features from LLM-generated\nplanning queries to form a closed loop between high-level planning and\nlow-level control. Extensive experiments show the effectiveness of EmbodiedGPT\non embodied tasks, including embodied planning, embodied control, visual\ncaptioning, and visual question answering. Notably, EmbodiedGPT significantly\nenhances the success rate of the embodied control task by extracting more\neffective features. It has achieved a remarkable 1.6 times increase in success\nrate on the Franka Kitchen benchmark and a 1.3 times increase on the Meta-World\nbenchmark, compared to the BLIP-2 baseline fine-tuned with the Ego4D dataset.",
          "link": "http://arxiv.org/abs/2305.15021",
          "publishedOn": "2023-09-16T00:40:56.565Z",
          "wordCount": null,
          "title": "EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought. (arXiv:2305.15021v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07135",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ingolfsson_T/0/1/0/all/0/1\">Thorir Mar Ingolfsson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chakraborty_U/0/1/0/all/0/1\">Upasana Chakraborty</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1\">Xiaying Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Beniczky_S/0/1/0/all/0/1\">Sandor Beniczky</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ducouret_P/0/1/0/all/0/1\">Pauline Ducouret</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Benatti_S/0/1/0/all/0/1\">Simone Benatti</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ryvlin_P/0/1/0/all/0/1\">Philippe Ryvlin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cossettini_A/0/1/0/all/0/1\">Andrea Cossettini</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Benini_L/0/1/0/all/0/1\">Luca Benini</a>",
          "description": "Epilepsy is a prevalent neurological disorder that affects millions of\nindividuals globally, and continuous monitoring coupled with automated seizure\ndetection appears as a necessity for effective patient treatment. To enable\nlong-term care in daily-life conditions, comfortable and smart wearable devices\nwith long battery life are required, which in turn set the demand for\nresource-constrained and energy-efficient computing solutions. In this context,\nthe development of machine learning algorithms for seizure detection faces the\nchallenge of heavily imbalanced datasets. This paper introduces EpiDeNet, a new\nlightweight seizure detection network, and Sensitivity-Specificity Weighted\nCross-Entropy (SSWCE), a new loss function that incorporates sensitivity and\nspecificity, to address the challenge of heavily unbalanced datasets. The\nproposed EpiDeNet-SSWCE approach demonstrates the successful detection of\n91.16% and 92.00% seizure events on two different datasets (CHB-MIT and\nPEDESITE, respectively), with only four EEG channels. A three-window majority\nvoting-based smoothing scheme combined with the SSWCE loss achieves 3x\nreduction of false positives to 1.18 FP/h. EpiDeNet is well suited for\nimplementation on low-power embedded platforms, and we evaluate its performance\non two ARM Cortex-based platforms (M4F/M7) and two parallel ultra-low power\n(PULP) systems (GAP8, GAP9). The most efficient implementation (GAP9) achieves\nan energy efficiency of 40 GMAC/s/W, with an energy consumption per inference\nof only 0.051 mJ at high performance (726.46 MMAC/s), outperforming the best\nARM Cortex-based solutions by approximately 160x in energy efficiency. The\nEpiDeNet-SSWCE method demonstrates effective and accurate seizure detection\nperformance on heavily imbalanced datasets, while being suited for\nimplementation on energy-constrained platforms.",
          "link": "http://arxiv.org/abs/2309.07135",
          "publishedOn": "2023-09-16T00:40:56.534Z",
          "wordCount": null,
          "title": "EpiDeNet: An Energy-Efficient Approach to Seizure Detection for Embedded Systems. (arXiv:2309.07135v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07461",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Farrukh_Y/0/1/0/all/0/1\">Yasir Ali Farrukh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wali_S/0/1/0/all/0/1\">Syed Wali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_I/0/1/0/all/0/1\">Irfan Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastian_N/0/1/0/all/0/1\">Nathaniel D. Bastian</a>",
          "description": "The widespread integration of Internet of Things (IoT) devices across all\nfacets of life has ushered in an era of interconnectedness, creating new\navenues for cybersecurity challenges and underscoring the need for robust\nintrusion detection systems. However, traditional security systems are designed\nwith a closed-world perspective and often face challenges in dealing with the\never-evolving threat landscape, where new and unfamiliar attacks are constantly\nemerging. In this paper, we introduce a framework aimed at mitigating the open\nset recognition (OSR) problem in the realm of Network Intrusion Detection\nSystems (NIDS) tailored for IoT environments. Our framework capitalizes on\nimage-based representations of packet-level data, extracting spatial and\ntemporal patterns from network traffic. Additionally, we integrate stacking and\nsub-clustering techniques, enabling the identification of unknown attacks by\neffectively modeling the complex and diverse nature of benign behavior. The\nempirical results prominently underscore the framework's efficacy, boasting an\nimpressive 88\\% detection rate for previously unseen attacks when compared\nagainst existing approaches and recent advancements. Future work will perform\nextensive experimentation across various openness levels and attack scenarios,\nfurther strengthening the adaptability and performance of our proposed solution\nin safeguarding IoT environments.",
          "link": "http://arxiv.org/abs/2309.07461",
          "publishedOn": "2023-09-16T00:40:56.503Z",
          "wordCount": null,
          "title": "Detecting Unknown Attacks in IoT Environments: An Open Set Classifier for Enhanced Network Intrusion Detection. (arXiv:2309.07461v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07893",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tripuraneni_N/0/1/0/all/0/1\">Nilesh Tripuraneni</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Richardson_L/0/1/0/all/0/1\">Lee Richardson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+DAmour_A/0/1/0/all/0/1\">Alexander D&#x27;Amour</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Soriano_J/0/1/0/all/0/1\">Jacopo Soriano</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yadlowsky_S/0/1/0/all/0/1\">Steve Yadlowsky</a>",
          "description": "In many randomized experiments, the treatment effect of the long-term metric\n(i.e. the primary outcome of interest) is often difficult or infeasible to\nmeasure. Such long-term metrics are often slow to react to changes and\nsufficiently noisy they are challenging to faithfully estimate in short-horizon\nexperiments. A common alternative is to measure several short-term proxy\nmetrics in the hope they closely track the long-term metric -- so they can be\nused to effectively guide decision-making in the near-term. We introduce a new\nstatistical framework to both define and construct an optimal proxy metric for\nuse in a homogeneous population of randomized experiments. Our procedure first\nreduces the construction of an optimal proxy metric in a given experiment to a\nportfolio optimization problem which depends on the true latent treatment\neffects and noise level of experiment under consideration. We then denoise the\nobserved treatment effects of the long-term metric and a set of proxies in a\nhistorical corpus of randomized experiments to extract estimates of the latent\ntreatment effects for use in the optimization problem. One key insight derived\nfrom our approach is that the optimal proxy metric for a given experiment is\nnot apriori fixed; rather it should depend on the sample size (or effective\nnoise level) of the randomized experiment for which it is deployed. To\ninstantiate and evaluate our framework, we employ our methodology in a large\ncorpus of randomized experiments from an industrial recommendation system and\nconstruct proxy metrics that perform favorably relative to several baselines.",
          "link": "http://arxiv.org/abs/2309.07893",
          "publishedOn": "2023-09-16T00:40:56.503Z",
          "wordCount": null,
          "title": "Choosing a Proxy Metric from Past Experiments. (arXiv:2309.07893v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07196",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianpu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1\">Weilong Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_M/0/1/0/all/0/1\">Mengda Xing</a>",
          "description": "As one of the important tools for spatial feature extraction, graph\nconvolution has been applied in a wide range of fields such as traffic flow\nprediction. However, current popular works of graph convolution cannot\nguarantee spatio-temporal consistency in a long period. The ignorance of\ncorrelational dynamics, convolutional locality and temporal comprehensiveness\nwould limit predictive accuracy. In this paper, a novel Attention-based Dynamic\nGraph Convolutional Recurrent Neural Network (ADGCRNN) is proposed to improve\ntraffic flow prediction in highway transportation. Three temporal resolutions\nof data sequence are effectively integrated by self-attention to extract\ncharacteristics; multi-dynamic graphs and their weights are dynamically created\nto compliantly combine the varying characteristics; a dedicated gated kernel\nemphasizing highly relative nodes is introduced on these complete graphs to\nreduce overfitting for graph convolution operations. Experiments on two public\ndatasets show our work better than state-of-the-art baselines, and case studies\nof a real Web system prove practical benefit in highway transportation.",
          "link": "http://arxiv.org/abs/2309.07196",
          "publishedOn": "2023-09-16T00:40:56.474Z",
          "wordCount": null,
          "title": "Attention-based Dynamic Graph Convolutional Recurrent Neural Network for Traffic Flow Prediction in Highway Transportation. (arXiv:2309.07196v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07289",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bicer_Y/0/1/0/all/0/1\">Yunus Bicer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smedemark_Margulies_N/0/1/0/all/0/1\">Niklas Smedemark-Margulies</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celik_B/0/1/0/all/0/1\">Basak Celik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sunger_E/0/1/0/all/0/1\">Elifnur Sunger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orendorff_R/0/1/0/all/0/1\">Ryan Orendorff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naufel_S/0/1/0/all/0/1\">Stephanie Naufel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imbiriba_T/0/1/0/all/0/1\">Tales Imbiriba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdo%7Bg%7Dmu%7Bs%7D_D/0/1/0/all/0/1\">Deniz Erdo{&#x11f;}mu{&#x15f;}</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tunik_E/0/1/0/all/0/1\">Eugene Tunik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yarossi_M/0/1/0/all/0/1\">Mathew Yarossi</a>",
          "description": "We designed and tested a system for real-time control of a user interface by\nextracting surface electromyographic (sEMG) activity from eight electrodes in a\nwrist-band configuration. sEMG data were streamed into a machine-learning\nalgorithm that classified hand gestures in real-time. After an initial model\ncalibration, participants were presented with one of three types of feedback\nduring a human-learning stage: veridical feedback, in which predicted\nprobabilities from the gesture classification algorithm were displayed without\nalteration, modified feedback, in which we applied a hidden augmentation of\nerror to these probabilities, and no feedback. User performance was then\nevaluated in a series of minigames, in which subjects were required to use\neight gestures to manipulate their game avatar to complete a task. Experimental\nresults indicated that, relative to baseline, the modified feedback condition\nled to significantly improved accuracy and improved gesture class separation.\nThese findings suggest that real-time feedback in a gamified user interface\nwith manipulation of feedback may enable intuitive, rapid, and accurate task\nacquisition for sEMG-based gesture recognition applications.",
          "link": "http://arxiv.org/abs/2309.07289",
          "publishedOn": "2023-09-16T00:40:56.451Z",
          "wordCount": null,
          "title": "User Training with Error Augmentation for Electromyogram-based Gesture Classification. (arXiv:2309.07289v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07176",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1\">Angela Zhou</a>",
          "description": "In consequential domains, it is often impossible to compel individuals to\ntake treatment, so that optimal policy rules are merely suggestions in the\npresence of human non-adherence to treatment recommendations. In these same\ndomains, there may be heterogeneity both in who responds in taking-up\ntreatment, and heterogeneity in treatment efficacy. While optimal treatment\nrules can maximize causal outcomes across the population, access parity\nconstraints or other fairness considerations can be relevant in the case of\nencouragement. For example, in social services, a persistent puzzle is the gap\nin take-up of beneficial services among those who may benefit from them the\nmost. When in addition the decision-maker has distributional preferences over\nboth access and average outcomes, the optimal decision rule changes. We study\ncausal identification, statistical variance-reduced estimation, and robust\nestimation of optimal treatment rules, including under potential violations of\npositivity. We consider fairness constraints such as demographic parity in\ntreatment take-up, and other constraints, via constrained optimization. Our\nframework can be extended to handle algorithmic recommendations under an\noften-reasonable covariate-conditional exclusion restriction, using our\nrobustness checks for lack of positivity in the recommendation. We develop a\ntwo-stage algorithm for solving over parametrized policy classes under general\nconstraints to obtain variance-sensitive regret bounds. We illustrate the\nmethods in two case studies based on data from randomized encouragement to\nenroll in insurance and from pretrial supervised release with electronic\nmonitoring.",
          "link": "http://arxiv.org/abs/2309.07176",
          "publishedOn": "2023-09-16T00:40:56.177Z",
          "wordCount": null,
          "title": "Optimal and Fair Encouragement Policy Evaluation and Learning. (arXiv:2309.07176v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.14541",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Faruque_O/0/1/0/all/0/1\">Omar Faruque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nji_F/0/1/0/all/0/1\">Francis Ndikum Nji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cham_M/0/1/0/all/0/1\">Mostafa Cham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salvi_R/0/1/0/all/0/1\">Rohan Mandar Salvi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xue Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianwu Wang</a>",
          "description": "Clustering high-dimensional spatiotemporal data using an unsupervised\napproach is a challenging problem for many data-driven applications. Existing\nstate-of-the-art methods for unsupervised clustering use different similarity\nand distance functions but focus on either spatial or temporal features of the\ndata. Concentrating on joint deep representation learning of spatial and\ntemporal features, we propose Deep Spatiotemporal Clustering (DSC), a novel\nalgorithm for the temporal clustering of high-dimensional spatiotemporal data\nusing an unsupervised deep learning method. Inspired by the U-net architecture,\nDSC utilizes an autoencoder integrating CNN-RNN layers to learn latent\nrepresentations of the spatiotemporal data. DSC also includes a unique layer\nfor cluster assignment on latent representations that uses the Student's\nt-distribution. By optimizing the clustering loss and data reconstruction loss\nsimultaneously, the algorithm gradually improves clustering assignments and the\nnonlinear mapping between low-dimensional latent feature space and\nhigh-dimensional original data space. A multivariate spatiotemporal climate\ndataset is used to evaluate the efficacy of the proposed method. Our extensive\nexperiments show our approach outperforms both conventional and deep\nlearning-based unsupervised clustering algorithms. Additionally, we compared\nthe proposed model with its various variants (CNN encoder, CNN autoencoder,\nCNN-RNN encoder, CNN-RNN autoencoder, etc.) to get insight into using both the\nCNN and RNN layers in the autoencoder, and our proposed technique outperforms\nthese variants in terms of clustering results.",
          "link": "http://arxiv.org/abs/2304.14541",
          "publishedOn": "2023-09-16T00:40:56.177Z",
          "wordCount": null,
          "title": "Deep Spatiotemporal Clustering: A Temporal Clustering Approach for Multi-dimensional Climate Data. (arXiv:2304.14541v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07140",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Cui_Y/0/1/0/all/0/1\">Yang Cui</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_H/0/1/0/all/0/1\">Han Zhu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1\">Yijian Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_L/0/1/0/all/0/1\">Lu Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>",
          "description": "In deep learning, the load data with non-temporal factors are difficult to\nprocess by sequence models. This problem results in insufficient precision of\nthe prediction. Therefore, a short-term load forecasting method based on\nconvolutional neural network (CNN), self-attention encoder-decoder network\n(SAEDN) and residual-refinement (Res) is proposed. In this method, feature\nextraction module is composed of a two-dimensional convolutional neural\nnetwork, which is used to mine the local correlation between data and obtain\nhigh-dimensional data features. The initial load fore-casting module consists\nof a self-attention encoder-decoder network and a feedforward neural network\n(FFN). The module utilizes self-attention mechanisms to encode high-dimensional\nfeatures. This operation can obtain the global correlation between data.\nTherefore, the model is able to retain important information based on the\ncoupling relationship between the data in data mixed with non-time series\nfactors. Then, self-attention decoding is per-formed and the feedforward neural\nnetwork is used to regression initial load. This paper introduces the residual\nmechanism to build the load optimization module. The module generates residual\nload values to optimize the initial load. The simulation results show that the\nproposed load forecasting method has advantages in terms of prediction accuracy\nand prediction stability.",
          "link": "http://arxiv.org/abs/2309.07140",
          "publishedOn": "2023-09-16T00:40:55.832Z",
          "wordCount": 724,
          "title": "Short-term power load forecasting method based on CNN-SAEDN-Res. (arXiv:2309.07140v1 [eess.SP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.04953",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Cavlak_M/0/1/0/all/0/1\">Meryem Banu Cavlak</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Singh_G/0/1/0/all/0/1\">Gagandeep Singh</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Alser_M/0/1/0/all/0/1\">Mohammed Alser</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Firtina_C/0/1/0/all/0/1\">Can Firtina</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lindegger_J/0/1/0/all/0/1\">Jo&#xeb;l Lindegger</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sadrosadati_M/0/1/0/all/0/1\">Mohammad Sadrosadati</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ghiasi_N/0/1/0/all/0/1\">Nika Mansouri Ghiasi</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Alkan_C/0/1/0/all/0/1\">Can Alkan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Mutlu_O/0/1/0/all/0/1\">Onur Mutlu</a>",
          "description": "Basecalling is an essential step in nanopore sequencing analysis where the\nraw signals of nanopore sequencers are converted into nucleotide sequences,\ni.e., reads. State-of-the-art basecallers employ complex deep learning models\nto achieve high basecalling accuracy. This makes basecalling\ncomputationally-inefficient and memory-hungry; bottlenecking the entire genome\nanalysis pipeline. However, for many applications, the majority of reads do no\nmatch the reference genome of interest (i.e., target reference) and thus are\ndiscarded in later steps in the genomics pipeline, wasting the basecalling\ncomputation. To overcome this issue, we propose TargetCall, the first\npre-basecalling filter to eliminate the wasted computation in basecalling.\nTargetCall's key idea is to discard reads that will not match the target\nreference (i.e., off-target reads) prior to basecalling. TargetCall consists of\ntwo main components: (1) LightCall, a lightweight neural network basecaller\nthat produces noisy reads; and (2) Similarity Check, which labels each of these\nnoisy reads as on-target or off-target by matching them to the target\nreference. TargetCall aims to filter out all off-target reads before\nbasecalling. The highly-accurate but slow basecalling is performed only on the\nraw signals whose noisy reads are labeled as on-target. Our thorough\nexperimental evaluations using both real and simulated data show that\nTargetCall 1) improves the end-to-end basecalling performance while maintaining\nhigh sensitivity in keeping on-target reads, 2) maintains high accuracy in\ndownstream analysis, 3) precisely filters out up to 94.71% of off-target reads,\nand 4) achieves better performance, throughput, sensitivity, precision, and\ngenerality compared to prior works. We open-source TargetCall at\nhttps://github.com/CMU-SAFARI/TargetCall",
          "link": "http://arxiv.org/abs/2212.04953",
          "publishedOn": "2023-09-16T00:40:55.822Z",
          "wordCount": 793,
          "title": "TargetCall: Eliminating the Wasted Computation in Basecalling via Pre-Basecalling Filtering. (arXiv:2212.04953v2 [q-bio.GN] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.10520",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lehner_J/0/1/0/all/0/1\">Johannes Lehner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alkin_B/0/1/0/all/0/1\">Benedikt Alkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furst_A/0/1/0/all/0/1\">Andreas F&#xfc;rst</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rumetshofer_E/0/1/0/all/0/1\">Elisabeth Rumetshofer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miklautz_L/0/1/0/all/0/1\">Lukas Miklautz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hochreiter_S/0/1/0/all/0/1\">Sepp Hochreiter</a>",
          "description": "Masked Image Modeling (MIM) methods, like Masked Autoencoders (MAE),\nefficiently learn a rich representation of the input. However, for adapting to\ndownstream tasks, they require a sufficient amount of labeled data since their\nrich features code not only objects but also less relevant image background. In\ncontrast, Instance Discrimination (ID) methods focus on objects. In this work,\nwe study how to combine the efficiency and scalability of MIM with the ability\nof ID to perform downstream classification in the absence of large amounts of\nlabeled data. To this end, we introduce Masked Autoencoder Contrastive Tuning\n(MAE-CT), a sequential approach that utilizes the implicit clustering of the\nNearest Neighbor Contrastive Learning (NNCLR) objective to induce abstraction\nin the topmost layers of a pre-trained MAE. MAE-CT tunes the rich features such\nthat they form semantic clusters of objects without using any labels. Notably,\nMAE-CT does not rely on hand-crafted augmentations and frequently achieves its\nbest performances while using only minimal augmentations (crop & flip).\nFurther, MAE-CT is compute efficient as it requires at most 10% overhead\ncompared to MAE re-training. Applied to large and huge Vision Transformer (ViT)\nmodels, MAE-CT excels over previous self-supervised methods trained on ImageNet\nin linear probing, k-NN and low-shot classification accuracy as well as in\nunsupervised clustering accuracy. With ViT-H/16 MAE-CT achieves a new\nstate-of-the-art in linear probing of 82.2%.",
          "link": "http://arxiv.org/abs/2304.10520",
          "publishedOn": "2023-09-16T00:40:55.810Z",
          "wordCount": 782,
          "title": "Contrastive Tuning: A Little Help to Make Masked Autoencoders Forget. (arXiv:2304.10520v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07250",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+East_R/0/1/0/all/0/1\">Richard D. P. East</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Alonso_Linaje_G/0/1/0/all/0/1\">Guillermo Alonso-Linaje</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Park_C/0/1/0/all/0/1\">Chae-Yeun Park</a>",
          "description": "Variational algorithms require architectures that naturally constrain the\noptimisation space to run efficiently. In geometric quantum machine learning,\none achieves this by encoding group structure into parameterised quantum\ncircuits to include the symmetries of a problem as an inductive bias. However,\nconstructing such circuits is challenging as a concrete guiding principle has\nyet to emerge. In this paper, we propose the use of spin networks, a form of\ndirected tensor network invariant under a group transformation, to devise SU(2)\nequivariant quantum circuit ans\\\"atze -- circuits possessing spin rotation\nsymmetry. By changing to the basis that block diagonalises SU(2) group action,\nthese networks provide a natural building block for constructing parameterised\nequivariant quantum circuits. We prove that our construction is mathematically\nequivalent to other known constructions, such as those based on twirling and\ngeneralised permutations, but more direct to implement on quantum hardware. The\nefficacy of our constructed circuits is tested by solving the ground state\nproblem of SU(2) symmetric Heisenberg models on the one-dimensional triangular\nlattice and on the Kagome lattice. Our results highlight that our equivariant\ncircuits boost the performance of quantum variational algorithms, indicating\nbroader applicability to other real-world problems.",
          "link": "http://arxiv.org/abs/2309.07250",
          "publishedOn": "2023-09-16T00:40:55.794Z",
          "wordCount": 729,
          "title": "All you need is spin: SU(2) equivariant variational quantum circuits based on spin networks. (arXiv:2309.07250v1 [quant-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.14131",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_S/0/1/0/all/0/1\">Shengchao Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shu_T/0/1/0/all/0/1\">Ting Shu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_H/0/1/0/all/0/1\">Huan Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhong_G/0/1/0/all/0/1\">Guo Zhong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1\">Xunlai Chen</a>",
          "description": "Meteorological radar reflectivity data (i.e. radar echo) significantly\ninfluences precipitation prediction. It can facilitate accurate and expeditious\nforecasting of short-term heavy rainfall bypassing the need for complex\nNumerical Weather Prediction (NWP) models. In comparison to conventional\nmodels, Deep Learning (DL)-based radar echo extrapolation algorithms exhibit\nhigher effectiveness and efficiency. Nevertheless, the development of reliable\nand generalized echo extrapolation algorithm is impeded by three primary\nchallenges: cumulative error spreading, imprecise representation of sparsely\ndistributed echoes, and inaccurate description of non-stationary motion\nprocesses. To tackle these challenges, this paper proposes a novel radar echo\nextrapolation algorithm called Temporal-Spatial Parallel Transformer, referred\nto as TempEE. TempEE avoids using auto-regression and instead employs a\none-step forward strategy to prevent cumulative error spreading during the\nextrapolation process. Additionally, we propose the incorporation of a\nMulti-level Temporal-Spatial Attention mechanism to improve the algorithm's\ncapability of capturing both global and local information while emphasizing\ntask-related regions, including sparse echo representations, in an efficient\nmanner. Furthermore, the algorithm extracts spatio-temporal representations\nfrom continuous echo images using a parallel encoder to model the\nnon-stationary motion process for echo extrapolation. The superiority of our\nTempEE has been demonstrated in the context of the classic radar echo\nextrapolation task, utilizing a real-world dataset. Extensive experiments have\nfurther validated the efficacy and indispensability of various components\nwithin TempEE.",
          "link": "http://arxiv.org/abs/2304.14131",
          "publishedOn": "2023-09-16T00:40:55.786Z",
          "wordCount": 774,
          "title": "TempEE: Temporal-Spatial Parallel Transformer for Radar Echo Extrapolation Beyond Auto-Regression. (arXiv:2304.14131v2 [eess.SP] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2009.01726",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Escobar_Bach_M/0/1/0/all/0/1\">Mikael Escobar-Bach</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Goudet_O/0/1/0/all/0/1\">Olivier Goudet</a>",
          "description": "In the presence of right-censored data with covariates, the conditional\nKaplan-Meier estimator (also known as the Beran estimator) consistently\nestimates the conditional survival function of the random follow-up for the\nevent of interest. However, a necessary condition is the unambiguous knowledge\nof whether each individual is censored or not, which may be incomplete in\npractice. We therefore propose a study of the Beran estimator when the\ncensoring indicators are generic random variables and discuss necessary\nconditions for the efficiency of the Beran estimator. From this, we provide a\nnew estimator for the conditional survival function with missing not at random\n(MNAR) censoring indicators based on a conditional copula model for the\nmissingness mechanism. In addition to the theoretical results, we illustrate\nhow the estimators work for small samples through a simulation study and show\ntheir practical applicability by analyzing synthetic and real data.",
          "link": "http://arxiv.org/abs/2009.01726",
          "publishedOn": "2023-09-16T00:40:55.687Z",
          "wordCount": 673,
          "title": "Survival Estimation for Missing not at Random Censoring Indicators based on Copula Models. (arXiv:2009.01726v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07602",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Klenitskiy_A/0/1/0/all/0/1\">Anton Klenitskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasilev_A/0/1/0/all/0/1\">Alexey Vasilev</a>",
          "description": "Recently sequential recommendations and next-item prediction task has become\nincreasingly popular in the field of recommender systems. Currently, two\nstate-of-the-art baselines are Transformer-based models SASRec and BERT4Rec.\nOver the past few years, there have been quite a few publications comparing\nthese two algorithms and proposing new state-of-the-art models. In most of the\npublications, BERT4Rec achieves better performance than SASRec. But BERT4Rec\nuses cross-entropy over softmax for all items, while SASRec uses negative\nsampling and calculates binary cross-entropy loss for one positive and one\nnegative item. In our work, we show that if both models are trained with the\nsame loss, which is used by BERT4Rec, then SASRec will significantly outperform\nBERT4Rec both in terms of quality and training speed. In addition, we show that\nSASRec could be effectively trained with negative sampling and still outperform\nBERT4Rec, but the number of negative examples should be much larger than one.",
          "link": "http://arxiv.org/abs/2309.07602",
          "publishedOn": "2023-09-16T00:40:55.653Z",
          "wordCount": 669,
          "title": "Turning Dross Into Gold Loss: is BERT4Rec really better than SASRec?. (arXiv:2309.07602v1 [cs.IR])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Klemen_M/0/1/0/all/0/1\">Maximiliano Klemen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carreira_Perpinan_M/0/1/0/all/0/1\">Miguel &#xc1;. Carreira-Perpi&#xf1;&#xe1;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopez_Garcia_P/0/1/0/all/0/1\">Pedro Lopez-Garcia</a>",
          "description": "Automatic static cost analysis infers information about the resources used by\nprograms without actually running them with concrete data, and presents such\ninformation as functions of input data sizes. Most of the analysis tools for\nlogic programs (and other languages) are based on setting up recurrence\nrelations representing (bounds on) the computational cost of predicates, and\nsolving them to find closed-form functions that are equivalent to (or a bound\non) them. Such recurrence solving is a bottleneck in current tools: many of the\nrecurrences that arise during the analysis cannot be solved with current\nsolvers, such as Computer Algebra Systems (CASs), so that specific methods for\ndifferent classes of recurrences need to be developed. We address such a\nchallenge by developing a novel, general approach for solving arbitrary,\nconstrained recurrence relations, that uses machine-learning sparse regression\ntechniques to guess a candidate closed-form function, and a combination of an\nSMT-solver and a CAS to check whether such function is actually a solution of\nthe recurrence. We have implemented a prototype and evaluated it with\nrecurrences generated by a cost analysis system (the one in CiaoPP). The\nexperimental results are quite promising, showing that our approach can find\nclosed-form solutions, in a reasonable time, for classes of recurrences that\ncannot be solved by such a system, nor by current CASs.",
          "link": "http://arxiv.org/abs/2309.07259",
          "publishedOn": "2023-09-16T00:40:55.637Z",
          "wordCount": 762,
          "title": "Solving Recurrence Relations using Machine Learning, with Application to Cost Analysis. (arXiv:2309.07259v1 [cs.PL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07809",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hasircioglu_B/0/1/0/all/0/1\">Burak Hasircioglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunduz_D/0/1/0/all/0/1\">Deniz Gunduz</a>",
          "description": "The task of preserving privacy while ensuring efficient communication is a\nfundamental challenge in federated learning. In this work, we tackle this\nchallenge in the trusted aggregator model, and propose a solution that achieves\nboth objectives simultaneously. We show that employing a quantization scheme\nbased on subtractive dithering at the clients can effectively replicate the\nnormal noise addition process at the aggregator. This implies that we can\nguarantee the same level of differential privacy against other clients while\nsubstantially reducing the amount of communication required, as opposed to\ntransmitting full precision gradients and using central noise addition. We also\nexperimentally demonstrate that the accuracy of our proposed approach matches\nthat of the full precision gradient method.",
          "link": "http://arxiv.org/abs/2309.07809",
          "publishedOn": "2023-09-16T00:40:55.620Z",
          "wordCount": 616,
          "title": "Communication Efficient Private Federated Learning Using Dithering. (arXiv:2309.07809v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07364",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mollers_A/0/1/0/all/0/1\">Alexander M&#xf6;llers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Immer_A/0/1/0/all/0/1\">Alexander Immer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fortuin_V/0/1/0/all/0/1\">Vincent Fortuin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isufi_E/0/1/0/all/0/1\">Elvin Isufi</a>",
          "description": "Simplicial complexes prove effective in modeling data with multiway\ndependencies, such as data defined along the edges of networks or within other\nhigher-order structures. Their spectrum can be decomposed into three\ninterpretable subspaces via the Hodge decomposition, resulting foundational in\nnumerous applications. We leverage this decomposition to develop a contrastive\nself-supervised learning approach for processing simplicial data and generating\nembeddings that encapsulate specific spectral information.Specifically, we\nencode the pertinent data invariances through simplicial neural networks and\ndevise augmentations that yield positive contrastive examples with suitable\nspectral properties for downstream tasks. Additionally, we reweight the\nsignificance of negative examples in the contrastive loss, considering the\nsimilarity of their Hodge components to the anchor. By encouraging a stronger\nseparation among less similar instances, we obtain an embedding space that\nreflects the spectral properties of the data. The numerical results on two\nstandard edge flow classification tasks show a superior performance even when\ncompared to supervised learning techniques. Our findings underscore the\nimportance of adopting a spectral perspective for contrastive learning with\nhigher-order data.",
          "link": "http://arxiv.org/abs/2309.07364",
          "publishedOn": "2023-09-16T00:40:55.549Z",
          "wordCount": 666,
          "title": "Hodge-Aware Contrastive Learning. (arXiv:2309.07364v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07770",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Yi_J/0/1/0/all/0/1\">Jianming Yi</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Suresh_K/0/1/0/all/0/1\">Kalyani Suresh</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Moghiseh_A/0/1/0/all/0/1\">Ali Moghiseh</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Wehn_N/0/1/0/all/0/1\">Norbert Wehn</a>",
          "description": "Quantum Support Vector Machines (QSVM) play a vital role in using quantum\nresources for supervised machine learning tasks, such as classification.\nHowever, current methods are strongly limited in terms of scalability on Noisy\nIntermediate Scale Quantum (NISQ) devices. In this work, we propose a novel\napproach called the Variational Quantum Linear Solver (VQLS) enhanced QSVM.\nThis is built upon our idea of utilizing the variational quantum linear solver\nto solve system of linear equations of a least squares-SVM on a NISQ device.\nThe implementation of our approach is evaluated by an extensive series of\nnumerical experiments with the Iris dataset, which consists of three distinct\niris plant species. Based on this, we explore the practicality and\neffectiveness of our algorithm by constructing a classifier capable of\nclassification in a feature space ranging from one to seven dimensions.\nFurthermore, by strategically exploiting both classical and quantum computing\nfor various subroutines of our algorithm, we effectively mitigate practical\nchallenges associated with the implementation. These include significant\nimprovement in the trainability of the variational ansatz and notable\nreductions in run-time for cost calculations. Based on the numerical\nexperiments, our approach exhibits the capability of identifying a separating\nhyperplane in an 8-dimensional feature space. Moreover, it consistently\ndemonstrated strong performance across various instances with the same dataset.",
          "link": "http://arxiv.org/abs/2309.07770",
          "publishedOn": "2023-09-16T00:40:55.543Z",
          "wordCount": 717,
          "title": "Variational Quantum Linear Solver enhanced Quantum Support Vector Machine. (arXiv:2309.07770v1 [quant-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.11721",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Donahue_K/0/1/0/all/0/1\">Kate Donahue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gollapudi_S/0/1/0/all/0/1\">Sreenivas Gollapudi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kollias_K/0/1/0/all/0/1\">Kostas Kollias</a>",
          "description": "Historically, much of machine learning research has focused on the\nperformance of the algorithm alone, but recently more attention has been\nfocused on optimizing joint human-algorithm performance. Here, we analyze a\nspecific type of human-algorithm collaboration where the algorithm has access\nto a set of $n$ items, and presents a subset of size $k$ to the human, who\nselects a final item from among those $k$. This scenario could model content\nrecommendation, route planning, or any type of labeling task. Because both the\nhuman and algorithm have imperfect, noisy information about the true ordering\nof items, the key question is: which value of $k$ maximizes the probability\nthat the best item will be ultimately selected? For $k=1$, performance is\noptimized by the algorithm acting alone, and for $k=n$ it is optimized by the\nhuman acting alone. Surprisingly, we show that for multiple of noise models, it\nis optimal to set $k \\in [2, n-1]$ - that is, there are strict benefits to\ncollaborating, even when the human and algorithm have equal accuracy\nseparately. We demonstrate this theoretically for the Mallows model and\nexperimentally for the Random Utilities models of noisy permutations. However,\nwe show this pattern is reversed when the human is anchored on the algorithm's\npresented ordering - the joint system always has strictly worse performance. We\nextend these results to the case where the human and algorithm differ in their\naccuracy levels, showing that there always exist regimes where a more accurate\nagent would strictly benefit from collaborating with a less accurate one, but\nthese regimes are asymmetric between the human and the algorithm's accuracy.",
          "link": "http://arxiv.org/abs/2308.11721",
          "publishedOn": "2023-09-16T00:40:55.527Z",
          "wordCount": 813,
          "title": "When Are Two Lists Better than One?: Benefits and Harms in Joint Decision-making. (arXiv:2308.11721v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07188",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lillelund_C/0/1/0/all/0/1\">Christian Marius Lillelund</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pannullo_F/0/1/0/all/0/1\">Fernando Pannullo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jakobsen_M/0/1/0/all/0/1\">Morten Opprud Jakobsen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pedersen_C/0/1/0/all/0/1\">Christian Fischer Pedersen</a>",
          "description": "Ball bearings find widespread use in various manufacturing and mechanical\ndomains, and methods based on machine learning have been widely adopted in the\nfield to monitor wear and spot defects before they lead to failures. Few\nstudies, however, have addressed the problem of censored data, in which failure\nis not observed. In this paper, we propose a novel approach to predict the time\nto failure in ball bearings using survival analysis. First, we analyze bearing\ndata in the frequency domain and annotate when a bearing fails by comparing the\nKullback-Leibler divergence and the standard deviation between its break-in\nfrequency bins and its break-out frequency bins. Second, we train several\nsurvival models to estimate the time to failure based on the annotated data and\ncovariates extracted from the time domain, such as skewness, kurtosis and\nentropy. The models give a probabilistic prediction of risk over time and allow\nus to compare the survival function between groups of bearings. We demonstrate\nour approach on the XJTU and PRONOSTIA datasets. On XJTU, the best result is a\n0.70 concordance-index and 0.21 integrated Brier score. On PRONOSTIA, the best\nis a 0.76 concordance-index and 0.19 integrated Brier score. Our work motivates\nfurther work on incorporating censored data in models for predictive\nmaintenance.",
          "link": "http://arxiv.org/abs/2309.07188",
          "publishedOn": "2023-09-16T00:40:55.521Z",
          "wordCount": 741,
          "title": "Predicting Survival Time of Ball Bearings in the Presence of Censoring. (arXiv:2309.07188v1 [eess.SP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.01952",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Rosca_M/0/1/0/all/0/1\">Mihaela Rosca</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1\">Yan Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Qin_C/0/1/0/all/0/1\">Chongli Qin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dherin_B/0/1/0/all/0/1\">Benoit Dherin</a>",
          "description": "The recipe behind the success of deep learning has been the combination of\nneural networks and gradient-based optimization. Understanding the behavior of\ngradient descent however, and particularly its instability, has lagged behind\nits empirical success. To add to the theoretical tools available to study\ngradient descent we propose the principal flow (PF), a continuous time flow\nthat approximates gradient descent dynamics. To our knowledge, the PF is the\nonly continuous flow that captures the divergent and oscillatory behaviors of\ngradient descent, including escaping local minima and saddle points. Through\nits dependence on the eigendecomposition of the Hessian the PF sheds light on\nthe recently observed edge of stability phenomena in deep learning. Using our\nnew understanding of instability we propose a learning rate adaptation method\nwhich enables us to control the trade-off between training stability and test\nset evaluation performance.",
          "link": "http://arxiv.org/abs/2302.01952",
          "publishedOn": "2023-09-16T00:40:55.516Z",
          "wordCount": 705,
          "title": "On a continuous time model of gradient descent dynamics and instability in deep learning. (arXiv:2302.01952v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07200",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Federici_M/0/1/0/all/0/1\">Marco Federici</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forre_P/0/1/0/all/0/1\">Patrick Forr&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomioka_R/0/1/0/all/0/1\">Ryota Tomioka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veeling_B/0/1/0/all/0/1\">Bastiaan S. Veeling</a>",
          "description": "Markov processes are widely used mathematical models for describing dynamic\nsystems in various fields. However, accurately simulating large-scale systems\nat long time scales is computationally expensive due to the short time steps\nrequired for accurate integration. In this paper, we introduce an inference\nprocess that maps complex systems into a simplified representational space and\nmodels large jumps in time. To achieve this, we propose Time-lagged Information\nBottleneck (T-IB), a principled objective rooted in information theory, which\naims to capture relevant temporal features while discarding high-frequency\ninformation to simplify the simulation task and minimize the inference error.\nOur experiments demonstrate that T-IB learns information-optimal\nrepresentations for accurately modeling the statistical properties and dynamics\nof the original process at a selected time lag, outperforming existing\ntime-lagged dimensionality reduction methods.",
          "link": "http://arxiv.org/abs/2309.07200",
          "publishedOn": "2023-09-16T00:40:55.493Z",
          "wordCount": 657,
          "title": "Latent Representation and Simulation of Markov Processes via Time-Lagged Information Bottleneck. (arXiv:2309.07200v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07907",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Braun_J/0/1/0/all/0/1\">Jona Braun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christen_S/0/1/0/all/0/1\">Sammy Christen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kocabas_M/0/1/0/all/0/1\">Muhammed Kocabas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aksan_E/0/1/0/all/0/1\">Emre Aksan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilliges_O/0/1/0/all/0/1\">Otmar Hilliges</a>",
          "description": "We propose a physics-based method for synthesizing dexterous hand-object\ninteractions in a full-body setting. While recent advancements have addressed\nspecific facets of human-object interactions, a comprehensive physics-based\napproach remains a challenge. Existing methods often focus on isolated segments\nof the interaction process and rely on data-driven techniques that may result\nin artifacts. In contrast, our proposed method embraces reinforcement learning\n(RL) and physics simulation to mitigate the limitations of data-driven\napproaches. Through a hierarchical framework, we first learn skill priors for\nboth body and hand movements in a decoupled setting. The generic skill priors\nlearn to decode a latent skill embedding into the motion of the underlying\npart. A high-level policy then controls hand-object interactions in these\npretrained latent spaces, guided by task objectives of grasping and 3D target\ntrajectory following. It is trained using a novel reward function that combines\nan adversarial style term with a task reward, encouraging natural motions while\nfulfilling the task incentives. Our method successfully accomplishes the\ncomplete interaction task, from approaching an object to grasping and\nsubsequent manipulation. We compare our approach against kinematics-based\nbaselines and show that it leads to more physically plausible motions.",
          "link": "http://arxiv.org/abs/2309.07907",
          "publishedOn": "2023-09-16T00:40:55.477Z",
          "wordCount": 695,
          "title": "Physically Plausible Full-Body Hand-Object Interaction Synthesis. (arXiv:2309.07907v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07544",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mingjie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinckney_N/0/1/0/all/0/1\">Nathaniel Pinckney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khailany_B/0/1/0/all/0/1\">Brucek Khailany</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1\">Haoxing Ren</a>",
          "description": "The increasing popularity of large language models (LLMs) has paved the way\nfor their application in diverse domains. This paper proposes a benchmarking\nframework tailored specifically for evaluating LLM performance in the context\nof Verilog code generation for hardware design and verification. We present a\ncomprehensive evaluation dataset consisting of 156 problems from the Verilog\ninstructional website HDLBits. The evaluation set consists of a diverse set of\nVerilog code generation tasks, ranging from simple combinational circuits to\ncomplex finite state machines. The Verilog code completions can be\nautomatically tested for functional correctness by comparing the transient\nsimulation outputs of the generated design with a golden solution. We also\ndemonstrate that the Verilog code generation capability of pretrained language\nmodels could be improved with supervised fine-tuning by bootstrapping with LLM\ngenerated synthetic problem-code pairs.",
          "link": "http://arxiv.org/abs/2309.07544",
          "publishedOn": "2023-09-16T00:40:55.456Z",
          "wordCount": 647,
          "title": "VerilogEval: Evaluating Large Language Models for Verilog Code Generation. (arXiv:2309.07544v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2208.00085",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bilik_S/0/1/0/all/0/1\">Simon Bilik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zemcik_T/0/1/0/all/0/1\">Tomas Zemcik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kratochvila_L/0/1/0/all/0/1\">Lukas Kratochvila</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ricanek_D/0/1/0/all/0/1\">Dominik Ricanek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richter_M/0/1/0/all/0/1\">Milos Richter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zambanini_S/0/1/0/all/0/1\">Sebastian Zambanini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horak_K/0/1/0/all/0/1\">Karel Horak</a>",
          "description": "Wide use and availability of the machine learning and computer vision\ntechniques allows development of relatively complex monitoring systems in many\ndomains. Besides the traditional industrial domain, new application appears\nalso in biology and agriculture, where we could speak about the detection of\ninfections, parasites and weeds, but also about automated monitoring and early\nwarning systems. This is also connected with the introduction of the easily\naccessible hardware and development kits such as Arduino, or RaspberryPi\nfamily. In this paper, we survey 50 existing papers focusing on the methods of\nautomated beehive monitoring methods using the computer vision techniques,\nparticularly on the pollen and Varroa mite detection together with the bee\ntraffic monitoring. Such systems could also be used for the monitoring of the\nhoneybee colonies and for the inspection of their health state, which could\nidentify potentially dangerous states before the situation is critical, or to\nbetter plan periodic bee colony inspections and therefore save significant\ncosts. Later, we also include analysis of the research trends in this\napplication field and we outline the possible direction of the new\nexplorations. Our paper is aimed also at veterinary and apidology professionals\nand experts, who might not be familiar with machine learning to introduce them\nto its possibilities, therefore each family of applications is opened by a\nbrief theoretical introduction and motivation related to its base method. We\nhope that this paper will inspire other scientists to use machine learning\ntechniques for other applications in beehive monitoring.",
          "link": "http://arxiv.org/abs/2208.00085",
          "publishedOn": "2023-09-16T00:40:55.451Z",
          "wordCount": 806,
          "title": "Machine Learning and Computer Vision Techniques in Continuous Beehive Monitoring Applications: A survey. (arXiv:2208.00085v3 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.13348",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ishikawa_K/0/1/0/all/0/1\">Kei Ishikawa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+He_N/0/1/0/all/0/1\">Niao He</a>",
          "description": "We study policy evaluation of offline contextual bandits subject to\nunobserved confounders. Sensitivity analysis methods are commonly used to\nestimate the policy value under the worst-case confounding over a given\nuncertainty set. However, existing work often resorts to some coarse relaxation\nof the uncertainty set for the sake of tractability, leading to overly\nconservative estimation of the policy value. In this paper, we propose a\ngeneral estimator that provides a sharp lower bound of the policy value. It can\nbe shown that our estimator contains the recently proposed sharp estimator by\nDorn and Guo (2022) as a special case, and our method enables a novel extension\nof the classical marginal sensitivity model using f-divergence. To construct\nour estimator, we leverage the kernel method to obtain a tractable\napproximation to the conditional moment constraints, which traditional\nnon-sharp estimators failed to take into account. In the theoretical analysis,\nwe provide a condition for the choice of the kernel which guarantees no\nspecification error that biases the lower bound estimation. Furthermore, we\nprovide consistency guarantees of policy evaluation and learning. In the\nexperiments with synthetic and real-world data, we demonstrate the\neffectiveness of the proposed method.",
          "link": "http://arxiv.org/abs/2302.13348",
          "publishedOn": "2023-09-16T00:40:55.445Z",
          "wordCount": 705,
          "title": "Kernel Conditional Moment Constraints for Confounding Robust Inference. (arXiv:2302.13348v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07207",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Smith_M/0/1/0/all/0/1\">Michael J. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fleming_L/0/1/0/all/0/1\">Luke Fleming</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geach_J/0/1/0/all/0/1\">James E. Geach</a>",
          "description": "We introduce EarthPT -- an Earth Observation (EO) pretrained transformer.\nEarthPT is a 700 million parameter decoding transformer foundation model\ntrained in an autoregressive self-supervised manner and developed specifically\nwith EO use-cases in mind. We demonstrate that EarthPT is an effective\nforecaster that can accurately predict future pixel-level surface reflectances\nacross the 400-2300 nm range well into the future. For example, forecasts of\nthe evolution of the Normalised Difference Vegetation Index (NDVI) have a\ntypical error of approximately 0.05 (over a natural range of -1 -> 1) at the\npixel level over a five month test set horizon, out-performing simple\nphase-folded models based on historical averaging. We also demonstrate that\nembeddings learnt by EarthPT hold semantically meaningful information and could\nbe exploited for downstream tasks such as highly granular, dynamic land use\nclassification. Excitingly, we note that the abundance of EO data provides us\nwith -- in theory -- quadrillions of training tokens. Therefore, if we assume\nthat EarthPT follows neural scaling laws akin to those derived for Large\nLanguage Models (LLMs), there is currently no data-imposed limit to scaling\nEarthPT and other similar `Large Observation Models.'",
          "link": "http://arxiv.org/abs/2309.07207",
          "publishedOn": "2023-09-16T00:40:55.429Z",
          "wordCount": 700,
          "title": "EarthPT: a foundation model for Earth Observation. (arXiv:2309.07207v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kicki_P/0/1/0/all/0/1\">Piotr Kicki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bidzinski_M/0/1/0/all/0/1\">Micha&#x142; Bidzi&#x144;ski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walas_K/0/1/0/all/0/1\">Krzysztof Walas</a>",
          "description": "The robotic manipulation of Deformable Linear Objects (DLOs) is a vital and\nchallenging task that is important in many practical applications. Classical\nmodel-based approaches to this problem require an accurate model to capture how\nrobot motions affect the deformation of the DLO. Nowadays, data-driven models\noffer the best tradeoff between quality and computation time. This paper\nanalyzes several learning-based 3D models of the DLO and proposes a new one\nbased on the Transformer architecture that achieves superior accuracy, even on\nthe DLOs of different lengths, thanks to the proposed scaling method. Moreover,\nwe introduce a data augmentation technique, which improves the prediction\nperformance of almost all considered DLO data-driven models. Thanks to this\ntechnique, even a simple Multilayer Perceptron (MLP) achieves close to\nstate-of-the-art performance while being significantly faster to evaluate. In\nthe experiments, we compare the performance of the learning-based 3D models of\nthe DLO on several challenging datasets quantitatively and demonstrate their\napplicability in the task of shaping a DLO.",
          "link": "http://arxiv.org/abs/2309.07609",
          "publishedOn": "2023-09-16T00:40:55.424Z",
          "wordCount": 691,
          "title": "Learning Quasi-Static 3D Models of Markerless Deformable Linear Objects for Bimanual Robotic Manipulation. (arXiv:2309.07609v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2202.03609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Junfeng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Ang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Cong Liu</a>",
          "description": "While real-world applications of reinforcement learning are becoming popular,\nthe security and robustness of RL systems are worthy of more attention and\nexploration. In particular, recent works have revealed that, in a multi-agent\nRL environment, backdoor trigger actions can be injected into a victim agent\n(a.k.a. Trojan agent), which can result in a catastrophic failure as soon as it\nsees the backdoor trigger action. To ensure the security of RL agents against\nmalicious backdoors, in this work, we propose the problem of Backdoor Detection\nin a multi-agent competitive reinforcement learning system, with the objective\nof detecting Trojan agents as well as the corresponding potential trigger\nactions, and further trying to mitigate their Trojan behavior. In order to\nsolve this problem, we propose PolicyCleanse that is based on the property that\nthe activated Trojan agents accumulated rewards degrade noticeably after\nseveral timesteps. Along with PolicyCleanse, we also design a machine\nunlearning-based approach that can effectively mitigate the detected backdoor.\nExtensive experiments demonstrate that the proposed methods can accurately\ndetect Trojan agents, and outperform existing backdoor mitigation baseline\napproaches by at least 3% in winning rate across various types of agents and\nenvironments.",
          "link": "http://arxiv.org/abs/2202.03609",
          "publishedOn": "2023-09-16T00:40:55.418Z",
          "wordCount": 756,
          "title": "PolicyCleanse: Backdoor Detection and Mitigation in Reinforcement Learning. (arXiv:2202.03609v5 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07189",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yeachan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_B/0/1/0/all/0/1\">Bonggun Shin</a>",
          "description": "Federated learning algorithms perform reasonably well on independent and\nidentically distributed (IID) data. They, on the other hand, suffer greatly\nfrom heterogeneous environments, i.e., Non-IID data. Despite the fact that many\nresearch projects have been done to address this issue, recent findings\nindicate that they are still sub-optimal when compared to training on IID data.\nIn this work, we carefully analyze the existing methods in heterogeneous\nenvironments. Interestingly, we find that regularizing the classifier's outputs\nis quite effective in preventing performance degradation on Non-IID data.\nMotivated by this, we propose Learning from Drift (LfD), a novel method for\neffectively training the model in heterogeneous settings. Our scheme\nencapsulates two key components: drift estimation and drift regularization.\nSpecifically, LfD first estimates how different the local model is from the\nglobal model (i.e., drift). The local model is then regularized such that it\ndoes not fall in the direction of the estimated drift. In the experiment, we\nevaluate each method through the lens of the five aspects of federated\nlearning, i.e., Generalization, Heterogeneity, Scalability, Forgetting, and\nEfficiency. Comprehensive evaluation results clearly support the superiority of\nLfD in federated learning with Non-IID data.",
          "link": "http://arxiv.org/abs/2309.07189",
          "publishedOn": "2023-09-16T00:40:55.406Z",
          "wordCount": 699,
          "title": "Learning From Drift: Federated Learning on Non-IID Data via Drift Regularization. (arXiv:2309.07189v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2110.12539",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Strong_M/0/1/0/all/0/1\">Marek Strong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rohnke_J/0/1/0/all/0/1\">Jonas Rohnke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonafonte_A/0/1/0/all/0/1\">Antonio Bonafonte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lajszczak_M/0/1/0/all/0/1\">Mateusz &#x141;ajszczak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wood_T/0/1/0/all/0/1\">Trevor Wood</a>",
          "description": "We present a Split Vector Quantized Variational Autoencoder (SVQ-VAE)\narchitecture using a split vector quantizer for NTTS, as an enhancement to the\nwell-known Variational Autoencoder (VAE) and Vector Quantized Variational\nAutoencoder (VQ-VAE) architectures. Compared to these previous architectures,\nour proposed model retains the benefits of using an utterance-level bottleneck,\nwhile keeping significant representation power and a discretized latent space\nsmall enough for efficient prediction from text. We train the model on\nrecordings in the expressive task-oriented dialogues domain and show that\nSVQ-VAE achieves a statistically significant improvement in naturalness over\nthe VAE and VQ-VAE models. Furthermore, we demonstrate that the SVQ-VAE latent\nacoustic space is predictable from text, reducing the gap between the standard\nconstant vector synthesis and vocoded recordings by 32%.",
          "link": "http://arxiv.org/abs/2110.12539",
          "publishedOn": "2023-09-16T00:40:55.390Z",
          "wordCount": 695,
          "title": "Discrete Acoustic Space for an Efficient Sampling in Neural Text-To-Speech. (arXiv:2110.12539v3 [cs.SD] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07133",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Sakal_C/0/1/0/all/0/1\">Collin Sakal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_T/0/1/0/all/0/1\">Tingyou Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1\">Juan Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1\">Xinyue Li</a>",
          "description": "Conducting cognitive tests is time-consuming for patients and clinicians.\nWearable device-based prediction models allow for continuous health monitoring\nunder normal living conditions and could offer an alternative to identifying\nolder adults with cognitive impairments for early interventions. In this study,\nwe first derived novel wearable-based features related to circadian rhythms,\nambient light exposure, physical activity levels, sleep, and signal processing.\nThen, we quantified the ability of wearable-based machine-learning models to\npredict poor cognition based on outcomes from the Digit Symbol Substitution\nTest (DSST), the Consortium to Establish a Registry for Alzheimers Disease\nWord-Learning subtest (CERAD-WL), and the Animal Fluency Test (AFT). We found\nthat the wearable-based models had significantly higher AUCs when predicting\nall three cognitive outcomes compared to benchmark models containing age, sex,\neducation, marital status, household income, diabetic status, depression\nsymptoms, and functional independence scores. In addition to uncovering\npreviously unidentified wearable-based features that are predictive of poor\ncognition such as the standard deviation of the midpoints of each persons most\nactive 10-hour periods and least active 5-hour periods, our paper provides\nproof-of-concept that wearable-based machine learning models can be used to\nautonomously screen older adults for possible cognitive impairments. Such\nmodels offer cost-effective alternatives to conducting initial screenings\nmanually in clinical settings.",
          "link": "http://arxiv.org/abs/2309.07133",
          "publishedOn": "2023-09-16T00:40:55.379Z",
          "wordCount": 733,
          "title": "Using wearable device-based machine learning models to autonomously identify older adults with poor cognition. (arXiv:2309.07133v1 [eess.SP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.08447",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cuadrado_N/0/1/0/all/0/1\">Nicolas Cuadrado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gutierrez_R/0/1/0/all/0/1\">Roberto Gutierrez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yongli Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takac_M/0/1/0/all/0/1\">Martin Takac</a>",
          "description": "Integrating variable renewable energy into the grid has posed challenges to\nsystem operators in achieving optimal trade-offs among energy availability,\ncost affordability, and pollution controllability. This paper proposes a\nmulti-agent reinforcement learning framework for managing energy transactions\nin microgrids. The framework addresses the challenges above: it seeks to\noptimize the usage of available resources by minimizing the carbon footprint\nwhile benefiting all stakeholders. The proposed architecture consists of three\nlayers of agents, each pursuing different objectives. The first layer,\ncomprised of prosumers and consumers, minimizes the total energy cost. The\nother two layers control the energy price to decrease the carbon impact while\nbalancing the consumption and production of both renewable and conventional\nenergy. This framework also takes into account fluctuations in energy demand\nand supply.",
          "link": "http://arxiv.org/abs/2303.08447",
          "publishedOn": "2023-09-16T00:40:55.372Z",
          "wordCount": 671,
          "title": "MAHTM: A Multi-Agent Framework for Hierarchical Transactive Microgrids. (arXiv:2303.08447v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.04688",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chen Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhou Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yunpeng Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junda He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jieke Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Kecen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1\">Arunesh Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1\">Bowen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_X/0/1/0/all/0/1\">Xinwen Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_D/0/1/0/all/0/1\">David Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianhao Wang</a>",
          "description": "A growing body of research has focused on the Reinforcement Learning (RL)\nmethods which allow the agent to learn from trial-and-error experiences\ngathered during the interaction with the environment. Recently, offline RL\nbecomes a popular RL paradigm because it saves the interactions with\nenvironments. In offline RL, data providers share large pre-collected datasets,\nand others can train high-quality agents without interacting with the\nenvironments. This paradigm has demonstrated effectiveness in critical tasks\nlike robot control, autonomous driving, etc. However, less attention is paid to\ninvestigating the security threats to the offline RL system. This paper focuses\non backdoor attacks, where some perturbations are added to the data\n(observations) such that given normal observations, the agent takes\nhigh-rewards actions, and low-reward actions on observations injected with\ntriggers. In this paper, we propose Baffle (Backdoor Attack for Offline\nReinforcement Learning), an approach that automatically implants backdoors to\nRL agents by poisoning the offline RL dataset, and evaluate how different\noffline RL algorithms react to this attack. Our experiments conducted on four\ntasks and four offline RL algorithms expose a disquieting fact: none of the\nexisting offline RL algorithms is immune to such a backdoor attack. Baffle\nmodifies $10\\%$ of the datasets for four tasks. Agents trained on the poisoned\ndatasets perform well in normal settings. However, when triggers are presented,\nthe agents' performance decreases drastically by $63.2\\%$, $53.9\\%$, $64.7\\%$,\nand $47.4\\%$ in the four tasks on average. The backdoor still persists after\nfine-tuning poisoned agents on clean datasets. We further show that the\ninserted backdoor is also hard to be detected by a popular defensive method.\nThis paper calls attention to developing more effective protection for the\nopen-source offline RL dataset.",
          "link": "http://arxiv.org/abs/2210.04688",
          "publishedOn": "2023-09-16T00:40:55.367Z",
          "wordCount": 818,
          "title": "BAFFLE: Backdoor Attack in Offline Reinforcement Learning. (arXiv:2210.04688v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2208.06028",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Michael Y. Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grant_E/0/1/0/all/0/1\">Erin Grant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1\">Thomas L. Griffiths</a>",
          "description": "Not being able to understand and predict the behavior of deep learning\nsystems makes it hard to decide what architecture and algorithm to use for a\ngiven problem. In science and engineering, modeling is a methodology used to\nunderstand complex systems whose internal processes are opaque. Modeling\nreplaces a complex system with a simpler, more interpretable surrogate. Drawing\ninspiration from this, we construct a class of surrogate models for neural\nnetworks using Gaussian processes. Rather than deriving kernels for infinite\nneural networks, we learn kernels empirically from the naturalistic behavior of\nfinite neural networks. We demonstrate our approach captures existing phenomena\nrelated to the spectral bias of neural networks, and then show that our\nsurrogate models can be used to solve practical problems such as identifying\nwhich points most influence the behavior of specific neural networks and\npredicting which architectures and algorithms will generalize well for specific\ndatasets.",
          "link": "http://arxiv.org/abs/2208.06028",
          "publishedOn": "2023-09-16T00:40:55.335Z",
          "wordCount": 676,
          "title": "Gaussian Process Surrogate Models for Neural Networks. (arXiv:2208.06028v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07887",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alecsa_C/0/1/0/all/0/1\">Cristian Daniel Alecsa</a>",
          "description": "In the present paper we introduce new optimization algorithms for the task of\ndensity ratio estimation. More precisely, we consider extending the well-known\nKMM method using the construction of a suitable loss function, in order to\nencompass more general situations involving the estimation of density ratio\nwith respect to subsets of the training data and test data, respectively. The\nassociated codes can be found at https://github.com/CDAlecsa/Generalized-KMM.",
          "link": "http://arxiv.org/abs/2309.07887",
          "publishedOn": "2023-09-16T00:40:55.324Z",
          "wordCount": 592,
          "title": "Some notes concerning a generalized KMM-type optimization method for density ratio estimation. (arXiv:2309.07887v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.04824",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Prokhorov_B/0/1/0/all/0/1\">Boris Prokhorov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koldasbayeva_D/0/1/0/all/0/1\">Diana Koldasbayeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaytsev_A/0/1/0/all/0/1\">Alexey Zaytsev</a>",
          "description": "In machine learning models, the estimation of errors is often complex due to\ndistribution bias, particularly in spatial data such as those found in\nenvironmental studies. We introduce an approach based on the ideas of\nimportance sampling to obtain an unbiased estimate of the target error. By\ntaking into account difference between desirable error and available data, our\nmethod reweights errors at each sample point and neutralizes the shift.\nImportance sampling technique and kernel density estimation were used for\nreweighteing. We validate the effectiveness of our approach using artificial\ndata that resemble real-world spatial datasets. Our findings demonstrate\nadvantages of the proposed approach for the estimation of the target error,\noffering a solution to a distribution shift problem. Overall error of\npredictions dropped from 7% to just 2% and it gets smaller for larger samples.",
          "link": "http://arxiv.org/abs/2309.04824",
          "publishedOn": "2023-09-16T00:40:55.297Z",
          "wordCount": 656,
          "title": "Correcting sampling biases via importance reweighting for spatial modeling. (arXiv:2309.04824v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.01029",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Angarano_S/0/1/0/all/0/1\">Simone Angarano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martini_M/0/1/0/all/0/1\">Mauro Martini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Navone_A/0/1/0/all/0/1\">Alessandro Navone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiaberge_M/0/1/0/all/0/1\">Marcello Chiaberge</a>",
          "description": "In recent years, precision agriculture has gradually oriented farming closer\nto automation processes to support all the activities related to field\nmanagement. Service robotics plays a predominant role in this evolution by\ndeploying autonomous agents that can navigate fields while performing tasks\nwithout human intervention, such as monitoring, spraying, and harvesting. To\nexecute these precise actions, mobile robots need a real-time perception system\nthat understands their surroundings and identifies their targets in the wild.\nGeneralizing to new crops and environmental conditions is critical for\npractical applications, as labeled samples are rarely available. In this paper,\nwe investigate the problem of crop segmentation and propose a novel approach to\nenhance domain generalization using knowledge distillation. In the proposed\nframework, we transfer knowledge from an ensemble of models individually\ntrained on source domains to a student model that can adapt to unseen target\ndomains. To evaluate the proposed method, we present a synthetic multi-domain\ndataset for crop segmentation containing plants of variegate shapes and\ncovering different terrain styles, weather conditions, and light scenarios for\nmore than 50,000 samples. We demonstrate significant improvements in\nperformance over state-of-the-art methods and superior sim-to-real\ngeneralization. Our approach provides a promising solution for domain\ngeneralization in crop segmentation and has the potential to enhance a wide\nvariety of precision agriculture applications.",
          "link": "http://arxiv.org/abs/2304.01029",
          "publishedOn": "2023-09-16T00:40:55.210Z",
          "wordCount": 735,
          "title": "Domain Generalization for Crop Segmentation with Knowledge Distillation. (arXiv:2304.01029v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07530",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gaillard_P/0/1/0/all/0/1\">Pierre Gaillard</a> (Thoth), <a href=\"http://arxiv.org/find/cs/1/au:+Gerchinovitz_S/0/1/0/all/0/1\">S&#xe9;bastien Gerchinovitz</a> (IMT), <a href=\"http://arxiv.org/find/cs/1/au:+Montbrun_E/0/1/0/all/0/1\">&#xc9;tienne de Montbrun</a> (TSE-R)",
          "description": "We study the classical problem of approximating a non-decreasing function $f:\n\\mathcal{X} \\to \\mathcal{Y}$ in $L^p(\\mu)$ norm by sequentially querying its\nvalues, for known compact real intervals $\\mathcal{X}$, $\\mathcal{Y}$ and a\nknown probability measure $\\mu$ on $\\cX$. For any function~$f$ we characterize\nthe minimum number of evaluations of $f$ that algorithms need to guarantee an\napproximation $\\hat{f}$ with an $L^p(\\mu)$ error below $\\epsilon$ after\nstopping. Unlike worst-case results that hold uniformly over all $f$, our\ncomplexity measure is dependent on each specific function $f$. To address this\nproblem, we introduce GreedyBox, a generalization of an algorithm originally\nproposed by Novak (1992) for numerical integration. We prove that GreedyBox\nachieves an optimal sample complexity for any function $f$, up to logarithmic\nfactors. Additionally, we uncover results regarding piecewise-smooth functions.\nPerhaps as expected, the $L^p(\\mu)$ error of GreedyBox decreases much faster\nfor piecewise-$C^2$ functions than predicted by the algorithm (without any\nknowledge on the smoothness of $f$). A simple modification even achieves\noptimal minimax approximation rates for such functions, which we compute\nexplicitly. In particular, our findings highlight multiple performance gaps\nbetween adaptive and non-adaptive algorithms, smooth and piecewise-smooth\nfunctions, as well as monotone or non-monotone functions. Finally, we provide\nnumerical experiments to support our theoretical results.",
          "link": "http://arxiv.org/abs/2309.07530",
          "publishedOn": "2023-09-16T00:40:55.202Z",
          "wordCount": 708,
          "title": "Adaptive approximation of monotone functions. (arXiv:2309.07530v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.05845",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Chen Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wannan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiralerspong_T/0/1/0/all/0/1\">Thomas Jiralerspong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malenfant_D/0/1/0/all/0/1\">Dane Malenfant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alsbury_Nealy_B/0/1/0/all/0/1\">Benjamin Alsbury-Nealy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richards_B/0/1/0/all/0/1\">Blake Richards</a>",
          "description": "In real life, success is often contingent upon multiple critical steps that\nare distant in time from each other and from the final reward. These critical\nsteps are challenging to identify with traditional reinforcement learning (RL)\nmethods that rely on the Bellman equation for credit assignment. Here, we\npresent a new RL algorithm that uses offline contrastive learning to hone in on\ncritical steps. This algorithm, which we call contrastive introspection\n(ConSpec), can be added to any existing RL algorithm. ConSpec learns a set of\nprototypes for the critical steps in a task by a novel contrastive loss and\ndelivers an intrinsic reward when the current state matches one of these\nprototypes. The prototypes in ConSpec provide two key benefits for credit\nassignment: (1) They enable rapid identification of all the critical steps. (2)\nThey do so in a readily interpretable manner, enabling out-of-distribution\ngeneralization when sensory features are altered. Distinct from other\ncontemporary RL approaches to credit assignment, ConSpec takes advantage of the\nfact that it is easier to retrospectively identify the small set of steps that\nsuccess is contingent upon than it is to prospectively predict reward at every\nstep taken in the environment. Altogether, ConSpec improves learning in a\ndiverse set of RL tasks, including both those with explicit, discrete critical\nsteps and those with complex, continuous critical steps.",
          "link": "http://arxiv.org/abs/2210.05845",
          "publishedOn": "2023-09-16T00:40:55.196Z",
          "wordCount": 798,
          "title": "ConSpec: honing in on critical steps for rapid learning and generalization in RL. (arXiv:2210.05845v5 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07418",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yeqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weixin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1\">Junze Yin</a>",
          "description": "Large language models (LLMs) have played a pivotal role in revolutionizing\nvarious facets of our daily existence. Solving attention regression is a\nfundamental task in optimizing LLMs. In this work, we focus on giving a\nprovable guarantee for the one-layer attention network objective function\n$L(X,Y) = \\sum_{j_0 = 1}^n \\sum_{i_0 = 1}^d ( \\langle \\langle \\exp(\n\\mathsf{A}_{j_0} x ) , {\\bf 1}_n \\rangle^{-1} \\exp( \\mathsf{A}_{j_0} x ), A_{3}\nY_{*,i_0} \\rangle - b_{j_0,i_0} )^2$. Here $\\mathsf{A} \\in \\mathbb{R}^{n^2\n\\times d^2}$ is Kronecker product between $A_1 \\in \\mathbb{R}^{n \\times d}$ and\n$A_2 \\in \\mathbb{R}^{n \\times d}$. $A_3$ is a matrix in $\\mathbb{R}^{n \\times\nd}$, $\\mathsf{A}_{j_0} \\in \\mathbb{R}^{n \\times d^2}$ is the $j_0$-th block of\n$\\mathsf{A}$. The $X, Y \\in \\mathbb{R}^{d \\times d}$ are variables we want to\nlearn. $B \\in \\mathbb{R}^{n \\times d}$ and $b_{j_0,i_0} \\in \\mathbb{R}$ is one\nentry at $j_0$-th row and $i_0$-th column of $B$, $Y_{*,i_0} \\in \\mathbb{R}^d$\nis the $i_0$-column vector of $Y$, and $x \\in \\mathbb{R}^{d^2}$ is the\nvectorization of $X$.\n\nIn a multi-layer LLM network, the matrix $B \\in \\mathbb{R}^{n \\times d}$ can\nbe viewed as the output of a layer, and $A_1= A_2 = A_3 \\in \\mathbb{R}^{n\n\\times d}$ can be viewed as the input of a layer. The matrix version of $x$ can\nbe viewed as $QK^\\top$ and $Y$ can be viewed as $V$. We provide an iterative\ngreedy algorithm to train loss function $L(X,Y)$ up $\\epsilon$ that runs in\n$\\widetilde{O}( ({\\cal T}_{\\mathrm{mat}}(n,n,d) + {\\cal\nT}_{\\mathrm{mat}}(n,d,d) + d^{2\\omega}) \\log(1/\\epsilon) )$ time. Here ${\\cal\nT}_{\\mathrm{mat}}(a,b,c)$ denotes the time of multiplying $a \\times b$ matrix\nanother $b \\times c$ matrix, and $\\omega\\approx 2.37$ denotes the exponent of\nmatrix multiplication.",
          "link": "http://arxiv.org/abs/2309.07418",
          "publishedOn": "2023-09-16T00:40:55.191Z",
          "wordCount": 839,
          "title": "A Fast Optimization View: Reformulating Single Layer Attention in LLM Based on Tensor and SVM Trick, and Solving It in Matrix Multiplication Time. (arXiv:2309.07418v1 [cs.DS])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07174",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Shouwei Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_M/0/1/0/all/0/1\">Meiyan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuepeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_W/0/1/0/all/0/1\">Wenqian Dong</a>",
          "description": "Hurricanes present major challenges in the U.S. due to their devastating\nimpacts. Mitigating these risks is important, and the insurance industry is\ncentral in this effort, using intricate statistical models for risk assessment.\nHowever, these models often neglect key temporal and spatial hurricane patterns\nand are limited by data scarcity. This study introduces a refined approach\ncombining the ARIMA model and K-MEANS to better capture hurricane trends, and\nan Autoencoder for enhanced hurricane simulations. Our experiments show that\nthis hybrid methodology effectively simulate historical hurricane behaviors\nwhile providing detailed projections of potential future trajectories and\nintensities. Moreover, by leveraging a comprehensive yet selective dataset, our\nsimulations enrich the current understanding of hurricane patterns and offer\nactionable insights for risk management strategies.",
          "link": "http://arxiv.org/abs/2309.07174",
          "publishedOn": "2023-09-16T00:40:55.145Z",
          "wordCount": 677,
          "title": "HurriCast: An Automatic Framework Using Machine Learning and Statistical Modeling for Hurricane Forecasting. (arXiv:2309.07174v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07367",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Nakazato_K/0/1/0/all/0/1\">Kenichi Nakazato</a>",
          "description": "Deep neural networks have shown many fruitful applications in this decade. A\nnetwork can get the generalized function through training with a finite\ndataset. The degree of generalization is a realization of the proximity scale\nin the data space. Specifically, the scale is not clear if the dataset is\ncomplicated. Here we consider a network for the distribution estimation of the\ndataset. We show the estimation is unstable and the instability depends on the\ndata density and training duration. We derive the kernel-balanced equation,\nwhich gives a short phenomenological description of the solution. The equation\ntells us the reason for the instability and the mechanism of the scale. The\nnetwork outputs a local average of the dataset as a prediction and the scale of\naveraging is determined along the equation. The scale gradually decreases along\ntraining and finally results in instability in our case.",
          "link": "http://arxiv.org/abs/2309.07367",
          "publishedOn": "2023-09-16T00:40:55.118Z",
          "wordCount": 643,
          "title": "The kernel-balanced equation for deep neural networks. (arXiv:2309.07367v1 [cond-mat.dis-nn])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.00305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhoubo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaohan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xi_Z/0/1/0/all/0/1\">Zekun Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>",
          "description": "Knowledge Graphs (KGs) often have two characteristics: heterogeneous graph\nstructure and text-rich entity/relation information. Text-based KG embeddings\ncan represent entities by encoding descriptions with pre-trained language\nmodels, but no open-sourced library is specifically designed for KGs with PLMs\nat present. In this paper, we present LambdaKG, a library for KGE that equips\nwith many pre-trained language models (e.g., BERT, BART, T5, GPT-3), and\nsupports various tasks (e.g., knowledge graph completion, question answering,\nrecommendation, and knowledge probing). LambdaKG is publicly open-sourced at\nhttps://github.com/zjunlp/PromptKG/tree/main/lambdaKG, with a demo video at\nthis http URL and long-term maintenance.",
          "link": "http://arxiv.org/abs/2210.00305",
          "publishedOn": "2023-09-16T00:40:55.109Z",
          "wordCount": 655,
          "title": "LambdaKG: A Library for Pre-trained Language Model-Based Knowledge Graph Embeddings. (arXiv:2210.00305v3 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2204.10372",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yue Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bichuch_M/0/1/0/all/0/1\">Maxim Bichuch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mallada_E/0/1/0/all/0/1\">Enrique Mallada</a>",
          "description": "We consider the problem of learning an inner approximation of the region of\nattraction (ROA) of an asymptotically stable equilibrium point without an\nexplicit model of the dynamics. Rather than leveraging approximate models with\nbounded uncertainty to find a (robust) invariant set contained in the ROA, we\npropose to learn sets that satisfy a more relaxed notion of containment known\nas recurrence. We define a set to be $\\tau$-recurrent (resp. $k$-recurrent) if\nevery trajectory that starts within the set, returns to it after at most $\\tau$\nseconds (resp. $k$ steps). We show that under mild assumptions a\n$\\tau$-recurrent set containing a stable equilibrium must be a subset of its\nROA. We then leverage this property to develop algorithms that compute inner\napproximations of the ROA using counter-examples of recurrence that are\nobtained by sampling finite-length trajectories. Our algorithms process samples\nsequentially, which allow them to continue being executed even after an initial\noffline training stage. We further provide an upper bound on the number of\ncounter-examples used by the algorithm, and almost sure convergence guarantees.",
          "link": "http://arxiv.org/abs/2204.10372",
          "publishedOn": "2023-09-16T00:40:55.094Z",
          "wordCount": 703,
          "title": "Model-free Learning of Regions of Attraction via Recurrent Sets. (arXiv:2204.10372v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.07200",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qingxu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">He Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_M/0/1/0/all/0/1\">Mengting Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1\">Lei Han</a>",
          "description": "Recent advances in learning reusable motion priors have demonstrated their\neffectiveness in generating naturalistic behaviors. In this paper, we propose a\nnew learning framework in this paradigm for controlling physics-based\ncharacters with significantly improved motion quality and diversity over\nexisting state-of-the-art methods. The proposed method uses reinforcement\nlearning (RL) to initially track and imitate life-like movements from\nunstructured motion clips using the discrete information bottleneck, as adopted\nin the Vector Quantized Variational AutoEncoder (VQ-VAE). This structure\ncompresses the most relevant information from the motion clips into a compact\nyet informative latent space, i.e., a discrete space over vector quantized\ncodes. By sampling codes in the space from a trained categorical prior\ndistribution, high-quality life-like behaviors can be generated, similar to the\nusage of VQ-VAE in computer vision. Although this prior distribution can be\ntrained with the supervision of the encoder's output, it follows the original\nmotion clip distribution in the dataset and could lead to imbalanced behaviors\nin our setting. To address the issue, we further propose a technique named\nprior shifting to adjust the prior distribution using curiosity-driven RL. The\noutcome distribution is demonstrated to offer sufficient behavioral diversity\nand significantly facilitates upper-level policy learning for downstream tasks.\nWe conduct comprehensive experiments using humanoid characters on two\nchallenging downstream tasks, sword-shield striking and two-player boxing game.\nOur results demonstrate that the proposed framework is capable of controlling\nthe character to perform considerably high-quality movements in terms of\nbehavioral strategies, diversity, and realism. Videos, codes, and data are\navailable at https://tencent-roboticsx.github.io/NCP/.",
          "link": "http://arxiv.org/abs/2308.07200",
          "publishedOn": "2023-09-16T00:40:55.089Z",
          "wordCount": 778,
          "title": "Neural Categorical Priors for Physics-Based Character Control. (arXiv:2308.07200v2 [cs.GR] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07610",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sajid_N/0/1/0/all/0/1\">Nafis Sajid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1\">Md Rashidul Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibrahim_M/0/1/0/all/0/1\">Muhammad Ibrahim</a>",
          "description": "Community question answering (CQA) forums are Internet-based platforms where\nusers ask questions about a topic and other expert users try to provide\nsolutions. Many CQA forums such as Quora, Stackoverflow, Yahoo!Answer,\nStackExchange exist with a lot of user-generated data. These data are leveraged\nin automated CQA ranking systems where similar questions (and answers) are\npresented in response to the query of the user. In this work, we empirically\ninvestigate a few aspects of this domain. Firstly, in addition to traditional\nfeatures like TF-IDF, BM25 etc., we introduce a BERT-based feature that\ncaptures the semantic similarity between the question and answer. Secondly,\nmost of the existing research works have focused on features extracted only\nfrom the question part; features extracted from answers have not been explored\nextensively. We combine both types of features in a linear fashion. Thirdly,\nusing our proposed concepts, we conduct an empirical investigation with\ndifferent rank-learning algorithms, some of which have not been used so far in\nCQA domain. On three standard CQA datasets, our proposed framework achieves\nstate-of-the-art performance. We also analyze importance of the features we use\nin our investigation. This work is expected to guide the practitioners to\nselect a better set of features for the CQA retrieval task.",
          "link": "http://arxiv.org/abs/2309.07610",
          "publishedOn": "2023-09-16T00:40:55.084Z",
          "wordCount": 720,
          "title": "Feature Engineering in Learning-to-Rank for Community Question Answering Task. (arXiv:2309.07610v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07173",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Swope_J/0/1/0/all/0/1\">Jason Swope</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chien_S/0/1/0/all/0/1\">Steve Chien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dunkel_E/0/1/0/all/0/1\">Emily Dunkel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosch_Lluis_X/0/1/0/all/0/1\">Xavier Bosch-Lluis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_Q/0/1/0/all/0/1\">Qing Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deal_W/0/1/0/all/0/1\">William Deal</a>",
          "description": "Smart Ice Cloud Sensing (SMICES) is a small-sat concept in which a primary\nradar intelligently targets ice storms based on information collected by a\nlookahead radiometer. Critical to the intelligent targeting is accurate\nidentification of storm/cloud types from eight bands of radiance collected by\nthe radiometer. The cloud types of interest are: clear sky, thin cirrus,\ncirrus, rainy anvil, and convection core.\n\nWe describe multi-step use of Machine Learning and Digital Twin of the\nEarth's atmosphere to derive such a classifier. First, a digital twin of\nEarth's atmosphere called a Weather Research Forecast (WRF) is used generate\nsimulated lookahead radiometer data as well as deeper \"science\" hidden\nvariables. The datasets simulate a tropical region over the Caribbean and a\nnon-tropical region over the Atlantic coast of the United States. A K-means\nclustering over the scientific hidden variables was utilized by human experts\nto generate an automatic labelling of the data - mapping each physical data\npoint to cloud types by scientists informed by mean/centroids of hidden\nvariables of the clusters. Next, classifiers were trained with the inputs of\nthe simulated radiometer data and its corresponding label. The classifiers of a\nrandom decision forest (RDF), support vector machine (SVM), Gaussian na\\\"ive\nbayes, feed forward artificial neural network (ANN), and a convolutional neural\nnetwork (CNN) were trained. Over the tropical dataset, the best performing\nclassifier was able to identify non-storm and storm clouds with over 80%\naccuracy in each class for a held-out test set. Over the non-tropical dataset,\nthe best performing classifier was able to classify non-storm clouds with over\n90% accuracy and storm clouds with over 40% accuracy. Additionally both sets of\nclassifiers were shown to be resilient to instrument noise.",
          "link": "http://arxiv.org/abs/2309.07173",
          "publishedOn": "2023-09-16T00:40:55.071Z",
          "wordCount": 818,
          "title": "Using Unsupervised and Supervised Learning and Digital Twin for Deep Convective Ice Storm Classification. (arXiv:2309.07173v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07168",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zadem_M/0/1/0/all/0/1\">Mehdi Zadem</a> (LIX, U2IS), <a href=\"http://arxiv.org/find/cs/1/au:+Mover_S/0/1/0/all/0/1\">Sergio Mover</a> (LIX), <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_S/0/1/0/all/0/1\">Sao Mai Nguyen</a> (U2IS, Flowers, IMT Atlantique - INFO, Lab-STICC_RAMBO)",
          "description": "Open-ended learning benefits immensely from the use of symbolic methods for\ngoal representation as they offer ways to structure knowledge for efficient and\ntransferable learning. However, the existing Hierarchical Reinforcement\nLearning (HRL) approaches relying on symbolic reasoning are often limited as\nthey require a manual goal representation. The challenge in autonomously\ndiscovering a symbolic goal representation is that it must preserve critical\ninformation, such as the environment dynamics. In this work, we propose a\ndevelopmental mechanism for subgoal discovery via an emergent representation\nthat abstracts (i.e., groups together) sets of environment states that have\nsimilar roles in the task. We create a HRL algorithm that gradually learns this\nrepresentation along with the policies and evaluate it on navigation tasks to\nshow the learned representation is interpretable and results in data\nefficiency.",
          "link": "http://arxiv.org/abs/2309.07168",
          "publishedOn": "2023-09-16T00:40:55.061Z",
          "wordCount": 682,
          "title": "Goal Space Abstraction in Hierarchical Reinforcement Learning via Reachability Analysis. (arXiv:2309.07168v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07178",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Guo_D/0/1/0/all/0/1\">Di Guo</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Li_S/0/1/0/all/0/1\">Sijin Li</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Liu_J/0/1/0/all/0/1\">Jun Liu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Tu_Z/0/1/0/all/0/1\">Zhangren Tu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Qiu_T/0/1/0/all/0/1\">Tianyu Qiu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Xu_J/0/1/0/all/0/1\">Jingjing Xu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Feng_L/0/1/0/all/0/1\">Liubin Feng</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lin_D/0/1/0/all/0/1\">Donghai Lin</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hong_Q/0/1/0/all/0/1\">Qing Hong</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lin_M/0/1/0/all/0/1\">Meijin Lin</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lin_Y/0/1/0/all/0/1\">Yanqin Lin</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Qu_X/0/1/0/all/0/1\">Xiaobo Qu</a>",
          "description": "Nuclear Magnetic Resonance (NMR) spectroscopy has served as a powerful\nanalytical tool for studying molecular structure and dynamics in chemistry and\nbiology. However, the processing of raw data acquired from NMR spectrometers\nand subsequent quantitative analysis involves various specialized tools, which\nnecessitates comprehensive knowledge in programming and NMR. Particularly, the\nemerging deep learning tools is hard to be widely used in NMR due to the\nsophisticated setup of computation. Thus, NMR processing is not an easy task\nfor chemist and biologists. In this work, we present CloudBrain-NMR, an\nintelligent online cloud computing platform designed for NMR data reading,\nprocessing, reconstruction, and quantitative analysis. The platform is\nconveniently accessed through a web browser, eliminating the need for any\nprogram installation on the user side. CloudBrain-NMR uses parallel computing\nwith graphics processing units and central processing units, resulting in\nsignificantly shortened computation time. Furthermore, it incorporates\nstate-of-the-art deep learning-based algorithms offering comprehensive\nfunctionalities that allow users to complete the entire processing procedure\nwithout relying on additional software. This platform has empowered NMR\napplications with advanced artificial intelligence processing. CloudBrain-NMR\nis openly accessible for free usage at https://csrc.xmu.edu.cn/CloudBrain.html",
          "link": "http://arxiv.org/abs/2309.07178",
          "publishedOn": "2023-09-16T00:40:55.033Z",
          "wordCount": 734,
          "title": "CloudBrain-NMR: An Intelligent Cloud Computing Platform for NMR Spectroscopy Processing, Reconstruction and Analysis. (arXiv:2309.07178v1 [q-bio.QM])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07708",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xia_H/0/1/0/all/0/1\">Haochong Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Shuo Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinrun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1\">Bo An</a>",
          "description": "Financial simulators play an important role in enhancing forecasting\naccuracy, managing risks, and fostering strategic financial decision-making.\nDespite the development of financial market simulation methodologies, existing\nframeworks often struggle with adapting to specialized simulation context. We\npinpoint the challenges as i) current financial datasets do not contain context\nlabels; ii) current techniques are not designed to generate financial data with\ncontext as control, which demands greater precision compared to other\nmodalities; iii) the inherent difficulties in generating context-aligned,\nhigh-fidelity data given the non-stationary, noisy nature of financial data. To\naddress these challenges, our contributions are: i) we proposed the Contextual\nMarket Dataset with market dynamics, stock ticker, and history state as\ncontext, leveraging a market dynamics modeling method that combines linear\nregression and Dynamic Time Warping clustering to extract market dynamics; ii)\nwe present Market-GAN, a novel architecture incorporating a Generative\nAdversarial Networks (GAN) for the controllable generation with context, an\nautoencoder for learning low-dimension features, and supervisors for knowledge\ntransfer; iii) we introduce a two-stage training scheme to ensure that\nMarket-GAN captures the intrinsic market distribution with multiple objectives.\nIn the pertaining stage, with the use of the autoencoder and supervisors, we\nprepare the generator with a better initialization for the adversarial training\nstage. We propose a set of holistic evaluation metrics that consider alignment,\nfidelity, data usability on downstream tasks, and market facts. We evaluate\nMarket-GAN with the Dow Jones Industrial Average data from 2000 to 2023 and\nshowcase superior performance in comparison to 4 state-of-the-art time-series\ngenerative models.",
          "link": "http://arxiv.org/abs/2309.07708",
          "publishedOn": "2023-09-16T00:40:55.028Z",
          "wordCount": 772,
          "title": "Market-GAN: Adding Control to Financial Market Data Generation with Semantic Context. (arXiv:2309.07708v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07315",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Molina_R/0/1/0/all/0/1\">Raul Molina</a>",
          "description": "Transformers have significantly advanced the field of natural language\nprocessing, but comprehending their internal mechanisms remains a challenge. In\nthis paper, we introduce a novel geometric perspective that elucidates the\ninner mechanisms of transformer operations. Our primary contribution is\nillustrating how layer normalization confines the latent features to a\nhyper-sphere, subsequently enabling attention to mold the semantic\nrepresentation of words on this surface. This geometric viewpoint seamlessly\nconnects established properties such as iterative refinement and contextual\nembeddings. We validate our insights by probing a pre-trained 124M parameter\nGPT-2 model. Our findings reveal clear query-key attention patterns in early\nlayers and build upon prior observations regarding the subject-specific nature\nof attention heads at deeper layers. Harnessing these geometric insights, we\npresent an intuitive understanding of transformers, depicting them as processes\nthat model the trajectory of word particles along the hyper-sphere.",
          "link": "http://arxiv.org/abs/2309.07315",
          "publishedOn": "2023-09-16T00:40:55.021Z",
          "wordCount": 624,
          "title": "Traveling Words: A Geometric Interpretation of Transformers. (arXiv:2309.07315v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.03893",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Manlin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jie Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1\">Yuxi Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Ming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1\">Jie Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xuefeng Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1\">Min Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_A/0/1/0/all/0/1\">Andy J. Ma</a>",
          "description": "Data is the cornerstone of deep learning. This paper reveals that the\nrecently developed Diffusion Model is a scalable data engine for object\ndetection. Existing methods for scaling up detection-oriented data often\nrequire manual collection or generative models to obtain target images,\nfollowed by data augmentation and labeling to produce training pairs, which are\ncostly, complex, or lacking diversity. To address these issues, we\npresentDiffusionEngine (DE), a data scaling-up engine that provides\nhigh-quality detection-oriented training pairs in a single stage. DE consists\nof a pre-trained diffusion model and an effective Detection-Adapter,\ncontributing to generating scalable, diverse and generalizable detection data\nin a plug-and-play manner. Detection-Adapter is learned to align the implicit\nsemantic and location knowledge in off-the-shelf diffusion models with\ndetection-aware signals to make better bounding-box predictions. Additionally,\nwe contribute two datasets, i.e., COCO-DE and VOC-DE, to scale up existing\ndetection benchmarks for facilitating follow-up research. Extensive experiments\ndemonstrate that data scaling-up via DE can achieve significant improvements in\ndiverse scenarios, such as various detection algorithms, self-supervised\npre-training, data-sparse, label-scarce, cross-domain, and semi-supervised\nlearning. For example, when using DE with a DINO-based adapter to scale up\ndata, mAP is improved by 3.1% on COCO, 7.6% on VOC, and 11.5% on Clipart.",
          "link": "http://arxiv.org/abs/2309.03893",
          "publishedOn": "2023-09-09T00:40:36.037Z",
          "wordCount": 742,
          "title": "DiffusionEngine: Diffusion Model is Scalable Data Engine for Object Detection. (arXiv:2309.03893v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2210.16193",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuxing Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1\">Yanwen Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Song Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jiachi Luo</a>",
          "description": "Researchers are solving the challenges of spatial-temporal prediction by\ncombining Federated Learning (FL) and graph models with respect to the\nconstrain of privacy and security. In order to make better use of the power of\ngraph model, some researchs also combine split learning(SL). However, there are\nstill several issues left unattended: 1) Clients might not be able to access\nthe server during inference phase; 2) The graph of clients designed manually in\nthe server model may not reveal the proper relationship between clients. This\npaper proposes a new GNN-oriented split federated learning method, named node\n{\\bfseries M}asking and {\\bfseries M}ulti-granularity {\\bfseries M}essage\npassing-based Federated Graph Model (M$^3$FGM) for the above issues. For the\nfirst issue, the server model of M$^3$FGM employs a MaskNode layer to simulate\nthe case of clients being offline. We also redesign the decoder of the client\nmodel using a dual-sub-decoders structure so that each client model can use its\nlocal data to predict independently when offline. As for the second issue, a\nnew GNN layer named Multi-Granularity Message Passing (MGMP) layer enables each\nclient node to perceive global and local information. We conducted extensive\nexperiments in two different scenarios on two real traffic datasets. Results\nshow that M$^3$FGM outperforms the baselines and variant models, achieves the\nbest results in both datasets and scenarios.",
          "link": "http://arxiv.org/abs/2210.16193",
          "publishedOn": "2023-09-09T00:40:36.018Z",
          "wordCount": 780,
          "title": "M3FGM:a node masking and multi-granularity message passing-based federated graph model for spatial-temporal data prediction. (arXiv:2210.16193v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.15116",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jingbang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1\">Xingwei Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Shuangjia Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yaodong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hao Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jie Fu</a>",
          "description": "Molecular dynamics simulations have emerged as a fundamental instrument for\nstudying biomolecules. At the same time, it is desirable to perform simulations\nof a collection of particles under various conditions in which the molecules\ncan fluctuate. In this paper, we explore and adapt the soft prompt-based\nlearning method to molecular dynamics tasks. Our model can remarkably\ngeneralize to unseen and out-of-distribution scenarios with limited training\ndata. While our work focuses on temperature as a test case, the versatility of\nour approach allows for efficient simulation through any continuous dynamic\nconditions, such as pressure and volumes. Our framework has two stages: 1)\nPre-trains with data mixing technique, augments molecular structure data and\ntemperature prompts, then applies a curriculum learning method by increasing\nthe ratio of them smoothly. 2) Meta-learning-based fine-tuning framework\nimproves sample-efficiency of fine-tuning process and gives the soft\nprompt-tuning better initialization points. Comprehensive experiments reveal\nthat our framework excels in accuracy for in-domain data and demonstrates\nstrong generalization capabilities for unseen and out-of-distribution samples.",
          "link": "http://arxiv.org/abs/2308.15116",
          "publishedOn": "2023-09-09T00:40:36.011Z",
          "wordCount": 699,
          "title": "Mixup-Augmented Meta-Learning for Sample-Efficient Fine-Tuning of Protein Simulators. (arXiv:2308.15116v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2002.01444",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Zhou_Q/0/1/0/all/0/1\">Quan Zhou</a>, <a href=\"http://arxiv.org/find/math/1/au:+Marecek_J/0/1/0/all/0/1\">Jakub Marecek</a>",
          "description": "There has been much recent progress in forecasting the next observation of a\nlinear dynamical system (LDS), which is known as the improper learning, as well\nas in the estimation of its system matrices, which is known as the proper\nlearning of LDS. We present an approach to proper learning of LDS, which in\nspite of the non-convexity of the problem, guarantees global convergence of\nnumerical solutions to a least-squares estimator. We present promising\ncomputational results.",
          "link": "http://arxiv.org/abs/2002.01444",
          "publishedOn": "2023-09-09T00:40:35.969Z",
          "wordCount": 648,
          "title": "Proper Learning of Linear Dynamical Systems as a Non-Commutative Polynomial Optimisation Problem. (arXiv:2002.01444v5 [math.OC] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.03190",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaochen Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_V/0/1/0/all/0/1\">Vincent Y. F. Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xiaokui Xiao</a>",
          "description": "Graph neural networks (GNNs) have gained an increasing amount of popularity\ndue to their superior capability in learning node embeddings for various graph\ninference tasks, but training them can raise privacy concerns. To address this,\nwe propose using link local differential privacy over decentralized nodes,\nenabling collaboration with an untrusted server to train GNNs without revealing\nthe existence of any link. Our approach spends the privacy budget separately on\nlinks and degrees of the graph for the server to better denoise the graph\ntopology using Bayesian estimation, alleviating the negative impact of LDP on\nthe accuracy of the trained GNNs. We bound the mean absolute error of the\ninferred link probabilities against the ground truth graph topology. We then\npropose two variants of our LDP mechanism complementing each other in different\nprivacy settings, one of which estimates fewer links under lower privacy\nbudgets to avoid false positive link estimates when the uncertainty is high,\nwhile the other utilizes more information and performs better given relatively\nhigher privacy budgets. Furthermore, we propose a hybrid variant that combines\nboth strategies and is able to perform better across different privacy budgets.\nExtensive experiments show that our approach outperforms existing methods in\nterms of accuracy under varying privacy budgets.",
          "link": "http://arxiv.org/abs/2309.03190",
          "publishedOn": "2023-09-09T00:40:35.963Z",
          "wordCount": 757,
          "title": "Blink: Link Local Differential Privacy in Graph Neural Networks via Bayesian Estimation. (arXiv:2309.03190v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.13280",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Lessig_C/0/1/0/all/0/1\">Christian Lessig</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Luise_I/0/1/0/all/0/1\">Ilaria Luise</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gong_B/0/1/0/all/0/1\">Bing Gong</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Langguth_M/0/1/0/all/0/1\">Michael Langguth</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Stadler_S/0/1/0/all/0/1\">Scarlet Stadler</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Schultz_M/0/1/0/all/0/1\">Martin Schultz</a>",
          "description": "The atmosphere affects humans in a multitude of ways, from loss of life due\nto adverse weather effects to long-term social and economic impacts on\nsocieties. Computer simulations of atmospheric dynamics are, therefore, of\ngreat importance for the well-being of our and future generations. Here, we\npropose AtmoRep, a novel, task-independent stochastic computer model of\natmospheric dynamics that can provide skillful results for a wide range of\napplications. AtmoRep uses large-scale representation learning from artificial\nintelligence to determine a general description of the highly complex,\nstochastic dynamics of the atmosphere from the best available estimate of the\nsystem's historical trajectory as constrained by observations. This is enabled\nby a novel self-supervised learning objective and a unique ensemble that\nsamples from the stochastic model with a variability informed by the one in the\nhistorical record. The task-independent nature of AtmoRep enables skillful\nresults for a diverse set of applications without specifically training for\nthem and we demonstrate this for nowcasting, temporal interpolation, model\ncorrection, and counterfactuals. We also show that AtmoRep can be improved with\nadditional data, for example radar observations, and that it can be extended to\ntasks such as downscaling. Our work establishes that large-scale neural\nnetworks can provide skillful, task-independent models of atmospheric dynamics.\nWith this, they provide a novel means to make the large record of atmospheric\nobservations accessible for applications and for scientific inquiry,\ncomplementing existing simulations based on first principles.",
          "link": "http://arxiv.org/abs/2308.13280",
          "publishedOn": "2023-09-09T00:40:35.956Z",
          "wordCount": 782,
          "title": "AtmoRep: A stochastic model of atmosphere dynamics using large scale representation learning. (arXiv:2308.13280v2 [physics.ao-ph] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.03487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Masuyama_N/0/1/0/all/0/1\">Naoki Masuyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nojima_Y/0/1/0/all/0/1\">Yusuke Nojima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toda_Y/0/1/0/all/0/1\">Yuichiro Toda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loo_C/0/1/0/all/0/1\">Chu Kiong Loo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishibuchi_H/0/1/0/all/0/1\">Hisao Ishibuchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kubota_N/0/1/0/all/0/1\">Naoyuki Kubota</a>",
          "description": "With the increasing importance of data privacy protection, various\nprivacy-preserving machine learning methods have been proposed. In the\nclustering domain, various algorithms with a federated learning framework\n(i.e., federated clustering) have been actively studied and showed high\nclustering performance while preserving data privacy. However, most of the base\nclusterers (i.e., clustering algorithms) used in existing federated clustering\nalgorithms need to specify the number of clusters in advance. These algorithms,\ntherefore, are unable to deal with data whose distributions are unknown or\ncontinually changing. To tackle this problem, this paper proposes a\nprivacy-preserving continual federated clustering algorithm. In the proposed\nalgorithm, an adaptive resonance theory-based clustering algorithm capable of\ncontinual learning is used as a base clusterer. Therefore, the proposed\nalgorithm inherits the ability of continual learning. Experimental results with\nsynthetic and real-world datasets show that the proposed algorithm has superior\nclustering performance to state-of-the-art federated clustering algorithms\nwhile realizing data privacy protection and continual learning ability. The\nsource code is available at \\url{https://github.com/Masuyama-lab/FCAC}.",
          "link": "http://arxiv.org/abs/2309.03487",
          "publishedOn": "2023-09-09T00:40:35.943Z",
          "wordCount": 697,
          "title": "Privacy-preserving Continual Federated Clustering via Adaptive Resonance Theory. (arXiv:2309.03487v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.08081",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mougan_C/0/1/0/all/0/1\">Carlos Mougan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Broelemann_K/0/1/0/all/0/1\">Klaus Broelemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masip_D/0/1/0/all/0/1\">David Masip</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasneci_G/0/1/0/all/0/1\">Gjergji Kasneci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thiropanis_T/0/1/0/all/0/1\">Thanassis Thiropanis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staab_S/0/1/0/all/0/1\">Steffen Staab</a>",
          "description": "As input data distributions evolve, the predictive performance of machine\nlearning models tends to deteriorate. In practice, new input data tend to come\nwithout target labels. Then, state-of-the-art techniques model input data\ndistributions or model prediction distributions and try to understand issues\nregarding the interactions between learned models and shifting distributions.\nWe suggest a novel approach that models how explanation characteristics shift\nwhen affected by distribution shifts. We find that the modeling of explanation\nshifts can be a better indicator for detecting out-of-distribution model\nbehaviour than state-of-the-art techniques. We analyze different types of\ndistribution shifts using synthetic examples and real-world data sets. We\nprovide an algorithmic method that allows us to inspect the interaction between\ndata set features and learned models and compare them to the state-of-the-art.\nWe release our methods in an open-source Python package, as well as the code\nused to reproduce our experiments.",
          "link": "http://arxiv.org/abs/2303.08081",
          "publishedOn": "2023-09-09T00:40:35.936Z",
          "wordCount": 690,
          "title": "Explanation Shift: How Did the Distribution Shift Impact the Model?. (arXiv:2303.08081v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.08272",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Juodelyte_D/0/1/0/all/0/1\">Dovile Juodelyte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jimenez_Sanchez_A/0/1/0/all/0/1\">Amelia Jim&#xe9;nez-S&#xe1;nchez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheplygina_V/0/1/0/all/0/1\">Veronika Cheplygina</a>",
          "description": "While a key component to the success of deep learning is the availability of\nmassive amounts of training data, medical image datasets are often limited in\ndiversity and size. Transfer learning has the potential to bridge the gap\nbetween related yet different domains. For medical applications, however, it\nremains unclear whether it is more beneficial to pre-train on natural or\nmedical images. We aim to shed light on this problem by comparing\ninitialization on ImageNet and RadImageNet on seven medical classification\ntasks. Our work includes a replication study, which yields results contrary to\npreviously published findings. In our experiments, ResNet50 models pre-trained\non ImageNet tend to outperform those trained on RadImageNet. To gain further\ninsights, we investigate the learned representations using Canonical\nCorrelation Analysis (CCA) and compare the predictions of the different models.\nOur results indicate that, contrary to intuition, ImageNet and RadImageNet may\nconverge to distinct intermediate representations, which appear to diverge\nfurther during fine-tuning. Despite these distinct representations, the\npredictions of the models remain similar. Our findings show that the similarity\nbetween networks before and after fine-tuning does not correlate with\nperformance gains, suggesting that the advantages of transfer learning might\nnot solely originate from the reuse of features in the early layers of a\nconvolutional neural network.",
          "link": "http://arxiv.org/abs/2302.08272",
          "publishedOn": "2023-09-09T00:40:35.740Z",
          "wordCount": null,
          "title": "Revisiting Hidden Representations in Transfer Learning for Medical Imaging. (arXiv:2302.08272v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03873",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ziemann_I/0/1/0/all/0/1\">Ingvar Ziemann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tsiamis_A/0/1/0/all/0/1\">Anastasios Tsiamis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_B/0/1/0/all/0/1\">Bruce Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jedra_Y/0/1/0/all/0/1\">Yassir Jedra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Matni_N/0/1/0/all/0/1\">Nikolai Matni</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pappas_G/0/1/0/all/0/1\">George J. Pappas</a>",
          "description": "This tutorial serves as an introduction to recently developed non-asymptotic\nmethods in the theory of -- mainly linear -- system identification. We\nemphasize tools we deem particularly useful for a range of problems in this\ndomain, such as the covering technique, the Hanson-Wright Inequality and the\nmethod of self-normalized martingales. We then employ these tools to give\nstreamlined proofs of the performance of various least-squares based estimators\nfor identifying the parameters in autoregressive models. We conclude by\nsketching out how the ideas presented herein can be extended to certain\nnonlinear identification problems.",
          "link": "http://arxiv.org/abs/2309.03873",
          "publishedOn": "2023-09-09T00:40:35.693Z",
          "wordCount": null,
          "title": "A Tutorial on the Non-Asymptotic Theory of System Identification. (arXiv:2309.03873v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03751",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lenssen_L/0/1/0/all/0/1\">Lars Lenssen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schubert_E/0/1/0/all/0/1\">Erich Schubert</a>",
          "description": "The evaluation of clustering results is difficult, highly dependent on the\nevaluated data set and the perspective of the beholder. There are many\ndifferent clustering quality measures, which try to provide a general measure\nto validate clustering results. A very popular measure is the Silhouette. We\ndiscuss the efficient medoid-based variant of the Silhouette, perform a\ntheoretical analysis of its properties, provide two fast versions for the\ndirect optimization, and discuss the use to choose the optimal number of\nclusters. We combine ideas from the original Silhouette with the well-known PAM\nalgorithm and its latest improvements FasterPAM. One of the versions guarantees\nequal results to the original variant and provides a run speedup of $O(k^2)$.\nIn experiments on real data with 30000 samples and $k$=100, we observed a\n10464$\\times$ speedup compared to the original PAMMEDSIL algorithm.\nAdditionally, we provide a variant to choose the optimal number of clusters\ndirectly.",
          "link": "http://arxiv.org/abs/2309.03751",
          "publishedOn": "2023-09-09T00:40:35.692Z",
          "wordCount": null,
          "title": "Medoid Silhouette clustering with automatic cluster number selection. (arXiv:2309.03751v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.02843",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gorgun_A/0/1/0/all/0/1\">Ada Gorgun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurbuz_Y/0/1/0/all/0/1\">Yeti Z. Gurbuz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alatan_A/0/1/0/all/0/1\">A. Aydin Alatan</a>",
          "description": "Typical technique in knowledge distillation (KD) is regularizing the learning\nof a limited capacity model (student) by pushing its responses to match a\npowerful model's (teacher). Albeit useful especially in the penultimate layer\nand beyond, its action on student's feature transform is rather implicit,\nlimiting its practice in the intermediate layers. To explicitly embed the\nteacher's knowledge in feature transform, we propose a learnable KD layer for\nthe student which improves KD with two distinct abilities: i) learning how to\nleverage the teacher's knowledge, enabling to discard nuisance information, and\nii) feeding forward the transferred knowledge deeper. Thus, the student enjoys\nthe teacher's knowledge during the inference besides training. Formally, we\nrepurpose 1x1-BN-ReLU-1x1 convolution block to assign a semantic vector to each\nlocal region according to the template (supervised by the teacher) that the\ncorresponding region of the student matches. To facilitate template learning in\nthe intermediate layers, we propose a novel form of supervision based on the\nteacher's decisions. Through rigorous experimentation, we demonstrate the\neffectiveness of our approach on 3 popular classification benchmarks. Code is\navailable at: https://github.com/adagorgun/letKD-framework",
          "link": "http://arxiv.org/abs/2309.02843",
          "publishedOn": "2023-09-09T00:40:35.651Z",
          "wordCount": null,
          "title": "Knowledge Distillation Layer that Lets the Student Decide. (arXiv:2309.02843v1 [cs.CV] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03557",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Talebi_S/0/1/0/all/0/1\">Sayed Pouria Talebi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mandic_D/0/1/0/all/0/1\">Danilo Mandic</a>",
          "description": "Multiagent systems aim to accomplish highly complex learning tasks through\ndecentralised consensus seeking dynamics and their use has garnered a great\ndeal of attention in the signal processing and computational intelligence\nsocieties. This article examines the behaviour of multiagent networked systems\nwith nonlinear filtering/learning dynamics. To this end, a general formulation\nfor the actions of an agent in multiagent networked systems is presented and\nconditions for achieving a cohesive learning behaviour is given. Importantly,\napplication of the so derived framework in distributed and federated learning\nscenarios are presented.",
          "link": "http://arxiv.org/abs/2309.03557",
          "publishedOn": "2023-09-09T00:40:35.600Z",
          "wordCount": null,
          "title": "On the dynamics of multi agent nonlinear filtering and learning. (arXiv:2309.03557v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Foosherian_M/0/1/0/all/0/1\">Mina Foosherian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purwins_H/0/1/0/all/0/1\">Hendrik Purwins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rathnayake_P/0/1/0/all/0/1\">Purna Rathnayake</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alam_T/0/1/0/all/0/1\">Touhidul Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teimao_R/0/1/0/all/0/1\">Rui Teimao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thoben_K/0/1/0/all/0/1\">Klaus-Dieter Thoben</a>",
          "description": "The latest advancements in AI and deep learning have led to a breakthrough in\nlarge language model (LLM)-based agents such as GPT-4. However, many commercial\nconversational agent development tools are pipeline-based and have limitations\nin holding a human-like conversation. This paper investigates the capabilities\nof LLMs to enhance pipeline-based conversational agents during two phases: 1)\nin the design and development phase and 2) during operations. In 1) LLMs can\naid in generating training data, extracting entities and synonyms,\nlocalization, and persona design. In 2) LLMs can assist in contextualization,\nintent classification to prevent conversational breakdown and handle\nout-of-scope questions, auto-correcting utterances, rephrasing responses,\nformulating disambiguation questions, summarization, and enabling closed\nquestion-answering capabilities. We conducted informal experiments with GPT-4\nin the private banking domain to demonstrate the scenarios above with a\npractical example. Companies may be hesitant to replace their pipeline-based\nagents with LLMs entirely due to privacy concerns and the need for deep\nintegration within their existing ecosystems. A hybrid approach in which LLMs'\nare integrated into the pipeline-based agents allows them to save time and\ncosts of building and running agents by capitalizing on the capabilities of\nLLMs while retaining the integration and privacy safeguards of their existing\nsystems.",
          "link": "http://arxiv.org/abs/2309.03748",
          "publishedOn": "2023-09-09T00:40:35.594Z",
          "wordCount": null,
          "title": "Enhancing Pipeline-Based Conversational Agents with Large Language Models. (arXiv:2309.03748v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.06566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hodson_T/0/1/0/all/0/1\">Timothy O. Hodson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Over_T/0/1/0/all/0/1\">Thomas M. Over</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_T/0/1/0/all/0/1\">Tyler J. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marshall_L/0/1/0/all/0/1\">Lucy M. Marshall</a>",
          "description": "In machine learning or scientific computing, model performance is measured\nwith an objective function. But why choose one objective over another?\nInformation theory gives one answer: To maximize the information in the model,\nselect the most likely objective function or whichever represents the error in\nthe fewest bits. To evaluate different objectives, transform them into\nlikelihood functions. As likelihoods, their relative magnitudes represent how\nmuch we should prefer one objective versus another, and the log of their\nmagnitude represents the expected uncertainty of the model.",
          "link": "http://arxiv.org/abs/2212.06566",
          "publishedOn": "2023-09-09T00:40:35.594Z",
          "wordCount": null,
          "title": "How to select an objective function using information theory. (arXiv:2212.06566v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03426",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yuancheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1\">Chenghao Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yanchao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Ruijie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiyao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jieyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Furong Huang</a>",
          "description": "Decisions made by machine learning models may have lasting impacts over time,\nmaking long-term fairness a crucial consideration. It has been shown that when\nignoring the long-term effect, naively imposing fairness criterion in static\nsettings can actually exacerbate bias over time. To explicitly address biases\nin sequential decision-making, recent works formulate long-term fairness\nnotions in Markov Decision Process (MDP) framework. They define the long-term\nbias to be the sum of static bias over each time step. However, we demonstrate\nthat naively summing up the step-wise bias can cause a false sense of fairness\nsince it fails to consider the importance difference of different time steps\nduring transition. In this work, we introduce a long-term fairness notion\ncalled Equal Long-term Benefit Rate (ELBERT), which explicitly considers\nvarying temporal importance and adapts static fairness principles to the\nsequential setting. Moreover, we show that the policy gradient of Long-term\nBenefit Rate can be analytically reduced to standard policy gradient. This\nmakes standard policy optimization methods applicable for reducing the bias,\nleading to our proposed bias mitigation method ELBERT-PO. Experiments on three\nsequential decision making environments show that ELBERT-PO significantly\nreduces bias and maintains high utility. Code is available at\nhttps://github.com/Yuancheng-Xu/ELBERT.",
          "link": "http://arxiv.org/abs/2309.03426",
          "publishedOn": "2023-09-09T00:40:35.586Z",
          "wordCount": null,
          "title": "Equal Long-term Benefit Rate: Adapting Static Fairness Notions to Sequential Decision Making. (arXiv:2309.03426v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03824",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hajimolahoseini_H/0/1/0/all/0/1\">Habib Hajimolahoseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_W/0/1/0/all/0/1\">Walid Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>",
          "description": "Low Rank Decomposition (LRD) is a model compression technique applied to the\nweight tensors of deep learning models in order to reduce the number of\ntrainable parameters and computational complexity. However, due to high number\nof new layers added to the architecture after applying LRD, it may not lead to\na high training/inference acceleration if the decomposition ranks are not small\nenough. The issue is that using small ranks increases the risk of significant\naccuracy drop after decomposition. In this paper, we propose two techniques for\naccelerating low rank decomposed models without requiring to use small ranks\nfor decomposition. These methods include rank optimization and sequential\nfreezing of decomposed layers. We perform experiments on both convolutional and\ntransformer-based models. Experiments show that these techniques can improve\nthe model throughput up to 60% during training and 37% during inference when\ncombined together while preserving the accuracy close to that of the original\nmodels",
          "link": "http://arxiv.org/abs/2309.03824",
          "publishedOn": "2023-09-09T00:40:35.583Z",
          "wordCount": null,
          "title": "Training Acceleration of Low-Rank Decomposed Networks using Sequential Freezing and Rank Quantization. (arXiv:2309.03824v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.13746",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Antal_B/0/1/0/all/0/1\">Botond B Antal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chesebro_A/0/1/0/all/0/1\">Anthony G Chesebro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strey_H/0/1/0/all/0/1\">Helmut H Strey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mujica_Parodi_L/0/1/0/all/0/1\">Lilianne R Mujica-Parodi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weistuch_C/0/1/0/all/0/1\">Corey Weistuch</a>",
          "description": "All fields of science depend on mathematical models. Occam's razor refers to\nthe principle that good models should exclude parameters beyond those minimally\nrequired to describe the systems they represent. This is because redundancy can\nlead to incorrect estimates of model parameters from data, and thus inaccurate\nor ambiguous conclusions. Here, we show how deep learning can be powerfully\nleveraged to address Occam's razor. FixFit, our new method, uses a feedforward\ndeep neural network with a bottleneck layer to characterize and predict the\nbehavior of a given model from its input parameters. FixFit has three major\nbenefits. First, it provides a metric to quantify the original model's degree\nof complexity. Second, it allows for the unique fitting of data. Third, it\nprovides an unbiased way to discriminate between experimental hypotheses that\nadd value versus those that do not. In two use cases, we demonstrate the broad\napplicability of this method across scientific domains. To validate the method\nusing a known system, we apply FixFit to recover known composite parameters for\nthe Kepler orbit model. To illustrate how the method can be applied to less\nwell-established fields, we use it to identify parameters for a multi-scale\nbrain model and reduce the search space for viable candidate mechanisms.",
          "link": "http://arxiv.org/abs/2303.13746",
          "publishedOn": "2023-09-09T00:40:35.575Z",
          "wordCount": null,
          "title": "Achieving Occam's Razor: Deep Learning for Optimal Model Reduction. (arXiv:2303.13746v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03774",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abrecht_S/0/1/0/all/0/1\">Stephanie Abrecht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirsch_A/0/1/0/all/0/1\">Alexander Hirsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raafatnia_S/0/1/0/all/0/1\">Shervin Raafatnia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woehrle_M/0/1/0/all/0/1\">Matthias Woehrle</a>",
          "description": "Recent advances in the field of deep learning and impressive performance of\ndeep neural networks (DNNs) for perception have resulted in an increased demand\nfor their use in automated driving (AD) systems. The safety of such systems is\nof utmost importance and thus requires to consider the unique properties of\nDNNs.\n\nIn order to achieve safety of AD systems with DNN-based perception components\nin a systematic and comprehensive approach, so-called safety concerns have been\nintroduced as a suitable structuring element. On the one hand, the concept of\nsafety concerns is -- by design -- well aligned to existing standards relevant\nfor safety of AD systems such as ISO 21448 (SOTIF). On the other hand, it has\nalready inspired several academic publications and upcoming standards on AI\nsafety such as ISO PAS 8800.\n\nWhile the concept of safety concerns has been previously introduced, this\npaper extends and refines it, leveraging feedback from various domain and\nsafety experts in the field. In particular, this paper introduces an additional\ncategorization for a better understanding as well as enabling cross-functional\nteams to jointly address the concerns.",
          "link": "http://arxiv.org/abs/2309.03774",
          "publishedOn": "2023-09-09T00:40:35.574Z",
          "wordCount": null,
          "title": "Deep Learning Safety Concerns in Automated Driving Perception. (arXiv:2309.03774v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03564",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1\">Hongzhi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qing Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1\">Changwei Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_W/0/1/0/all/0/1\">Wei Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_D/0/1/0/all/0/1\">Dan Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shuo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yi Jing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_H/0/1/0/all/0/1\">Huijing Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bing Xiang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianqiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_G/0/1/0/all/0/1\">Guanghui Fu</a>",
          "description": "Large language models, particularly those akin to the rapidly progressing GPT\nseries, are gaining traction for their expansive influence. While there is keen\ninterest in their applicability within medical domains such as psychology,\ntangible explorations on real-world data remain scant. Concurrently, users on\nsocial media platforms are increasingly vocalizing personal sentiments; under\nspecific thematic umbrellas, these sentiments often manifest as negative\nemotions, sometimes escalating to suicidal inclinations. Timely discernment of\nsuch cognitive distortions and suicidal risks is crucial to effectively\nintervene and potentially avert dire circumstances. Our study ventured into\nthis realm by experimenting on two pivotal tasks: suicidal risk and cognitive\ndistortion identification on Chinese social media platforms. Using supervised\nlearning as a baseline, we examined and contrasted the efficacy of large\nlanguage models via three distinct strategies: zero-shot, few-shot, and\nfine-tuning. Our findings revealed a discernible performance gap between the\nlarge language models and traditional supervised learning approaches, primarily\nattributed to the models' inability to fully grasp subtle categories. Notably,\nwhile GPT-4 outperforms its counterparts in multiple scenarios, GPT-3.5 shows\nsignificant enhancement in suicide risk classification after fine-tuning. To\nour knowledge, this investigation stands as the maiden attempt at gauging large\nlanguage models on Chinese social media tasks. This study underscores the\nforward-looking and transformative implications of using large language models\nin the field of psychology. It lays the groundwork for future applications in\npsychological research and practice.",
          "link": "http://arxiv.org/abs/2309.03564",
          "publishedOn": "2023-09-09T00:40:35.573Z",
          "wordCount": null,
          "title": "Evaluating the Efficacy of Supervised Learning vs Large Language Models for Identifying Cognitive Distortions and Suicidal Risks in Chinese Social Media. (arXiv:2309.03564v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03440",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ren_Z/0/1/0/all/0/1\">Zehua Ren</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sun_Y/0/1/0/all/0/1\">Yongheng Sun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_M/0/1/0/all/0/1\">Miaomiao Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Feng_Y/0/1/0/all/0/1\">Yuying Feng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1\">Xianjun Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jin_C/0/1/0/all/0/1\">Chao Jin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_J/0/1/0/all/0/1\">Jian Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lian_C/0/1/0/all/0/1\">Chunfeng Lian</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_F/0/1/0/all/0/1\">Fan Wang</a>",
          "description": "Accurate segmentation of punctate white matter lesions (PWMLs) are\nfundamental for the timely diagnosis and treatment of related developmental\ndisorders. Automated PWMLs segmentation from infant brain MR images is\nchallenging, considering that the lesions are typically small and low-contrast,\nand the number of lesions may dramatically change across subjects. Existing\nlearning-based methods directly apply general network architectures to this\nchallenging task, which may fail to capture detailed positional information of\nPWMLs, potentially leading to severe under-segmentations. In this paper, we\npropose to leverage the idea of counterfactual reasoning coupled with the\nauxiliary task of brain tissue segmentation to learn fine-grained positional\nand morphological representations of PWMLs for accurate localization and\nsegmentation. A simple and easy-to-implement deep-learning framework (i.e.,\nDeepPWML) is accordingly designed. It combines the lesion counterfactual map\nwith the tissue probability map to train a lightweight PWML segmentation\nnetwork, demonstrating state-of-the-art performance on a real-clinical dataset\nof infant T1w MR images. The code is available at\n\\href{https://github.com/ladderlab-xjtu/DeepPWML}{https://github.com/ladderlab-xjtu/DeepPWML}.",
          "link": "http://arxiv.org/abs/2309.03440",
          "publishedOn": "2023-09-09T00:40:35.572Z",
          "wordCount": null,
          "title": "Punctate White Matter Lesion Segmentation in Preterm Infants Powered by Counterfactually Generative Learning. (arXiv:2309.03440v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03759",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ozkan_E/0/1/0/all/0/1\">Ece Ozkan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sutter_T/0/1/0/all/0/1\">Thomas M. Sutter</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hu_Y/0/1/0/all/0/1\">Yurong Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Balzer_S/0/1/0/all/0/1\">Sebastian Balzer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vogt_J/0/1/0/all/0/1\">Julia E. Vogt</a>",
          "description": "Early detection of cardiac dysfunction through routine screening is vital for\ndiagnosing cardiovascular diseases. An important metric of cardiac function is\nthe left ventricular ejection fraction (EF), where lower EF is associated with\ncardiomyopathy. Echocardiography is a popular diagnostic tool in cardiology,\nwith ultrasound being a low-cost, real-time, and non-ionizing technology.\nHowever, human assessment of echocardiograms for calculating EF is\ntime-consuming and expertise-demanding, raising the need for an automated\napproach. In this work, we propose using the M(otion)-mode of echocardiograms\nfor estimating the EF and classifying cardiomyopathy. We generate multiple\nartificial M-mode images from a single echocardiogram and combine them using\noff-the-shelf model architectures. Additionally, we extend contrastive learning\n(CL) to cardiac imaging to learn meaningful representations from exploiting\nstructures in unlabeled data allowing the model to achieve high accuracy, even\nwith limited annotations. Our experiments show that the supervised setting\nconverges with only ten modes and is comparable to the baseline method while\nbypassing its cumbersome training process and being computationally much more\nefficient. Furthermore, CL using M-mode images is helpful for limited data\nscenarios, such as having labels for only 200 patients, which is common in\nmedical applications.",
          "link": "http://arxiv.org/abs/2309.03759",
          "publishedOn": "2023-09-09T00:40:35.565Z",
          "wordCount": null,
          "title": "M(otion)-mode Based Prediction of Ejection Fraction using Echocardiograms. (arXiv:2309.03759v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03797",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deutschmann_N/0/1/0/all/0/1\">Nicolas Deutschmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alberts_M/0/1/0/all/0/1\">Marvin Alberts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinez_M/0/1/0/all/0/1\">Mar&#xed;a Rodr&#xed;guez Mart&#xed;nez</a>",
          "description": "We introduce two new extensions to the beam search algorithm based on\nconformal predictions (CP) to produce sets of sequences with theoretical\ncoverage guarantees. The first method is very simple and proposes\ndynamically-sized subsets of beam search results but, unlike typical CP\nprocedures, has an upper bound on the achievable guarantee depending on a\npost-hoc calibration measure. Our second algorithm introduces the conformal set\nprediction procedure as part of the decoding process, producing a variable beam\nwidth which adapts to the current uncertainty. While more complex, this\nprocedure can achieve coverage guarantees selected a priori. We provide\nmarginal coverage bounds for each method, and evaluate them empirically on a\nselection of tasks drawing from natural language processing and chemistry.",
          "link": "http://arxiv.org/abs/2309.03797",
          "publishedOn": "2023-09-09T00:40:35.564Z",
          "wordCount": null,
          "title": "Conformal Autoregressive Generation: Beam Search with Coverage Guarantees. (arXiv:2309.03797v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03322",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zheyuan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rovinsky_A/0/1/0/all/0/1\">Aaron Rovinsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jianlan Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Vikash Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Abhishek Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>",
          "description": "Dexterous manipulation tasks involving contact-rich interactions pose a\nsignificant challenge for both model-based control systems and imitation\nlearning algorithms. The complexity arises from the need for multi-fingered\nrobotic hands to dynamically establish and break contacts, balance\nnon-prehensile forces, and control large degrees of freedom. Reinforcement\nlearning (RL) offers a promising approach due to its general applicability and\ncapacity to autonomously acquire optimal manipulation strategies. However, its\nreal-world application is often hindered by the necessity to generate a large\nnumber of samples, reset the environment, and obtain reward signals. In this\nwork, we introduce an efficient system for learning dexterous manipulation\nskills with RL to alleviate these challenges. The main idea of our approach is\nthe integration of recent advances in sample-efficient RL and replay buffer\nbootstrapping. This combination allows us to utilize data from different tasks\nor objects as a starting point for training new tasks, significantly improving\nlearning efficiency. Additionally, our system completes the real-world training\ncycle by incorporating learned resets via an imitation-based pickup policy as\nwell as learned reward functions, eliminating the need for manual resets and\nreward engineering. We demonstrate the benefits of reusing past data as replay\nbuffer initialization for new tasks, for instance, the fast acquisition of\nintricate manipulation skills in the real world on a four-fingered robotic\nhand. (Videos: https://sites.google.com/view/reboot-dexterous)",
          "link": "http://arxiv.org/abs/2309.03322",
          "publishedOn": "2023-09-09T00:40:35.540Z",
          "wordCount": null,
          "title": "REBOOT: Reuse Data for Bootstrapping Efficient Real-World Dexterous Manipulation. (arXiv:2309.03322v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03234",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Poche_A/0/1/0/all/0/1\">Antonin Poch&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hervier_L/0/1/0/all/0/1\">Lucas Hervier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bakkay_M/0/1/0/all/0/1\">Mohamed-Chafik Bakkay</a>",
          "description": "Explainable Artificial Intelligence (XAI) has become increasingly significant\nfor improving the interpretability and trustworthiness of machine learning\nmodels. While saliency maps have stolen the show for the last few years in the\nXAI field, their ability to reflect models' internal processes has been\nquestioned. Although less in the spotlight, example-based XAI methods have\ncontinued to improve. It encompasses methods that use examples as explanations\nfor a machine learning model's predictions. This aligns with the psychological\nmechanisms of human reasoning and makes example-based explanations natural and\nintuitive for users to understand. Indeed, humans learn and reason by forming\nmental representations of concepts based on examples.\n\nThis paper provides an overview of the state-of-the-art in natural\nexample-based XAI, describing the pros and cons of each approach. A \"natural\"\nexample simply means that it is directly drawn from the training data without\ninvolving any generative process. The exclusion of methods that require\ngenerating examples is justified by the need for plausibility which is in some\nregards required to gain a user's trust. Consequently, this paper will explore\nthe following family of methods: similar examples, counterfactual and\nsemi-factual, influential instances, prototypes, and concepts. In particular,\nit will compare their semantic definition, their cognitive impact, and added\nvalues. We hope it will encourage and facilitate future work on natural\nexample-based XAI.",
          "link": "http://arxiv.org/abs/2309.03234",
          "publishedOn": "2023-09-09T00:40:35.538Z",
          "wordCount": null,
          "title": "Natural Example-Based Explainability: a Survey. (arXiv:2309.03234v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.04521",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sheatsley_R/0/1/0/all/0/1\">Ryan Sheatsley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoak_B/0/1/0/all/0/1\">Blaine Hoak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pauley_E/0/1/0/all/0/1\">Eric Pauley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McDaniel_P/0/1/0/all/0/1\">Patrick McDaniel</a>",
          "description": "Adversarial examples, inputs designed to induce worst-case behavior in\nmachine learning models, have been extensively studied over the past decade.\nYet, our understanding of this phenomenon stems from a rather fragmented pool\nof knowledge; at present, there are a handful of attacks, each with disparate\nassumptions in threat models and incomparable definitions of optimality. In\nthis paper, we propose a systematic approach to characterize worst-case (i.e.,\noptimal) adversaries. We first introduce an extensible decomposition of attacks\nin adversarial machine learning by atomizing attack components into surfaces\nand travelers. With our decomposition, we enumerate over components to create\n576 attacks (568 of which were previously unexplored). Next, we propose the\nPareto Ensemble Attack (PEA): a theoretical attack that upper-bounds attack\nperformance. With our new attacks, we measure performance relative to the PEA\non: both robust and non-robust models, seven datasets, and three extended\nlp-based threat models incorporating compute costs, formalizing the Space of\nAdversarial Strategies. From our evaluation we find that attack performance to\nbe highly contextual: the domain, model robustness, and threat model can have a\nprofound influence on attack efficacy. Our investigation suggests that future\nstudies measuring the security of machine learning should: (1) be\ncontextualized to the domain & threat models, and (2) go beyond the handful of\nknown attacks used today.",
          "link": "http://arxiv.org/abs/2209.04521",
          "publishedOn": "2023-09-09T00:40:35.538Z",
          "wordCount": null,
          "title": "The Space of Adversarial Strategies. (arXiv:2209.04521v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03239",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ke_S/0/1/0/all/0/1\">Songyu Ke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Ting Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Li Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yanping Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1\">Qintian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junbo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yu Zheng</a>",
          "description": "Accurate acquisition of crowd flow at Points of Interest (POIs) is pivotal\nfor effective traffic management, public service, and urban planning. Despite\nthis importance, due to the limitations of urban sensing techniques, the data\nquality from most sources is inadequate for monitoring crowd flow at each POI.\nThis renders the inference of accurate crowd flow from low-quality data a\ncritical and challenging task. The complexity is heightened by three key\nfactors: 1) \\emph{The scarcity and rarity of labeled data}, 2) \\emph{The\nintricate spatio-temporal dependencies among POIs}, and 3) \\emph{The myriad\ncorrelations between precise crowd flow and GPS reports}.\n\nTo address these challenges, we recast the crowd flow inference problem as a\nself-supervised attributed graph representation learning task and introduce a\nnovel \\underline{C}ontrastive \\underline{S}elf-learning framework for\n\\underline{S}patio-\\underline{T}emporal data (\\model). Our approach initiates\nwith the construction of a spatial adjacency graph founded on the POIs and\ntheir respective distances. We then employ a contrastive learning technique to\nexploit large volumes of unlabeled spatio-temporal data. We adopt a swapped\nprediction approach to anticipate the representation of the target subgraph\nfrom similar instances. Following the pre-training phase, the model is\nfine-tuned with accurate crowd flow data. Our experiments, conducted on two\nreal-world datasets, demonstrate that the \\model pre-trained on extensive noisy\ndata consistently outperforms models trained from scratch.",
          "link": "http://arxiv.org/abs/2309.03239",
          "publishedOn": "2023-09-09T00:40:35.537Z",
          "wordCount": null,
          "title": "Spatio-Temporal Contrastive Self-Supervised Learning for POI-level Crowd Flow Inference. (arXiv:2309.03239v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03279",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Jaderberg_B/0/1/0/all/0/1\">Ben Jaderberg</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Gentile_A/0/1/0/all/0/1\">Antonio A. Gentile</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Berrada_Y/0/1/0/all/0/1\">Youssef Achari Berrada</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Shishenina_E/0/1/0/all/0/1\">Elvira Shishenina</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Elfving_V/0/1/0/all/0/1\">Vincent E. Elfving</a>",
          "description": "Parameterized quantum circuits as machine learning models are typically well\ndescribed by their representation as a partial Fourier series of the input\nfeatures, with frequencies uniquely determined by the feature map's generator\nHamiltonians. Ordinarily, these data-encoding generators are chosen in advance,\nfixing the space of functions that can be represented. In this work we consider\na generalization of quantum models to include a set of trainable parameters in\nthe generator, leading to a trainable frequency (TF) quantum model. We\nnumerically demonstrate how TF models can learn generators with desirable\nproperties for solving the task at hand, including non-regularly spaced\nfrequencies in their spectra and flexible spectral richness. Finally, we\nshowcase the real-world effectiveness of our approach, demonstrating an\nimproved accuracy in solving the Navier-Stokes equations using a TF model with\nonly a single parameter added to each encoding operation. Since TF models\nencompass conventional fixed frequency models, they may offer a sensible\ndefault choice for variational quantum machine learning.",
          "link": "http://arxiv.org/abs/2309.03279",
          "publishedOn": "2023-09-09T00:40:35.536Z",
          "wordCount": null,
          "title": "Let Quantum Neural Networks Choose Their Own Frequencies. (arXiv:2309.03279v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.04436",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Peiris_V/0/1/0/all/0/1\">Vinesha Peiris</a>, <a href=\"http://arxiv.org/find/math/1/au:+Millan_R/0/1/0/all/0/1\">Reinier Diaz Millan</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sukhorukova_N/0/1/0/all/0/1\">Nadezda Sukhorukova</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ugon_J/0/1/0/all/0/1\">Julien Ugon</a>",
          "description": "Rational and neural network based approximations are efficient tools in\nmodern approximation. These approaches are able to produce accurate\napproximations to nonsmooth and non-Lipschitz functions, including multivariate\ndomain functions. In this paper we compare the efficiency of function\napproximation using rational approximation, neural network and their\ncombinations. It was found that rational approximation is superior to neural\nnetwork based approaches with the same number of decision variables. Our\nnumerical experiments demonstrate the efficiency of rational approximation,\neven when the number of approximation parameters (that is, the dimension of the\ncorresponding optimisation problems) is small. Another important contribution\nof this paper lies in the improvement of rational approximation algorithms.\nNamely, the optimisation based algorithms for rational approximation can be\nadjusted to in such a way that the conditioning number of the constraint\nmatrices are controlled. This simple adjustment enables us to work with high\ndimension optimisation problems and improve the design of the neural network.\nThe main strength of neural networks is in their ability to handle models with\na large number of variables: complex models are decomposed in several simple\noptimisation problems. Therefore the the large number of decision variables is\nin the nature of neural networks.",
          "link": "http://arxiv.org/abs/2303.04436",
          "publishedOn": "2023-09-09T00:40:35.535Z",
          "wordCount": null,
          "title": "A comparison of rational and neural network based approximations. (arXiv:2303.04436v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03318",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tzruia_I/0/1/0/all/0/1\">Itai Tzruia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Halperin_T/0/1/0/all/0/1\">Tomer Halperin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sipper_M/0/1/0/all/0/1\">Moshe Sipper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elyasaf_A/0/1/0/all/0/1\">Achiya Elyasaf</a>",
          "description": "We present a novel approach to performing fitness approximation in genetic\nalgorithms (GAs) using machine-learning (ML) models, focusing on evolutionary\nagents in Gymnasium (game) simulators -- where fitness computation is costly.\nMaintaining a dataset of sampled individuals along with their actual fitness\nscores, we continually update throughout an evolutionary run a\nfitness-approximation ML model. We compare different methods for: 1) switching\nbetween actual and approximate fitness, 2) sampling the population, and 3)\nweighting the samples. Experimental findings demonstrate significant\nimprovement in evolutionary runtimes, with fitness scores that are either\nidentical or slightly lower than that of the fully run GA -- depending on the\nratio of approximate-to-actual-fitness computation. Our approach is generic and\ncan be easily applied to many different domains.",
          "link": "http://arxiv.org/abs/2309.03318",
          "publishedOn": "2023-09-09T00:40:35.532Z",
          "wordCount": null,
          "title": "Fitness Approximation through Machine Learning. (arXiv:2309.03318v1 [cs.NE])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.07019",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Junpeng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Ziyue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhishuai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_L/0/1/0/all/0/1\">Lei Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1\">Rui Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chen Zhang</a>",
          "description": "Modeling complex spatiotemporal dependencies in correlated traffic series is\nessential for traffic prediction. While recent works have shown improved\nprediction performance by using neural networks to extract spatiotemporal\ncorrelations, their effectiveness depends on the quality of the graph\nstructures used to represent the spatial topology of the traffic network. In\nthis work, we propose a novel approach for traffic prediction that embeds\ntime-varying dynamic Bayesian network to capture the fine spatiotemporal\ntopology of traffic data. We then use graph convolutional networks to generate\ntraffic forecasts. To enable our method to efficiently model nonlinear traffic\npropagation patterns, we develop a deep learning-based module as a\nhyper-network to generate stepwise dynamic causal graphs. Our experimental\nresults on a real traffic dataset demonstrate the superior prediction\nperformance of the proposed method. The code is available at\nhttps://github.com/MonBG/DCGCN.",
          "link": "http://arxiv.org/abs/2306.07019",
          "publishedOn": "2023-09-09T00:40:35.526Z",
          "wordCount": null,
          "title": "Dynamic Causal Graph Convolutional Network for Traffic Prediction. (arXiv:2306.07019v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.01108",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Maharana_S/0/1/0/all/0/1\">Sarthak Kumar Maharana</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Adidam_K/0/1/0/all/0/1\">Krishna Kamal Adidam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nandi_S/0/1/0/all/0/1\">Shoumik Nandi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Srivastava_A/0/1/0/all/0/1\">Ajitesh Srivastava</a>",
          "description": "$ $Acoustic-to-articulatory inversion (AAI) involves mapping from the\nacoustic space to the articulatory space. Signal-processing features like the\nMFCCs, have been widely used for the AAI task. For subjects with dysarthric\nspeech, AAI is challenging because of an imprecise and indistinct\npronunciation. In this work, we perform AAI for dysarthric speech using\nrepresentations from pre-trained self-supervised learning (SSL) models. We\ndemonstrate the impact of different pre-trained features on this challenging\nAAI task, at low-resource conditions. In addition, we also condition x-vectors\nto the extracted SSL features to train a BLSTM network. In the seen case, we\nexperiment with three AAI training schemes (subject-specific, pooled, and\nfine-tuned). The results, consistent across training schemes, reveal that\nDeCoAR, in the fine-tuned scheme, achieves a relative improvement of the\nPearson Correlation Coefficient (CC) by ${\\sim}$1.81\\% and ${\\sim}$4.56\\% for\nhealthy controls and patients, respectively, over MFCCs. In the unseen case, we\nobserve similar average trends for different SSL features. Overall, SSL\nnetworks like wav2vec, APC, and DeCoAR, which are trained with feature\nreconstruction or future timestep prediction tasks, perform well in predicting\ndysarthric articulatory trajectories.",
          "link": "http://arxiv.org/abs/2309.01108",
          "publishedOn": "2023-09-09T00:40:35.515Z",
          "wordCount": null,
          "title": "Acoustic-to-articulatory inversion for dysarthric speech: Are pre-trained self-supervised representations favorable?. (arXiv:2309.01108v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.15223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Serramazza_D/0/1/0/all/0/1\">Davide Italo Serramazza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thu Trang Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thach Le Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ifrim_G/0/1/0/all/0/1\">Georgiana Ifrim</a>",
          "description": "Multivariate time series classification is an important computational task\narising in applications where data is recorded over time and over multiple\nchannels. For example, a smartwatch can record the acceleration and orientation\nof a person's motion, and these signals are recorded as multivariate time\nseries. We can classify this data to understand and predict human movement and\nvarious properties such as fitness levels. In many applications classification\nalone is not enough, we often need to classify but also understand what the\nmodel learns (e.g., why was a prediction given, based on what information in\nthe data). The main focus of this paper is on analysing and evaluating\nexplanation methods tailored to Multivariate Time Series Classification (MTSC).\nWe focus on saliency-based explanation methods that can point out the most\nrelevant channels and time series points for the classification decision. We\nanalyse two popular and accurate multivariate time series classifiers, ROCKET\nand dResNet, as well as two popular explanation methods, SHAP and dCAM. We\nstudy these methods on 3 synthetic datasets and 2 real-world datasets and\nprovide a quantitative and qualitative analysis of the explanations provided.\nWe find that flattening the multivariate datasets by concatenating the channels\nworks as well as using multivariate classifiers directly and adaptations of\nSHAP for MTSC work quite well. Additionally, we also find that the popular\nsynthetic datasets we used are not suitable for time series analysis.",
          "link": "http://arxiv.org/abs/2308.15223",
          "publishedOn": "2023-09-09T00:40:35.506Z",
          "wordCount": null,
          "title": "Evaluating Explanation Methods for Multivariate Time Series Classification. (arXiv:2308.15223v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.09671",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zheng_H/0/1/0/all/0/1\">Huangjie Zheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+He_P/0/1/0/all/0/1\">Pengcheng He</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhou_M/0/1/0/all/0/1\">Mingyuan Zhou</a>",
          "description": "Employing a forward diffusion chain to gradually map the data to a noise\ndistribution, diffusion-based generative models learn how to generate the data\nby inferring a reverse diffusion chain. However, this approach is slow and\ncostly because it needs many forward and reverse steps. We propose a faster and\ncheaper approach that adds noise not until the data become pure random noise,\nbut until they reach a hidden noisy data distribution that we can confidently\nlearn. Then, we use fewer reverse steps to generate data by starting from this\nhidden distribution that is made similar to the noisy data. We reveal that the\nproposed model can be cast as an adversarial auto-encoder empowered by both the\ndiffusion process and a learnable implicit prior. Experimental results show\neven with a significantly smaller number of reverse diffusion steps, the\nproposed truncated diffusion probabilistic models can provide consistent\nimprovements over the non-truncated ones in terms of performance in both\nunconditional and text-guided image generations.",
          "link": "http://arxiv.org/abs/2202.09671",
          "publishedOn": "2023-09-09T00:40:35.500Z",
          "wordCount": null,
          "title": "Truncated Diffusion Probabilistic Models and Diffusion-based Adversarial Auto-Encoders. (arXiv:2202.09671v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.09183",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beckerich_M/0/1/0/all/0/1\">Mika Beckerich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plein_L/0/1/0/all/0/1\">Laura Plein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coronado_S/0/1/0/all/0/1\">Sergio Coronado</a>",
          "description": "The evolution of Generative AI and the capabilities of the newly released\nLarge Language Models (LLMs) open new opportunities in software engineering.\nHowever, they also lead to new challenges in cybersecurity. Recently,\nresearchers have shown the possibilities of using LLMs such as ChatGPT to\ngenerate malicious content that can directly be exploited or guide\ninexperienced hackers to weaponize tools and code. These studies covered\nscenarios that still require the attacker to be in the middle of the loop. In\nthis study, we leverage openly available plugins and use an LLM as proxy\nbetween the attacker and the victim. We deliver a proof-of-concept where\nChatGPT is used for the dissemination of malicious software while evading\ndetection, alongside establishing the communication to a command and control\n(C2) server to receive commands to interact with a victim's system. Finally, we\npresent the general approach as well as essential elements in order to stay\nundetected and make the attack a success. This proof-of-concept highlights\nsignificant cybersecurity issues with openly available plugins and LLMs, which\nrequire the development of security guidelines, controls, and mitigation\nstrategies.",
          "link": "http://arxiv.org/abs/2308.09183",
          "publishedOn": "2023-09-09T00:40:35.492Z",
          "wordCount": null,
          "title": "RatGPT: Turning online LLMs into Proxies for Malware Attacks. (arXiv:2308.09183v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03694",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Quansah_P/0/1/0/all/0/1\">Paapa Kwesi Quansah</a>",
          "description": "Short-term load forecasting is of paramount importance in the efficient\noperation and planning of power systems, given its inherent non-linear and\ndynamic nature. Recent strides in deep learning have shown promise in\naddressing this challenge. However, these methods often grapple with\nhyperparameter sensitivity, opaqueness in interpretability, and high\ncomputational overhead for real-time deployment. In this paper, I propose a\nnovel solution that surmounts these obstacles. Our approach harnesses the power\nof the Particle-Swarm Optimization algorithm to autonomously explore and\noptimize hyperparameters, a Multi-Head Attention mechanism to discern the\nsalient features crucial for accurate forecasting, and a streamlined framework\nfor computational efficiency. Our method undergoes rigorous evaluation using a\ngenuine electricity demand dataset. The results underscore its superiority in\nterms of accuracy, robustness, and computational efficiency. Notably, our Mean\nAbsolute Percentage Error of 1.9376 marks a significant advancement over\nexisting state-of-the-art approaches, heralding a new era in short-term load\nforecasting.",
          "link": "http://arxiv.org/abs/2309.03694",
          "publishedOn": "2023-09-09T00:40:35.481Z",
          "wordCount": null,
          "title": "Short-Term Load Forecasting Using A Particle-Swarm Optimized Multi-Head Attention-Augmented CNN-LSTM Network. (arXiv:2309.03694v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.09199",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Albright_A/0/1/0/all/0/1\">Apollo Albright</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gelfand_B/0/1/0/all/0/1\">Boris Gelfand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dixon_M/0/1/0/all/0/1\">Michael Dixon</a>",
          "description": "It is shown that a class of optical physical unclonable functions (PUFs) can\nbe learned to arbitrary precision with arbitrarily high probability, even in\nthe presence of noise, given access to polynomially many challenge-response\npairs and polynomially bounded computational power, under mild assumptions\nabout the distributions of the noise and challenge vectors. This extends the\nresults of Rh\\\"uramir et al. (2013), who showed a subset of this class of PUFs\nto be learnable in polynomial time in the absence of noise, under the\nassumption that the optics of the PUF were either linear or had negligible\nnonlinear effects. We derive polynomial bounds for the required number of\nsamples and the computational complexity of a linear regression algorithm,\nbased on size parameters of the PUF, the distributions of the challenge and\nnoise vectors, and the probability and accuracy of the regression algorithm,\nwith a similar analysis to one done by Bootle et al. (2018), who demonstrated a\nlearning attack on a poorly implemented version of the Learning With Errors\nproblem.",
          "link": "http://arxiv.org/abs/2308.09199",
          "publishedOn": "2023-09-09T00:40:35.458Z",
          "wordCount": null,
          "title": "Polynomial Bounds for Learning Noisy Optical Physical Unclonable Functions and Connections to Learning With Errors. (arXiv:2308.09199v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03169",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhargavi_D/0/1/0/all/0/1\">Divya Bhargavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravipati_V/0/1/0/all/0/1\">Vidya Sagar Ravipati</a>",
          "description": "While recommender systems have significantly benefited from implicit\nfeedback, they have often missed the nuances of multi-behavior interactions\nbetween users and items. Historically, these systems either amalgamated all\nbehaviors, such as \\textit{impression} (formerly \\textit{view}),\n\\textit{add-to-cart}, and \\textit{buy}, under a singular 'interaction' label,\nor prioritized only the target behavior, often the \\textit{buy} action,\ndiscarding valuable auxiliary signals. Although recent advancements tried\naddressing this simplification, they primarily gravitated towards optimizing\nthe target behavior alone, battling with data scarcity. Additionally, they\ntended to bypass the nuanced hierarchy intrinsic to behaviors. To bridge these\ngaps, we introduce the \\textbf{H}ierarchical \\textbf{M}ulti-behavior\n\\textbf{G}raph Attention \\textbf{N}etwork (HMGN). This pioneering framework\nleverages attention mechanisms to discern information from both inter and\nintra-behaviors while employing a multi-task Hierarchical Bayesian Personalized\nRanking (HBPR) for optimization. Recognizing the need for scalability, our\napproach integrates a specialized multi-behavior sub-graph sampling technique.\nMoreover, the adaptability of HMGN allows for the seamless inclusion of\nknowledge metadata and time-series data. Empirical results attest to our\nmodel's prowess, registering a notable performance boost of up to 64\\% in\nNDCG@100 metrics over conventional graph neural network methods.",
          "link": "http://arxiv.org/abs/2309.03169",
          "publishedOn": "2023-09-09T00:40:35.458Z",
          "wordCount": null,
          "title": "Impression-Informed Multi-Behavior Recommender System: A Hierarchical Graph Attention Approach. (arXiv:2309.03169v2 [cs.IR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.02613",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Piche_A/0/1/0/all/0/1\">Alexandre Pich&#xe9;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Thomas_V/0/1/0/all/0/1\">Valentin Thomas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pardinas_R/0/1/0/all/0/1\">Rafael Pardinas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Marino_J/0/1/0/all/0/1\">Joseph Marino</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Marconi_G/0/1/0/all/0/1\">Gian Maria Marconi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pal_C/0/1/0/all/0/1\">Christopher Pal</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Khan_M/0/1/0/all/0/1\">Mohammad Emtiyaz Khan</a>",
          "description": "Bootstrapping is behind much of the successes of deep Reinforcement Learning.\nHowever, learning the value function via bootstrapping often leads to unstable\ntraining due to fast-changing target values. Target Networks are employed to\nstabilize training by using an additional set of lagging parameters to estimate\nthe target values. Despite the popularity of Target Networks, their effect on\nthe optimization is still misunderstood. In this work, we show that they act as\nan implicit regularizer which can be beneficial in some cases, but also have\ndisadvantages such as being inflexible and can result in instabilities, even\nwhen vanilla TD(0) converges. To overcome these issues, we propose an explicit\nFunctional Regularization alternative that is flexible and a convex regularizer\nin function space and we theoretically study its convergence. We conduct an\nexperimental study across a range of environments, discount factors, and\noff-policiness data collections to investigate the effectiveness of the\nregularization induced by Target Networks and Functional Regularization in\nterms of performance, accuracy, and stability. Our findings emphasize that\nFunctional Regularization can be used as a drop-in replacement for Target\nNetworks and result in performance improvement. Furthermore, adjusting both the\nregularization weight and the network update period in Functional\nRegularization can result in further performance improvements compared to\nsolely adjusting the network update period as typically done with Target\nNetworks. Our approach also enhances the ability to networks to recover\naccurate $Q$-values.",
          "link": "http://arxiv.org/abs/2106.02613",
          "publishedOn": "2023-09-09T00:40:35.452Z",
          "wordCount": null,
          "title": "Bridging the Gap Between Target Networks and Functional Regularization. (arXiv:2106.02613v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03818",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Fang_G/0/1/0/all/0/1\">Guanhua Fang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_P/0/1/0/all/0/1\">Ping Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Samorodnitsky_G/0/1/0/all/0/1\">Gennady Samorodnitsky</a>",
          "description": "This paper considers an empirical risk minimization problem under\nheavy-tailed settings, where data does not have finite variance, but only has\n$p$-th moment with $p \\in (1,2)$. Instead of using estimation procedure based\non truncated observed data, we choose the optimizer by minimizing the risk\nvalue. Those risk values can be robustly estimated via using the remarkable\nCatoni's method (Catoni, 2012). Thanks to the structure of Catoni-type\ninfluence functions, we are able to establish excess risk upper bounds via\nusing generalized generic chaining methods. Moreover, we take computational\nissues into consideration. We especially theoretically investigate two types of\noptimization methods, robust gradient descent algorithm and empirical\nrisk-based methods. With an extensive numerical study, we find that the\noptimizer based on empirical risks via Catoni-style estimation indeed shows\nbetter performance than other baselines. It indicates that estimation directly\nbased on truncated data may lead to unsatisfactory results.",
          "link": "http://arxiv.org/abs/2309.03818",
          "publishedOn": "2023-09-09T00:40:35.451Z",
          "wordCount": null,
          "title": "Empirical Risk Minimization for Losses without Variance. (arXiv:2309.03818v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.00115",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Choe_Y/0/1/0/all/0/1\">Yo Joong Choe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>",
          "description": "Consider two forecasters, each making a single prediction for a sequence of\nevents over time. We ask a relatively basic question: how might we compare\nthese forecasters, either online or post-hoc, while avoiding unverifiable\nassumptions on how the forecasts and outcomes were generated? In this paper, we\npresent a rigorous answer to this question by designing novel sequential\ninference procedures for estimating the time-varying difference in forecast\nscores. To do this, we employ confidence sequences (CS), which are sequences of\nconfidence intervals that can be continuously monitored and are valid at\narbitrary data-dependent stopping times (\"anytime-valid\"). The widths of our\nCSs are adaptive to the underlying variance of the score differences.\nUnderlying their construction is a game-theoretic statistical framework, in\nwhich we further identify e-processes and p-processes for sequentially testing\na weak null hypothesis -- whether one forecaster outperforms another on average\n(rather than always). Our methods do not make distributional assumptions on the\nforecasts or outcomes; our main theorems apply to any bounded scores, and we\nlater provide alternative methods for unbounded scores. We empirically validate\nour approaches by comparing real-world baseball and weather forecasters.",
          "link": "http://arxiv.org/abs/2110.00115",
          "publishedOn": "2023-09-09T00:40:35.446Z",
          "wordCount": null,
          "title": "Comparing Sequential Forecasters. (arXiv:2110.00115v5 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.02556",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nagamori_T/0/1/0/all/0/1\">Teru Nagamori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shiota_S/0/1/0/all/0/1\">Sayaka Shiota</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiya_H/0/1/0/all/0/1\">Hitoshi Kiya</a>",
          "description": "In recent years, deep neural networks (DNNs) trained with transformed data\nhave been applied to various applications such as privacy-preserving learning,\naccess control, and adversarial defenses. However, the use of transformed data\ndecreases the performance of models. Accordingly, in this paper, we propose a\nnovel method for fine-tuning models with transformed images under the use of\nthe vision transformer (ViT). The proposed domain adaptation method does not\ncause the accuracy degradation of models, and it is carried out on the basis of\nthe embedding structure of ViT. In experiments, we confirmed that the proposed\nmethod prevents accuracy degradation even when using encrypted images with the\nCIFAR-10 and CIFAR-100 datasets.",
          "link": "http://arxiv.org/abs/2309.02556",
          "publishedOn": "2023-09-09T00:40:35.444Z",
          "wordCount": null,
          "title": "Domain Adaptation for Efficiently Fine-tuning Vision Transformer with Encrypted Images. (arXiv:2309.02556v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.12250",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abrahamsen_N/0/1/0/all/0/1\">Nilin Abrahamsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1\">Lin Lin</a>",
          "description": "Explicit antisymmetrization of a neural network is a potential candidate for\na universal function approximator for generic antisymmetric functions, which\nare ubiquitous in quantum physics. However, this procedure is a priori\nfactorially costly to implement, making it impractical for large numbers of\nparticles. The strategy also suffers from a sign problem. Namely, due to\nnear-exact cancellation of positive and negative contributions, the magnitude\nof the antisymmetrized function may be significantly smaller than before\nanti-symmetrization. We show that the anti-symmetric projection of a two-layer\nneural network can be evaluated efficiently, opening the door to using a\ngeneric antisymmetric layer as a building block in anti-symmetric neural\nnetwork Ansatzes. This approximation is effective when the sign problem is\ncontrolled, and we show that this property depends crucially the choice of\nactivation function under standard Xavier/He initialization methods. As a\nconsequence, using a smooth activation function requires re-scaling of the\nneural network weights compared to standard initializations.",
          "link": "http://arxiv.org/abs/2205.12250",
          "publishedOn": "2023-09-09T00:40:35.412Z",
          "wordCount": null,
          "title": "Efficient anti-symmetrization of a neural network layer by taming the sign problem. (arXiv:2205.12250v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.09241",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1\">Wan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diao_Y/0/1/0/all/0/1\">Yunfeng Diao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">He Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jianxin Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Meng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_R/0/1/0/all/0/1\">Richang Hong</a>",
          "description": "Safeguarding data from unauthorized exploitation is vital for privacy and\nsecurity, especially in recent rampant research in security breach such as\nadversarial/membership attacks. To this end, \\textit{unlearnable examples}\n(UEs) have been recently proposed as a compelling protection, by adding\nimperceptible perturbation to data so that models trained on them cannot\nclassify them accurately on original clean distribution. Unfortunately, we find\nUEs provide a false sense of security, because they cannot stop unauthorized\nusers from utilizing other unprotected data to remove the protection, by\nturning unlearnable data into learnable again. Motivated by this observation,\nwe formally define a new threat by introducing \\textit{learnable unauthorized\nexamples} (LEs) which are UEs with their protection removed. The core of this\napproach is a novel purification process that projects UEs onto the manifold of\nLEs. This is realized by a new joint-conditional diffusion model which denoises\nUEs conditioned on the pixel and perceptual similarity between UEs and LEs.\nExtensive experiments demonstrate that LE delivers state-of-the-art countering\nperformance against both supervised UEs and unsupervised UEs in various\nscenarios, which is the first generalizable countermeasure to UEs across\nsupervised learning and unsupervised learning. Our code is available at\n\\url{https://github.com/jiangw-0/LE_JCDP}.",
          "link": "http://arxiv.org/abs/2305.09241",
          "publishedOn": "2023-09-09T00:40:35.412Z",
          "wordCount": null,
          "title": "Unlearnable Examples Give a False Sense of Security: Piercing through Unexploitable Data with Learnable Examples. (arXiv:2305.09241v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.02428",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Helal_M/0/1/0/all/0/1\">Manal Helal</a>",
          "description": "The burgeoning growth of public domain data and the increasing complexity of\ndeep learning model architectures have underscored the need for more efficient\ndata representation and analysis techniques. This paper is motivated by the\nwork of Helal (2023) and aims to present a comprehensive overview of\ntensorization. This transformative approach bridges the gap between the\ninherently multidimensional nature of data and the simplified 2-dimensional\nmatrices commonly used in linear algebra-based machine learning algorithms.\nThis paper explores the steps involved in tensorization, multidimensional data\nsources, various multiway analysis methods employed, and the benefits of these\napproaches. A small example of Blind Source Separation (BSS) is presented\ncomparing 2-dimensional algorithms and a multiway algorithm in Python. Results\nindicate that multiway analysis is more expressive. Contrary to the intuition\nof the dimensionality curse, utilising multidimensional datasets in their\nnative form and applying multiway analysis methods grounded in multilinear\nalgebra reveal a profound capacity to capture intricate interrelationships\namong various dimensions while, surprisingly, reducing the number of model\nparameters and accelerating processing. A survey of the multi-away analysis\nmethods and integration with various Deep Neural Networks models is presented\nusing case studies in different domains.",
          "link": "http://arxiv.org/abs/2309.02428",
          "publishedOn": "2023-09-09T00:40:35.412Z",
          "wordCount": null,
          "title": "Enhancing Deep Learning Models through Tensorization: A Comprehensive Survey and Framework. (arXiv:2309.02428v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03891",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christen_S/0/1/0/all/0/1\">Sammy Christen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Zicong Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Luocheng Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwangbo_J/0/1/0/all/0/1\">Jemin Hwangbo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jie Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilliges_O/0/1/0/all/0/1\">Otmar Hilliges</a>",
          "description": "We present ArtiGrasp, a novel method to synthesize bi-manual hand-object\ninteractions that include grasping and articulation. This task is challenging\ndue to the diversity of the global wrist motions and the precise finger control\nthat are necessary to articulate objects. ArtiGrasp leverages reinforcement\nlearning and physics simulations to train a policy that controls the global and\nlocal hand pose. Our framework unifies grasping and articulation within a\nsingle policy guided by a single hand pose reference. Moreover, to facilitate\nthe training of the precise finger control required for articulation, we\npresent a learning curriculum with increasing difficulty. It starts with\nsingle-hand manipulation of stationary objects and continues with multi-agent\ntraining including both hands and non-stationary objects. To evaluate our\nmethod, we introduce Dynamic Object Grasping and Articulation, a task that\ninvolves bringing an object into a target articulated pose. This task requires\ngrasping, relocation, and articulation. We show our method's efficacy towards\nthis task. We further demonstrate that our method can generate motions with\nnoisy hand-object pose estimates from an off-the-shelf image-based regressor.",
          "link": "http://arxiv.org/abs/2309.03891",
          "publishedOn": "2023-09-09T00:40:35.411Z",
          "wordCount": null,
          "title": "ArtiGrasp: Physically Plausible Synthesis of Bi-Manual Dexterous Grasping and Articulation. (arXiv:2309.03891v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.13008",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ostmeier_S/0/1/0/all/0/1\">Sophie Ostmeier</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Axelrod_B/0/1/0/all/0/1\">Brian Axelrod</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bertels_J/0/1/0/all/0/1\">Jeroen Bertels</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Isensee_F/0/1/0/all/0/1\">Fabian Isensee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lansberg_M/0/1/0/all/0/1\">Maarten G.Lansberg</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Christensen_S/0/1/0/all/0/1\">Soren Christensen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Albers_G/0/1/0/all/0/1\">Gregory W. Albers</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_L/0/1/0/all/0/1\">Li-Jia Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Heit_J/0/1/0/all/0/1\">Jeremy J. Heit</a>",
          "description": "Performance metrics for medical image segmentation models are used to measure\nthe agreement between the reference annotation and the predicted segmentation.\nUsually, overlap metrics, such as the Dice, are used as a metric to evaluate\nthe performance of these models in order for results to be comparable. However,\nthere is a mismatch between the distributions of cases and difficulty level of\nsegmentation tasks in public data sets compared to clinical practice. Common\nmetrics fail to measure the impact of this mismatch, especially for clinical\ndata sets that include low signal pathologies, a difficult segmentation task,\nand uncertain, small, or empty reference annotations. This limitation may\nresult in ineffective research of machine learning practitioners in designing\nand optimizing models. Dimensions of evaluating clinical value include\nconsideration of the uncertainty of reference annotations, independence from\nreference annotation volume size, and evaluation of classification of empty\nreference annotations. We study how uncertain, small, and empty reference\nannotations influence the value of metrics for medical image segmentation on an\nin-house data set regardless of the model. We examine metrics behavior on the\npredictions of a standard deep learning framework in order to identify metrics\nwith clinical value. We compare to a public benchmark data set (BraTS 2019)\nwith a high-signal pathology and certain, larger, and no empty reference\nannotations. We may show machine learning practitioners, how uncertain, small,\nor empty reference annotations require a rethinking of the evaluation and\noptimizing procedures. The evaluation code was released to encourage further\nanalysis of this topic.\nhttps://github.com/SophieOstmeier/UncertainSmallEmpty.git",
          "link": "http://arxiv.org/abs/2209.13008",
          "publishedOn": "2023-09-09T00:40:35.411Z",
          "wordCount": null,
          "title": "USE-Evaluator: Performance Metrics for Medical Image Segmentation Models with Uncertain, Small or Empty Reference Annotations. (arXiv:2209.13008v4 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03835",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhi_W/0/1/0/all/0/1\">Weiming Zhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnson_Roberson_M/0/1/0/all/0/1\">Matthew Johnson-Roberson</a>",
          "description": "Learning for Demonstration (LfD) enables robots to acquire new skills by\nimitating expert demonstrations, allowing users to communicate their\ninstructions in an intuitive manner. Recent progress in LfD often relies on\nkinesthetic teaching or teleoperation as the medium for users to specify the\ndemonstrations. Kinesthetic teaching requires physical handling of the robot,\nwhile teleoperation demands proficiency with additional hardware. This paper\nintroduces an alternative paradigm for LfD called Diagrammatic Teaching.\nDiagrammatic Teaching aims to teach robots novel skills by prompting the user\nto sketch out demonstration trajectories on 2D images of the scene, these are\nthen synthesised as a generative model of motion trajectories in 3D task space.\nAdditionally, we present the Ray-tracing Probabilistic Trajectory Learning\n(RPTL) framework for Diagrammatic Teaching. RPTL extracts time-varying\nprobability densities from the 2D sketches, applies ray-tracing to find\ncorresponding regions in 3D Cartesian space, and fits a probabilistic model of\nmotion trajectories to these regions. New motion trajectories, which mimic\nthose sketched by the user, can then be generated from the probabilistic model.\nWe empirically validate our framework both in simulation and on real robots,\nwhich include a fixed-base manipulator and a quadruped-mounted manipulator.",
          "link": "http://arxiv.org/abs/2309.03835",
          "publishedOn": "2023-09-09T00:40:35.409Z",
          "wordCount": null,
          "title": "Learning from Demonstration via Probabilistic Diagrammatic Teaching. (arXiv:2309.03835v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.02685",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ryu_H/0/1/0/all/0/1\">Hyunwoo Ryu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jiwoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1\">Junwoo Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_H/0/1/0/all/0/1\">Hyun Seok Ahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1\">Joohwan Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Taehan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yubin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jongeun Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horowitz_R/0/1/0/all/0/1\">Roberto Horowitz</a>",
          "description": "Recent studies have verified that equivariant methods can significantly\nimprove the data efficiency, generalizability, and robustness in robot\nlearning. Meanwhile, denoising diffusion-based generative modeling has recently\ngained significant attention as a promising approach for robotic manipulation\nlearning from demonstrations with stochastic behaviors. In this paper, we\npresent Diffusion-EDFs, a novel approach that incorporates spatial\nroto-translation equivariance, i.e., SE(3)-equivariance to diffusion generative\nmodeling. By integrating SE(3)-equivariance into our model architectures, we\ndemonstrate that our proposed method exhibits remarkable data efficiency,\nrequiring only 5 to 10 task demonstrations for effective end-to-end training.\nFurthermore, our approach showcases superior generalizability compared to\nprevious diffusion-based manipulation methods.",
          "link": "http://arxiv.org/abs/2309.02685",
          "publishedOn": "2023-09-09T00:40:35.407Z",
          "wordCount": null,
          "title": "Diffusion-EDFs: Bi-equivariant Denoising Generative Modeling on SE(3) for Visual Robotic Manipulation. (arXiv:2309.02685v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03569",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rao_L/0/1/0/all/0/1\">Luping Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Chuan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Ming Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yuwen Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Lu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhe Liu</a>",
          "description": "As an essential component part of the Intelligent Transportation System\n(ITS), the Internet of Vehicles (IoV) plays a vital role in alleviating traffic\nissues. Object detection is one of the key technologies in the IoV, which has\nbeen widely used to provide traffic management services by analyzing timely and\nsensitive vehicle-related information. However, the current object detection\nmethods are mostly based on centralized deep training, that is, the sensitive\ndata obtained by edge devices need to be uploaded to the server, which raises\nprivacy concerns. To mitigate such privacy leakage, we first propose a\nfederated learning-based framework, where well-trained local models are shared\nin the central server. However, since edge devices usually have limited\ncomputing power, plus a strict requirement of low latency in IoVs, we further\npropose a sparse training process on edge devices, which can effectively\nlighten the model, and ensure its training efficiency on edge devices, thereby\nreducing communication overheads. In addition, due to the diverse computing\ncapabilities and dynamic environment, different sparsity rates are applied to\nedge devices. To further guarantee the performance, we propose, FedWeg, an\nimproved aggregation scheme based on FedAvg, which is designed by the inverse\nratio of sparsity rates. Experiments on the real-life dataset using YOLO show\nthat the proposed scheme can achieve the required object detection rate while\nsaving considerable communication costs.",
          "link": "http://arxiv.org/abs/2309.03569",
          "publishedOn": "2023-09-09T00:40:35.406Z",
          "wordCount": null,
          "title": "Sparse Federated Training of Object Detection in the Internet of Vehicles. (arXiv:2309.03569v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03876",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haller_P/0/1/0/all/0/1\">Patrick Haller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aynetdinov_A/0/1/0/all/0/1\">Ansar Aynetdinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akbik_A/0/1/0/all/0/1\">Alan Akbik</a>",
          "description": "Instruction-tuned Large Language Models (LLMs) have recently showcased\nremarkable ability to generate fitting responses to natural language\ninstructions. However, an open research question concerns the inherent biases\nof trained models and their responses. For instance, if the data used to tune\nan LLM is dominantly written by persons with a specific political bias, we\nmight expect generated answers to share this bias. Current research work seeks\nto de-bias such models, or suppress potentially biased answers. With this\ndemonstration, we take a different view on biases in instruction-tuning: Rather\nthan aiming to suppress them, we aim to make them explicit and transparent. To\nthis end, we present OpinionGPT, a web demo in which users can ask questions\nand select all biases they wish to investigate. The demo will answer this\nquestion using a model fine-tuned on text representing each of the selected\nbiases, allowing side-by-side comparison. To train the underlying model, we\nidentified 11 different biases (political, geographic, gender, age) and derived\nan instruction-tuning corpus in which each answer was written by members of one\nof these demographics. This paper presents OpinionGPT, illustrates how we\ntrained the bias-aware model and showcases the web application (available at\nhttps://opiniongpt.informatik.hu-berlin.de).",
          "link": "http://arxiv.org/abs/2309.03876",
          "publishedOn": "2023-09-09T00:40:35.398Z",
          "wordCount": null,
          "title": "OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs. (arXiv:2309.03876v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03905",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiaming Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Renrui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1\">Wenqi Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1\">Peng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Peng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1\">Han Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaipeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chris Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_S/0/1/0/all/0/1\">Song Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Ziyu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xudong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Shuai Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Yafei Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaoxin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1\">Xiangyu Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongsheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>",
          "description": "We present ImageBind-LLM, a multi-modality instruction tuning method of large\nlanguage models (LLMs) via ImageBind. Existing works mainly focus on language\nand image instruction tuning, different from which, our ImageBind-LLM can\nrespond to multi-modality conditions, including audio, 3D point clouds, video,\nand their embedding-space arithmetic by only image-text alignment training.\nDuring training, we adopt a learnable bind network to align the embedding space\nbetween LLaMA and ImageBind's image encoder. Then, the image features\ntransformed by the bind network are added to word tokens of all layers in\nLLaMA, which progressively injects visual instructions via an attention-free\nand zero-initialized gating mechanism. Aided by the joint embedding of\nImageBind, the simple image-text training enables our model to exhibit superior\nmulti-modality instruction-following capabilities. During inference, the\nmulti-modality inputs are fed into the corresponding ImageBind encoders, and\nprocessed by a proposed visual cache model for further cross-modal embedding\nenhancement. The training-free cache model retrieves from three million image\nfeatures extracted by ImageBind, which effectively mitigates the\ntraining-inference modality discrepancy. Notably, with our approach,\nImageBind-LLM can respond to instructions of diverse modalities and demonstrate\nsignificant language generation quality. Code is released at\nhttps://github.com/OpenGVLab/LLaMA-Adapter.",
          "link": "http://arxiv.org/abs/2309.03905",
          "publishedOn": "2023-09-09T00:40:35.398Z",
          "wordCount": null,
          "title": "ImageBind-LLM: Multi-modality Instruction Tuning. (arXiv:2309.03905v1 [cs.MM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.06104",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wenjie Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yuning Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Svetozarevic_B/0/1/0/all/0/1\">Bratislav Svetozarevic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_C/0/1/0/all/0/1\">Colin N. Jones</a>",
          "description": "This paper studies the problem of online performance optimization of\nconstrained closed-loop control systems, where both the objective and the\nconstraints are unknown black-box functions affected by exogenous time-varying\ncontextual disturbances. A primal-dual contextual Bayesian optimization\nalgorithm is proposed that achieves sublinear cumulative regret with respect to\nthe dynamic optimal solution under certain regularity conditions. Furthermore,\nthe algorithm achieves zero time-average constraint violation, ensuring that\nthe average value of the constraint function satisfies the desired constraint.\nThe method is applied to both sampled instances from Gaussian processes and a\ncontinuous stirred tank reactor parameter tuning problem; simulation results\nshow that the method simultaneously provides close-to-optimal performance and\nmaintains constraint feasibility on average. This contrasts current\nstate-of-the-art methods, which either suffer from large cumulative regret or\nsevere constraint violations for the case studies presented.",
          "link": "http://arxiv.org/abs/2304.06104",
          "publishedOn": "2023-09-09T00:40:35.396Z",
          "wordCount": null,
          "title": "Primal-Dual Contextual Bayesian Optimization for Control System Online Optimization with Time-Average Constraints. (arXiv:2304.06104v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2111.06781",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kara_A/0/1/0/all/0/1\">Ali Devran Kara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saldi_N/0/1/0/all/0/1\">Naci Saldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuksel_S/0/1/0/all/0/1\">Serdar Y&#xfc;ksel</a>",
          "description": "Reinforcement learning algorithms often require finiteness of state and\naction spaces in Markov decision processes (MDPs) (also called controlled\nMarkov chains) and various efforts have been made in the literature towards the\napplicability of such algorithms for continuous state and action spaces. In\nthis paper, we show that under very mild regularity conditions (in particular,\ninvolving only weak continuity of the transition kernel of an MDP), Q-learning\nfor standard Borel MDPs via quantization of states and actions (called\nQuantized Q-Learning) converges to a limit, and furthermore this limit\nsatisfies an optimality equation which leads to near optimality with either\nexplicit performance bounds or which are guaranteed to be asymptotically\noptimal. Our approach builds on (i) viewing quantization as a measurement\nkernel and thus a quantized MDP as a partially observed Markov decision process\n(POMDP), (ii) utilizing near optimality and convergence results of Q-learning\nfor POMDPs, and (iii) finally, near-optimality of finite state model\napproximations for MDPs with weakly continuous kernels which we show to\ncorrespond to the fixed point of the constructed POMDP. Thus, our paper\npresents a very general convergence and approximation result for the\napplicability of Q-learning for continuous MDPs.",
          "link": "http://arxiv.org/abs/2111.06781",
          "publishedOn": "2023-09-09T00:40:35.390Z",
          "wordCount": null,
          "title": "Q-Learning for MDPs with General Spaces: Convergence and Near Optimality via Quantization under Weak Continuity. (arXiv:2111.06781v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03241",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Ming Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_Q/0/1/0/all/0/1\">Qingsong Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhihuan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zehai He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yuyi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1\">Jinfeng Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>",
          "description": "Previous studies have typically assumed that large language models are unable\nto accurately perform arithmetic operations, particularly multiplication of >8\ndigits, and operations involving decimals and fractions, without the use of\ncalculator tools. This paper aims to challenge this misconception. With\nsufficient training data, a 2 billion-parameter language model can accurately\nperform multi-digit arithmetic operations with almost 100% accuracy without\ndata leakage, significantly surpassing GPT-4 (whose multi-digit multiplication\naccuracy is only 4.3%). We also demonstrate that our MathGLM, fine-tuned from\nGLM-10B on a dataset with additional multi-step arithmetic operations and math\nproblems described in text, achieves similar performance to GPT-4 on a\n5,000-samples Chinese math problem test set.",
          "link": "http://arxiv.org/abs/2309.03241",
          "publishedOn": "2023-09-09T00:40:35.387Z",
          "wordCount": null,
          "title": "GPT Can Solve Mathematical Problems Without a Calculator. (arXiv:2309.03241v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03581",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Giovanelli_J/0/1/0/all/0/1\">Joseph Giovanelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tornede_A/0/1/0/all/0/1\">Alexander Tornede</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tornede_T/0/1/0/all/0/1\">Tanja Tornede</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindauer_M/0/1/0/all/0/1\">Marius Lindauer</a>",
          "description": "Hyperparameter optimization (HPO) is important to leverage the full potential\nof machine learning (ML). In practice, users are often interested in\nmulti-objective (MO) problems, i.e., optimizing potentially conflicting\nobjectives, like accuracy and energy consumption. To tackle this, the vast\nmajority of MO-ML algorithms return a Pareto front of non-dominated machine\nlearning models to the user. Optimizing the hyperparameters of such algorithms\nis non-trivial as evaluating a hyperparameter configuration entails evaluating\nthe quality of the resulting Pareto front. In literature, there are known\nindicators that assess the quality of a Pareto front (e.g., hypervolume, R2) by\nquantifying different properties (e.g., volume, proximity to a reference\npoint). However, choosing the indicator that leads to the desired Pareto front\nmight be a hard task for a user. In this paper, we propose a human-centered\ninteractive HPO approach tailored towards multi-objective ML leveraging\npreference learning to extract desiderata from users that guide the\noptimization. Instead of relying on the user guessing the most suitable\nindicator for their needs, our approach automatically learns an appropriate\nindicator. Concretely, we leverage pairwise comparisons of distinct Pareto\nfronts to learn such an appropriate quality indicator. Then, we optimize the\nhyperparameters of the underlying MO-ML algorithm towards this learned\nindicator using a state-of-the-art HPO approach. In an experimental study\ntargeting the environmental impact of ML, we demonstrate that our approach\nleads to substantially better Pareto fronts compared to optimizing based on a\nwrong indicator pre-selected by the user, and performs comparable in the case\nof an advanced user knowing which indicator to pick.",
          "link": "http://arxiv.org/abs/2309.03581",
          "publishedOn": "2023-09-09T00:40:35.387Z",
          "wordCount": null,
          "title": "Interactive Hyperparameter Optimization in Multi-Objective Problems via Preference Learning. (arXiv:2309.03581v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Yaning Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chunhui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jundong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chuxu Zhang</a>",
          "description": "The Lipschitz bound, a technique from robust statistics, can limit the\nmaximum changes in the output concerning the input, taking into account\nassociated irrelevant biased factors. It is an efficient and provable method\nfor examining the output stability of machine learning models without incurring\nadditional computation costs. Recently, Graph Neural Networks (GNNs), which\noperate on non-Euclidean data, have gained significant attention. However, no\nprevious research has investigated the GNN Lipschitz bounds to shed light on\nstabilizing model outputs, especially when working on non-Euclidean data with\ninherent biases. Given the inherent biases in common graph data used for GNN\ntraining, it poses a serious challenge to constraining the GNN output\nperturbations induced by input biases, thereby safeguarding fairness during\ntraining. Recently, despite the Lipschitz constant's use in controlling the\nstability of Euclideanneural networks, the calculation of the precise Lipschitz\nconstant remains elusive for non-Euclidean neural networks like GNNs,\nespecially within fairness contexts. To narrow this gap, we begin with the\ngeneral GNNs operating on an attributed graph, and formulate a Lipschitz bound\nto limit the changes in the output regarding biases associated with the input.\nAdditionally, we theoretically analyze how the Lipschitz constant of a GNN\nmodel could constrain the output perturbations induced by biases learned from\ndata for fairness training. We experimentally validate the Lipschitz bound's\neffectiveness in limiting biases of the model output. Finally, from a training\ndynamics perspective, we demonstrate why the theoretical Lipschitz bound can\neffectively guide the GNN training to better trade-off between accuracy and\nfairness.",
          "link": "http://arxiv.org/abs/2309.03648",
          "publishedOn": "2023-09-09T00:40:35.387Z",
          "wordCount": null,
          "title": "Characterizing Lipschitz Stability of GNN for Fairness. (arXiv:2309.03648v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03386",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xurui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuhong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1\">Yangyang Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Changlong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaozhong Liu</a>",
          "description": "Positive-Unlabeled (PU) Learning is a challenge presented by binary\nclassification problems where there is an abundance of unlabeled data along\nwith a small number of positive data instances, which can be used to address\nchronic disease screening problem. State-of-the-art PU learning methods have\nresulted in the development of various risk estimators, yet they neglect the\ndifferences among distinct populations. To address this issue, we present a\nnovel Positive-Unlabeled Learning Tree (PUtree) algorithm. PUtree is designed\nto take into account communities such as different age or income brackets, in\ntasks of chronic disease prediction. We propose a novel approach for binary\ndecision-making, which hierarchically builds community-based PU models and then\naggregates their deliverables. Our method can explicate each PU model on the\ntree for the optimized non-leaf PU node splitting. Furthermore, a mask-recovery\ndata augmentation strategy enables sufficient training of the model in\nindividual communities. Additionally, the proposed approach includes an\nadversarial PU risk estimator to capture hierarchical PU-relationships, and a\nmodel fusion network that integrates data from each tree path, resulting in\nrobust binary classification results. We demonstrate the superior performance\nof PUtree as well as its variants on two benchmarks and a new\ndiabetes-prediction dataset.",
          "link": "http://arxiv.org/abs/2309.03386",
          "publishedOn": "2023-09-09T00:40:35.386Z",
          "wordCount": null,
          "title": "Community-Based Hierarchical Positive-Unlabeled (PU) Model Fusion for Chronic Disease Prediction. (arXiv:2309.03386v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03619",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brima_Y/0/1/0/all/0/1\">Yusuf Brima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krumnack_U/0/1/0/all/0/1\">Ulf Krumnack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pika_S/0/1/0/all/0/1\">Simone Pika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heidemann_G/0/1/0/all/0/1\">Gunther Heidemann</a>",
          "description": "The choice of the objective function is crucial in emerging high-quality\nrepresentations from self-supervised learning. This paper investigates how\ndifferent formulations of the Barlow Twins (BT) objective impact downstream\ntask performance for speech data. We propose Modified Barlow Twins (MBT) with\nnormalized latents to enforce scale-invariance and evaluate on speaker\nidentification, gender recognition and keyword spotting tasks. Our results show\nMBT improves representation generalization over original BT, especially when\nfine-tuning with limited target data. This highlights the importance of\ndesigning objectives that encourage invariant and transferable representations.\nOur analysis provides insights into how the BT learning objective can be\ntailored to produce speech representations that excel when adapted to new\ndownstream tasks. This study is an important step towards developing reusable\nself-supervised speech representations.",
          "link": "http://arxiv.org/abs/2309.03619",
          "publishedOn": "2023-09-09T00:40:35.385Z",
          "wordCount": null,
          "title": "Understanding Self-Supervised Learning of Speech Representation via Invariance and Redundancy Reduction. (arXiv:2309.03619v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03720",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Svoboda_R/0/1/0/all/0/1\">Radek Svoboda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basterrech_S/0/1/0/all/0/1\">Sebastian Basterrech</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kozal_J/0/1/0/all/0/1\">J&#x119;drzej Kozal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Platos_J/0/1/0/all/0/1\">Jan Plato&#x161;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wozniak_M/0/1/0/all/0/1\">Micha&#x142; Wo&#x17a;niak</a>",
          "description": "Forecasting natural gas consumption, considering seasonality and trends, is\ncrucial in planning its supply and consumption and optimizing the cost of\nobtaining it, mainly by industrial entities. However, in times of threats to\nits supply, it is also a critical element that guarantees the supply of this\nraw material to meet individual consumers' needs, ensuring society's energy\nsecurity. This article introduces a novel multistep ahead forecasting of\nnatural gas consumption with change point detection integration for model\ncollection selection with continual learning capabilities using data stream\nprocessing. The performance of the forecasting models based on the proposed\napproach is evaluated in a complex real-world use case of natural gas\nconsumption forecasting. We employed Hoeffding tree predictors as forecasting\nmodels and the Pruned Exact Linear Time (PELT) algorithm for the change point\ndetection procedure. The change point detection integration enables selecting a\ndifferent model collection for successive time frames. Thus, three model\ncollection selection procedures (with and without an error feedback loop) are\ndefined and evaluated for forecasting scenarios with various densities of\ndetected change points. These models were compared with change point agnostic\nbaseline approaches. Our experiments show that fewer change points result in a\nlower forecasting error regardless of the model collection selection procedure\nemployed. Also, simpler model collection selection procedures omitting\nforecasting error feedback leads to more robust forecasting models suitable for\ncontinual learning tasks.",
          "link": "http://arxiv.org/abs/2309.03720",
          "publishedOn": "2023-09-09T00:40:35.385Z",
          "wordCount": null,
          "title": "A Natural Gas Consumption Forecasting System for Continual Learning Scenarios based on Hoeffding Trees with Change Point Detection Mechanism. (arXiv:2309.03720v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03409",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chengrun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuezhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yifeng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hanxiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1\">Quoc V. Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Denny Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinyun Chen</a>",
          "description": "Optimization is ubiquitous. While derivative-based algorithms have been\npowerful tools for various problems, the absence of gradient imposes challenges\non many real-world applications. In this work, we propose Optimization by\nPROmpting (OPRO), a simple and effective approach to leverage large language\nmodels (LLMs) as optimizers, where the optimization task is described in\nnatural language. In each optimization step, the LLM generates new solutions\nfrom the prompt that contains previously generated solutions with their values,\nthen the new solutions are evaluated and added to the prompt for the next\noptimization step. We first showcase OPRO on linear regression and traveling\nsalesman problems, then move on to prompt optimization where the goal is to\nfind instructions that maximize the task accuracy. With a variety of LLMs, we\ndemonstrate that the best prompts optimized by OPRO outperform human-designed\nprompts by up to 8% on GSM8K, and by up to 50% on Big-Bench Hard tasks.",
          "link": "http://arxiv.org/abs/2309.03409",
          "publishedOn": "2023-09-09T00:40:35.382Z",
          "wordCount": null,
          "title": "Large Language Models as Optimizers. (arXiv:2309.03409v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.15341",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ostmeier_S/0/1/0/all/0/1\">Sophie Ostmeier</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Axelrod_B/0/1/0/all/0/1\">Brian Axelrod</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Verhaaren_B/0/1/0/all/0/1\">Benjamin F.J. Verhaaren</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Christensen_S/0/1/0/all/0/1\">Soren Christensen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mahammedi_A/0/1/0/all/0/1\">Abdelkader Mahammedi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1\">Yongkai Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pulli_B/0/1/0/all/0/1\">Benjamin Pulli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_L/0/1/0/all/0/1\">Li-Jia Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zaharchuk_G/0/1/0/all/0/1\">Greg Zaharchuk</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Heit_J/0/1/0/all/0/1\">Jeremy J. Heit</a>",
          "description": "To determine if a convolutional neural network (CNN) deep learning model can\naccurately segment acute ischemic changes on non-contrast CT compared to\nneuroradiologists. Non-contrast CT (NCCT) examinations from 232 acute ischemic\nstroke patients who were enrolled in the DEFUSE 3 trial were included in this\nstudy. Three experienced neuroradiologists independently segmented hypodensity\nthat reflected the ischemic core on each scan. The neuroradiologist with the\nmost experience (expert A) served as the ground truth for deep learning model\ntraining. Two additional neuroradiologists (experts B and C) segmentations were\nused for data testing. The 232 studies were randomly split into training and\ntest sets. The training set was further randomly divided into 5 folds with\ntraining and validation sets. A 3-dimensional CNN architecture was trained and\noptimized to predict the segmentations of expert A from NCCT. The performance\nof the model was assessed using a set of volume, overlap, and distance metrics\nusing non-inferiority thresholds of 20%, 3ml, and 3mm. The optimized model\ntrained on expert A was compared to test experts B and C. We used a one-sided\nWilcoxon signed-rank test to test for the non-inferiority of the model-expert\ncompared to the inter-expert agreement. The final model performance for the\nischemic core segmentation task reached a performance of 0.46+-0.09 Surface\nDice at Tolerance 5mm and 0.47+-0.13 Dice when trained on expert A. Compared to\nthe two test neuroradiologists the model-expert agreement was non-inferior to\nthe inter-expert agreement, p < 0.05. The CNN accurately delineates the\nhypodense ischemic core on NCCT in acute ischemic stroke patients with an\naccuracy comparable to neuroradiologists.",
          "link": "http://arxiv.org/abs/2211.15341",
          "publishedOn": "2023-09-09T00:40:35.381Z",
          "wordCount": null,
          "title": "Non-inferiority of Deep Learning Acute Ischemic Stroke Segmentation on Non-Contrast CT Compared to Expert Neuroradiologists. (arXiv:2211.15341v3 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03451",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jeongsoo Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_D/0/1/0/all/0/1\">Dong-Gyun Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+La_H/0/1/0/all/0/1\">Hyoung Sul La</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sangmin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yoonchang Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1\">Eun-Jin Yang</a>",
          "description": "This paper presents a novel deep learning approach for analyzing massive\nunderwater acoustic data by leveraging a model trained on a broad spectrum of\nnon-underwater (aerial) sounds. Recognizing the challenge in labeling vast\namounts of underwater data, we propose a two-fold methodology to accelerate\nthis labor-intensive procedure.\n\nThe first part of our approach involves PCA and UMAP visualization of the\nunderwater data using the feature vectors of an aerial sound recognition model.\nThis enables us to cluster the data in a two dimensional space and listen to\npoints within these clusters to understand their defining characteristics. This\ninnovative method simplifies the process of selecting candidate labels for\nfurther training.\n\nIn the second part, we train a neural network model using both the selected\nunderwater data and the non-underwater dataset. We conducted a quantitative\nanalysis to measure the precision, recall, and F1 score of our model for\nrecognizing airgun sounds, a common type of underwater sound. The F1 score\nachieved by our model exceeded 84.3%, demonstrating the effectiveness of our\napproach in analyzing underwater acoustic data.\n\nThe methodology presented in this paper holds significant potential to reduce\nthe amount of labor required in underwater data analysis and opens up new\npossibilities for further research in the field of cross-domain data analysis.",
          "link": "http://arxiv.org/abs/2309.03451",
          "publishedOn": "2023-09-09T00:40:35.377Z",
          "wordCount": null,
          "title": "Cross-domain Sound Recognition for Efficient Underwater Data Analysis. (arXiv:2309.03451v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03708",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Helal_M/0/1/0/all/0/1\">Manal Helal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holthaus_P/0/1/0/all/0/1\">Patrick Holthaus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakatos_G/0/1/0/all/0/1\">Gabriella Lakatos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amirabdollahian_F/0/1/0/all/0/1\">Farshid Amirabdollahian</a>",
          "description": "This paper examines some common problems in Human-Robot Interaction (HRI)\ncausing failures and troubles in Chat. A given use case's design decisions\nstart with the suitable robot, the suitable chatting model, identifying common\nproblems that cause failures, identifying potential solutions, and planning\ncontinuous improvement. In conclusion, it is recommended to use a closed-loop\ncontrol algorithm that guides the use of trained Artificial Intelligence (AI)\npre-trained models and provides vocabulary filtering, re-train batched models\non new datasets, learn online from data streams, and/or use reinforcement\nlearning models to self-update the trained models and reduce errors.",
          "link": "http://arxiv.org/abs/2309.03708",
          "publishedOn": "2023-09-09T00:40:35.377Z",
          "wordCount": null,
          "title": "Chat Failures and Troubles: Reasons and Solutions. (arXiv:2309.03708v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03780",
          "author": "<a href=\"http://arxiv.org/find/hep-ex/1/au:+Odyurt_U/0/1/0/all/0/1\">Uraz Odyurt</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Swatman_S/0/1/0/all/0/1\">Stephen Nicholas Swatman</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Varbanescu_A/0/1/0/all/0/1\">Ana-Lucia Varbanescu</a>, <a href=\"http://arxiv.org/find/hep-ex/1/au:+Caron_S/0/1/0/all/0/1\">Sascha Caron</a>",
          "description": "Subatomic particle track reconstruction (tracking) is a vital task in\nHigh-Energy Physics experiments. Tracking is exceptionally computationally\nchallenging and fielded solutions, relying on traditional algorithms, do not\nscale linearly. Machine Learning (ML) assisted solutions are a promising\nanswer. We argue that a complexity-reduced problem description and the data\nrepresenting it, will facilitate the solution exploration workflow. We provide\nthe REDuced VIrtual Detector (REDVID) as a complexity-reduced detector model\nand particle collision event simulator combo. REDVID is intended as a\nsimulation-in-the-loop, to both generate synthetic data efficiently and to\nsimplify the challenge of ML model design. The fully parametric nature of our\ntool, with regards to system-level configuration, while in contrast to\nphysics-accurate simulations, allows for the generation of simplified data for\nresearch and education, at different levels. Resulting from the reduced\ncomplexity, we showcase the computational efficiency of REDVID by providing the\ncomputational cost figures for a multitude of simulation benchmarks. As a\nsimulation and a generative tool for ML-assisted solution design, REDVID is\nhighly flexible, reusable and open-source. Reference data sets generated with\nREDVID are publicly available.",
          "link": "http://arxiv.org/abs/2309.03780",
          "publishedOn": "2023-09-09T00:40:35.375Z",
          "wordCount": null,
          "title": "Reduced Simulations for High-Energy Physics, a Middle Ground for Data-Driven Physics Research. (arXiv:2309.03780v1 [hep-ex])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03808",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhong_Z/0/1/0/all/0/1\">Ziliang Samuel Zhong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ling_S/0/1/0/all/0/1\">Shuyang Ling</a>",
          "description": "Given pairwise comparisons between multiple items, how to rank them so that\nthe ranking matches the observations? This problem, known as rank aggregation,\nhas found many applications in sports, recommendation systems, and other web\napplications. As it is generally NP-hard to find a global ranking that\nminimizes the mismatch (known as the Kemeny optimization), we focus on the\nErd\\\"os-R\\'enyi outliers (ERO) model for this ranking problem. Here, each\npairwise comparison is a corrupted copy of the true score difference. We\ninvestigate spectral ranking algorithms that are based on unnormalized and\nnormalized data matrices. The key is to understand their performance in\nrecovering the underlying scores of each item from the observed data. This\nreduces to deriving an entry-wise perturbation error bound between the top\neigenvectors of the unnormalized/normalized data matrix and its population\ncounterpart. By using the leave-one-out technique, we provide a sharper\n$\\ell_{\\infty}$-norm perturbation bound of the eigenvectors and also derive an\nerror bound on the maximum displacement for each item, with only $\\Omega(n\\log\nn)$ samples. Our theoretical analysis improves upon the state-of-the-art\nresults in terms of sample complexity, and our numerical experiments confirm\nthese theoretical findings.",
          "link": "http://arxiv.org/abs/2309.03808",
          "publishedOn": "2023-09-09T00:40:35.370Z",
          "wordCount": null,
          "title": "Improved theoretical guarantee for rank aggregation via spectral method. (arXiv:2309.03808v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03831",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khaki_S/0/1/0/all/0/1\">Saeed Khaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aditya_A/0/1/0/all/0/1\">Akhouri Abhinav Aditya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karnin_Z/0/1/0/all/0/1\">Zohar Karnin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1\">Lan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_O/0/1/0/all/0/1\">Olivia Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandrashekar_S/0/1/0/all/0/1\">Samarth Marudheri Chandrashekar</a>",
          "description": "Drift in machine learning refers to the phenomenon where the statistical\nproperties of data or context, in which the model operates, change over time\nleading to a decrease in its performance. Therefore, maintaining a constant\nmonitoring process for machine learning model performance is crucial in order\nto proactively prevent any potential performance regression. However,\nsupervised drift detection methods require human annotation and consequently\nlead to a longer time to detect and mitigate the drift. In our proposed\nunsupervised drift detection method, we follow a two step process. Our first\nstep involves encoding a sample of production data as the target distribution,\nand the model training data as the reference distribution. In the second step,\nwe employ a kernel-based statistical test that utilizes the maximum mean\ndiscrepancy (MMD) distance metric to compare the reference and target\ndistributions and estimate any potential drift. Our method also identifies the\nsubset of production data that is the root cause of the drift. The models\nretrained using these identified high drift samples show improved performance\non online customer experience quality metrics.",
          "link": "http://arxiv.org/abs/2309.03831",
          "publishedOn": "2023-09-09T00:40:35.370Z",
          "wordCount": null,
          "title": "Uncovering Drift in Textual Data: An Unsupervised Method for Detecting and Mitigating Drift in Machine Learning Models. (arXiv:2309.03831v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03468",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Raghuraman_N/0/1/0/all/0/1\">Nikhil Raghuraman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harley_A/0/1/0/all/0/1\">Adam W. Harley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1\">Leonidas Guibas</a>",
          "description": "Current machine learning methods struggle to solve Bongard problems, which\nare a type of IQ test that requires deriving an abstract \"concept\" from a set\nof positive and negative \"support\" images, and then classifying whether or not\na new query image depicts the key concept. On Bongard-HOI, a benchmark for\nnatural-image Bongard problems, existing methods have only reached 66% accuracy\n(where chance is 50%). Low accuracy is often attributed to neural nets' lack of\nability to find human-like symbolic rules. In this work, we point out that many\nexisting methods are forfeiting accuracy due to a much simpler problem: they do\nnot incorporate information contained in the support set as a whole, and rely\ninstead on information extracted from individual supports. This is a critical\nissue, because unlike in few-shot learning tasks concerning object\nclassification, the \"key concept\" in a typical Bongard problem can only be\ndistinguished using multiple positives and multiple negatives. We explore a\nvariety of simple methods to take this cross-image context into account, and\ndemonstrate substantial gains over prior methods, leading to new\nstate-of-the-art performance on Bongard-LOGO (75.3%) and Bongard-HOI (72.45%)\nand strong performance on the original Bongard problem set (60.84%).",
          "link": "http://arxiv.org/abs/2309.03468",
          "publishedOn": "2023-09-09T00:40:35.356Z",
          "wordCount": null,
          "title": "Cross-Image Context Matters for Bongard Problems. (arXiv:2309.03468v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03730",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bockel_Rickermann_C/0/1/0/all/0/1\">Christopher Bockel-Rickermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verboven_S/0/1/0/all/0/1\">Sam Verboven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verdonck_T/0/1/0/all/0/1\">Tim Verdonck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verbeke_W/0/1/0/all/0/1\">Wouter Verbeke</a>",
          "description": "In lending, where prices are specific to both customers and products, having\na well-functioning personalized pricing policy in place is essential to\neffective business making. Typically, such a policy must be derived from\nobservational data, which introduces several challenges. While the problem of\n``endogeneity'' is prominently studied in the established pricing literature,\nthe problem of selection bias (or, more precisely, bid selection bias) is not.\nWe take a step towards understanding the effects of selection bias by posing\npricing as a problem of causal inference. Specifically, we consider the\nreaction of a customer to price a treatment effect. In our experiments, we\nsimulate varying levels of selection bias on a semi-synthetic dataset on\nmortgage loan applications in Belgium. We investigate the potential of\nparametric and nonparametric methods for the identification of individual\nbid-response functions. Our results illustrate how conventional methods such as\nlogistic regression and neural networks suffer adversely from selection bias.\nIn contrast, we implement state-of-the-art methods from causal machine learning\nand show their capability to overcome selection bias in pricing data.",
          "link": "http://arxiv.org/abs/2309.03730",
          "publishedOn": "2023-09-09T00:40:35.355Z",
          "wordCount": null,
          "title": "A Causal Perspective on Loan Pricing: Investigating the Impacts of Selection Bias on Identifying Bid-Response Functions. (arXiv:2309.03730v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03447",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Shi_Y/0/1/0/all/0/1\">Yaozhong Shi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lavrentiadis_G/0/1/0/all/0/1\">Grigorios Lavrentiadis</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Asimaki_D/0/1/0/all/0/1\">Domniki Asimaki</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ross_Z/0/1/0/all/0/1\">Zachary E. Ross</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Azizzadenesheli_K/0/1/0/all/0/1\">Kamyar Azizzadenesheli</a>",
          "description": "We present a data-driven model for ground-motion synthesis using a Generative\nAdversarial Neural Operator (GANO) that combines recent advancements in machine\nlearning and open access strong motion data sets to generate three-component\nacceleration time histories conditioned on moment magnitude ($M$), rupture\ndistance ($R_{rup}$), time-average shear-wave velocity at the top $30m$\n($V_{S30}$), and tectonic environment or style of faulting. We use Neural\nOperators, a resolution invariant architecture that guarantees that the model\ntraining is independent of the data sampling frequency. We first present the\nconditional ground-motion synthesis algorithm (referred to heretofore as\ncGM-GANO) and discuss its advantages compared to previous work. Next, we verify\nthe cGM-GANO framework using simulated ground motions generated with the\nSouthern California Earthquake Center (SCEC) Broadband Platform (BBP). We\nlastly train cGM-GANO on a KiK-net dataset from Japan, showing that the\nframework can recover the magnitude, distance, and $V_{S30}$ scaling of Fourier\namplitude and pseudo-spectral accelerations. We evaluate cGM-GANO through\nresidual analysis with the empirical dataset as well as by comparison with\nconventional Ground Motion Models (GMMs) for selected ground motion scenarios.\nResults show that cGM-GANO produces consistent median scaling with the GMMs for\nthe corresponding tectonic environments. The largest misfit is observed at\nshort distances due to the scarcity of training data. With the exception of\nshort distances, the aleatory variability of the response spectral ordinates is\nalso well captured, especially for subduction events due to the adequacy of\ntraining data. Applications of the presented framework include generation of\nrisk-targeted ground motions for site-specific engineering applications.",
          "link": "http://arxiv.org/abs/2309.03447",
          "publishedOn": "2023-09-09T00:40:35.346Z",
          "wordCount": null,
          "title": "Broadband Ground Motion Synthesis via Generative Adversarial Neural Operators: Development and Validation. (arXiv:2309.03447v1 [physics.geo-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03616",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Srambical_F/0/1/0/all/0/1\">Franz Srambical</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rieck_B/0/1/0/all/0/1\">Bastian Rieck</a>",
          "description": "Existing approaches for classifying dynamic graphs either lift graph kernels\nto the temporal domain, or use graph neural networks (GNNs). However, current\nbaselines have scalability issues, cannot handle a changing node set, or do not\ntake edge weight information into account. We propose filtration surfaces, a\nnovel method that is scalable and flexible, to alleviate said restrictions. We\nexperimentally validate the efficacy of our model and show that filtration\nsurfaces outperform previous state-of-the-art baselines on datasets that rely\non edge weight information. Our method does so while being either completely\nparameter-free or having at most one parameter, and yielding the lowest overall\nstandard deviation.",
          "link": "http://arxiv.org/abs/2309.03616",
          "publishedOn": "2023-09-09T00:40:35.344Z",
          "wordCount": null,
          "title": "Filtration Surfaces for Dynamic Graph Classification. (arXiv:2309.03616v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03245",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1\">Sampriti Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasudev_Y/0/1/0/all/0/1\">Yadu Vasudev</a>",
          "description": "We study distribution testing in the standard access model and the\nconditional access model when the memory available to the testing algorithm is\nbounded. In both scenarios, the samples appear in an online fashion and the\ngoal is to test the properties of distribution using an optimal number of\nsamples subject to a memory constraint on how many samples can be stored at a\ngiven time. First, we provide a trade-off between the sample complexity and the\nspace complexity for testing identity when the samples are drawn according to\nthe conditional access oracle. We then show that we can learn a succinct\nrepresentation of a monotone distribution efficiently with a memory constraint\non the number of samples that are stored that is almost optimal. We also show\nthat the algorithm for monotone distributions can be extended to a larger class\nof decomposable distributions.",
          "link": "http://arxiv.org/abs/2309.03245",
          "publishedOn": "2023-09-09T00:40:35.337Z",
          "wordCount": null,
          "title": "Testing properties of distributions in the streaming model. (arXiv:2309.03245v1 [cs.DS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03531",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choudhuri_S/0/1/0/all/0/1\">Sandipan Choudhuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adeniye_S/0/1/0/all/0/1\">Suli Adeniye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sen_A/0/1/0/all/0/1\">Arunabha Sen</a>",
          "description": "This work proposes a robust Partial Domain Adaptation (PDA) framework that\nmitigates the negative transfer problem by incorporating a robust\ntarget-supervision strategy. It leverages ensemble learning and includes\ndiverse, complementary label feedback, alleviating the effect of incorrect\nfeedback and promoting pseudo-label refinement. Rather than relying exclusively\non first-order moments for distribution alignment, our approach offers explicit\nobjectives to optimize intra-class compactness and inter-class separation with\nthe inferred source prototypes and highly-confident target samples in a\ndomain-invariant fashion. Notably, we ensure source data privacy by eliminating\nthe need to access the source data during the adaptation phase through a priori\ninference of source prototypes. We conducted a series of comprehensive\nexperiments, including an ablation analysis, covering a range of partial domain\nadaptation tasks. Comprehensive evaluations on benchmark datasets corroborate\nour framework's enhanced robustness and generalization, demonstrating its\nsuperiority over existing state-of-the-art PDA approaches.",
          "link": "http://arxiv.org/abs/2309.03531",
          "publishedOn": "2023-09-09T00:40:35.331Z",
          "wordCount": null,
          "title": "A Robust Negative Learning Approach to Partial Domain Adaptation Using Source Prototypes. (arXiv:2309.03531v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.01311",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Harry Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Appleby_G/0/1/0/all/0/1\">Gabriel Appleby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brumar_C/0/1/0/all/0/1\">Camelia Daniela Brumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_R/0/1/0/all/0/1\">Remco Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suh_A/0/1/0/all/0/1\">Ashley Suh</a>",
          "description": "This study presents insights from interviews with nineteen Knowledge Graph\n(KG) practitioners who work in both enterprise and academic settings on a wide\nvariety of use cases. Through this study, we identify critical challenges\nexperienced by KG practitioners when creating, exploring, and analyzing KGs\nthat could be alleviated through visualization design. Our findings reveal\nthree major personas among KG practitioners - KG Builders, Analysts, and\nConsumers - each of whom have their own distinct expertise and needs. We\ndiscover that KG Builders would benefit from schema enforcers, while KG\nAnalysts need customizable query builders that provide interim query results.\nFor KG Consumers, we identify a lack of efficacy for node-link diagrams, and\nthe need for tailored domain-specific visualizations to promote KG adoption and\ncomprehension. Lastly, we find that implementing KGs effectively in practice\nrequires both technical and social solutions that are not addressed with\ncurrent tools, technologies, and collaborative workflows. From the analysis of\nour interviews, we distill several visualization research directions to improve\nKG usability, including knowledge cards that balance digestibility and\ndiscoverability, timeline views to track temporal changes, interfaces that\nsupport organic discovery, and semantic explanations for AI and machine\nlearning predictions.",
          "link": "http://arxiv.org/abs/2304.01311",
          "publishedOn": "2023-09-09T00:40:35.315Z",
          "wordCount": null,
          "title": "Knowledge Graphs in Practice: Characterizing their Users, Challenges, and Visualization Opportunities. (arXiv:2304.01311v3 [cs.HC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.06145",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Iqbal_S/0/1/0/all/0/1\">Shahzaib Iqbal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Khan_T/0/1/0/all/0/1\">Tariq M. Khan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Naqvi_S/0/1/0/all/0/1\">Syed S. Naqvi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Usman_M/0/1/0/all/0/1\">Muhammad Usman</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Razzak_I/0/1/0/all/0/1\">Imran Razzak</a>",
          "description": "In this study, we propose LDMRes-Net, a lightweight dual-multiscale residual\nblock-based computational neural network tailored for medical image\nsegmentation on IoT and edge platforms. Conventional U-Net-based models face\nchallenges in meeting the speed and efficiency demands of real-time clinical\napplications, such as disease monitoring, radiation therapy, and image-guided\nsurgery. LDMRes-Net overcomes these limitations with its remarkably low number\nof learnable parameters (0.072M), making it highly suitable for\nresource-constrained devices. The model's key innovation lies in its dual\nmulti-residual block architecture, which enables the extraction of refined\nfeatures on multiple scales, enhancing overall segmentation performance. To\nfurther optimize efficiency, the number of filters is carefully selected to\nprevent overlap, reduce training time, and improve computational efficiency.\nThe study includes comprehensive evaluations, focusing on segmentation of the\nretinal image of vessels and hard exudates crucial for the diagnosis and\ntreatment of ophthalmology. The results demonstrate the robustness,\ngeneralizability, and high segmentation accuracy of LDMRes-Net, positioning it\nas an efficient tool for accurate and rapid medical image segmentation in\ndiverse clinical applications, particularly on IoT and edge platforms. Such\nadvances hold significant promise for improving healthcare outcomes and\nenabling real-time medical image analysis in resource-limited settings.",
          "link": "http://arxiv.org/abs/2306.06145",
          "publishedOn": "2023-09-09T00:40:35.312Z",
          "wordCount": null,
          "title": "LDMRes-Net: Enabling Efficient Medical Image Segmentation on IoT and Edge Platforms. (arXiv:2306.06145v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03530",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moos_A/0/1/0/all/0/1\">Arne Moos</a>",
          "description": "This paper proposes a novel approach for detecting objects using mobile\nrobots in the context of the RoboCup Standard Platform League, with a primary\nfocus on detecting the ball. The challenge lies in detecting a dynamic object\nin varying lighting conditions and blurred images caused by fast movements. To\naddress this challenge, the paper presents a convolutional neural network\narchitecture designed specifically for computationally constrained robotic\nplatforms. The proposed CNN is trained to achieve high precision classification\nof single objects in image patches and to determine their precise spatial\npositions. The paper further integrates Early Exits into the existing\nhigh-precision CNN architecture to reduce the computational cost of easily\nrejectable cases in the background class. The training process involves a\ncomposite loss function based on confidence and positional losses with dynamic\nweighting and data augmentation. The proposed approach achieves a precision of\n100% on the validation dataset and a recall of almost 87%, while maintaining an\nexecution time of around 170 $\\mu$s per hypotheses. By combining the proposed\napproach with an Early Exit, a runtime optimization of more than 28%, on\naverage, can be achieved compared to the original CNN. Overall, this paper\nprovides an efficient solution for an enhanced detection of objects, especially\nthe ball, in computationally constrained robotic platforms.",
          "link": "http://arxiv.org/abs/2309.03530",
          "publishedOn": "2023-09-09T00:40:35.311Z",
          "wordCount": null,
          "title": "Efficient Single Object Detection on Image Patches with Early Exit Enhanced High-Precision CNNs. (arXiv:2309.03530v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03353",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sameer_V/0/1/0/all/0/1\">Venkata Udaya Sameer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukhopadhyay_S/0/1/0/all/0/1\">Shilpa Mukhopadhyay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naskar_R/0/1/0/all/0/1\">Ruchira Naskar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dali_I/0/1/0/all/0/1\">Ishaan Dali</a>",
          "description": "Source camera identification in digital videos is the problem of associating\nan unknown digital video with its source device, within a closed set of\npossible devices. The existing techniques in source detection of digital videos\ntry to find a fingerprint of the actual source in the video in form of PRNU\n(Photo Response Non--Uniformity), and match it against the SPN (Sensor Pattern\nNoise) of each possible device. The highest correlation indicates the correct\nsource. We investigate the problem of identifying a video source through a\nfeature based approach using machine learning. In this paper, we present a\nblind forensic technique of video source authentication and identification,\nbased on feature extraction, feature selection and subsequent source\nclassification. The main aim is to determine whether a claimed source for a\nvideo is actually its original source. If not, we identify its original source.\nOur experimental results prove the efficiency of the proposed method compared\nto traditional fingerprint based technique.",
          "link": "http://arxiv.org/abs/2309.03353",
          "publishedOn": "2023-09-09T00:40:35.306Z",
          "wordCount": null,
          "title": "Source Camera Identification and Detection in Digital Videos through Blind Forensics. (arXiv:2309.03353v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zikai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1\">Rui Hu</a>",
          "description": "Federated learning (FL) is designed to preserve data privacy during model\ntraining, where the data remains on the client side (i.e., IoT devices), and\nonly model updates of clients are shared iteratively for collaborative\nlearning. However, this process is vulnerable to privacy attacks and Byzantine\nattacks: the local model updates shared throughout the FL network will leak\nprivate information about the local training data, and they can also be\nmaliciously crafted by Byzantine attackers to disturb the learning. In this\npaper, we propose a new FL scheme that guarantees rigorous privacy and\nsimultaneously enhances system robustness against Byzantine attacks. Our\napproach introduces sparsification- and momentum-driven variance reduction into\nthe client-level differential privacy (DP) mechanism, to defend against\nByzantine attackers. The security design does not violate the privacy guarantee\nof the client-level DP mechanism; hence, our approach achieves the same\nclient-level DP guarantee as the state-of-the-art. We conduct extensive\nexperiments on both IID and non-IID datasets and different tasks and evaluate\nthe performance of our approach against different Byzantine attacks by\ncomparing it with state-of-the-art defense methods. The results of our\nexperiments show the efficacy of our framework and demonstrate its ability to\nimprove system robustness against Byzantine attacks while achieving a strong\nprivacy guarantee.",
          "link": "http://arxiv.org/abs/2309.03437",
          "publishedOn": "2023-09-09T00:40:35.301Z",
          "wordCount": null,
          "title": "Byzantine-Robust Federated Learning with Variance Reduction and Differential Privacy. (arXiv:2309.03437v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03242",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Zhou_J/0/1/0/all/0/1\">Juexiao Zhou</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_B/0/1/0/all/0/1\">Bin Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chen_X/0/1/0/all/0/1\">Xiuying Chen</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Li_H/0/1/0/all/0/1\">Haoyang Li</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Xu_X/0/1/0/all/0/1\">Xiaopeng Xu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chen_S/0/1/0/all/0/1\">Siyuan Chen</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Gao_X/0/1/0/all/0/1\">Xin Gao</a>",
          "description": "With the fast-growing and evolving omics data, the demand for streamlined and\nadaptable tools to handle the analysis continues to grow. In response to this\nneed, we introduce Auto Bioinformatics Analysis (AutoBA), an autonomous AI\nagent based on a large language model designed explicitly for conventional\nomics data analysis. AutoBA simplifies the analytical process by requiring\nminimal user input while delivering detailed step-by-step plans for various\nbioinformatics tasks. Through rigorous validation by expert bioinformaticians,\nAutoBA's robustness and adaptability are affirmed across a diverse range of\nomics analysis cases, including whole genome sequencing (WGS), RNA sequencing\n(RNA-seq), single-cell RNA-seq, ChIP-seq, and spatial transcriptomics. AutoBA's\nunique capacity to self-design analysis processes based on input data\nvariations further underscores its versatility. Compared with online\nbioinformatic services, AutoBA deploys the analysis locally, preserving data\nprivacy. Moreover, different from the predefined pipeline, AutoBA has\nadaptability in sync with emerging bioinformatics tools. Overall, AutoBA\nrepresents a convenient tool, offering robustness and adaptability for complex\nomics data analysis.",
          "link": "http://arxiv.org/abs/2309.03242",
          "publishedOn": "2023-09-09T00:40:35.300Z",
          "wordCount": null,
          "title": "Automated Bioinformatics Analysis via AutoBA. (arXiv:2309.03242v1 [q-bio.GN])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03229",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bulck_D/0/1/0/all/0/1\">David Van Bulck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goossens_D/0/1/0/all/0/1\">Dries Goossens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clarner_J/0/1/0/all/0/1\">Jan-Patrick Clarner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dimitsas_A/0/1/0/all/0/1\">Angelos Dimitsas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fonseca_G/0/1/0/all/0/1\">George H. G. Fonseca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lamas_Fernandez_C/0/1/0/all/0/1\">Carlos Lamas-Fernandez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lester_M/0/1/0/all/0/1\">Martin Mariusz Lester</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pedersen_J/0/1/0/all/0/1\">Jaap Pedersen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phillips_A/0/1/0/all/0/1\">Antony E. Phillips</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosati_R/0/1/0/all/0/1\">Roberto Maria Rosati</a>",
          "description": "Any sports competition needs a timetable, specifying when and where teams\nmeet each other. The recent International Timetabling Competition (ITC2021) on\nsports timetabling showed that, although it is possible to develop general\nalgorithms, the performance of each algorithm varies considerably over the\nproblem instances. This paper provides an instance space analysis for sports\ntimetabling, resulting in powerful insights into the strengths and weaknesses\nof eight state-of-the-art algorithms. Based on machine learning techniques, we\npropose an algorithm selection system that predicts which algorithm is likely\nto perform best when given the characteristics of a sports timetabling problem\ninstance. Furthermore, we identify which characteristics are important in\nmaking that prediction, providing insights in the performance of the\nalgorithms, and suggestions to further improve them. Finally, we assess the\nempirical hardness of the instances. Our results are based on large\ncomputational experiments involving about 50 years of CPU time on more than 500\nnewly generated problem instances.",
          "link": "http://arxiv.org/abs/2309.03229",
          "publishedOn": "2023-09-09T00:40:35.282Z",
          "wordCount": null,
          "title": "Which algorithm to select in sports timetabling?. (arXiv:2309.03229v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03231",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Shah_S/0/1/0/all/0/1\">Syed Atif Ali Shah</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Algeelani_N/0/1/0/all/0/1\">Nasir Algeelani</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Al_Sammarraie_N/0/1/0/all/0/1\">Najeeb Al-Sammarraie</a>",
          "description": "Surveillance systems have emerged as crucial elements in upholding peace and\nsecurity in the modern world. Their ubiquity aids in monitoring suspicious\nactivities effectively. However, in densely populated environments, continuous\nactive monitoring becomes impractical, necessitating the development of\nintelligent surveillance systems. AI integration in the surveillance domain was\na big revolution, however, speed issues have prevented its widespread\nimplementation in the field. It has been observed that quantum artificial\nintelligence has led to a great breakthrough. Quantum artificial\nintelligence-based surveillance systems have shown to be more accurate as well\nas capable of performing well in real-time scenarios, which had never been seen\nbefore. In this research, a RentinaNet model is integrated with Quantum CNN and\ntermed as Quantum-RetinaNet. By harnessing the Quantum capabilities of QCNN,\nQuantum-RetinaNet strikes a balance between accuracy and speed. This innovative\nintegration positions it as a game-changer, addressing the challenges of active\nmonitoring in densely populated scenarios. As demand for efficient surveillance\nsolutions continues to grow, Quantum-RetinaNet offers a compelling alternative\nto existing CNN models, upholding accuracy standards without sacrificing\nreal-time performance. The unique attributes of Quantum-RetinaNet have\nfar-reaching implications for the future of intelligent surveillance. With its\nenhanced processing speed, it is poised to revolutionize the field, catering to\nthe pressing need for rapid yet precise monitoring. As Quantum-RetinaNet\nbecomes the new standard, it ensures public safety and security while pushing\nthe boundaries of AI in surveillance.",
          "link": "http://arxiv.org/abs/2309.03231",
          "publishedOn": "2023-09-09T00:40:35.281Z",
          "wordCount": null,
          "title": "Quantum-AI empowered Intelligent Surveillance: Advancing Public Safety Through Innovative Contraband Detection. (arXiv:2309.03231v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03350",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Teng_J/0/1/0/all/0/1\">Jiayan Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1\">Wendi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Ming Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_W/0/1/0/all/0/1\">Wenyi Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wangni_J/0/1/0/all/0/1\">Jianqiao Wangni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuoyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>",
          "description": "Diffusion models achieved great success in image synthesis, but still face\nchallenges in high-resolution generation. Through the lens of discrete cosine\ntransformation, we find the main reason is that \\emph{the same noise level on a\nhigher resolution results in a higher Signal-to-Noise Ratio in the frequency\ndomain}. In this work, we present Relay Diffusion Model (RDM), which transfers\na low-resolution image or noise into an equivalent high-resolution one for\ndiffusion model via blurring diffusion and block noise. Therefore, the\ndiffusion process can continue seamlessly in any new resolution or model\nwithout restarting from pure noise or low-resolution conditioning. RDM achieves\nstate-of-the-art FID on CelebA-HQ and sFID on ImageNet 256$\\times$256,\nsurpassing previous works such as ADM, LDM and DiT by a large margin. All the\ncodes and checkpoints are open-sourced at\n\\url{https://github.com/THUDM/RelayDiffusion}.",
          "link": "http://arxiv.org/abs/2309.03350",
          "publishedOn": "2023-09-09T00:40:35.280Z",
          "wordCount": null,
          "title": "Relay Diffusion: Unifying diffusion process across resolutions for image synthesis. (arXiv:2309.03350v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jiuyun Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_N/0/1/0/all/0/1\">Naichen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kontar_R/0/1/0/all/0/1\">Raed Al Kontar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1\">Hao Yan</a>",
          "description": "We propose personalized Tucker decomposition (perTucker) to address the\nlimitations of traditional tensor decomposition methods in capturing\nheterogeneity across different datasets. perTucker decomposes tensor data into\nshared global components and personalized local components. We introduce a mode\northogonality assumption and develop a proximal gradient regularized block\ncoordinate descent algorithm that is guaranteed to converge to a stationary\npoint. By learning unique and common representations across datasets, we\ndemonstrate perTucker's effectiveness in anomaly detection, client\nclassification, and clustering through a simulation study and two case studies\non solar flare detection and tonnage signal classification.",
          "link": "http://arxiv.org/abs/2309.03439",
          "publishedOn": "2023-09-09T00:40:35.275Z",
          "wordCount": null,
          "title": "Personalized Tucker Decomposition: Modeling Commonality and Peculiarity on Tensor Data. (arXiv:2309.03439v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03360",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Arjon Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_X/0/1/0/all/0/1\">Xin Zhong</a>",
          "description": "Joint Embedding Architecture-based self-supervised learning methods have\nattributed the composition of data augmentations as a crucial factor for their\nstrong representation learning capabilities. While regional dropout strategies\nhave proven to guide models to focus on lesser indicative parts of the objects\nin supervised methods, it hasn't been adopted by self-supervised methods for\ngenerating positive pairs. This is because the regional dropout methods are not\nsuitable for the input sampling process of the self-supervised methodology.\nWhereas dropping informative pixels from the positive pairs can result in\ninefficient training, replacing patches of a specific object with a different\none can steer the model from maximizing the agreement between different\npositive pairs. Moreover, joint embedding representation learning methods have\nnot made robustness their primary training outcome. To this end, we propose the\nViewMix augmentation policy, specially designed for self-supervised learning,\nupon generating different views of the same image, patches are cut and pasted\nfrom one view to another. By leveraging the different views created by this\naugmentation strategy, multiple joint embedding-based self-supervised\nmethodologies obtained better localization capability and consistently\noutperformed their corresponding baseline methods. It is also demonstrated that\nincorporating ViewMix augmentation policy promotes robustness of the\nrepresentations in the state-of-the-art methods. Furthermore, our\nexperimentation and analysis of compute times suggest that ViewMix augmentation\ndoesn't introduce any additional overhead compared to other counterparts.",
          "link": "http://arxiv.org/abs/2309.03360",
          "publishedOn": "2023-09-09T00:40:35.274Z",
          "wordCount": null,
          "title": "ViewMix: Augmentation for Robust Representation in Self-Supervised Learning. (arXiv:2309.03360v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03659",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Niemann_O/0/1/0/all/0/1\">Onno Niemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vox_C/0/1/0/all/0/1\">Christopher Vox</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Werner_T/0/1/0/all/0/1\">Thorben Werner</a>",
          "description": "Knowledge Distillation (KD) is one proposed solution to large model sizes and\nslow inference speed in semantic segmentation. In our research we identify 25\nproposed distillation loss terms from 14 publications in the last 4 years.\nUnfortunately, a comparison of terms based on published results is often\nimpossible, because of differences in training configurations. A good\nillustration of this problem is the comparison of two publications from 2022.\nUsing the same models and dataset, Structural and Statistical Texture\nDistillation (SSTKD) reports an increase of student mIoU of 4.54 and a final\nperformance of 29.19, while Adaptive Perspective Distillation (APD) only\nimproves student performance by 2.06 percentage points, but achieves a final\nperformance of 39.25. The reason for such extreme differences is often a\nsuboptimal choice of hyperparameters and a resulting underperformance of the\nstudent model used as reference point. In our work, we reveal problems of\ninsufficient hyperparameter tuning by showing that distillation improvements of\ntwo widely accepted frameworks, SKD and IFVD, vanish when hyperparameters are\noptimized sufficiently. To improve comparability of future research in the\nfield, we establish a solid baseline for three datasets and two student models\nand provide extensive information on hyperparameter tuning. We find that only\ntwo out of eight techniques can compete with our simple baseline on the ADE20K\ndataset.",
          "link": "http://arxiv.org/abs/2309.03659",
          "publishedOn": "2023-09-09T00:40:35.273Z",
          "wordCount": null,
          "title": "Towards Comparable Knowledge Distillation in Semantic Image Segmentation. (arXiv:2309.03659v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03452",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhuokai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palani_H/0/1/0/all/0/1\">Harish Palani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Evans_L/0/1/0/all/0/1\">Lena Evans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toner_R/0/1/0/all/0/1\">Ruth Toner</a>",
          "description": "Multimodal models have gained significant success in recent years. Standard\nmultimodal approaches often assume unchanged modalities from training stage to\ninference stage. In practice, however, many scenarios fail to satisfy such\nassumptions with missing modalities during inference, leading to limitations on\nwhere multimodal models can be applied. While existing methods mitigate the\nproblem through reconstructing the missing modalities, it increases unnecessary\ncomputational cost, which could be just as critical, especially for large,\ndeployed systems. To solve the problem from both sides, we propose a novel\nguidance network that promotes knowledge sharing during training, taking\nadvantage of the multimodal representations to train better single-modality\nmodels for inference. Real-life experiment in violence detection shows that our\nproposed framework trains single-modality models that significantly outperform\nits traditionally trained counterparts while maintaining the same inference\ncost.",
          "link": "http://arxiv.org/abs/2309.03452",
          "publishedOn": "2023-09-09T00:40:35.264Z",
          "wordCount": null,
          "title": "Multi-Modality Guidance Network For Missing Modality Inference. (arXiv:2309.03452v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03315",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+DAmbrosio_D/0/1/0/all/0/1\">David B. D&#x27;Ambrosio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abelian_J/0/1/0/all/0/1\">Jonathan Abelian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abeyruwan_S/0/1/0/all/0/1\">Saminda Abeyruwan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_M/0/1/0/all/0/1\">Michael Ahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bewley_A/0/1/0/all/0/1\">Alex Bewley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boyd_J/0/1/0/all/0/1\">Justin Boyd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1\">Krzysztof Choromanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cortes_O/0/1/0/all/0/1\">Omar Cortes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coumans_E/0/1/0/all/0/1\">Erwin Coumans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_T/0/1/0/all/0/1\">Tianli Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Wenbo Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Graesser_L/0/1/0/all/0/1\">Laura Graesser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iscen_A/0/1/0/all/0/1\">Atil Iscen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaitly_N/0/1/0/all/0/1\">Navdeep Jaitly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_D/0/1/0/all/0/1\">Deepali Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kangaspunta_J/0/1/0/all/0/1\">Juhana Kangaspunta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kataoka_S/0/1/0/all/0/1\">Satoshi Kataoka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kouretas_G/0/1/0/all/0/1\">Gus Kouretas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuang_Y/0/1/0/all/0/1\">Yuheng Kuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lazic_N/0/1/0/all/0/1\">Nevena Lazic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lynch_C/0/1/0/all/0/1\">Corey Lynch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahjourian_R/0/1/0/all/0/1\">Reza Mahjourian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moore_S/0/1/0/all/0/1\">Sherry Q. Moore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thinh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oslund_K/0/1/0/all/0/1\">Ken Oslund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reed_B/0/1/0/all/0/1\">Barney J Reed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reymann_K/0/1/0/all/0/1\">Krista Reymann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanketi_P/0/1/0/all/0/1\">Pannag R. Sanketi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shankar_A/0/1/0/all/0/1\">Anish Shankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sermanet_P/0/1/0/all/0/1\">Pierre Sermanet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sindhwani_V/0/1/0/all/0/1\">Vikas Sindhwani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Avi Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vanhoucke_V/0/1/0/all/0/1\">Vincent Vanhoucke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vesom_G/0/1/0/all/0/1\">Grace Vesom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Peng Xu</a>",
          "description": "We present a deep-dive into a real-world robotic learning system that, in\nprevious work, was shown to be capable of hundreds of table tennis rallies with\na human and has the ability to precisely return the ball to desired targets.\nThis system puts together a highly optimized perception subsystem, a high-speed\nlow-latency robot controller, a simulation paradigm that can prevent damage in\nthe real world and also train policies for zero-shot transfer, and automated\nreal world environment resets that enable autonomous training and evaluation on\nphysical robots. We complement a complete system description, including\nnumerous design decisions that are typically not widely disseminated, with a\ncollection of studies that clarify the importance of mitigating various sources\nof latency, accounting for training and deployment distribution shifts,\nrobustness of the perception system, sensitivity to policy hyper-parameters,\nand choice of action space. A video demonstrating the components of the system\nand details of experimental results can be found at\nhttps://youtu.be/uFcnWjB42I0.",
          "link": "http://arxiv.org/abs/2309.03315",
          "publishedOn": "2023-09-09T00:40:35.259Z",
          "wordCount": null,
          "title": "Robotic Table Tennis: A Case Study into a High Speed Learning System. (arXiv:2309.03315v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03224",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haotian Xu</a>",
          "description": "Large language models (LLMs) exhibit impressive language understanding and\nin-context learning abilities including natural language processing (NLP) tasks\nand challenging mathematical reasoning. However, due to the lack of\nprocess-supervision, applying PLMs to mathematical reasoning tasks often fail\nto generate correct reasoning steps and final answer even though solutions have\nhigh probabilities. To unleash the mathematical reasoning of finetuned-LLMs\nwithout any further fineutuning steps, we propose a method to endow LLMs with\nimmediate reaction and delicate reasoning system via Monte Carlo Tree\nSearch(MCTS) and a light energy function to rank the decision steps. In\nparticular, We first re-formalize the finetuned-LLMs to a Residual-based Energy\nModel~(Residual-EBM) and apply noise contrastive estimation to estimate the\nparameters of energy function . Then we use MCTS with energy function as path\nverifier to search the output space and evaluating the reasoning path. Through\nextensive experiments on two mathematical reasoning benchmarks, namely GSM8k\nand MATH, we reveal the extraordinary capabilities of our method that improve\nthe pass@1 of the finetuned-model without further finetuning or RLHF alignment\nby a substantial margin.",
          "link": "http://arxiv.org/abs/2309.03224",
          "publishedOn": "2023-09-09T00:40:35.256Z",
          "wordCount": null,
          "title": "No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function. (arXiv:2309.03224v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03237",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hu_E/0/1/0/all/0/1\">Erdong Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yuxin Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1\">Anastasios Kyrillidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jermaine_C/0/1/0/all/0/1\">Chris Jermaine</a>",
          "description": "We carefully evaluate a number of algorithms for learning in a federated\nenvironment, and test their utility for a variety of image classification\ntasks. We consider many issues that have not been adequately considered before:\nwhether learning over data sets that do not have diverse sets of images affects\nthe results; whether to use a pre-trained feature extraction \"backbone\"; how to\nevaluate learner performance (we argue that classification accuracy is not\nenough), among others. Overall, across a wide variety of settings, we find that\nvertically decomposing a neural network seems to give the best results, and\noutperforms more standard reconciliation-used methods.",
          "link": "http://arxiv.org/abs/2309.03237",
          "publishedOn": "2023-09-09T00:40:35.255Z",
          "wordCount": null,
          "title": "Federated Learning Over Images: Vertical Decompositions and Pre-Trained Backbones Are Difficult to Beat. (arXiv:2309.03237v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03351",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1\">Li Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neto_J/0/1/0/all/0/1\">Jeova Farias Sales Rocha Neto</a>",
          "description": "The analysis of Synthetic Aperture Radar (SAR) imagery is an important step\nin remote sensing applications, and it is a challenging problem due to its\ninherent speckle noise. One typical solution is to model the data using the\n$G_I^0$ distribution and extract its roughness information, which in turn can\nbe used in posterior imaging tasks, such as segmentation, classification and\ninterpretation. This leads to the need of quick and reliable estimation of the\nroughness parameter from SAR data, especially with high resolution images.\nUnfortunately, traditional parameter estimation procedures are slow and prone\nto estimation failures. In this work, we proposed a neural network-based\nestimation framework that first learns how to predict underlying parameters of\n$G_I^0$ samples and then can be used to estimate the roughness of unseen data.\nWe show that this approach leads to an estimator that is quicker, yields less\nestimation error and is less prone to failures than the traditional estimation\nprocedures for this problem, even when we use a simple network. More\nimportantly, we show that this same methodology can be generalized to handle\nimage inputs and, even if trained on purely synthetic data for a few seconds,\nis able to perform real time pixel-wise roughness estimation for high\nresolution real SAR imagery.",
          "link": "http://arxiv.org/abs/2309.03351",
          "publishedOn": "2023-09-09T00:40:35.252Z",
          "wordCount": null,
          "title": "Using Neural Networks for Fast SAR Roughness Estimation of High Resolution Images. (arXiv:2309.03351v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03707",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Morales_K/0/1/0/all/0/1\">Katherine Morales</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Petetin_Y/0/1/0/all/0/1\">Yohan Petetin</a>",
          "description": "Triplet Markov chains are general generative models for sequential data which\ntake into account three kinds of random variables: (noisy) observations, their\nassociated discrete labels and latent variables which aim at strengthening the\ndistribution of the observations and their associated labels. However, in\npractice, we do not have at our disposal all the labels associated to the\nobservations to estimate the parameters of such models. In this paper, we\npropose a general framework based on a variational Bayesian inference to train\nparameterized triplet Markov chain models in a semi-supervised context. The\ngenerality of our approach enables us to derive semi-supervised algorithms for\na variety of generative models for sequential Bayesian classification.",
          "link": "http://arxiv.org/abs/2309.03707",
          "publishedOn": "2023-09-09T00:40:35.252Z",
          "wordCount": null,
          "title": "A Probabilistic Semi-Supervised Approach with Triplet Markov Chains. (arXiv:2309.03707v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03755",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ang_Y/0/1/0/all/0/1\">Yihao Ang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qiang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1\">Yifan Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tung_A/0/1/0/all/0/1\">Anthony K. H. Tung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhiyong Huang</a>",
          "description": "Synthetic Time Series Generation (TSG) is crucial in a range of applications,\nincluding data augmentation, anomaly detection, and privacy preservation.\nAlthough significant strides have been made in this field, existing methods\nexhibit three key limitations: (1) They often benchmark against similar model\ntypes, constraining a holistic view of performance capabilities. (2) The use of\nspecialized synthetic and private datasets introduces biases and hampers\ngeneralizability. (3) Ambiguous evaluation measures, often tied to custom\nnetworks or downstream tasks, hinder consistent and fair comparison.\n\nTo overcome these limitations, we introduce \\textsf{TSGBench}, the inaugural\nTSG Benchmark, designed for a unified and comprehensive assessment of TSG\nmethods. It comprises three modules: (1) a curated collection of publicly\navailable, real-world datasets tailored for TSG, together with a standardized\npreprocessing pipeline; (2) a comprehensive evaluation measures suite including\nvanilla measures, new distance-based assessments, and visualization tools; (3)\na pioneering generalization test rooted in Domain Adaptation (DA), compatible\nwith all methods. We have conducted extensive experiments across ten real-world\ndatasets from diverse domains, utilizing ten advanced TSG methods and twelve\nevaluation measures, all gauged through \\textsf{TSGBench}. The results\nhighlight its remarkable efficacy and consistency. More importantly,\n\\textsf{TSGBench} delivers a statistical breakdown of method rankings,\nilluminating performance variations across different datasets and measures, and\noffering nuanced insights into the effectiveness of each method.",
          "link": "http://arxiv.org/abs/2309.03755",
          "publishedOn": "2023-09-09T00:40:35.252Z",
          "wordCount": null,
          "title": "TSGBench: Time Series Generation Benchmark. (arXiv:2309.03755v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03244",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Korber_N/0/1/0/all/0/1\">Nikolai K&#xf6;rber</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kromer_E/0/1/0/all/0/1\">Eduard Kromer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Siebert_A/0/1/0/all/0/1\">Andreas Siebert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hauke_S/0/1/0/all/0/1\">Sascha Hauke</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mueller_Gritschneder_D/0/1/0/all/0/1\">Daniel Mueller-Gritschneder</a>",
          "description": "We introduce EGIC, a novel generative image compression method that allows\ntraversing the distortion-perception curve efficiently from a single model.\nSpecifically, we propose an implicitly encoded variant of image interpolation\nthat predicts the residual between a MSE-optimized and GAN-optimized decoder\noutput. On the receiver side, the user can then control the impact of the\nresidual on the GAN-based reconstruction. Together with improved GAN-based\nbuilding blocks, EGIC outperforms a wide-variety of perception-oriented and\ndistortion-oriented baselines, including HiFiC, MRIC and DIRAC, while\nperforming almost on par with VTM-20.0 on the distortion end. EGIC is simple to\nimplement, very lightweight (e.g. 0.18x model parameters compared to HiFiC) and\nprovides excellent interpolation characteristics, which makes it a promising\ncandidate for practical applications targeting the low bit range.",
          "link": "http://arxiv.org/abs/2309.03244",
          "publishedOn": "2023-09-09T00:40:35.251Z",
          "wordCount": null,
          "title": "EGIC: Enhanced Low-Bit-Rate Generative Image Compression Guided by Semantic Segmentation. (arXiv:2309.03244v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.12591",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pakbin_A/0/1/0/all/0/1\">Arash Pakbin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaochen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mortazavi_B/0/1/0/all/0/1\">Bobak J. Mortazavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Donald K.K. Lee</a>",
          "description": "Modern applications of survival analysis increasingly involve time-dependent\ncovariates. The Python package BoXHED2.0 is a tree-boosted hazard estimator\nthat is fully nonparametric, and is applicable to survival settings far more\ngeneral than right-censoring, including recurring events and competing risks.\nBoXHED2.0 is also scalable to the point of being on the same order of speed as\nparametric boosted survival models, in part because its core is written in C++\nand it also supports the use of GPUs and multicore CPUs. BoXHED2.0 is available\nfrom PyPI and also from www.github.com/BoXHED.",
          "link": "http://arxiv.org/abs/2103.12591",
          "publishedOn": "2023-09-09T00:40:35.251Z",
          "wordCount": null,
          "title": "BoXHED2.0: Scalable boosting of dynamic survival analysis. (arXiv:2103.12591v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.10226",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zheren Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1\">Zhiming Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lichi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_C/0/1/0/all/0/1\">Chenjin Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_X/0/1/0/all/0/1\">Xi Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Dongdong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiangyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yajia Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zaiyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chunling Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_D/0/1/0/all/0/1\">Dinggang Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1\">Jie-Zhi Cheng</a>",
          "description": "The deep learning technique has been shown to be effectively addressed\nseveral image analysis tasks in the computer-aided diagnosis scheme for\nmammography. The training of an efficacious deep learning model requires large\ndata with diverse styles and qualities. The diversity of data often comes from\nthe use of various scanners of vendors. But, in practice, it is impractical to\ncollect a sufficient amount of diverse data for training. To this end, a novel\ncontrastive learning is developed to equip the deep learning models with better\nstyle generalization capability. Specifically, the multi-style and multi-view\nunsupervised self-learning scheme is carried out to seek robust feature\nembedding against style diversity as a pretrained model. Afterward, the\npretrained network is further fine-tuned to the downstream tasks, e.g., mass\ndetection, matching, BI-RADS rating, and breast density classification. The\nproposed method has been evaluated extensively and rigorously with mammograms\nfrom various vendor style domains and several public datasets. The experimental\nresults suggest that the proposed domain generalization method can effectively\nimprove performance of four mammographic image tasks on the data from both seen\nand unseen domains, and outperform many state-of-the-art (SOTA) generalization\nmethods.",
          "link": "http://arxiv.org/abs/2304.10226",
          "publishedOn": "2023-09-09T00:40:35.251Z",
          "wordCount": null,
          "title": "Domain Generalization for Mammographic Image Analysis with Contrastive Learning. (arXiv:2304.10226v5 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03791",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Birrell_J/0/1/0/all/0/1\">Jeremiah Birrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ebrahimi_M/0/1/0/all/0/1\">Mohammadreza Ebrahimi</a>",
          "description": "We introduce the $ARMOR_D$ methods as novel approaches to enhancing the\nadversarial robustness of deep learning models. These methods are based on a\nnew class of optimal-transport-regularized divergences, constructed via an\ninfimal convolution between an information divergence and an optimal-transport\n(OT) cost. We use these as tools to enhance adversarial robustness by\nmaximizing the expected loss over a neighborhood of distributions, a technique\nknown as distributionally robust optimization. Viewed as a tool for\nconstructing adversarial samples, our method allows samples to be both\ntransported, according to the OT cost, and re-weighted, according to the\ninformation divergence. We demonstrate the effectiveness of our method on\nmalware detection and image recognition applications and find that, to our\nknowledge, it outperforms existing methods at enhancing the robustness against\nadversarial attacks. $ARMOR_D$ yields the robustified accuracy of $98.29\\%$\nagainst $FGSM$ and $98.18\\%$ against $PGD^{40}$ on the MNIST dataset, reducing\nthe error rate by more than $19.7\\%$ and $37.2\\%$ respectively compared to\nprior methods. Similarly, in malware detection, a discrete (binary) data\ndomain, $ARMOR_D$ improves the robustified accuracy under $rFGSM^{50}$ attack\ncompared to the previous best-performing adversarial training methods by\n$37.0\\%$ while lowering false negative and false positive rates by $51.1\\%$ and\n$57.53\\%$, respectively.",
          "link": "http://arxiv.org/abs/2309.03791",
          "publishedOn": "2023-09-09T00:40:35.246Z",
          "wordCount": null,
          "title": "Adversarially Robust Deep Learning with Optimal-Transport-Regularized Divergences. (arXiv:2309.03791v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.08643",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiaqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xingyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1\">Suhan Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Che_L/0/1/0/all/0/1\">Liwei Che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_L/0/1/0/all/0/1\">Lingjuan Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1\">Dongkuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1\">Fenglong Ma</a>",
          "description": "This paper focuses on addressing the practical yet challenging problem of\nmodel heterogeneity in federated learning, where clients possess models with\ndifferent network structures. To track this problem, we propose a novel\nframework called pFedHR, which leverages heterogeneous model reassembly to\nachieve personalized federated learning. In particular, we approach the problem\nof heterogeneous model personalization as a model-matching optimization task on\nthe server side. Moreover, pFedHR automatically and dynamically generates\ninformative and diverse personalized candidates with minimal human\nintervention. Furthermore, our proposed heterogeneous model reassembly\ntechnique mitigates the adverse impact introduced by using public data with\ndifferent distributions from the client data to a certain extent. Experimental\nresults demonstrate that pFedHR outperforms baselines on three datasets under\nboth IID and Non-IID settings. Additionally, pFedHR effectively reduces the\nadverse impact of using different public data and dynamically generates diverse\npersonalized models in an automated manner.",
          "link": "http://arxiv.org/abs/2308.08643",
          "publishedOn": "2023-09-09T00:40:35.246Z",
          "wordCount": null,
          "title": "Towards Personalized Federated Learning via Heterogeneous Model Reassembly. (arXiv:2308.08643v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03731",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bockel_Rickermann_C/0/1/0/all/0/1\">Christopher Bockel-Rickermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vanderschueren_T/0/1/0/all/0/1\">Toon Vanderschueren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berrevoets_J/0/1/0/all/0/1\">Jeroen Berrevoets</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verdonck_T/0/1/0/all/0/1\">Tim Verdonck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verbeke_W/0/1/0/all/0/1\">Wouter Verbeke</a>",
          "description": "Estimating the effects of treatments with an associated dose on an instance's\noutcome, the \"dose response\", is relevant in a variety of domains, from\nhealthcare to business, economics, and beyond. Such effects, also known as\ncontinuous-valued treatment effects, are typically estimated from observational\ndata, which may be subject to dose selection bias. This means that the\nallocation of doses depends on pre-treatment covariates. Previous studies have\nshown that conventional machine learning approaches fail to learn accurate\nindividual estimates of dose responses under the presence of dose selection\nbias. In this work, we propose CBRNet, a causal machine learning approach to\nestimate an individual dose response from observational data. CBRNet adopts the\nNeyman-Rubin potential outcome framework and extends the concept of balanced\nrepresentation learning for overcoming selection bias to continuous-valued\ntreatments. Our work is the first to apply representation balancing in a\ncontinuous-valued treatment setting. We evaluate our method on a newly proposed\nbenchmark. Our experiments demonstrate CBRNet's ability to accurately learn\ntreatment effects under selection bias and competitive performance with respect\nto other state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2309.03731",
          "publishedOn": "2023-09-09T00:40:35.244Z",
          "wordCount": null,
          "title": "Learning continuous-valued treatment effects through representation balancing. (arXiv:2309.03731v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2010.10274",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mesgaran_M/0/1/0/all/0/1\">Mahsa Mesgaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamza_A/0/1/0/all/0/1\">A. Ben Hamza</a>",
          "description": "Graph convolution is a fundamental building block for many deep neural\nnetworks on graph-structured data. In this paper, we introduce a simple, yet\nvery effective graph convolutional network with skip connections for\nsemi-supervised anomaly detection. The proposed layerwise propagation rule of\nour model is theoretically motivated by the concept of implicit fairing in\ngeometry processing, and comprises a graph convolution module for aggregating\ninformation from immediate node neighbors and a skip connection module for\ncombining layer-wise neighborhood representations. This propagation rule is\nderived from the iterative solution of the implicit fairing equation via the\nJacobi method. In addition to capturing information from distant graph nodes\nthrough skip connections between the network's layers, our approach exploits\nboth the graph structure and node features for learning discriminative node\nrepresentations. These skip connections are integrated by design in our\nproposed network architecture. The effectiveness of our model is demonstrated\nthrough extensive experiments on five benchmark datasets, achieving better or\ncomparable anomaly detection results against strong baseline methods. We also\ndemonstrate through an ablation study that skip connection helps improve the\nmodel performance.",
          "link": "http://arxiv.org/abs/2010.10274",
          "publishedOn": "2023-09-09T00:40:35.243Z",
          "wordCount": null,
          "title": "Graph Fairing Convolutional Networks for Anomaly Detection. (arXiv:2010.10274v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.04014",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_K/0/1/0/all/0/1\">Kshitij Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Therien_B/0/1/0/all/0/1\">Benjamin Th&#xe9;rien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibrahim_A/0/1/0/all/0/1\">Adam Ibrahim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richter_M/0/1/0/all/0/1\">Mats L. Richter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anthony_Q/0/1/0/all/0/1\">Quentin Anthony</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belilovsky_E/0/1/0/all/0/1\">Eugene Belilovsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1\">Irina Rish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lesort_T/0/1/0/all/0/1\">Timoth&#xe9;e Lesort</a>",
          "description": "Large language models (LLMs) are routinely pre-trained on billions of tokens,\nonly to restart the process over again once new data becomes available. A much\ncheaper and more efficient solution would be to enable the continual\npre-training of these models, i.e. updating pre-trained models with new data\ninstead of re-training them from scratch. However, the distribution shift\ninduced by novel data typically results in degraded performance on past data.\nTaking a step towards efficient continual pre-training, in this work, we\nexamine the effect of different warm-up strategies. Our hypothesis is that the\nlearning rate must be re-increased to improve compute efficiency when training\non a new dataset. We study the warmup phase of models pre-trained on the Pile\n(upstream data, 300B tokens) as we continue to pre-train on SlimPajama\n(downstream data, 297B tokens), following a linear warmup and cosine decay\nschedule. We conduct all experiments on the Pythia 410M language model\narchitecture and evaluate performance through validation perplexity. We\nexperiment with different pre-training checkpoints, various maximum learning\nrates, and various warmup lengths. Our results show that while rewarming models\nfirst increases the loss on upstream and downstream data, in the longer run it\nimproves the downstream performance, outperforming models trained from\nscratch$\\unicode{x2013}$even for a large downstream dataset.",
          "link": "http://arxiv.org/abs/2308.04014",
          "publishedOn": "2023-09-09T00:40:35.242Z",
          "wordCount": null,
          "title": "Continual Pre-Training of Large Language Models: How to (re)warm your model?. (arXiv:2308.04014v2 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03561",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zakrisson_H/0/1/0/all/0/1\">Henning Zakrisson</a>",
          "description": "This paper introduces the Trinary decision tree, an algorithm designed to\nimprove the handling of missing data in decision tree regressors and\nclassifiers. Unlike other approaches, the Trinary decision tree does not assume\nthat missing values contain any information about the response. Both\ntheoretical calculations on estimator bias and numerical illustrations using\nreal data sets are presented to compare its performance with established\nalgorithms in different missing data scenarios (Missing Completely at Random\n(MCAR), and Informative Missingness (IM)). Notably, the Trinary tree\noutperforms its peers in MCAR settings, especially when data is only missing\nout-of-sample, while lacking behind in IM settings. A hybrid model, the\nTrinaryMIA tree, which combines the Trinary tree and the Missing In Attributes\n(MIA) approach, shows robust performance in all types of missingness. Despite\nthe potential drawback of slower training speed, the Trinary tree offers a\npromising and more accurate method of handling missing data in decision tree\nalgorithms.",
          "link": "http://arxiv.org/abs/2309.03561",
          "publishedOn": "2023-09-09T00:40:35.241Z",
          "wordCount": null,
          "title": "Trinary Decision Trees for missing value handling. (arXiv:2309.03561v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03307",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Wang_H/0/1/0/all/0/1\">Haiyan Wang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Bayro_A/0/1/0/all/0/1\">Allison Bayro</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Yamamoto_N/0/1/0/all/0/1\">Nao Yamamoto</a>",
          "description": "We present a novel approach for efficiently generating quantum feature maps\nfor quantum-enhanced support vector machines, a kernel-based classifier,\nenabling access to high-dimensional Hilbert space. Our method employs a\nmulti-objective genetic algorithm that simultaneously maximizes classification\naccuracy while minimizing both the local and non-local gate costs of the\nquantum feature map's circuit. To achieve this, we define distinct fitness\nfunctions for local gates and entanglement gates. Comparisons with classical\nclassifiers are given in order to understand the advantages of using quantum\nmachine learning. Surprisingly, our experiments reveal that the optimal\nconfiguration of quantum circuits for the quantum kernel method incorporates a\nproportional number of non-local gates for entanglement, contrary to previous\nliterature where non-local gates were largely suppressed.\n\nFurthermore, we demonstrate that the separability indexes of data can be\neffectively leveraged to determine the number of non-local gates required for\nthe quantum support vector machine's feature maps. This insight can\nsignificantly aid in selecting appropriate parameters, such as the entanglement\nparameter, in various quantum programming packages like quiskit.org based on\ndata analysis. Our findings offer valuable guidance for enhancing the\nefficiency and accuracy of quantum machine learning algorithms.",
          "link": "http://arxiv.org/abs/2309.03307",
          "publishedOn": "2023-09-09T00:40:35.236Z",
          "wordCount": null,
          "title": "Generating quantum feature maps using multi-objective genetic algorithm. (arXiv:2309.03307v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.02335",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1\">Zhengyang Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ju_W/0/1/0/all/0/1\">Wei Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yifang Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1\">Xiao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Ming Zhang</a>",
          "description": "Graph classification is a crucial task in many real-world multimedia\napplications, where graphs can represent various multimedia data types such as\nimages, videos, and social networks. Previous efforts have applied graph neural\nnetworks (GNNs) in balanced situations where the class distribution is\nbalanced. However, real-world data typically exhibit long-tailed class\ndistributions, resulting in a bias towards the head classes when using GNNs and\nlimited generalization ability over the tail classes. Recent approaches mainly\nfocus on re-balancing different classes during model training, which fails to\nexplicitly introduce new knowledge and sacrifices the performance of the head\nclasses. To address these drawbacks, we propose a novel framework called\nRetrieval Augmented Hybrid Network (RAHNet) to jointly learn a robust feature\nextractor and an unbiased classifier in a decoupled manner. In the feature\nextractor training stage, we develop a graph retrieval module to search for\nrelevant graphs that directly enrich the intra-class diversity for the tail\nclasses. Moreover, we innovatively optimize a category-centered supervised\ncontrastive loss to obtain discriminative representations, which is more\nsuitable for long-tailed scenarios. In the classifier fine-tuning stage, we\nbalance the classifier weights with two weight regularization techniques, i.e.,\nMax-norm and weight decay. Experiments on various popular benchmarks verify the\nsuperiority of the proposed method against state-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2308.02335",
          "publishedOn": "2023-09-09T00:40:35.235Z",
          "wordCount": null,
          "title": "RAHNet: Retrieval Augmented Hybrid Network for Long-tailed Graph Classification. (arXiv:2308.02335v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.02976",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schumacher_P/0/1/0/all/0/1\">Pierre Schumacher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geijtenbeek_T/0/1/0/all/0/1\">Thomas Geijtenbeek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caggiano_V/0/1/0/all/0/1\">Vittorio Caggiano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Vikash Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmitt_S/0/1/0/all/0/1\">Syn Schmitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martius_G/0/1/0/all/0/1\">Georg Martius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haeufle_D/0/1/0/all/0/1\">Daniel F. B. Haeufle</a>",
          "description": "Humans excel at robust bipedal walking in complex natural environments. In\neach step, they adequately tune the interaction of biomechanical muscle\ndynamics and neuronal signals to be robust against uncertainties in ground\nconditions. However, it is still not fully understood how the nervous system\nresolves the musculoskeletal redundancy to solve the multi-objective control\nproblem considering stability, robustness, and energy efficiency. In computer\nsimulations, energy minimization has been shown to be a successful optimization\ntarget, reproducing natural walking with trajectory optimization or\nreflex-based control methods. However, these methods focus on particular\nmotions at a time and the resulting controllers are limited when compensating\nfor perturbations. In robotics, reinforcement learning~(RL) methods recently\nachieved highly stable (and efficient) locomotion on quadruped systems, but the\ngeneration of human-like walking with bipedal biomechanical models has required\nextensive use of expert data sets. This strong reliance on demonstrations often\nresults in brittle policies and limits the application to new behaviors,\nespecially considering the potential variety of movements for high-dimensional\nmusculoskeletal models in 3D. Achieving natural locomotion with RL without\nsacrificing its incredible robustness might pave the way for a novel approach\nto studying human walking in complex natural environments. Videos:\nhttps://sites.google.com/view/naturalwalkingrl",
          "link": "http://arxiv.org/abs/2309.02976",
          "publishedOn": "2023-09-09T00:40:35.229Z",
          "wordCount": null,
          "title": "Natural and Robust Walking using Reinforcement Learning without Demonstrations in High-Dimensional Musculoskeletal Models. (arXiv:2309.02976v2 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.08754",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Sungduk Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hannah_W/0/1/0/all/0/1\">Walter M. Hannah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_L/0/1/0/all/0/1\">Liran Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jerry Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhouri_M/0/1/0/all/0/1\">Mohamed Aziz Bhouri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1\">Ritwik Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lutjens_B/0/1/0/all/0/1\">Bj&#xf6;rn L&#xfc;tjens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Will_J/0/1/0/all/0/1\">Justus C. Will</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Behrens_G/0/1/0/all/0/1\">Gunnar Behrens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Busecke_J/0/1/0/all/0/1\">Julius J. M. Busecke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loose_N/0/1/0/all/0/1\">Nora Loose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stern_C/0/1/0/all/0/1\">Charles Stern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beucler_T/0/1/0/all/0/1\">Tom Beucler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harrop_B/0/1/0/all/0/1\">Bryce E. Harrop</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilman_B/0/1/0/all/0/1\">Benjamin R. Hilman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jenney_A/0/1/0/all/0/1\">Andrea M. Jenney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferretti_S/0/1/0/all/0/1\">Savannah L. Ferretti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Nana Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brenowitz_N/0/1/0/all/0/1\">Noah D. Brenowitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eyring_V/0/1/0/all/0/1\">Veronika Eyring</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geneva_N/0/1/0/all/0/1\">Nicholas Geneva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gentine_P/0/1/0/all/0/1\">Pierre Gentine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandt_S/0/1/0/all/0/1\">Stephan Mandt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pathak_J/0/1/0/all/0/1\">Jaideep Pathak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subramaniam_A/0/1/0/all/0/1\">Akshay Subramaniam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vondrick_C/0/1/0/all/0/1\">Carl Vondrick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1\">Rose Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zanna_L/0/1/0/all/0/1\">Laure Zanna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1\">Tian Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abernathey_R/0/1/0/all/0/1\">Ryan P. Abernathey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_F/0/1/0/all/0/1\">Fiaz Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bader_D/0/1/0/all/0/1\">David C. Bader</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldi_P/0/1/0/all/0/1\">Pierre Baldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barnes_E/0/1/0/all/0/1\">Elizabeth A. Barnes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bretherton_C/0/1/0/all/0/1\">Christopher S. Bretherton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caldwell_P/0/1/0/all/0/1\">Peter M. Caldwell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chuang_W/0/1/0/all/0/1\">Wayne Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yilun Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iglesias_Suarez_F/0/1/0/all/0/1\">Fernando Iglesias-Suarez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jantre_S/0/1/0/all/0/1\">Sanket Jantre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kashinath_K/0/1/0/all/0/1\">Karthik Kashinath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khairoutdinov_M/0/1/0/all/0/1\">Marat Khairoutdinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurth_T/0/1/0/all/0/1\">Thorsten Kurth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lutsko_N/0/1/0/all/0/1\">Nicholas J. Lutsko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_P/0/1/0/all/0/1\">Po-Lun Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mooers_G/0/1/0/all/0/1\">Griffin Mooers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neelin_J/0/1/0/all/0/1\">J. David Neelin</a>, et al. (7 additional authors not shown)",
          "description": "Modern climate projections lack adequate spatial and temporal resolution due\nto computational constraints. A consequence is inaccurate and imprecise\npredictions of critical processes such as storms. Hybrid methods that combine\nphysics with machine learning (ML) have introduced a new generation of higher\nfidelity climate simulators that can sidestep Moore's Law by outsourcing\ncompute-hungry, short, high-resolution simulations to ML emulators. However,\nthis hybrid ML-physics simulation approach requires domain-specific treatment\nand has been inaccessible to ML experts because of lack of training data and\nrelevant, easy-to-use workflows. We present ClimSim, the largest-ever dataset\ndesigned for hybrid ML-physics research. It comprises multi-scale climate\nsimulations, developed by a consortium of climate scientists and ML\nresearchers. It consists of 5.7 billion pairs of multivariate input and output\nvectors that isolate the influence of locally-nested, high-resolution,\nhigh-fidelity physics on a host climate simulator's macro-scale physical state.\n\nThe dataset is global in coverage, spans multiple years at high sampling\nfrequency, and is designed such that resulting emulators are compatible with\ndownstream coupling into operational climate simulators. We implement a range\nof deterministic and stochastic regression baselines to highlight the ML\nchallenges and their scoring. The data\n(https://huggingface.co/datasets/LEAP/ClimSim_high-res,\nhttps://huggingface.co/datasets/LEAP/ClimSim_low-res, and\nhttps://huggingface.co/datasets/LEAP/ClimSim_low-res_aqua-planet) and code\n(https://leap-stc.github.io/ClimSim) are released openly to support the\ndevelopment of hybrid ML-physics and high-fidelity climate simulations for the\nbenefit of science and society.",
          "link": "http://arxiv.org/abs/2306.08754",
          "publishedOn": "2023-09-09T00:40:35.227Z",
          "wordCount": null,
          "title": "ClimSim: An open large-scale dataset for training high-resolution physics emulators in hybrid multi-scale climate simulators. (arXiv:2306.08754v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.13596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tarzanagh_D/0/1/0/all/0/1\">Davoud Ataee Tarzanagh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yingcong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuechen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oymak_S/0/1/0/all/0/1\">Samet Oymak</a>",
          "description": "Attention mechanism is a central component of the transformer architecture\nwhich led to the phenomenal success of large language models. However, the\ntheoretical principles underlying the attention mechanism are poorly\nunderstood, especially its nonconvex optimization dynamics. In this work, we\nexplore the seminal softmax-attention model $f(\\boldsymbol{X})=\\langle\n\\boldsymbol{Xv}, \\texttt{softmax}(\\boldsymbol{XWp})\\rangle$, where\n$\\boldsymbol{X}$ is the token sequence and\n$(\\boldsymbol{v},\\boldsymbol{W},\\boldsymbol{p})$ are trainable parameters. We\nprove that running gradient descent on $\\boldsymbol{p}$, or equivalently\n$\\boldsymbol{W}$, converges in direction to a max-margin solution that\nseparates $\\textit{locally-optimal}$ tokens from non-optimal ones. This clearly\nformalizes attention as an optimal token selection mechanism. Remarkably, our\nresults are applicable to general data and precisely characterize\n$\\textit{optimality}$ of tokens in terms of the value embeddings\n$\\boldsymbol{Xv}$ and problem geometry. We also provide a broader\nregularization path analysis that establishes the margin maximizing nature of\nattention even for nonlinear prediction heads. When optimizing $\\boldsymbol{v}$\nand $\\boldsymbol{p}$ simultaneously with logistic loss, we identify conditions\nunder which the regularization paths directionally converge to their respective\nhard-margin SVM solutions where $\\boldsymbol{v}$ separates the input features\nbased on their labels. Interestingly, the SVM formulation of $\\boldsymbol{p}$\nis influenced by the support vector geometry of $\\boldsymbol{v}$. Finally, we\nverify our theoretical findings via numerical experiments and provide insights.",
          "link": "http://arxiv.org/abs/2306.13596",
          "publishedOn": "2023-09-09T00:40:35.222Z",
          "wordCount": null,
          "title": "Max-Margin Token Selection in Attention Mechanism. (arXiv:2306.13596v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03843",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Mousavi_Hosseini_A/0/1/0/all/0/1\">Alireza Mousavi-Hosseini</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wu_D/0/1/0/all/0/1\">Denny Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1\">Taiji Suzuki</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Erdogdu_M/0/1/0/all/0/1\">Murat A. Erdogdu</a>",
          "description": "Recent works have demonstrated that the sample complexity of gradient-based\nlearning of single index models, i.e. functions that depend on a 1-dimensional\nprojection of the input data, is governed by their information exponent.\nHowever, these results are only concerned with isotropic data, while in\npractice the input often contains additional structure which can implicitly\nguide the algorithm. In this work, we investigate the effect of a spiked\ncovariance structure and reveal several interesting phenomena. First, we show\nthat in the anisotropic setting, the commonly used spherical gradient dynamics\nmay fail to recover the true direction, even when the spike is perfectly\naligned with the target direction. Next, we show that appropriate weight\nnormalization that is reminiscent of batch normalization can alleviate this\nissue. Further, by exploiting the alignment between the (spiked) input\ncovariance and the target, we obtain improved sample complexity compared to the\nisotropic case. In particular, under the spiked model with a suitably large\nspike, the sample complexity of gradient-based training can be made independent\nof the information exponent while also outperforming lower bounds for\nrotationally invariant kernel methods.",
          "link": "http://arxiv.org/abs/2309.03843",
          "publishedOn": "2023-09-09T00:40:35.220Z",
          "wordCount": null,
          "title": "Gradient-Based Feature Learning under Structured Data. (arXiv:2309.03843v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.03680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhongzhan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1\">Senwei Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haizhao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1\">Liang Lin</a>",
          "description": "The large-scale simulation of dynamical systems is critical in numerous\nscientific and engineering disciplines. However, traditional numerical solvers\nare limited by the choice of step sizes when estimating integration, resulting\nin a trade-off between accuracy and computational efficiency. To address this\nchallenge, we introduce a deep learning-based corrector called Neural Vector\n(NeurVec), which can compensate for integration errors and enable larger time\nstep sizes in simulations. Our extensive experiments on a variety of complex\ndynamical system benchmarks demonstrate that NeurVec exhibits remarkable\ngeneralization capability on a continuous phase space, even when trained using\nlimited and discrete data. NeurVec significantly accelerates traditional\nsolvers, achieving speeds tens to hundreds of times faster while maintaining\nhigh levels of accuracy and stability. Moreover, NeurVec's simple-yet-effective\ndesign, combined with its ease of implementation, has the potential to\nestablish a new paradigm for fast-solving differential equations based on deep\nlearning.",
          "link": "http://arxiv.org/abs/2208.03680",
          "publishedOn": "2023-09-09T00:40:35.220Z",
          "wordCount": null,
          "title": "Accelerating Numerical Solvers for Large-Scale Simulation of Dynamical System via NeurVec. (arXiv:2208.03680v2 [cs.CE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03754",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tosi_M/0/1/0/all/0/1\">Mauro DL Tosi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theobald_M/0/1/0/all/0/1\">Martin Theobald</a>",
          "description": "Over the last decades, Stochastic Gradient Descent (SGD) has been intensively\nstudied by the Machine Learning community. Despite its versatility and\nexcellent performance, the optimization of large models via SGD still is a\ntime-consuming task. To reduce training time, it is common to distribute the\ntraining process across multiple devices. Recently, it has been shown that the\nconvergence of asynchronous SGD (ASGD) will always be faster than mini-batch\nSGD. However, despite these improvements in the theoretical bounds, most ASGD\nconvergence-rate proofs still rely on a centralized parameter server, which is\nprone to become a bottleneck when scaling out the gradient computations across\nmany distributed processes.\n\nIn this paper, we present a novel convergence-rate analysis for decentralized\nand asynchronous SGD (DASGD) which does not require partial synchronization\namong nodes nor restrictive network topologies. Specifically, we provide a\nbound of $\\mathcal{O}(\\sigma\\epsilon^{-2}) +\n\\mathcal{O}(QS_{avg}\\epsilon^{-3/2}) + \\mathcal{O}(S_{avg}\\epsilon^{-1})$ for\nthe convergence rate of DASGD, where $S_{avg}$ is the average staleness between\nmodels, $Q$ is a constant that bounds the norm of the gradients, and $\\epsilon$\nis a (small) error that is allowed within the bound. Furthermore, when\ngradients are not bounded, we prove the convergence rate of DASGD to be\n$\\mathcal{O}(\\sigma\\epsilon^{-2}) +\n\\mathcal{O}(\\sqrt{\\hat{S}_{avg}\\hat{S}_{max}}\\epsilon^{-1})$, with\n$\\hat{S}_{max}$ and $\\hat{S}_{avg}$ representing a loose version of the average\nand maximum staleness, respectively. Our convergence proof holds for a fixed\nstepsize and any non-convex, homogeneous, and L-smooth objective function. We\nanticipate that our results will be of high relevance for the adoption of DASGD\nby a broad community of researchers and developers.",
          "link": "http://arxiv.org/abs/2309.03754",
          "publishedOn": "2023-09-09T00:40:35.219Z",
          "wordCount": null,
          "title": "Convergence Analysis of Decentralized ASGD. (arXiv:2309.03754v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06555",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shijun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jianfeng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hongkai Zhao</a>",
          "description": "This paper explores the expressive power of deep neural networks for a\ndiverse range of activation functions. An activation function set $\\mathscr{A}$\nis defined to encompass the majority of commonly used activation functions,\nsuch as $\\mathtt{ReLU}$, $\\mathtt{LeakyReLU}$, $\\mathtt{ReLU}^2$,\n$\\mathtt{ELU}$, $\\mathtt{SELU}$, $\\mathtt{Softplus}$, $\\mathtt{GELU}$,\n$\\mathtt{SiLU}$, $\\mathtt{Swish}$, $\\mathtt{Mish}$, $\\mathtt{Sigmoid}$,\n$\\mathtt{Tanh}$, $\\mathtt{Arctan}$, $\\mathtt{Softsign}$, $\\mathtt{dSiLU}$, and\n$\\mathtt{SRS}$. We demonstrate that for any activation function $\\varrho\\in\n\\mathscr{A}$, a $\\mathtt{ReLU}$ network of width $N$ and depth $L$ can be\napproximated to arbitrary precision by a $\\varrho$-activated network of width\n$4N$ and depth $2L$ on any bounded set. This finding enables the extension of\nmost approximation results achieved with $\\mathtt{ReLU}$ networks to a wide\nvariety of other activation functions, at the cost of slightly larger\nconstants.",
          "link": "http://arxiv.org/abs/2307.06555",
          "publishedOn": "2023-09-09T00:40:35.218Z",
          "wordCount": null,
          "title": "Deep Network Approximation: Beyond ReLU to Diverse Activation Functions. (arXiv:2307.06555v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03883",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1\">Yung-Sung Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yujia Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Hongyin Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1\">James Glass</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pengcheng He</a>",
          "description": "Despite their impressive capabilities, large language models (LLMs) are prone\nto hallucinations, i.e., generating content that deviates from facts seen\nduring pretraining. We propose a simple decoding strategy for reducing\nhallucinations with pretrained LLMs that does not require conditioning on\nretrieved external knowledge nor additional fine-tuning. Our approach obtains\nthe next-token distribution by contrasting the differences in logits obtained\nfrom projecting the later layers versus earlier layers to the vocabulary space,\nexploiting the fact that factual knowledge in an LLMs has generally been shown\nto be localized to particular transformer layers. We find that this Decoding by\nContrasting Layers (DoLa) approach is able to better surface factual knowledge\nand reduce the generation of incorrect facts. DoLa consistently improves the\ntruthfulness across multiple choices tasks and open-ended generation tasks, for\nexample improving the performance of LLaMA family models on TruthfulQA by\n12-17% absolute points, demonstrating its potential in making LLMs reliably\ngenerate truthful facts.",
          "link": "http://arxiv.org/abs/2309.03883",
          "publishedOn": "2023-09-09T00:40:35.217Z",
          "wordCount": null,
          "title": "DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models. (arXiv:2309.03883v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.12198",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Leyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhi-Qin John Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_T/0/1/0/all/0/1\">Tao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yaoyu Zhang</a>",
          "description": "In recent years, understanding the implicit regularization of neural networks\n(NNs) has become a central task in deep learning theory. However, implicit\nregularization is itself not completely defined and well understood. In this\nwork, we attempt to mathematically define and study implicit regularization.\nImportantly, we explore the limitations of a common approach to characterizing\nimplicit regularization using data-independent functions. We propose two\ndynamical mechanisms, i.e., Two-point and One-point Overlapping mechanisms,\nbased on which we provide two recipes for producing classes of\none-hidden-neuron NNs that provably cannot be fully characterized by a type of\nor all data-independent functions. Following the previous works, our results\nfurther emphasize the profound data dependency of implicit regularization in\ngeneral, inspiring us to study in detail the data dependency of NN implicit\nregularization in the future.",
          "link": "http://arxiv.org/abs/2201.12198",
          "publishedOn": "2023-09-09T00:40:35.217Z",
          "wordCount": null,
          "title": "Limitation of Characterizing Implicit Regularization by Data-independent Functions. (arXiv:2201.12198v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03354",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wu_M/0/1/0/all/0/1\">Mingqi Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_Q/0/1/0/all/0/1\">Qiang Sun</a>",
          "description": "Interpolators are unstable. For example, the mininum $\\ell_2$ norm least\nsquare interpolator exhibits unbounded test errors when dealing with noisy\ndata. In this paper, we study how ensemble stabilizes and thus improves the\ngeneralization performance, measured by the out-of-sample prediction risk, of\nan individual interpolator. We focus on bagged linear interpolators, as bagging\nis a popular randomization-based ensemble method that can be implemented in\nparallel. We introduce the multiplier-bootstrap-based bagged least square\nestimator, which can then be formulated as an average of the sketched least\nsquare estimators. The proposed multiplier bootstrap encompasses the classical\nbootstrap with replacement as a special case, along with a more intriguing\nvariant which we call the Bernoulli bootstrap.\n\nFocusing on the proportional regime where the sample size scales\nproportionally with the feature dimensionality, we investigate the\nout-of-sample prediction risks of the sketched and bagged least square\nestimators in both underparametrized and overparameterized regimes. Our results\nreveal the statistical roles of sketching and bagging. In particular, sketching\nmodifies the aspect ratio and shifts the interpolation threshold of the minimum\n$\\ell_2$ norm estimator. However, the risk of the sketched estimator continues\nto be unbounded around the interpolation threshold due to excessive variance.\nIn stark contrast, bagging effectively mitigates this variance, leading to a\nbounded limiting out-of-sample prediction risk. To further understand this\nstability improvement property, we establish that bagging acts as a form of\nimplicit regularization, substantiated by the equivalence of the bagged\nestimator with its explicitly regularized counterpart. We also discuss several\nextensions.",
          "link": "http://arxiv.org/abs/2309.03354",
          "publishedOn": "2023-09-09T00:40:35.216Z",
          "wordCount": null,
          "title": "Ensemble linear interpolators: The role of ensembling. (arXiv:2309.03354v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.04031",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xiao Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yongkai Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1\">Shuhan Yuan</a>",
          "description": "Due to a wide spectrum of applications in the real world, such as security,\nfinancial surveillance, and health risk, various deep anomaly detection models\nhave been proposed and achieved state-of-the-art performance. However, besides\nbeing effective, in practice, the practitioners would further like to know what\ncauses the abnormal outcome and how to further fix it. In this work, we propose\nRootCLAM, which aims to achieve Root Cause Localization and Anomaly Mitigation\nfrom a causal perspective. Especially, we formulate anomalies caused by\nexternal interventions on the normal causal mechanism and aim to locate the\nabnormal features with external interventions as root causes. After that, we\nfurther propose an anomaly mitigation approach that aims to recommend\nmitigation actions on abnormal features to revert the abnormal outcomes such\nthat the counterfactuals guided by the causal mechanism are normal. Experiments\non three datasets show that our approach can locate the root causes and further\nflip the abnormal labels.",
          "link": "http://arxiv.org/abs/2212.04031",
          "publishedOn": "2023-09-09T00:40:35.215Z",
          "wordCount": null,
          "title": "On Root Cause Localization and Anomaly Mitigation through Causal Inference. (arXiv:2212.04031v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03664",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Conti_F/0/1/0/all/0/1\">Francesco Conti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banchelli_M/0/1/0/all/0/1\">Martina Banchelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bessi_V/0/1/0/all/0/1\">Valentina Bessi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cecchi_C/0/1/0/all/0/1\">Cristina Cecchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiti_F/0/1/0/all/0/1\">Fabrizio Chiti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colantonio_S/0/1/0/all/0/1\">Sara Colantonio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DAndrea_C/0/1/0/all/0/1\">Cristiano D&#x27;Andrea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Angelis_M/0/1/0/all/0/1\">Marella de Angelis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moroni_D/0/1/0/all/0/1\">Davide Moroni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nacmias_B/0/1/0/all/0/1\">Benedetta Nacmias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pascali_M/0/1/0/all/0/1\">Maria Antonietta Pascali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sorbi_S/0/1/0/all/0/1\">Sandro Sorbi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matteini_P/0/1/0/all/0/1\">Paolo Matteini</a>",
          "description": "The cerebrospinal fluid (CSF) of 19 subjects who received a clinical\ndiagnosis of Alzheimer's disease (AD) as well as of 5 pathological controls\nhave been collected and analysed by Raman spectroscopy (RS). We investigated\nwhether the raw and preprocessed Raman spectra could be used to distinguish AD\nfrom controls. First, we applied standard Machine Learning (ML) methods\nobtaining unsatisfactory results. Then, we applied ML to a set of topological\ndescriptors extracted from raw spectra, achieving a very good classification\naccuracy (>87%). Although our results are preliminary, they indicate that RS\nand topological analysis together may provide an effective combination to\nconfirm or disprove a clinical diagnosis of AD. The next steps will include\nenlarging the dataset of CSF samples to validate the proposed method better\nand, possibly, to understand if topological data analysis could support the\ncharacterization of AD subtypes.",
          "link": "http://arxiv.org/abs/2309.03664",
          "publishedOn": "2023-09-09T00:40:35.212Z",
          "wordCount": null,
          "title": "Alzheimer Disease Detection from Raman Spectroscopy of the Cerebrospinal Fluid via Topological Machine Learning. (arXiv:2309.03664v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03825",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daryanavard_S/0/1/0/all/0/1\">Sama Daryanavard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Porr_B/0/1/0/all/0/1\">Bernd Porr</a>",
          "description": "Deep neural networks employing error back-propagation for learning can suffer\nfrom exploding and vanishing gradient problems. Numerous solutions have been\nproposed such as normalisation techniques or limiting activation functions to\nlinear rectifying units. In this work we follow a different approach which is\nparticularly applicable to closed-loop learning of forward models where\nback-propagation makes exclusive use of the sign of the error signal to prime\nthe learning, whilst a global relevance signal modulates the rate of learning.\nThis is inspired by the interaction between local plasticity and a global\nneuromodulation. For example, whilst driving on an empty road, one can allow\nfor slow step-wise optimisation of actions, whereas, at a busy junction, an\nerror must be corrected at once. Hence, the error is the priming signal and the\nintensity of the experience is a modulating factor in the weight change. The\nadvantages of this Prime and Modulate paradigm is twofold: it is free from\nnormalisation and it makes use of relevant cues from the environment to enrich\nthe learning. We present a mathematical derivation of the learning rule in\nz-space and demonstrate the real-time performance with a robotic platform. The\nresults show a significant improvement in the speed of convergence compared to\nthat of the conventional back-propagation.",
          "link": "http://arxiv.org/abs/2309.03825",
          "publishedOn": "2023-09-09T00:40:35.211Z",
          "wordCount": null,
          "title": "Prime and Modulate Learning: Generation of forward models with signed back-propagation and environmental cues. (arXiv:2309.03825v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1907.04483",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Freedman_R/0/1/0/all/0/1\">Roy S. Freedman</a>",
          "description": "The exclusive or (xor) function is one of the simplest examples that\nillustrate why nonlinear feedforward networks are superior to linear regression\nfor machine learning applications. We review the xor representation and\napproximation problems and discuss their solutions in terms of probabilistic\nlogic and associative copula functions. After briefly reviewing the\nspecification of feedforward networks, we compare the dynamics of learned error\nsurfaces with different activation functions such as RELU and tanh through a\nset of colorful three-dimensional charts. The copula representations extend xor\nfrom Boolean to real values, thereby providing a convenient way to demonstrate\nthe concept of cross-validation on in-sample and out-sample data sets. Our\napproach is pedagogical and is meant to be a machine learning prolegomenon.",
          "link": "http://arxiv.org/abs/1907.04483",
          "publishedOn": "2023-09-09T00:40:35.209Z",
          "wordCount": null,
          "title": "Copula Representations and Error Surface Projections for the Exclusive Or Problem. (arXiv:1907.04483v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.03428",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Liu_J/0/1/0/all/0/1\">Junyu Liu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Liu_M/0/1/0/all/0/1\">Minzhao Liu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Liu_J/0/1/0/all/0/1\">Jin-Peng Liu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Ye_Z/0/1/0/all/0/1\">Ziyu Ye</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Wang_Y/0/1/0/all/0/1\">Yunfei Wang</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Alexeev_Y/0/1/0/all/0/1\">Yuri Alexeev</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Eisert_J/0/1/0/all/0/1\">Jens Eisert</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Jiang_L/0/1/0/all/0/1\">Liang Jiang</a>",
          "description": "Large machine learning models are revolutionary technologies of artificial\nintelligence whose bottlenecks include huge computational expenses, power, and\ntime used both in the pre-training and fine-tuning process. In this work, we\nshow that fault-tolerant quantum computing could possibly provide provably\nefficient resolutions for generic (stochastic) gradient descent algorithms,\nscaling as $\\mathcal{O}(T^2 \\times \\text{polylog}(n))$, where $n$ is the size\nof the models and $T$ is the number of iterations in the training, as long as\nthe models are both sufficiently dissipative and sparse, with small learning\nrates. Based on earlier efficient quantum algorithms for dissipative\ndifferential equations, we find and prove that similar algorithms work for\n(stochastic) gradient descent, the primary algorithm for machine learning. In\npractice, we benchmark instances of large machine learning models from 7\nmillion to 103 million parameters. We find that, in the context of sparse\ntraining, a quantum enhancement is possible at the early stage of learning\nafter model pruning, motivating a sparse parameter download and re-upload\nscheme. Our work shows solidly that fault-tolerant quantum algorithms could\npotentially contribute to most state-of-the-art, large-scale machine-learning\nproblems.",
          "link": "http://arxiv.org/abs/2303.03428",
          "publishedOn": "2023-09-09T00:40:35.209Z",
          "wordCount": null,
          "title": "Towards provably efficient quantum algorithms for large-scale machine-learning models. (arXiv:2303.03428v4 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.08901",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Piccialli_V/0/1/0/all/0/1\">Veronica Piccialli</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sudoso_A/0/1/0/all/0/1\">Antonio M. Sudoso</a>",
          "description": "The minimum sum-of-squares clustering (MSSC), or k-means type clustering, has\nbeen recently extended to exploit prior knowledge on the cardinality of each\ncluster. Such knowledge is used to increase performance as well as solution\nquality. In this paper, we propose a global optimization approach based on the\nbranch-and-cut technique to solve the cardinality-constrained MSSC. For the\nlower bound routine, we use the semidefinite programming (SDP) relaxation\nrecently proposed by Rujeerapaiboon et al. [SIAM J. Optim. 29(2), 1211-1239,\n(2019)]. However, this relaxation can be used in a branch-and-cut method only\nfor small-size instances. Therefore, we derive a new SDP relaxation that scales\nbetter with the instance size and the number of clusters. In both cases, we\nstrengthen the bound by adding polyhedral cuts. Benefiting from a tailored\nbranching strategy which enforces pairwise constraints, we reduce the\ncomplexity of the problems arising in the children nodes. For the upper bound,\ninstead, we present a local search procedure that exploits the solution of the\nSDP relaxation solved at each node. Computational results show that the\nproposed algorithm globally solves, for the first time, real-world instances of\nsize 10 times larger than those solved by state-of-the-art exact methods.",
          "link": "http://arxiv.org/abs/2209.08901",
          "publishedOn": "2023-09-09T00:40:35.191Z",
          "wordCount": null,
          "title": "Global Optimization for Cardinality-constrained Minimum Sum-of-Squares Clustering via Semidefinite Programming. (arXiv:2209.08901v3 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.12760",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gordon_O/0/1/0/all/0/1\">Ori Gordon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avrahami_O/0/1/0/all/0/1\">Omri Avrahami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lischinski_D/0/1/0/all/0/1\">Dani Lischinski</a>",
          "description": "Editing a local region or a specific object in a 3D scene represented by a\nNeRF or consistently blending a new realistic object into the scene is\nchallenging, mainly due to the implicit nature of the scene representation. We\npresent Blended-NeRF, a robust and flexible framework for editing a specific\nregion of interest in an existing NeRF scene, based on text prompts, along with\na 3D ROI box. Our method leverages a pretrained language-image model to steer\nthe synthesis towards a user-provided text prompt, along with a 3D MLP model\ninitialized on an existing NeRF scene to generate the object and blend it into\na specified region in the original scene. We allow local editing by localizing\na 3D ROI box in the input scene, and blend the content synthesized inside the\nROI with the existing scene using a novel volumetric blending technique. To\nobtain natural looking and view-consistent results, we leverage existing and\nnew geometric priors and 3D augmentations for improving the visual fidelity of\nthe final result. We test our framework both qualitatively and quantitatively\non a variety of real 3D scenes and text prompts, demonstrating realistic\nmulti-view consistent results with much flexibility and diversity compared to\nthe baselines. Finally, we show the applicability of our framework for several\n3D editing applications, including adding new objects to a scene,\nremoving/replacing/altering existing objects, and texture conversion.",
          "link": "http://arxiv.org/abs/2306.12760",
          "publishedOn": "2023-09-09T00:40:35.165Z",
          "wordCount": null,
          "title": "Blended-NeRF: Zero-Shot Object Generation and Blending in Existing Neural Radiance Fields. (arXiv:2306.12760v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.14971",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xumin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1\">Yongming Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiwen Lu</a>",
          "description": "With the overwhelming trend of mask image modeling led by MAE, generative\npre-training has shown a remarkable potential to boost the performance of\nfundamental models in 2D vision. However, in 3D vision, the over-reliance on\nTransformer-based backbones and the unordered nature of point clouds have\nrestricted the further development of generative pre-training. In this paper,\nwe propose a novel 3D-to-2D generative pre-training method that is adaptable to\nany point cloud model. We propose to generate view images from different\ninstructed poses via the cross-attention mechanism as the pre-training scheme.\nGenerating view images has more precise supervision than its point cloud\ncounterpart, thus assisting 3D backbones to have a finer comprehension of the\ngeometrical structure and stereoscopic relations of the point cloud.\nExperimental results have proved the superiority of our proposed 3D-to-2D\ngenerative pre-training over previous pre-training methods. Our method is also\neffective in boosting the performance of architecture-oriented approaches,\nachieving state-of-the-art performance when fine-tuning on ScanObjectNN\nclassification and ShapeNetPart segmentation tasks. Code is available at\nhttps://github.com/wangzy22/TAP.",
          "link": "http://arxiv.org/abs/2307.14971",
          "publishedOn": "2023-09-09T00:40:35.165Z",
          "wordCount": null,
          "title": "Take-A-Photo: 3D-to-2D Generative Pre-training of Point Cloud Models. (arXiv:2307.14971v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03839",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jensen Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Siddharth Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berseth_G/0/1/0/all/0/1\">Glen Berseth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1\">Anca D. Dragan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>",
          "description": "Adaptive interfaces can help users perform sequential decision-making tasks\nlike robotic teleoperation given noisy, high-dimensional command signals (e.g.,\nfrom a brain-computer interface). Recent advances in human-in-the-loop machine\nlearning enable such systems to improve by interacting with users, but tend to\nbe limited by the amount of data that they can collect from individual users in\npractice. In this paper, we propose a reinforcement learning algorithm to\naddress this by training an interface to map raw command signals to actions\nusing a combination of offline pre-training and online fine-tuning. To address\nthe challenges posed by noisy command signals and sparse rewards, we develop a\nnovel method for representing and inferring the user's long-term intent for a\ngiven trajectory. We primarily evaluate our method's ability to assist users\nwho can only communicate through noisy, high-dimensional input channels through\na user study in which 12 participants performed a simulated navigation task by\nusing their eye gaze to modulate a 128-dimensional command signal from their\nwebcam. The results show that our method enables successful goal navigation\nmore often than a baseline directional interface, by learning to denoise user\ncommands signals and provide shared autonomy assistance. We further evaluate on\na simulated Sawyer pushing task with eye gaze control, and the Lunar Lander\ngame with simulated user commands, and find that our method improves over\nbaseline interfaces in these domains as well. Extensive ablation experiments\nwith simulated user commands empirically motivate each component of our method.",
          "link": "http://arxiv.org/abs/2309.03839",
          "publishedOn": "2023-09-09T00:40:35.160Z",
          "wordCount": null,
          "title": "Bootstrapping Adaptive Human-Machine Interfaces with Offline Reinforcement Learning. (arXiv:2309.03839v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03812",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Picetti_F/0/1/0/all/0/1\">Francesco Picetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deshpande_S/0/1/0/all/0/1\">Shrinath Deshpande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leban_J/0/1/0/all/0/1\">Jonathan Leban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahtalebi_S/0/1/0/all/0/1\">Soroosh Shahtalebi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_J/0/1/0/all/0/1\">Jay Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jing_P/0/1/0/all/0/1\">Peifeng Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chunpu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metze_C/0/1/0/all/0/1\">Charles Metze III</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Cameron Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laidlaw_C/0/1/0/all/0/1\">Cera Laidlaw</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warren_J/0/1/0/all/0/1\">James Warren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huynh_K/0/1/0/all/0/1\">Kathy Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Page_R/0/1/0/all/0/1\">River Page</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hogins_J/0/1/0/all/0/1\">Jonathan Hogins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crespi_A/0/1/0/all/0/1\">Adam Crespi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganguly_S/0/1/0/all/0/1\">Sujoy Ganguly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ebadi_S/0/1/0/all/0/1\">Salehe Erfanian Ebadi</a>",
          "description": "We present a novel human body model formulated by an extensive set of\nanthropocentric measurements, which is capable of generating a wide range of\nhuman body shapes and poses. The proposed model enables direct modeling of\nspecific human identities through a deep generative architecture, which can\nproduce humans in any arbitrary pose. It is the first of its kind to have been\ntrained end-to-end using only synthetically generated data, which not only\nprovides highly accurate human mesh representations but also allows for precise\nanthropometry of the body. Moreover, using a highly diverse animation library,\nwe articulated our synthetic humans' body and hands to maximize the diversity\nof the learnable priors for model training. Our model was trained on a dataset\nof $100k$ procedurally-generated posed human meshes and their corresponding\nanthropometric measurements. Our synthetic data generator can be used to\ngenerate millions of unique human identities and poses for non-commercial\nacademic research purposes.",
          "link": "http://arxiv.org/abs/2309.03812",
          "publishedOn": "2023-09-09T00:40:35.143Z",
          "wordCount": null,
          "title": "AnthroNet: Conditional Generation of Humans via Anthropometrics. (arXiv:2309.03812v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.07853",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Prabakaran_B/0/1/0/all/0/1\">Bharath Srinivas Prabakaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ostrowski_E/0/1/0/all/0/1\">Erik Ostrowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafique_M/0/1/0/all/0/1\">Muhammad Shafique</a>",
          "description": "Weakly Supervised Semantic Segmentation (WSSS) relying only on image-level\nsupervision is a promising approach to deal with the need for Segmentation\nnetworks, especially for generating a large number of pixel-wise masks in a\ngiven dataset. However, most state-of-the-art image-level WSSS techniques lack\nan understanding of the geometric features embedded in the images since the\nnetwork cannot derive any object boundary information from just image-level\nlabels. We define a boundary here as the line separating an object and its\nbackground, or two different objects. To address this drawback, we are\nproposing our novel ReFit framework, which deploys state-of-the-art class\nactivation maps combined with various post-processing techniques in order to\nachieve fine-grained higher-accuracy segmentation masks. To achieve this, we\ninvestigate a state-of-the-art unsupervised segmentation network that can be\nused to construct a boundary map, which enables ReFit to predict object\nlocations with sharper boundaries. By applying our method to WSSS predictions,\nwe achieved up to 10% improvement over the current state-of-the-art WSSS\nmethods for medical imaging. The framework is open-source, to ensure that our\nresults are reproducible, and accessible online at\nhttps://github.com/bharathprabakaran/ReFit.",
          "link": "http://arxiv.org/abs/2303.07853",
          "publishedOn": "2023-09-09T00:40:35.142Z",
          "wordCount": null,
          "title": "ReFit: A Framework for Refinement of Weakly Supervised Semantic Segmentation using Object Border Fitting for Medical Images. (arXiv:2303.07853v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.09882",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ben_Dov_O/0/1/0/all/0/1\">Omri Ben-Dov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1\">Pravir Singh Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abrevaya_V/0/1/0/all/0/1\">Victoria Abrevaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Black_M/0/1/0/all/0/1\">Michael J. Black</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_P/0/1/0/all/0/1\">Partha Ghosh</a>",
          "description": "Generative Adversarial Networks (GANs) can produce high-quality samples, but\ndo not provide an estimate of the probability density around the samples.\nHowever, it has been noted that maximizing the log-likelihood within an\nenergy-based setting can lead to an adversarial framework where the\ndiscriminator provides unnormalized density (often called energy). We further\ndevelop this perspective, incorporate importance sampling, and show that 1)\nWasserstein GAN performs a biased estimate of the partition function, and we\npropose instead to use an unbiased estimator; and 2) when optimizing for\nlikelihood, one must maximize generator entropy. This is hypothesized to\nprovide a better mode coverage. Different from previous works, we explicitly\ncompute the density of the generated samples. This is the key enabler to\ndesigning an unbiased estimator of the partition function and computation of\nthe generator entropy term. The generator density is obtained via a new type of\nflow network, called one-way flow network, that is less constrained in terms of\narchitecture, as it does not require a tractable inverse function. Our\nexperimental results show that our method converges faster, produces comparable\nsample quality to GANs with similar architecture, successfully avoids\nover-fitting to commonly used datasets and produces smooth low-dimensional\nlatent representations of the training data.",
          "link": "http://arxiv.org/abs/2307.09882",
          "publishedOn": "2023-09-09T00:40:35.136Z",
          "wordCount": null,
          "title": "Adversarial Likelihood Estimation With One-Way Flows. (arXiv:2307.09882v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.12774",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carlsson_E/0/1/0/all/0/1\">Emil Carlsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_D/0/1/0/all/0/1\">Debabrota Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johansson_F/0/1/0/all/0/1\">Fredrik D. Johansson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubhashi_D/0/1/0/all/0/1\">Devdatt Dubhashi</a>",
          "description": "We address the problem of identifying the optimal policy with a fixed\nconfidence level in a multi-armed bandit setup, when \\emph{the arms are subject\nto linear constraints}. Unlike the standard best-arm identification problem\nwhich is well studied, the optimal policy in this case may not be deterministic\nand could mix between several arms. This changes the geometry of the problem\nwhich we characterize via an information-theoretic lower bound. We introduce\ntwo asymptotically optimal algorithms for this setting, one based on the\nTrack-and-Stop method and the other based on a game-theoretic approach. Both\nthese algorithms try to track an optimal allocation based on the lower bound\nand computed by a weighted projection onto the boundary of a normal cone.\nFinally, we provide empirical results that validate our bounds and visualize\nhow constraints change the hardness of the problem.",
          "link": "http://arxiv.org/abs/2306.12774",
          "publishedOn": "2023-09-09T00:40:35.102Z",
          "wordCount": null,
          "title": "Pure Exploration in Bandits with Linear Constraints. (arXiv:2306.12774v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03879",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ericsson_L/0/1/0/all/0/1\">Linus Ericsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Da Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hospedales_T/0/1/0/all/0/1\">Timothy M. Hospedales</a>",
          "description": "Distribution shifts are all too common in real-world applications of machine\nlearning. Domain adaptation (DA) aims to address this by providing various\nframeworks for adapting models to the deployment data without using labels.\nHowever, the domain shift scenario raises a second more subtle challenge: the\ndifficulty of performing hyperparameter optimisation (HPO) for these adaptation\nalgorithms without access to a labelled validation set. The unclear validation\nprotocol for DA has led to bad practices in the literature, such as performing\nHPO using the target test labels when, in real-world scenarios, they are not\navailable. This has resulted in over-optimism about DA research progress\ncompared to reality. In this paper, we analyse the state of DA when using good\nevaluation practice, by benchmarking a suite of candidate validation criteria\nand using them to assess popular adaptation algorithms. We show that there are\nchallenges across all three branches of domain adaptation methodology including\nUnsupervised Domain Adaptation (UDA), Source-Free Domain Adaptation (SFDA), and\nTest Time Adaptation (TTA). While the results show that realistically\nachievable performance is often worse than expected, they also show that using\nproper validation splits is beneficial, as well as showing that some previously\nunexplored validation metrics provide the best options to date. Altogether, our\nimproved practices covering data, training, validation and hyperparameter\noptimisation form a new rigorous pipeline to improve benchmarking, and hence\nresearch progress, within this important field going forward.",
          "link": "http://arxiv.org/abs/2309.03879",
          "publishedOn": "2023-09-09T00:40:35.090Z",
          "wordCount": null,
          "title": "Better Practices for Domain Adaptation. (arXiv:2309.03879v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Martin_P/0/1/0/all/0/1\">Pierre-Etienne Martin</a>",
          "description": "This paper presents a bonobo detection and classification pipeline built from\nthe commonly used machine learning methods. Such application is motivated by\nthe need to test bonobos in their enclosure using touch screen devices without\nhuman assistance. This work introduces a newly acquired dataset based on bonobo\nrecordings generated semi-automatically. The recordings are weakly labelled and\nfed to a macaque detector in order to spatially detect the individual present\nin the video. Handcrafted features coupled with different classification\nalgorithms and deep-learning methods using a ResNet architecture are\ninvestigated for bonobo identification. Performance is compared in terms of\nclassification accuracy on the splits of the database using different data\nseparation methods. We demonstrate the importance of data preparation and how a\nwrong data separation can lead to false good results. Finally, after a\nmeaningful separation of the data, the best classification performance is\nobtained using a fine-tuned ResNet model and reaches 75% of accuracy.",
          "link": "http://arxiv.org/abs/2309.03671",
          "publishedOn": "2023-09-09T00:40:35.086Z",
          "wordCount": null,
          "title": "Dataset Generation and Bonobo Classification from Weakly Labelled Videos. (arXiv:2309.03671v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03672",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Baumann_D/0/1/0/all/0/1\">Dominik Baumann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kowalczyk_K/0/1/0/all/0/1\">Krzysztof Kowalczyk</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tiels_K/0/1/0/all/0/1\">Koen Tiels</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wachel_P/0/1/0/all/0/1\">Pawe&#x142; Wachel</a>",
          "description": "Safety is an essential asset when learning control policies for physical\nsystems, as violating safety constraints during training can lead to expensive\nhardware damage. In response to this need, the field of safe learning has\nemerged with algorithms that can provide probabilistic safety guarantees\nwithout knowledge of the underlying system dynamics. Those algorithms often\nrely on Gaussian process inference. Unfortunately, Gaussian process inference\nscales cubically with the number of data points, limiting applicability to\nhigh-dimensional and embedded systems. In this paper, we propose a safe\nlearning algorithm that provides probabilistic safety guarantees but leverages\nthe Nadaraya-Watson estimator instead of Gaussian processes. For the\nNadaraya-Watson estimator, we can reach logarithmic scaling with the number of\ndata points. We provide theoretical guarantees for the estimates, embed them\ninto a safe learning algorithm, and show numerical experiments on a simulated\nseven-degrees-of-freedom robot manipulator.",
          "link": "http://arxiv.org/abs/2309.03672",
          "publishedOn": "2023-09-09T00:40:35.079Z",
          "wordCount": null,
          "title": "A computationally lightweight safe learning algorithm. (arXiv:2309.03672v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Edelman_B/0/1/0/all/0/1\">Benjamin L. Edelman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1\">Surbhi Goel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1\">Sham Kakade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malach_E/0/1/0/all/0/1\">Eran Malach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Cyril Zhang</a>",
          "description": "This work investigates the nuanced algorithm design choices for deep learning\nin the presence of computational-statistical gaps. We begin by considering\noffline sparse parity learning, a supervised classification problem which\nadmits a statistical query lower bound for gradient-based training of a\nmultilayer perceptron. This lower bound can be interpreted as a multi-resource\ntradeoff frontier: successful learning can only occur if one is sufficiently\nrich (large model), knowledgeable (large dataset), patient (many training\niterations), or lucky (many random guesses). We show, theoretically and\nexperimentally, that sparse initialization and increasing network width yield\nsignificant improvements in sample efficiency in this setting. Here, width\nplays the role of parallel search: it amplifies the probability of finding\n\"lottery ticket\" neurons, which learn sparse features more sample-efficiently.\nFinally, we show that the synthetic sparse parity task can be useful as a proxy\nfor real problems requiring axis-aligned feature learning. We demonstrate\nimproved sample efficiency on tabular classification benchmarks by using wide,\nsparsely-initialized MLP models; these networks sometimes outperform tuned\nrandom forests.",
          "link": "http://arxiv.org/abs/2309.03800",
          "publishedOn": "2023-09-09T00:40:35.079Z",
          "wordCount": null,
          "title": "Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and Luck. (arXiv:2309.03800v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03779",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Ti Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1\">Man Lin</a>",
          "description": "Small devices are frequently used in IoT and smart-city applications to\nperform periodic dedicated tasks with soft deadlines. This work focuses on\ndeveloping methods to derive efficient power-management methods for periodic\ntasks on small devices. We first study the limitations of the existing Linux\nbuilt-in methods used in small devices. We illustrate three typical\nworkload/system patterns that are challenging to manage with Linux's built-in\nsolutions. We develop a reinforcement-learning-based technique with temporal\nencoding to derive an effective DVFS governor even with the presence of the\nthree system patterns. The derived governor uses only one performance counter,\nthe same as the built-in Linux mechanism, and does not require an explicit task\nmodel for the workload. We implemented a prototype system on the Nvidia Jetson\nNano Board and experimented with it with six applications, including two\nself-designed and four benchmark applications. Under different deadline\nconstraints, our approach can quickly derive a DVFS governor that can adapt to\nperformance requirements and outperform the built-in Linux approach in energy\nsaving. On Mibench workloads, with performance slack ranging from 0.04 s to 0.4\ns, the proposed method can save 3% - 11% more energy compared to Ondemand.\nAudioReg and FaceReg applications tested have 5%- 14% energy-saving\nimprovement. We have open-sourced the implementation of our in-kernel quantized\nneural network engine. The codebase can be found at:\nhttps://github.com/coladog/tinyagent.",
          "link": "http://arxiv.org/abs/2309.03779",
          "publishedOn": "2023-09-09T00:40:35.077Z",
          "wordCount": null,
          "title": "CPU frequency scheduling of real-time applications on embedded devices with temporal encoding-based deep reinforcement learning. (arXiv:2309.03779v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03607",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Marchiori_F/0/1/0/all/0/1\">Francesco Marchiori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conti_M/0/1/0/all/0/1\">Mauro Conti</a>",
          "description": "Lithium-ion (Li-ion) batteries are the primary power source in various\napplications due to their high energy and power density. Their market was\nestimated to be up to 48 billion U.S. dollars in 2022. However, the widespread\nadoption of Li-ion batteries has resulted in counterfeit cell production, which\ncan pose safety hazards to users. Counterfeit cells can cause explosions or\nfires, and their prevalence in the market makes it difficult for users to\ndetect fake cells. Indeed, current battery authentication methods can be\nsusceptible to advanced counterfeiting techniques and are often not adaptable\nto various cells and systems. In this paper, we improve the state of the art on\nbattery authentication by proposing two novel methodologies, DCAuth and\nEISthentication, which leverage the internal characteristics of each cell\nthrough Machine Learning models. Our methods automatically authenticate\nlithium-ion battery models and architectures using data from their regular\nusage without the need for any external device. They are also resilient to the\nmost common and critical counterfeit practices and can scale to several\nbatteries and devices. To evaluate the effectiveness of our proposed\nmethodologies, we analyze time-series data from a total of 20 datasets that we\nhave processed to extract meaningful features for our analysis. Our methods\nachieve high accuracy in battery authentication for both architectures (up to\n0.99) and models (up to 0.96). Moreover, our methods offer comparable\nidentification performances. By using our proposed methodologies, manufacturers\ncan ensure that devices only use legitimate batteries, guaranteeing the\noperational state of any system and safety measures for the users.",
          "link": "http://arxiv.org/abs/2309.03607",
          "publishedOn": "2023-09-09T00:40:35.072Z",
          "wordCount": null,
          "title": "Your Battery Is a Blast! Safeguarding Against Counterfeit Batteries with Authentication. (arXiv:2309.03607v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hao Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pengyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_M/0/1/0/all/0/1\">Meng Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_Z/0/1/0/all/0/1\">Zhiyuan Ning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pengfei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuanchun Zhou</a>",
          "description": "Temporal Knowledge Graph (TKG) is an extension of traditional Knowledge Graph\n(KG) that incorporates the dimension of time. Reasoning on TKGs is a crucial\ntask that aims to predict future facts based on historical occurrences. The key\nchallenge lies in uncovering structural dependencies within historical\nsubgraphs and temporal patterns. Most existing approaches model TKGs relying on\nentity modeling, as nodes in the graph play a crucial role in knowledge\nrepresentation. However, the real-world scenario often involves an extensive\nnumber of entities, with new entities emerging over time. This makes it\nchallenging for entity-dependent methods to cope with extensive volumes of\nentities, and effectively handling newly emerging entities also becomes a\nsignificant challenge. Therefore, we propose Temporal Inductive Path Neural\nNetwork (TiPNN), which models historical information in an entity-independent\nperspective. Specifically, TiPNN adopts a unified graph, namely history\ntemporal graph, to comprehensively capture and encapsulate information from\nhistory. Subsequently, we utilize the defined query-aware temporal paths to\nmodel historical path information related to queries on history temporal graph\nfor the reasoning. Extensive experiments illustrate that the proposed model not\nonly attains significant performance enhancements but also handles inductive\nsettings, while additionally facilitating the provision of reasoning evidence\nthrough history temporal graphs.",
          "link": "http://arxiv.org/abs/2309.03251",
          "publishedOn": "2023-09-09T00:40:35.051Z",
          "wordCount": null,
          "title": "Temporal Inductive Path Neural Network for Temporal Knowledge Graph Reasoning. (arXiv:2309.03251v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03535",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Khan_T/0/1/0/all/0/1\">Tariq M. Khan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Arsalan_M/0/1/0/all/0/1\">Muhammad Arsalan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Iqbal_S/0/1/0/all/0/1\">Shahzaib Iqbal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Razzak_I/0/1/0/all/0/1\">Imran Razzak</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Meijering_E/0/1/0/all/0/1\">Erik Meijering</a>",
          "description": "Diseases such as diabetic retinopathy and age-related macular degeneration\npose a significant risk to vision, highlighting the importance of precise\nsegmentation of retinal vessels for the tracking and diagnosis of progression.\nHowever, existing vessel segmentation methods that heavily rely on\nencoder-decoder structures struggle to capture contextual information about\nretinal vessel configurations, leading to challenges in reconciling semantic\ndisparities between encoder and decoder features. To address this, we propose a\nnovel feature enhancement segmentation network (FES-Net) that achieves accurate\npixel-wise segmentation without requiring additional image enhancement steps.\nFES-Net directly processes the input image and utilizes four prompt\nconvolutional blocks (PCBs) during downsampling, complemented by a shallow\nupsampling approach to generate a binary mask for each class. We evaluate the\nperformance of FES-Net on four publicly available state-of-the-art datasets:\nDRIVE, STARE, CHASE, and HRF. The evaluation results clearly demonstrate the\nsuperior performance of FES-Net compared to other competitive approaches\ndocumented in the existing literature.",
          "link": "http://arxiv.org/abs/2309.03535",
          "publishedOn": "2023-09-09T00:40:35.048Z",
          "wordCount": null,
          "title": "Feature Enhancer Segmentation Network (FES-Net) for Vessel Segmentation. (arXiv:2309.03535v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.00452",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Qilin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhengyuan Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haipeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_W/0/1/0/all/0/1\">W.K. Chan</a>",
          "description": "Patch robustness certification ensures no patch within a given bound on a\nsample can manipulate a deep learning model to predict a different label.\nHowever, existing techniques cannot certify samples that cannot meet their\nstrict bars at the classifier or patch region levels. This paper proposes\nMajorCert. MajorCert firstly finds all possible label sets manipulatable by the\nsame patch region on the same sample across the underlying classifiers, then\nenumerates their combinations element-wise, and finally checks whether the\nmajority invariant of all these combinations is intact to certify samples.",
          "link": "http://arxiv.org/abs/2308.00452",
          "publishedOn": "2023-09-09T00:40:34.934Z",
          "wordCount": null,
          "title": "A Majority Invariant Approach to Patch Robustness Certification for Deep Learning Models. (arXiv:2308.00452v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">John Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dun_C/0/1/0/all/0/1\">Chen Dun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1\">Anastasios Kyrillidis</a>",
          "description": "Advances in Semi-Supervised Learning (SSL) have almost entirely closed the\ngap between SSL and Supervised Learning at a fraction of the number of labels.\nHowever, recent performance improvements have often come \\textit{at the cost of\nsignificantly increased training computation}. To address this, we propose\nCurriculum Batch Size (CBS), \\textit{an unlabeled batch size curriculum which\nexploits the natural training dynamics of deep neural networks.} A small\nunlabeled batch size is used in the beginning of training and is gradually\nincreased to the end of training. A fixed curriculum is used regardless of\ndataset, model or number of epochs, and reduced training computations is\ndemonstrated on all settings. We apply CBS, strong labeled augmentation,\nCurriculum Pseudo Labeling (CPL) \\citep{FlexMatch} to FixMatch \\citep{FixMatch}\nand term the new SSL algorithm Fast FixMatch. We perform an ablation study to\nshow that strong labeled augmentation and/or CPL do not significantly reduce\ntraining computations, but, in synergy with CBS, they achieve optimal\nperformance. Fast FixMatch also achieves substantially higher data utilization\ncompared to previous state-of-the-art. Fast FixMatch achieves between\n$2.1\\times$ - $3.4\\times$ reduced training computations on CIFAR-10 with all\nbut 40, 250 and 4000 labels removed, compared to vanilla FixMatch, while\nattaining the same cited state-of-the-art error rate \\citep{FixMatch}. Similar\nresults are achieved for CIFAR-100, SVHN and STL-10. Finally, Fast MixMatch\nachieves between $2.6\\times$ - $3.3\\times$ reduced training computations in\nfederated SSL tasks and online/streaming learning SSL tasks, which further\ndemonstrate the generializbility of Fast MixMatch to different scenarios and\ntasks.",
          "link": "http://arxiv.org/abs/2309.03469",
          "publishedOn": "2023-09-09T00:40:34.876Z",
          "wordCount": null,
          "title": "Fast FixMatch: Faster Semi-Supervised Learning with Curriculum Batch Size. (arXiv:2309.03469v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_A/0/1/0/all/0/1\">Ajitesh Srivastava</a>",
          "description": "Measuring distance or similarity between time-series data is a fundamental\naspect of many applications including classification and clustering. Existing\nmeasures may fail to capture similarities due to local trends (shapes) and may\neven produce misleading results. Our goal is to develop a measure that looks\nfor similar trends occurring around similar times and is easily interpretable\nfor researchers in applied domains. This is particularly useful for\napplications where time-series have a sequence of meaningful local trends that\nare ordered, such as in epidemics (a surge to an increase to a peak to a\ndecrease). We propose a novel measure, DTW+S, which creates an interpretable\n\"closeness-preserving\" matrix representation of the time-series, where each\ncolumn represents local trends, and then it applies Dynamic Time Warping to\ncompute distances between these matrices. We present a theoretical analysis\nthat supports the choice of this representation. We demonstrate the utility of\nDTW+S in ensemble building and clustering of epidemic curves. We also\ndemonstrate that our approach results in better classification compared to\nDynamic Time Warping for a class of datasets, particularly when local trends\nrather than scale play a decisive role.",
          "link": "http://arxiv.org/abs/2309.03579",
          "publishedOn": "2023-09-09T00:40:34.873Z",
          "wordCount": null,
          "title": "DTW+S: Shape-based Comparison of Time-series with Ordered Local Trend. (arXiv:2309.03579v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.03944",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agiza_A/0/1/0/all/0/1\">Ahmed Agiza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_R/0/1/0/all/0/1\">Rajarshi Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ene_T/0/1/0/all/0/1\">Teodor Dumitru Ene</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Godil_S/0/1/0/all/0/1\">Saad Godil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reda_S/0/1/0/all/0/1\">Sherief Reda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1\">Bryan Catanzaro</a>",
          "description": "In this work, we introduce GraPhSyM, a Graph Attention Network (GATv2) model\nfor fast and accurate estimation of post-physical synthesis circuit delay and\narea metrics from pre-physical synthesis circuit netlists. Once trained,\nGraPhSyM provides accurate visibility of final design metrics to early EDA\nstages, such as logic synthesis, without running the slow physical synthesis\nflow, enabling global co-optimization across stages. Additionally, the swift\nand precise feedback provided by GraPhSyM is instrumental for\nmachine-learning-based EDA optimization frameworks. Given a gate-level netlist\nof a circuit represented as a graph, GraPhSyM utilizes graph structure,\nconnectivity, and electrical property features to predict the impact of\nphysical synthesis transformations such as buffer insertion and gate sizing.\nWhen trained on a dataset of 6000 prefix adder designs synthesized at an\naggressive delay target, GraPhSyM can accurately predict the post-synthesis\ndelay (98.3%) and area (96.1%) metrics of unseen adders with a fast 0.22s\ninference time. Furthermore, we illustrate the compositionality of GraPhSyM by\nemploying the model trained on a fixed delay target to accurately anticipate\npost-synthesis metrics at a variety of unseen delay targets. Lastly, we report\npromising generalization capabilities of the GraPhSyM model when it is\nevaluated on circuits different from the adders it was exclusively trained on.\nThe results show the potential for GraPhSyM to serve as a powerful tool for\nadvanced optimization techniques and as an oracle for EDA machine learning\nframeworks.",
          "link": "http://arxiv.org/abs/2308.03944",
          "publishedOn": "2023-09-09T00:40:34.829Z",
          "wordCount": null,
          "title": "GraPhSyM: Graph Physical Synthesis Model. (arXiv:2308.03944v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03710",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moskovitz_T/0/1/0/all/0/1\">Ted Moskovitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hromadka_S/0/1/0/all/0/1\">Samo Hromadka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Touati_A/0/1/0/all/0/1\">Ahmed Touati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borsa_D/0/1/0/all/0/1\">Diana Borsa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahani_M/0/1/0/all/0/1\">Maneesh Sahani</a>",
          "description": "A common setting in multitask reinforcement learning (RL) demands that an\nagent rapidly adapt to various stationary reward functions randomly sampled\nfrom a fixed distribution. In such situations, the successor representation\n(SR) is a popular framework which supports rapid policy evaluation by\ndecoupling a policy's expected discounted, cumulative state occupancies from a\nspecific reward function. However, in the natural world, sequential tasks are\nrarely independent, and instead reflect shifting priorities based on the\navailability and subjective perception of rewarding stimuli. Reflecting this\ndisjunction, in this paper we study the phenomenon of diminishing marginal\nutility and introduce a novel state representation, the $\\lambda$\nrepresentation ($\\lambda$R) which, surprisingly, is required for policy\nevaluation in this setting and which generalizes the SR as well as several\nother state representations from the literature. We establish the $\\lambda$R's\nformal properties and examine its normative advantages in the context of\nmachine learning, as well as its usefulness for studying natural behaviors,\nparticularly foraging.",
          "link": "http://arxiv.org/abs/2309.03710",
          "publishedOn": "2023-09-09T00:40:34.824Z",
          "wordCount": null,
          "title": "A State Representation for Diminishing Rewards. (arXiv:2309.03710v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.09096",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hashemifar_S/0/1/0/all/0/1\">Somaye Hashemifar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iriondo_C/0/1/0/all/0/1\">Claudia Iriondo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casey_E/0/1/0/all/0/1\">Evan Casey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hejrati_M/0/1/0/all/0/1\">Mohsen Hejrati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Initiative_f/0/1/0/all/0/1\">for Alzheimer&#x27;s Disease Neuroimaging Initiative</a>",
          "description": "The ability to predict the future trajectory of a patient is a key step\ntoward the development of therapeutics for complex diseases such as Alzheimer's\ndisease (AD). However, most machine learning approaches developed for\nprediction of disease progression are either single-task or single-modality\nmodels, which can not be directly adopted to our setting involving multi-task\nlearning with high dimensional images. Moreover, most of those approaches are\ntrained on a single dataset (i.e. cohort), which can not be generalized to\nother cohorts. We propose a novel multimodal multi-task deep learning model to\npredict AD progression by analyzing longitudinal clinical and neuroimaging data\nfrom multiple cohorts. Our proposed model integrates high dimensional MRI\nfeatures from a 3D convolutional neural network with other data modalities,\nincluding clinical and demographic information, to predict the future\ntrajectory of patients. Our model employs an adversarial loss to alleviate the\nstudy-specific imaging bias, in particular the inter-study domain shifts. In\naddition, a Sharpness-Aware Minimization (SAM) optimization technique is\napplied to further improve model generalization. The proposed model is trained\nand tested on various datasets in order to evaluate and validate the results.\nOur results showed that 1) our model yields significant improvement over the\nbaseline models, and 2) models using extracted neuroimaging features from 3D\nconvolutional neural network outperform the same models when applied to\nMRI-derived volumetric features.",
          "link": "http://arxiv.org/abs/2203.09096",
          "publishedOn": "2023-09-09T00:40:34.824Z",
          "wordCount": null,
          "title": "DeepAD: A Robust Deep Learning Model of Alzheimer's Disease Progression for Real-World Clinical Applications. (arXiv:2203.09096v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03292",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hammar_K/0/1/0/all/0/1\">Kim Hammar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Stadler_R/0/1/0/all/0/1\">Rolf Stadler</a>",
          "description": "We study automated intrusion response for an IT infrastructure and formulate\nthe interaction between an attacker and a defender as a partially observed\nstochastic game. To solve the game we follow an approach where attack and\ndefense strategies co-evolve through reinforcement learning and self-play\ntoward an equilibrium. Solutions proposed in previous work prove the\nfeasibility of this approach for small infrastructures but do not scale to\nrealistic scenarios due to the exponential growth in computational complexity\nwith the infrastructure size. We address this problem by introducing a method\nthat recursively decomposes the game into subgames which can be solved in\nparallel. Applying optimal stopping theory we show that the best response\nstrategies in these subgames exhibit threshold structures, which allows us to\ncompute them efficiently. To solve the decomposed game we introduce an\nalgorithm called Decompositional Fictitious Self-Play (DFSP), which learns Nash\nequilibria through stochastic approximation. We evaluate the learned strategies\nin an emulation environment where real intrusions and response actions can be\nexecuted. The results show that the learned strategies approximate an\nequilibrium and that DFSP significantly outperforms a state-of-the-art\nalgorithm for a realistic infrastructure configuration.",
          "link": "http://arxiv.org/abs/2309.03292",
          "publishedOn": "2023-09-09T00:40:34.822Z",
          "wordCount": null,
          "title": "Scalable Learning of Intrusion Responses through Recursive Decomposition. (arXiv:2309.03292v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03238",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jaiswal_M/0/1/0/all/0/1\">Mimansa Jaiswal</a>",
          "description": "Emotion recognition is a complex task due to the inherent subjectivity in\nboth the perception and production of emotions. The subjectivity of emotions\nposes significant challenges in developing accurate and robust computational\nmodels. This thesis examines critical facets of emotion recognition, beginning\nwith the collection of diverse datasets that account for psychological factors\nin emotion production.\n\nTo handle the challenge of non-representative training data, this work\ncollects the Multimodal Stressed Emotion dataset, which introduces controlled\nstressors during data collection to better represent real-world influences on\nemotion production. To address issues with label subjectivity, this research\ncomprehensively analyzes how data augmentation techniques and annotation\nschemes impact emotion perception and annotator labels. It further handles\nnatural confounding variables and variations by employing adversarial networks\nto isolate key factors like stress from learned emotion representations during\nmodel training. For tackling concerns about leakage of sensitive demographic\nvariables, this work leverages adversarial learning to strip sensitive\ndemographic information from multimodal encodings. Additionally, it proposes\noptimized sociological evaluation metrics aligned with cost-effective,\nreal-world needs for model testing.\n\nThis research advances robust, practical emotion recognition through\nmultifaceted studies of challenges in datasets, labels, modeling, demographic\nand membership variable encoding in representations, and evaluation. The\ngroundwork has been laid for cost-effective, generalizable emotion recognition\nmodels that are less likely to encode sensitive demographic information.",
          "link": "http://arxiv.org/abs/2309.03238",
          "publishedOn": "2023-09-09T00:40:34.786Z",
          "wordCount": null,
          "title": "Implicit Design Choices and Their Impact on Emotion Recognition Model Development and Evaluation. (arXiv:2309.03238v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.02539",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Watcharasupat_K/0/1/0/all/0/1\">Karn N. Watcharasupat</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_C/0/1/0/all/0/1\">Chih-Wei Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ding_Y/0/1/0/all/0/1\">Yiwei Ding</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Orife_I/0/1/0/all/0/1\">Iroro Orife</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hipple_A/0/1/0/all/0/1\">Aaron J. Hipple</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Williams_P/0/1/0/all/0/1\">Phillip A. Williams</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kramer_S/0/1/0/all/0/1\">Scott Kramer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lerch_A/0/1/0/all/0/1\">Alexander Lerch</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wolcott_W/0/1/0/all/0/1\">William Wolcott</a>",
          "description": "Cinematic audio source separation is a relatively new subtask of audio source\nseparation, with the aim of extracting the dialogue stem, the music stem, and\nthe effects stem from their mixture. In this work, we developed a model\ngeneralizing the Bandsplit RNN for any complete or overcomplete partitions of\nthe frequency axis. Psycho-acoustically motivated frequency scales were used to\ninform the band definitions which are now defined with redundancy for more\nreliable feature extraction. A loss function motivated by the signal-to-noise\nratio and the sparsity-promoting property of the 1-norm was proposed. We\nadditionally exploit the information-sharing property of a common-encoder setup\nto reduce computational complexity during both training and inference, improve\nseparation performance for hard-to-generalize classes of sounds, and allow\nflexibility during inference time with easily detachable decoders. Our best\nmodel sets the state of the art on the Divide and Remaster dataset with\nperformance above the ideal ratio mask for the dialogue stem.",
          "link": "http://arxiv.org/abs/2309.02539",
          "publishedOn": "2023-09-09T00:40:34.781Z",
          "wordCount": null,
          "title": "A Generalized Bandsplit Neural Network for Cinematic Audio Source Separation. (arXiv:2309.02539v2 [eess.AS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03851",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shahin_A/0/1/0/all/0/1\">Ahmed H. Shahin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_A/0/1/0/all/0/1\">An Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whitehead_A/0/1/0/all/0/1\">Alexander C. Whitehead</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alexander_D/0/1/0/all/0/1\">Daniel C. Alexander</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacob_J/0/1/0/all/0/1\">Joseph Jacob</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barber_D/0/1/0/all/0/1\">David Barber</a>",
          "description": "Survival analysis is a valuable tool for estimating the time until specific\nevents, such as death or cancer recurrence, based on baseline observations.\nThis is particularly useful in healthcare to prognostically predict clinically\nimportant events based on patient data. However, existing approaches often have\nlimitations; some focus only on ranking patients by survivability, neglecting\nto estimate the actual event time, while others treat the problem as a\nclassification task, ignoring the inherent time-ordered structure of the\nevents. Furthermore, the effective utilization of censored samples - training\ndata points where the exact event time is unknown - is essential for improving\nthe predictive accuracy of the model. In this paper, we introduce CenTime, a\nnovel approach to survival analysis that directly estimates the time to event.\nOur method features an innovative event-conditional censoring mechanism that\nperforms robustly even when uncensored data is scarce. We demonstrate that our\napproach forms a consistent estimator for the event model parameters, even in\nthe absence of uncensored data. Furthermore, CenTime is easily integrated with\ndeep learning models with no restrictions on batch size or the number of\nuncensored samples. We compare our approach with standard survival analysis\nmethods, including the Cox proportional-hazard model and DeepHit. Our results\nindicate that CenTime offers state-of-the-art performance in predicting\ntime-to-death while maintaining comparable ranking performance. Our\nimplementation is publicly available at\nhttps://github.com/ahmedhshahin/CenTime.",
          "link": "http://arxiv.org/abs/2309.03851",
          "publishedOn": "2023-09-09T00:40:34.769Z",
          "wordCount": null,
          "title": "CenTime: Event-Conditional Modelling of Censoring in Survival Analysis. (arXiv:2309.03851v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.00904",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yonghe Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qiang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Siwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yun Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Huiyan Sun</a>",
          "description": "Causal inference plays a vital role in diverse domains like epidemiology,\nhealthcare, and economics. De-confounding and counterfactual prediction in\nobservational data has emerged as a prominent concern in causal inference\nresearch. While existing models tackle observed confounders, the presence of\nunobserved confounders remains a significant challenge, distorting causal\ninference and impacting counterfactual outcome accuracy. To address this, we\npropose a novel variational learning model of unobserved confounders for\ncounterfactual inference (VLUCI), which generates the posterior distribution of\nunobserved confounders. VLUCI relaxes the unconfoundedness assumption often\noverlooked by most causal inference methods. By disentangling observed and\nunobserved confounders, VLUCI constructs a doubly variational inference model\nto approximate the distribution of unobserved confounders, which are used for\ninferring more accurate counterfactual outcomes. Extensive experiments on\nsynthetic and semi-synthetic datasets demonstrate VLUCI's superior performance\nin inferring unobserved confounders. It is compatible with state-of-the-art\ncounterfactual inference models, significantly improving inference accuracy at\nboth group and individual levels. Additionally, VLUCI provides confidence\nintervals for counterfactual outcomes, aiding decision-making in risk-sensitive\ndomains. We further clarify the considerations when applying VLUCI to cases\nwhere unobserved confounders don't strictly conform to our model assumptions\nusing the public IHDP dataset as an example, highlighting the practical\nadvantages of VLUCI.",
          "link": "http://arxiv.org/abs/2308.00904",
          "publishedOn": "2023-09-09T00:40:34.765Z",
          "wordCount": null,
          "title": "VLUCI: Variational Learning of Unobserved Confounders for Counterfactual Inference. (arXiv:2308.00904v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.09479",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ponglertnapakorn_P/0/1/0/all/0/1\">Puntawat Ponglertnapakorn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tritrong_N/0/1/0/all/0/1\">Nontawat Tritrong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suwajanakorn_S/0/1/0/all/0/1\">Supasorn Suwajanakorn</a>",
          "description": "We present a novel approach to single-view face relighting in the wild.\nHandling non-diffuse effects, such as global illumination or cast shadows, has\nlong been a challenge in face relighting. Prior work often assumes Lambertian\nsurfaces, simplified lighting models or involves estimating 3D shape, albedo,\nor a shadow map. This estimation, however, is error-prone and requires many\ntraining examples with lighting ground truth to generalize well. Our work\nbypasses the need for accurate estimation of intrinsic components and can be\ntrained solely on 2D images without any light stage data, multi-view images, or\nlighting ground truth. Our key idea is to leverage a conditional diffusion\nimplicit model (DDIM) for decoding a disentangled light encoding along with\nother encodings related to 3D shape and facial identity inferred from\noff-the-shelf estimators. We also propose a novel conditioning technique that\neases the modeling of the complex interaction between light and geometry by\nusing a rendered shading reference to spatially modulate the DDIM. We achieve\nstate-of-the-art performance on standard benchmark Multi-PIE and can\nphotorealistically relight in-the-wild images. Please visit our page:\nhttps://diffusion-face-relighting.github.io",
          "link": "http://arxiv.org/abs/2304.09479",
          "publishedOn": "2023-09-09T00:40:34.758Z",
          "wordCount": null,
          "title": "DiFaReli: Diffusion Face Relighting. (arXiv:2304.09479v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03223",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Drumm_K/0/1/0/all/0/1\">Kieron Drumm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_V/0/1/0/all/0/1\">Vincent Tran</a>",
          "description": "One of the most common things that a genealogist is tasked with is the\ngathering of a person's initial family history, normally via in-person\ninterviews or with the use of a platform such as ancestry.com, as this can\nprovide a strong foundation upon which a genealogist may build. However, the\nability to conduct these interviews can often be hindered by both geographical\nconstraints and the technical proficiency of the interviewee, as the\ninterviewee in these types of interviews is most often an elderly person with a\nlower than average level of technical proficiency. With this in mind, this\nstudy presents what we believe, based on prior research, to be the first\nchatbot geared entirely towards the gathering of family histories, and explores\nthe viability of utilising such a chatbot by comparing the performance and\nusability of such a method with the aforementioned alternatives. With a\nchatbot-based approach, we show that, though the average time taken to conduct\nan interview may be longer than if the user had used ancestry.com or\nparticipated in an in-person interview, the number of mistakes made and the\nlevel of confusion from the user regarding the UI and process required is lower\nthan the other two methods. Note that the final metric regarding the user's\nconfusion is not applicable for the in-person interview sessions due to its\nlack of a UI. With refinement, we believe this use of a chatbot could be a\nvaluable tool for genealogists, especially when dealing with interviewees who\nare based in other countries where it is not possible to conduct an in-person\ninterview.",
          "link": "http://arxiv.org/abs/2309.03223",
          "publishedOn": "2023-09-09T00:40:34.720Z",
          "wordCount": null,
          "title": "Examining the Effectiveness of Chatbots in Gathering Family History Information in Comparison to the Standard In-Person Interview-Based Approach. (arXiv:2309.03223v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03770",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Delgado_D/0/1/0/all/0/1\">David Delgado</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Curbelo_E/0/1/0/all/0/1\">Ernesto Curbelo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Carreras_D/0/1/0/all/0/1\">Danae Carreras</a>",
          "description": "In recent years, there is a growing interest in combining techniques\nattributed to the areas of Statistics and Machine Learning in order to obtain\nthe benefits of both approaches. In this article, the statistical technique\nlasso for variable selection is represented through a neural network. It is\nobserved that, although both the statistical approach and its neural version\nhave the same objective function, they differ due to their optimization. In\nparticular, the neural version is usually optimized in one-step using a single\nvalidation set, while the statistical counterpart uses a two-step optimization\nbased on cross-validation. The more elaborated optimization of the statistical\nmethod results in more accurate parameter estimation, especially when the\ntraining set is small. For this reason, a modification of the standard approach\nfor training neural networks, that mimics the statistical framework, is\nproposed. During the development of the above modification, a new optimization\nalgorithm for identifying the significant variables emerged. Experimental\nresults, using synthetic and real data sets, show that this new optimization\nalgorithm achieves better performance than any of the three previous\noptimization approaches.",
          "link": "http://arxiv.org/abs/2309.03770",
          "publishedOn": "2023-09-09T00:40:34.712Z",
          "wordCount": null,
          "title": "Neural lasso: a unifying approach of lasso and neural networks. (arXiv:2309.03770v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.02231",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Knox_W/0/1/0/all/0/1\">W. Bradley Knox</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hatgis_Kessell_S/0/1/0/all/0/1\">Stephane Hatgis-Kessell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Booth_S/0/1/0/all/0/1\">Serena Booth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1\">Scott Niekum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stone_P/0/1/0/all/0/1\">Peter Stone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allievi_A/0/1/0/all/0/1\">Alessandro Allievi</a>",
          "description": "The utility of reinforcement learning is limited by the alignment of reward\nfunctions with the interests of human stakeholders. One promising method for\nalignment is to learn the reward function from human-generated preferences\nbetween pairs of trajectory segments, a type of reinforcement learning from\nhuman feedback (RLHF). These human preferences are typically assumed to be\ninformed solely by partial return, the sum of rewards along each segment. We\nfind this assumption to be flawed and propose modeling human preferences\ninstead as informed by each segment's regret, a measure of a segment's\ndeviation from optimal decision-making. Given infinitely many preferences\ngenerated according to regret, we prove that we can identify a reward function\nequivalent to the reward function that generated those preferences, and we\nprove that the previous partial return model lacks this identifiability\nproperty in multiple contexts. We empirically show that our proposed regret\npreference model outperforms the partial return preference model with finite\ntraining data in otherwise the same setting. Additionally, we find that our\nproposed regret preference model better predicts real human preferences and\nalso learns reward functions from these preferences that lead to policies that\nare better human-aligned. Overall, this work establishes that the choice of\npreference model is impactful, and our proposed regret preference model\nprovides an improvement upon a core assumption of recent research. We have open\nsourced our experimental code, the human preferences dataset we gathered, and\nour training and preference elicitation interfaces for gathering a such a\ndataset.",
          "link": "http://arxiv.org/abs/2206.02231",
          "publishedOn": "2023-09-09T00:40:34.710Z",
          "wordCount": null,
          "title": "Models of human preference for learning reward functions. (arXiv:2206.02231v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.14051",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Alexander C. Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_E/0/1/0/all/0/1\">Ellis Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Efros_A/0/1/0/all/0/1\">Alexei A. Efros</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1\">Deepak Pathak</a>",
          "description": "Modern vision models typically rely on fine-tuning general-purpose models\npre-trained on large, static datasets. These general-purpose models only\ncapture the knowledge within their pre-training datasets, which are tiny,\nout-of-date snapshots of the Internet -- where billions of images are uploaded\neach day. We suggest an alternate approach: rather than hoping our static\ndatasets transfer to our desired tasks after large-scale pre-training, we\npropose dynamically utilizing the Internet to quickly train a small-scale model\nthat does extremely well on the task at hand. Our approach, called Internet\nExplorer, explores the web in a self-supervised manner to progressively find\nrelevant examples that improve performance on a desired target dataset. It\ncycles between searching for images on the Internet with text queries,\nself-supervised training on downloaded images, determining which images were\nuseful, and prioritizing what to search for next. We evaluate Internet Explorer\nacross several datasets and show that it outperforms or matches CLIP oracle\nperformance by using just a single GPU desktop to actively query the Internet\nfor 30--40 hours. Results, visualizations, and videos at\nhttps://internet-explorer-ssl.github.io/",
          "link": "http://arxiv.org/abs/2302.14051",
          "publishedOn": "2023-09-09T00:40:34.710Z",
          "wordCount": null,
          "title": "Internet Explorer: Targeted Representation Learning on the Open Web. (arXiv:2302.14051v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.08719",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bian_Z/0/1/0/all/0/1\">Zeyu Bian</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shi_C/0/1/0/all/0/1\">Chengchun Shi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Qi_Z/0/1/0/all/0/1\">Zhengling Qi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_L/0/1/0/all/0/1\">Lan Wang</a>",
          "description": "This work aims to study off-policy evaluation (OPE) under scenarios where two\nkey reinforcement learning (RL) assumptions -- temporal stationarity and\nindividual homogeneity are both violated. To handle the ``double\ninhomogeneities\", we propose a class of latent factor models for the reward and\nobservation transition functions, under which we develop a general OPE\nframework that consists of both model-based and model-free approaches. To our\nknowledge, this is the first paper that develops statistically sound OPE\nmethods in offline RL with double inhomogeneities. It contributes to a deeper\nunderstanding of OPE in environments, where standard RL assumptions are not\nmet, and provides several practical approaches in these settings. We establish\nthe theoretical properties of the proposed value estimators and empirically\nshow that our approach outperforms competing methods that ignore either\ntemporal nonstationarity or individual heterogeneity. Finally, we illustrate\nour method on a data set from the Medical Information Mart for Intensive Care.",
          "link": "http://arxiv.org/abs/2306.08719",
          "publishedOn": "2023-09-09T00:40:34.697Z",
          "wordCount": null,
          "title": "Off-policy Evaluation in Doubly Inhomogeneous Environments. (arXiv:2306.08719v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03202",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Khare_I/0/1/0/all/0/1\">Ishan S. Khare</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Martheswaran_T/0/1/0/all/0/1\">Tarun K. Martheswaran</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Dassanaike_Perera_A/0/1/0/all/0/1\">Akshana Dassanaike-Perera</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Ezekiel_J/0/1/0/all/0/1\">Jonah B. Ezekiel</a>",
          "description": "This work seeks to answer key research questions regarding the viability of\nreinforcement learning over the S&P 500 index. The on-policy techniques of\nValue Iteration (VI) and State-action-reward-state-action (SARSA) are\nimplemented along with the off-policy technique of Q-Learning. The models are\ntrained and tested on a dataset comprising multiple years of stock market data\nfrom 2000-2023. The analysis presents the results and findings from training\nand testing the models using two different time periods: one including the\nCOVID-19 pandemic years and one excluding them. The results indicate that\nincluding market data from the COVID-19 period in the training dataset leads to\nsuperior performance compared to the baseline strategies. During testing, the\non-policy approaches (VI and SARSA) outperform Q-learning, highlighting the\ninfluence of bias-variance tradeoff and the generalization capabilities of\nsimpler policies. However, it is noted that the performance of Q-learning may\nvary depending on the stability of future market conditions. Future work is\nsuggested, including experiments with updated Q-learning policies during\ntesting and trading diverse individual stocks. Additionally, the exploration of\nalternative economic indicators for training the models is proposed.",
          "link": "http://arxiv.org/abs/2309.03202",
          "publishedOn": "2023-09-09T00:40:34.614Z",
          "wordCount": null,
          "title": "Evaluation of Reinforcement Learning Techniques for Trading on a Diverse Portfolio. (arXiv:2309.03202v1 [q-fin.TR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03665",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sutton_O/0/1/0/all/0/1\">Oliver J. Sutton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Qinghua Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tyukin_I/0/1/0/all/0/1\">Ivan Y. Tyukin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gorban_A/0/1/0/all/0/1\">Alexander N. Gorban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastounis_A/0/1/0/all/0/1\">Alexander Bastounis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Higham_D/0/1/0/all/0/1\">Desmond J. Higham</a>",
          "description": "Adversarial attacks dramatically change the output of an otherwise accurate\nlearning system using a seemingly inconsequential modification to a piece of\ninput data. Paradoxically, empirical evidence indicates that even systems which\nare robust to large random perturbations of the input data remain susceptible\nto small, easily constructed, adversarial perturbations of their inputs. Here,\nwe show that this may be seen as a fundamental feature of classifiers working\nwith high dimensional input data. We introduce a simple generic and\ngeneralisable framework for which key behaviours observed in practical systems\narise with high probability -- notably the simultaneous susceptibility of the\n(otherwise accurate) model to easily constructed adversarial attacks, and\nrobustness to random perturbations of the input data. We confirm that the same\nphenomena are directly observed in practical neural networks trained on\nstandard image classification problems, where even large additive random noise\nfails to trigger the adversarial instability of the network. A surprising\ntakeaway is that even small margins separating a classifier's decision surface\nfrom training and testing data can hide adversarial susceptibility from being\ndetected using randomly sampled perturbations. Counterintuitively, using\nadditive noise during training or testing is therefore inefficient for\neradicating or detecting adversarial examples, and more demanding adversarial\ntraining is required.",
          "link": "http://arxiv.org/abs/2309.03665",
          "publishedOn": "2023-09-09T00:40:34.037Z",
          "wordCount": null,
          "title": "How adversarial attacks can disrupt seemingly stable accurate classifiers. (arXiv:2309.03665v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.04838",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xi_W/0/1/0/all/0/1\">Wenjie Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Arnav Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Li Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jessica Lin</a>",
          "description": "Time series classification is an important data mining task that has received\na lot of interest in the past two decades. Due to the label scarcity in\npractice, semi-supervised time series classification with only a few labeled\nsamples has become popular. Recently, Similarity-aware Time Series\nClassification (SimTSC) is proposed to address this problem by using a graph\nneural network classification model on the graph generated from pairwise\nDynamic Time Warping (DTW) distance of batch data. It shows excellent accuracy\nand outperforms state-of-the-art deep learning models in several few-label\nsettings. However, since SimTSC relies on pairwise DTW distances, the quadratic\ncomplexity of DTW limits its usability to only reasonably sized datasets. To\naddress this challenge, we propose a new efficient semi-supervised time series\nclassification technique, LB-SimTSC, with a new graph construction module.\nInstead of using DTW, we propose to utilize a lower bound of DTW, LB_Keogh, to\napproximate the dissimilarity between instances in linear time, while retaining\nthe relative proximity relationships one would have obtained via computing DTW.\nWe construct the pairwise distance matrix using LB_Keogh and build a graph for\nthe graph neural network. We apply this approach to the ten largest datasets\nfrom the well-known UCR time series classification archive. The results\ndemonstrate that this approach can be up to 104x faster than SimTSC when\nconstructing the graph on large datasets without significantly decreasing\nclassification accuracy.",
          "link": "http://arxiv.org/abs/2301.04838",
          "publishedOn": "2023-09-09T00:40:33.789Z",
          "wordCount": 780,
          "title": "LB-SimTSC: An Efficient Similarity-Aware Graph Neural Network for Semi-Supervised Time Series Classification. (arXiv:2301.04838v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.03227",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jegal_Y/0/1/0/all/0/1\">Yongseung Jegal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jaewoong Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jiho Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1\">Ki-Su Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seyoung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Janghyeok Yoon</a>",
          "description": "Drug repositioning-a promising strategy for discovering new therapeutic uses\nfor existing drugs-has been increasingly explored in the computational science\nliterature using biomedical databases. However, the technological potential of\ndrug repositioning candidates has often been overlooked. This study presents a\nnovel protocol to comprehensively analyse various sources such as\npharmaceutical patents and biomedical databases, and identify drug\nrepositioning candidates with both technological potential and scientific\nevidence. To this end, first, we constructed a scientific biomedical knowledge\ngraph (s-BKG) comprising relationships between drugs, diseases, and genes\nderived from biomedical databases. Our protocol involves identifying drugs that\nexhibit limited association with the target disease but are closely located in\nthe s-BKG, as potential drug candidates. We constructed a patent-informed\nbiomedical knowledge graph (p-BKG) by adding pharmaceutical patent information.\nFinally, we developed a graph embedding protocol to ascertain the structure of\nthe p-BKG, thereby calculating the relevance scores of those candidates with\ntarget disease-related patents to evaluate their technological potential. Our\ncase study on Alzheimer's disease demonstrates its efficacy and feasibility,\nwhile the quantitative outcomes and systematic methods are expected to bridge\nthe gap between computational discoveries and successful market applications in\ndrug repositioning research.",
          "link": "http://arxiv.org/abs/2309.03227",
          "publishedOn": "2023-09-09T00:40:33.769Z",
          "wordCount": 721,
          "title": "Learning a Patent-Informed Biomedical Knowledge Graph Reveals Technological Potential of Drug Repositioning Candidates. (arXiv:2309.03227v1 [cs.AI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.03631",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wenzel_M/0/1/0/all/0/1\">Markus Wenzel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gruner_E/0/1/0/all/0/1\">Erik Gr&#xfc;ner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strodthoff_N/0/1/0/all/0/1\">Nils Strodthoff</a>",
          "description": "Motivation: We explored how explainable AI (XAI) can help to shed light into\nthe inner workings of neural networks for protein function prediction, by\nextending the widely used XAI method of integrated gradients such that latent\nrepresentations inside of transformer models, which were finetuned to Gene\nOntology term and Enzyme Commission number prediction, can be inspected too.\nResults: The approach enabled us to identify amino acids in the sequences that\nthe transformers pay particular attention to, and to show that these relevant\nsequence parts reflect expectations from biology and chemistry, both in the\nembedding layer and inside of the model, where we identified transformer heads\nwith a statistically significant correspondence of attribution maps with ground\ntruth sequence annotations (e.g., transmembrane regions, active sites) across\nmany proteins. Availability and Implementation: Source code can be accessed at\nhttps://github.com/markuswenzel/xai-proteins .",
          "link": "http://arxiv.org/abs/2309.03631",
          "publishedOn": "2023-09-09T00:40:33.762Z",
          "wordCount": 673,
          "title": "Insights Into the Inner Workings of Transformer Models for Protein Function Prediction. (arXiv:2309.03631v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.03847",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Afzali_M/0/1/0/all/0/1\">Mohammad Afzali</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ashtiani_H/0/1/0/all/0/1\">Hassan Ashtiani</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liaw_C/0/1/0/all/0/1\">Christopher Liaw</a>",
          "description": "We study the problem of estimating mixtures of Gaussians under the constraint\nof differential privacy (DP). Our main result is that $\\tilde{O}(k^2 d^4\n\\log(1/\\delta) / \\alpha^2 \\varepsilon)$ samples are sufficient to estimate a\nmixture of $k$ Gaussians up to total variation distance $\\alpha$ while\nsatisfying $(\\varepsilon, \\delta)$-DP. This is the first finite sample\ncomplexity upper bound for the problem that does not make any structural\nassumptions on the GMMs.\n\nTo solve the problem, we devise a new framework which may be useful for other\ntasks. On a high level, we show that if a class of distributions (such as\nGaussians) is (1) list decodable and (2) admits a \"locally small'' cover\n[BKSW19] with respect to total variation distance, then the class of its\nmixtures is privately learnable. The proof circumvents a known barrier\nindicating that, unlike Gaussians, GMMs do not admit a locally small cover\n[AAL21].",
          "link": "http://arxiv.org/abs/2309.03847",
          "publishedOn": "2023-09-09T00:40:33.755Z",
          "wordCount": 674,
          "title": "Mixtures of Gaussians are Privately Learnable with a Polynomial Number of Samples. (arXiv:2309.03847v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.03544",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ashhad_M/0/1/0/all/0/1\">Mohd Ashhad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_O/0/1/0/all/0/1\">Omar Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ambat_S/0/1/0/all/0/1\">Sooraj K. Ambat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haq_Z/0/1/0/all/0/1\">Zeeshan Ali Haq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alam_M/0/1/0/all/0/1\">Mansaf Alam</a>",
          "description": "Rising urban populations have led to a surge in vehicle use and made traffic\nmonitoring and management indispensable. Acoustic traffic monitoring (ATM)\noffers a cost-effective and efficient alternative to more computationally\nexpensive methods of monitoring traffic such as those involving computer vision\ntechnologies. In this paper, we present MVD and MVDA: two open datasets for the\ndevelopment of acoustic traffic monitoring and vehicle-type classification\nalgorithms, which contain audio recordings of moving vehicles. The dataset\ncontain four classes- Trucks, Cars, Motorbikes, and a No-vehicle class.\nAdditionally, we propose a novel and efficient way to accurately classify these\nacoustic signals using cepstrum and spectrum based local and global audio\nfeatures, and a multi-input neural network. Experimental results show that our\nmethodology improves upon the established baselines of previous works and\nachieves an accuracy of 91.98% and 96.66% on MVD and MVDA Datasets,\nrespectively. Finally, the proposed model was deployed through an Android\napplication to make it accessible for testing and demonstrate its efficacy.",
          "link": "http://arxiv.org/abs/2309.03544",
          "publishedOn": "2023-09-09T00:40:33.748Z",
          "wordCount": 676,
          "title": "MVD:A Novel Methodology and Dataset for Acoustic Vehicle Type Classification. (arXiv:2309.03544v1 [cs.SD])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.03702",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Silva_H/0/1/0/all/0/1\">Hondamunige Prasanna Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seidenari_L/0/1/0/all/0/1\">Lorenzo Seidenari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bimbo_A/0/1/0/all/0/1\">Alberto Del Bimbo</a>",
          "description": "This paper presents a novel reconstruction method that leverages Diffusion\nModels to protect machine learning classifiers against adversarial attacks, all\nwithout requiring any modifications to the classifiers themselves. The\nsusceptibility of machine learning models to minor input perturbations renders\nthem vulnerable to adversarial attacks. While diffusion-based methods are\ntypically disregarded for adversarial defense due to their slow reverse\nprocess, this paper demonstrates that our proposed method offers robustness\nagainst adversarial threats while preserving clean accuracy, speed, and\nplug-and-play compatibility. Code at:\nhttps://github.com/HondamunigePrasannaSilva/DiffDefence.",
          "link": "http://arxiv.org/abs/2309.03702",
          "publishedOn": "2023-09-09T00:40:33.729Z",
          "wordCount": 621,
          "title": "DiffDefense: Defending against Adversarial Attacks via Diffusion Models. (arXiv:2309.03702v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2201.12191",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ravfogel_S/0/1/0/all/0/1\">Shauli Ravfogel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vargas_F/0/1/0/all/0/1\">Francisco Vargas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "The representation space of neural models for textual data emerges in an\nunsupervised manner during training. Understanding how those representations\nencode human-interpretable concepts is a fundamental problem. One prominent\napproach for the identification of concepts in neural representations is\nsearching for a linear subspace whose erasure prevents the prediction of the\nconcept from the representations. However, while many linear erasure algorithms\nare tractable and interpretable, neural networks do not necessarily represent\nconcepts in a linear manner. To identify non-linearly encoded concepts, we\npropose a kernelization of a linear minimax game for concept erasure. We\ndemonstrate that it is possible to prevent specific non-linear adversaries from\npredicting the concept. However, the protection does not transfer to different\nnonlinear adversaries. Therefore, exhaustively erasing a non-linearly encoded\nconcept remains an open problem.",
          "link": "http://arxiv.org/abs/2201.12191",
          "publishedOn": "2023-09-09T00:40:33.720Z",
          "wordCount": 681,
          "title": "Kernelized Concept Erasure. (arXiv:2201.12191v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.03232",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Tuan Dinh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hihara_K/0/1/0/all/0/1\">Keisuke Hihara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoang_T/0/1/0/all/0/1\">Tung Cao Hoang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Utada_Y/0/1/0/all/0/1\">Yumeka Utada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torii_A/0/1/0/all/0/1\">Akihiko Torii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Izumi_N/0/1/0/all/0/1\">Naoki Izumi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thuy_N/0/1/0/all/0/1\">Nguyen Thanh Thuy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_L/0/1/0/all/0/1\">Long Quoc Tran</a>",
          "description": "Understanding customer behavior in retail stores plays a crucial role in\nimproving customer satisfaction by adding personalized value to services.\nBehavior analysis reveals both general and detailed patterns in the interaction\nof customers with a store items and other people, providing store managers with\ninsight into customer preferences. Several solutions aim to utilize this data\nby recognizing specific behaviors through statistical visualization. However,\ncurrent approaches are limited to the analysis of small customer behavior sets,\nutilizing conventional methods to detect behaviors. They do not use deep\nlearning techniques such as deep neural networks, which are powerful methods in\nthe field of computer vision. Furthermore, these methods provide limited\nfigures when visualizing the behavioral data acquired by the system. In this\nstudy, we propose a framework that includes three primary parts: mathematical\nmodeling of customer behaviors, behavior analysis using an efficient deep\nlearning based system, and individual and group behavior visualization. Each\nmodule and the entire system were validated using data from actual situations\nin a retail store.",
          "link": "http://arxiv.org/abs/2309.03232",
          "publishedOn": "2023-09-09T00:40:33.714Z",
          "wordCount": 699,
          "title": "Retail store customer behavior analysis system: Design and Implementation. (arXiv:2309.03232v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.01448",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jun Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendieta_M/0/1/0/all/0/1\">Matias Mendieta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shandong Wu</a>",
          "description": "Personalized federated learning has received an upsurge of attention due to\nthe mediocre performance of conventional federated learning (FL) over\nheterogeneous data. Unlike conventional FL which trains a single global\nconsensus model, personalized FL allows different models for different clients.\nHowever, existing personalized FL algorithms only implicitly transfer the\ncollaborative knowledge across the federation by embedding the knowledge into\nthe aggregated model or regularization. We observed that this implicit\nknowledge transfer fails to maximize the potential of each client's empirical\nrisk toward other clients. Based on our observation, in this work, we propose\nPersonalized Global Federated Learning (PGFed), a novel personalized FL\nframework that enables each client to personalize its own global objective by\nexplicitly and adaptively aggregating the empirical risks of itself and other\nclients. To avoid massive (O(N^2)) communication overhead and potential privacy\nleakage while achieving this, each client's risk is estimated through a\nfirst-order approximation for other clients' adaptive risk aggregation. On top\nof PGFed, we develop a momentum upgrade, dubbed PGFedMo, to more efficiently\nutilize clients' empirical risks. Our extensive experiments on four datasets\nunder different federated settings show consistent improvements of PGFed over\nprevious state-of-the-art methods. The code is publicly available at\nhttps://github.com/ljaiverson/pgfed.",
          "link": "http://arxiv.org/abs/2212.01448",
          "publishedOn": "2023-09-09T00:40:33.702Z",
          "wordCount": 734,
          "title": "PGFed: Personalize Each Client's Global Objective for Federated Learning. (arXiv:2212.01448v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2205.04151",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Feng_L/0/1/0/all/0/1\">Lingyu Feng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gao_T/0/1/0/all/0/1\">Ting Gao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dai_M/0/1/0/all/0/1\">Min Dai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Duan_J/0/1/0/all/0/1\">Jinqiao Duan</a>",
          "description": "Multiscale stochastic dynamical systems have been widely adopted to\nscientific and engineering problems due to their capability of depicting\ncomplex phenomena in many real world applications. This work is devoted to\ninvestigating the effective reduced dynamics for a slow-fast stochastic\ndynamical system. Given observation data on a short-term period satisfying some\nunknown slow-fast stochastic system, we propose a novel algorithm including a\nneural network called Auto-SDE to learn invariant slow manifold. Our approach\ncaptures the evolutionary nature of a series of time-dependent autoencoder\nneural networks with the loss constructed from a discretized stochastic\ndifferential equation. Our algorithm is also proved to be accurate, stable and\neffective through numerical experiments under various evaluation metrics.",
          "link": "http://arxiv.org/abs/2205.04151",
          "publishedOn": "2023-09-09T00:40:33.688Z",
          "wordCount": 649,
          "title": "Auto-SDE: Learning effective reduced dynamics from data-driven stochastic dynamical systems. (arXiv:2205.04151v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.03886",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schwettmann_S/0/1/0/all/0/1\">Sarah Schwettmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaham_T/0/1/0/all/0/1\">Tamar Rott Shaham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Materzynska_J/0/1/0/all/0/1\">Joanna Materzynska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_N/0/1/0/all/0/1\">Neil Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1\">Jacob Andreas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bau_D/0/1/0/all/0/1\">David Bau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1\">Antonio Torralba</a>",
          "description": "Labeling neural network submodules with human-legible descriptions is useful\nfor many downstream tasks: such descriptions can surface failures, guide\ninterventions, and perhaps even explain important model behaviors. To date,\nmost mechanistic descriptions of trained networks have involved small models,\nnarrowly delimited phenomena, and large amounts of human labor. Labeling all\nhuman-interpretable sub-computations in models of increasing size and\ncomplexity will almost certainly require tools that can generate and validate\ndescriptions automatically. Recently, techniques that use learned models\nin-the-loop for labeling have begun to gain traction, but methods for\nevaluating their efficacy are limited and ad-hoc. How should we validate and\ncompare open-ended labeling tools? This paper introduces FIND (Function\nINterpretation and Description), a benchmark suite for evaluating the building\nblocks of automated interpretability methods. FIND contains functions that\nresemble components of trained neural networks, and accompanying descriptions\nof the kind we seek to generate. The functions are procedurally constructed\nacross textual and numeric domains, and involve a range of real-world\ncomplexities, including noise, composition, approximation, and bias. We\nevaluate new and existing methods that use language models (LMs) to produce\ncode-based and language descriptions of function behavior. We find that an\noff-the-shelf LM augmented with only black-box access to functions can\nsometimes infer their structure, acting as a scientist by forming hypotheses,\nproposing experiments, and updating descriptions in light of new data. However,\nLM-based descriptions tend to capture global function behavior and miss local\ncorruptions. These results show that FIND will be useful for characterizing the\nperformance of more sophisticated interpretability methods before they are\napplied to real-world models.",
          "link": "http://arxiv.org/abs/2309.03886",
          "publishedOn": "2023-09-09T00:40:33.663Z",
          "wordCount": 777,
          "title": "A Function Interpretation Benchmark for Evaluating Interpretability Methods. (arXiv:2309.03886v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.03842",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Feng_L/0/1/0/all/0/1\">Lingyu Feng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gao_T/0/1/0/all/0/1\">Ting Gao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xiao_W/0/1/0/all/0/1\">Wang Xiao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Duan_J/0/1/0/all/0/1\">Jinqiao Duan</a>",
          "description": "Early warnings for dynamical transitions in complex systems or\nhigh-dimensional observation data are essential in many real world\napplications, such as gene mutation, brain diseases, natural disasters,\nfinancial crises, and engineering reliability. To effectively extract early\nwarning signals, we develop a novel approach: the directed anisotropic\ndiffusion map that captures the latent evolutionary dynamics in low-dimensional\nmanifold. Applying the methodology to authentic electroencephalogram (EEG)\ndata, we successfully find the appropriate effective coordinates, and derive\nearly warning signals capable of detecting the tipping point during the state\ntransition. Our method bridges the latent dynamics with the original dataset.\nThe framework is validated to be accurate and effective through numerical\nexperiments, in terms of density and transition probability. It is shown that\nthe second coordinate holds meaningful information for critical transition in\nvarious evaluation metrics.",
          "link": "http://arxiv.org/abs/2309.03842",
          "publishedOn": "2023-09-09T00:40:33.650Z",
          "wordCount": 635,
          "title": "Early warning via transitions in latent stochastic dynamical systems. (arXiv:2309.03842v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.03450",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nijkamp_E/0/1/0/all/0/1\">Erik Nijkamp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tian Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayashi_H/0/1/0/all/0/1\">Hiroaki Hayashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_B/0/1/0/all/0/1\">Bo Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_C/0/1/0/all/0/1\">Congying Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_C/0/1/0/all/0/1\">Chen Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vig_J/0/1/0/all/0/1\">Jesse Vig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yavuz_S/0/1/0/all/0/1\">Semih Yavuz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laban_P/0/1/0/all/0/1\">Philippe Laban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_B/0/1/0/all/0/1\">Ben Krause</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purushwalkam_S/0/1/0/all/0/1\">Senthil Purushwalkam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_T/0/1/0/all/0/1\">Tong Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kryscinski_W/0/1/0/all/0/1\">Wojciech Kry&#x15b;ci&#x144;ski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murakhovska_L/0/1/0/all/0/1\">Lidiya Murakhovs&#x27;ka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choubey_P/0/1/0/all/0/1\">Prafulla Kumar Choubey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fabbri_A/0/1/0/all/0/1\">Alex Fabbri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Ye Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_R/0/1/0/all/0/1\">Rui Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_L/0/1/0/all/0/1\">Lifu Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhat_M/0/1/0/all/0/1\">Meghana Bhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chien-Sheng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1\">Silvio Savarese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yingbo Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>",
          "description": "Large Language Models (LLMs) have become ubiquitous across various domains,\ntransforming the way we interact with information and conduct research.\nHowever, most high-performing LLMs remain confined behind proprietary walls,\nhindering scientific progress. Most open-source LLMs, on the other hand, are\nlimited in their ability to support longer sequence lengths, which is a key\nrequirement for many tasks that require inference over an input context. To\naddress this, we have trained XGen, a series of 7B parameter models on up to 8K\nsequence length for up to 1.5T tokens. We have also finetuned the XGen models\non public-domain instructional data, creating their instruction-tuned\ncounterparts (XGen-Inst). We open-source our models for both research\nadvancements and commercial applications. Our evaluation on standard benchmarks\nshows that XGen models achieve comparable or better results when compared with\nstate-of-the-art open-source LLMs. Our targeted evaluation on long sequence\nmodeling tasks shows the benefits of our 8K-sequence models over 2K-sequence\nopen-source LLMs.",
          "link": "http://arxiv.org/abs/2309.03450",
          "publishedOn": "2023-09-09T00:40:33.641Z",
          "wordCount": 682,
          "title": "XGen-7B Technical Report. (arXiv:2309.03450v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.03827",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barua_H/0/1/0/all/0/1\">Hrishav Bakul Barua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnasamy_G/0/1/0/all/0/1\">Ganesh Krishnasamy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1\">KokSheik Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stefanov_K/0/1/0/all/0/1\">Kalin Stefanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhall_A/0/1/0/all/0/1\">Abhinav Dhall</a>",
          "description": "High Dynamic Range (HDR) content creation has become an important topic for\nmodern media and entertainment sectors, gaming and Augmented/Virtual Reality\nindustries. Many methods have been proposed to recreate the HDR counterparts of\ninput Low Dynamic Range (LDR) images/videos given a single exposure or\nmulti-exposure LDRs. The state-of-the-art methods focus primarily on the\npreservation of the reconstruction's structural similarity and the pixel-wise\naccuracy. However, these conventional approaches do not emphasize preserving\nthe artistic intent of the images in terms of human visual perception, which is\nan essential element in media, entertainment and gaming. In this paper, we\nattempt to study and fill this gap. We propose an architecture called\nArtHDR-Net based on a Convolutional Neural Network that uses multi-exposed LDR\nfeatures as input. Experimental results show that ArtHDR-Net can achieve\nstate-of-the-art performance in terms of the HDR-VDP-2 score (i.e., mean\nopinion score index) while reaching competitive performance in terms of PSNR\nand SSIM.",
          "link": "http://arxiv.org/abs/2309.03827",
          "publishedOn": "2023-09-09T00:40:33.632Z",
          "wordCount": 699,
          "title": "ArtHDR-Net: Perceptually Realistic and Accurate HDR Content Creation. (arXiv:2309.03827v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.03537",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zheng_R/0/1/0/all/0/1\">Ruigang Zheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhuang_X/0/1/0/all/0/1\">Xiaosheng Zhuang</a>",
          "description": "In this work, we proposed a novel and general method to construct tight\nframes on graphs with compact supports based on a series of hierarchical\npartitions. Starting from our abstract construction that generalizes previous\nmethods based on partition trees, we are able to flexibly incorporate subgraph\nLaplacians into our design of graph frames. Consequently, our general methods\npermit adjusting the (subgraph) vanishing moments of the framelets and extra\nproperties, such as directionality, for efficiently representing graph signals\nwith path-like supports. Several variants are explicitly defined and tested.\nExperimental results show our proposed graph frames perform superiorly in\nnon-linear approximation tasks.",
          "link": "http://arxiv.org/abs/2309.03537",
          "publishedOn": "2023-09-09T00:40:33.613Z",
          "wordCount": 613,
          "title": "Subgraph-based Tight Frames on Graphs with Compact Supports and Vanishing Moments. (arXiv:2309.03537v1 [eess.SP])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.03249",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Surajit Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mallick_A/0/1/0/all/0/1\">Archita Mallick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_A/0/1/0/all/0/1\">Anuva Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_K/0/1/0/all/0/1\">Kounik De Sarkar</a>",
          "description": "Geospatial sciences include a wide range of applications, from environmental\nmonitoring transportation to infrastructure planning, as well as location-based\nanalysis and services. Graph theory algorithms in mathematics have emerged as\nindispensable tools in these domains due to their capability to model and\nanalyse spatial relationships efficiently. This technical report explores the\napplications of graph theory algorithms in geospatial sciences, highlighting\ntheir role in network analysis, spatial connectivity, geographic information\nsystems, and various other spatial problem-solving scenarios. It provides a\ncomprehensive idea about the key concepts and algorithms of graph theory that\nassist the modelling processes. The report provides insights into the practical\nsignificance of graph theory in addressing real-world geospatial challenges and\nopportunities. It lists the extensive research, innovative technologies and\nmethodologies implemented in this field.",
          "link": "http://arxiv.org/abs/2309.03249",
          "publishedOn": "2023-09-09T00:40:33.606Z",
          "wordCount": 640,
          "title": "Graph Theory Applications in Advanced Geospatial Research. (arXiv:2309.03249v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.03837",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sangwook Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purdie_T/0/1/0/all/0/1\">Thomas G. Purdie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McIntosh_C/0/1/0/all/0/1\">Chris McIntosh</a>",
          "description": "Multi-task learning (MTL) is a powerful approach in deep learning that\nleverages the information from multiple tasks during training to improve model\nperformance. In medical imaging, MTL has shown great potential to solve various\ntasks. However, existing MTL architectures in medical imaging are limited in\nsharing information across tasks, reducing the potential performance\nimprovements of MTL. In this study, we introduce a novel attention-based MTL\nframework to better leverage inter-task interactions for various tasks from\npixel-level to image-level predictions. Specifically, we propose a Cross-Task\nAttention Network (CTAN) which utilizes cross-task attention mechanisms to\nincorporate information by interacting across tasks. We validated CTAN on four\nmedical imaging datasets that span different domains and tasks including:\nradiation treatment planning prediction using planning CT images of two\ndifferent target cancers (Prostate, OpenKBP); pigmented skin lesion\nsegmentation and diagnosis using dermatoscopic images (HAM10000); and COVID-19\ndiagnosis and severity prediction using chest CT scans (STOIC). Our study\ndemonstrates the effectiveness of CTAN in improving the accuracy of medical\nimaging tasks. Compared to standard single-task learning (STL), CTAN\ndemonstrated a 4.67% improvement in performance and outperformed both widely\nused MTL baselines: hard parameter sharing (HPS) with an average performance\nimprovement of 3.22%; and multi-task attention network (MTAN) with a relative\ndecrease of 5.38%. These findings highlight the significance of our proposed\nMTL framework in solving medical imaging tasks and its potential to improve\ntheir accuracy across domains.",
          "link": "http://arxiv.org/abs/2309.03837",
          "publishedOn": "2023-09-09T00:40:33.596Z",
          "wordCount": 792,
          "title": "Cross-Task Attention Network: Improving Multi-Task Learning for Medical Imaging Applications. (arXiv:2309.03837v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.03219",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hoang_V/0/1/0/all/0/1\">Van Thuy Hoang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_S/0/1/0/all/0/1\">Sang Thanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sangmyeong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jooho Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1\">Luong Vuong Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_O/0/1/0/all/0/1\">O-Joun Lee</a>",
          "description": "Knowledge graph (KG) embedding has been used to benefit the diagnosis of\nanimal diseases by analyzing electronic medical records (EMRs), such as notes\nand veterinary records. However, learning representations to capture entities\nand relations with literal information in KGs is challenging as the KGs show\nheterogeneous properties and various types of literal information. Meanwhile,\nthe existing methods mostly aim to preserve graph structures surrounding target\nnodes without considering different types of literals, which could also carry\nsignificant information. In this paper, we propose a knowledge graph embedding\nmodel for the efficient diagnosis of animal diseases, which could learn various\ntypes of literal information and graph structure and fuse them into unified\nrepresentations, namely LiteralKG. Specifically, we construct a knowledge graph\nthat is built from EMRs along with literal information collected from various\nanimal hospitals. We then fuse different types of entities and node feature\ninformation into unified vector representations through gate networks. Finally,\nwe propose a self-supervised learning task to learn graph structure in pretext\ntasks and then towards various downstream tasks. Experimental results on link\nprediction tasks demonstrate that our model outperforms the baselines that\nconsist of state-of-the-art models. The source code is available at\nhttps://github.com/NSLab-CUK/LiteralKG.",
          "link": "http://arxiv.org/abs/2309.03219",
          "publishedOn": "2023-09-09T00:40:33.572Z",
          "wordCount": 730,
          "title": "Companion Animal Disease Diagnostics based on Literal-aware Medical Knowledge Graph Representation Learning. (arXiv:2309.03219v1 [cs.AI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.03246",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Chengjie Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qinghua Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_T/0/1/0/all/0/1\">Tao Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1\">Shaukat Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwitalla_T/0/1/0/all/0/1\">Thomas Schwitalla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nygaard_J/0/1/0/all/0/1\">Jan F. Nyg&#xe5;rd</a>",
          "description": "The Cancer Registry of Norway (CRN) collects information on cancer patients\nby receiving cancer messages from different medical entities (e.g., medical\nlabs, and hospitals) in Norway. Such messages are validated by an automated\ncancer registry system: GURI. Its correct operation is crucial since it lays\nthe foundation for cancer research and provides critical cancer-related\nstatistics to its stakeholders. Constructing a cyber-cyber digital twin (CCDT)\nfor GURI can facilitate various experiments and advanced analyses of the\noperational state of GURI without requiring intensive interactions with the\nreal system. However, GURI constantly evolves due to novel medical diagnostics\nand treatment, technological advances, etc. Accordingly, CCDT should evolve as\nwell to synchronize with GURI. A key challenge of achieving such\nsynchronization is that evolving CCDT needs abundant data labelled by the new\nGURI. To tackle this challenge, we propose EvoCLINICAL, which considers the\nCCDT developed for the previous version of GURI as the pretrained model and\nfine-tunes it with the dataset labelled by querying a new GURI version.\nEvoCLINICAL employs a genetic algorithm to select an optimal subset of cancer\nmessages from a candidate dataset and query GURI with it. We evaluate\nEvoCLINICAL on three evolution processes. The precision, recall, and F1 score\nare all greater than 91%, demonstrating the effectiveness of EvoCLINICAL.\nFurthermore, we replace the active learning part of EvoCLINICAL with random\nselection to study the contribution of transfer learning to the overall\nperformance of EvoCLINICAL. Results show that employing active learning in\nEvoCLINICAL increases its performances consistently.",
          "link": "http://arxiv.org/abs/2309.03246",
          "publishedOn": "2023-09-09T00:40:33.541Z",
          "wordCount": 823,
          "title": "EvoCLINICAL: Evolving Cyber-Cyber Digital Twin with Active Transfer Learning for Automated Cancer Registry System. (arXiv:2309.03246v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.19979",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gema_A/0/1/0/all/0/1\">Aryo Pradipta Gema</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grabarczyk_D/0/1/0/all/0/1\">Dominik Grabarczyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wulf_W/0/1/0/all/0/1\">Wolf De Wulf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borole_P/0/1/0/all/0/1\">Piyush Borole</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alfaro_J/0/1/0/all/0/1\">Javier Antonio Alfaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minervini_P/0/1/0/all/0/1\">Pasquale Minervini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vergari_A/0/1/0/all/0/1\">Antonio Vergari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajan_A/0/1/0/all/0/1\">Ajitha Rajan</a>",
          "description": "Knowledge graphs are powerful tools for representing and organising complex\nbiomedical data. Several knowledge graph embedding algorithms have been\nproposed to learn from and complete knowledge graphs. However, a recent study\ndemonstrates the limited efficacy of these embedding algorithms when applied to\nbiomedical knowledge graphs, raising the question of whether knowledge graph\nembeddings have limitations in biomedical settings. This study aims to apply\nstate-of-the-art knowledge graph embedding models in the context of a recent\nbiomedical knowledge graph, BioKG, and evaluate their performance and potential\ndownstream uses. We achieve a three-fold improvement in terms of performance\nbased on the HITS@10 score over previous work on the same biomedical knowledge\ngraph. Additionally, we provide interpretable predictions through a rule-based\nmethod. We demonstrate that knowledge graph embedding models are applicable in\npractice by evaluating the best-performing model on four tasks that represent\nreal-life polypharmacy situations. Results suggest that knowledge learnt from\nlarge biomedical knowledge graphs can be transferred to such downstream use\ncases. Our code is available at https://github.com/aryopg/biokge.",
          "link": "http://arxiv.org/abs/2305.19979",
          "publishedOn": "2023-09-02T00:40:03.066Z",
          "wordCount": 756,
          "title": "Knowledge Graph Embeddings in the Biomedical Domain: Are They Useful? A Look at Link Prediction, Rule Learning, and Downstream Polypharmacy Tasks. (arXiv:2305.19979v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.15690",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ban_B/0/1/0/all/0/1\">Byunghyun Ban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryu_D/0/1/0/all/0/1\">Donghun Ryu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Su-won Hwang</a>",
          "description": "We present 'CongNaMul', a comprehensive dataset designed for various tasks in\nsoybean sprouts image analysis. The CongNaMul dataset is curated to facilitate\ntasks such as image classification, semantic segmentation, decomposition, and\nmeasurement of length and weight. The classification task provides four classes\nto determine the quality of soybean sprouts: normal, broken, spotted, and\nbroken and spotted, for the development of AI-aided automatic quality\ninspection technology. For semantic segmentation, images with varying\ncomplexity, from single sprout images to images with multiple sprouts, along\nwith human-labelled mask images, are included. The label has 4 different\nclasses: background, head, body, tail. The dataset also provides images and\nmasks for the image decomposition task, including two separate sprout images\nand their combined form. Lastly, 5 physical features of sprouts (head length,\nbody length, body thickness, tail length, weight) are provided for image-based\nmeasurement tasks. This dataset is expected to be a valuable resource for a\nwide range of research and applications in the advanced analysis of images of\nsoybean sprouts. Also, we hope that this dataset can assist researchers\nstudying classification, semantic segmentation, decomposition, and physical\nfeature measurement in other industrial fields, in evaluating their models. The\ndataset is available at the authors' repository. (https://bhban.kr/data)",
          "link": "http://arxiv.org/abs/2308.15690",
          "publishedOn": "2023-09-02T00:40:03.038Z",
          "wordCount": 749,
          "title": "CongNaMul: A Dataset for Advanced Image Processing of Soybean Sprouts. (arXiv:2308.15690v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.06620",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bastianello_N/0/1/0/all/0/1\">Nicola Bastianello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rikos_A/0/1/0/all/0/1\">Apostolos I. Rikos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johansson_K/0/1/0/all/0/1\">Karl H. Johansson</a>",
          "description": "In this paper we consider online distributed learning problems. Online\ndistributed learning refers to the process of training learning models on\ndistributed data sources. In our setting a set of agents need to cooperatively\ntrain a learning model from streaming data. Differently from federated\nlearning, the proposed approach does not rely on a central server but only on\npeer-to-peer communications among the agents. This approach is often used in\nscenarios where data cannot be moved to a centralized location due to privacy,\nsecurity, or cost reasons. In order to overcome the absence of a central\nserver, we propose a distributed algorithm that relies on a quantized,\nfinite-time coordination protocol to aggregate the locally trained models.\nFurthermore, our algorithm allows for the use of stochastic gradients during\nlocal training. Stochastic gradients are computed using a randomly sampled\nsubset of the local training data, which makes the proposed algorithm more\nefficient and scalable than traditional gradient descent. In our paper, we\nanalyze the performance of the proposed algorithm in terms of the mean distance\nfrom the online solution. Finally, we present numerical results for a logistic\nregression task.",
          "link": "http://arxiv.org/abs/2307.06620",
          "publishedOn": "2023-09-02T00:40:03.032Z",
          "wordCount": 722,
          "title": "Online Distributed Learning with Quantized Finite-Time Coordination. (arXiv:2307.06620v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.11737",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1\">Bruno Roy</a>",
          "description": "Partitioning a polygonal mesh into meaningful parts can be challenging. Many\napplications require decomposing such structures for further processing in\ncomputer graphics. In the last decade, several methods were proposed to tackle\nthis problem, at the cost of intensive computational times. Recently, machine\nlearning has proven to be effective for the segmentation task on 3D structures.\nNevertheless, these state-of-the-art methods are often hardly generalizable and\nrequire dividing the learned model into several specific classes of objects to\navoid overfitting. We present a data-driven approach leveraging deep learning\nto encode a mapping function prior to mesh segmentation for multiple\napplications. Our network reproduces a neighborhood map using our knowledge of\nthe \\textsl{Shape Diameter Function} (SDF) method using similarities among\nvertex neighborhoods. Our approach is resolution-agnostic as we downsample the\ninput meshes and query the full-resolution structure solely for neighborhood\ncontributions. Using our predicted SDF values, we can inject the resulting\nstructure into a graph-cut algorithm to generate an efficient and robust mesh\nsegmentation while considerably reducing the required computation times.",
          "link": "http://arxiv.org/abs/2306.11737",
          "publishedOn": "2023-09-02T00:40:03.026Z",
          "wordCount": 706,
          "title": "Neural ShDF: Reviving an Efficient and Consistent Mesh Segmentation Method. (arXiv:2306.11737v2 [cs.GR] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.04726",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ada_S/0/1/0/all/0/1\">Suzan Ece Ada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oztop_E/0/1/0/all/0/1\">Erhan Oztop</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ugur_E/0/1/0/all/0/1\">Emre Ugur</a>",
          "description": "Offline Reinforcement Learning (RL) methods leverage previous experiences to\nlearn better policies than the behavior policy used for data collection. In\ncontrast to behavior cloning, which assumes the data is collected from expert\ndemonstrations, offline RL can work with non-expert data and multimodal\nbehavior policies. However, offline RL algorithms face challenges in handling\ndistribution shifts and effectively representing policies due to the lack of\nonline interaction during training. Prior work on offline RL uses conditional\ndiffusion models to represent multimodal behavior in the dataset. Nevertheless,\nthese methods are not tailored toward alleviating the out-of-distribution state\ngeneralization. We introduce a novel method, named State Reconstruction for\nDiffusion Policies (SRDP), incorporating state reconstruction feature learning\nin the recent class of diffusion policies to address the out-of-distribution\ngeneralization problem. State reconstruction loss promotes more descriptive\nrepresentation learning of states to alleviate the distribution shift incurred\nby the out-of-distribution (OOD) states. We design a novel 2D Multimodal\nContextual Bandit environment to illustrate the OOD generalization of SRDP\ncompared to prior algorithms. In addition, we assess the performance of our\nmodel on D4RL continuous control benchmarks, namely the navigation of an 8-DoF\nant and forward locomotion of half-cheetah, hopper, and walker2d, achieving\nstate-of-the-art results.",
          "link": "http://arxiv.org/abs/2307.04726",
          "publishedOn": "2023-09-02T00:40:02.919Z",
          "wordCount": 743,
          "title": "Diffusion Policies for Out-of-Distribution Generalization in Offline Reinforcement Learning. (arXiv:2307.04726v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.06777",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nemecek_J/0/1/0/all/0/1\">Jiri Nemecek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pevny_T/0/1/0/all/0/1\">Tomas Pevny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marecek_J/0/1/0/all/0/1\">Jakub Marecek</a>",
          "description": "In classification and forecasting with tabular data, one often utilizes\ntree-based models. Those can be competitive with deep neural networks on\ntabular data [cf. Grinsztajn et al., NeurIPS 2022, arXiv:2207.08815] and, under\nsome conditions, explainable. The explainability depends on the depth of the\ntree and the accuracy in each leaf of the tree. Decision trees containing\nleaves with unbalanced accuracy can provide misleading explanations.\nLow-accuracy leaves give less valid explanations, which could be interpreted as\nunfairness among explanations. Here, we train a shallow tree with the objective\nof minimizing the maximum misclassification error across each leaf node. Then,\nwe extend each leaf with a separate tree-based model. The shallow tree provides\na global explanation, while the overall statistical performance of the shallow\ntree with extended leaves improves upon decision trees of unlimited depth\ntrained using classical methods (e.g., CART) and is comparable to\nstate-of-the-art methods (e.g., well-tuned XGBoost).",
          "link": "http://arxiv.org/abs/2306.06777",
          "publishedOn": "2023-09-02T00:40:02.913Z",
          "wordCount": 689,
          "title": "Improving the Validity of Decision Trees as Explanations. (arXiv:2306.06777v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.15777",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Xu_X/0/1/0/all/0/1\">Xinyue Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hsi_Y/0/1/0/all/0/1\">Yuhan Hsi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Haonan Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1\">Xiaomeng Li</a>",
          "description": "Medical image data are often limited due to the expensive acquisition and\nannotation process. Hence, training a deep-learning model with only raw data\ncan easily lead to overfitting. One solution to this problem is to augment the\nraw data with various transformations, improving the model's ability to\ngeneralize to new data. However, manually configuring a generic augmentation\ncombination and parameters for different datasets is non-trivial due to\ninconsistent acquisition approaches and data distributions. Therefore,\nautomatic data augmentation is proposed to learn favorable augmentation\nstrategies for different datasets while incurring large GPU overhead. To this\nend, we present a novel method, called Dynamic Data Augmentation (DDAug), which\nis efficient and has negligible computation cost. Our DDAug develops a\nhierarchical tree structure to represent various augmentations and utilizes an\nefficient Monte-Carlo tree searching algorithm to update, prune, and sample the\ntree. As a result, the augmentation pipeline can be optimized for each dataset\nautomatically. Experiments on multiple Prostate MRI datasets show that our\nmethod outperforms the current state-of-the-art data augmentation strategies.",
          "link": "http://arxiv.org/abs/2305.15777",
          "publishedOn": "2023-09-02T00:40:02.868Z",
          "wordCount": null,
          "title": "Dynamic Data Augmentation via MCTS for Prostate MRI Segmentation. (arXiv:2305.15777v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.14388",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1\">Jiqiang Wang</a>",
          "description": "In this paper, we first reviewed several biclustering methods that are used\nto identify the most significant clusters in gene expression data. Here we\nmainly focused on the SSVD(sparse SVD) method and tried a new sparse penalty\nnamed \"Prenet penalty\" which has been used only in factor analysis to gain\nsparsity. Then in the simulation study, we tried different types of generated\ndatasets (with different sparsity and dimension) and tried 1-layer\napproximation then for k-layers which shows the mixed Prenet penalty is very\neffective for non-overlapped data. Finally, we used some real gene expression\ndata to show the behavior of our methods.",
          "link": "http://arxiv.org/abs/2308.14388",
          "publishedOn": "2023-09-02T00:40:02.867Z",
          "wordCount": null,
          "title": "Biclustering Methods via Sparse Penalty. (arXiv:2308.14388v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.17670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hammouamri_I/0/1/0/all/0/1\">Ilyass Hammouamri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalfaoui_Hassani_I/0/1/0/all/0/1\">Ismail Khalfaoui-Hassani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masquelier_T/0/1/0/all/0/1\">Timoth&#xe9;e Masquelier</a>",
          "description": "Spiking Neural Networks (SNNs) are a promising research direction for\nbuilding power-efficient information processing systems, especially for\ntemporal tasks such as speech recognition. In SNNs, delays refer to the time\nneeded for one spike to travel from one neuron to another. These delays matter\nbecause they influence the spike arrival times, and it is well-known that\nspiking neurons respond more strongly to coincident input spikes. More\nformally, it has been shown theoretically that plastic delays greatly increase\nthe expressivity in SNNs. Yet, efficient algorithms to learn these delays have\nbeen lacking. Here, we propose a new discrete-time algorithm that addresses\nthis issue in deep feedforward SNNs using backpropagation, in an offline\nmanner. To simulate delays between consecutive layers, we use 1D convolutions\nacross time. The kernels contain only a few non-zero weights - one per synapse\n- whose positions correspond to the delays. These positions are learned\ntogether with the weights using the recently proposed Dilated Convolution with\nLearnable Spacings (DCLS). We evaluated our method on three datasets: the\nSpiking Heidelberg Dataset (SHD), the Spiking Speech Commands (SSC) and its\nnon-spiking version Google Speech Commands v0.02 (GSC) benchmarks, which\nrequire detecting temporal patterns. We used feedforward SNNs with two or three\nhidden fully connected layers, and vanilla leaky integrate-and fire neurons. We\nshowed that fixed random delays help and that learning them helps even more.\nFurthermore, our method outperformed the state-of-the-art in the three datasets\nwithout using recurrent connections and with substantially fewer parameters.\nOur work demonstrates the potential of delay learning in developing accurate\nand precise models for temporal data processing. Our code is based on PyTorch /\nSpikingJelly and available at: https://github.com/Thvnvtos/SNN-delays",
          "link": "http://arxiv.org/abs/2306.17670",
          "publishedOn": "2023-09-02T00:40:02.854Z",
          "wordCount": null,
          "title": "Learning Delays in Spiking Neural Networks using Dilated Convolutions with Learnable Spacings. (arXiv:2306.17670v2 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.05109",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Water_R/0/1/0/all/0/1\">Robin van de Water</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_H/0/1/0/all/0/1\">Hendrik Schmidt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elbers_P/0/1/0/all/0/1\">Paul Elbers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thoral_P/0/1/0/all/0/1\">Patrick Thoral</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arnrich_B/0/1/0/all/0/1\">Bert Arnrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rockenschaub_P/0/1/0/all/0/1\">Patrick Rockenschaub</a>",
          "description": "Medical applications of machine learning (ML) have experienced a surge in\npopularity in recent years. The intensive care unit (ICU) is a natural habitat\nfor ML given the abundance of available data from electronic health records.\nModels have been proposed to address numerous ICU prediction tasks like the\nearly detection of complications. While authors frequently report\nstate-of-the-art performance, it is challenging to verify claims of\nsuperiority. Datasets and code are not always published, and cohort\ndefinitions, preprocessing pipelines, and training setups are difficult to\nreproduce. This work introduces Yet Another ICU Benchmark (YAIB), a modular\nframework that allows researchers to define reproducible and comparable\nclinical ML experiments; we offer an end-to-end solution from cohort definition\nto model evaluation. The framework natively supports most open-access ICU\ndatasets (MIMIC III/IV, eICU, HiRID, AUMCdb) and is easily adaptable to future\nICU datasets. Combined with a transparent preprocessing pipeline and extensible\ntraining code for multiple ML and deep learning models, YAIB enables unified\nmodel development. Our benchmark comes with five predefined established\nprediction tasks (mortality, acute kidney injury, sepsis, kidney function, and\nlength of stay) developed in collaboration with clinicians. Adding further\ntasks is straightforward by design. Using YAIB, we demonstrate that the choice\nof dataset, cohort definition, and preprocessing have a major impact on the\nprediction performance - often more so than model class - indicating an urgent\nneed for YAIB as a holistic benchmarking tool. We provide our work to the\nclinical ML community to accelerate method development and enable real-world\nclinical implementations. Software Repository:\nhttps://github.com/rvandewater/YAIB.",
          "link": "http://arxiv.org/abs/2306.05109",
          "publishedOn": "2023-09-02T00:40:02.853Z",
          "wordCount": null,
          "title": "Yet Another ICU Benchmark: A Flexible Multi-Center Framework for Clinical ML. (arXiv:2306.05109v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16139",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianning Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pepe_A/0/1/0/all/0/1\">Antonio Pepe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gsaxner_C/0/1/0/all/0/1\">Christina Gsaxner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luijten_G/0/1/0/all/0/1\">Gijs Luijten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1\">Yuan Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ambigapathy_N/0/1/0/all/0/1\">Narmada Ambigapathy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasca_E/0/1/0/all/0/1\">Enrico Nasca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solak_N/0/1/0/all/0/1\">Naida Solak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melito_G/0/1/0/all/0/1\">Gian Marco Melito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Memon_A/0/1/0/all/0/1\">Afaque R. Memon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaojun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirschke_J/0/1/0/all/0/1\">Jan Stefan Kirschke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosa_E/0/1/0/all/0/1\">Ezequiel de la Rosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christ_P/0/1/0/all/0/1\">Patrich Ferndinand Christ</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongwei Bran Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ellis_D/0/1/0/all/0/1\">David G. Ellis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aizenberg_M/0/1/0/all/0/1\">Michele R. Aizenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gatidis_S/0/1/0/all/0/1\">Sergios Gatidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuestner_T/0/1/0/all/0/1\">Thomas Kuestner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shusharina_N/0/1/0/all/0/1\">Nadya Shusharina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heller_N/0/1/0/all/0/1\">Nicholas Heller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andrearczyk_V/0/1/0/all/0/1\">Vincent Andrearczyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Depeursinge_A/0/1/0/all/0/1\">Adrien Depeursinge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hatt_M/0/1/0/all/0/1\">Mathieu Hatt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sekuboyina_A/0/1/0/all/0/1\">Anjany Sekuboyina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loeffler_M/0/1/0/all/0/1\">Maximilian Loeffler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liebl_H/0/1/0/all/0/1\">Hans Liebl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dorent_R/0/1/0/all/0/1\">Reuben Dorent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vercauteren_T/0/1/0/all/0/1\">Tom Vercauteren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shapey_J/0/1/0/all/0/1\">Jonathan Shapey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kujawa_A/0/1/0/all/0/1\">Aaron Kujawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cornelissen_S/0/1/0/all/0/1\">Stefan Cornelissen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langenhuizen_P/0/1/0/all/0/1\">Patrick Langenhuizen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_Hamadou_A/0/1/0/all/0/1\">Achraf Ben-Hamadou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rekik_A/0/1/0/all/0/1\">Ahmed Rekik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pujades_S/0/1/0/all/0/1\">Sergi Pujades</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boyer_E/0/1/0/all/0/1\">Edmond Boyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bolelli_F/0/1/0/all/0/1\">Federico Bolelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grana_C/0/1/0/all/0/1\">Costantino Grana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lumetti_L/0/1/0/all/0/1\">Luca Lumetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salehi_H/0/1/0/all/0/1\">Hamidreza Salehi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jun Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gharleghi_R/0/1/0/all/0/1\">Ramtin Gharleghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beier_S/0/1/0/all/0/1\">Susann Beier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sowmya_A/0/1/0/all/0/1\">Arcot Sowmya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garza_Villarreal_E/0/1/0/all/0/1\">Eduardo A. Garza-Villarreal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balducci_T/0/1/0/all/0/1\">Thania Balducci</a>, et al. (68 additional authors not shown)",
          "description": "We present MedShapeNet, a large collection of anatomical shapes (e.g., bones,\norgans, vessels) and 3D surgical instrument models. Prior to the deep learning\nera, the broad application of statistical shape models (SSMs) in medical image\nanalysis is evidence that shapes have been commonly used to describe medical\ndata. Nowadays, however, state-of-the-art (SOTA) deep learning algorithms in\nmedical imaging are predominantly voxel-based. In computer vision, on the\ncontrary, shapes (including, voxel occupancy grids, meshes, point clouds and\nimplicit surface models) are preferred data representations in 3D, as seen from\nthe numerous shape-related publications in premier vision conferences, such as\nthe IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), as\nwell as the increasing popularity of ShapeNet (about 51,300 models) and\nPrinceton ModelNet (127,915 models) in computer vision research. MedShapeNet is\ncreated as an alternative to these commonly used shape benchmarks to facilitate\nthe translation of data-driven vision algorithms to medical applications, and\nit extends the opportunities to adapt SOTA vision algorithms to solve critical\nmedical problems. Besides, the majority of the medical shapes in MedShapeNet\nare modeled directly on the imaging data of real patients, and therefore it\ncomplements well existing shape benchmarks comprising of computer-aided design\n(CAD) models. MedShapeNet currently includes more than 100,000 medical shapes,\nand provides annotations in the form of paired data. It is therefore also a\nfreely available repository of 3D models for extended reality (virtual reality\n- VR, augmented reality - AR, mixed reality - MR) and medical 3D printing. This\nwhite paper describes in detail the motivations behind MedShapeNet, the shape\nacquisition procedures, the use cases, as well as the usage of the online shape\nsearch portal: https://medshapenet.ikim.nrw/",
          "link": "http://arxiv.org/abs/2308.16139",
          "publishedOn": "2023-09-02T00:40:02.851Z",
          "wordCount": 1177,
          "title": "MedShapeNet -- A Large-Scale Dataset of 3D Medical Shapes for Computer Vision. (arXiv:2308.16139v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.07873",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yechao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shengshan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Leo Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Junyu Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Minghui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaogeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_W/0/1/0/all/0/1\">Wei Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1\">Hai Jin</a>",
          "description": "Adversarial examples (AEs) for DNNs have been shown to be transferable: AEs\nthat successfully fool white-box surrogate models can also deceive other\nblack-box models with different architectures. Although a bunch of empirical\nstudies have provided guidance on generating highly transferable AEs, many of\nthese findings lack explanations and even lead to inconsistent advice. In this\npaper, we take a further step towards understanding adversarial\ntransferability, with a particular focus on surrogate aspects. Starting from\nthe intriguing little robustness phenomenon, where models adversarially trained\nwith mildly perturbed adversarial samples can serve as better surrogates, we\nattribute it to a trade-off between two predominant factors: model smoothness\nand gradient similarity. Our investigations focus on their joint effects,\nrather than their separate correlations with transferability. Through a series\nof theoretical and empirical analyses, we conjecture that the data distribution\nshift in adversarial training explains the degradation of gradient similarity.\nBuilding on these insights, we explore the impacts of data augmentation and\ngradient regularization on transferability and identify that the trade-off\ngenerally exists in the various training mechanisms, thus building a\ncomprehensive blueprint for the regulation mechanism behind transferability.\nFinally, we provide a general route for constructing better surrogates to boost\ntransferability which optimizes both model smoothness and gradient similarity\nsimultaneously, e.g., the combination of input gradient regularization and\nsharpness-aware minimization (SAM), validated by extensive experiments. In\nsummary, we call for attention to the united impacts of these two factors for\nlaunching effective transfer attacks, rather than optimizing one while ignoring\nthe other, and emphasize the crucial role of manipulating surrogate models.",
          "link": "http://arxiv.org/abs/2307.07873",
          "publishedOn": "2023-09-02T00:40:02.843Z",
          "wordCount": 859,
          "title": "Why Does Little Robustness Help? Understanding and Improving Adversarial Transferability from Surrogate Training. (arXiv:2307.07873v5 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.08396",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Khan_A/0/1/0/all/0/1\">Abdul Rehman Khan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Khan_A/0/1/0/all/0/1\">Asifullah Khan</a>",
          "description": "In this work, we present MaxViT-UNet, an Encoder-Decoder based hybrid vision\ntransformer (CNN-Transformer) for medical image segmentation. The proposed\nHybrid Decoder, based on MaxViT-block, is designed to harness the power of both\nthe convolution and self-attention mechanisms at each decoding stage with a\nnominal memory and computational burden. The inclusion of multi-axis\nself-attention, within each decoder stage, significantly enhances the\ndiscriminating capacity between the object and background regions, thereby\nhelping in improving the segmentation efficiency. In the Hybrid Decoder block,\nthe fusion process commences by integrating the upsampled lower-level decoder\nfeatures, obtained through transpose convolution, with the skip-connection\nfeatures derived from the hybrid encoder. Subsequently, the fused features\nundergo refinement through the utilization of a multi-axis attention mechanism.\nThe proposed decoder block is repeated multiple times to progressively segment\nthe nuclei regions. Experimental results on MoNuSeg18 and MoNuSAC20 dataset\ndemonstrates the effectiveness of the proposed technique. Our MaxViT-UNet\noutperformed the previous CNN-based (UNet) and Transformer-based (Swin-UNet)\ntechniques by a considerable margin on both of the standard datasets. The\nfollowing github (https://github.com/PRLAB21/MaxViT-UNet) contains the\nimplementation and trained weights.",
          "link": "http://arxiv.org/abs/2305.08396",
          "publishedOn": "2023-09-02T00:40:02.837Z",
          "wordCount": 730,
          "title": "MaxViT-UNet: Multi-Axis Attention for Medical Image Segmentation. (arXiv:2305.08396v4 [eess.IV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.10474",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1\">Songwei Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nah_S/0/1/0/all/0/1\">Seungjun Nah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guilin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_T/0/1/0/all/0/1\">Tyler Poon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_A/0/1/0/all/0/1\">Andrew Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1\">Bryan Catanzaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobs_D/0/1/0/all/0/1\">David Jacobs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jia-Bin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Ming-Yu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balaji_Y/0/1/0/all/0/1\">Yogesh Balaji</a>",
          "description": "Despite tremendous progress in generating high-quality images using diffusion\nmodels, synthesizing a sequence of animated frames that are both photorealistic\nand temporally coherent is still in its infancy. While off-the-shelf\nbillion-scale datasets for image generation are available, collecting similar\nvideo data of the same scale is still challenging. Also, training a video\ndiffusion model is computationally much more expensive than its image\ncounterpart. In this work, we explore finetuning a pretrained image diffusion\nmodel with video data as a practical solution for the video synthesis task. We\nfind that naively extending the image noise prior to video noise prior in video\ndiffusion leads to sub-optimal performance. Our carefully designed video noise\nprior leads to substantially better performance. Extensive experimental\nvalidation shows that our model, Preserve Your Own Correlation (PYoCo), attains\nSOTA zero-shot text-to-video results on the UCF-101 and MSR-VTT benchmarks. It\nalso achieves SOTA video generation quality on the small-scale UCF-101\nbenchmark with a $10\\times$ smaller model using significantly less computation\nthan the prior art.",
          "link": "http://arxiv.org/abs/2305.10474",
          "publishedOn": "2023-09-02T00:40:02.831Z",
          "wordCount": 721,
          "title": "Preserve Your Own Correlation: A Noise Prior for Video Diffusion Models. (arXiv:2305.10474v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.08149",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wortwein_T/0/1/0/all/0/1\">Torsten W&#xf6;rtwein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allen_N/0/1/0/all/0/1\">Nicholas Allen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheeber_L/0/1/0/all/0/1\">Lisa B. Sheeber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Auerbach_R/0/1/0/all/0/1\">Randy P. Auerbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohn_J/0/1/0/all/0/1\">Jeffrey F. Cohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1\">Louis-Philippe Morency</a>",
          "description": "Personalized prediction is a machine learning approach that predicts a\nperson's future observations based on their past labeled observations and is\ntypically used for sequential tasks, e.g., to predict daily mood ratings. When\nmaking personalized predictions, a model can combine two types of trends: (a)\ntrends shared across people, i.e., person-generic trends, such as being happier\non weekends, and (b) unique trends for each person, i.e., person-specific\ntrends, such as a stressful weekly meeting. Mixed effect models are popular\nstatistical models to study both trends by combining person-generic and\nperson-specific parameters. Though linear mixed effect models are gaining\npopularity in machine learning by integrating them with neural networks, these\nintegrations are currently limited to linear person-specific parameters: ruling\nout nonlinear person-specific trends. In this paper, we propose Neural Mixed\nEffect (NME) models to optimize nonlinear person-specific parameters anywhere\nin a neural network in a scalable manner. NME combines the efficiency of neural\nnetwork optimization with nonlinear mixed effects modeling. Empirically, we\nobserve that NME improves performance across six unimodal and multimodal\ndatasets, including a smartphone dataset to predict daily mood and a\nmother-adolescent dataset to predict affective state sequences where half the\nmothers experience at least moderate symptoms of depression. Furthermore, we\nevaluate NME for two model architectures, including for neural conditional\nrandom fields (CRF) to predict affective state sequences where the CRF learns\nnonlinear person-specific temporal transitions between affective states.\nAnalysis of these person-specific transitions on the mother-adolescent dataset\nshows interpretable trends related to the mother's depression symptoms.",
          "link": "http://arxiv.org/abs/2306.08149",
          "publishedOn": "2023-09-02T00:40:02.811Z",
          "wordCount": 788,
          "title": "Neural Mixed Effects for Nonlinear Personalized Predictions. (arXiv:2306.08149v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.01890",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghashti_J/0/1/0/all/0/1\">Jesse S. Ghashti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thompson_J/0/1/0/all/0/1\">John R. J. Thompson</a>",
          "description": "Distance-based clustering and classification are widely used in various\nfields to group mixed numeric and categorical data. In many algorithms, a\npredefined distance measurement is used to cluster data points based on their\ndissimilarity. While there exist numerous distance-based measures for data with\npure numerical attributes and several ordered and unordered categorical\nmetrics, an efficient and accurate distance for mixed-type data that utilizes\nthe continuous and discrete properties simulatenously is an open problem. Many\nmetrics convert numerical attributes to categorical ones or vice versa. They\nhandle the data points as a single attribute type or calculate a distance\nbetween each attribute separately and add them up. We propose a metric called\nKDSUM that uses mixed kernels to measure dissimilarity, with cross-validated\noptimal bandwidth selection. We demonstrate that KDSUM is a shrinkage method\nfrom existing mixed-type metrics to a uniform dissimilarity metric, and\nimproves clustering accuracy when utilized in existing distance-based\nclustering algorithms on simulated and real-world datasets containing\ncontinuous-only, categorical-only, and mixed-type data.",
          "link": "http://arxiv.org/abs/2306.01890",
          "publishedOn": "2023-09-02T00:40:02.804Z",
          "wordCount": 725,
          "title": "Mixed-type Distance Shrinkage and Selection for Clustering via Kernel Metric Learning. (arXiv:2306.01890v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.15370",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lee_T/0/1/0/all/0/1\">Taehee Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_J/0/1/0/all/0/1\">Jun S. Liu</a>",
          "description": "Despite the widespread utilization of Gaussian process models for versatile\nnonparametric modeling, they exhibit limitations in effectively capturing\nabrupt changes in function smoothness and accommodating relationships with\nheteroscedastic errors. Addressing these shortcomings, the heteroscedastic\nGaussian process (HeGP) regression seeks to introduce flexibility by\nacknowledging the variability of residual variances across covariates in the\nregression model. In this work, we extend the HeGP concept, expanding its scope\nbeyond regression tasks to encompass classification and state-space models. To\nachieve this, we propose a novel framework where the Gaussian process is\ncoupled with a covariate-induced precision matrix process, adopting a mixture\nformulation. This approach enables the modeling of heteroscedastic covariance\nfunctions across covariates. To mitigate the computational challenges posed by\nsampling, we employ variational inference to approximate the posterior and\nfacilitate posterior predictive modeling. Additionally, our training process\nleverages an EM algorithm featuring closed-form M-step updates to efficiently\nevaluate the heteroscedastic covariance function. A notable feature of our\nmodel is its consistent performance on multivariate responses, accommodating\nvarious types (continuous or categorical) seamlessly. Through a combination of\nsimulations and real-world applications in climatology, we illustrate the\nmodel's prowess and advantages. By overcoming the limitations of traditional\nGaussian process models, our proposed framework offers a robust and versatile\ntool for a wide array of applications.",
          "link": "http://arxiv.org/abs/2308.15370",
          "publishedOn": "2023-09-02T00:40:02.798Z",
          "wordCount": 735,
          "title": "Multi-Response Heteroscedastic Gaussian Process Models and Their Inference. (arXiv:2308.15370v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.15034",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+White_C/0/1/0/all/0/1\">Colin White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_R/0/1/0/all/0/1\">Renbo Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kossaifi_J/0/1/0/all/0/1\">Jean Kossaifi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pekhimenko_G/0/1/0/all/0/1\">Gennady Pekhimenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azizzadenesheli_K/0/1/0/all/0/1\">Kamyar Azizzadenesheli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>",
          "description": "The Fourier neural operator (FNO) is a powerful technique for learning\nsurrogate maps for partial differential equation (PDE) solution operators. For\nmany real-world applications, which often require high-resolution data points,\ntraining time and memory usage are significant bottlenecks. While there are\nmixed-precision training techniques for standard neural networks, those work\nfor real-valued datatypes on finite dimensions and therefore cannot be directly\napplied to FNO, which crucially operates in the (complex-valued) Fourier domain\nand in function spaces. On the other hand, since the Fourier transform is\nalready an approximation (due to discretization error), we do not need to\nperform the operation at full precision. In this work, we (i) profile memory\nand runtime for FNO with full and mixed-precision training, (ii) conduct a\nstudy on the numerical stability of mixed-precision training of FNO, and (iii)\ndevise a training routine which substantially decreases training time and\nmemory usage (up to 34%), with little or no reduction in accuracy, on the\nNavier-Stokes and Darcy flow equations. Combined with the recently proposed\ntensorized FNO (Kossaifi et al., 2023), the resulting model has far better\nperformance while also being significantly faster than the original FNO.",
          "link": "http://arxiv.org/abs/2307.15034",
          "publishedOn": "2023-09-02T00:40:02.792Z",
          "wordCount": 720,
          "title": "Speeding up Fourier Neural Operators via Mixed Precision. (arXiv:2307.15034v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2306.05727",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weltevrede_M/0/1/0/all/0/1\">Max Weltevrede</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spaan_M/0/1/0/all/0/1\">Matthijs T.J. Spaan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohmer_W/0/1/0/all/0/1\">Wendelin B&#xf6;hmer</a>",
          "description": "In reinforcement learning (RL), key components of many algorithms are the\nexploration strategy and replay buffer. These strategies regulate what\nenvironment data is collected and trained on and have been extensively studied\nin the RL literature. In this paper, we investigate the impact of these\ncomponents in the context of generalisation in multi-task RL. We investigate\nthe hypothesis that collecting and training on more diverse data from the\ntraining environments will improve zero-shot generalisation to new tasks. We\nmotivate mathematically and show empirically that generalisation to tasks that\nare \"reachable'' during training is improved by increasing the diversity of\ntransitions in the replay buffer. Furthermore, we show empirically that this\nsame strategy also shows improvement for generalisation to similar but\n\"unreachable'' tasks which could be due to improved generalisation of the\nlearned latent representations.",
          "link": "http://arxiv.org/abs/2306.05727",
          "publishedOn": "2023-09-02T00:40:02.774Z",
          "wordCount": 666,
          "title": "The Role of Diverse Replay for Generalisation in Reinforcement Learning. (arXiv:2306.05727v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.11304",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yunyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_Z/0/1/0/all/0/1\">Zhixuan Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruan_Y/0/1/0/all/0/1\">Yijia Ruan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_G/0/1/0/all/0/1\">Ge Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuchen Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sheng Li</a>",
          "description": "Various probabilistic time series forecasting models have sprung up and shown\nremarkably good performance. However, the choice of model highly relies on the\ncharacteristics of the input time series and the fixed distribution that the\nmodel is based on. Due to the fact that the probability distributions cannot be\naveraged over different models straightforwardly, the current time series model\nensemble methods cannot be directly applied to improve the robustness and\naccuracy of forecasting. To address this issue, we propose pTSE, a multi-model\ndistribution ensemble method for probabilistic forecasting based on Hidden\nMarkov Model (HMM). pTSE only takes off-the-shelf outputs from member models\nwithout requiring further information about each model. Besides, we provide a\ncomplete theoretical analysis of pTSE to prove that the empirical distribution\nof time series subject to an HMM will converge to the stationary distribution\nalmost surely. Experiments on benchmarks show the superiority of pTSE overall\nmember models and competitive ensemble methods.",
          "link": "http://arxiv.org/abs/2305.11304",
          "publishedOn": "2023-09-02T00:40:02.767Z",
          "wordCount": 697,
          "title": "pTSE: A Multi-model Ensemble Method for Probabilistic Time Series Forecasting. (arXiv:2305.11304v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.09312",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hebert_L/0/1/0/all/0/1\">Liam Hebert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahu_G/0/1/0/all/0/1\">Gaurav Sahu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yuxuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sreenivas_N/0/1/0/all/0/1\">Nanda Kishore Sreenivas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golab_L/0/1/0/all/0/1\">Lukasz Golab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_R/0/1/0/all/0/1\">Robin Cohen</a>",
          "description": "We present the Multi-Modal Discussion Transformer (mDT), a novel multi-modal\ngraph-based transformer model for detecting hate speech in online social\nnetworks, such as Reddit discussions. In contrast to traditional comment-only\nmethods, our approach to labelling a comment as hate speech involves a holistic\nanalysis of text and images grounded in the discussion context. This is done by\nleveraging graph transformers to capture the contextual relationships in the\nentire discussion surrounding a comment and grounding the interwoven fusion\nlayers that combine individual comments' text and image embeddings instead of\nprocessing modalities separately. We compare the performance of our model to\nbaselines that only process individual comments and conduct extensive ablation\nstudies. To evaluate our work, we present a new dataset, HatefulDiscussions,\ncomprising complete multi-modal discussions from multiple online communities on\nReddit. We conclude with future work for multimodal solutions to deliver social\nvalue in online contexts, arguing that capturing a holistic view of a\nconversation significantly advances the effort to detect anti-social behaviour.",
          "link": "http://arxiv.org/abs/2307.09312",
          "publishedOn": "2023-09-02T00:40:02.720Z",
          "wordCount": 728,
          "title": "Multi-Modal Discussion Transformer: Integrating Text, Images and Graph Transformers to Detect Hate Speech on Social Media. (arXiv:2307.09312v2 [cs.CL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.11463",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hertrich_J/0/1/0/all/0/1\">Johannes Hertrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wald_C/0/1/0/all/0/1\">Christian Wald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altekruger_F/0/1/0/all/0/1\">Fabian Altekr&#xfc;ger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hagemann_P/0/1/0/all/0/1\">Paul Hagemann</a>",
          "description": "Maximum mean discrepancy (MMD) flows suffer from high computational costs in\nlarge scale computations. In this paper, we show that MMD flows with Riesz\nkernels $K(x,y) = - \\Vert x-y\\Vert^r$, $r \\in (0,2)$ have exceptional\nproperties which allow their efficient computation. We prove that the MMD of\nRiesz kernels coincides with the MMD of their sliced version. As a consequence,\nthe computation of gradients of MMDs can be performed in the one-dimensional\nsetting. Here, for $r=1$, a simple sorting algorithm can be applied to reduce\nthe complexity from $O(MN+N^2)$ to $O((M+N)\\log(M+N))$ for two measures with\n$M$ and $N$ support points. As another interesting follow-up result, the MMD of\ncompactly supported measures can be estimated from above and below by the\nWasserstein-1 distance. For the implementations we approximate the gradient of\nthe sliced MMD by using only a finite number $P$ of slices. We show that the\nresulting error has complexity $O(\\sqrt{d/P})$, where $d$ is the data\ndimension. These results enable us to train generative models by approximating\nMMD gradient flows by neural networks even for image applications. We\ndemonstrate the efficiency of our model by image generation on MNIST,\nFashionMNIST and CIFAR10.",
          "link": "http://arxiv.org/abs/2305.11463",
          "publishedOn": "2023-09-02T00:40:02.714Z",
          "wordCount": 717,
          "title": "Generative Sliced MMD Flows with Riesz Kernels. (arXiv:2305.11463v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.02329",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Skocaj_M/0/1/0/all/0/1\">Marco Skocaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conserva_F/0/1/0/all/0/1\">Francesca Conserva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grande_N/0/1/0/all/0/1\">Nicol Sarcone Grande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orsi_A/0/1/0/all/0/1\">Andrea Orsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Micheli_D/0/1/0/all/0/1\">Davide Micheli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghinamo_G/0/1/0/all/0/1\">Giorgio Ghinamo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bizzarri_S/0/1/0/all/0/1\">Simone Bizzarri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verdone_R/0/1/0/all/0/1\">Roberto Verdone</a>",
          "description": "The advent of novel 5G services and applications with binding latency\nrequirements and guaranteed Quality of Service (QoS) hastened the need to\nincorporate autonomous and proactive decision-making in network management\nprocedures. The objective of our study is to provide a thorough analysis of\npredictive latency within 5G networks by utilizing real-world network data that\nis accessible to mobile network operators (MNOs). In particular, (i) we present\nan analytical formulation of the user-plane latency as a Hypoexponential\ndistribution, which is validated by means of a comparative analysis with\nempirical measurements, and (ii) we conduct experimental results of\nprobabilistic regression, anomaly detection, and predictive forecasting\nleveraging on emerging domains in Machine Learning (ML), such as Bayesian\nLearning (BL) and Machine Learning on Graphs (GML). We test our predictive\nframework using data gathered from scenarios of vehicular mobility, dense-urban\ntraffic, and social gathering events. Our results provide valuable insights\ninto the efficacy of predictive algorithms in practical applications.",
          "link": "http://arxiv.org/abs/2307.02329",
          "publishedOn": "2023-09-02T00:40:02.708Z",
          "wordCount": 712,
          "title": "Data-driven Predictive Latency for 5G: A Theoretical and Experimental Analysis Using Network Measurements. (arXiv:2307.02329v3 [cs.NI] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2307.05628",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_D/0/1/0/all/0/1\">Daoan Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_W/0/1/0/all/0/1\">Weitong Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhao_Y/0/1/0/all/0/1\">Yu Zhao</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_J/0/1/0/all/0/1\">Jianguo Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+He_B/0/1/0/all/0/1\">Bing He</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Qin_C/0/1/0/all/0/1\">Chenchen Qin</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Yao_J/0/1/0/all/0/1\">Jianhua Yao</a>",
          "description": "Pre-trained large language models demonstrate potential in extracting\ninformation from DNA sequences, yet adapting to a variety of tasks and data\nmodalities remains a challenge. To address this, we propose DNAGPT, a\ngeneralized DNA pre-training model trained on over 200 billion base pairs from\nall mammals. By enhancing the classic GPT model with a binary classification\ntask (DNA sequence order), a numerical regression task (guanine-cytosine\ncontent prediction), and a comprehensive token language, DNAGPT can handle\nversatile DNA analysis tasks while processing both sequence and numerical data.\nOur evaluation of genomic signal and region recognition, mRNA abundance\nregression, and artificial genomes generation tasks demonstrates DNAGPT's\nsuperior performance compared to existing models designed for specific\ndownstream tasks, benefiting from pre-training using the newly designed model\nstructure.",
          "link": "http://arxiv.org/abs/2307.05628",
          "publishedOn": "2023-09-02T00:40:02.596Z",
          "wordCount": 666,
          "title": "DNAGPT: A Generalized Pre-trained Tool for Versatile DNA Sequence Analysis Tasks. (arXiv:2307.05628v3 [q-bio.GN] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2206.07741",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schaefer_C/0/1/0/all/0/1\">Clemens JS Schaefer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_S/0/1/0/all/0/1\">Siddharth Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blazquez_R/0/1/0/all/0/1\">Raul Blazquez</a>",
          "description": "The large computing and memory cost of deep neural networks (DNNs) often\nprecludes their use in resource-constrained devices. Quantizing the parameters\nand operations to lower bit-precision offers substantial memory and energy\nsavings for neural network inference, facilitating the use of DNNs on edge\ncomputing platforms. Recent efforts at quantizing DNNs have employed a range of\ntechniques encompassing progressive quantization, step-size adaptation, and\ngradient scaling. This paper proposes a new quantization approach for mixed\nprecision convolutional neural networks (CNNs) targeting edge-computing. Our\nmethod establishes a new pareto frontier in model accuracy and memory footprint\ndemonstrating a range of quantized models, delivering best-in-class accuracy\nbelow 4.3 MB of weights (wgts.) and activations (acts.). Our main contributions\nare: (i) hardware-aware heterogeneous differentiable quantization with\ntensor-sliced learned precision, (ii) targeted gradient modification for wgts.\nand acts. to mitigate quantization errors, and (iii) a multi-phase learning\nschedule to address instability in learning arising from updates to the learned\nquantizer and model parameters. We demonstrate the effectiveness of our\ntechniques on the ImageNet dataset across a range of models including\nEfficientNet-Lite0 (e.g., 4.14MB of wgts. and acts. at 67.66% accuracy) and\nMobileNetV2 (e.g., 3.51MB wgts. and acts. at 65.39% accuracy).",
          "link": "http://arxiv.org/abs/2206.07741",
          "publishedOn": "2023-09-02T00:40:02.519Z",
          "wordCount": 734,
          "title": "Edge Inference with Fully Differentiable Quantized Mixed Precision Neural Networks. (arXiv:2206.07741v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.03450",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leblanc_B/0/1/0/all/0/1\">Benjamin Leblanc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Germain_P/0/1/0/all/0/1\">Pascal Germain</a>",
          "description": "We study the use of binary activated neural networks as interpretable and\nexplainable predictors in the context of regression tasks on tabular data; more\nspecifically, we provide guarantees on their expressiveness, present an\napproach based on the efficient computation of SHAP values for quantifying the\nrelative importance of the features, hidden neurons and even weights. As the\nmodel's simplicity is instrumental in achieving interpretability, we propose a\ngreedy algorithm for building compact binary activated networks. This approach\ndoesn't need to fix an architecture for the network in advance: it is built one\nlayer at a time, one neuron at a time, leading to predictors that aren't\nneedlessly complex for a given task.",
          "link": "http://arxiv.org/abs/2209.03450",
          "publishedOn": "2023-09-02T00:40:02.501Z",
          "wordCount": 629,
          "title": "Seeking Interpretability and Explainability in Binary Activated Neural Networks. (arXiv:2209.03450v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.09981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1\">Soyeon Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1\">Mykel J. Kochenderfer</a>",
          "description": "Realistic aircraft trajectory models are useful in the design and validation\nof air traffic management (ATM) systems. Models of aircraft operated under\ninstrument flight rules (IFR) require capturing the variability inherent in how\naircraft follow standard flight procedures. The variability in aircraft\nbehavior varies among flight stages. In this paper, we propose a probabilistic\nmodel that can learn the variability from the procedural data and flight tracks\ncollected from radar surveillance data. For each segment, a Gaussian mixture\nmodel is used to learn the deviations of aircraft trajectories from their\nprocedures. Given new procedures, we can generate synthetic trajectories by\nsampling a series of deviations from the trained Gaussian distributions and\nreconstructing the aircraft trajectory using the deviations and the procedures.\nWe extend this method to capture pairwise correlations between aircraft and\nshow how a pairwise model can be used to generate traffic involving an\narbitrary number of aircraft. We demonstrate the proposed models on the arrival\ntracks and procedures of the John F. Kennedy International Airport. The\ndistributional similarity between the original and the synthetic trajectory\ndataset was evaluated using the Jensen-Shannon divergence between the empirical\ndistributions of different variables. We also provide qualitative analyses of\nthe synthetic trajectories generated from the models.",
          "link": "http://arxiv.org/abs/2303.09981",
          "publishedOn": "2023-09-02T00:40:02.484Z",
          "wordCount": 733,
          "title": "Inferring Traffic Models in Terminal Airspace from Flight Tracks and Procedures. (arXiv:2303.09981v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2303.00262",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sarukkai_V/0/1/0/all/0/1\">Vishnu Sarukkai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linden Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_A/0/1/0/all/0/1\">Arden Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Re_C/0/1/0/all/0/1\">Christopher R&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fatahalian_K/0/1/0/all/0/1\">Kayvon Fatahalian</a>",
          "description": "We seek to give users precise control over diffusion-based image generation\nby modeling complex scenes as sequences of layers, which define the desired\nspatial arrangement and visual attributes of objects in the scene. Collage\nDiffusion harmonizes the input layers to make objects fit together -- the key\nchallenge involves minimizing changes in the positions and key visual\nattributes of the input layers while allowing other attributes to change in the\nharmonization process. We ensure that objects are generated in the correct\nlocations by modifying text-image cross-attention with the layers' alpha masks.\nWe preserve key visual attributes of input layers by learning specialized text\nrepresentations per layer and by extending ControlNet to operate on layers.\nLayer input allows users to control the extent of image harmonization on a\nper-object basis, and users can even iteratively edit individual objects in\ngenerated images while keeping other objects fixed. By leveraging the rich\ninformation present in layer input, Collage Diffusion generates globally\nharmonized images that maintain desired object characteristics better than\nprior approaches.",
          "link": "http://arxiv.org/abs/2303.00262",
          "publishedOn": "2023-09-02T00:40:02.477Z",
          "wordCount": 672,
          "title": "Collage Diffusion. (arXiv:2303.00262v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.12977",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1\">Dongliang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_Z/0/1/0/all/0/1\">Zhixuan Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sheng Li</a>",
          "description": "Tackling unfairness in graph learning models is a challenging task, as the\nunfairness issues on graphs involve both attributes and topological structures.\nExisting work on fair graph learning simply assumes that attributes of all\nnodes are available for model training and then makes fair predictions. In\npractice, however, the attributes of some nodes might not be accessible due to\nmissing data or privacy concerns, which makes fair graph learning even more\nchallenging. In this paper, we propose FairAC, a fair attribute completion\nmethod, to complement missing information and learn fair node embeddings for\ngraphs with missing attributes. FairAC adopts an attention mechanism to deal\nwith the attribute missing problem and meanwhile, it mitigates two types of\nunfairness, i.e., feature unfairness from attributes and topological unfairness\ndue to attribute completion. FairAC can work on various types of homogeneous\ngraphs and generate fair embeddings for them and thus can be applied to most\ndownstream tasks to improve their fairness performance. To our best knowledge,\nFairAC is the first method that jointly addresses the graph attribution\ncompletion and graph unfairness problems. Experimental results on benchmark\ndatasets show that our method achieves better fairness performance with less\nsacrifice in accuracy, compared with the state-of-the-art methods of fair graph\nlearning. Code is available at: https://github.com/donglgcn/FairAC.",
          "link": "http://arxiv.org/abs/2302.12977",
          "publishedOn": "2023-09-02T00:40:02.465Z",
          "wordCount": 742,
          "title": "Fair Attribute Completion on Graph with Missing Attributes. (arXiv:2302.12977v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.13455",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zubic_N/0/1/0/all/0/1\">Nikola Zubi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gehrig_D/0/1/0/all/0/1\">Daniel Gehrig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gehrig_M/0/1/0/all/0/1\">Mathias Gehrig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scaramuzza_D/0/1/0/all/0/1\">Davide Scaramuzza</a>",
          "description": "Today, state-of-the-art deep neural networks that process events first\nconvert them into dense, grid-like input representations before using an\noff-the-shelf network. However, selecting the appropriate representation for\nthe task traditionally requires training a neural network for each\nrepresentation and selecting the best one based on the validation score, which\nis very time-consuming. This work eliminates this bottleneck by selecting\nrepresentations based on the Gromov-Wasserstein Discrepancy (GWD) between raw\nevents and their representation. It is about 200 times faster to compute than\ntraining a neural network and preserves the task performance ranking of event\nrepresentations across multiple representations, network backbones, datasets,\nand tasks. Thus finding representations with high task scores is equivalent to\nfinding representations with a low GWD. We use this insight to, for the first\ntime, perform a hyperparameter search on a large family of event\nrepresentations, revealing new and powerful representations that exceed the\nstate-of-the-art. Our optimized representations outperform existing\nrepresentations by 1.7 mAP on the 1 Mpx dataset and 0.3 mAP on the Gen1\ndataset, two established object detection benchmarks, and reach a 3.8% higher\nclassification score on the mini N-ImageNet benchmark. Moreover, we outperform\nstate-of-the-art by 2.1 mAP on Gen1 and state-of-the-art feed-forward methods\nby 6.0 mAP on the 1 Mpx datasets. This work opens a new unexplored field of\nexplicit representation optimization for event-based learning.",
          "link": "http://arxiv.org/abs/2304.13455",
          "publishedOn": "2023-09-02T00:40:02.459Z",
          "wordCount": 788,
          "title": "From Chaos Comes Order: Ordering Event Representations for Object Recognition and Detection. (arXiv:2304.13455v4 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.16900",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bender_T/0/1/0/all/0/1\">Thoranna Bender</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sorensen_S/0/1/0/all/0/1\">Simon M&#xf8;e S&#xf8;rensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kashani_A/0/1/0/all/0/1\">Alireza Kashani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hjorleifsson_K/0/1/0/all/0/1\">K. Eldjarn Hjorleifsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hyldig_G/0/1/0/all/0/1\">Grethe Hyldig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1\">S&#xf8;ren Hauberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belongie_S/0/1/0/all/0/1\">Serge Belongie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warburg_F/0/1/0/all/0/1\">Frederik Warburg</a>",
          "description": "We present WineSensed, a large multimodal wine dataset for studying the\nrelations between visual perception, language, and flavor. The dataset\nencompasses 897k images of wine labels and 824k reviews of wines curated from\nthe Vivino platform. It has over 350k unique vintages, annotated with year,\nregion, rating, alcohol percentage, price, and grape composition. We obtained\nfine-grained flavor annotations on a subset by conducting a wine-tasting\nexperiment with 256 participants who were asked to rank wines based on their\nsimilarity in flavor, resulting in more than 5k pairwise flavor distances. We\npropose a low-dimensional concept embedding algorithm that combines human\nexperience with automatic machine similarity kernels. We demonstrate that this\nshared concept embedding space improves upon separate embedding spaces for\ncoarse flavor classification (alcohol percentage, country, grape, price,\nrating) and aligns with the intricate human perception of flavor.",
          "link": "http://arxiv.org/abs/2308.16900",
          "publishedOn": "2023-09-02T00:40:02.434Z",
          "wordCount": 644,
          "title": "Learning to Taste: A Multimodal Wine Dataset. (arXiv:2308.16900v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.16891",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ze_Y/0/1/0/all/0/1\">Yanjie Ze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_G/0/1/0/all/0/1\">Ge Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yueh-Hua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Macaluso_A/0/1/0/all/0/1\">Annabella Macaluso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yuying Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jianglong Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hansen_N/0/1/0/all/0/1\">Nicklas Hansen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Li Erran Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolong Wang</a>",
          "description": "It is a long-standing problem in robotics to develop agents capable of\nexecuting diverse manipulation tasks from visual observations in unstructured\nreal-world environments. To achieve this goal, the robot needs to have a\ncomprehensive understanding of the 3D structure and semantics of the scene. In\nthis work, we present $\\textbf{GNFactor}$, a visual behavior cloning agent for\nmulti-task robotic manipulation with $\\textbf{G}$eneralizable $\\textbf{N}$eural\nfeature $\\textbf{F}$ields. GNFactor jointly optimizes a generalizable neural\nfield (GNF) as a reconstruction module and a Perceiver Transformer as a\ndecision-making module, leveraging a shared deep 3D voxel representation. To\nincorporate semantics in 3D, the reconstruction module utilizes a\nvision-language foundation model ($\\textit{e.g.}$, Stable Diffusion) to distill\nrich semantic information into the deep 3D voxel. We evaluate GNFactor on 3\nreal robot tasks and perform detailed ablations on 10 RLBench tasks with a\nlimited number of demonstrations. We observe a substantial improvement of\nGNFactor over current state-of-the-art methods in seen and unseen tasks,\ndemonstrating the strong generalization ability of GNFactor. Our project\nwebsite is https://yanjieze.com/GNFactor/ .",
          "link": "http://arxiv.org/abs/2308.16891",
          "publishedOn": "2023-09-02T00:40:02.428Z",
          "wordCount": 699,
          "title": "GNFactor: Multi-Task Real Robot Learning with Generalizable Neural Feature Fields. (arXiv:2308.16891v1 [cs.RO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.14172",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_B/0/1/0/all/0/1\">Bohan Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Siheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xiaowen Dong</a>",
          "description": "Hypergraphs are important for processing data with higher-order relationships\ninvolving more than two entities. In scenarios where explicit hypergraphs are\nnot readily available, it is desirable to infer a meaningful hypergraph\nstructure from the node features to capture the intrinsic relations within the\ndata. However, existing methods either adopt simple pre-defined rules that fail\nto precisely capture the distribution of the potential hypergraph structure, or\nlearn a mapping between hypergraph structures and node features but require a\nlarge amount of labelled data, i.e., pre-existing hypergraph structures, for\ntraining. Both restrict their applications in practical scenarios. To fill this\ngap, we propose a novel smoothness prior that enables us to design a method to\ninfer the probability for each potential hyperedge without labelled data as\nsupervision. The proposed prior indicates features of nodes in a hyperedge are\nhighly correlated by the features of the hyperedge containing them. We use this\nprior to derive the relation between the hypergraph structure and the node\nfeatures via probabilistic modelling. This allows us to develop an unsupervised\ninference method to estimate the probability for each potential hyperedge via\nsolving an optimisation problem that has an analytical solution. Experiments on\nboth synthetic and real-world data demonstrate that our method can learn\nmeaningful hypergraph structures from data more efficiently than existing\nhypergraph structure inference methods.",
          "link": "http://arxiv.org/abs/2308.14172",
          "publishedOn": "2023-09-02T00:40:02.324Z",
          "wordCount": null,
          "title": "Hypergraph Structure Inference From Data Under Smoothness Prior. (arXiv:2308.14172v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.02611",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khorzooghi_S/0/1/0/all/0/1\">Seyyed Mohammad Sadegh Moosavi Khorzooghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nilizadeh_S/0/1/0/all/0/1\">Shirin Nilizadeh</a>",
          "description": "Face de-identification methods have been proposed to preserve users' privacy\nby obscuring their faces. These methods, however, can degrade the quality of\nphotos, and they usually do not preserve the utility of faces, i.e., their age,\ngender, pose, and facial expression. Recently, GANs, such as StyleGAN, have\nbeen proposed, which generate realistic, high-quality imaginary faces. In this\npaper, we investigate the use of StyleGAN in generating de-identified faces\nthrough style mixing. We examined this de-identification method for preserving\nutility and privacy by implementing several face detection, verification, and\nidentification attacks and conducting a user study. The results from our\nextensive experiments, human evaluation, and comparison with two\nstate-of-the-art methods, i.e., CIAGAN and DeepPrivacy, show that StyleGAN\nperforms on par or better than these methods, preserving users' privacy and\nimages' utility. In particular, the results of the machine learning-based\nexperiments show that StyleGAN0-4 preserves utility better than CIAGAN and\nDeepPrivacy while preserving privacy at the same level. StyleGAN0-3 preserves\nutility at the same level while providing more privacy. In this paper, for the\nfirst time, we also performed a carefully designed user study to examine both\nprivacy and utility-preserving properties of StyleGAN0-3, 0-4, and 0-5, as well\nas CIAGAN and DeepPrivacy from the human observers' perspectives. Our\nstatistical tests showed that participants tend to verify and identify\nStyleGAN0-5 images more easily than DeepPrivacy images. All the methods but\nStyleGAN0-5 had significantly lower identification rates than CIAGAN. Regarding\nutility, as expected, StyleGAN0-5 performed significantly better in preserving\nsome attributes. Among all methods, on average, participants believe gender has\nbeen preserved the most while naturalness has been preserved the least.",
          "link": "http://arxiv.org/abs/2212.02611",
          "publishedOn": "2023-09-02T00:40:02.323Z",
          "wordCount": null,
          "title": "StyleGAN as a Utility-Preserving Face De-identification Method. (arXiv:2212.02611v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.13570",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dianhui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Felicetti_M/0/1/0/all/0/1\">Matthew J. Felicetti</a>",
          "description": "Real-time predictive modelling with desired accuracy is highly expected in\nindustrial artificial intelligence (IAI), where neural networks play a key\nrole. Neural networks in IAI require powerful, high-performance computing\ndevices to operate a large number of floating point data. Based on stochastic\nconfiguration networks (SCNs), this paper proposes a new randomized learner\nmodel, termed stochastic configuration machines (SCMs), to stress effective\nmodelling and data size saving that are useful and valuable for industrial\napplications. Compared to SCNs and random vector functional-link (RVFL) nets\nwith binarized implementation, the model storage of SCMs can be significantly\ncompressed while retaining favourable prediction performance. Besides the\narchitecture of the SCM learner model and its learning algorithm, as an\nimportant part of this contribution, we also provide a theoretical basis on the\nlearning capacity of SCMs by analysing the model's complexity. Experimental\nstudies are carried out over some benchmark datasets and three industrial\napplications. The results demonstrate that SCM has great potential for dealing\nwith industrial data analytics.",
          "link": "http://arxiv.org/abs/2308.13570",
          "publishedOn": "2023-09-02T00:40:02.322Z",
          "wordCount": null,
          "title": "Stochastic Configuration Machines for Industrial Artificial Intelligence. (arXiv:2308.13570v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.11029",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Lin Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Guoheng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1\">Fenghuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1\">Xiaochen Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pun_C/0/1/0/all/0/1\">Chi-Man Pun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_G/0/1/0/all/0/1\">Guo Zhong</a>",
          "description": "Emotion recognition in conversation (ERC) has received increasing attention\nfrom researchers due to its wide range of applications.As conversation has a\nnatural graph structure,numerous approaches used to model ERC based on graph\nconvolutional networks (GCNs) have yielded significant results.However,the\naggregation approach of traditional GCNs suffers from the node information\nredundancy problem,leading to node discriminant information\nloss.Additionally,single-layer GCNs lack the capacity to capture long-range\ncontextual information from the graph. Furthermore,the majority of approaches\nare based on textual modality or stitching together different modalities,\nresulting in a weak ability to capture interactions between modalities. To\naddress these problems, we present the relational bilevel aggregation graph\nconvolutional network (RBA-GCN), which consists of three modules: the graph\ngeneration module (GGM), similarity-based cluster building module (SCBM) and\nbilevel aggregation module (BiAM). First, GGM constructs a novel graph to\nreduce the redundancy of target node information.Then,SCBM calculates the node\nsimilarity in the target node and its structural neighborhood, where noisy\ninformation with low similarity is filtered out to preserve the discriminant\ninformation of the node. Meanwhile, BiAM is a novel aggregation method that can\npreserve the information of nodes during the aggregation process. This module\ncan construct the interaction between different modalities and capture\nlong-range contextual information based on similarity clusters. On both the\nIEMOCAP and MELD datasets, the weighted average F1 score of RBA-GCN has a\n2.17$\\sim$5.21\\% improvement over that of the most advanced method.Our code is\navailable at https://github.com/luftmenscher/RBA-GCN and our article with the\nsame name has been published in IEEE/ACM Transactions on Audio,Speech,and\nLanguage Processing,vol.31,2023",
          "link": "http://arxiv.org/abs/2308.11029",
          "publishedOn": "2023-09-02T00:40:02.321Z",
          "wordCount": null,
          "title": "RBA-GCN: Relational Bilevel Aggregation Graph Convolutional Network for Emotion Recognition. (arXiv:2308.11029v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.11155",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pengmei_Z/0/1/0/all/0/1\">Zihan Pengmei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_Y/0/1/0/all/0/1\">Yinan Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Junyu Liu</a>",
          "description": "Neural force fields (NFFs) have gained prominence in computational chemistry\nas surrogate models, superseding quantum-chemistry calculations in ab initio\nmolecular dynamics. The prevalent benchmark for NFFs has been the MD17 dataset\nand its subsequent extension. These datasets predominantly comprise geometries\nfrom the equilibrium region of the ground electronic state potential energy\nsurface, sampling from direct adiabatic dynamics. However, many chemical\nreactions entail significant molecular deformations, notably bond breaking. We\ndemonstrate the constrained distribution of internal coordinates and energies\nin the MD17 datasets, underscoring their inadequacy for representing systems\nundergoing chemical reactions. Addressing this sampling limitation, we\nintroduce the xxMD (Extended Excited-state Molecular Dynamics) dataset, derived\nfrom non-adiabatic dynamics. This dataset encompasses energies and forces\nascertained from both multireference wave function theory and density\nfunctional theory. Furthermore, its nuclear configuration spaces authentically\ndepict chemical reactions, making xxMD a more chemically relevant dataset. Our\nre-assessment of equivariant models on the xxMD datasets reveals notably higher\nmean absolute errors than those reported for MD17 and its variants. This\nobservation underscores the challenges faced in crafting a generalizable NFF\nmodel with extrapolation capability. Our proposed xxMD-CASSCF and xxMD-DFT\ndatasets are available at https://github.com/zpengmei/xxMD.",
          "link": "http://arxiv.org/abs/2308.11155",
          "publishedOn": "2023-09-02T00:40:02.320Z",
          "wordCount": null,
          "title": "xxMD: Benchmarking Neural Force Fields Using Extended Dynamics beyond Equilibrium. (arXiv:2308.11155v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.06720",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1\">Songwei Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_T/0/1/0/all/0/1\">Taesung Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun-Yan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jia-Bin Huang</a>",
          "description": "Plain text has become a prevalent interface for text-to-image synthesis.\nHowever, its limited customization options hinder users from accurately\ndescribing desired outputs. For example, plain text makes it hard to specify\ncontinuous quantities, such as the precise RGB color value or importance of\neach word. Furthermore, creating detailed text prompts for complex scenes is\ntedious for humans to write and challenging for text encoders to interpret. To\naddress these challenges, we propose using a rich-text editor supporting\nformats such as font style, size, color, and footnote. We extract each word's\nattributes from rich text to enable local style control, explicit token\nreweighting, precise color rendering, and detailed region synthesis. We achieve\nthese capabilities through a region-based diffusion process. We first obtain\neach word's region based on attention maps of a diffusion process using plain\ntext. For each region, we enforce its text attributes by creating\nregion-specific detailed prompts and applying region-specific guidance, and\nmaintain its fidelity against plain-text generation through region-based\ninjections. We present various examples of image generation from rich text and\ndemonstrate that our method outperforms strong baselines with quantitative\nevaluations.",
          "link": "http://arxiv.org/abs/2304.06720",
          "publishedOn": "2023-09-02T00:40:02.318Z",
          "wordCount": null,
          "title": "Expressive Text-to-Image Generation with Rich Text. (arXiv:2304.06720v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.14994",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Finzi_M/0/1/0/all/0/1\">Marc Finzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potapczynski_A/0/1/0/all/0/1\">Andres Potapczynski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choptuik_M/0/1/0/all/0/1\">Matthew Choptuik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1\">Andrew Gordon Wilson</a>",
          "description": "Unlike conventional grid and mesh based methods for solving partial\ndifferential equations (PDEs), neural networks have the potential to break the\ncurse of dimensionality, providing approximate solutions to problems where\nusing classical solvers is difficult or impossible. While global minimization\nof the PDE residual over the network parameters works well for boundary value\nproblems, catastrophic forgetting impairs the applicability of this approach to\ninitial value problems (IVPs). In an alternative local-in-time approach, the\noptimization problem can be converted into an ordinary differential equation\n(ODE) on the network parameters and the solution propagated forward in time;\nhowever, we demonstrate that current methods based on this approach suffer from\ntwo key issues. First, following the ODE produces an uncontrolled growth in the\nconditioning of the problem, ultimately leading to unacceptably large numerical\nerrors. Second, as the ODE methods scale cubically with the number of model\nparameters, they are restricted to small neural networks, significantly\nlimiting their ability to represent intricate PDE initial conditions and\nsolutions. Building on these insights, we develop Neural IVP, an ODE based IVP\nsolver which prevents the network from getting ill-conditioned and runs in time\nlinear in the number of parameters, enabling us to evolve the dynamics of\nchallenging PDEs with neural networks.",
          "link": "http://arxiv.org/abs/2304.14994",
          "publishedOn": "2023-09-02T00:40:02.318Z",
          "wordCount": null,
          "title": "A Stable and Scalable Method for Solving Initial Value PDEs with Neural Networks. (arXiv:2304.14994v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.03312",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pei_K/0/1/0/all/0/1\">Kexin Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weichen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1\">Qirui Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shuyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_S/0/1/0/all/0/1\">Scott Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cavallaro_L/0/1/0/all/0/1\">Lorenzo Cavallaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Junfeng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jana_S/0/1/0/all/0/1\">Suman Jana</a>",
          "description": "Large Language Models (LLMs) have shown promise in automated program\nreasoning, a crucial aspect of many security tasks. However, existing LLM\narchitectures for code are often borrowed from other domains like natural\nlanguage processing, raising concerns about their generalization and robustness\nto unseen code. A key generalization challenge is to incorporate the knowledge\nof code semantics, including control and data flow, into the LLM architectures.\n\nDrawing inspiration from examples of convolution layers exploiting\ntranslation symmetry, we explore how code symmetries can enhance LLM\narchitectures for program analysis and modeling. We present a rigorous\ngroup-theoretic framework that formally defines code symmetries as\nsemantics-preserving transformations and provides techniques for precisely\nreasoning about symmetry preservation within LLM architectures. Using this\nframework, we introduce a novel variant of self-attention that preserves\nprogram symmetries, demonstrating its effectiveness in generalization and\nrobustness through detailed experimental evaluations across different binary\nand source code analysis tasks. Overall, our code symmetry framework offers\nrigorous and powerful reasoning techniques that can guide the future\ndevelopment of specialized LLMs for code and advance LLM-guided program\nreasoning tasks.",
          "link": "http://arxiv.org/abs/2308.03312",
          "publishedOn": "2023-09-02T00:40:02.318Z",
          "wordCount": null,
          "title": "Symmetry-Preserving Program Representations for Learning Code Semantics. (arXiv:2308.03312v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.10283",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thanasutives_P/0/1/0/all/0/1\">Pongpisit Thanasutives</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morita_T/0/1/0/all/0/1\">Takashi Morita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Numao_M/0/1/0/all/0/1\">Masayuki Numao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fukui_K/0/1/0/all/0/1\">Ken-ichi Fukui</a>",
          "description": "We propose a new parameter-adaptive uncertainty-penalized Bayesian\ninformation criterion (UBIC) to prioritize the parsimonious partial\ndifferential equation (PDE) that sufficiently governs noisy spatial-temporal\nobserved data with few reliable terms. Since the naive use of the BIC for model\nselection has been known to yield an undesirable overfitted PDE, the UBIC\npenalizes the found PDE not only by its complexity but also the quantified\nuncertainty, derived from the model supports' coefficient of variation in a\nprobabilistic view. We also introduce physics-informed neural network learning\nas a simulation-based approach to further validate the selected PDE flexibly\nagainst the other discovered PDE. Numerical results affirm the successful\napplication of the UBIC in identifying the true governing PDE. Additionally, we\nreveal an interesting effect of denoising the observed data on improving the\ntrade-off between the BIC score and model complexity. Code is available at\nhttps://github.com/Pongpisit-Thanasutives/UBIC.",
          "link": "http://arxiv.org/abs/2308.10283",
          "publishedOn": "2023-09-02T00:40:02.318Z",
          "wordCount": null,
          "title": "Adaptive Uncertainty-Guided Model Selection for Data-Driven PDE Discovery. (arXiv:2308.10283v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.05102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yifan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chen Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yueke Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_K/0/1/0/all/0/1\">Kevin Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andersen_S/0/1/0/all/0/1\">Scott Thomas Andersen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_H/0/1/0/all/0/1\">Huajie Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leach_K/0/1/0/all/0/1\">Kevin Leach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yu Huang</a>",
          "description": "Compiled software is delivered as executable binary code. Developers write\nsource code to express the software semantics, but the compiler converts it to\na binary format that the CPU can directly execute. Therefore, binary code\nanalysis is critical to applications in reverse engineering and computer\nsecurity tasks where source code is not available. However, unlike source code\nand natural language that contain rich semantic information, binary code is\ntypically difficult for human engineers to understand and analyze. While\nexisting work uses AI models to assist source code analysis, few studies have\nconsidered binary code. In this paper, we propose a COntrastive learning Model\nfor Binary cOde Analysis, or COMBO, that incorporates source code and comment\ninformation into binary code during representation learning. Specifically, we\npresent three components in COMBO: (1) a primary contrastive learning method\nfor cold-start pre-training, (2) a simplex interpolation method to incorporate\nsource code, comments, and binary code, and (3) an intermediate representation\nlearning algorithm to provide binary code embeddings. Finally, we evaluate the\neffectiveness of the pre-trained representations produced by COMBO using three\nindicative downstream tasks relating to binary code: algorithmic functionality\nclassification, binary code similarity, and vulnerability detection. Our\nexperimental results show that COMBO facilitates representation learning of\nbinary code visualized by distribution analysis, and improves the performance\non all three downstream tasks by 5.45% on average compared to state-of-the-art\nlarge-scale language representation models. To the best of our knowledge, COMBO\nis the first language representation model that incorporates source code,\nbinary code, and comments into contrastive code representation learning and\nunifies multiple tasks for binary code analysis.",
          "link": "http://arxiv.org/abs/2210.05102",
          "publishedOn": "2023-09-02T00:40:02.317Z",
          "wordCount": null,
          "title": "Pre-Training Representations of Binary Code Using Contrastive Learning. (arXiv:2210.05102v2 [cs.SE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.08566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Haoyu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1\">Jianfei Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_B/0/1/0/all/0/1\">Bohan Zhuang</a>",
          "description": "Visual Parameter-Efficient Fine-Tuning (PEFT) has become a powerful\nalternative for full fine-tuning so as to adapt pre-trained vision models to\ndownstream tasks, which only tunes a small number of parameters while freezing\nthe vast majority ones to ease storage burden and optimization difficulty.\nHowever, existing PEFT methods introduce trainable parameters to the same\npositions across different tasks depending solely on human heuristics and\nneglect the domain gaps. To this end, we study where to introduce and how to\nallocate trainable parameters by proposing a novel Sensitivity-aware visual\nParameter-efficient fine-Tuning (SPT) scheme, which adaptively allocates\ntrainable parameters to task-specific important positions given a desired\ntunable parameter budget. Specifically, our SPT first quickly identifies the\nsensitive parameters that require tuning for a given task in a data-dependent\nway. Next, our SPT further boosts the representational capability for the\nweight matrices whose number of sensitive parameters exceeds a pre-defined\nthreshold by utilizing existing structured tuning methods, e.g., LoRA [23] or\nAdapter [22], to replace directly tuning the selected sensitive parameters\n(unstructured tuning) under the budget. Extensive experiments on a wide range\nof downstream recognition tasks show that our SPT is complementary to the\nexisting PEFT methods and largely boosts their performance, e.g., SPT improves\nAdapter with supervised pre-trained ViT-B/16 backbone by 4.2% and 1.4% mean\nTop-1 accuracy, reaching SOTA performance on FGVC and VTAB-1k benchmarks,\nrespectively. Source code is at https://github.com/ziplab/SPT",
          "link": "http://arxiv.org/abs/2303.08566",
          "publishedOn": "2023-09-02T00:40:02.317Z",
          "wordCount": null,
          "title": "Sensitivity-Aware Visual Parameter-Efficient Fine-Tuning. (arXiv:2303.08566v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.11594",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Seok_J/0/1/0/all/0/1\">Jinwuk Seok</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Cho_C/0/1/0/all/0/1\">Changsik Cho</a>",
          "description": "Statistical and stochastic analysis based on thermodynamics has been the main\nanalysis framework for stochastic global optimization. Recently, appearing\nquantum annealing or quantum tunneling algorithm for global optimization, we\nrequire a new researching framework for global optimization algorithms. In this\npaper, we provide the analysis for quantization-based optimization based on the\nSchr\\\"odinger equation to reveal what property in quantum mechanics enables\nglobal optimization. We present that the tunneling effect derived by the\nSchr\\\"odinger equation in quantization-based optimization enables to escape of\na local minimum. Additionally, we confirm that this tunneling effect is the\nsame property included in quantum mechanics-based global optimization.\nExperiments with standard multi-modal benchmark functions represent that the\nproposed analysis is valid.",
          "link": "http://arxiv.org/abs/2308.11594",
          "publishedOn": "2023-09-02T00:40:02.317Z",
          "wordCount": null,
          "title": "Quantization-based Optimization with Perspective of Quantum Mechanics. (arXiv:2308.11594v2 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.12431",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Williams_E/0/1/0/all/0/1\">Ezekiel Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bredenberg_C/0/1/0/all/0/1\">Colin Bredenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lajoie_G/0/1/0/all/0/1\">Guillaume Lajoie</a>",
          "description": "Many learning algorithms used as normative models in neuroscience or as\ncandidate approaches for learning on neuromorphic chips learn by contrasting\none set of network states with another. These Contrastive Learning (CL)\nalgorithms are traditionally implemented with rigid, temporally non-local, and\nperiodic learning dynamics that could limit the range of physical systems\ncapable of harnessing CL. In this study, we build on recent work exploring how\nCL might be implemented by biological or neurmorphic systems and show that this\nform of learning can be made temporally local, and can still function even if\nmany of the dynamical requirements of standard training procedures are relaxed.\nThanks to a set of general theorems corroborated by numerical experiments\nacross several CL models, our results provide theoretical foundations for the\nstudy and development of CL methods for biological and neuromorphic neural\nnetworks.",
          "link": "http://arxiv.org/abs/2302.12431",
          "publishedOn": "2023-09-02T00:40:02.316Z",
          "wordCount": null,
          "title": "Flexible Phase Dynamics for Bio-Plausible Contrastive Learning. (arXiv:2302.12431v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.08761",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Neun_M/0/1/0/all/0/1\">Moritz Neun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eichenberger_C/0/1/0/all/0/1\">Christian Eichenberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xin_Y/0/1/0/all/0/1\">Yanan Xin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Cheng Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiedemann_N/0/1/0/all/0/1\">Nina Wiedemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_H/0/1/0/all/0/1\">Henry Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomko_M/0/1/0/all/0/1\">Martin Tomko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ambuhl_L/0/1/0/all/0/1\">Lukas Amb&#xfc;hl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hermes_L/0/1/0/all/0/1\">Luca Hermes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kopp_M/0/1/0/all/0/1\">Michael Kopp</a>",
          "description": "Traffic analysis is crucial for urban operations and planning, while the\navailability of dense urban traffic data beyond loop detectors is still scarce.\nWe present a large-scale floating vehicle dataset of per-street segment traffic\ninformation, Metropolitan Segment Traffic Speeds from Massive Floating Car Data\nin 10 Cities (MeTS-10), available for 10 global cities with a 15-minute\nresolution for collection periods ranging between 108 and 361 days in 2019-2021\nand covering more than 1500 square kilometers per metropolitan area. MeTS-10\nfeatures traffic speed information at all street levels from main arterials to\nlocal streets for Antwerp, Bangkok, Barcelona, Berlin, Chicago, Istanbul,\nLondon, Madrid, Melbourne and Moscow. The dataset leverages the\nindustrial-scale floating vehicle Traffic4cast data with speeds and vehicle\ncounts provided in a privacy-preserving spatio-temporal aggregation. We detail\nthe efficient matching approach mapping the data to the OpenStreetMap road\ngraph. We evaluate the dataset by comparing it with publicly available\nstationary vehicle detector data (for Berlin, London, and Madrid) and the Uber\ntraffic speed dataset (for Barcelona, Berlin, and London). The comparison\nhighlights the differences across datasets in spatio-temporal coverage and\nvariations in the reported traffic caused by the binning method. MeTS-10\nenables novel, city-wide analysis of mobility and traffic patterns for ten\nmajor world cities, overcoming current limitations of spatially sparse vehicle\ndetector data. The large spatial and temporal coverage offers an opportunity\nfor joining the MeTS-10 with other datasets, such as traffic surveys in traffic\nplanning studies or vehicle detector data in traffic control settings.",
          "link": "http://arxiv.org/abs/2302.08761",
          "publishedOn": "2023-09-02T00:40:02.315Z",
          "wordCount": null,
          "title": "Metropolitan Segment Traffic Speeds from Massive Floating Car Data in 10 Cities. (arXiv:2302.08761v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.00241",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Huchette_J/0/1/0/all/0/1\">Joey Huchette</a>, <a href=\"http://arxiv.org/find/math/1/au:+Munoz_G/0/1/0/all/0/1\">Gonzalo Mu&#xf1;oz</a>, <a href=\"http://arxiv.org/find/math/1/au:+Serra_T/0/1/0/all/0/1\">Thiago Serra</a>, <a href=\"http://arxiv.org/find/math/1/au:+Tsay_C/0/1/0/all/0/1\">Calvin Tsay</a>",
          "description": "In the past decade, deep learning became the prevalent methodology for\npredictive modeling thanks to the remarkable accuracy of deep neural networks\nin tasks such as computer vision and natural language processing. Meanwhile,\nthe structure of neural networks converged back to simpler representations\nbased on piecewise constant and piecewise linear functions such as the\nRectified Linear Unit (ReLU), which became the most commonly used type of\nactivation function in neural networks. That made certain types of network\nstructure $\\unicode{x2014}$such as the typical fully-connected feedforward\nneural network$\\unicode{x2014}$ amenable to analysis through polyhedral theory\nand to the application of methodologies such as Linear Programming (LP) and\nMixed-Integer Linear Programming (MILP) for a variety of purposes. In this\npaper, we survey the main topics emerging from this fast-paced area of work,\nwhich bring a fresh perspective to understanding neural networks in more detail\nas well as to applying linear optimization techniques to train, verify, and\nreduce the size of such networks.",
          "link": "http://arxiv.org/abs/2305.00241",
          "publishedOn": "2023-09-02T00:40:02.315Z",
          "wordCount": null,
          "title": "When Deep Learning Meets Polyhedral Theory: A Survey. (arXiv:2305.00241v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.09134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beckers_J/0/1/0/all/0/1\">Jim Beckers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erp_B/0/1/0/all/0/1\">Bart van Erp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Ziyue Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kondrashov_K/0/1/0/all/0/1\">Kirill Kondrashov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vries_B/0/1/0/all/0/1\">Bert de Vries</a>",
          "description": "Bayesian model reduction provides an efficient approach for comparing the\nperformance of all nested sub-models of a model, without re-evaluating any of\nthese sub-models. Until now, Bayesian model reduction has been applied mainly\nin the computational neuroscience community on simple models. In this paper, we\nformulate and apply Bayesian model reduction to perform principled pruning of\nBayesian neural networks, based on variational free energy minimization. Direct\napplication of Bayesian model reduction, however, gives rise to approximation\nerrors. Therefore, a novel iterative pruning algorithm is presented to\nalleviate the problems arising with naive Bayesian model reduction, as\nsupported experimentally on the publicly available UCI datasets for different\ninference algorithms. This novel parameter pruning scheme solves the\nshortcomings of current state-of-the-art pruning methods that are used by the\nsignal processing community. The proposed approach has a clear stopping\ncriterion and minimizes the same objective that is used during training. Next\nto these benefits, our experiments indicate better model performance in\ncomparison to state-of-the-art pruning schemes.",
          "link": "http://arxiv.org/abs/2210.09134",
          "publishedOn": "2023-09-02T00:40:02.314Z",
          "wordCount": null,
          "title": "Principled Pruning of Bayesian Neural Networks through Variational Free Energy Minimization. (arXiv:2210.09134v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.05102",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kawano_K/0/1/0/all/0/1\">Keisuke Kawano</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kutsuna_T/0/1/0/all/0/1\">Takuro Kutsuna</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tokuhisa_R/0/1/0/all/0/1\">Ryoko Tokuhisa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nakamura_A/0/1/0/all/0/1\">Akihiro Nakamura</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Esaki_Y/0/1/0/all/0/1\">Yasushi Esaki</a>",
          "description": "One major challenge in machine learning applications is coping with\nmismatches between the datasets used in the development and those obtained in\nreal-world applications. These mismatches may lead to inaccurate predictions\nand errors, resulting in poor product quality and unreliable systems. In this\nstudy, we propose StyleDiff to inform developers of the differences between the\ntwo datasets for the steady development of machine learning systems. Using\ndisentangled image spaces obtained from recently proposed generative models,\nStyleDiff compares the two datasets by focusing on attributes in the images and\nprovides an easy-to-understand analysis of the differences between the\ndatasets. The proposed StyleDiff performs in $O (d N\\log N)$, where $N$ is the\nsize of the datasets and $d$ is the number of attributes, enabling the\napplication to large datasets. We demonstrate that StyleDiff accurately detects\ndifferences between datasets and presents them in an understandable format\nusing, for example, driving scenes datasets.",
          "link": "http://arxiv.org/abs/2303.05102",
          "publishedOn": "2023-09-02T00:40:02.314Z",
          "wordCount": null,
          "title": "StyleDiff: Attribute Comparison Between Unlabeled Datasets in Latent Disentangled Space. (arXiv:2303.05102v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.12743",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jungwook Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jaeill Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kyungeun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1\">Hyunghun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rhee_W/0/1/0/all/0/1\">Wonjong Rhee</a>",
          "description": "In autonomous driving, data augmentation is commonly used for improving 3D\nobject detection. The most basic methods include insertion of copied objects\nand rotation and scaling of the entire training frame. Numerous variants have\nbeen developed as well. The existing methods, however, are considerably limited\nwhen compared to the variety of the real world possibilities. In this work, we\ndevelop a diversified and realistic augmentation method that can flexibly\nconstruct a whole-body object, freely locate and rotate the object, and apply\nself-occlusion and external-occlusion accordingly. To improve the diversity of\nthe whole-body object construction, we develop an iterative method that\nstochastically combines multiple objects observed from the real world into a\nsingle object. Unlike the existing augmentation methods, the constructed\nobjects can be randomly located and rotated in the training frame because\nproper occlusions can be reflected to the whole-body objects in the final step.\nFinally, proper self-occlusion at each local object level and\nexternal-occlusion at the global frame level are applied using the Hidden Point\nRemoval (HPR) algorithm that is computationally efficient. HPR is also used for\nadaptively controlling the point density of each object according to the\nobject's distance from the LiDAR. Experiment results show that the proposed\nDR.CPO algorithm is data-efficient and model-agnostic without incurring any\ncomputational overhead. Also, DR.CPO can improve mAP performance by 2.08% when\ncompared to the best 3D detection result known for KITTI dataset. The code is\navailable at https://github.com/SNU-DRL/DRCPO.git",
          "link": "http://arxiv.org/abs/2303.12743",
          "publishedOn": "2023-09-02T00:40:02.314Z",
          "wordCount": null,
          "title": "DR.CPO: Diversified and Realistic 3D Augmentation via Iterative Construction, Random Placement, and HPR Occlusion. (arXiv:2303.12743v4 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.00646",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Tada_M/0/1/0/all/0/1\">Mikio Tada</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Lang_U/0/1/0/all/0/1\">Ursula E. Lang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Yeh_I/0/1/0/all/0/1\">Iwei Yeh</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Wei_M/0/1/0/all/0/1\">Maria L. Wei</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Keiser_M/0/1/0/all/0/1\">Michael J. Keiser</a>",
          "description": "Melanoma is one of the most aggressive forms of skin cancer, causing a large\nproportion of skin cancer deaths. However, melanoma diagnoses by pathologists\nshows low interrater reliability. As melanoma is a cancer of the melanocyte,\nthere is a clear need to develop a melanocytic cell segmentation tool that is\nagnostic to pathologist variability and automates pixel-level annotation.\nGigapixel-level pathologist labeling, however, is impractical. Herein, we\npropose a means to train deep neural networks for melanocytic cell segmentation\nfrom hematoxylin and eosin (H&E) stained sections and paired\nimmunohistochemistry (IHC) of adjacent tissue sections, achieving a mean IOU of\n0.64 despite imperfect ground-truth labels.",
          "link": "http://arxiv.org/abs/2211.00646",
          "publishedOn": "2023-09-02T00:40:02.313Z",
          "wordCount": null,
          "title": "Learning Melanocytic Cell Masks from Adjacent Stained Tissue. (arXiv:2211.00646v3 [q-bio.QM] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.07446",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yu-Zhen Janice Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuchuang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xutong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajiesmaili_M/0/1/0/all/0/1\">Mohammad Hajiesmaili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lui_J/0/1/0/all/0/1\">John C.S. Lui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Towsley_D/0/1/0/all/0/1\">Don Towsley</a>",
          "description": "This paper studies a cooperative multi-agent multi-armed stochastic bandit\nproblem where agents operate asynchronously -- agent pull times and rates are\nunknown, irregular, and heterogeneous -- and face the same instance of a\nK-armed bandit problem. Agents can share reward information to speed up the\nlearning process at additional communication costs. We propose ODC, an\non-demand communication protocol that tailors the communication of each pair of\nagents based on their empirical pull times. ODC is efficient when the pull\ntimes of agents are highly heterogeneous, and its communication complexity\ndepends on the empirical pull times of agents. ODC is a generic protocol that\ncan be integrated into most cooperative bandit algorithms without degrading\ntheir performance. We then incorporate ODC into the natural extensions of UCB\nand AAE algorithms and propose two communication-efficient cooperative\nalgorithms. Our analysis shows that both algorithms are near-optimal in regret.",
          "link": "http://arxiv.org/abs/2302.07446",
          "publishedOn": "2023-09-02T00:40:02.312Z",
          "wordCount": null,
          "title": "On-Demand Communication for Asynchronous Multi-Agent Bandits. (arXiv:2302.07446v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.09379",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Shenglong Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Geoffrey Ye Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiu_N/0/1/0/all/0/1\">Naihua Xiu</a>",
          "description": "The step function is one of the simplest and most natural activation\nfunctions for deep neural networks (DNNs). As it counts 1 for positive\nvariables and 0 for others, its intrinsic characteristics (e.g., discontinuity\nand no viable information of subgradients) impede its development for several\ndecades. Even if there is an impressive body of work on designing DNNs with\ncontinuous activation functions that can be deemed as surrogates of the step\nfunction, it is still in the possession of some advantageous properties, such\nas complete robustness to outliers and being capable of attaining the best\nlearning-theoretic guarantee of predictive accuracy. Hence, in this paper, we\naim to train DNNs with the step function used as an activation function (dubbed\nas 0/1 DNNs). We first reformulate 0/1 DNNs as an unconstrained optimization\nproblem and then solve it by a block coordinate descend (BCD) method. Moreover,\nwe acquire closed-form solutions for sub-problems of BCD as well as its\nconvergence properties. Furthermore, we also integrate\n$\\ell_{2,0}$-regularization into 0/1 DNN to accelerate the training process and\ncompress the network scale. As a result, the proposed algorithm has a high\nperformance on classifying MNIST and Fashion-MNIST datasets. As a result, the\nproposed algorithm has a desirable performance on classifying MNIST,\nFashionMNIST, Cifar10, and Cifar100 datasets.",
          "link": "http://arxiv.org/abs/2206.09379",
          "publishedOn": "2023-09-02T00:40:02.304Z",
          "wordCount": null,
          "title": "0/1 Deep Neural Networks via Block Coordinate Descent. (arXiv:2206.09379v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.09429",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Guo_H/0/1/0/all/0/1\">Hao Guo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Python_A/0/1/0/all/0/1\">Andre Python</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_Y/0/1/0/all/0/1\">Yu Liu</a>",
          "description": "In spatial regression models, spatial heterogeneity may be considered with\neither continuous or discrete specifications. The latter is related to\ndelineation of spatially connected regions with homogeneous relationships\nbetween variables (spatial regimes). Although various regionalization\nalgorithms have been proposed and studied in the field of spatial analytics,\nmethods to optimize spatial regimes have been largely unexplored. In this\npaper, we propose two new algorithms for spatial regime delineation, two-stage\nK-Models and Regional-K-Models. We also extend the classic Automatic Zoning\nProcedure to spatial regression context. The proposed algorithms are applied to\na series of synthetic datasets and two real-world datasets. Results indicate\nthat all three algorithms achieve superior or comparable performance to\nexisting approaches, while the two-stage K-Models algorithm largely outperforms\nexisting approaches on model fitting, region reconstruction, and coefficient\nestimation. Our work enriches the spatial analytics toolbox to explore spatial\nheterogeneous processes.",
          "link": "http://arxiv.org/abs/2206.09429",
          "publishedOn": "2023-09-02T00:40:02.302Z",
          "wordCount": null,
          "title": "Extending regionalization algorithms to explore spatial process heterogeneity. (arXiv:2206.09429v4 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.02796",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Borycki_P/0/1/0/all/0/1\">Piotr Borycki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kubacki_P/0/1/0/all/0/1\">Piotr Kubacki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Przewiezlikowski_M/0/1/0/all/0/1\">Marcin Przewi&#x119;&#x17a;likowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kusmierczyk_T/0/1/0/all/0/1\">Tomasz Ku&#x15b;mierczyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tabor_J/0/1/0/all/0/1\">Jacek Tabor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spurek_P/0/1/0/all/0/1\">Przemys&#x142;aw Spurek</a>",
          "description": "The main goal of Few-Shot learning algorithms is to enable learning from\nsmall amounts of data. One of the most popular and elegant Few-Shot learning\napproaches is Model-Agnostic Meta-Learning (MAML). The main idea behind this\nmethod is to learn the shared universal weights of a meta-model, which are then\nadapted for specific tasks. However, the method suffers from over-fitting and\npoorly quantifies uncertainty due to limited data size. Bayesian approaches\ncould, in principle, alleviate these shortcomings by learning weight\ndistributions in place of point-wise weights. Unfortunately, previous\nmodifications of MAML are limited due to the simplicity of Gaussian posteriors,\nMAML-like gradient-based weight updates, or by the same structure enforced for\nuniversal and adapted weights.\n\nIn this paper, we propose a novel framework for Bayesian MAML called\nBayesianHMAML, which employs Hypernetworks for weight updates. It learns the\nuniversal weights point-wise, but a probabilistic structure is added when\nadapted for specific tasks. In such a framework, we can use simple Gaussian\ndistributions or more complicated posteriors induced by Continuous Normalizing\nFlows.",
          "link": "http://arxiv.org/abs/2210.02796",
          "publishedOn": "2023-09-02T00:40:02.302Z",
          "wordCount": null,
          "title": "Hypernetwork approach to Bayesian MAML. (arXiv:2210.02796v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.07864",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_S/0/1/0/all/0/1\">Shangchao Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Mingzhao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1\">Xiangyang Xue</a>",
          "description": "Federated learning (FL) enables multiple clients to collaboratively train a\nglobal model without disclosing their data. Previous researches often require\ntraining the complete model parameters. However, the emergence of powerful\npre-trained models makes it possible to achieve higher performance with fewer\nlearnable parameters in FL. In this paper, we propose a federated adaptive\nprompt tuning algorithm, FedAPT, for multi-domain collaborative image\nclassification with powerful foundation models, like CLIP. Compared with direct\nfederated prompt tuning, our core idea is to adaptively unlock specific domain\nknowledge for each test sample in order to provide them with personalized\nprompts. To implement this idea, we design an adaptive prompt tuning module,\nwhich consists of a meta prompt, an adaptive network, and some keys. The server\nrandomly generates a set of keys and assigns a unique key to each client. Then\nall clients cooperatively train the global adaptive network and meta prompt\nwith the local datasets and the frozen keys. Ultimately, the global aggregation\nmodel can assign a personalized prompt to CLIP based on the domain features of\neach test sample. We perform extensive experiments on two multi-domain image\nclassification datasets across two different settings - supervised and\nunsupervised. The results show that FedAPT can achieve better performance with\nless than 10\\% of the number of parameters of the fully trained model, and the\nglobal model can perform well in diverse client domains simultaneously.",
          "link": "http://arxiv.org/abs/2211.07864",
          "publishedOn": "2023-09-02T00:40:02.302Z",
          "wordCount": null,
          "title": "Federated Adaptive Prompt Tuning for Multi-domain Collaborative Learning. (arXiv:2211.07864v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.00752",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ohta_S/0/1/0/all/0/1\">Shoki Ohta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nishio_T/0/1/0/all/0/1\">Takayuki Nishio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kudo_R/0/1/0/all/0/1\">Riichi Kudo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takahashi_K/0/1/0/all/0/1\">Kahoko Takahashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagata_H/0/1/0/all/0/1\">Hisashi Nagata</a>",
          "description": "This study demonstrates the feasibility of point cloud-based proactive link\nquality prediction for millimeter-wave (mmWave) communications. Previous\nstudies have proposed machine learning-based methods to predict received signal\nstrength for future time periods using time series of depth images to mitigate\nthe line-of-sight (LOS) path blockage by pedestrians in mmWave communication.\nHowever, these image-based methods have limited applicability due to privacy\nconcerns as camera images may contain sensitive information. This study\nproposes a point cloud-based method for mmWave link quality prediction and\ndemonstrates its feasibility through experiments. Point clouds represent\nthree-dimensional (3D) spaces as a set of points and are sparser and less\nlikely to contain sensitive information than camera images. Additionally, point\nclouds provide 3D position and motion information, which is necessary for\nunderstanding the radio propagation environment involving pedestrians. This\nstudy designs the mmWave link quality prediction method and conducts realistic\nindoor experiments, where the link quality fluctuates significantly due to\nhuman blockage, using commercially available IEEE 802.11ad-based 60 GHz\nwireless LAN devices and Kinect v2 RGB-D camera and Velodyne VLP-16 light\ndetection and ranging (LiDAR) for point cloud acquisition. The experimental\nresults showed that our proposed method can predict future large attenuation of\nmmWave received signal strength and throughput induced by the LOS path blockage\nby pedestrians with comparable or superior accuracy to image-based prediction\nmethods. Hence, our point cloud-based method can serve as a viable alternative\nto image-based methods.",
          "link": "http://arxiv.org/abs/2301.00752",
          "publishedOn": "2023-09-02T00:40:02.302Z",
          "wordCount": null,
          "title": "Point Cloud-based Proactive Link Quality Prediction for Millimeter-wave Communications. (arXiv:2301.00752v3 [cs.NI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.11656",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fraboni_Y/0/1/0/all/0/1\">Yann Fraboni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waerebeke_M/0/1/0/all/0/1\">Martin Van Waerebeke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scaman_K/0/1/0/all/0/1\">Kevin Scaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidal_R/0/1/0/all/0/1\">Richard Vidal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kameni_L/0/1/0/all/0/1\">Laetitia Kameni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lorenzi_M/0/1/0/all/0/1\">Marco Lorenzi</a>",
          "description": "The aim of Machine Unlearning (MU) is to provide theoretical guarantees on\nthe removal of the contribution of a given data point from a training\nprocedure. Federated Unlearning (FU) consists in extending MU to unlearn a\ngiven client's contribution from a federated training routine. Current FU\napproaches are generally not scalable, and do not come with sound theoretical\nquantification of the effectiveness of unlearning. In this work we present\nInformed Federated Unlearning (IFU), a novel efficient and quantifiable FU\napproach. Upon unlearning request from a given client, IFU identifies the\noptimal FL iteration from which FL has to be reinitialized, with unlearning\nguarantees obtained through a randomized perturbation mechanism. The theory of\nIFU is also extended to account for sequential unlearning requests.\nExperimental results on different tasks and dataset show that IFU leads to more\nefficient unlearning procedures as compared to basic re-training and\nstate-of-the-art FU approaches.",
          "link": "http://arxiv.org/abs/2211.11656",
          "publishedOn": "2023-09-02T00:40:02.300Z",
          "wordCount": null,
          "title": "Sequential Informed Federated Unlearning: Efficient and Provable Client Unlearning in Federated Optimization. (arXiv:2211.11656v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2104.01129",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tennekes_M/0/1/0/all/0/1\">Martijn Tennekes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jong_T/0/1/0/all/0/1\">Tim de Jong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Curier_L/0/1/0/all/0/1\">Lyana Curier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coecke_B/0/1/0/all/0/1\">Bob Coecke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Min Chen</a>",
          "description": "Quality-sensitive applications of machine learning (ML) require quality\nassurance (QA) by humans before the predictions of an ML model can be deployed.\nQA for ML (QA4ML) interfaces require users to view a large amount of data and\nperform many interactions to correct errors made by the ML model. An optimized\nuser interface (UI) can significantly reduce interaction costs. While UI\noptimization can be informed by user studies evaluating design options, this\napproach is not scalable because there are typically numerous small variations\nthat can affect the efficiency of a QA4ML interface. Hence, we propose using\nsimulation to evaluate and aid the optimization of QA4ML interfaces. In\nparticular, we focus on simulating the combined effects of human intelligence\nin initiating appropriate interaction commands and machine intelligence in\nproviding algorithmic assistance for accelerating QA4ML processes. As QA4ML is\nusually labor-intensive, we use the simulated task completion time as the\nmetric for UI optimization under different interface and algorithm setups. We\ndemonstrate the usage of this UI design method in several QA4ML applications.",
          "link": "http://arxiv.org/abs/2104.01129",
          "publishedOn": "2023-09-02T00:40:02.299Z",
          "wordCount": null,
          "title": "Simulation-Based Optimization of User Interfaces for Quality-Assuring Machine Learning Model Predictions. (arXiv:2104.01129v2 [cs.HC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.14052",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Andresel_M/0/1/0/all/0/1\">Medina Andresel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Trung-Kien Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Domokos_C/0/1/0/all/0/1\">Csaba Domokos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minervini_P/0/1/0/all/0/1\">Pasquale Minervini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stepanova_D/0/1/0/all/0/1\">Daria Stepanova</a>",
          "description": "Current methods for embedding-based query answering over incomplete Knowledge\nGraphs (KGs) only focus on inductive reasoning, i.e., predicting answers by\nlearning patterns from the data, and lack the complementary ability to do\ndeductive reasoning, which requires the application of domain knowledge to\ninfer further information. To address this shortcoming, we investigate the\nproblem of incorporating ontologies into embedding-based query answering models\nby defining the task of embedding-based ontology-mediated query answering. We\npropose various integration strategies into prominent representatives of\nembedding models that involve (1) different ontology-driven data augmentation\ntechniques and (2) adaptation of the loss function to enforce the ontology\naxioms. We design novel benchmarks for the considered task based on the LUBM\nand the NELL KGs and evaluate our methods on them. The achieved improvements in\nthe setting that requires both inductive and deductive reasoning are from 20%\nto 55% in HITS@3.",
          "link": "http://arxiv.org/abs/2106.14052",
          "publishedOn": "2023-09-02T00:40:02.295Z",
          "wordCount": null,
          "title": "Combining Inductive and Deductive Reasoning for Query Answering over Incomplete Knowledge Graphs. (arXiv:2106.14052v2 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16848",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Pfau_D/0/1/0/all/0/1\">David Pfau</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Axelrod_S/0/1/0/all/0/1\">Simon Axelrod</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sutterud_H/0/1/0/all/0/1\">Halvard Sutterud</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Glehn_I/0/1/0/all/0/1\">Ingrid von Glehn</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Spencer_J/0/1/0/all/0/1\">James S. Spencer</a>",
          "description": "We present a variational Monte Carlo algorithm for estimating the lowest\nexcited states of a quantum system which is a natural generalization of the\nestimation of ground states. The method has no free parameters and requires no\nexplicit orthogonalization of the different states, instead transforming the\nproblem of finding excited states of a given system into that of finding the\nground state of an expanded system. Expected values of arbitrary observables\ncan be calculated, including off-diagonal expectations between different states\nsuch as the transition dipole moment. Although the method is entirely general,\nit works particularly well in conjunction with recent work on using neural\nnetworks as variational Ansatze for many-electron systems, and we show that by\ncombining this method with the FermiNet and Psiformer Ansatze we can accurately\nrecover vertical excitation energies and oscillator strengths on molecules as\nlarge as benzene. Beyond the examples on molecules presented here, we expect\nthis technique will be of great interest for applications of variational\nquantum Monte Carlo to atomic, nuclear and condensed matter physics.",
          "link": "http://arxiv.org/abs/2308.16848",
          "publishedOn": "2023-09-02T00:40:02.294Z",
          "wordCount": null,
          "title": "Natural Quantum Monte Carlo Computation of Excited States. (arXiv:2308.16848v1 [physics.comp-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.00780",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_G/0/1/0/all/0/1\">Giang Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taesiri_M/0/1/0/all/0/1\">Mohammad Reza Taesiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">Anh Nguyen</a>",
          "description": "Explaining artificial intelligence (AI) predictions is increasingly important\nand even imperative in many high-stakes applications where humans are the\nultimate decision-makers. In this work, we propose two novel architectures of\nself-interpretable image classifiers that first explain, and then predict (as\nopposed to post-hoc explanations) by harnessing the visual correspondences\nbetween a query image and exemplars. Our models consistently improve (by 1 to 4\npoints) on out-of-distribution (OOD) datasets while performing marginally worse\n(by 1 to 2 points) on in-distribution tests than ResNet-50 and a $k$-nearest\nneighbor classifier (kNN). Via a large-scale, human study on ImageNet and CUB,\nour correspondence-based explanations are found to be more useful to users than\nkNN explanations. Our explanations help users more accurately reject AI's wrong\ndecisions than all other tested methods. Interestingly, for the first time, we\nshow that it is possible to achieve complementary human-AI team accuracy (i.e.,\nthat is higher than either AI-alone or human-alone), in ImageNet and CUB image\nclassification tasks.",
          "link": "http://arxiv.org/abs/2208.00780",
          "publishedOn": "2023-09-02T00:40:02.294Z",
          "wordCount": null,
          "title": "Visual correspondence-based explanations improve AI robustness and human-AI team accuracy. (arXiv:2208.00780v5 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16896",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zuo_S/0/1/0/all/0/1\">Sicheng Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1\">Wenzhao Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuanhui Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiwen Lu</a>",
          "description": "Semantic segmentation in autonomous driving has been undergoing an evolution\nfrom sparse point segmentation to dense voxel segmentation, where the objective\nis to predict the semantic occupancy of each voxel in the concerned 3D space.\nThe dense nature of the prediction space has rendered existing efficient\n2D-projection-based methods (e.g., bird's eye view, range view, etc.)\nineffective, as they can only describe a subspace of the 3D scene. To address\nthis, we propose a cylindrical tri-perspective view to represent point clouds\neffectively and comprehensively and a PointOcc model to process them\nefficiently. Considering the distance distribution of LiDAR point clouds, we\nconstruct the tri-perspective view in the cylindrical coordinate system for\nmore fine-grained modeling of nearer areas. We employ spatial group pooling to\nmaintain structural details during projection and adopt 2D backbones to\nefficiently process each TPV plane. Finally, we obtain the features of each\npoint by aggregating its projected features on each of the processed TPV planes\nwithout the need for any post-processing. Extensive experiments on both 3D\noccupancy prediction and LiDAR segmentation benchmarks demonstrate that the\nproposed PointOcc achieves state-of-the-art performance with much faster speed.\nSpecifically, despite only using LiDAR, PointOcc significantly outperforms all\nother methods, including multi-modal methods, with a large margin on the\nOpenOccupancy benchmark. Code: https://github.com/wzzheng/PointOcc.",
          "link": "http://arxiv.org/abs/2308.16896",
          "publishedOn": "2023-09-02T00:40:02.288Z",
          "wordCount": null,
          "title": "PointOcc: Cylindrical Tri-Perspective View for Point-based 3D Semantic Occupancy Prediction. (arXiv:2308.16896v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16835",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zhiying Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qiong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaoxi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qianyi Huang</a>",
          "description": "Federated Learning (FL) requires frequent exchange of model parameters, which\nleads to long communication delay, especially when the network environments of\nclients vary greatly. Moreover, the parameter server needs to wait for the\nslowest client (i.e., straggler, which may have the largest model size, lowest\ncomputing capability or worst network condition) to upload parameters, which\nmay significantly degrade the communication efficiency. Commonly-used client\nselection methods such as partial client selection would lead to the waste of\ncomputing resources and weaken the generalization of the global model. To\ntackle this problem, along a different line, in this paper, we advocate the\napproach of model parameter dropout instead of client selection, and\naccordingly propose a novel framework of Federated learning scheme with\nDifferential parameter Dropout (FedDD). FedDD consists of two key modules:\ndropout rate allocation and uploaded parameter selection, which will optimize\nthe model parameter uploading ratios tailored to different clients'\nheterogeneous conditions and also select the proper set of important model\nparameters for uploading subject to clients' dropout rate constraints.\nSpecifically, the dropout rate allocation is formulated as a convex\noptimization problem, taking system heterogeneity, data heterogeneity, and\nmodel heterogeneity among clients into consideration. The uploaded parameter\nselection strategy prioritizes on eliciting important parameters for uploading\nto speedup convergence. Furthermore, we theoretically analyze the convergence\nof the proposed FedDD scheme. Extensive performance evaluations demonstrate\nthat the proposed FedDD scheme can achieve outstanding performances in both\ncommunication efficiency and model convergence, and also possesses a strong\ngeneralization capability to data of rare classes.",
          "link": "http://arxiv.org/abs/2308.16835",
          "publishedOn": "2023-09-02T00:40:02.283Z",
          "wordCount": null,
          "title": "FedDD: Toward Communication-efficient Federated Learning with Differential Parameter Dropout. (arXiv:2308.16835v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2102.04307",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bozkurt_A/0/1/0/all/0/1\">Alper Kamil Bozkurt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zavlanos_M/0/1/0/all/0/1\">Michael M. Zavlanos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pajic_M/0/1/0/all/0/1\">Miroslav Pajic</a>",
          "description": "Synthesis from linear temporal logic (LTL) specifications provides assured\ncontrollers for systems operating in stochastic and potentially adversarial\nenvironments. Automatic synthesis tools, however, require a model of the\nenvironment to construct controllers. In this work, we introduce a model-free\nreinforcement learning (RL) approach to derive controllers from given LTL\nspecifications even when the environment is completely unknown. We model the\nproblem as a stochastic game (SG) between the controller and the adversarial\nenvironment; we then learn optimal control strategies that maximize the\nprobability of satisfying the LTL specifications against the worst-case\nenvironment behavior. We first construct a product game using the deterministic\nparity automaton (DPA) translated from the given LTL specification. By deriving\ndistinct rewards and discount factors from the acceptance condition of the DPA,\nwe reduce the maximization of the worst-case probability of satisfying the LTL\nspecification into the maximization of a discounted reward objective in the\nproduct game; this enables the use of model-free RL algorithms to learn an\noptimal controller strategy. To deal with the common scalability problems when\nthe number of sets defining the acceptance condition of the DPA (usually\nreferred as colors), is large, we propose a lazy color generation method where\ndistinct rewards and discount factors are utilized only when needed, and an\napproximate method where the controller eventually focuses on only one color.\nIn several case studies, we show that our approach is scalable to a wide range\nof LTL formulas, significantly outperforming existing methods for learning\ncontrollers from LTL specifications in SGs.",
          "link": "http://arxiv.org/abs/2102.04307",
          "publishedOn": "2023-09-02T00:40:02.283Z",
          "wordCount": null,
          "title": "Learning Optimal Strategies for Temporal Tasks in Stochastic Games. (arXiv:2102.04307v3 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.08060",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hellermann_J/0/1/0/all/0/1\">Justin Hellermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lessmann_S/0/1/0/all/0/1\">Stefan Lessmann</a>",
          "description": "Generative models for images have gained significant attention in computer\nvision and natural language processing due to their ability to generate\nrealistic samples from complex data distributions. To leverage the advances of\nimage-based generative models for the time series domain, we propose a\ntwo-dimensional image representation for time series, the Extended\nIntertemporal Return Plot (XIRP). Our approach captures the intertemporal time\nseries dynamics in a scale-invariant and invertible way, reducing training time\nand improving sample quality. We benchmark synthetic XIRPs obtained by an\noff-the-shelf Wasserstein GAN with gradient penalty (WGAN-GP) to other image\nrepresentations and models regarding similarity and predictive ability metrics.\nOur novel, validated image representation for time series consistently and\nsignificantly outperforms a state-of-the-art RNN-based generative model\nregarding predictive ability. Further, we introduce an improved stochastic\ninversion to substantially improve simulation quality regardless of the\nrepresentation and provide the prospect of transfer potentials in other\ndomains.",
          "link": "http://arxiv.org/abs/2112.08060",
          "publishedOn": "2023-09-02T00:40:02.282Z",
          "wordCount": null,
          "title": "Leveraging Image-based Generative Adversarial Networks for Time Series Generation. (arXiv:2112.08060v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.02373",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Celledoni_E/0/1/0/all/0/1\">Elena Celledoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murari_D/0/1/0/all/0/1\">Davide Murari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Owren_B/0/1/0/all/0/1\">Brynjulf Owren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1\">Carola-Bibiane Sch&#xf6;nlieb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sherry_F/0/1/0/all/0/1\">Ferdia Sherry</a>",
          "description": "Neural networks have gained much interest because of their effectiveness in\nmany applications. However, their mathematical properties are generally not\nwell understood. If there is some underlying geometric structure inherent to\nthe data or to the function to approximate, it is often desirable to take this\ninto account in the design of the neural network. In this work, we start with a\nnon-autonomous ODE and build neural networks using a suitable,\nstructure-preserving, numerical time-discretisation. The structure of the\nneural network is then inferred from the properties of the ODE vector field.\nBesides injecting more structure into the network architectures, this modelling\nprocedure allows a better theoretical understanding of their behaviour. We\npresent two universal approximation results and demonstrate how to impose some\nparticular properties on the neural networks. A particular focus is on\n1-Lipschitz architectures including layers that are not 1-Lipschitz. These\nnetworks are expressive and robust against adversarial attacks, as shown for\nthe CIFAR-10 and CIFAR-100 datasets.",
          "link": "http://arxiv.org/abs/2210.02373",
          "publishedOn": "2023-09-02T00:40:02.282Z",
          "wordCount": null,
          "title": "Dynamical systems' based neural networks. (arXiv:2210.02373v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16680",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kagan_M/0/1/0/all/0/1\">Michael Kagan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Heinrich_L/0/1/0/all/0/1\">Lukas Heinrich</a>",
          "description": "We propose to apply several gradient estimation techniques to enable the\ndifferentiation of programs with discrete randomness in High Energy Physics.\nSuch programs are common in High Energy Physics due to the presence of\nbranching processes and clustering-based analysis. Thus differentiating such\nprograms can open the way for gradient based optimization in the context of\ndetector design optimization, simulator tuning, or data analysis and\nreconstruction optimization. We discuss several possible gradient estimation\nstrategies, including the recent Stochastic AD method, and compare them in\nsimplified detector design experiments. In doing so we develop, to the best of\nour knowledge, the first fully differentiable branching program.",
          "link": "http://arxiv.org/abs/2308.16680",
          "publishedOn": "2023-09-02T00:40:02.281Z",
          "wordCount": null,
          "title": "Branches of a Tree: Taking Derivatives of Programs with Discrete and Branching Randomness in High Energy Physics. (arXiv:2308.16680v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16822",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Chunchao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leroy_A/0/1/0/all/0/1\">Arthur Leroy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alvarez_M/0/1/0/all/0/1\">Mauricio Alvarez</a>",
          "description": "Multi-output Gaussian processes (MOGPs) have been introduced to deal with\nmultiple tasks by exploiting the correlations between different outputs.\nGenerally, MOGPs models assume a flat correlation structure between the\noutputs. However, such a formulation does not account for more elaborate\nrelationships, for instance, if several replicates were observed for each\noutput (which is a typical setting in biological experiments). This paper\nproposes an extension of MOGPs for hierarchical datasets (i.e. datasets for\nwhich the relationships between observations can be represented within a tree\nstructure). Our model defines a tailored kernel function accounting for\nhierarchical structures in the data to capture different levels of correlations\nwhile leveraging the introduction of latent variables to express the underlying\ndependencies between outputs through a dedicated kernel. This latter feature is\nexpected to significantly improve scalability as the number of tasks increases.\nAn extensive experimental study involving both synthetic and real-world data\nfrom genomics and motion capture is proposed to support our claims.",
          "link": "http://arxiv.org/abs/2308.16822",
          "publishedOn": "2023-09-02T00:40:02.281Z",
          "wordCount": null,
          "title": "Latent Variable Multi-output Gaussian Processes for Hierarchical Datasets. (arXiv:2308.16822v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16659",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Harilal_A/0/1/0/all/0/1\">Abhirami Harilal</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Park_K/0/1/0/all/0/1\">Kyungmin Park</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Andrews_M/0/1/0/all/0/1\">Michael Andrews</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Paulini_M/0/1/0/all/0/1\">Manfred Paulini</a> (on behalf of the CMS Collaboration)",
          "description": "The online Data Quality Monitoring system (DQM) of the CMS electromagnetic\ncalorimeter (ECAL) is a crucial operational tool that allows ECAL experts to\nquickly identify, localize, and diagnose a broad range of detector issues that\nwould otherwise hinder physics-quality data taking. Although the existing ECAL\nDQM system has been continuously updated to respond to new problems, it remains\none step behind newer and unforeseen issues. Using unsupervised deep learning,\na real-time autoencoder-based anomaly detection system is developed that is\nable to detect ECAL anomalies unseen in past data. After accounting for spatial\nvariations in the response of the ECAL and the temporal evolution of anomalies,\nthe new system is able to efficiently detect anomalies while maintaining an\nestimated false discovery rate between $10^{-2}$ to $10^{-4}$, beating existing\nbenchmarks by about two orders of magnitude. The real-world performance of the\nsystem is validated using anomalies found in 2018 and 2022 LHC collision data.\nAdditionally, first results from deploying the autoencoder-based system in the\nCMS online DQM workflow for the ECAL barrel during Run 3 of the LHC are\npresented, showing its promising performance in detecting obscure issues that\ncould have been missed in the existing DQM system.",
          "link": "http://arxiv.org/abs/2308.16659",
          "publishedOn": "2023-09-02T00:40:02.280Z",
          "wordCount": null,
          "title": "Autoencoder-based Online Data Quality Monitoring for the CMS Electromagnetic Calorimeter. (arXiv:2308.16659v1 [physics.ins-det])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16886",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Park_H/0/1/0/all/0/1\">Hyun Park</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Yu_B/0/1/0/all/0/1\">Boyuan Yu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Park_J/0/1/0/all/0/1\">Juhae Park</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sun_G/0/1/0/all/0/1\">Ge Sun</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Tajkhorshid_E/0/1/0/all/0/1\">Emad Tajkhorshid</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pablo_J/0/1/0/all/0/1\">Juan J. de Pablo</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Schneider_L/0/1/0/all/0/1\">Ludwig Schneider</a>",
          "description": "A machine learning approach is presented to accelerate the computation of\nblock polymer morphology evolution for large domains over long timescales. The\nstrategy exploits the separation of characteristic times between coarse-grained\nparticle evolution on the monomer scale and slow morphological evolution over\nmesoscopic scales. In contrast to empirical continuum models, the proposed\napproach learns stochastically driven defect annihilation processes directly\nfrom particle-based simulations. A UNet architecture that respects different\nboundary conditions is adopted, thereby allowing periodic and fixed substrate\nboundary conditions of arbitrary shape. Physical concepts are also introduced\nvia the loss function and symmetries are incorporated via data augmentation.\nThe model is validated using three different use cases. Explainable artificial\nintelligence methods are applied to visualize the morphology evolution over\ntime. This approach enables the generation of large system sizes and long\ntrajectories to investigate defect densities and their evolution under\ndifferent types of confinement. As an application, we demonstrate the\nimportance of accessing late-stage morphologies for understanding particle\ndiffusion inside a single block. This work has implications for directed\nself-assembly and materials design in micro-electronics, battery materials, and\nmembranes.",
          "link": "http://arxiv.org/abs/2308.16886",
          "publishedOn": "2023-09-02T00:40:02.280Z",
          "wordCount": null,
          "title": "Prediction of Diblock Copolymer Morphology via Machine Learning. (arXiv:2308.16886v1 [physics.chem-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16681",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Simson_J/0/1/0/all/0/1\">Jan Simson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pfisterer_F/0/1/0/all/0/1\">Florian Pfisterer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kern_C/0/1/0/all/0/1\">Christoph Kern</a>",
          "description": "A vast number of systems across the world use algorithmic decision making\n(ADM) to (partially) automate decisions that have previously been made by\nhumans. When designed well, these systems promise more objective decisions\nwhile saving large amounts of resources and freeing up human time. However,\nwhen ADM systems are not designed well, they can lead to unfair decisions which\ndiscriminate against societal groups. The downstream effects of ADMs critically\ndepend on the decisions made during the systems' design and implementation, as\nbiases in data can be mitigated or reinforced along the modeling pipeline. Many\nof these design decisions are made implicitly, without knowing exactly how they\nwill influence the final system. It is therefore important to make explicit the\ndecisions made during the design of ADM systems and understand how these\ndecisions affect the fairness of the resulting system.\n\nTo study this issue, we draw on insights from the field of psychology and\nintroduce the method of multiverse analysis for algorithmic fairness. In our\nproposed method, we turn implicit design decisions into explicit ones and\ndemonstrate their fairness implications. By combining decisions, we create a\ngrid of all possible \"universes\" of decision combinations. For each of these\nuniverses, we compute metrics of fairness and performance. Using the resulting\ndataset, one can see how and which decisions impact fairness. We demonstrate\nhow multiverse analyses can be used to better understand variability and\nrobustness of algorithmic fairness using an exemplary case study of predicting\npublic health coverage of vulnerable populations for potential interventions.\nOur results illustrate how decisions during the design of a machine learning\nsystem can have surprising effects on its fairness and how to detect these\neffects using multiverse analysis.",
          "link": "http://arxiv.org/abs/2308.16681",
          "publishedOn": "2023-09-02T00:40:02.279Z",
          "wordCount": null,
          "title": "Everything, Everywhere All in One Evaluation: Using Multiverse Analysis to Evaluate the Influence of Model Design Decisions on Algorithmic Fairness. (arXiv:2308.16681v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16847",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tuel_A/0/1/0/all/0/1\">Alexandre Tuel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kerdreux_T/0/1/0/all/0/1\">Thomas Kerdreux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hulbert_C/0/1/0/all/0/1\">Claudia Hulbert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rouet_Leduc_B/0/1/0/all/0/1\">Bertrand Rouet-Leduc</a>",
          "description": "Probabilistic Diffusion Models (PDMs) have recently emerged as a very\npromising class of generative models, achieving high performance in natural\nimage generation. However, their performance relative to non-natural images,\nlike radar-based satellite data, remains largely unknown. Generating large\namounts of synthetic (and especially labelled) satellite data is crucial to\nimplement deep-learning approaches for the processing and analysis of\n(interferometric) satellite aperture radar data. Here, we leverage PDMs to\ngenerate several radar-based satellite image datasets. We show that PDMs\nsucceed in generating images with complex and realistic structures, but that\nsampling time remains an issue. Indeed, accelerated sampling strategies, which\nwork well on simple image datasets like MNIST, fail on our radar datasets. We\nprovide a simple and versatile open-source\nhttps://github.com/thomaskerdreux/PDM_SAR_InSAR_generation to train, sample and\nevaluate PDMs using any dataset on a single GPU.",
          "link": "http://arxiv.org/abs/2308.16847",
          "publishedOn": "2023-09-02T00:40:02.278Z",
          "wordCount": null,
          "title": "Diffusion Models for Interferometric Satellite Aperture Radar. (arXiv:2308.16847v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16884",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bandarkar_L/0/1/0/all/0/1\">Lucas Bandarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1\">Davis Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_B/0/1/0/all/0/1\">Benjamin Muller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artetxe_M/0/1/0/all/0/1\">Mikel Artetxe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shukla_S/0/1/0/all/0/1\">Satya Narayan Shukla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Husa_D/0/1/0/all/0/1\">Donald Husa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_N/0/1/0/all/0/1\">Naman Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnan_A/0/1/0/all/0/1\">Abhinandan Krishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khabsa_M/0/1/0/all/0/1\">Madian Khabsa</a>",
          "description": "We present Belebele, a multiple-choice machine reading comprehension (MRC)\ndataset spanning 122 language variants. Significantly expanding the language\ncoverage of natural language understanding (NLU) benchmarks, this dataset\nenables the evaluation of text models in high-, medium-, and low-resource\nlanguages. Each question is based on a short passage from the Flores-200\ndataset and has four multiple-choice answers. The questions were carefully\ncurated to discriminate between models with different levels of general\nlanguage comprehension. The English dataset on its own proves difficult enough\nto challenge state-of-the-art language models. Being fully parallel, this\ndataset enables direct comparison of model performance across all languages. We\nuse this dataset to evaluate the capabilities of multilingual masked language\nmodels (MLMs) and large language models (LLMs). We present extensive results\nand find that despite significant cross-lingual transfer in English-centric\nLLMs, much smaller MLMs pretrained on balanced multilingual data still\nunderstand far more languages. We also observe that larger vocabulary size and\nconscious vocabulary construction correlate with better performance on\nlow-resource languages. Overall, Belebele opens up new avenues for evaluating\nand analyzing the multilingual capabilities of NLP systems.",
          "link": "http://arxiv.org/abs/2308.16884",
          "publishedOn": "2023-09-02T00:40:02.277Z",
          "wordCount": null,
          "title": "The Belebele Benchmark: a Parallel Reading Comprehension Dataset in 122 Language Variants. (arXiv:2308.16884v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16898",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tarzanagh_D/0/1/0/all/0/1\">Davoud Ataee Tarzanagh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yingcong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thrampoulidis_C/0/1/0/all/0/1\">Christos Thrampoulidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oymak_S/0/1/0/all/0/1\">Samet Oymak</a>",
          "description": "Since its inception in \"Attention Is All You Need\", transformer architecture\nhas led to revolutionary advancements in NLP. The attention layer within the\ntransformer admits a sequence of input tokens $X$ and makes them interact\nthrough pairwise similarities computed as softmax$(XQK^\\top X^\\top)$, where\n$(K,Q)$ are the trainable key-query parameters. In this work, we establish a\nformal equivalence between the optimization geometry of self-attention and a\nhard-margin SVM problem that separates optimal input tokens from non-optimal\ntokens using linear constraints on the outer-products of token pairs. This\nformalism allows us to characterize the implicit bias of 1-layer transformers\noptimized with gradient descent: (1) Optimizing the attention layer with\nvanishing regularization, parameterized by $(K,Q)$, converges in direction to\nan SVM solution minimizing the nuclear norm of the combined parameter\n$W=KQ^\\top$. Instead, directly parameterizing by $W$ minimizes a Frobenius norm\nobjective. We characterize this convergence, highlighting that it can occur\ntoward locally-optimal directions rather than global ones. (2) Complementing\nthis, we prove the local/global directional convergence of gradient descent\nunder suitable geometric conditions. Importantly, we show that\nover-parameterization catalyzes global convergence by ensuring the feasibility\nof the SVM problem and by guaranteeing a benign optimization landscape devoid\nof stationary points. (3) While our theory applies primarily to linear\nprediction heads, we propose a more general SVM equivalence that predicts the\nimplicit bias with nonlinear heads. Our findings are applicable to arbitrary\ndatasets and their validity is verified via experiments. We also introduce\nseveral open problems and research directions. We believe these findings\ninspire the interpretation of transformers as a hierarchy of SVMs that\nseparates and selects optimal tokens.",
          "link": "http://arxiv.org/abs/2308.16898",
          "publishedOn": "2023-09-02T00:40:02.276Z",
          "wordCount": null,
          "title": "Transformers as Support Vector Machines. (arXiv:2308.16898v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16889",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yahya_M/0/1/0/all/0/1\">Mariam Yahya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maghsudi_S/0/1/0/all/0/1\">Setareh Maghsudi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stanczak_S/0/1/0/all/0/1\">Slawomir Stanczak</a>",
          "description": "Federated learning (FL) involves several devices that collaboratively train a\nshared model without transferring their local data. FL reduces the\ncommunication overhead, making it a promising learning method in UAV-enhanced\nwireless networks with scarce energy resources. Despite the potential,\nimplementing FL in UAV-enhanced networks is challenging, as conventional UAV\nplacement methods that maximize coverage increase the FL delay significantly.\nMoreover, the uncertainty and lack of a priori information about crucial\nvariables, such as channel quality, exacerbate the problem. In this paper, we\nfirst analyze the statistical characteristics of a UAV-enhanced wireless sensor\nnetwork (WSN) with energy harvesting. We then develop a model and solution\nbased on the multi-objective multi-armed bandit theory to maximize the network\ncoverage while minimizing the FL delay. Besides, we propose another solution\nthat is particularly useful with large action sets and strict energy\nconstraints at the UAVs. Our proposal uses a scalarized best-arm identification\nalgorithm to find the optimal arms that maximize the ratio of the expected\nreward to the expected energy cost by sequentially eliminating one or more arms\nin each round. Then, we derive the upper bound on the error probability of our\nmulti-objective and cost-aware algorithm. Numerical results show the\neffectiveness of our approach.",
          "link": "http://arxiv.org/abs/2308.16889",
          "publishedOn": "2023-09-02T00:40:02.275Z",
          "wordCount": null,
          "title": "Federated Learning in UAV-Enhanced Networks: Joint Coverage and Convergence Time Optimization. (arXiv:2308.16889v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16775",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_M/0/1/0/all/0/1\">Minh Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Nhan Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luong_N/0/1/0/all/0/1\">Ngoc Hoang Luong</a>",
          "description": "In prediction-based Neural Architecture Search (NAS), performance indicators\nderived from graph convolutional networks have shown significant success. These\nindicators, achieved by representing feed-forward structures as component\ngraphs through one-hot encoding, face a limitation: their inability to evaluate\narchitecture performance across varying search spaces. In contrast, handcrafted\nperformance indicators (zero-shot NAS), which use the same architecture with\nrandom initialization, can generalize across multiple search spaces. Addressing\nthis limitation, we propose a novel approach for zero-shot NAS using deep\nlearning. Our method employs Fourier sum of sines encoding for convolutional\nkernels, enabling the construction of a computational feed-forward graph with a\nstructure similar to the architecture under evaluation. These encodings are\nlearnable and offer a comprehensive view of the architecture's topological\ninformation. An accompanying multi-layer perceptron (MLP) then ranks these\narchitectures based on their encodings. Experimental results show that our\napproach surpasses previous methods using graph convolutional networks in terms\nof correlation on the NAS-Bench-201 dataset and exhibits a higher convergence\nrate. Moreover, our extracted feature representation trained on each\nNAS-Benchmark is transferable to other NAS-Benchmarks, showing promising\ngeneralizability across multiple search spaces. The code is available at:\nhttps://github.com/minh1409/DFT-NPZS-NAS",
          "link": "http://arxiv.org/abs/2308.16775",
          "publishedOn": "2023-09-02T00:40:02.268Z",
          "wordCount": null,
          "title": "Efficacy of Neural Prediction-Based NAS for Zero-Shot NAS Paradigm. (arXiv:2308.16775v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16752",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Mirzaeifard_R/0/1/0/all/0/1\">Reza Mirzaeifard</a>, <a href=\"http://arxiv.org/find/math/1/au:+Venkategowda_N/0/1/0/all/0/1\">Naveen K. D. Venkategowda</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jung_A/0/1/0/all/0/1\">Alexander Jung</a>, <a href=\"http://arxiv.org/find/math/1/au:+Werner_S/0/1/0/all/0/1\">Stefan Werner</a>",
          "description": "This paper proposes a proximal variant of the alternating direction method of\nmultipliers (ADMM) for distributed optimization. Although the current versions\nof ADMM algorithm provide promising numerical results in producing solutions\nthat are close to optimal for many convex and non-convex optimization problems,\nit remains unclear if they can converge to a stationary point for weakly convex\nand locally non-smooth functions. Through our analysis using the Moreau\nenvelope function, we demonstrate that MADM can indeed converge to a stationary\npoint under mild conditions. Our analysis also includes computing the bounds on\nthe amount of change in the dual variable update step by relating the gradient\nof the Moreau envelope function to the proximal function. Furthermore, the\nresults of our numerical experiments indicate that our method is faster and\nmore robust than widely-used approaches.",
          "link": "http://arxiv.org/abs/2308.16752",
          "publishedOn": "2023-09-02T00:40:02.267Z",
          "wordCount": null,
          "title": "Moreau Envelope ADMM for Decentralized Weakly Convex Optimization. (arXiv:2308.16752v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16781",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>",
          "description": "With the growing imbalance between limited medical resources and escalating\ndemands, AI-based clinical tasks have become paramount. Medication\nrecommendation, as a sub-domain, aims to amalgamate longitudinal patient\nhistory with medical knowledge, assisting physicians in prescribing safer and\nmore accurate medication combinations. Existing methods overlook the inherent\nlong-tail distribution in medical data, lacking balanced representation between\nhead and tail data, which leads to sub-optimal model performance. To address\nthis challenge, we introduce StratMed, a model that incorporates an innovative\nrelevance stratification mechanism. It harmonizes discrepancies in data\nlong-tail distribution and strikes a balance between the safety and accuracy of\nmedication combinations. Specifically, we first construct a pre-training method\nusing deep learning networks to obtain entity representation. After that, we\ndesign a pyramid-like data stratification method to obtain more generalized\nentity relationships by reinforcing the features of unpopular entities. Based\non this relationship, we designed two graph structures to express medication\nprecision and safety at the same level to obtain visit representations.\nFinally, the patient's historical clinical information is fitted to generate\nmedication combinations for the current health condition. Experiments on the\nMIMIC-III dataset demonstrate that our method has outperformed current\nstate-of-the-art methods in four evaluation metrics (including safety and\naccuracy).",
          "link": "http://arxiv.org/abs/2308.16781",
          "publishedOn": "2023-09-02T00:40:02.267Z",
          "wordCount": null,
          "title": "StratMed: Relevance Stratification for Low-resource Medication Recommendation. (arXiv:2308.16781v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roth_A/0/1/0/all/0/1\">Andreas Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liebig_T/0/1/0/all/0/1\">Thomas Liebig</a>",
          "description": "Our study reveals new theoretical insights into over-smoothing and feature\nover-correlation in deep graph neural networks. We show the prevalence of\ninvariant subspaces, demonstrating a fixed relative behavior that is unaffected\nby feature transformations. Our work clarifies recent observations related to\nconvergence to a constant state and a potential over-separation of node states,\nas the amplification of subspaces only depends on the spectrum of the\naggregation function. In linear scenarios, this leads to node representations\nbeing dominated by a low-dimensional subspace with an asymptotic convergence\nrate independent of the feature transformations. This causes a rank collapse of\nthe node representations, resulting in over-smoothing when smooth vectors span\nthis subspace, and over-correlation even when over-smoothing is avoided. Guided\nby our theory, we propose a sum of Kronecker products as a beneficial property\nthat can provably prevent over-smoothing, over-correlation, and rank collapse.\nWe empirically extend our insights to the non-linear case, demonstrating the\ninability of existing models to capture linearly independent features.",
          "link": "http://arxiv.org/abs/2308.16800",
          "publishedOn": "2023-09-02T00:40:02.267Z",
          "wordCount": null,
          "title": "Rank Collapse Causes Over-Smoothing and Over-Correlation in Graph Neural Networks. (arXiv:2308.16800v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16893",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_A/0/1/0/all/0/1\">Amber Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Youngwoon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+James_S/0/1/0/all/0/1\">Stephen James</a>",
          "description": "Contact is at the core of robotic manipulation. At times, it is desired (e.g.\nmanipulation and grasping), and at times, it is harmful (e.g. when avoiding\nobstacles). However, traditional path planning algorithms focus solely on\ncollision-free paths, limiting their applicability in contact-rich tasks. To\naddress this limitation, we propose the domain of Language-Conditioned Path\nPlanning, where contact-awareness is incorporated into the path planning\nproblem. As a first step in this domain, we propose Language-Conditioned\nCollision Functions (LACO) a novel approach that learns a collision function\nusing only a single-view image, language prompt, and robot configuration. LACO\npredicts collisions between the robot and the environment, enabling flexible,\nconditional path planning without the need for manual object annotations, point\ncloud data, or ground-truth object meshes. In both simulation and the real\nworld, we demonstrate that LACO can facilitate complex, nuanced path plans that\nallow for interaction with objects that are safe to collide, rather than\nprohibiting any collision.",
          "link": "http://arxiv.org/abs/2308.16893",
          "publishedOn": "2023-09-02T00:40:02.267Z",
          "wordCount": null,
          "title": "Language-Conditioned Path Planning. (arXiv:2308.16893v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16379",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghanem_A/0/1/0/all/0/1\">Abdelghani Ghanem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ciblat_P/0/1/0/all/0/1\">Philippe Ciblat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghogho_M/0/1/0/all/0/1\">Mounir Ghogho</a>",
          "description": "Offline Reinforcement Learning (RL) is structured to derive policies from\nstatic trajectory data without requiring real-time environment interactions.\nRecent studies have shown the feasibility of framing offline RL as a sequence\nmodeling task, where the sole aim is to predict actions based on prior context\nusing the transformer architecture. However, the limitation of this single task\nlearning approach is its potential to undermine the transformer model's\nattention mechanism, which should ideally allocate varying attention weights\nacross different tokens in the input context for optimal prediction. To address\nthis, we reformulate offline RL as a multi-objective optimization problem,\nwhere the prediction is extended to states and returns. We also highlight a\npotential flaw in the trajectory representation used for sequence modeling,\nwhich could generate inaccuracies when modeling the state and return\ndistributions. This is due to the non-smoothness of the action distribution\nwithin the trajectory dictated by the behavioral policy. To mitigate this\nissue, we introduce action space regions to the trajectory representation. Our\nexperiments on D4RL benchmark locomotion tasks reveal that our propositions\nallow for more effective utilization of the attention mechanism in the\ntransformer model, resulting in performance that either matches or outperforms\ncurrent state-of-the art methods.",
          "link": "http://arxiv.org/abs/2308.16379",
          "publishedOn": "2023-09-02T00:40:02.266Z",
          "wordCount": null,
          "title": "Multi-Objective Decision Transformers for Offline Reinforcement Learning. (arXiv:2308.16379v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16859",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Veedu_M/0/1/0/all/0/1\">Mishfad Shaikh Veedu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Deka_D/0/1/0/all/0/1\">Deepjyoti Deka</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Salapaka_M/0/1/0/all/0/1\">Murti V. Salapaka</a>",
          "description": "In this article, the optimal sample complexity of learning the underlying\ninteraction/dependencies of a Linear Dynamical System (LDS) over a Directed\nAcyclic Graph (DAG) is studied. The sample complexity of learning a DAG's\nstructure is well-studied for static systems, where the samples of nodal states\nare independent and identically distributed (i.i.d.). However, such a study is\nless explored for DAGs with dynamical systems, where the nodal states are\ntemporally correlated. We call such a DAG underlying an LDS as \\emph{dynamical}\nDAG (DDAG). In particular, we consider a DDAG where the nodal dynamics are\ndriven by unobserved exogenous noise sources that are wide-sense stationary\n(WSS) in time but are mutually uncorrelated, and have the same {power spectral\ndensity (PSD)}. Inspired by the static settings, a metric and an algorithm\nbased on the PSD matrix of the observed time series are proposed to reconstruct\nthe DDAG. The equal noise PSD assumption can be relaxed such that\nidentifiability conditions for DDAG reconstruction are not violated. For the\nLDS with WSS (sub) Gaussian exogenous noise sources, it is shown that the\noptimal sample complexity (or length of state trajectory) needed to learn the\nDDAG is $n=\\Theta(q\\log(p/q))$, where $p$ is the number of nodes and $q$ is the\nmaximum number of parents per node. To prove the sample complexity upper bound,\na concentration bound for the PSD estimation is derived, under two different\nsampling strategies. A matching min-max lower bound using generalized Fano's\ninequality also is provided, thus showing the order optimality of the proposed\nalgorithm.",
          "link": "http://arxiv.org/abs/2308.16859",
          "publishedOn": "2023-09-02T00:40:02.266Z",
          "wordCount": null,
          "title": "Information Theoretically Optimal Sample Complexity of Learning Dynamical Directed Acyclic Graphs. (arXiv:2308.16859v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16737",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mirzaeifard_R/0/1/0/all/0/1\">Reza Mirzaeifard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venkategowda_N/0/1/0/all/0/1\">Naveen K. D. Venkategowda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Werner_S/0/1/0/all/0/1\">Stefan Werner</a>",
          "description": "This paper addresses the problem of localization, which is inherently\nnon-convex and non-smooth in a federated setting where the data is distributed\nacross a multitude of devices. Due to the decentralized nature of federated\nenvironments, distributed learning becomes essential for scalability and\nadaptability. Moreover, these environments are often plagued by outlier data,\nwhich presents substantial challenges to conventional methods, particularly in\nmaintaining estimation accuracy and ensuring algorithm convergence. To mitigate\nthese challenges, we propose a method that adopts an $L_1$-norm robust\nformulation within a distributed sub-gradient framework, explicitly designed to\nhandle these obstacles. Our approach addresses the problem in its original\nform, without resorting to iterative simplifications or approximations,\nresulting in enhanced computational efficiency and improved estimation\naccuracy. We demonstrate that our method converges to a stationary point,\nhighlighting its effectiveness and reliability. Through numerical simulations,\nwe confirm the superior performance of our approach, notably in outlier-rich\nenvironments, which surpasses existing state-of-the-art localization methods.",
          "link": "http://arxiv.org/abs/2308.16737",
          "publishedOn": "2023-09-02T00:40:02.259Z",
          "wordCount": null,
          "title": "Robust Networked Federated Learning for Localization. (arXiv:2308.16737v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16483",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Jeon_J/0/1/0/all/0/1\">Jaeik Jeon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ha_S/0/1/0/all/0/1\">Seongmin Ha</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yoon_Y/0/1/0/all/0/1\">Yeonyee E. Yoon</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1\">Jiyeon Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jeong_H/0/1/0/all/0/1\">Hyunseok Jeong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jeong_D/0/1/0/all/0/1\">Dawun Jeong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jang_Y/0/1/0/all/0/1\">Yeonggul Jang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hong_Y/0/1/0/all/0/1\">Youngtaek Hong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chang_H/0/1/0/all/0/1\">Hyuk-Jae Chang</a>",
          "description": "In the rapidly evolving field of automatic echocardiographic analysis and\ninterpretation, automatic view classification is a critical yet challenging\ntask, owing to the inherent complexity and variability of echocardiographic\ndata. This study presents ECHOcardiography VIew Classification with\nOut-of-Distribution dEtection (ECHO-VICODE), a novel deep learning-based\nframework that effectively addresses this challenge by training to classify 31\nclasses, surpassing previous studies and demonstrating its capacity to handle a\nwide range of echocardiographic views. Furthermore, ECHO-VICODE incorporates an\nintegrated out-of-distribution (OOD) detection function, leveraging the\nrelative Mahalanobis distance to effectively identify 'near-OOD' instances\ncommonly encountered in echocardiographic data. Through extensive\nexperimentation, we demonstrated the outstanding performance of ECHO-VICODE in\nterms of view classification and OOD detection, significantly reducing the\npotential for errors in echocardiographic analyses. This pioneering study\nsignificantly advances the domain of automated echocardiography analysis and\nexhibits promising prospects for substantial applications in extensive clinical\nresearch and practice.",
          "link": "http://arxiv.org/abs/2308.16483",
          "publishedOn": "2023-09-02T00:40:02.257Z",
          "wordCount": null,
          "title": "Echocardiographic View Classification with Integrated Out-of-Distribution Detection for Enhanced Automatic Echocardiographic Analysis. (arXiv:2308.16483v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16544",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tuominen_J/0/1/0/all/0/1\">Jalmari Tuominen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pulkkinen_E/0/1/0/all/0/1\">Eetu Pulkkinen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peltonen_J/0/1/0/all/0/1\">Jaakko Peltonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanniainen_J/0/1/0/all/0/1\">Juho Kanniainen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oksala_N/0/1/0/all/0/1\">Niku Oksala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palomaki_A/0/1/0/all/0/1\">Ari Palom&#xe4;ki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roine_A/0/1/0/all/0/1\">Antti Roine</a>",
          "description": "Emergency department (ED) crowding is a significant threat to patient safety\nand it has been repeatedly associated with increased mortality. Forecasting\nfuture service demand has the potential patient outcomes. Despite active\nresearch on the subject, several gaps remain: 1) proposed forecasting models\nhave become outdated due to quick influx of advanced machine learning models\n(ML), 2) amount of multivariable input data has been limited and 3) discrete\nperformance metrics have been rarely reported. In this study, we document the\nperformance of a set of advanced ML models in forecasting ED occupancy 24 hours\nahead. We use electronic health record data from a large, combined ED with an\nextensive set of explanatory variables, including the availability of beds in\ncatchment area hospitals, traffic data from local observation stations, weather\nvariables, etc. We show that N-BEATS and LightGBM outpeform benchmarks with 11\n% and 9 % respective improvements and that DeepAR predicts next day crowding\nwith an AUC of 0.76 (95 % CI 0.69-0.84). To the best of our knowledge, this is\nthe first study to document the superiority of LightGBM and N-BEATS over\nstatistical benchmarks in the context of ED forecasting.",
          "link": "http://arxiv.org/abs/2308.16544",
          "publishedOn": "2023-09-02T00:40:02.257Z",
          "wordCount": null,
          "title": "Forecasting Emergency Department Crowding with Advanced Machine Learning Models and Multivariable Input. (arXiv:2308.16544v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huynh_P/0/1/0/all/0/1\">Phuong Duy Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dau_S/0/1/0/all/0/1\">Son Hoang Dau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaodong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luong_P/0/1/0/all/0/1\">Phuc Luong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Viterbo_E/0/1/0/all/0/1\">Emanuele Viterbo</a>",
          "description": "The rapid development of blockchain has led to more and more funding pouring\ninto the cryptocurrency market, which also attracted cybercriminals' interest\nin recent years. The Ponzi scheme, an old-fashioned fraud, is now popular on\nthe blockchain, causing considerable financial losses to many crypto-investors.\nA few Ponzi detection methods have been proposed in the literature, most of\nwhich detect a Ponzi scheme based on its smart contract source code or opcode.\nThe contract-code-based approach, while achieving very high accuracy, is not\nrobust: first, the source codes of a majority of contracts on Ethereum are not\navailable, and second, a Ponzi developer can fool a contract-code-based\ndetection model by obfuscating the opcode or inventing a new profit\ndistribution logic that cannot be detected (since these models were trained on\nexisting Ponzi logics only). A transaction-based approach could improve the\nrobustness of detection because transactions, unlike smart contracts, are\nharder to be manipulated. However, the current transaction-based detection\nmodels achieve fairly low accuracy. We address this gap in the literature by\ndeveloping new detection models that rely only on the transactions, hence\nguaranteeing the robustness, and moreover, achieve considerably higher\nAccuracy, Precision, Recall, and F1-score than existing transaction-based\nmodels. This is made possible thanks to the introduction of novel\ntime-dependent features that capture Ponzi behaviours characteristics derived\nfrom our comprehensive data analyses on Ponzi and non-Ponzi data from the\nXBlock-ETH repository",
          "link": "http://arxiv.org/abs/2308.16391",
          "publishedOn": "2023-09-02T00:40:02.256Z",
          "wordCount": null,
          "title": "Improving Robustness and Accuracy of Ponzi Scheme Detection on Ethereum Using Time-Dependent Features. (arXiv:2308.16391v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16684",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Sze Jue Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1\">Quang Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_C/0/1/0/all/0/1\">Chee Seng Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doan_K/0/1/0/all/0/1\">Khoa Doan</a>",
          "description": "The vulnerabilities to backdoor attacks have recently threatened the\ntrustworthiness of machine learning models in practical applications.\nConventional wisdom suggests that not everyone can be an attacker since the\nprocess of designing the trigger generation algorithm often involves\nsignificant effort and extensive experimentation to ensure the attack's\nstealthiness and effectiveness. Alternatively, this paper shows that there\nexists a more severe backdoor threat: anyone can exploit an easily-accessible\nalgorithm for silent backdoor attacks. Specifically, this attacker can employ\nthe widely-used lossy image compression from a plethora of compression tools to\neffortlessly inject a trigger pattern into an image without leaving any\nnoticeable trace; i.e., the generated triggers are natural artifacts. One does\nnot require extensive knowledge to click on the \"convert\" or \"save as\" button\nwhile using tools for lossy image compression. Via this attack, the adversary\ndoes not need to design a trigger generator as seen in prior works and only\nrequires poisoning the data. Empirically, the proposed attack consistently\nachieves 100% attack success rate in several benchmark datasets such as MNIST,\nCIFAR-10, GTSRB and CelebA. More significantly, the proposed attack can still\nachieve almost 100% attack success rate with very small (approximately 10%)\npoisoning rates in the clean label setting. The generated trigger of the\nproposed attack using one lossy compression algorithm is also transferable\nacross other related compression algorithms, exacerbating the severity of this\nbackdoor threat. This work takes another crucial step toward understanding the\nextensive risks of backdoor attacks in practice, urging practitioners to\ninvestigate similar attacks and relevant backdoor mitigation methods.",
          "link": "http://arxiv.org/abs/2308.16684",
          "publishedOn": "2023-09-02T00:40:02.254Z",
          "wordCount": null,
          "title": "Everyone Can Attack: Repurpose Lossy Compression as a Natural Backdoor Attack. (arXiv:2308.16684v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16671",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Shenglong Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Kaidi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Geoffrey Ye Li</a>",
          "description": "Decentralized federated learning (DFL) has gained popularity due to its\npracticality across various applications. Compared to the centralized version,\ntraining a shared model among a large number of nodes in DFL is more\nchallenging, as there is no central server to coordinate the training process.\nEspecially when distributed nodes suffer from limitations in communication or\ncomputational resources, DFL will experience extremely inefficient and unstable\ntraining. Motivated by these challenges, in this paper, we develop a novel\nalgorithm based on the framework of the inexact alternating direction method\n(iADM). On one hand, our goal is to train a shared model with a sparsity\nconstraint. This constraint enables us to leverage one-bit compressive sensing\n(1BCS), allowing transmission of one-bit information among neighbour nodes. On\nthe other hand, communication between neighbour nodes occurs only at certain\nsteps, reducing the number of communication rounds. Therefore, the algorithm\nexhibits notable communication efficiency. Additionally, as each node selects\nonly a subset of neighbours to participate in the training, the algorithm is\nrobust against stragglers. Additionally, complex items are computed only once\nfor several consecutive steps and subproblems are solved inexactly using\nclosed-form solutions, resulting in high computational efficiency. Finally,\nnumerical experiments showcase the algorithm's effectiveness in both\ncommunication and computation.",
          "link": "http://arxiv.org/abs/2308.16671",
          "publishedOn": "2023-09-02T00:40:02.253Z",
          "wordCount": null,
          "title": "Communication-Efficient Decentralized Federated Learning via One-Bit Compressive Sensing. (arXiv:2308.16671v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Benfenati_A/0/1/0/all/0/1\">Alessandro Benfenati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chouzenoux_E/0/1/0/all/0/1\">Emilie Chouzenoux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Franchini_G/0/1/0/all/0/1\">Giorgia Franchini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Latva_Aijo_S/0/1/0/all/0/1\">Salla Latva-Aijo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narnhofer_D/0/1/0/all/0/1\">Dominik Narnhofer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pesquet_J/0/1/0/all/0/1\">Jean-Christophe Pesquet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scott_S/0/1/0/all/0/1\">Sebastian J. Scott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yousefi_M/0/1/0/all/0/1\">Mahsa Yousefi</a>",
          "description": "Several decades ago, Support Vector Machines (SVMs) were introduced for\nperforming binary classification tasks, under a supervised framework. Nowadays,\nthey often outperform other supervised methods and remain one of the most\npopular approaches in the machine learning arena. In this work, we investigate\nthe training of SVMs through a smooth sparse-promoting-regularized squared\nhinge loss minimization. This choice paves the way to the application of quick\ntraining methods built on majorization-minimization approaches, benefiting from\nthe Lipschitz differentiabililty of the loss function. Moreover, the proposed\napproach allows us to handle sparsity-preserving regularizers promoting the\nselection of the most significant features, so enhancing the performance.\nNumerical tests and comparisons conducted on three different datasets\ndemonstrate the good performance of the proposed methodology in terms of\nqualitative metrics (accuracy, precision, recall, and F 1 score) as well as\ncomputational cost.",
          "link": "http://arxiv.org/abs/2308.16858",
          "publishedOn": "2023-09-02T00:40:02.252Z",
          "wordCount": null,
          "title": "Majorization-Minimization for sparse SVMs. (arXiv:2308.16858v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16648",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Espinosa_M/0/1/0/all/0/1\">Miguel Espinosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crowley_E/0/1/0/all/0/1\">Elliot J. Crowley</a>",
          "description": "Despite recent advancements in image generation, diffusion models still\nremain largely underexplored in Earth Observation. In this paper we show that\nstate-of-the-art pretrained diffusion models can be conditioned on cartographic\ndata to generate realistic satellite images. We provide two large datasets of\npaired OpenStreetMap images and satellite views over the region of Mainland\nScotland and the Central Belt. We train a ControlNet model and qualitatively\nevaluate the results, demonstrating that both image quality and map fidelity\nare possible. Finally, we provide some insights on the opportunities and\nchallenges of applying these models for remote sensing. Our model weights and\ncode for creating the dataset are publicly available at\nhttps://github.com/miquel-espinosa/map-sat.",
          "link": "http://arxiv.org/abs/2308.16648",
          "publishedOn": "2023-09-02T00:40:02.251Z",
          "wordCount": null,
          "title": "Generate Your Own Scotland: Satellite Image Generation Conditioned on Maps. (arXiv:2308.16648v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16245",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lofstrom_T/0/1/0/all/0/1\">Tuwe L&#xf6;fstr&#xf6;m</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lofstrom_H/0/1/0/all/0/1\">Helena L&#xf6;fstr&#xf6;m</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johansson_U/0/1/0/all/0/1\">Ulf Johansson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonstrod_C/0/1/0/all/0/1\">Cecilia S&#xf6;nstr&#xf6;d</a>",
          "description": "Artificial Intelligence (AI) is often an integral part of modern decision\nsupport systems (DSSs). The best-performing predictive models used in AI-based\nDSSs lack transparency. Explainable Artificial Intelligence (XAI) aims to\ncreate AI systems that can explain their rationale to human users. Local\nexplanations in XAI can provide information about the causes of individual\npredictions in terms of feature importance. However, a critical drawback of\nexisting local explanation methods is their inability to quantify the\nuncertainty associated with a feature's importance. This paper introduces an\nextension of a feature importance explanation method, Calibrated Explanations\n(CE), previously only supporting classification, with support for standard\nregression and probabilistic regression, i.e., the probability that the target\nis above an arbitrary threshold. The extension for regression keeps all the\nbenefits of CE, such as calibration of the prediction from the underlying model\nwith confidence intervals, uncertainty quantification of feature importance,\nand allows both factual and counterfactual explanations. CE for standard\nregression provides fast, reliable, stable, and robust explanations. CE for\nprobabilistic regression provides an entirely new way of creating probabilistic\nexplanations from any ordinary regression model and with a dynamic selection of\nthresholds. The performance of CE for probabilistic regression regarding\nstability and speed is comparable to LIME. The method is model agnostic with\neasily understood conditional rules. An implementation in Python is freely\navailable on GitHub and for installation using pip making the results in this\npaper easily replicable.",
          "link": "http://arxiv.org/abs/2308.16245",
          "publishedOn": "2023-09-02T00:40:02.250Z",
          "wordCount": null,
          "title": "Calibrated Explanations for Regression. (arXiv:2308.16245v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16754",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Werneburg_E/0/1/0/all/0/1\">Eric Arthur Werneburg</a>",
          "description": "We introduce and study the theory of training neural networks using\ninterpolation techniques from reproducing kernel Hilbert space theory. We\ngeneralize the method to Krein spaces, and show that widely-used neural network\narchitectures are subsets of reproducing kernel Krein spaces (RKKS). We study\nthe concept of \"associated Hilbert spaces\" of RKKS and develop techniques to\nimprove upon the expressivity of various activation functions. Next, using\nconcepts from the theory of functions of several complex variables, we prove a\ncomputationally applicable, multidimensional generalization of the celebrated\nAdamjan- Arov-Krein (AAK) theorem. The theorem yields a novel class of neural\nnetworks, called Prolongation Neural Networks (PNN). We demonstrate that, by\napplying the multidimensional AAK theorem to gain a PNN, one can gain\nperformance superior to both our interpolatory methods and current\nstate-of-the-art methods in noisy environments. We provide useful illustrations\nof our methods in practice.",
          "link": "http://arxiv.org/abs/2308.16754",
          "publishedOn": "2023-09-02T00:40:02.250Z",
          "wordCount": null,
          "title": "Training Neural Networks Using Reproducing Kernel Space Interpolation and Model Reduction. (arXiv:2308.16754v1 [math.FA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16585",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saux_P/0/1/0/all/0/1\">Patrick Saux</a> (Scool, CRIStAL), <a href=\"http://arxiv.org/find/cs/1/au:+Bauvin_P/0/1/0/all/0/1\">Pierre Bauvin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raverdy_V/0/1/0/all/0/1\">Violeta Raverdy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teigny_J/0/1/0/all/0/1\">Julien Teigny</a> (Scool), <a href=\"http://arxiv.org/find/cs/1/au:+Verkindt_H/0/1/0/all/0/1\">H&#xe9;l&#xe8;ne Verkindt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soumphonphakdy_T/0/1/0/all/0/1\">Tomy Soumphonphakdy</a> (Scool), <a href=\"http://arxiv.org/find/cs/1/au:+Debert_M/0/1/0/all/0/1\">Maxence Debert</a> (Scool), <a href=\"http://arxiv.org/find/cs/1/au:+Jacobs_A/0/1/0/all/0/1\">Anne Jacobs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobs_D/0/1/0/all/0/1\">Daan Jacobs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monpellier_V/0/1/0/all/0/1\">Valerie Monpellier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_P/0/1/0/all/0/1\">Phong Ching Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_C/0/1/0/all/0/1\">Chin Hong Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andersson_Assarsson_J/0/1/0/all/0/1\">Johanna C Andersson-Assarsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carlsson_L/0/1/0/all/0/1\">Lena Carlsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Svensson_P/0/1/0/all/0/1\">Per-Arne Svensson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galtier_F/0/1/0/all/0/1\">Florence Galtier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dezfoulian_G/0/1/0/all/0/1\">Guelareh Dezfoulian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moldovanu_M/0/1/0/all/0/1\">Mihaela Moldovanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andrieux_S/0/1/0/all/0/1\">Severine Andrieux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Couster_J/0/1/0/all/0/1\">Julien Couster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lepage_M/0/1/0/all/0/1\">Marie Lepage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lembo_E/0/1/0/all/0/1\">Erminia Lembo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verrastro_O/0/1/0/all/0/1\">Ornella Verrastro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robert_M/0/1/0/all/0/1\">Maud Robert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salminen_P/0/1/0/all/0/1\">Paulina Salminen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mingrone_G/0/1/0/all/0/1\">Geltrude Mingrone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peterli_R/0/1/0/all/0/1\">Ralph Peterli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_R/0/1/0/all/0/1\">Ricardo V Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zerrweck_C/0/1/0/all/0/1\">Carlos Zerrweck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nocca_D/0/1/0/all/0/1\">David Nocca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roux_C/0/1/0/all/0/1\">Carel W Le Roux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caiazzo_R/0/1/0/all/0/1\">Robert Caiazzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preux_P/0/1/0/all/0/1\">Philippe Preux</a> (Scool, CRIStAL), <a href=\"http://arxiv.org/find/cs/1/au:+Pattou_F/0/1/0/all/0/1\">Fran&#xe7;ois Pattou</a>",
          "description": "Background Weight loss trajectories after bariatric surgery vary widely\nbetween individuals, and predicting weight loss before the operation remains\nchallenging. We aimed to develop a model using machine learning to provide\nindividual preoperative prediction of 5-year weight loss trajectories after\nsurgery. Methods In this multinational retrospective observational study we\nenrolled adult participants (aged $\\ge$18 years) from ten prospective cohorts\n(including ABOS [NCT01129297], BAREVAL [NCT02310178], the Swedish Obese\nSubjects study, and a large cohort from the Dutch Obesity Clinic [Nederlandse\nObesitas Kliniek]) and two randomised trials (SleevePass [NCT00793143] and\nSM-BOSS [NCT00356213]) in Europe, the Americas, and Asia, with a 5 year\nfollowup after Roux-en-Y gastric bypass, sleeve g…",
          "link": "http://arxiv.org/abs/2308.16585",
          "publishedOn": "2023-09-02T00:40:02.235Z",
          "wordCount": null,
          "title": "Development and validation of an interpretable machine learning-based calculator for predicting 5-year weight trajectories after bariatric surgery: a multinational retrospective cohort SOPHIA study. (arXiv:2308.16585v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16598",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Mojtahedi_R/0/1/0/all/0/1\">Ramtin Mojtahedi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hamghalam_M/0/1/0/all/0/1\">Mohammad Hamghalam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Do_R/0/1/0/all/0/1\">Richard K. G. Do</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Simpson_A/0/1/0/all/0/1\">Amber L. Simpson</a>",
          "description": "Detection of tumors in metastatic colorectal cancer (mCRC) plays an essential\nrole in the early diagnosis and treatment of liver cancer. Deep learning models\nbackboned by fully convolutional neural networks (FCNNs) have become the\ndominant model for segmenting 3D computerized tomography (CT) scans. However,\nsince their convolution layers suffer from limited kernel size, they are not\nable to capture long-range dependencies and global context. To tackle this\nrestriction, vision transformers have been introduced to solve FCNN's locality\nof receptive fields. Although transformers can capture long-range features,\ntheir segmentation performance decreases with various tumor sizes due to the\nmodel sensitivity to the input patch size. While finding an optimal patch size\nimproves the performance of vision transformer-based models on segmentation\ntasks, it is a time-consuming and challenging procedure. This paper proposes a\ntechnique to select the vision transformer's optimal input multi-resolution\nimage patch size based on the average volume size of metastasis lesions. We\nfurther validated our suggested framework using a transfer-learning technique,\ndemonstrating that the highest Dice similarity coefficient (DSC) performance\nwas obtained by pre-training on training data with a larger tumour volume using\nthe suggested ideal patch size and then training with a smaller one. We\nexperimentally evaluate this idea through pre-training our model on a\nmulti-resolution public dataset. Our model showed consistent and improved\nresults when applied to our private multi-resolution mCRC dataset with a\nsmaller average tumor volume. This study lays the groundwork for optimizing\nsemantic segmentation of small objects using vision transformers. The\nimplementation source code is available\nat:https://github.com/Ramtin-Mojtahedi/OVTPS.",
          "link": "http://arxiv.org/abs/2308.16598",
          "publishedOn": "2023-09-02T00:40:02.235Z",
          "wordCount": null,
          "title": "Towards Optimal Patch Size in Vision Transformers for Tumor Segmentation. (arXiv:2308.16598v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16570",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dias_D/0/1/0/all/0/1\">Duarte Dias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sousa_B/0/1/0/all/0/1\">Bruno Sousa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antunes_N/0/1/0/all/0/1\">Nuno Antunes</a>",
          "description": "Mobile devices have widespread to become the most used piece of technology.\nDue to their characteristics, they have become major targets for botnet-related\nmalware. FluBot is one example of botnet malware that infects mobile devices.\nIn particular, FluBot is a DNS-based botnet that uses Domain Generation\nAlgorithms (DGA) to establish communication with the Command and Control Server\n(C2). MONDEO is a multistage mechanism with a flexible design to detect\nDNS-based botnet malware. MONDEO is lightweight and can be deployed without\nrequiring the deployment of software, agents, or configuration in mobile\ndevices, allowing easy integration in core networks. MONDEO comprises four\ndetection stages: Blacklisting/Whitelisting, Query rate analysis, DGA analysis,\nand Machine learning evaluation. It was created with the goal of processing\nstreams of packets to identify attacks with high efficiency, in the distinct\nphases. MONDEO was tested against several datasets to measure its efficiency\nand performance, being able to achieve high performance with RandomForest\nclassifiers. The implementation is available at github.",
          "link": "http://arxiv.org/abs/2308.16570",
          "publishedOn": "2023-09-02T00:40:02.234Z",
          "wordCount": null,
          "title": "MONDEO: Multistage Botnet Detection. (arXiv:2308.16570v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16490",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_S/0/1/0/all/0/1\">Shih-Chieh Su</a>",
          "description": "Latent diffusers revolutionized the generative AI and inspired creative art.\nWhen denoising the latent, the predicted original image at each step\ncollectively animates the formation. However, the animation is limited by the\ndenoising nature of the diffuser, and only renders a sharpening process. This\nwork presents Latent Painter, which uses the latent as the canvas, and the\ndiffuser predictions as the plan, to generate painting animation. Latent\nPainter also transits one generated image to another, which can happen between\nimages from two different sets of checkpoints.",
          "link": "http://arxiv.org/abs/2308.16490",
          "publishedOn": "2023-09-02T00:40:02.233Z",
          "wordCount": null,
          "title": "Latent Painter. (arXiv:2308.16490v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16759",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1\">Zheng Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junting Chen</a>",
          "description": "Radio map construction requires a large amount of radio measurement data with\nlocation labels, which imposes a high deployment cost. This paper develops a\nregion-based radio map from received signal strength (RSS) measurements without\nlocation labels. The construction is based on a set of blindly collected RSS\nmeasurement data from a device that visits each region in an indoor area\nexactly once, where the footprints and timestamps are not recorded. The main\nchallenge is to cluster the RSS data and match clusters with the physical\nregions. Classical clustering algorithms fail to work as the RSS data naturally\nappears as non-clustered due to multipaths and noise. In this paper, a signal\nsubspace model with a sequential prior is constructed for the RSS data, and an\nintegrated segmentation and clustering algorithm is developed, which is shown\nto find the globally optimal solution in a special case. Furthermore, the\nclustered data is matched with the physical regions using a graph-based\napproach. Based on real measurements from an office space, the proposed scheme\nreduces the region localization error by roughly 50% compared to a weighted\ncentroid localization (WCL) baseline, and it even outperforms some supervised\nlocalization schemes, including k-nearest neighbor (KNN), support vector\nmachine (SVM), and deep neural network (DNN), which require labeled data for\ntraining.",
          "link": "http://arxiv.org/abs/2308.16759",
          "publishedOn": "2023-09-02T00:40:02.233Z",
          "wordCount": null,
          "title": "Constructing Indoor Region-based Radio Map without Location Labels. (arXiv:2308.16759v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16541",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Yi Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Siwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1\">Ke Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_W/0/1/0/all/0/1\">Weixuan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xinhang Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xinwang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Suyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_E/0/1/0/all/0/1\">En Zhu</a>",
          "description": "The success of existing multi-view clustering (MVC) relies on the assumption\nthat all views are complete. However, samples are usually partially available\ndue to data corruption or sensor malfunction, which raises the research of\nincomplete multi-view clustering (IMVC). Although several anchor-based IMVC\nmethods have been proposed to process the large-scale incomplete data, they\nstill suffer from the following drawbacks: i) Most existing approaches neglect\nthe inter-view discrepancy and enforce cross-view representation to be\nconsistent, which would corrupt the representation capability of the model; ii)\nDue to the samples disparity between different views, the learned anchor might\nbe misaligned, which we referred as the Anchor-Unaligned Problem for Incomplete\ndata (AUP-ID). Such the AUP-ID would cause inaccurate graph fusion and degrades\nclustering performance. To tackle these issues, we propose a novel incomplete\nanchor graph learning framework termed Scalable Incomplete Multi-View\nClustering with Structure Alignment (SIMVC-SA). Specially, we construct the\nview-specific anchor graph to capture the complementary information from\ndifferent views. In order to solve the AUP-ID, we propose a novel structure\nalignment module to refine the cross-view anchor correspondence. Meanwhile, the\nanchor graph construction and alignment are jointly optimized in our unified\nframework to enhance clustering quality. Through anchor graph construction\ninstead of full graphs, the time and space complexity of the proposed SIMVC-SA\nis proven to be linearly correlated with the number of samples. Extensive\nexperiments on seven incomplete benchmark datasets demonstrate the\neffectiveness and efficiency of our proposed method. Our code is publicly\navailable at https://github.com/wy1019/SIMVC-SA.",
          "link": "http://arxiv.org/abs/2308.16541",
          "publishedOn": "2023-09-02T00:40:02.231Z",
          "wordCount": null,
          "title": "Scalable Incomplete Multi-View Clustering with Structure Alignment. (arXiv:2308.16541v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16572",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Madan_N/0/1/0/all/0/1\">Neelu Madan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ristea_N/0/1/0/all/0/1\">Nicolae-Catalin Ristea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasrollahi_K/0/1/0/all/0/1\">Kamal Nasrollahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moeslund_T/0/1/0/all/0/1\">Thomas B. Moeslund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ionescu_R/0/1/0/all/0/1\">Radu Tudor Ionescu</a>",
          "description": "Masked image modeling has been demonstrated as a powerful pretext task for\ngenerating robust representations that can be effectively generalized across\nmultiple downstream tasks. Typically, this approach involves randomly masking\npatches (tokens) in input images, with the masking strategy remaining unchanged\nduring training. In this paper, we propose a curriculum learning approach that\nupdates the masking strategy to continually increase the complexity of the\nself-supervised reconstruction task. We conjecture that, by gradually\nincreasing the task complexity, the model can learn more sophisticated and\ntransferable representations. To facilitate this, we introduce a novel\nlearnable masking module that possesses the capability to generate masks of\ndifferent complexities, and integrate the proposed module into masked\nautoencoders (MAE). Our module is jointly trained with the MAE, while adjusting\nits behavior during training, transitioning from a partner to the MAE\n(optimizing the same reconstruction loss) to an adversary (optimizing the\nopposite loss), while passing through a neutral state. The transition between\nthese behaviors is smooth, being regulated by a factor that is multiplied with\nthe reconstruction loss of the masking module. The resulting training procedure\ngenerates an easy-to-hard curriculum. We train our Curriculum-Learned Masked\nAutoencoder (CL-MAE) on ImageNet and show that it exhibits superior\nrepresentation learning capabilities compared to MAE. The empirical results on\nfive downstream tasks confirm our conjecture, demonstrating that curriculum\nlearning can be successfully used to self-supervise masked autoencoders.",
          "link": "http://arxiv.org/abs/2308.16572",
          "publishedOn": "2023-09-02T00:40:02.231Z",
          "wordCount": null,
          "title": "CL-MAE: Curriculum-Learned Masked Autoencoders. (arXiv:2308.16572v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16664",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Umeano_C/0/1/0/all/0/1\">Chukwudubem Umeano</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Paine_A/0/1/0/all/0/1\">Annie E. Paine</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Elfving_V/0/1/0/all/0/1\">Vincent E. Elfving</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kyriienko_O/0/1/0/all/0/1\">Oleksandr Kyriienko</a>",
          "description": "We can learn from analyzing quantum convolutional neural networks (QCNNs)\nthat: 1) working with quantum data can be perceived as embedding physical\nsystem parameters through a hidden feature map; 2) their high performance for\nquantum phase recognition can be attributed to generation of a very suitable\nbasis set during the ground state embedding, where quantum criticality of spin\nmodels leads to basis functions with rapidly changing features; 3) pooling\nlayers of QCNNs are responsible for picking those basis functions that can\ncontribute to forming a high-performing decision boundary, and the learning\nprocess corresponds to adapting the measurement such that few-qubit operators\nare mapped to full-register observables; 4) generalization of QCNN models\nstrongly depends on the embedding type, and that rotation-based feature maps\nwith the Fourier basis require careful feature engineering; 5) accuracy and\ngeneralization of QCNNs with readout based on a limited number of shots favor\nthe ground state embeddings and associated physics-informed models. We\ndemonstrate these points in simulation, where our results shed light on\nclassification for physical processes, relevant for applications in sensing.\nFinally, we show that QCNNs with properly chosen ground state embeddings can be\nused for fluid dynamics problems, expressing shock wave solutions with good\ngeneralization and proven trainability.",
          "link": "http://arxiv.org/abs/2308.16664",
          "publishedOn": "2023-09-02T00:40:02.230Z",
          "wordCount": null,
          "title": "What can we learn from quantum convolutional neural networks?. (arXiv:2308.16664v1 [quant-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16571",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Ashrafur Rahman Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azad_A/0/1/0/all/0/1\">Asif Azad</a>",
          "description": "In the rapidly evolving digital era, the analysis of document layouts plays a\npivotal role in automated information extraction and interpretation. In our\nwork, we have trained MViTv2 transformer model architecture with cascaded mask\nR-CNN on BaDLAD dataset to extract text box, paragraphs, images and tables from\na document. After training on 20365 document images for 36 epochs in a 3 phase\ncycle, we achieved a training loss of 0.2125 and a mask loss of 0.19. Our work\nextends beyond training, delving into the exploration of potential enhancement\navenues. We investigate the impact of rotation and flip augmentation, the\neffectiveness of slicing input images pre-inference, the implications of\nvarying the resolution of the transformer backbone, and the potential of\nemploying a dual-pass inference to uncover missed text-boxes. Through these\nexplorations, we observe a spectrum of outcomes, where some modifications\nresult in tangible performance improvements, while others offer unique insights\nfor future endeavors.",
          "link": "http://arxiv.org/abs/2308.16571",
          "publishedOn": "2023-09-02T00:40:02.229Z",
          "wordCount": null,
          "title": "Document Layout Analysis on BaDLAD Dataset: A Comprehensive MViTv2 Based Approach. (arXiv:2308.16571v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16458",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xiangru Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_B/0/1/0/all/0/1\">Bill Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1\">Rick Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiakang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinyun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerstein_M/0/1/0/all/0/1\">Mark Gerstein</a>",
          "description": "Pre-trained language models like ChatGPT have significantly improved code\ngeneration. As these models scale up, there is an increasing need for the\noutput to handle more intricate tasks. Moreover, in bioinformatics, generating\nfunctional programs poses additional notable challenges due to the amount of\ndomain knowledge, the need for complicated data operations, and intricate\nfunctional dependencies between the operations. Here, we present BioCoder, a\nbenchmark developed to evaluate existing pre-trained models in generating\nbioinformatics code. In relation to function-code generation, BioCoder covers\npotential package dependencies, class declarations, and global variables. It\nincorporates 1026 functions and 1243 methods in Python and Java from GitHub and\n253 examples from the Rosalind Project. BioCoder incorporates a fuzz-testing\nframework for evaluation, and we have applied it to evaluate many models\nincluding InCoder, CodeGen, CodeGen2, SantaCoder, StarCoder, StarCoder+,\nInstructCodeT5+, and ChatGPT. Our detailed analysis of these models emphasizes\nthe importance of domain knowledge, pragmatic code generation, and contextual\nunderstanding. Our dataset, benchmark, Docker images, and scripts required for\ntesting are all available at https://github.com/gersteinlab/biocoder.",
          "link": "http://arxiv.org/abs/2308.16458",
          "publishedOn": "2023-09-02T00:40:02.227Z",
          "wordCount": null,
          "title": "BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge. (arXiv:2308.16458v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16609",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1\">Siyu Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1\">Zhengyang Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ju_W/0/1/0/all/0/1\">Wei Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yongdao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Luchen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1\">Xiao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Ming Zhang</a>",
          "description": "Graph classification, aiming at learning the graph-level representations for\neffective class assignments, has received outstanding achievements, which\nheavily relies on high-quality datasets that have balanced class distribution.\nIn fact, most real-world graph data naturally presents a long-tailed form,\nwhere the head classes occupy much more samples than the tail classes, it thus\nis essential to study the graph-level classification over long-tailed data\nwhile still remaining largely unexplored. However, most existing long-tailed\nlearning methods in visions fail to jointly optimize the representation\nlearning and classifier training, as well as neglect the mining of the\nhard-to-classify classes. Directly applying existing methods to graphs may lead\nto sub-optimal performance, since the model trained on graphs would be more\nsensitive to the long-tailed distribution due to the complex topological\ncharacteristics. Hence, in this paper, we propose a novel long-tailed\ngraph-level classification framework via Collaborative Multi-expert Learning\n(CoMe) to tackle the problem. To equilibrate the contributions of head and tail\nclasses, we first develop balanced contrastive learning from the view of\nrepresentation learning, and then design an individual-expert classifier\ntraining based on hard class mining. In addition, we execute gated fusion and\ndisentangled knowledge distillation among the multiple experts to promote the\ncollaboration in a multi-expert framework. Comprehensive experiments are\nperformed on seven widely-used benchmark datasets to demonstrate the\nsuperiority of our method CoMe over state-of-the-art baselines.",
          "link": "http://arxiv.org/abs/2308.16609",
          "publishedOn": "2023-09-02T00:40:02.202Z",
          "wordCount": null,
          "title": "Towards Long-Tailed Recognition for Graph Classification via Collaborative Experts. (arXiv:2308.16609v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weiqin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_S/0/1/0/all/0/1\">Shun Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qiaochu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yixuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1\">Shiyin Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1\">Helen Meng</a>",
          "description": "The spontaneous behavior that often occurs in conversations makes speech more\nhuman-like compared to reading-style. However, synthesizing spontaneous-style\nspeech is challenging due to the lack of high-quality spontaneous datasets and\nthe high cost of labeling spontaneous behavior. In this paper, we propose a\nsemi-supervised pre-training method to increase the amount of spontaneous-style\nspeech and spontaneous behavioral labels. In the process of semi-supervised\nlearning, both text and speech information are considered for detecting\nspontaneous behaviors labels in speech. Moreover, a linguistic-aware encoder is\nused to model the relationship between each sentence in the conversation.\nExperimental results indicate that our proposed method achieves superior\nexpressive speech synthesis performance with the ability to model spontaneous\nbehavior in spontaneous-style speech and predict reasonable spontaneous\nbehavior from text.",
          "link": "http://arxiv.org/abs/2308.16593",
          "publishedOn": "2023-09-02T00:40:02.195Z",
          "wordCount": null,
          "title": "Towards Spontaneous Style Modeling with Semi-supervised Pre-training for Conversational Text-to-Speech Synthesis. (arXiv:2308.16593v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_N/0/1/0/all/0/1\">Ning Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vien_N/0/1/0/all/0/1\">Ngo Anh Vien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziesche_H/0/1/0/all/0/1\">Hanna Ziesche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1\">Gerhard Neumann</a>",
          "description": "To enable meaningful robotic manipulation of objects in the real-world, 6D\npose estimation is one of the critical aspects. Most existing approaches have\ndifficulties to extend predictions to scenarios where novel object instances\nare continuously introduced, especially with heavy occlusions. In this work, we\npropose a few-shot pose estimation (FSPE) approach called SA6D, which uses a\nself-adaptive segmentation module to identify the novel target object and\nconstruct a point cloud model of the target object using only a small number of\ncluttered reference images. Unlike existing methods, SA6D does not require\nobject-centric reference images or any additional object information, making it\na more generalizable and scalable solution across categories. We evaluate SA6D\non real-world tabletop object datasets and demonstrate that SA6D outperforms\nexisting FSPE methods, particularly in cluttered scenes with occlusions, while\nrequiring fewer reference images.",
          "link": "http://arxiv.org/abs/2308.16528",
          "publishedOn": "2023-09-02T00:40:02.194Z",
          "wordCount": null,
          "title": "SA6D: Self-Adaptive Few-Shot 6D Pose Estimator for Novel and Occluded Objects. (arXiv:2308.16528v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.14505",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Cheslerean_Boghiu_T/0/1/0/all/0/1\">Theodor Cheslerean-Boghiu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fleischmann_M/0/1/0/all/0/1\">Melia-Evelina Fleischmann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Willem_T/0/1/0/all/0/1\">Theresa Willem</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lasser_T/0/1/0/all/0/1\">Tobias Lasser</a>",
          "description": "A lot of deep learning (DL) research these days is mainly focused on\nimproving quantitative metrics regardless of other factors. In human-centered\napplications, like skin lesion classification in dermatology, DL-driven\nclinical decision support systems are still in their infancy due to the limited\ntransparency of their decision-making process. Moreover, the lack of procedures\nthat can explain the behavior of trained DL algorithms leads to almost no trust\nfrom clinical physicians. To diagnose skin lesions, dermatologists rely on\nvisual assessment of the disease and the data gathered from the patient's\nanamnesis. Data-driven algorithms dealing with multi-modal data are limited by\nthe separation of feature-level and decision-level fusion procedures required\nby convolutional architectures. To address this issue, we enable single-stage\nmulti-modal data fusion via the attention mechanism of transformer-based\narchitectures to aid in diagnosing skin diseases. Our method beats other\nstate-of-the-art single- and multi-modal DL architectures in image-rich and\npatient-data-rich environments. Additionally, the choice of the architecture\nenables native interpretability support for the classification task both in the\nimage and metadata domain with no additional modifications necessary.",
          "link": "http://arxiv.org/abs/2304.14505",
          "publishedOn": "2023-09-02T00:40:02.193Z",
          "wordCount": null,
          "title": "Transformer-based interpretable multi-modal data fusion for skin lesion classification. (arXiv:2304.14505v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16539",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Diehl_C/0/1/0/all/0/1\">Christopher Diehl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klosek_T/0/1/0/all/0/1\">Tobias Klosek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kruger_M/0/1/0/all/0/1\">Martin Kr&#xfc;ger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murzyn_N/0/1/0/all/0/1\">Nils Murzyn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bertram_T/0/1/0/all/0/1\">Torsten Bertram</a>",
          "description": "Game theory offers an interpretable mathematical framework for modeling\nmulti-agent interactions. However, its applicability in real-world robotics\napplications is hindered by several challenges, such as unknown agents'\npreferences and goals. To address these challenges, we show a connection\nbetween differential games, optimal control, and energy-based models and\ndemonstrate how existing approaches can be unified under our proposed\nEnergy-based Potential Game formulation. Building upon this formulation, this\nwork introduces a new end-to-end learning application that combines neural\nnetworks for game-parameter inference with a differentiable game-theoretic\noptimization layer, acting as an inductive bias. The experiments using\nsimulated mobile robot pedestrian interactions and real-world automated driving\ndata provide empirical evidence that the game-theoretic layer improves the\npredictive performance of various neural network backbones.",
          "link": "http://arxiv.org/abs/2308.16539",
          "publishedOn": "2023-09-02T00:40:02.188Z",
          "wordCount": null,
          "title": "On a Connection between Differential Games, Optimal Control, and Energy-based Models for Multi-Agent Interactions. (arXiv:2308.16539v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16470",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xiao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1\">Shirui Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_K/0/1/0/all/0/1\">Kup-Sze Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xi Zhou</a>",
          "description": "Cross-network node classification (CNNC), which aims to classify nodes in a\nlabel-deficient target network by transferring the knowledge from a source\nnetwork with abundant labels, draws increasing attention recently. To address\nCNNC, we propose a domain-adaptive message passing graph neural network\n(DM-GNN), which integrates graph neural network (GNN) with conditional\nadversarial domain adaptation. DM-GNN is capable of learning informative\nrepresentations for node classification that are also transferrable across\nnetworks. Firstly, a GNN encoder is constructed by dual feature extractors to\nseparate ego-embedding learning from neighbor-embedding learning so as to\njointly capture commonality and discrimination between connected nodes.\nSecondly, a label propagation node classifier is proposed to refine each node's\nlabel prediction by combining its own prediction and its neighbors' prediction.\nIn addition, a label-aware propagation scheme is devised for the labeled source\nnetwork to promote intra-class propagation while avoiding inter-class\npropagation, thus yielding label-discriminative source embeddings. Thirdly,\nconditional adversarial domain adaptation is performed to take the\nneighborhood-refined class-label information into account during adversarial\ndomain adaptation, so that the class-conditional distributions across networks\ncan be better matched. Comparisons with eleven state-of-the-art methods\ndemonstrate the effectiveness of the proposed DM-GNN.",
          "link": "http://arxiv.org/abs/2308.16470",
          "publishedOn": "2023-09-02T00:40:02.182Z",
          "wordCount": null,
          "title": "Domain-adaptive Message Passing Graph Neural Network. (arXiv:2308.16470v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16481",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hatem_A/0/1/0/all/0/1\">Ahmed Hatem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yiming Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yang Wang</a>",
          "description": "We present Point-TTA, a novel test-time adaptation framework for point cloud\nregistration (PCR) that improves the generalization and the performance of\nregistration models. While learning-based approaches have achieved impressive\nprogress, generalization to unknown testing environments remains a major\nchallenge due to the variations in 3D scans. Existing methods typically train a\ngeneric model and the same trained model is applied on each instance during\ntesting. This could be sub-optimal since it is difficult for the same model to\nhandle all the variations during testing. In this paper, we propose a test-time\nadaptation approach for PCR. Our model can adapt to unseen distributions at\ntest-time without requiring any prior knowledge of the test data. Concretely,\nwe design three self-supervised auxiliary tasks that are optimized jointly with\nthe primary PCR task. Given a test instance, we adapt our model using these\nauxiliary tasks and the updated model is used to perform the inference. During\ntraining, our model is trained using a meta-auxiliary learning approach, such\nthat the adapted model via auxiliary tasks improves the accuracy of the primary\ntask. Experimental results demonstrate the effectiveness of our approach in\nimproving generalization of point cloud registration and outperforming other\nstate-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2308.16481",
          "publishedOn": "2023-09-02T00:40:02.182Z",
          "wordCount": null,
          "title": "Point-TTA: Test-Time Adaptation for Point Cloud Registration Using Multitask Meta-Auxiliary Learning. (arXiv:2308.16481v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16484",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hatem_A/0/1/0/all/0/1\">Ahmed Hatem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yiming Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yang Wang</a>",
          "description": "Affordable 3D scanners often produce sparse and non-uniform point clouds that\nnegatively impact downstream applications in robotic systems. While existing\npoint cloud upsampling architectures have demonstrated promising results on\nstandard benchmarks, they tend to experience significant performance drops when\nthe test data have different distributions from the training data. To address\nthis issue, this paper proposes a test-time adaption approach to enhance model\ngenerality of point cloud upsampling. The proposed approach leverages\nmeta-learning to explicitly learn network parameters for test-time adaption.\nOur method does not require any prior information about the test data. During\nmeta-training, the model parameters are learned from a collection of\ninstance-level tasks, each of which consists of a sparse-dense pair of point\nclouds from the training data. During meta-testing, the trained model is\nfine-tuned with a few gradient updates to produce a unique set of network\nparameters for each test instance. The updated model is then used for the final\nprediction. Our framework is generic and can be applied in a plug-and-play\nmanner with existing backbone networks in point cloud upsampling. Extensive\nexperiments demonstrate that our approach improves the performance of\nstate-of-the-art models.",
          "link": "http://arxiv.org/abs/2308.16484",
          "publishedOn": "2023-09-02T00:40:02.180Z",
          "wordCount": null,
          "title": "Test-Time Adaptation for Point Cloud Upsampling Using Meta-Learning. (arXiv:2308.16484v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16385",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qiang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jiawei Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_X/0/1/0/all/0/1\">Xi Susie Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Ce Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1\">Zhichao Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zitao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yongjun He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Quanqing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1\">Chuang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_S/0/1/0/all/0/1\">Shuo Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1\">Bo Du</a>",
          "description": "To handle graphs in which features or connectivities are evolving over time,\na series of temporal graph neural networks (TGNNs) have been proposed. Despite\nthe success of these TGNNs, the previous TGNN evaluations reveal several\nlimitations regarding four critical issues: 1) inconsistent datasets, 2)\ninconsistent evaluation pipelines, 3) lacking workload diversity, and 4)\nlacking efficient comparison. Overall, there lacks an empirical study that puts\nTGNN models onto the same ground and compares them comprehensively. To this\nend, we propose BenchTemp, a general benchmark for evaluating TGNN models on\nvarious workloads. BenchTemp provides a set of benchmark datasets so that\ndifferent TGNN models can be fairly compared. Further, BenchTemp engineers a\nstandard pipeline that unifies the TGNN evaluation. With BenchTemp, we\nextensively compare the representative TGNN models on different tasks (e.g.,\nlink prediction and node classification) and settings (transductive and\ninductive), w.r.t. both effectiveness and efficiency metrics. We have made\nBenchTemp publicly available at https://github.com/qianghuangwhu/benchtemp.",
          "link": "http://arxiv.org/abs/2308.16385",
          "publishedOn": "2023-09-02T00:40:02.179Z",
          "wordCount": null,
          "title": "BenchTemp: A General Benchmark for Evaluating Temporal Graph Neural Networks. (arXiv:2308.16385v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16491",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gligoric_K/0/1/0/all/0/1\">Kristina Gligoric</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piccardi_T/0/1/0/all/0/1\">Tiziano Piccardi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofman_J/0/1/0/all/0/1\">Jake Hofman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+West_R/0/1/0/all/0/1\">Robert West</a>",
          "description": "Science is facing a reproducibility crisis. Previous work has proposed\nincorporating data analysis replications into classrooms as a potential\nsolution. However, despite the potential benefits, it is unclear whether this\napproach is feasible, and if so, what the involved stakeholders-students,\neducators, and scientists-should expect from it. Can students perform a data\nanalysis replication over the course of a class? What are the costs and\nbenefits for educators? And how can this solution help benchmark and improve\nthe state of science?\n\nIn the present study, we incorporated data analysis replications in the\nproject component of the Applied Data Analysis course (CS-401) taught at EPFL\n(N=354 students). Here we report pre-registered findings based on surveys\nadministered throughout the course. First, we demonstrate that students can\nreplicate previously published scientific papers, most of them qualitatively\nand some exactly. We find discrepancies between what students expect of data\nanalysis replications and what they experience by doing them along with changes\nin expectations about reproducibility, which together serve as evidence of\nattitude shifts to foster students' critical thinking. Second, we provide\ninformation for educators about how much overhead is needed to incorporate\nreplications into the classroom and identify concerns that replications bring\nas compared to more traditional assignments. Third, we identify tangible\nbenefits of the in-class data analysis replications for scientific communities,\nsuch as a collection of replication reports and insights about replication\nbarriers in scientific work that should be avoided going forward.\n\nOverall, we demonstrate that incorporating replication tasks into a large\ndata science class can increase the reproducibility of scientific work as a\nby-product of data science instruction, thus benefiting both science and\nstudents.",
          "link": "http://arxiv.org/abs/2308.16491",
          "publishedOn": "2023-09-02T00:40:02.179Z",
          "wordCount": null,
          "title": "In-class Data Analysis Replications: Teaching Students while Testing Science. (arXiv:2308.16491v1 [cs.CY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.15449",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Edelman_A/0/1/0/all/0/1\">Alan Edelman</a>, <a href=\"http://arxiv.org/find/math/1/au:+Akyurek_E/0/1/0/all/0/1\">Ekin Akyurek</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wang_Y/0/1/0/all/0/1\">Yuyang Wang</a>",
          "description": "We present a linear algebra formulation of backpropagation which allows the\ncalculation of gradients by using a generically written ``backslash'' or\nGaussian elimination on triangular systems of equations. Generally, the matrix\nelements are operators. This paper has three contributions: (i) it is of\nintellectual value to replace traditional treatments of automatic\ndifferentiation with a (left acting) operator theoretic, graph-based approach;\n(ii) operators can be readily placed in matrices in software in programming\nlanguages such as Julia as an implementation option; (iii) we introduce a novel\nnotation, ``transpose dot'' operator ``$\\{\\}^{T_\\bullet}$'' that allows for the\nreversal of operators.\n\nWe further demonstrate the elegance of the operators approach in a suitable\nprogramming language consisting of generic linear algebra operators such as\nJulia \\cite{bezanson2017julia}, and that it is possible to realize this\nabstraction in code. Our implementation shows how generic linear algebra can\nallow operators as elements of matrices. In contrast to ``operator\noverloading,'' where backslash would normally have to be rewritten to take\nadvantage of operators, with ``generic programming'' there is no such need.",
          "link": "http://arxiv.org/abs/2303.15449",
          "publishedOn": "2023-09-02T00:40:02.176Z",
          "wordCount": null,
          "title": "Backpropagation through Back Substitution with a Backslash. (arXiv:2303.15449v2 [math.NA] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.15487",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Werner_L/0/1/0/all/0/1\">Luisa Werner</a> (TYREX, UGA), <a href=\"http://arxiv.org/find/cs/1/au:+Layaida_N/0/1/0/all/0/1\">Nabil Laya&#xef;da</a> (TYREX), <a href=\"http://arxiv.org/find/cs/1/au:+Geneves_P/0/1/0/all/0/1\">Pierre Genev&#xe8;s</a> (CNRS, TYREX), <a href=\"http://arxiv.org/find/cs/1/au:+Chlyah_S/0/1/0/all/0/1\">Sarah Chlyah</a> (TYREX)",
          "description": "Graph data is omnipresent and has a wide variety of applications, such as in\nnatural science, social networks, or the semantic web. However, while being\nrich in information, graphs are often noisy and incomplete. As a result, graph\ncompletion tasks, such as node classification or link prediction, have gained\nattention. On one hand, neural methods, such as graph neural networks, have\nproven to be robust tools for learning rich representations of noisy graphs. On\nthe other hand, symbolic methods enable exact reasoning on graphs.We propose\nKnowledge Enhanced Graph Neural Networks (KeGNN), a neuro-symbolic framework\nfor graph completion that combines both paradigms as it allows for the\nintegration of prior knowledge into a graph neural network model.Essentially,\nKeGNN consists of a graph neural network as a base upon which knowledge\nenhancement layers are stacked with the goal of refining predictions with\nrespect to prior knowledge.We instantiate KeGNN in conjunction with two\nstate-of-the-art graph neural networks, Graph Convolutional Networks and Graph\nAttention Networks, and evaluate KeGNN on multiple benchmark datasets for node\nclassification.",
          "link": "http://arxiv.org/abs/2303.15487",
          "publishedOn": "2023-09-02T00:40:02.176Z",
          "wordCount": null,
          "title": "Knowledge Enhanced Graph Neural Networks for Graph Completion. (arXiv:2303.15487v3 [cs.AI] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.14424",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xu_C/0/1/0/all/0/1\">Chen Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cheng_X/0/1/0/all/0/1\">Xiuyuan Cheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xie_Y/0/1/0/all/0/1\">Yao Xie</a>",
          "description": "Normalizing flow is a class of deep generative models for efficient sampling\nand density estimation. In practice, the flow often appears as a chain of\ninvertible neural network blocks; to facilitate training, existing works have\nregularized flow trajectories and designed special network architectures. The\ncurrent paper develops a neural ODE flow network inspired by the\nJordan-Kinderleherer-Otto (JKO) scheme, which allows efficient block-wise\ntraining of the residual blocks without sampling SDE trajectories or inner\nloops of score matching or variational learning. As the JKO scheme unfolds the\ndynamic of gradient flow, the proposed model naturally stacks residual network\nblocks one by one, reducing the memory load and difficulty in performing\nend-to-end deep flow network training. We also develop adaptive time\nreparameterization of the flow network with a progressive refinement of the\ntrajectory in probability space, which improves the model training efficiency\nand accuracy in practice. Using numerical experiments with synthetic and real\ndata, we show that the proposed JKO-iFlow model achieves similar or better\nperformance in generating new samples compared with the existing flow and\ndiffusion models at a significantly reduced computational and memory cost.",
          "link": "http://arxiv.org/abs/2212.14424",
          "publishedOn": "2023-09-02T00:40:02.170Z",
          "wordCount": null,
          "title": "Invertible normalizing flow neural networks by JKO scheme. (arXiv:2212.14424v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.04348",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Choudhary_A/0/1/0/all/0/1\">Anshul Choudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radhakrishnan_A/0/1/0/all/0/1\">Anil Radhakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindner_J/0/1/0/all/0/1\">John F. Lindner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_S/0/1/0/all/0/1\">Sudeshna Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ditto_W/0/1/0/all/0/1\">William L. Ditto</a>",
          "description": "Diversity conveys advantages in nature, yet homogeneous neurons typically\ncomprise the layers of artificial neural networks. Here we construct neural\nnetworks from neurons that learn their own activation functions, quickly\ndiversify, and subsequently outperform their homogeneous counterparts on image\nclassification and nonlinear regression tasks. Sub-networks instantiate the\nneurons, which meta-learn especially efficient sets of nonlinear responses.\nExamples include conventional neural networks classifying digits and\nforecasting a van der Pol oscillator and physics-informed Hamiltonian neural\nnetworks learning H\\'enon-Heiles stellar orbits and the swing of a video\nrecorded pendulum clock. Such \\textit{learned diversity} provides examples of\ndynamical systems selecting diversity over uniformity and elucidates the role\nof diversity in natural and artificial systems.",
          "link": "http://arxiv.org/abs/2204.04348",
          "publishedOn": "2023-09-02T00:40:02.169Z",
          "wordCount": null,
          "title": "Neuronal diversity can improve machine learning for physics and beyond. (arXiv:2204.04348v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.06677",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Han_Y/0/1/0/all/0/1\">Yena Han</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Poggio_T/0/1/0/all/0/1\">Tomaso Poggio</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Cheung_B/0/1/0/all/0/1\">Brian Cheung</a>",
          "description": "Artificial neural networks are being proposed as models of parts of the\nbrain. The networks are compared to recordings of biological neurons, and good\nperformance in reproducing neural responses is considered to support the\nmodel's validity. A key question is how much this system identification\napproach tells us about brain computation. Does it validate one model\narchitecture over another? We evaluate the most commonly used comparison\ntechniques, such as a linear encoding model and centered kernel alignment, to\ncorrectly identify a model by replacing brain recordings with known ground\ntruth models. System identification performance is quite variable; it also\ndepends significantly on factors independent of the ground truth architecture,\nsuch as stimuli images. In addition, we show the limitations of using\nfunctional similarity scores in identifying higher-level architectural motifs.",
          "link": "http://arxiv.org/abs/2302.06677",
          "publishedOn": "2023-09-02T00:40:02.169Z",
          "wordCount": null,
          "title": "System identification of neural systems: If we got it right, would we know?. (arXiv:2302.06677v2 [q-bio.NC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1\">Jacob Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huroyan_V/0/1/0/all/0/1\">Vahan Huroyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kobourov_S/0/1/0/all/0/1\">Stephen Kobourov</a>",
          "description": "We present a method for balancing between the Local and Global Structures\n(LGS) in graph embedding, via a tunable parameter. Some embedding methods aim\nto capture global structures, while others attempt to preserve local\nneighborhoods. Few methods attempt to do both, and it is not always possible to\ncapture well both local and global information in two dimensions, which is\nwhere most graph drawing live. The choice of using a local or a global\nembedding for visualization depends not only on the task but also on the\nstructure of the underlying data, which may not be known in advance. For a\ngiven graph, LGS aims to find a good balance between the local and global\nstructure to preserve. We evaluate the performance of LGS with synthetic and\nreal-world datasets and our results indicate that it is competitive with the\nstate-of-the-art methods, using established quality metrics such as stress and\nneighborhood preservation. We introduce a novel quality metric, cluster\ndistance preservation, to assess intermediate structure capture. All\nsource-code, datasets, experiments and analysis are available online.",
          "link": "http://arxiv.org/abs/2308.16403",
          "publishedOn": "2023-09-02T00:40:02.168Z",
          "wordCount": null,
          "title": "Balancing between the Local and Global Structures (LGS) in Graph Embedding. (arXiv:2308.16403v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16453",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Juncheng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1\">Qige Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jiang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sang_Y/0/1/0/all/0/1\">Yafei Sang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shuyuan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongzheng Zhang</a>",
          "description": "Mobile Internet has profoundly reshaped modern lifestyles in various aspects.\nEncrypted Traffic Classification (ETC) naturally plays a crucial role in\nmanaging mobile Internet, especially with the explosive growth of mobile apps\nusing encrypted communication. Despite some existing learning-based ETC methods\nshowing promising results, three-fold limitations still remain in real-world\nnetwork environments, 1) label bias caused by traffic class imbalance, 2)\ntraffic homogeneity caused by component sharing, and 3) training with reliance\non sufficient labeled traffic. None of the existing ETC methods can address all\nthese limitations. In this paper, we propose a novel Pre-trAining\nSemi-Supervised ETC framework, dubbed PASS. Our key insight is to resample the\noriginal train dataset and perform contrastive pre-training without using\nindividual app labels directly to avoid label bias issues caused by class\nimbalance, while obtaining a robust feature representation to differentiate\noverlapping homogeneous traffic by pulling positive traffic pairs closer and\npushing negative pairs away. Meanwhile, PASS designs a semi-supervised\noptimization strategy based on pseudo-label iteration and dynamic loss\nweighting algorithms in order to effectively utilize massive unlabeled traffic\ndata and alleviate manual train dataset annotation workload. PASS outperforms\nstate-of-the-art ETC methods and generic sampling approaches on four public\ndatasets with significant class imbalance and traffic homogeneity, remarkably\npushing the F1 of Cross-Platform215 with 1.31%, ISCX-17 with 9.12%.\nFurthermore, we validate the generality of the contrastive pre-training and\npseudo-label iteration components of PASS, which can adaptively benefit ETC\nmethods with diverse feature extractors.",
          "link": "http://arxiv.org/abs/2308.16453",
          "publishedOn": "2023-09-02T00:40:02.168Z",
          "wordCount": null,
          "title": "Listen to Minority: Encrypted Traffic Classification for Class Imbalance with Contrastive Pre-Training. (arXiv:2308.16453v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16456",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1\">Shuai Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1\">Zhen Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shao_Y/0/1/0/all/0/1\">Yuan-Hai Shao</a>",
          "description": "In this paper, we propose a new way of remembering by introducing a memory\ninfluence mechanism for the least squares support vector machine (LSSVM).\nWithout changing the equation constraints of the original LSSVM, this\nmechanism, allows an accurate partitioning of the training set without\noverfitting. The maximum memory impact model (MIMM) and the weighted impact\nmemory model (WIMM) are then proposed. It is demonstrated that these models can\nbe degraded to the LSSVM. Furthermore, we propose some different memory impact\nfunctions for the MIMM and WIMM. The experimental results show that that our\nMIMM and WIMM have better generalization performance compared to the LSSVM and\nsignificant advantage in time cost compared to other memory models.",
          "link": "http://arxiv.org/abs/2308.16456",
          "publishedOn": "2023-09-02T00:40:02.168Z",
          "wordCount": null,
          "title": "Least Squares Maximum and Weighted Generalization-Memorization Machines. (arXiv:2308.16456v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16468",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Saleh_Y/0/1/0/all/0/1\">Yahya Saleh</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Corral_A/0/1/0/all/0/1\">&#xc1;lvaro Fern&#xe1;ndez Corral</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Iske_A/0/1/0/all/0/1\">Armin Iske</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kupper_J/0/1/0/all/0/1\">Jochen K&#xfc;pper</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Yachmenev_A/0/1/0/all/0/1\">Andrey Yachmenev</a>",
          "description": "We present a new nonlinear variational framework for simultaneously computing\nground and excited states of quantum systems. Our approach is based on\napproximating wavefunctions in the linear span of basis functions that are\naugmented and optimized \\emph{via} composition with normalizing flows. The\naccuracy and efficiency of our approach are demonstrated in the calculations of\na large number of vibrational states of the triatomic H$_2$S molecule as well\nas ground and several excited electronic states of prototypical one-electron\nsystems including the hydrogen atom, the molecular hydrogen ion, and a carbon\natom in a single-active-electron approximation. The results demonstrate\nsignificant improvements in the accuracy of energy predictions and accelerated\nbasis-set convergence even when using normalizing flows with a small number of\nparameters. The present approach can be also seen as the optimization of a set\nof intrinsic coordinates that best capture the underlying physics within the\ngiven basis set.",
          "link": "http://arxiv.org/abs/2308.16468",
          "publishedOn": "2023-09-02T00:40:02.167Z",
          "wordCount": null,
          "title": "Computing excited states of molecules using normalizing flows. (arXiv:2308.16468v1 [physics.chem-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16259",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Hongshuo Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magar_R/0/1/0/all/0/1\">Rishikesh Magar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Changwen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farimani_A/0/1/0/all/0/1\">Amir Bariti Farimani</a>",
          "description": "Recently, the remarkable capabilities of large language models (LLMs) have\nbeen illustrated across a variety of research domains such as natural language\nprocessing, computer vision, and molecular modeling. We extend this paradigm by\nutilizing LLMs for material property prediction by introducing our model\nMaterials Informatics Transformer (MatInFormer). Specifically, we introduce a\nnovel approach that involves learning the grammar of crystallography through\nthe tokenization of pertinent space group information. We further illustrate\nthe adaptability of MatInFormer by incorporating task-specific data pertaining\nto Metal-Organic Frameworks (MOFs). Through attention visualization, we uncover\nthe key features that the model prioritizes during property prediction. The\neffectiveness of our proposed model is empirically validated across 14 distinct\ndatasets, hereby underscoring its potential for high throughput screening\nthrough accurate material property prediction.",
          "link": "http://arxiv.org/abs/2308.16259",
          "publishedOn": "2023-09-02T00:40:02.166Z",
          "wordCount": null,
          "title": "Materials Informatics Transformer: A Language Model for Interpretable Materials Properties Prediction. (arXiv:2308.16259v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16425",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1\">Zenan Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_Z/0/1/0/all/0/1\">Zhenyu Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_R/0/1/0/all/0/1\">Robert C. Qiu</a>",
          "description": "Implicit neural networks have demonstrated remarkable success in various\ntasks. However, there is a lack of theoretical analysis of the connections and\ndifferences between implicit and explicit networks. In this paper, we study\nhigh-dimensional implicit neural networks and provide the high dimensional\nequivalents for the corresponding conjugate kernels and neural tangent kernels.\nBuilt upon this, we establish the equivalence between implicit and explicit\nnetworks in high dimensions.",
          "link": "http://arxiv.org/abs/2308.16425",
          "publishedOn": "2023-09-02T00:40:02.166Z",
          "wordCount": null,
          "title": "On the Equivalence between Implicit and Explicit Neural Networks: A High-dimensional Viewpoint. (arXiv:2308.16425v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16336",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cagatan_O/0/1/0/all/0/1\">Omer Veysel Cagatan</a>",
          "description": "We present ToddlerBERTa, a BabyBERTa-like language model, exploring its\ncapabilities through five different models with varied hyperparameters.\nEvaluating on BLiMP, SuperGLUE, MSGS, and a Supplement benchmark from the\nBabyLM challenge, we find that smaller models can excel in specific tasks,\nwhile larger models perform well with substantial data. Despite training on a\nsmaller dataset, ToddlerBERTa demonstrates commendable performance, rivalling\nthe state-of-the-art RoBERTa-base. The model showcases robust language\nunderstanding, even with single-sentence pretraining, and competes with\nbaselines that leverage broader contextual information. Our work provides\ninsights into hyperparameter choices, and data utilization, contributing to the\nadvancement of language models.",
          "link": "http://arxiv.org/abs/2308.16336",
          "publishedOn": "2023-09-02T00:40:02.158Z",
          "wordCount": null,
          "title": "ToddlerBERTa: Exploiting BabyBERTa for Grammar Learning and Language Understanding. (arXiv:2308.16336v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16362",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Zhu_D/0/1/0/all/0/1\">Daoli Zhu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhao_L/0/1/0/all/0/1\">Lei Zhao</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhang_S/0/1/0/all/0/1\">Shuzhong Zhang</a>",
          "description": "In this paper we propose a proximal subgradient method (Prox-SubGrad) for\nsolving nonconvex and nonsmooth optimization problems without assuming\nLipschitz continuity conditions. A number of subgradient upper bounds and their\nrelationships are presented. By means of these upper bounding conditions, we\nestablish some uniform recursive relations for the Moreau envelopes for weakly\nconvex optimization. This uniform scheme simplifies and unifies the proof\nschemes to establish rate of convergence for Prox-SubGrad without assuming\nLipschitz continuity. We present a novel convergence analysis in this context.\nFurthermore, we propose some new stochastic subgradient upper bounding\nconditions and establish convergence and iteration complexity rates for the\nstochastic subgradient method (Sto-SubGrad) to solve non-Lipschitz and\nnonsmooth stochastic optimization problems. In particular, for both\ndeterministic and stochastic subgradient methods on weakly convex optimization\nproblems without Lipschitz continuity, under any of the subgradient upper\nbounding conditions to be introduced in the paper, we show that $O(1/\\sqrt{T})$\nconvergence rate holds in terms of the square of gradient of the Moreau\nenvelope function, which further improves to be $O(1/{T})$ if, in addition, the\nuniform KL condition with exponent $1/2$ holds.",
          "link": "http://arxiv.org/abs/2308.16362",
          "publishedOn": "2023-09-02T00:40:02.158Z",
          "wordCount": null,
          "title": "A Unified Analysis for the Subgradient Methods Minimizing Composite Nonconvex, Nonsmooth and Non-Lipschitz Functions. (arXiv:2308.16362v1 [math.OC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16454",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suzuki_S/0/1/0/all/0/1\">Satoshi Suzuki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamaguchi_S/0/1/0/all/0/1\">Shin&#x27;ya Yamaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takeda_S/0/1/0/all/0/1\">Shoichiro Takeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanai_S/0/1/0/all/0/1\">Sekitoshi Kanai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Makishima_N/0/1/0/all/0/1\">Naoki Makishima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ando_A/0/1/0/all/0/1\">Atsushi Ando</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masumura_R/0/1/0/all/0/1\">Ryo Masumura</a>",
          "description": "This paper addresses the tradeoff between standard accuracy on clean examples\nand robustness against adversarial examples in deep neural networks (DNNs).\nAlthough adversarial training (AT) improves robustness, it degrades the\nstandard accuracy, thus yielding the tradeoff. To mitigate this tradeoff, we\npropose a novel AT method called ARREST, which comprises three components: (i)\nadversarial finetuning (AFT), (ii) representation-guided knowledge distillation\n(RGKD), and (iii) noisy replay (NR). AFT trains a DNN on adversarial examples\nby initializing its parameters with a DNN that is standardly pretrained on\nclean examples. RGKD and NR respectively entail a regularization term and an\nalgorithm to preserve latent representations of clean examples during AFT. RGKD\npenalizes the distance between the representations of the standardly pretrained\nand AFT DNNs. NR switches input adversarial examples to nonadversarial ones\nwhen the representation changes significantly during AFT. By combining these\ncomponents, ARREST achieves both high standard accuracy and robustness.\nExperimental results demonstrate that ARREST mitigates the tradeoff more\neffectively than previous AT-based methods do.",
          "link": "http://arxiv.org/abs/2308.16454",
          "publishedOn": "2023-09-02T00:40:02.158Z",
          "wordCount": null,
          "title": "Adversarial Finetuning with Latent Representation Constraint to Mitigate Accuracy-Robustness Tradeoff. (arXiv:2308.16454v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16316",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1\">Tanujit Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+S_U/0/1/0/all/0/1\">Ujjwal Reddy K S</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naik_S/0/1/0/all/0/1\">Shraddha M. Naik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panja_M/0/1/0/all/0/1\">Madhurima Panja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manvitha_B/0/1/0/all/0/1\">Bayapureddy Manvitha</a>",
          "description": "Since their inception in 2014, Generative Adversarial Networks (GANs) have\nrapidly emerged as powerful tools for generating realistic and diverse data\nacross various domains, including computer vision and other applied areas.\nConsisting of a discriminative network and a generative network engaged in a\nMinimax game, GANs have revolutionized the field of generative modeling. In\nFebruary 2018, GAN secured the leading spot on the ``Top Ten Global\nBreakthrough Technologies List'' issued by the Massachusetts Science and\nTechnology Review. Over the years, numerous advancements have been proposed,\nleading to a rich array of GAN variants, such as conditional GAN, Wasserstein\nGAN, CycleGAN, and StyleGAN, among many others. This survey aims to provide a\ngeneral overview of GANs, summarizing the latent architecture, validation\nmetrics, and application areas of the most widely recognized variants. We also\ndelve into recent theoretical developments, exploring the profound connection\nbetween the adversarial principle underlying GAN and Jensen-Shannon divergence,\nwhile discussing the optimality characteristics of the GAN framework. The\nefficiency of GAN variants and their model architectures will be evaluated\nalong with training obstacles as well as training solutions. In addition, a\ndetailed discussion will be provided, examining the integration of GANs with\nnewly developed deep learning frameworks such as Transformers, Physics-Informed\nNeural Networks, Large Language models, and Diffusion models. Finally, we\nreveal several issues as well as future research outlines in this field.",
          "link": "http://arxiv.org/abs/2308.16316",
          "publishedOn": "2023-09-02T00:40:02.157Z",
          "wordCount": null,
          "title": "Ten Years of Generative Adversarial Nets (GANs): A survey of the state-of-the-art. (arXiv:2308.16316v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huan_Z/0/1/0/all/0/1\">Zhaoxin Huan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_K/0/1/0/all/0/1\">Ke Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Ang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaolu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_X/0/1/0/all/0/1\">Xu Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Liang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mo_L/0/1/0/all/0/1\">Linjian Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jinjie Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhongyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_W/0/1/0/all/0/1\">Wenliang Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guannan Zhang</a>",
          "description": "Click-through rate (CTR) prediction is a crucial issue in recommendation\nsystems. There has been an emergence of various public CTR datasets. However,\nexisting datasets primarily suffer from the following limitations. Firstly,\nusers generally click different types of items from multiple scenarios, and\nmodeling from multiple scenarios can provide a more comprehensive understanding\nof users. Existing datasets only include data for the same type of items from a\nsingle scenario. Secondly, multi-modal features are essential in multi-scenario\nprediction as they address the issue of inconsistent ID encoding between\ndifferent scenarios. The existing datasets are based on ID features and lack\nmulti-modal features. Third, a large-scale dataset can provide a more reliable\nevaluation of models, fully reflecting the performance differences between\nmodels. The scale of existing datasets is around 100 million, which is\nrelatively small compared to the real-world CTR prediction. To address these\nlimitations, we propose AntM$^{2}$C, a Multi-Scenario Multi-Modal CTR dataset\nbased on industrial data from Alipay. Specifically, AntM$^{2}$C provides the\nfollowing advantages: 1) It covers CTR data of 5 different types of items,\nproviding insights into the preferences of users for different items, including\nadvertisements, vouchers, mini-programs, contents, and videos. 2) Apart from\nID-based features, AntM$^{2}$C also provides 2 multi-modal features, raw text\nand image features, which can effectively establish connections between items\nwith different IDs. 3) AntM$^{2}$C provides 1 billion CTR data with 200\nfeatures, including 200 million users and 6 million items. It is currently the\nlargest-scale CTR dataset available. Based on AntM$^{2}$C, we construct several\ntypical CTR tasks and provide comparisons with baseline methods. The dataset\nhomepage is available at https://www.atecup.cn/home.",
          "link": "http://arxiv.org/abs/2308.16437",
          "publishedOn": "2023-09-02T00:40:02.157Z",
          "wordCount": null,
          "title": "AntM$^{2}$C: A Large Scale Dataset For Multi-Scenario Multi-Modal CTR Prediction. (arXiv:2308.16437v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16271",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_T/0/1/0/all/0/1\">Tianzhe Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_S/0/1/0/all/0/1\">Shengbang Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Ziyang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pai_D/0/1/0/all/0/1\">Druv Pai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buchanan_S/0/1/0/all/0/1\">Sam Buchanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi Ma</a>",
          "description": "Transformer-like models for vision tasks have recently proven effective for a\nwide range of downstream applications such as segmentation and detection.\nPrevious works have shown that segmentation properties emerge in vision\ntransformers (ViTs) trained using self-supervised methods such as DINO, but not\nin those trained on supervised classification tasks. In this study, we probe\nwhether segmentation emerges in transformer-based models solely as a result of\nintricate self-supervised learning mechanisms, or if the same emergence can be\nachieved under much broader conditions through proper design of the model\narchitecture. Through extensive experimental results, we demonstrate that when\nemploying a white-box transformer-like architecture known as CRATE, whose\ndesign explicitly models and pursues low-dimensional structures in the data\ndistribution, segmentation properties, at both the whole and parts levels,\nalready emerge with a minimalistic supervised training recipe. Layer-wise\nfiner-grained analysis reveals that the emergent properties strongly\ncorroborate the designed mathematical functions of the white-box network. Our\nresults suggest a path to design white-box foundation models that are\nsimultaneously highly performant and mathematically fully interpretable. Code\nis at \\url{https://github.com/Ma-Lab-Berkeley/CRATE}.",
          "link": "http://arxiv.org/abs/2308.16271",
          "publishedOn": "2023-09-02T00:40:02.156Z",
          "wordCount": null,
          "title": "Emergence of Segmentation with Minimalistic White-Box Transformers. (arXiv:2308.16271v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16207",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yi Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Su Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1\">Chuangao Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1\">Cuntai Guan</a>",
          "description": "Emotion recognition using electroencephalogram (EEG) mainly has two\nscenarios: classification of the discrete labels and regression of the\ncontinuously tagged labels. Although many algorithms were proposed for\nclassification tasks, there are only a few methods for regression tasks. For\nemotion regression, the label is continuous in time. A natural method is to\nlearn the temporal dynamic patterns. In previous studies, long short-term\nmemory (LSTM) and temporal convolutional neural networks (TCN) were utilized to\nlearn the temporal contextual information from feature vectors of EEG. However,\nthe spatial patterns of EEG were not effectively extracted. To enable the\nspatial learning ability of TCN towards better regression and classification\nperformances, we propose a novel unified model, named MASA-TCN, for EEG emotion\nregression and classification tasks. The space-aware temporal layer enables TCN\nto additionally learn from spatial relations among EEG electrodes. Besides, a\nnovel multi-anchor block with attentive fusion is proposed to learn dynamic\ntemporal dependencies. Experiments on two publicly available datasets show\nMASA-TCN achieves higher results than the state-of-the-art methods for both EEG\nemotion regression and classification tasks. The code is available at\nhttps://github.com/yi-ding-cs/MASA-TCN.",
          "link": "http://arxiv.org/abs/2308.16207",
          "publishedOn": "2023-09-02T00:40:02.155Z",
          "wordCount": null,
          "title": "MASA-TCN: Multi-anchor Space-aware Temporal Convolutional Neural Networks for Continuous and Discrete EEG Emotion Recognition. (arXiv:2308.16207v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16375",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yuying Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhaoqing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xueqi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kotevska_O/0/1/0/all/0/1\">Olivera Kotevska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Derr_T/0/1/0/all/0/1\">Tyler Derr</a>",
          "description": "Graph Neural Networks (GNNs) have gained significant attention owing to their\nability to handle graph-structured data and the improvement in practical\napplications. However, many of these models prioritize high utility\nperformance, such as accuracy, with a lack of privacy consideration, which is a\nmajor concern in modern society where privacy attacks are rampant. To address\nthis issue, researchers have started to develop privacy-preserving GNNs.\nDespite this progress, there is a lack of a comprehensive overview of the\nattacks and the techniques for preserving privacy in the graph domain. In this\nsurvey, we aim to address this gap by summarizing the attacks on graph data\naccording to the targeted information, categorizing the privacy preservation\ntechniques in GNNs, and reviewing the datasets and applications that could be\nused for analyzing/solving privacy issues in GNNs. We also outline potential\ndirections for future research in order to build better privacy-preserving\nGNNs.",
          "link": "http://arxiv.org/abs/2308.16375",
          "publishedOn": "2023-09-02T00:40:02.154Z",
          "wordCount": null,
          "title": "A Survey on Privacy in Graph Neural Networks: Attacks, Preservation, and Applications. (arXiv:2308.16375v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.02064",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Javanmard_A/0/1/0/all/0/1\">Adel Javanmard</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mehrabi_M/0/1/0/all/0/1\">Mohammad Mehrabi</a>",
          "description": "Performance of classifiers is often measured in terms of average accuracy on\ntest data. Despite being a standard measure, average accuracy fails in\ncharacterizing the fit of the model to the underlying conditional law of labels\ngiven the features vector ($Y|X$), e.g. due to model misspecification, over\nfitting, and high-dimensionality. In this paper, we consider the fundamental\nproblem of assessing the goodness-of-fit for a general binary classifier. Our\nframework does not make any parametric assumption on the conditional law $Y|X$,\nand treats that as a black box oracle model which can be accessed only through\nqueries. We formulate the goodness-of-fit assessment problem as a tolerance\nhypothesis testing of the form \\[ H_0: \\mathbb{E}\\Big[D_f\\Big({\\sf\nBern}(\\eta(X))\\|{\\sf Bern}(\\hat{\\eta}(X))\\Big)\\Big]\\leq \\tau\\,, \\] where $D_f$\nrepresents an $f$-divergence function, and $\\eta(x)$, $\\hat{\\eta}(x)$\nrespectively denote the true and an estimate likelihood for a feature vector\n$x$ admitting a positive label. We propose a novel test, called \\grasp for\ntesting $H_0$, which works in finite sample settings, no matter the features\n(distribution-free). We also propose model-X \\grasp designed for model-X\nsettings where the joint distribution of the features vector is known. Model-X\n\\grasp uses this distributional information to achieve better power. We\nevaluate the performance of our tests through extensive numerical experiments.",
          "link": "http://arxiv.org/abs/2209.02064",
          "publishedOn": "2023-09-02T00:40:02.154Z",
          "wordCount": null,
          "title": "GRASP: A Goodness-of-Fit Test for Classification Learning. (arXiv:2209.02064v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16198",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Galliera_R/0/1/0/all/0/1\">Raffaele Galliera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venable_K/0/1/0/all/0/1\">Kristen Brent Venable</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bassani_M/0/1/0/all/0/1\">Matteo Bassani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suri_N/0/1/0/all/0/1\">Niranjan Suri</a>",
          "description": "In modern communication systems, efficient and reliable information\ndissemination is crucial for supporting critical operations across domains like\ndisaster response, autonomous vehicles, and sensor networks. This paper\nintroduces a Multi-Agent Reinforcement Learning (MARL) approach as a\nsignificant step forward in achieving more decentralized, efficient, and\ncollaborative solutions. We propose a Decentralized-POMDP formulation for\ninformation dissemination, empowering each agent to independently decide on\nmessage forwarding. This constitutes a significant paradigm shift from\ntraditional heuristics based on Multi-Point Relay (MPR) selection. Our approach\nharnesses Graph Convolutional Reinforcement Learning, employing Graph Attention\nNetworks (GAT) with dynamic attention to capture essential network features. We\npropose two approaches, L-DGN and HL-DGN, which differ in the information that\nis exchanged among agents. We evaluate the performance of our decentralized\napproaches, by comparing them with a widely-used MPR heuristic, and we show\nthat our trained policies are able to efficiently cover the network while\nbypassing the MPR set selection process. Our approach promises a first step\ntoward bolstering the resilience of real-world broadcast communication\ninfrastructures via learned, collaborative information dissemination.",
          "link": "http://arxiv.org/abs/2308.16198",
          "publishedOn": "2023-09-02T00:40:02.149Z",
          "wordCount": null,
          "title": "Learning Collaborative Information Dissemination with Graph-based Multi-Agent Reinforcement Learning. (arXiv:2308.16198v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16212",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Igashov_I/0/1/0/all/0/1\">Ilia Igashov</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Schneuing_A/0/1/0/all/0/1\">Arne Schneuing</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Segler_M/0/1/0/all/0/1\">Marwin Segler</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Bronstein_M/0/1/0/all/0/1\">Michael Bronstein</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Correia_B/0/1/0/all/0/1\">Bruno Correia</a>",
          "description": "Retrosynthesis planning is a fundamental challenge in chemistry which aims at\ndesigning reaction pathways from commercially available starting materials to a\ntarget molecule. Each step in multi-step retrosynthesis planning requires\naccurate prediction of possible precursor molecules given the target molecule\nand confidence estimates to guide heuristic search algorithms. We model\nsingle-step retrosynthesis planning as a distribution learning problem in a\ndiscrete state space. First, we introduce the Markov Bridge Model, a generative\nframework aimed to approximate the dependency between two intractable discrete\ndistributions accessible via a finite sample of coupled data points. Our\nframework is based on the concept of a Markov bridge, a Markov process pinned\nat its endpoints. Unlike diffusion-based methods, our Markov Bridge Model does\nnot need a tractable noise distribution as a sampling proxy and directly\noperates on the input product molecules as samples from the intractable prior\ndistribution. We then address the retrosynthesis planning problem with our\nnovel framework and introduce RetroBridge, a template-free retrosynthesis\nmodeling approach that achieves state-of-the-art results on standard evaluation\nbenchmarks.",
          "link": "http://arxiv.org/abs/2308.16212",
          "publishedOn": "2023-09-02T00:40:02.149Z",
          "wordCount": null,
          "title": "RetroBridge: Modeling Retrosynthesis with Markov Bridges. (arXiv:2308.16212v1 [q-bio.QM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16215",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Reich_C/0/1/0/all/0/1\">Christoph Reich</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Debnath_B/0/1/0/all/0/1\">Biplob Debnath</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Patel_D/0/1/0/all/0/1\">Deep Patel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Prangemeier_T/0/1/0/all/0/1\">Tim Prangemeier</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chakradhar_S/0/1/0/all/0/1\">Srimat Chakradhar</a>",
          "description": "Lossy video compression is commonly used when transmitting and storing video\ndata. Unified video codecs (e.g., H.264 or H.265) remain the \\emph{de facto}\nstandard, despite the availability of advanced (neural) compression approaches.\nTransmitting videos in the face of dynamic network bandwidth conditions\nrequires video codecs to adapt to vastly different compression strengths. Rate\ncontrol modules augment the codec's compression such that bandwidth constraints\nare satisfied and video distortion is minimized. While, both standard video\ncodes and their rate control modules are developed to minimize video distortion\nw.r.t. human quality assessment, preserving the downstream performance of deep\nvision models is not considered. In this paper, we present the first end-to-end\nlearnable deep video codec control considering both bandwidth constraints and\ndownstream vision performance, while not breaking existing standardization. We\ndemonstrate for two common vision tasks (semantic segmentation and optical flow\nestimation) and on two different datasets that our deep codec control better\npreserves downstream performance than using 2-pass average bit rate control\nwhile meeting dynamic bandwidth constraints and adhering to standardizations.",
          "link": "http://arxiv.org/abs/2308.16215",
          "publishedOn": "2023-09-02T00:40:02.146Z",
          "wordCount": null,
          "title": "Deep Video Codec Control. (arXiv:2308.16215v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16272",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Valenzuela_N/0/1/0/all/0/1\">Nicol&#xe1;s Valenzuela</a>",
          "description": "We consider the fractional elliptic problem with Dirichlet boundary\nconditions on a bounded and convex domain $D$ of $\\mathbb{R}^d$, with $d \\geq\n2$. In this paper, we perform a stochastic gradient descent algorithm that\napproximates the solution of the fractional problem via Deep Neural Networks.\nAdditionally, we provide four numerical examples to test the efficiency of the\nalgorithm, and each example will be studied for many values of $\\alpha \\in\n(1,2)$ and $d \\geq 2$.",
          "link": "http://arxiv.org/abs/2308.16272",
          "publishedOn": "2023-09-02T00:40:02.144Z",
          "wordCount": null,
          "title": "A numerical approach for the fractional Laplacian via deep neural networks. (arXiv:2308.16272v1 [math.AP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.00049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geisler_S/0/1/0/all/0/1\">Simon Geisler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yujia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mankowitz_D/0/1/0/all/0/1\">Daniel Mankowitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cemgil_A/0/1/0/all/0/1\">Ali Taylan Cemgil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1\">Stephan G&#xfc;nnemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paduraru_C/0/1/0/all/0/1\">Cosmin Paduraru</a>",
          "description": "Transformers were originally proposed as a sequence-to-sequence model for\ntext but have become vital for a wide range of modalities, including images,\naudio, video, and undirected graphs. However, transformers for directed graphs\nare a surprisingly underexplored topic, despite their applicability to\nubiquitous domains, including source code and logic circuits. In this work, we\npropose two direction- and structure-aware positional encodings for directed\ngraphs: (1) the eigenvectors of the Magnetic Laplacian - a direction-aware\ngeneralization of the combinatorial Laplacian; (2) directional random walk\nencodings. Empirically, we show that the extra directionality information is\nuseful in various downstream tasks, including correctness testing of sorting\nnetworks and source code understanding. Together with a data-flow-centric graph\nconstruction, our model outperforms the prior state of the art on the Open\nGraph Benchmark Code2 relatively by 14.7%.",
          "link": "http://arxiv.org/abs/2302.00049",
          "publishedOn": "2023-09-02T00:40:02.144Z",
          "wordCount": null,
          "title": "Transformers Meet Directed Graphs. (arXiv:2302.00049v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16904",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Bergou_E/0/1/0/all/0/1\">El Houcine Bergou</a>, <a href=\"http://arxiv.org/find/math/1/au:+Boucherouite_S/0/1/0/all/0/1\">Soumia Boucherouite</a>, <a href=\"http://arxiv.org/find/math/1/au:+Dutta_A/0/1/0/all/0/1\">Aritra Dutta</a>, <a href=\"http://arxiv.org/find/math/1/au:+Li_X/0/1/0/all/0/1\">Xin Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Ma_A/0/1/0/all/0/1\">Anna Ma</a>",
          "description": "Large-scale linear systems, $Ax=b$, frequently arise in practice and demand\neffective iterative solvers. Often, these systems are noisy due to operational\nerrors or faulty data-collection processes. In the past decade, the randomized\nKaczmarz (RK) algorithm has been studied extensively as an efficient iterative\nsolver for such systems. However, the convergence study of RK in the noisy\nregime is limited and considers measurement noise in the right-hand side\nvector, $b$. Unfortunately, in practice, that is not always the case; the\ncoefficient matrix $A$ can also be noisy. In this paper, we analyze the\nconvergence of RK for noisy linear systems when the coefficient matrix, $A$, is\ncorrupted with both additive and multiplicative noise, along with the noisy\nvector, $b$. In our analyses, the quantity $\\tilde R=\\| \\tilde A^{\\dagger}\n\\|_2^2 \\|\\tilde A \\|_F^2$ influences the convergence of RK, where $\\tilde A$\nrepresents a noisy version of $A$. We claim that our analysis is robust and\nrealistically applicable, as we do not require information about the noiseless\ncoefficient matrix, $A$, and considering different conditions on noise, we can\ncontrol the convergence of RK. We substantiate our theoretical findings by\nperforming comprehensive numerical experiments.",
          "link": "http://arxiv.org/abs/2308.16904",
          "publishedOn": "2023-09-02T00:40:02.131Z",
          "wordCount": null,
          "title": "A Note on Randomized Kaczmarz Algorithm for Solving Doubly-Noisy Linear Systems. (arXiv:2308.16904v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2201.12994",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cui_G/0/1/0/all/0/1\">Guanyu Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhewei Wei</a>",
          "description": "Graph Neural Networks (GNNs) have emerged as a prominent research topic in\nthe field of machine learning. Existing GNN models are commonly categorized\ninto two types: spectral GNNs, which are designed based on polynomial graph\nfilters, and spatial GNNs, which utilize a message-passing scheme as the\nfoundation of the model. For the expressive power and universality of spectral\nGNNs, a natural approach is to improve the design of basis functions for better\napproximation ability. As for spatial GNNs, models like Graph Isomorphism\nNetworks (GIN) analyze their expressive power based on Graph Isomorphism Tests.\nRecently, there have been attempts to establish connections between spatial\nGNNs and geometric concepts like curvature and cellular sheaves, as well as\nphysical phenomena like oscillators. However, despite the recent progress,\nthere is still a lack of comprehensive analysis regarding the universality of\nspatial GNNs from the perspectives of geometry and physics. In this paper, we\npropose MetricGNN (MGNN), a spatial GNN model inspired by the\ncongruent-insensitivity property of classifiers in the classification phase of\nGNNs. We demonstrate that a GNN model is universal in the spatial domain if it\ncan generate embedding matrices that are congruent to any given embedding\nmatrix. This property is closely related to the Distance Geometry Problem\n(DGP). Since DGP is an NP-Hard combinatorial optimization problem, we propose\noptimizing an energy function derived from spring networks and the\nMulti-Dimensional Scaling (MDS) problem. This approach also allows our model to\nhandle both homophilic and heterophilic graphs. Finally, we propose employing\nthe iteration method to optimize our energy function. We extensively evaluate\nthe effectiveness of our model through experiments conducted on both synthetic\nand real-world datasets. Our code is available at:\nhttps://github.com/GuanyuCui/MGNN.",
          "link": "http://arxiv.org/abs/2201.12994",
          "publishedOn": "2023-09-02T00:40:02.131Z",
          "wordCount": null,
          "title": "MGNN: Graph Neural Networks Inspired by Distance Geometry Problem. (arXiv:2201.12994v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16789",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhao_Q/0/1/0/all/0/1\">Qiyang Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zou_H/0/1/0/all/0/1\">Hang Zou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bennis_M/0/1/0/all/0/1\">Mehdi Bennis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Debbah_M/0/1/0/all/0/1\">Merouane Debbah</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Almazrouei_E/0/1/0/all/0/1\">Ebtesam Almazrouei</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bader_F/0/1/0/all/0/1\">Faouzi Bader</a>",
          "description": "In this work, we study the problem of semantic communication and inference,\nin which a student agent (i.e. mobile device) queries a teacher agent (i.e.\ncloud sever) to generate higher-order data semantics living in a simplicial\ncomplex. Specifically, the teacher first maps its data into a k-order\nsimplicial complex and learns its high-order correlations. For effective\ncommunication and inference, the teacher seeks minimally sufficient and\ninvariant semantic structures prior to conveying information. These minimal\nsimplicial structures are found via judiciously removing simplices selected by\nthe Hodge Laplacians without compromising the inference query accuracy.\nSubsequently, the student locally runs its own set of queries based on a masked\nsimplicial convolutional autoencoder (SCAE) leveraging both local and remote\nteacher's knowledge. Numerical results corroborate the effectiveness of the\nproposed approach in terms of improving inference query accuracy under\ndifferent channel conditions and simplicial structures. Experiments on a\ncoauthorship dataset show that removing simplices by ranking the Laplacian\nvalues yields a 85% reduction in payload size without sacrificing accuracy.\nJoint semantic communication and inference by masked SCAE improves query\naccuracy by 25% compared to local student based query and 15% compared to\nremote teacher based query. Finally, incorporating channel semantics is shown\nto effectively improve inference accuracy, notably at low SNR values.",
          "link": "http://arxiv.org/abs/2308.16789",
          "publishedOn": "2023-09-02T00:40:02.122Z",
          "wordCount": null,
          "title": "Joint Semantic-Native Communication and Inference via Minimal Simplicial Structures. (arXiv:2308.16789v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16818",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weijia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Le Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jindong Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingbo Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_Y/0/1/0/all/0/1\">Yu Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Hui Xiong</a>",
          "description": "Accurate traffic forecasting at intersections governed by intelligent traffic\nsignals is critical for the advancement of an effective intelligent traffic\nsignal control system. However, due to the irregular traffic time series\nproduced by intelligent intersections, the traffic forecasting task becomes\nmuch more intractable and imposes three major new challenges: 1) asynchronous\nspatial dependency, 2) irregular temporal dependency among traffic data, and 3)\nvariable-length sequence to be predicted, which severely impede the performance\nof current traffic forecasting methods. To this end, we propose an Asynchronous\nSpatio-tEmporal graph convolutional nEtwoRk (ASeer) to predict the traffic\nstates of the lanes entering intelligent intersections in a future time window.\nSpecifically, by linking lanes via a traffic diffusion graph, we first propose\nan Asynchronous Graph Diffusion Network to model the asynchronous spatial\ndependency between the time-misaligned traffic state measurements of lanes.\nAfter that, to capture the temporal dependency within irregular traffic state\nsequence, a learnable personalized time encoding is devised to embed the\ncontinuous time for each lane. Then we propose a Transformable Time-aware\nConvolution Network that learns meta-filters to derive time-aware convolution\nfilters with transformable filter sizes for efficient temporal convolution on\nthe irregular sequence. Furthermore, a Semi-Autoregressive Prediction Network\nconsisting of a state evolution unit and a semiautoregressive predictor is\ndesigned to effectively and efficiently predict variable-length traffic state\nsequences. Extensive experiments on two real-world datasets demonstrate the\neffectiveness of ASeer in six metrics.",
          "link": "http://arxiv.org/abs/2308.16818",
          "publishedOn": "2023-09-02T00:40:02.122Z",
          "wordCount": null,
          "title": "Irregular Traffic Time Series Forecasting Based on Asynchronous Spatio-Temporal Graph Convolutional Network. (arXiv:2308.16818v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16534",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scassola_D/0/1/0/all/0/1\">Davide Scassola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saccani_S/0/1/0/all/0/1\">Sebastiano Saccani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carbone_G/0/1/0/all/0/1\">Ginevra Carbone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bortolussi_L/0/1/0/all/0/1\">Luca Bortolussi</a>",
          "description": "Score-based and diffusion models have emerged as effective approaches for\nboth conditional and unconditional generation. Still conditional generation is\nbased on either a specific training of a conditional model or classifier\nguidance, which requires training a noise-dependent classifier, even when the\nclassifier for uncorrupted data is given. We propose an approach to sample from\nunconditional score-based generative models enforcing arbitrary logical\nconstraints, without any additional training. Firstly, we show how to\nmanipulate the learned score in order to sample from an un-normalized\ndistribution conditional on a user-defined constraint. Then, we define a\nflexible and numerically stable neuro-symbolic framework for encoding soft\nlogical constraints. Combining these two ingredients we obtain a general, but\napproximate, conditional sampling algorithm. We further developed effective\nheuristics aimed at improving the approximation. Finally, we show the\neffectiveness of our approach for various types of constraints and data:\ntabular data, images and time series.",
          "link": "http://arxiv.org/abs/2308.16534",
          "publishedOn": "2023-09-02T00:40:02.072Z",
          "wordCount": null,
          "title": "Conditioning Score-Based Generative Models by Neuro-Symbolic Constraints. (arXiv:2308.16534v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16718",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yu Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Dong-Dong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1\">Xin Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min-Ling Zhang</a>",
          "description": "Partial Label Learning (PLL) is a type of weakly supervised learning where\neach training instance is assigned a set of candidate labels, but only one\nlabel is the ground-truth. However, this idealistic assumption may not always\nhold due to potential annotation inaccuracies, meaning the ground-truth may not\nbe present in the candidate label set. This is known as Unreliable Partial\nLabel Learning (UPLL) that introduces an additional complexity due to the\ninherent unreliability and ambiguity of partial labels, often resulting in a\nsub-optimal performance with existing methods. To address this challenge, we\npropose the Unreliability-Robust Representation Learning framework (URRL) that\nleverages unreliability-robust contrastive learning to help the model fortify\nagainst unreliable partial labels effectively. Concurrently, we propose a dual\nstrategy that combines KNN-based candidate label set correction and\nconsistency-regularization-based label disambiguation to refine label quality\nand enhance the ability of representation learning within the URRL framework.\nExtensive experiments demonstrate that the proposed method outperforms\nstate-of-the-art PLL methods on various datasets with diverse degrees of\nunreliability and ambiguity. Furthermore, we provide a theoretical analysis of\nour approach from the perspective of the expectation maximization (EM)\nalgorithm. Upon acceptance, we pledge to make the code publicly accessible.",
          "link": "http://arxiv.org/abs/2308.16718",
          "publishedOn": "2023-09-02T00:40:02.072Z",
          "wordCount": null,
          "title": "Robust Representation Learning for Unreliable Partial Label Learning. (arXiv:2308.16718v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16678",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Miccini_R/0/1/0/all/0/1\">Riccardo Miccini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zniber_A/0/1/0/all/0/1\">Alaa Zniber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laroche_C/0/1/0/all/0/1\">Cl&#xe9;ment Laroche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piechowiak_T/0/1/0/all/0/1\">Tobias Piechowiak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schoeberl_M/0/1/0/all/0/1\">Martin Schoeberl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pezzarossa_L/0/1/0/all/0/1\">Luca Pezzarossa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karrakchou_O/0/1/0/all/0/1\">Ouassim Karrakchou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sparso_J/0/1/0/all/0/1\">Jens Spars&#xf8;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghogho_M/0/1/0/all/0/1\">Mounir Ghogho</a>",
          "description": "Although deep learning has made strides in the field of deep noise\nsuppression, leveraging deep architectures on resource-constrained devices\nstill proved challenging. Therefore, we present an early-exiting model based on\nnsNet2 that provides several levels of accuracy and resource savings by halting\ncomputations at different stages. Moreover, we adapt the original architecture\nby splitting the information flow to take into account the injected dynamism.\nWe show the trade-offs between performance and computational complexity based\non established metrics.",
          "link": "http://arxiv.org/abs/2308.16678",
          "publishedOn": "2023-09-02T00:40:02.064Z",
          "wordCount": null,
          "title": "Dynamic nsNet2: Efficient Deep Noise Suppression with Early Exiting. (arXiv:2308.16678v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16516",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sanders_C/0/1/0/all/0/1\">Cedric Sanders</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_A/0/1/0/all/0/1\">Andreas Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liebig_T/0/1/0/all/0/1\">Thomas Liebig</a>",
          "description": "Over-squashing and over-smoothing are two critical issues, that limit the\ncapabilities of graph neural networks (GNNs). While over-smoothing eliminates\nthe differences between nodes making them indistinguishable, over-squashing\nrefers to the inability of GNNs to propagate information over long distances,\nas exponentially many node states are squashed into fixed-size representations.\nBoth phenomena share similar causes, as both are largely induced by the graph\ntopology. To mitigate these problems in graph classification tasks, we propose\nCurvPool, a novel pooling method. CurvPool exploits the notion of curvature of\na graph to adaptively identify structures responsible for both over-smoothing\nand over-squashing. By clustering nodes based on the Balanced Forman curvature,\nCurvPool constructs a graph with a more suitable structure, allowing deeper\nmodels and the combination of distant information. We compare it to other\nstate-of-the-art pooling approaches and establish its competitiveness in terms\nof classification accuracy, computational complexity, and flexibility. CurvPool\noutperforms several comparable methods across all considered tasks. The most\nconsistent results are achieved by pooling densely connected clusters using the\nsum aggregation, as this allows additional information about the size of each\npool.",
          "link": "http://arxiv.org/abs/2308.16516",
          "publishedOn": "2023-09-02T00:40:02.051Z",
          "wordCount": null,
          "title": "Curvature-based Pooling within Graph Neural Networks. (arXiv:2308.16516v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16599",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wagner_F/0/1/0/all/0/1\">Felix Wagner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nachtigall_F/0/1/0/all/0/1\">Florian Nachtigall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Franken_L/0/1/0/all/0/1\">Lukas Franken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milojevic_Dupont_N/0/1/0/all/0/1\">Nikola Milojevic-Dupont</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pereira_R/0/1/0/all/0/1\">Rafael H.M. Pereira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koch_N/0/1/0/all/0/1\">Nicolas Koch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Runge_J/0/1/0/all/0/1\">Jakob Runge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_M/0/1/0/all/0/1\">Marta Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Creutzig_F/0/1/0/all/0/1\">Felix Creutzig</a>",
          "description": "Global sustainability requires low-carbon urban transport systems, shaped by\nadequate infrastructure, deployment of low-carbon transport modes and shifts in\ntravel behavior. To adequately implement alterations in infrastructure, it's\nessential to grasp the location-specific cause-and-effect mechanisms that the\nconstructed environment has on travel. Yet, current research falls short in\nrepresenting causal relationships between the 6D urban form variables and\ntravel, generalizing across different regions, and modeling urban form effects\nat high spatial resolution. Here, we address all three gaps by utilizing a\ncausal discovery and an explainable machine learning framework to detect urban\nform effects on intra-city travel based on high-resolution mobility data of six\ncities across three continents. We show that both distance to city center,\ndemographics and density indirectly affect other urban form features. By\nconsidering the causal relationships, we find that location-specific influences\nalign across cities, yet vary in magnitude. In addition, the spread of the city\nand the coverage of jobs across the city are the strongest determinants of\ntravel-related emissions, highlighting the benefits of compact development and\nassociated benefits. Differences in urban form effects across the cities call\nfor a more holistic definition of 6D measures. Our work is a starting point for\nlocation-specific analysis of urban form effects on mobility behavior using\ncausal discovery approaches, which is highly relevant for city planners and\nmunicipalities across continents.",
          "link": "http://arxiv.org/abs/2308.16599",
          "publishedOn": "2023-09-02T00:40:02.051Z",
          "wordCount": null,
          "title": "A Causal Discovery Approach To Learn How Urban Form Shapes Sustainable Mobility Across Continents. (arXiv:2308.16599v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16738",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yue_Y/0/1/0/all/0/1\">Yubiao Yue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xue_J/0/1/0/all/0/1\">Jun Xue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liang_H/0/1/0/all/0/1\">Haihua Liang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Luo_B/0/1/0/all/0/1\">Bingchun Luo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Z/0/1/0/all/0/1\">Zhenzhang Li</a>",
          "description": "Ultrasound imaging serves as a pivotal tool for diagnosing cervical lymph\nnode lesions. However, the diagnoses of these images largely hinge on the\nexpertise of medical practitioners, rendering the process susceptible to\nmisdiagnoses. Although rapidly developing deep learning has substantially\nimproved the diagnoses of diverse ultrasound images, there remains a\nconspicuous research gap concerning cervical lymph nodes. The objective of our\nwork is to accurately diagnose cervical lymph node lesions by leveraging a deep\nlearning model. To this end, we first collected 3392 images containing normal\nlymph nodes, benign lymph node lesions, malignant primary lymph node lesions,\nand malignant metastatic lymph node lesions. Given that ultrasound images are\ngenerated by the reflection and scattering of sound waves across varied bodily\ntissues, we proposed the Conv-FFT Block. It integrates convolutional operations\nwith the fast Fourier transform to more astutely model the images. Building\nupon this foundation, we designed a novel architecture, named US-SFNet. This\narchitecture not only discerns variances in ultrasound images from the spatial\ndomain but also adeptly captures microstructural alterations across various\nlesions in the frequency domain. To ascertain the potential of US-SFNet, we\nbenchmarked it against 12 popular architectures through five-fold\ncross-validation. The results show that US-SFNet is SOTA and can achieve 92.89%\naccuracy, 90.46% precision, 89.95% sensitivity and 97.49% specificity,\nrespectively.",
          "link": "http://arxiv.org/abs/2308.16738",
          "publishedOn": "2023-09-02T00:40:02.051Z",
          "wordCount": null,
          "title": "US-SFNet: A Spatial-Frequency Domain-based Multi-branch Network for Cervical Lymph Node Lesions Diagnoses in Ultrasound Images. (arXiv:2308.16738v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16406",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1\">Zehao Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_W/0/1/0/all/0/1\">Weidong Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Muhan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yixin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuan Zhang</a>",
          "description": "The electronic design automation of analog circuits has been a longstanding\nchallenge in the integrated circuit field due to the huge design space and\ncomplex design trade-offs among circuit specifications. In the past decades,\nintensive research efforts have mostly been paid to automate the transistor\nsizing with a given circuit topology. By recognizing the graph nature of\ncircuits, this paper presents a Circuit Graph Neural Network (CktGNN) that\nsimultaneously automates the circuit topology generation and device sizing\nbased on the encoder-dependent optimization subroutines. Particularly, CktGNN\nencodes circuit graphs using a two-level GNN framework (of nested GNN) where\ncircuits are represented as combinations of subgraphs in a known subgraph\nbasis. In this way, it significantly improves design efficiency by reducing the\nnumber of subgraphs to perform message passing. Nonetheless, another critical\nroadblock to advancing learning-assisted circuit design automation is a lack of\npublic benchmarks to perform canonical assessment and reproducible research. To\ntackle the challenge, we introduce Open Circuit Benchmark (OCB), an\nopen-sourced dataset that contains $10$K distinct operational amplifiers with\ncarefully-extracted circuit specifications. OCB is also equipped with\ncommunicative circuit generation and evaluation capabilities such that it can\nhelp to generalize CktGNN to design various analog circuits by producing\ncorresponding datasets. Experiments on OCB show the extraordinary advantages of\nCktGNN through representation-based optimization frameworks over other recent\npowerful GNN baselines and human experts' manual designs. Our work paves the\nway toward a learning-based open-sourced design automation for analog circuits.\nOur source code is available at \\url{https://github.com/zehao-dong/CktGNN}.",
          "link": "http://arxiv.org/abs/2308.16406",
          "publishedOn": "2023-09-02T00:40:02.003Z",
          "wordCount": null,
          "title": "CktGNN: Circuit Graph Neural Network for Electronic Design Automation. (arXiv:2308.16406v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16422",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Zhao_T/0/1/0/all/0/1\">Tianyu Zhao</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Zhou_Y/0/1/0/all/0/1\">Yue Zhou</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Shi_R/0/1/0/all/0/1\">Ruijun Shi</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Cao_Z/0/1/0/all/0/1\">Zhoujian Cao</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Ren_Z/0/1/0/all/0/1\">Zhixiang Ren</a>",
          "description": "The detection of Extreme Mass Ratio Inspirals (EMRIs) is intricate due to\ntheir complex waveforms, extended duration, and low signal-to-noise ratio\n(SNR), making them more challenging to be identified compared to compact binary\ncoalescences. While matched filtering-based techniques are known for their\ncomputational demands, existing deep learning-based methods primarily handle\ntime-domain data and are often constrained by data duration and SNR. In\naddition, most existing work ignores time-delay interferometry (TDI) and\napplies the long-wavelength approximation in detector response calculations,\nthus limiting their ability to handle laser frequency noise. In this study, we\nintroduce DECODE, an end-to-end model focusing on EMRI signal detection by\nsequence modeling in the frequency domain. Centered around a dilated causal\nconvolutional neural network, trained on synthetic data considering TDI-1.5\ndetector response, DECODE can efficiently process a year's worth of\nmultichannel TDI data with an SNR of around 50. We evaluate our model on 1-year\ndata with accumulated SNR ranging from 50 to 120 and achieve a true positive\nrate of 96.3% at a false positive rate of 1%, keeping an inference time of less\nthan 0.01 seconds. With the visualization of three showcased EMRI signals for\ninterpretability and generalization, DECODE exhibits strong potential for\nfuture space-based gravitational wave data analyses.",
          "link": "http://arxiv.org/abs/2308.16422",
          "publishedOn": "2023-09-02T00:40:02.003Z",
          "wordCount": null,
          "title": "DECODE: DilatEd COnvolutional neural network for Detecting Extreme-mass-ratio inspirals. (arXiv:2308.16422v1 [astro-ph.IM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16274",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nicolicioiu_A/0/1/0/all/0/1\">Armand Mihai Nicolicioiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nicolicioiu_A/0/1/0/all/0/1\">Andrei Liviu Nicolicioiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alexe_B/0/1/0/all/0/1\">Bogdan Alexe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teney_D/0/1/0/all/0/1\">Damien Teney</a>",
          "description": "Deep learning models often rely only on a small set of features even when\nthere is a rich set of predictive signals in the training data. This makes\nmodels brittle and sensitive to distribution shifts. In this work, we first\nexamine vision transformers (ViTs) and find that they tend to extract robust\nand spurious features with distinct attention heads. As a result of this\nmodularity, their performance under distribution shifts can be significantly\nimproved at test time by pruning heads corresponding to spurious features,\nwhich we demonstrate using an \"oracle selection\" on validation data. Second, we\npropose a method to further enhance the diversity and complementarity of the\nlearned features by encouraging orthogonality of the attention heads' input\ngradients. We observe improved out-of-distribution performance on diagnostic\nbenchmarks (MNIST-CIFAR, Waterbirds) as a consequence of the enhanced diversity\nof features and the pruning of undesirable heads.",
          "link": "http://arxiv.org/abs/2308.16274",
          "publishedOn": "2023-09-02T00:40:01.997Z",
          "wordCount": null,
          "title": "Learning Diverse Features in Vision Transformers for Improved Generalization. (arXiv:2308.16274v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16360",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuhang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xuan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_G/0/1/0/all/0/1\">Ge Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_Q/0/1/0/all/0/1\">Qiaozhu Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ai_W/0/1/0/all/0/1\">Wei Ai</a>",
          "description": "Although remote working is increasingly adopted during the pandemic, many are\nconcerned by the low-efficiency in the remote working. Missing in text-based\ncommunication are non-verbal cues such as facial expressions and body language,\nwhich hinders the effective communication and negatively impacts the work\noutcomes. Prevalent on social media platforms, emojis, as alternative\nnon-verbal cues, are gaining popularity in the virtual workspaces well. In this\npaper, we study how emoji usage influences developer participation and issue\nresolution in virtual workspaces. To this end, we collect GitHub issues for a\none-year period and apply causal inference techniques to measure the causal\neffect of emojis on the outcome of issues, controlling for confounders such as\nissue content, repository, and author information. We find that emojis can\nsignificantly reduce the resolution time of issues and attract more user\nparticipation. We also compare the heterogeneous effect on different types of\nissues. These findings deepen our understanding of the developer communities,\nand they provide design implications on how to facilitate interactions and\nbroaden developer participation.",
          "link": "http://arxiv.org/abs/2308.16360",
          "publishedOn": "2023-09-02T00:40:01.997Z",
          "wordCount": null,
          "title": "Emoji Promotes Developer Participation and Issue Resolution on GitHub. (arXiv:2308.16360v1 [cs.CY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yamamori_S/0/1/0/all/0/1\">Satoshi Yamamori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morimoto_J/0/1/0/all/0/1\">Jun Morimoto</a>",
          "description": "In dynamic motion generation tasks, including contact and collisions, small\nchanges in policy parameters can lead to extremely different returns. For\nexample, in soccer, the ball can fly in completely different directions with a\nsimilar heading motion by slightly changing the hitting position or the force\napplied to the ball or when the friction of the ball varies. However, it is\ndifficult to imagine that completely different skills are needed for heading a\nball in different directions. In this study, we proposed a multitask\nreinforcement learning algorithm for adapting a policy to implicit changes in\ngoals or environments in a single motion category with different reward\nfunctions or physical parameters of the environment. We evaluated the proposed\nmethod on the ball heading task using a monopod robot model. The results showed\nthat the proposed method can adapt to implicit changes in the goal positions or\nthe coefficients of restitution of the ball, whereas the standard domain\nrandomization approach cannot cope with different task settings.",
          "link": "http://arxiv.org/abs/2308.16471",
          "publishedOn": "2023-09-02T00:40:01.997Z",
          "wordCount": null,
          "title": "A Policy Adaptation Method for Implicit Multitask Reinforcement Learning Problems. (arXiv:2308.16471v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16279",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bordeau_Aubert_K/0/1/0/all/0/1\">Korantin Bordeau-Aubert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whatley_J/0/1/0/all/0/1\">Justin Whatley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nadeau_S/0/1/0/all/0/1\">Sylvain Nadeau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glatard_T/0/1/0/all/0/1\">Tristan Glatard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaumard_B/0/1/0/all/0/1\">Brigitte Jaumard</a>",
          "description": "The increasing complexity and scale of telecommunication networks have led to\na growing interest in automated anomaly detection systems. However, the\nclassification of anomalies detected on network Key Performance Indicators\n(KPI) has received less attention, resulting in a lack of information about\nanomaly characteristics and classification processes. To address this gap, this\npaper proposes a modular anomaly classification framework. The framework\nassumes separate entities for the anomaly classifier and the detector, allowing\nfor a distinct treatment of anomaly detection and classification tasks on time\nseries. The objectives of this study are (1) to develop a time series simulator\nthat generates synthetic time series resembling real-world network KPI\nbehavior, (2) to build a detection model to identify anomalies in the time\nseries, (3) to build classification models that accurately categorize detected\nanomalies into predefined classes (4) to evaluate the classification framework\nperformance on simulated and real-world network KPI time series. This study has\ndemonstrated the good performance of the anomaly classification models trained\non simulated anomalies when applied to real-world network time series data.",
          "link": "http://arxiv.org/abs/2308.16279",
          "publishedOn": "2023-09-02T00:40:01.955Z",
          "wordCount": null,
          "title": "Classification of Anomalies in Telecommunication Network KPI Time Series. (arXiv:2308.16279v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16210",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bueff_A/0/1/0/all/0/1\">Andreas Bueff</a> (University of Edinburgh), <a href=\"http://arxiv.org/find/cs/1/au:+Belle_V/0/1/0/all/0/1\">Vaishak Belle</a> (University of Edinburgh)",
          "description": "One approach to explaining the hierarchical levels of understanding within a\nmachine learning model is the symbolic method of inductive logic programming\n(ILP), which is data efficient and capable of learning first-order logic rules\nthat can entail data behaviour. A differentiable extension to ILP, so-called\ndifferentiable Neural Logic (dNL) networks, are able to learn Boolean functions\nas their neural architecture includes symbolic reasoning. We propose an\napplication of dNL in the field of Relational Reinforcement Learning (RRL) to\naddress dynamic continuous environments. This represents an extension of\nprevious work in applying dNL-based ILP in RRL settings, as our proposed model\nupdates the architecture to enable it to solve problems in continuous RL\nenvironments. The goal of this research is to improve upon current ILP methods\nfor use in RRL by incorporating non-linear continuous predicates, allowing RRL\nagents to reason and make decisions in dynamic and continuous environments.",
          "link": "http://arxiv.org/abs/2308.16210",
          "publishedOn": "2023-09-02T00:40:01.822Z",
          "wordCount": 689,
          "title": "Deep Inductive Logic Programming meets Reinforcement Learning. (arXiv:2308.16210v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.16331",
          "author": "<a href=\"http://arxiv.org/find/math-ph/1/au:+Vaquero_M/0/1/0/all/0/1\">Miguel Vaquero</a>, <a href=\"http://arxiv.org/find/math-ph/1/au:+Cortes_J/0/1/0/all/0/1\">Jorge Cort&#xe9;s</a>, <a href=\"http://arxiv.org/find/math-ph/1/au:+Diego_D/0/1/0/all/0/1\">David Mart&#xed;n de Diego</a>",
          "description": "This work presents a general geometric framework for simulating and learning\nthe dynamics of Hamiltonian systems that are invariant under a Lie group of\ntransformations. This means that a group of symmetries is known to act on the\nsystem respecting its dynamics and, as a consequence, Noether's Theorem,\nconserved quantities are observed. We propose to simulate and learn the\nmappings of interest through the construction of $G$-invariant Lagrangian\nsubmanifolds, which are pivotal objects in symplectic geometry. A notable\nproperty of our constructions is that the simulated/learned dynamics also\npreserves the same conserved quantities as the original system, resulting in a\nmore faithful surrogate of the original dynamics than non-symmetry aware\nmethods, and in a more accurate predictor of non-observed trajectories.\nFurthermore, our setting is able to simulate/learn not only Hamiltonian flows,\nbut any Lie group-equivariant symplectic transformation. Our designs leverage\npivotal techniques and concepts in symplectic geometry and geometric mechanics:\nreduction theory, Noether's Theorem, Lagrangian submanifolds, momentum\nmappings, and coisotropic reduction among others. We also present methods to\nlearn Poisson transformations while preserving the underlying geometry and how\nto endow non-geometric integrators with geometric properties. Thus, this work\npresents a novel attempt to harness the power of symplectic and Poisson\ngeometry towards simulating and learning problems.",
          "link": "http://arxiv.org/abs/2308.16331",
          "publishedOn": "2023-09-02T00:40:01.816Z",
          "wordCount": 735,
          "title": "Symmetry Preservation in Hamiltonian Systems: Simulation and Learning. (arXiv:2308.16331v1 [math-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.16369",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1\">Amey Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panwar_A/0/1/0/all/0/1\">Ashish Panwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohan_J/0/1/0/all/0/1\">Jayashree Mohan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwatra_N/0/1/0/all/0/1\">Nipun Kwatra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gulavani_B/0/1/0/all/0/1\">Bhargav S. Gulavani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramjee_R/0/1/0/all/0/1\">Ramachandran Ramjee</a>",
          "description": "Large Language Model (LLM) inference consists of two distinct phases -\nprefill phase which processes the input prompt and decode phase which generates\noutput tokens autoregressively. While the prefill phase effectively saturates\nGPU compute at small batch sizes, the decode phase results in low compute\nutilization as it generates one token at a time per request. The varying\nprefill and decode times also lead to imbalance across micro-batches when using\npipeline parallelism, resulting in further inefficiency due to bubbles.\n\nWe present SARATHI to address these challenges. SARATHI employs\nchunked-prefills, which splits a prefill request into equal sized chunks, and\ndecode-maximal batching, which constructs a batch using a single prefill chunk\nand populates the remaining slots with decodes. During inference, the prefill\nchunk saturates GPU compute, while the decode requests 'piggyback' and cost up\nto an order of magnitude less compared to a decode-only batch. Chunked-prefills\nallows constructing multiple decode-maximal batches from a single prefill\nrequest, maximizing coverage of decodes that can piggyback. Furthermore, the\nuniform compute design of these batches ameliorates the imbalance between\nmicro-batches, significantly reducing pipeline bubbles.\n\nOur techniques yield significant improvements in inference performance across\nmodels and hardware. For the LLaMA-13B model on A6000 GPU, SARATHI improves\ndecode throughput by up to 10x, and accelerates end-to-end throughput by up to\n1.33x. For LLaMa-33B on A100 GPU, we achieve 1.25x higher end-to-end-throughput\nand up to 4.25x higher decode throughput. When used with pipeline parallelism\non GPT-3, SARATHI reduces bubbles by 6.29x, resulting in an end-to-end\nthroughput improvement of 1.91x.",
          "link": "http://arxiv.org/abs/2308.16369",
          "publishedOn": "2023-09-02T00:40:01.793Z",
          "wordCount": 773,
          "title": "SARATHI: Efficient LLM Inference by Piggybacking Decodes with Chunked Prefills. (arXiv:2308.16369v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.12844",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guerra_M/0/1/0/all/0/1\">Michele Guerra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scardapane_S/0/1/0/all/0/1\">Simone Scardapane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bianchi_F/0/1/0/all/0/1\">Filippo Maria Bianchi</a>",
          "description": "Some applications of deep learning require not only to provide accurate\nresults but also to quantify the amount of confidence in their prediction. The\nmanagement of an electric power grid is one of these cases: to avoid risky\nscenarios, decision-makers need both precise and reliable forecasts of, for\nexample, power loads. For this reason, point forecasts are not enough hence it\nis necessary to adopt methods that provide an uncertainty quantification.\n\nThis work focuses on reservoir computing as the core time series forecasting\nmethod, due to its computational efficiency and effectiveness in predicting\ntime series. While the RC literature mostly focused on point forecasting, this\nwork explores the compatibility of some popular uncertainty quantification\nmethods with the reservoir setting. Both Bayesian and deterministic approaches\nto uncertainty assessment are evaluated and compared in terms of their\nprediction accuracy, computational resource efficiency and reliability of the\nestimated uncertainty, based on a set of carefully chosen performance metrics.",
          "link": "http://arxiv.org/abs/2308.12844",
          "publishedOn": "2023-08-26T00:39:49.936Z",
          "wordCount": null,
          "title": "Probabilistic load forecasting with Reservoir Computing. (arXiv:2308.12844v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12956",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kuang_H/0/1/0/all/0/1\">Huafeng Kuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jie Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xiawu Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Ming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xuefeng Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1\">Min Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_R/0/1/0/all/0/1\">Rongrong Ji</a>",
          "description": "Vision-Language Pre-training (VLP) shows remarkable progress with the\nassistance of extremely heavy parameters, which challenges deployment in real\napplications. Knowledge distillation is well recognized as the essential\nprocedure in model compression. However, existing knowledge distillation\ntechniques lack an in-depth investigation and analysis of VLP, and practical\nguidelines for VLP-oriented distillation are still not yet explored. In this\npaper, we present DLIP, a simple yet efficient Distilling Language-Image\nPre-training framework, through which we investigate how to distill a light VLP\nmodel. Specifically, we dissect the model distillation from multiple\ndimensions, such as the architecture characteristics of different modules and\nthe information transfer of different modalities. We conduct comprehensive\nexperiments and provide insights on distilling a light but performant VLP\nmodel. Experimental results reveal that DLIP can achieve a state-of-the-art\naccuracy/efficiency trade-off across diverse cross-modal tasks, e.g.,\nimage-text retrieval, image captioning and visual question answering. For\nexample, DLIP compresses BLIP by 1.9x, from 213M to 108M parameters, while\nachieving comparable or better performance. Furthermore, DLIP succeeds in\nretaining more than 95% of the performance with 22.4% parameters and 24.8%\nFLOPs compared to the teacher model and accelerates inference speed by 2.7x.",
          "link": "http://arxiv.org/abs/2308.12956",
          "publishedOn": "2023-08-26T00:39:49.932Z",
          "wordCount": null,
          "title": "DLIP: Distilling Language-Image Pre-training. (arXiv:2308.12956v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.08040",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mougan_C/0/1/0/all/0/1\">Carlos Mougan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+State_L/0/1/0/all/0/1\">Laura State</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrara_A/0/1/0/all/0/1\">Antonio Ferrara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruggieri_S/0/1/0/all/0/1\">Salvatore Ruggieri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staab_S/0/1/0/all/0/1\">Steffen Staab</a>",
          "description": "Liberalism-oriented political philosophy reasons that all individuals should\nbe treated equally independently of their protected characteristics. Related\nwork in machine learning has translated the concept of equal treatment into\nterms of equal outcome and measured it as demographic parity (also called\nstatistical parity). Our analysis reveals that the two concepts of equal\noutcome and equal treatment diverge; therefore, demographic parity does not\nfaithfully represent the notion of equal treatment. We propose a new\nformalization for equal treatment by (i) considering the influence of feature\nvalues on predictions, such as computed by Shapley values explaining\nclassifications, (ii) defining distributions of explanations, and (iii)\ncomparing explanation distributions between populations with different\nprotected characteristics. We show the theoretical properties of our notion of\nequal treatment and devise a classifier two-sample test based on the AUC of an\nequal treatment inspector. We study our formalization of equal treatment on\nsynthetic and natural data. We release explanationspace, an open-source Python\npackage with methods and tutorials.",
          "link": "http://arxiv.org/abs/2303.08040",
          "publishedOn": "2023-08-26T00:39:49.932Z",
          "wordCount": null,
          "title": "Equal Treatment: Measuring Fairness using Explanation Distributions. (arXiv:2303.08040v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12923",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Constante_Flores_G/0/1/0/all/0/1\">Gonzalo E. Constante-Flores</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Can Li</a>",
          "description": "Decision-making problems can be represented as mathematical optimization\nmodels, finding wide applications in fields such as economics, engineering and\nmanufacturing, transportation, and health care. Optimization models are\nmathematical abstractions of the problem of making the best decision while\nsatisfying a set of requirements or constraints. One of the primary barriers to\ndeploying these models in practice is the challenge of helping practitioners\nunderstand and interpret such models, particularly when they are infeasible,\nmeaning no decision satisfies all the constraints. Existing methods for\ndiagnosing infeasible optimization models often rely on expert systems,\nnecessitating significant background knowledge in optimization. In this paper,\nwe introduce OptiChat, a first-of-its-kind natural language-based system\nequipped with a chatbot GUI for engaging in interactive conversations about\ninfeasible optimization models. OptiChat can provide natural language\ndescriptions of the optimization model itself, identify potential sources of\ninfeasibility, and offer suggestions to make the model feasible. The\nimplementation of OptiChat is built on GPT-4, which interfaces with an\noptimization solver to identify the minimal subset of constraints that render\nthe entire optimization problem infeasible, also known as the Irreducible\nInfeasible Subset (IIS). We utilize few-shot learning, expert chain-of-thought,\nkey-retrieve, and sentiment prompts to enhance OptiChat's reliability. Our\nexperiments demonstrate that OptiChat assists both expert and non-expert users\nin improving their understanding of the optimization models, enabling them to\nquickly identify the sources of infeasibility.",
          "link": "http://arxiv.org/abs/2308.12923",
          "publishedOn": "2023-08-26T00:39:49.931Z",
          "wordCount": null,
          "title": "Diagnosing Infeasible Optimization Problems Using Large Language Models. (arXiv:2308.12923v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12126",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Yang_W/0/1/0/all/0/1\">Weifeng Yang</a>, <a href=\"http://arxiv.org/find/math/1/au:+Min_W/0/1/0/all/0/1\">Wenwen Min</a>",
          "description": "We propose an accelerated block proximal linear framework with adaptive\nmomentum (ABPL$^+$) for nonconvex and nonsmooth optimization. We analyze the\npotential causes of the extrapolation step failing in some algorithms, and\nresolve this issue by enhancing the comparison process that evaluates the\ntrade-off between the proximal gradient step and the linear extrapolation step\nin our algorithm. Furthermore, we extends our algorithm to any scenario\ninvolving updating block variables with positive integers, allowing each cycle\nto randomly shuffle the update order of the variable blocks. Additionally,\nunder mild assumptions, we prove that ABPL$^+$ can monotonically decrease the\nfunction value without strictly restricting the extrapolation parameters and\nstep size, demonstrates the viability and effectiveness of updating these\nblocks in a random order, and we also more obviously and intuitively\ndemonstrate that the derivative set of the sequence generated by our algorithm\nis a critical point set. Moreover, we demonstrate the global convergence as\nwell as the linear and sublinear convergence rates of our algorithm by\nutilizing the Kurdyka-Lojasiewicz (K{\\L}) condition. To enhance the\neffectiveness and flexibility of our algorithm, we also expand the study to the\nimprecise version of our algorithm and construct an adaptive extrapolation\nparameter strategy, which improving its overall performance. We apply our\nalgorithm to multiple non-negative matrix factorization with the $\\ell_0$ norm,\nnonnegative tensor decomposition with the $\\ell_0$ norm, and perform extensive\nnumerical experiments to validate its effectiveness and efficiency.",
          "link": "http://arxiv.org/abs/2308.12126",
          "publishedOn": "2023-08-26T00:39:49.928Z",
          "wordCount": null,
          "title": "An Accelerated Block Proximal Framework with Adaptive Momentum for Nonconvex and Nonsmooth Optimization. (arXiv:2308.12126v2 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.01805",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_T/0/1/0/all/0/1\">Tianjiao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_S/0/1/0/all/0/1\">Shengbang Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1\">Kwan Ho Ryan Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1\">Xili Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haeffele_B/0/1/0/all/0/1\">Benjamin D. Haeffele</a>",
          "description": "We consider the problem of simultaneously clustering and learning a linear\nrepresentation of data lying close to a union of low-dimensional manifolds, a\nfundamental task in machine learning and computer vision. When the manifolds\nare assumed to be linear subspaces, this reduces to the classical problem of\nsubspace clustering, which has been studied extensively over the past two\ndecades. Unfortunately, many real-world datasets such as natural images can not\nbe well approximated by linear subspaces. On the other hand, numerous works\nhave attempted to learn an appropriate transformation of the data, such that\ndata is mapped from a union of general non-linear manifolds to a union of\nlinear subspaces (with points from the same manifold being mapped to the same\nsubspace). However, many existing works have limitations such as assuming\nknowledge of the membership of samples to clusters, requiring high sampling\ndensity, or being shown theoretically to learn trivial representations. In this\npaper, we propose to optimize the Maximal Coding Rate Reduction metric with\nrespect to both the data representation and a novel doubly stochastic cluster\nmembership, inspired by state-of-the-art subspace clustering results. We give a\nparameterization of such a representation and membership, allowing efficient\nmini-batching and one-shot initialization. Experiments on CIFAR-10, -20, -100,\nand TinyImageNet-200 datasets show that the proposed method is much more\naccurate and scalable than state-of-the-art deep clustering methods, and\nfurther learns a latent linear representation of the data.",
          "link": "http://arxiv.org/abs/2301.01805",
          "publishedOn": "2023-08-26T00:39:49.927Z",
          "wordCount": null,
          "title": "Unsupervised Manifold Linearizing and Clustering. (arXiv:2301.01805v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.10145",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kim_Y/0/1/0/all/0/1\">Young-geun Kim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_K/0/1/0/all/0/1\">Kyungbok Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Choi_Y/0/1/0/all/0/1\">Youngwon Choi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Won_J/0/1/0/all/0/1\">Joong-Ho Won</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Paik_M/0/1/0/all/0/1\">Myunghee Cho Paik</a>",
          "description": "Generating samples given a specific label requires estimating conditional\ndistributions. We derive a tractable upper bound of the Wasserstein distance\nbetween conditional distributions to lay the theoretical groundwork to learn\nconditional distributions. Based on this result, we propose a novel conditional\ngeneration algorithm where conditional distributions are fully characterized by\na metric space defined by a statistical distance. We employ optimal transport\ntheory to propose the Wasserstein geodesic generator, a new conditional\ngenerator that learns the Wasserstein geodesic. The proposed method learns both\nconditional distributions for observed domains and optimal transport maps\nbetween them. The conditional distributions given unobserved intermediate\ndomains are on the Wasserstein geodesic between conditional distributions given\ntwo observed domain labels. Experiments on face images with light conditions as\ndomain labels demonstrate the efficacy of the proposed method.",
          "link": "http://arxiv.org/abs/2308.10145",
          "publishedOn": "2023-08-26T00:39:49.927Z",
          "wordCount": null,
          "title": "Wasserstein Geodesic Generator for Conditional Distributions. (arXiv:2308.10145v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2203.16331",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Verwer_S/0/1/0/all/0/1\">Sicco Verwer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hammerschmidt_C/0/1/0/all/0/1\">Christian Hammerschmidt</a>",
          "description": "We present the efficient implementations of probabilistic deterministic\nfinite automaton learning methods available in FlexFringe. These implement\nwell-known strategies for state-merging including several modifications to\nimprove their performance in practice. We show experimentally that these\nalgorithms obtain competitive results and significant improvements over a\ndefault implementation. We also demonstrate how to use FlexFringe to learn\ninterpretable models from software logs and use these for anomaly detection.\nAlthough less interpretable, we show that learning smaller more convoluted\nmodels improves the performance of FlexFringe on anomaly detection,\noutperforming an existing solution based on neural nets.",
          "link": "http://arxiv.org/abs/2203.16331",
          "publishedOn": "2023-08-26T00:39:49.926Z",
          "wordCount": null,
          "title": "FlexFringe: Modeling Software Behavior by Learning Probabilistic Automata. (arXiv:2203.16331v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12673",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daskalakis_D/0/1/0/all/0/1\">Dimitrios Daskalakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gkalelis_N/0/1/0/all/0/1\">Nikolaos Gkalelis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mezaris_V/0/1/0/all/0/1\">Vasileios Mezaris</a>",
          "description": "In this paper, we introduce Masked Feature Modelling (MFM), a novel approach\nfor the unsupervised pre-training of a Graph Attention Network (GAT) block. MFM\nutilizes a pretrained Visual Tokenizer to reconstruct masked features of\nobjects within a video, leveraging the MiniKinetics dataset. We then\nincorporate the pre-trained GAT block into a state-of-the-art bottom-up\nsupervised video-event recognition architecture, ViGAT, to improve the model's\nstarting point and overall accuracy. Experimental evaluations on the YLI-MED\ndataset demonstrate the effectiveness of MFM in improving event recognition\nperformance.",
          "link": "http://arxiv.org/abs/2308.12673",
          "publishedOn": "2023-08-26T00:39:49.919Z",
          "wordCount": null,
          "title": "Masked Feature Modelling: Feature Masking for the Unsupervised Pre-training of a Graph Attention Network Block for Bottom-up Video Event Recognition. (arXiv:2308.12673v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12681",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yanci Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Han Yu</a>",
          "description": "Federated learning (FL) is an emerging approach for training machine learning\nmodels collaboratively while preserving data privacy. The need for privacy\nprotection makes it difficult for FL models to achieve global transparency and\nexplainability. To address this limitation, we incorporate logic-based\nexplanations into FL by proposing the Logical Reasoning-based eXplainable\nFederated Learning (LR-XFL) approach. Under LR-XFL, FL clients create local\nlogic rules based on their local data and send them, along with model updates,\nto the FL server. The FL server connects the local logic rules through a proper\nlogical connector that is derived based on properties of client data, without\nrequiring access to the raw data. In addition, the server also aggregates the\nlocal model updates with weight values determined by the quality of the\nclients' local data as reflected by their uploaded logic rules. The results\nshow that LR-XFL outperforms the most relevant baseline by 1.19%, 5.81% and\n5.41% in terms of classification accuracy, rule accuracy and rule fidelity,\nrespectively. The explicit rule evaluation and expression under LR-XFL enable\nhuman experts to validate and correct the rules on the server side, hence\nimproving the global FL model's robustness to errors. It has the potential to\nenhance the transparency of FL models for areas like healthcare and finance\nwhere both data privacy and explainability are important.",
          "link": "http://arxiv.org/abs/2308.12681",
          "publishedOn": "2023-08-26T00:39:49.917Z",
          "wordCount": null,
          "title": "LR-XFL: Logical Reasoning-based Explainable Federated Learning. (arXiv:2308.12681v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12859",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Juan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borchers_D/0/1/0/all/0/1\">David L. Borchers</a>",
          "description": "Passive acoustic monitoring can be an effective way of monitoring wildlife\npopulations that are acoustically active but difficult to survey visually.\nDigital recorders allow surveyors to gather large volumes of data at low cost,\nbut identifying target species vocalisations in these data is non-trivial.\nMachine learning (ML) methods are often used to do the identification. They can\nprocess large volumes of data quickly, but they do not detect all vocalisations\nand they do generate some false positives (vocalisations that are not from the\ntarget species). Existing wildlife abundance survey methods have been designed\nspecifically to deal with the first of these mistakes, but current methods of\ndealing with false positives are not well-developed. They do not take account\nof features of individual vocalisations, some of which are more likely to be\nfalse positives than others. We propose three methods for acoustic spatial\ncapture-recapture inference that integrate individual-level measures of\nconfidence from ML vocalisation identification into the likelihood and hence\nintegrate ML uncertainty into inference. The methods include a mixture model in\nwhich species identity is a latent variable. We test the methods by simulation\nand find that in a scenario based on acoustic data from Hainan gibbons, in\nwhich ignoring false positives results in 17% positive bias, our methods give\nnegligible bias and coverage probabilities that are close to the nominal 95%\nlevel.",
          "link": "http://arxiv.org/abs/2308.12859",
          "publishedOn": "2023-08-26T00:39:49.911Z",
          "wordCount": null,
          "title": "Towards Automated Animal Density Estimation with Acoustic Spatial Capture-Recapture. (arXiv:2308.12859v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.09107",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Kazemimoghadam_M/0/1/0/all/0/1\">Mahdieh Kazemimoghadam</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Z/0/1/0/all/0/1\">Zi Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ma_L/0/1/0/all/0/1\">Lin Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_M/0/1/0/all/0/1\">Mingli Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lu_W/0/1/0/all/0/1\">Weiguo Lu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gu_X/0/1/0/all/0/1\">Xuejun Gu</a>",
          "description": "Deep learning (DL) models for medical image segmentation are highly\ninfluenced by intensity variations of input images and lack generalization due\nto primarily utilizing pixels' intensity information for inference. Acquiring\nsufficient training data is another challenge limiting models' applications. We\nproposed to leverage the consistency of organs' anatomical shape and position\ninformation in medical images. We introduced a framework leveraging recurring\nanatomical patterns through global binary masks for organ segmentation. Two\nscenarios were studied.1) Global binary masks were the only model's (i.e.\nU-Net) input, forcing exclusively encoding organs' position and shape\ninformation for segmentation/localization.2) Global binary masks were\nincorporated as an additional channel functioning as position/shape clues to\nmitigate training data scarcity. Two datasets of the brain and heart CT images\nwith their ground-truth were split into (26:10:10) and (12:3:5) for training,\nvalidation, and test respectively. Training exclusively on global binary masks\nled to Dice scores of 0.77(0.06) and 0.85(0.04), with the average Euclidian\ndistance of 3.12(1.43)mm and 2.5(0.93)mm relative to the center of mass of the\nground truth for the brain and heart structures respectively. The outcomes\nindicate that a surprising degree of position and shape information is encoded\nthrough global binary masks. Incorporating global binary masks led to\nsignificantly higher accuracy relative to the model trained on only CT images\nin small subsets of training data; the performance improved by 4.3-125.3% and\n1.3-48.1% for 1-8 training cases of the brain and heart datasets respectively.\nThe findings imply the advantages of utilizing global binary masks for building\ngeneralizable models and to compensate for training data scarcity.",
          "link": "http://arxiv.org/abs/2205.09107",
          "publishedOn": "2023-08-26T00:39:49.910Z",
          "wordCount": null,
          "title": "Leveraging Global Binary Masks for Structure Segmentation in Medical Images. (arXiv:2205.09107v2 [eess.IV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12734",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bird_J/0/1/0/all/0/1\">Jordan J. Bird</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lotfi_A/0/1/0/all/0/1\">Ahmad Lotfi</a>",
          "description": "There are growing implications surrounding generative AI in the speech domain\nthat enable voice cloning and real-time voice conversion from one individual to\nanother. This technology poses a significant ethical threat and could lead to\nbreaches of privacy and misrepresentation, thus there is an urgent need for\nreal-time detection of AI-generated speech for DeepFake Voice Conversion. To\naddress the above emerging issues, the DEEP-VOICE dataset is generated in this\nstudy, comprised of real human speech from eight well-known figures and their\nspeech converted to one another using Retrieval-based Voice Conversion.\nPresenting as a binary classification problem of whether the speech is real or\nAI-generated, statistical analysis of temporal audio features through t-testing\nreveals that there are significantly different distributions. Hyperparameter\noptimisation is implemented for machine learning models to identify the source\nof speech. Following the training of 208 individual machine learning models\nover 10-fold cross validation, it is found that the Extreme Gradient Boosting\nmodel can achieve an average classification accuracy of 99.3% and can classify\nspeech in real-time, at around 0.004 milliseconds given one second of speech.\nAll data generated for this study is released publicly for future research on\nAI speech detection.",
          "link": "http://arxiv.org/abs/2308.12734",
          "publishedOn": "2023-08-26T00:39:49.882Z",
          "wordCount": null,
          "title": "Real-time Detection of AI-Generated Speech for DeepFake Voice Conversion. (arXiv:2308.12734v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.15596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koskela_A/0/1/0/all/0/1\">Antti Koskela</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tobaben_M/0/1/0/all/0/1\">Marlon Tobaben</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Honkela_A/0/1/0/all/0/1\">Antti Honkela</a>",
          "description": "Individual privacy accounting enables bounding differential privacy (DP) loss\nindividually for each participant involved in the analysis. This can be\ninformative as often the individual privacy losses are considerably smaller\nthan those indicated by the DP bounds that are based on considering worst-case\nbounds at each data access. In order to account for the individual privacy\nlosses in a principled manner, we need a privacy accountant for adaptive\ncompositions of randomised mechanisms, where the loss incurred at a given data\naccess is allowed to be smaller than the worst-case loss. This kind of analysis\nhas been carried out for the R\\'enyi differential privacy (RDP) by Feldman and\nZrnic (2021), however not yet for the so-called optimal privacy accountants. We\nmake first steps in this direction by providing a careful analysis using the\nGaussian differential privacy which gives optimal bounds for the Gaussian\nmechanism, one of the most versatile DP mechanisms. This approach is based on\ndetermining a certain supermartingale for the hockey-stick divergence and on\nextending the R\\'enyi divergence-based fully adaptive composition results by\nFeldman and Zrnic. We also consider measuring the individual\n$(\\varepsilon,\\delta)$-privacy losses using the so-called privacy loss\ndistributions. With the help of the Blackwell theorem, we can then make use of\nthe RDP analysis to construct an approximative individual\n$(\\varepsilon,\\delta)$-accountant.",
          "link": "http://arxiv.org/abs/2209.15596",
          "publishedOn": "2023-08-26T00:39:49.882Z",
          "wordCount": null,
          "title": "Individual Privacy Accounting with Gaussian Differential Privacy. (arXiv:2209.15596v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Power_T/0/1/0/all/0/1\">Thomas Power</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berenson_D/0/1/0/all/0/1\">Dmitry Berenson</a>",
          "description": "We present Constrained Stein Variational Trajectory Optimization (CSVTO), an\nalgorithm for performing trajectory optimization with constraints on a set of\ntrajectories in parallel. We frame constrained trajectory optimization as a\nnovel form of constrained functional minimization over trajectory\ndistributions, which avoids treating the constraints as a penalty in the\nobjective and allows us to generate diverse sets of constraint-satisfying\ntrajectories. Our method uses Stein Variational Gradient Descent (SVGD) to find\na set of particles that approximates a distribution over low-cost trajectories\nwhile obeying constraints. CSVTO is applicable to problems with arbitrary\nequality and inequality constraints and includes a novel particle resampling\nstep to escape local minima. By explicitly generating diverse sets of\ntrajectories, CSVTO is better able to avoid poor local minima and is more\nrobust to initialization. We demonstrate that CSVTO outperforms baselines in\nchallenging highly-constrained tasks, such as a 7DoF wrench manipulation task,\nwhere CSVTO succeeds in 20/20 trials vs 13/20 for the closest baseline. Our\nresults demonstrate that generating diverse constraint-satisfying trajectories\nimproves robustness to disturbances and initialization over baselines.",
          "link": "http://arxiv.org/abs/2308.12110",
          "publishedOn": "2023-08-26T00:39:49.881Z",
          "wordCount": null,
          "title": "Constrained Stein Variational Trajectory Optimization. (arXiv:2308.12110v1 [cs.RO] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12585",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Park_I/0/1/0/all/0/1\">Il Memming Park</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sagodi_A/0/1/0/all/0/1\">&#xc1;bel S&#xe1;godi</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Soko%5Cl_P/0/1/0/all/0/1\">Piotr Aleksander Sok&#xf3;&#x142;</a>",
          "description": "Neural dynamical systems with stable attractor structures, such as point\nattractors and continuous attractors, are hypothesized to underlie meaningful\ntemporal behavior that requires working memory. However, working memory may not\nsupport useful learning signals necessary to adapt to changes in the temporal\nstructure of the environment. We show that in addition to the continuous\nattractors that are widely implicated, periodic and quasi-periodic attractors\ncan also support learning arbitrarily long temporal relationships. Unlike the\ncontinuous attractors that suffer from the fine-tuning problem, the less\nexplored quasi-periodic attractors are uniquely qualified for learning to\nproduce temporally structured behavior. Our theory has broad implications for\nthe design of artificial learning systems and makes predictions about\nobservable signatures of biological neural dynamics that can support temporal\ndependence learning and working memory. Based on our theory, we developed a new\ninitialization scheme for artificial recurrent neural networks that outperforms\nstandard methods for tasks that require learning temporal dynamics. Moreover,\nwe propose a robust recurrent memory mechanism for integrating and maintaining\nhead direction without a ring attractor.",
          "link": "http://arxiv.org/abs/2308.12585",
          "publishedOn": "2023-08-26T00:39:49.879Z",
          "wordCount": null,
          "title": "Persistent learning signals and working memory without continuous attractors. (arXiv:2308.12585v1 [q-bio.NC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.09355",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shwartz_Ziv_R/0/1/0/all/0/1\">Ravid Shwartz-Ziv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1\">Yann LeCun</a>",
          "description": "\\begin{abstract} Deep neural networks excel in supervised learning tasks but\nare constrained by the need for extensive labeled data. Self-supervised\nlearning emerges as a promising alternative, allowing models to learn without\nexplicit labels. Information theory, and notably the information bottleneck\nprinciple, has been pivotal in shaping deep neural networks. This principle\nfocuses on optimizing the trade-off between compression and preserving relevant\ninformation, providing a foundation for efficient network design in supervised\ncontexts. However, its precise role and adaptation in self-supervised learning\nremain unclear. In this work, we scrutinize various self-supervised learning\napproaches from an information-theoretic perspective, introducing a unified\nframework that encapsulates the self-supervised information-theoretic learning\nproblem. We weave together existing research into a cohesive narrative, delve\ninto contemporary self-supervised methodologies, and spotlight potential\nresearch avenues and inherent challenges. Additionally, we discuss the\nempirical evaluation of information-theoretic quantities and their estimation\nmethods. Overall, this paper furnishes an exhaustive review of the intersection\nof information theory, self-supervised learning, and deep neural networks.",
          "link": "http://arxiv.org/abs/2304.09355",
          "publishedOn": "2023-08-26T00:39:49.879Z",
          "wordCount": null,
          "title": "To Compress or Not to Compress- Self-Supervised Learning and Information Theory: A Review. (arXiv:2304.09355v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.07134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ye_R/0/1/0/all/0/1\">Ruosong Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Caiqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Runhui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>",
          "description": "The emergence of large-scale pre-trained language models, such as ChatGPT,\nhas revolutionized various research fields in artificial intelligence.\nTransformers-based large language models (LLMs) have gradually replaced CNNs\nand RNNs to unify fields of computer vision and natural language processing.\nCompared with the data that exists relatively independently such as images,\nvideos or texts, graph is a type of data that contains rich structural and\nrelational information. Meanwhile, natural language, as one of the most\nexpressive mediums, excels in describing complex structures. However, existing\nwork on incorporating graph learning problems into the generative language\nmodeling framework remains very limited. As the importance of large language\nmodels continues to grow, it becomes essential to explore whether LLMs can also\nreplace GNNs as the foundation model for graphs. In this paper, we propose\nInstructGLM (Instruction-finetuned Graph Language Model), systematically design\nhighly scalable prompts based on natural language instructions, and use natural\nlanguage to describe the geometric structure and node features of the graph for\ninstruction tuning an LLM to perform learning and inference on graphs in a\ngenerative manner. Our method exceeds all competitive GNN baselines on\nogbn-arxiv, Cora and PubMed datasets, which demonstrates the effectiveness of\nour method and sheds light on generative large language models as the\nfoundation model for graph machine learning.",
          "link": "http://arxiv.org/abs/2308.07134",
          "publishedOn": "2023-08-26T00:39:49.879Z",
          "wordCount": null,
          "title": "Natural Language is All a Graph Needs. (arXiv:2308.07134v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Patel_P/0/1/0/all/0/1\">Pratyush Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choukse_E/0/1/0/all/0/1\">Esha Choukse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chaojie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goiri_I/0/1/0/all/0/1\">&#xcd;&#xf1;igo Goiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warrier_B/0/1/0/all/0/1\">Brijesh Warrier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahalingam_N/0/1/0/all/0/1\">Nithish Mahalingam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bianchini_R/0/1/0/all/0/1\">Ricardo Bianchini</a>",
          "description": "Recent innovation in large language models (LLMs), and their myriad use-cases\nhave rapidly driven up the compute capacity demand for datacenter GPUs. Several\ncloud providers and other enterprises have made substantial plans of growth in\ntheir datacenters to support these new workloads. One of the key bottleneck\nresources in datacenters is power, and given the increasing model sizes of\nLLMs, they are becoming increasingly power intensive. In this paper, we show\nthat there is a significant opportunity to oversubscribe power in LLM clusters.\nPower oversubscription improves the power efficiency of these datacenters,\nallowing more deployable servers per datacenter, and reduces the deployment\ntime, since building new datacenters is slow.\n\nWe extensively characterize the power consumption patterns of a variety of\nLLMs and their configurations. We identify the differences between the\ninference and training power consumption patterns. Based on our analysis of\nthese LLMs, we claim that the average and peak power utilization in LLM\nclusters for inference should not be very high. Our deductions align with the\ndata from production LLM clusters, revealing that inference workloads offer\nsubstantial headroom for power oversubscription. However, the stringent set of\ntelemetry and controls that GPUs offer in a virtualized environment, makes it\nchallenging to have a reliable and robust power oversubscription mechanism.\n\nWe propose POLCA, our framework for power oversubscription that is robust,\nreliable, and readily deployable for GPU clusters. Using open-source models to\nreplicate the power patterns observed in production, we simulate POLCA and\ndemonstrate that we can deploy 30% more servers in the same GPU cluster for\ninference, with minimal performance loss",
          "link": "http://arxiv.org/abs/2308.12908",
          "publishedOn": "2023-08-26T00:39:49.878Z",
          "wordCount": null,
          "title": "POLCA: Power Oversubscription in LLM Cloud Providers. (arXiv:2308.12908v1 [cs.DC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.11723",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bauer_A/0/1/0/all/0/1\">Alexander Bauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakajima_S/0/1/0/all/0/1\">Shinichi Nakajima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_K/0/1/0/all/0/1\">Klaus-Robert M&#xfc;ller</a>",
          "description": "Deep autoencoders provide an effective tool for learning non-linear\ndimensionality reduction in an unsupervised way. Recently, they have been used\nfor the task of anomaly detection in the visual domain. By optimizing for the\nreconstruction error using anomaly-free examples, the common belief is that a\ncorresponding network should fail to accurately reconstruct anomalous regions\nin the application phase. This goal is typically addressed by controlling the\ncapacity of the network, either by reducing the size of the bottleneck layer or\nby enforcing sparsity constraints on the activations. However, neither of these\ntechniques does explicitly penalize reconstruction of anomalous signals often\nresulting in poor detection. We tackle this problem by adapting a\nself-supervised learning regime that allows the use of discriminative\ninformation during training but focuses on the data manifold of normal\nexamples. We emphasize that inference with our approach is very efficient\nduring training and prediction requiring a single forward pass for each input\nimage. Our experiments on the MVTec AD dataset demonstrate high detection and\nlocalization performance. On the texture-subset, in particular, our approach\nconsistently outperforms recent anomaly detection methods by a significant\nmargin.",
          "link": "http://arxiv.org/abs/2206.11723",
          "publishedOn": "2023-08-26T00:39:49.878Z",
          "wordCount": null,
          "title": "Self-Supervised Training with Autoencoders for Visual Anomaly Detection. (arXiv:2206.11723v4 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12896",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Landeghem_J/0/1/0/all/0/1\">Jordy Van Landeghem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biswas_S/0/1/0/all/0/1\">Sanket Biswas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blaschko_M/0/1/0/all/0/1\">Matthew B. Blaschko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moens_M/0/1/0/all/0/1\">Marie-Francine Moens</a>",
          "description": "This paper highlights the need to bring document classification benchmarking\ncloser to real-world applications, both in the nature of data tested ($X$:\nmulti-channel, multi-paged, multi-industry; $Y$: class distributions and label\nset variety) and in classification tasks considered ($f$: multi-page document,\npage stream, and document bundle classification, ...). We identify the lack of\npublic multi-page document classification datasets, formalize different\nclassification tasks arising in application scenarios, and motivate the value\nof targeting efficient multi-page document representations. An experimental\nstudy on proposed multi-page document classification datasets demonstrates that\ncurrent benchmarks have become irrelevant and need to be updated to evaluate\ncomplete documents, as they naturally occur in practice. This reality check\nalso calls for more mature evaluation methodologies, covering calibration\nevaluation, inference complexity (time-memory), and a range of realistic\ndistribution shifts (e.g., born-digital vs. scanning noise, shifting page\norder). Our study ends on a hopeful note by recommending concrete avenues for\nfuture improvements.}",
          "link": "http://arxiv.org/abs/2308.12896",
          "publishedOn": "2023-08-26T00:39:49.877Z",
          "wordCount": null,
          "title": "Beyond Document Page Classification: Design, Datasets, and Challenges. (arXiv:2308.12896v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.17058",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zaiser_F/0/1/0/all/0/1\">Fabian Zaiser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murawski_A/0/1/0/all/0/1\">Andrzej S. Murawski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_L/0/1/0/all/0/1\">Luke Ong</a>",
          "description": "We present an exact Bayesian inference method for discrete statistical\nmodels, which can find exact solutions to many discrete inference problems,\neven with infinite support and continuous priors. To express such models, we\nintroduce a probabilistic programming language that supports discrete and\ncontinuous sampling, discrete observations, affine functions, (stochastic)\nbranching, and conditioning on events. Our key tool is probability generating\nfunctions: they provide a compact closed-form representation of distributions\nthat are definable by programs, thus enabling the exact computation of\nposterior probabilities, expectation, variance, and higher moments. Our\ninference method is provably correct, fully automated and uses automatic\ndifferentiation (specifically, Taylor polynomials), but does not require\ncomputer algebra. Our experiments show that its performance on a range of\nreal-world examples is competitive with approximate Monte Carlo methods, while\navoiding approximation errors.",
          "link": "http://arxiv.org/abs/2305.17058",
          "publishedOn": "2023-08-26T00:39:49.877Z",
          "wordCount": null,
          "title": "Exact Bayesian Inference on Discrete Models via Probability Generating Functions: A Probabilistic Programming Approach. (arXiv:2305.17058v2 [cs.PL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.04706",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shanshan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haoxuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qingsong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chunyuan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Li Liu</a>",
          "description": "Multimedia recommendation involves personalized ranking tasks, where\nmultimedia content is usually represented using a generic encoder. However,\nthese generic representations introduce spurious correlations that fail to\nreveal users' true preferences. Existing works attempt to alleviate this\nproblem by learning invariant representations, but overlook the balance between\nindependent and identically distributed (IID) and out-of-distribution (OOD)\ngeneralization. In this paper, we propose a framework called Pareto Invariant\nRepresentation Learning (PaInvRL) to mitigate the impact of spurious\ncorrelations from an IID-OOD multi-objective optimization perspective, by\nlearning invariant representations (intrinsic factors that attract user\nattention) and variant representations (other factors) simultaneously.\nSpecifically, PaInvRL includes three iteratively executed modules: (i)\nheterogeneous identification module, which identifies the heterogeneous\nenvironments to reflect distributional shifts for user-item interactions; (ii)\ninvariant mask generation module, which learns invariant masks based on the\nPareto-optimal solutions that minimize the adaptive weighted Invariant Risk\nMinimization (IRM) and Empirical Risk (ERM) losses; (iii) convert module, which\ngenerates both variant representations and item-invariant representations for\ntraining a multi-modal recommendation model that mitigates spurious\ncorrelations and balances the generalization performance within and cross the\nenvironmental distributions. We compare the proposed PaInvRL with\nstate-of-the-art recommendation models on three public multimedia\nrecommendation datasets (Movielens, Tiktok, and Kwai), and the experimental\nresults validate the effectiveness of PaInvRL for both within- and\ncross-environmental learning.",
          "link": "http://arxiv.org/abs/2308.04706",
          "publishedOn": "2023-08-26T00:39:49.877Z",
          "wordCount": null,
          "title": "Pareto Invariant Representation Learning for Multimedia Recommendation. (arXiv:2308.04706v2 [cs.IR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12902",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shakibania_H/0/1/0/all/0/1\">Hossein Shakibania</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raoufi_S/0/1/0/all/0/1\">Sina Raoufi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khotanlou_H/0/1/0/all/0/1\">Hassan Khotanlou</a>",
          "description": "Low-light images, characterized by inadequate illumination, pose challenges\nof diminished clarity, muted colors, and reduced details. Low-light image\nenhancement, an essential task in computer vision, aims to rectify these issues\nby improving brightness, contrast, and overall perceptual quality, thereby\nfacilitating accurate analysis and interpretation. This paper introduces the\nConvolutional Dense Attention-guided Network (CDAN), a novel solution for\nenhancing low-light images. CDAN integrates an autoencoder-based architecture\nwith convolutional and dense blocks, complemented by an attention mechanism and\nskip connections. This architecture ensures efficient information propagation\nand feature learning. Furthermore, a dedicated post-processing phase refines\ncolor balance and contrast. Our approach demonstrates notable progress compared\nto state-of-the-art results in low-light image enhancement, showcasing its\nrobustness across a wide range of challenging scenarios. Our model performs\nremarkably on benchmark datasets, effectively mitigating under-exposure and\nproficiently restoring textures and colors in diverse low-light scenarios. This\nachievement underscores CDAN's potential for diverse computer vision tasks,\nnotably enabling robust object detection and recognition in challenging\nlow-light conditions.",
          "link": "http://arxiv.org/abs/2308.12902",
          "publishedOn": "2023-08-26T00:39:49.876Z",
          "wordCount": null,
          "title": "CDAN: Convolutional Dense Attention-guided Network for Low-light Image Enhancement. (arXiv:2308.12902v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.06965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qiang_B/0/1/0/all/0/1\">Bo Qiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yiran Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yuheng Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Ningfeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Song Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Liangren Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1\">Bo Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhenming Liu</a>",
          "description": "Chemical reactions are the fundamental building blocks of drug design and\norganic chemistry research. In recent years, there has been a growing need for\na large-scale deep-learning framework that can efficiently capture the basic\nrules of chemical reactions. In this paper, we have proposed a unified\nframework that addresses both the reaction representation learning and molecule\ngeneration tasks, which allows for a more holistic approach. Inspired by the\norganic chemistry mechanism, we develop a novel pretraining framework that\nenables us to incorporate inductive biases into the model. Our framework\nachieves state-of-the-art results on challenging downstream tasks. By\npossessing chemical knowledge, our generative framework overcome the\nlimitations of current molecule generation models that rely on a small number\nof reaction templates. In the extensive experiments, our model generates\nsynthesizable drug-like structures of high quality. Overall, our work presents\na significant step toward a large-scale deep-learning framework for a variety\nof reaction-based applications.",
          "link": "http://arxiv.org/abs/2303.06965",
          "publishedOn": "2023-08-26T00:39:49.876Z",
          "wordCount": null,
          "title": "Bridging the Gap between Chemical Reaction Pretraining and Conditional Molecule Generation with a Unified Model. (arXiv:2303.06965v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.01975",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Geng_J/0/1/0/all/0/1\">Jiahui Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zongxiong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuandou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woisetschlaeger_H/0/1/0/all/0/1\">Herbert Woisetschlaeger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schimmler_S/0/1/0/all/0/1\">Sonja Schimmler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mayer_R/0/1/0/all/0/1\">Ruben Mayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhiming Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rong_C/0/1/0/all/0/1\">Chunming Rong</a>",
          "description": "Dataset distillation is attracting more attention in machine learning as\ntraining sets continue to grow and the cost of training state-of-the-art models\nbecomes increasingly high. By synthesizing datasets with high information\ndensity, dataset distillation offers a range of potential applications,\nincluding support for continual learning, neural architecture search, and\nprivacy protection. Despite recent advances, we lack a holistic understanding\nof the approaches and applications. Our survey aims to bridge this gap by first\nproposing a taxonomy of dataset distillation, characterizing existing\napproaches, and then systematically reviewing the data modalities, and related\napplications. In addition, we summarize the challenges and discuss future\ndirections for this field of research.",
          "link": "http://arxiv.org/abs/2305.01975",
          "publishedOn": "2023-08-26T00:39:49.876Z",
          "wordCount": null,
          "title": "A Survey on Dataset Distillation: Approaches, Applications and Future Directions. (arXiv:2305.01975v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.14343",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jiawei Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chengkai Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1\">Wenjun Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingyuan Wang</a>",
          "description": "As deep learning technology advances and more urban spatial-temporal data\naccumulates, an increasing number of deep learning models are being proposed to\nsolve urban spatial-temporal prediction problems. However, there are\nlimitations in the existing field, including open-source data being in various\nformats and difficult to use, few papers making their code and data openly\navailable, and open-source models often using different frameworks and\nplatforms, making comparisons challenging. A standardized framework is urgently\nneeded to implement and evaluate these methods. To address these issues, we\nprovide a comprehensive review of urban spatial-temporal prediction and propose\na unified storage format for spatial-temporal data called atomic files. We also\npropose LibCity, an open-source library that offers researchers a credible\nexperimental tool and a convenient development framework. In this library, we\nhave reproduced 65 spatial-temporal prediction models and collected 55\nspatial-temporal datasets, allowing researchers to conduct comprehensive\nexperiments conveniently. Using LibCity, we conducted a series of experiments\nto validate the effectiveness of different models and components, and we\nsummarized promising future technology developments and research directions for\nspatial-temporal prediction. By enabling fair model comparisons, designing a\nunified data storage format, and simplifying the process of developing new\nmodels, LibCity is poised to make significant contributions to the\nspatial-temporal prediction field.",
          "link": "http://arxiv.org/abs/2304.14343",
          "publishedOn": "2023-08-26T00:39:49.875Z",
          "wordCount": null,
          "title": "Towards Efficient and Comprehensive Urban Spatial-Temporal Prediction: A Unified Library and Performance Benchmark. (arXiv:2304.14343v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12857",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1\">Mengnan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lihe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_Y/0/1/0/all/0/1\">Yuqiu Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1\">Baocai Yin</a>",
          "description": "Fast adversarial training (FAT) is beneficial for improving the adversarial\nrobustness of neural networks. However, previous FAT work has encountered a\nsignificant issue known as catastrophic overfitting when dealing with large\nperturbation budgets, \\ie the adversarial robustness of models declines to near\nzero during training.\n\nTo address this, we analyze the training process of prior FAT work and\nobserve that catastrophic overfitting is accompanied by the appearance of loss\nconvergence outliers.\n\nTherefore, we argue a moderately smooth loss convergence process will be a\nstable FAT process that solves catastrophic overfitting.\n\nTo obtain a smooth loss convergence process, we propose a novel oscillatory\nconstraint (dubbed ConvergeSmooth) to limit the loss difference between\nadjacent epochs. The convergence stride of ConvergeSmooth is introduced to\nbalance convergence and smoothing. Likewise, we design weight centralization\nwithout introducing additional hyperparameters other than the loss balance\ncoefficient.\n\nOur proposed methods are attack-agnostic and thus can improve the training\nstability of various FAT techniques.\n\nExtensive experiments on popular datasets show that the proposed methods\nefficiently avoid catastrophic overfitting and outperform all previous FAT\nmethods. Code is available at \\url{https://github.com/FAT-CS/ConvergeSmooth}.",
          "link": "http://arxiv.org/abs/2308.12857",
          "publishedOn": "2023-08-26T00:39:49.874Z",
          "wordCount": null,
          "title": "Fast Adversarial Training with Smooth Convergence. (arXiv:2308.12857v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1910.09642",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vareto_R/0/1/0/all/0/1\">Rafael Henrique Vareto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandanha_A/0/1/0/all/0/1\">Araceli Marcia Sandanha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwartz_W/0/1/0/all/0/1\">William Robson Schwartz</a>",
          "description": "A face spoofing attack occurs when an intruder attempts to impersonate\nsomeone who carries a gainful authentication clearance. It is a trending topic\ndue to the increasing demand for biometric authentication on mobile devices,\nhigh-security areas, among others. This work introduces a new database named\nSense Wax Attack dataset (SWAX), comprised of real human and wax figure images\nand videos that endorse the problem of face spoofing detection. The dataset\nconsists of more than 1800 face images and 110 videos of 55 people/waxworks,\narranged in training, validation and test sets with a large range in\nexpression, illumination and pose variations. Experiments performed with\nbaseline methods show that despite the progress in recent years, advanced\nspoofing methods are still vulnerable to high-quality violation attempts.",
          "link": "http://arxiv.org/abs/1910.09642",
          "publishedOn": "2023-08-26T00:39:49.873Z",
          "wordCount": null,
          "title": "The SWAX Benchmark: Attacking Biometric Systems with Wax Figures. (arXiv:1910.09642v1 [cs.CV] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.07445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vareto_R/0/1/0/all/0/1\">Rafael Henrique Vareto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwartz_W/0/1/0/all/0/1\">William Robson Schwartz</a>",
          "description": "Open-set face recognition describes a scenario where unknown subjects, unseen\nduring the training stage, appear on test time. Not only it requires methods\nthat accurately identify individuals of interest, but also demands approaches\nthat effectively deal with unfamiliar faces. This work details a scalable\nopen-set face identification approach to galleries composed of hundreds and\nthousands of subjects. It is composed of clustering and an ensemble of binary\nlearning algorithms that estimates when query face samples belong to the face\ngallery and then retrieves their correct identity. The approach selects the\nmost suitable gallery subjects and uses the ensemble to improve prediction\nperformance. We carry out experiments on well-known LFW and YTF benchmarks.\nResults show that competitive performance can be achieved even when targeting\nscalability.",
          "link": "http://arxiv.org/abs/2308.07445",
          "publishedOn": "2023-08-26T00:39:49.873Z",
          "wordCount": null,
          "title": "Open-set Face Recognition using Ensembles trained on Clustered Data. (arXiv:2308.07445v1 [cs.CV] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.00939",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1\">Susung Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1\">Gyuseong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_W/0/1/0/all/0/1\">Wooseok Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seungryong Kim</a>",
          "description": "Denoising diffusion models (DDMs) have attracted attention for their\nexceptional generation quality and diversity. This success is largely\nattributed to the use of class- or text-conditional diffusion guidance methods,\nsuch as classifier and classifier-free guidance. In this paper, we present a\nmore comprehensive perspective that goes beyond the traditional guidance\nmethods. From this generalized perspective, we introduce novel condition- and\ntraining-free strategies to enhance the quality of generated images. As a\nsimple solution, blur guidance improves the suitability of intermediate samples\nfor their fine-scale information and structures, enabling diffusion models to\ngenerate higher quality samples with a moderate guidance scale. Improving upon\nthis, Self-Attention Guidance (SAG) uses the intermediate self-attention maps\nof diffusion models to enhance their stability and efficacy. Specifically, SAG\nadversarially blurs only the regions that diffusion models attend to at each\niteration and guides them accordingly. Our experimental results show that our\nSAG improves the performance of various diffusion models, including ADM, IDDPM,\nStable Diffusion, and DiT. Moreover, combining SAG with conventional guidance\nmethods leads to further improvement.",
          "link": "http://arxiv.org/abs/2210.00939",
          "publishedOn": "2023-08-26T00:39:49.872Z",
          "wordCount": null,
          "title": "Improving Sample Quality of Diffusion Models Using Self-Attention Guidance. (arXiv:2210.00939v6 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.03543",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wydmanski_W/0/1/0/all/0/1\">Witold Wydma&#x144;ski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bulenok_O/0/1/0/all/0/1\">Oleksii Bulenok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smieja_M/0/1/0/all/0/1\">Marek &#x15a;mieja</a>",
          "description": "Deep learning has achieved impressive performance in many domains, such as\ncomputer vision and natural language processing, but its advantage over\nclassical shallow methods on tabular datasets remains questionable. It is\nespecially challenging to surpass the performance of tree-like ensembles, such\nas XGBoost or Random Forests, on small-sized datasets (less than 1k samples).\nTo tackle this challenge, we introduce HyperTab, a hypernetwork-based approach\nto solving small sample problems on tabular datasets. By combining the\nadvantages of Random Forests and neural networks, HyperTab generates an\nensemble of neural networks, where each target model is specialized to process\na specific lower-dimensional view of the data. Since each view plays the role\nof data augmentation, we virtually increase the number of training samples\nwhile keeping the number of trainable parameters unchanged, which prevents\nmodel overfitting. We evaluated HyperTab on more than 40 tabular datasets of a\nvarying number of samples and domains of origin, and compared its performance\nwith shallow and deep learning models representing the current\nstate-of-the-art. We show that HyperTab consistently outranks other methods on\nsmall data (with a statistically significant difference) and scores comparable\nto them on larger datasets.\n\nWe make a python package with the code available to download at\nhttps://pypi.org/project/hypertab/",
          "link": "http://arxiv.org/abs/2304.03543",
          "publishedOn": "2023-08-26T00:39:49.872Z",
          "wordCount": null,
          "title": "HyperTab: Hypernetwork Approach for Deep Learning on Small Tabular Datasets. (arXiv:2304.03543v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12661",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gavrikov_P/0/1/0/all/0/1\">Paul Gavrikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keuper_J/0/1/0/all/0/1\">Janis Keuper</a>",
          "description": "Assessing the robustness of deep neural networks against out-of-distribution\ninputs is crucial, especially in safety-critical domains like autonomous\ndriving, but also in safety systems where malicious actors can digitally alter\ninputs to circumvent safety guards. However, designing effective\nout-of-distribution tests that encompass all possible scenarios while\npreserving accurate label information is a challenging task. Existing\nmethodologies often entail a compromise between variety and constraint levels\nfor attacks and sometimes even both. In a first step towards a more holistic\nrobustness evaluation of image classification models, we introduce an attack\nmethod based on image solarization that is conceptually straightforward yet\navoids jeopardizing the global structure of natural images independent of the\nintensity. Through comprehensive evaluations of multiple ImageNet models, we\ndemonstrate the attack's capacity to degrade accuracy significantly, provided\nit is not integrated into the training augmentations. Interestingly, even then,\nno full immunity to accuracy deterioration is achieved. In other settings, the\nattack can often be simplified into a black-box attack with model-independent\nparameters. Defenses against other corruptions do not consistently extend to be\neffective against our specific attack.\n\nProject website: https://github.com/paulgavrikov/adversarial_solarization",
          "link": "http://arxiv.org/abs/2308.12661",
          "publishedOn": "2023-08-26T00:39:49.871Z",
          "wordCount": null,
          "title": "Don't Look into the Sun: Adversarial Solarization Attacks on Image Classifiers. (arXiv:2308.12661v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.01075",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Cleaveland_M/0/1/0/all/0/1\">Matthew Cleaveland</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_I/0/1/0/all/0/1\">Insup Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pappas_G/0/1/0/all/0/1\">George J. Pappas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lindemann_L/0/1/0/all/0/1\">Lars Lindemann</a>",
          "description": "Conformal prediction is a statistical tool for producing prediction regions\nof machine learning models that are valid with high probability. However,\napplying conformal prediction to time series data leads to conservative\nprediction regions. In fact, to obtain prediction regions over $T$ time steps\nwith confidence $1-\\delta$, {previous works require that each individual\nprediction region is valid} with confidence $1-\\delta/T$. We propose an\noptimization-based method for reducing this conservatism to enable long horizon\nplanning and verification when using learning-enabled time series predictors.\nInstead of considering prediction errors individually at each time step, we\nconsider a parameterized prediction error over multiple time steps. By\noptimizing the parameters over an additional dataset, we find prediction\nregions that are not conservative. We show that this problem can be cast as a\nmixed integer linear complementarity program (MILCP), which we then relax into\na linear complementarity program (LCP). Additionally, we prove that the relaxed\nLP has the same optimal cost as the original MILCP. Finally, we demonstrate the\nefficacy of our method on case studies using pedestrian trajectory predictors\nand F16 fighter jet altitude predictors.",
          "link": "http://arxiv.org/abs/2304.01075",
          "publishedOn": "2023-08-26T00:39:49.870Z",
          "wordCount": null,
          "title": "Conformal Prediction Regions for Time Series using Linear Complementarity Programming. (arXiv:2304.01075v3 [eess.SY] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12000",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_P/0/1/0/all/0/1\">Po-An Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ariu_K/0/1/0/all/0/1\">Kaito Ariu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Proutiere_A/0/1/0/all/0/1\">Alexandre Proutiere</a>",
          "description": "We study the problem of best-arm identification with fixed budget in\nstochastic two-arm bandits with Bernoulli rewards. We prove that surprisingly,\nthere is no algorithm that (i) performs as well as the algorithm sampling each\narm equally (this algorithm is referred to as the {\\it uniform sampling}\nalgorithm) on all instances, and that (ii) strictly outperforms this algorithm\non at least one instance. In short, there is no algorithm better than the\nuniform sampling algorithm. Towards this result, we introduce the natural class\nof {\\it consistent} and {\\it stable} algorithms, and show that any algorithm\nthat performs as well as the uniform sampling algorithm on all instances\nbelongs to this class. The proof is completed by deriving a lower bound on the\nerror rate satisfied by any consistent and stable algorithm, and by showing\nthat the uniform sampling algorithm matches this lower bound. Our results\nprovide a solution to the two open problems presented in \\cite{qin2022open}.",
          "link": "http://arxiv.org/abs/2308.12000",
          "publishedOn": "2023-08-26T00:39:49.870Z",
          "wordCount": null,
          "title": "On Uniformly Optimal Algorithms for Best Arm Identification in Two-Armed Bandits with Fixed Budget. (arXiv:2308.12000v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12670",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Drent_C/0/1/0/all/0/1\">Collin Drent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drent_M/0/1/0/all/0/1\">Melvin Drent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houtum_G/0/1/0/all/0/1\">Geert-Jan van Houtum</a>",
          "description": "This paper addresses the benefits of pooling data for shared learning in\nmaintenance operations. We consider a set of systems subject to Poisson\ndegradation that are coupled through an a-priori unknown rate. Decision\nproblems involving these systems are high-dimensional Markov decision processes\n(MDPs). We present a decomposition result that reduces such an MDP to\ntwo-dimensional MDPs, enabling structural analyses and computations. We\nleverage this decomposition to demonstrate that pooling data can lead to\nsignificant cost reductions compared to not pooling.",
          "link": "http://arxiv.org/abs/2308.12670",
          "publishedOn": "2023-08-26T00:39:49.869Z",
          "wordCount": null,
          "title": "Optimal data pooling for shared learning in maintenance operations. (arXiv:2308.12670v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12575",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuxi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhenhao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_S/0/1/0/all/0/1\">Shaowen Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salim_F/0/1/0/all/0/1\">Flora D. Salim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yepes_A/0/1/0/all/0/1\">Antonio Jimeno Yepes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Jun Shen</a>",
          "description": "The Intensive Care Unit (ICU) is one of the most important parts of a\nhospital, which admits critically ill patients and provides continuous\nmonitoring and treatment. Various patient outcome prediction methods have been\nattempted to assist healthcare professionals in clinical decision-making.\nExisting methods focus on measuring the similarity between patients using deep\nneural networks to capture the hidden feature structures. However, the\nhigher-order relationships are ignored, such as patient characteristics (e.g.,\ndiagnosis codes) and their causal effects on downstream clinical predictions.\n\nIn this paper, we propose a novel Hypergraph Convolutional Network that\nallows the representation of non-pairwise relationships among diagnosis codes\nin a hypergraph to capture the hidden feature structures so that fine-grained\npatient similarity can be calculated for personalized mortality risk\nprediction. Evaluation using a publicly available eICU Collaborative Research\nDatabase indicates that our method achieves superior performance over the\nstate-of-the-art models on mortality risk prediction. Moreover, the results of\nseveral case studies demonstrated the effectiveness of constructing graph\nnetworks in providing good transparency and robustness in decision-making.",
          "link": "http://arxiv.org/abs/2308.12575",
          "publishedOn": "2023-08-26T00:39:49.867Z",
          "wordCount": null,
          "title": "Hypergraph Convolutional Networks for Fine-grained ICU Patient Similarity Analysis and Risk Prediction. (arXiv:2308.12575v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.09113",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tang_H/0/1/0/all/0/1\">Hewei Tang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kong_Q/0/1/0/all/0/1\">Qingkai Kong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Morris_J/0/1/0/all/0/1\">Joseph P. Morris</a>",
          "description": "Deep learning-based surrogate models have been widely applied in geological\ncarbon storage (GCS) problems to accelerate the prediction of reservoir\npressure and CO2 plume migration. Large amounts of data from physics-based\nnumerical simulators are required to train a model to accurately predict the\ncomplex physical behaviors associated with this process. In practice, the\navailable training data are always limited in large-scale 3D problems due to\nthe high computational cost. Therefore, we propose to use a multi-fidelity\nFourier Neural Operator to solve large-scale GCS problems with more affordable\nmulti-fidelity training datasets. The Fourier Neural Operator has a desirable\ngrid-invariant property, which simplifies the transfer learning procedure\nbetween datasets with different discretization. We first test the model\nefficacy on a GCS reservoir model being discretized into 110k grid cells. The\nmulti-fidelity model can predict with accuracy comparable to a high-fidelity\nmodel trained with the same amount of high-fidelity data with 81% less data\ngeneration costs. We further test the generalizability of the multi-fidelity\nmodel on a same reservoir model with a finer discretization of 1 million grid\ncells. This case was made more challenging by employing high-fidelity and\nlow-fidelity datasets generated by different geostatistical models and\nreservoir simulators. We observe that the multi-fidelity FNO model can predict\npressure fields with reasonable accuracy even when the high-fidelity data are\nextremely limited.",
          "link": "http://arxiv.org/abs/2308.09113",
          "publishedOn": "2023-08-26T00:39:49.867Z",
          "wordCount": null,
          "title": "Multi-fidelity Fourier Neural Operator for Fast Modeling of Large-Scale Geological Carbon Storage. (arXiv:2308.09113v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.11881",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rafid_A/0/1/0/all/0/1\">Ali Haisam Muhammad Rafid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandu_A/0/1/0/all/0/1\">Adrian Sandu</a>",
          "description": "Deep neural networks (DNN) have found wide applicability in numerous fields\ndue to their ability to accurately learn very complex input-output relations.\nDespite their accuracy and extensive use, DNNs are highly susceptible to\nadversarial attacks due to limited generalizability. For future progress in the\nfield, it is essential to build DNNs that are robust to any kind of\nperturbations to the data points. In the past, many techniques have been\nproposed to robustify DNNs using first-order derivative information of the\nnetwork.\n\nThis paper proposes a new robustification approach based on control theory. A\nneural network architecture that incorporates feedback control, named Feedback\nNeural Networks, is proposed. The controller is itself a neural network, which\nis trained using regular and adversarial data such as to stabilize the system\noutputs. The novel adversarial training approach based on the feedback control\narchitecture is called Feedback Looped Adversarial Training (FLAT). Numerical\nresults on standard test problems empirically show that our FLAT method is more\neffective than the state-of-the-art to guard against adversarial attacks.",
          "link": "http://arxiv.org/abs/2308.11881",
          "publishedOn": "2023-08-26T00:39:49.867Z",
          "wordCount": null,
          "title": "Adversarial Training Using Feedback Loops. (arXiv:2308.11881v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.06228",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1\">Yingwen Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_S/0/1/0/all/0/1\">Sizhe Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fang_K/0/1/0/all/0/1\">Kun Fang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_X/0/1/0/all/0/1\">Xiaolin Huang</a>",
          "description": "The wide application of deep neural networks (DNNs) demands an increasing\namount of attention to their real-world robustness, i.e., whether a DNN resists\nblack-box adversarial attacks, among which score-based query attacks (SQAs) are\nmost threatening since they can effectively hurt a victim network with the only\naccess to model outputs. Defending against SQAs requires a slight but artful\nvariation of outputs due to the service purpose for users, who share the same\noutput information with SQAs. In this paper, we propose a real-world defense by\nUnifying Gradients (UniG) of different data so that SQAs could only probe a\nmuch weaker attack direction that is similar for different samples. Since such\nuniversal attack perturbations have been validated as less aggressive than the\ninput-specific perturbations, UniG protects real-world DNNs by indicating\nattackers a twisted and less informative attack direction. We implement UniG\nefficiently by a Hadamard product module which is plug-and-play. According to\nextensive experiments on 5 SQAs, 2 adaptive attacks and 7 defense baselines,\nUniG significantly improves real-world robustness without hurting clean\naccuracy on CIFAR10 and ImageNet. For instance, UniG maintains a model of\n77.80% accuracy under 2500-query Square attack while the state-of-the-art\nadversarially-trained model only has 67.34% on CIFAR10. Simultaneously, UniG\noutperforms all compared baselines in terms of clean accuracy and achieves the\nsmallest modification of the model output. The code is released at\nhttps://github.com/snowien/UniG-pytorch.",
          "link": "http://arxiv.org/abs/2208.06228",
          "publishedOn": "2023-08-26T00:39:49.866Z",
          "wordCount": null,
          "title": "Unifying Gradients to Improve Real-world Robustness for Deep Networks. (arXiv:2208.06228v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12371",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vareto_R/0/1/0/all/0/1\">Rafael Henrique Vareto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunther_M/0/1/0/all/0/1\">Manuel G&#xfc;nther</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwartz_W/0/1/0/all/0/1\">William Robson Schwartz</a>",
          "description": "Open-set face recognition refers to a scenario in which biometric systems\nhave incomplete knowledge of all existing subjects. Therefore, they are\nexpected to prevent face samples of unregistered subjects from being identified\nas previously enrolled identities. This watchlist context adds an arduous\nrequirement that calls for the dismissal of irrelevant faces by focusing mainly\non subjects of interest. As a response, this work introduces a novel method\nthat associates an ensemble of compact neural networks with a margin-based cost\nfunction that explores additional samples. Supplementary negative samples can\nbe obtained from external databases or synthetically built at the\nrepresentation level in training time with a new mix-up feature augmentation\napproach. Deep neural networks pre-trained on large face datasets serve as the\npreliminary feature extraction module. We carry out experiments on well-known\nLFW and IJB-C datasets where results show that the approach is able to boost\nclosed and open-set identification rates.",
          "link": "http://arxiv.org/abs/2308.12371",
          "publishedOn": "2023-08-26T00:39:49.826Z",
          "wordCount": null,
          "title": "Open-set Face Recognition with Neural Ensemble, Maximal Entropy Loss and Feature Augmentation. (arXiv:2308.12371v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12649",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Galler_H/0/1/0/all/0/1\">Hadar Schreiber Galler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zahavy_T/0/1/0/all/0/1\">Tom Zahavy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desjardins_G/0/1/0/all/0/1\">Guillaume Desjardins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_A/0/1/0/all/0/1\">Alon Cohen</a>",
          "description": "We study diverse skill discovery in reward-free environments, aiming to\ndiscover all possible skills in simple grid-world environments where prior\nmethods have struggled to succeed. This problem is formulated as mutual\ntraining of skills using an intrinsic reward and a discriminator trained to\npredict a skill given its trajectory. Our initial solution replaces the\nstandard one-vs-all (softmax) discriminator with a one-vs-one (all pairs)\ndiscriminator and combines it with a novel intrinsic reward function and a\ndropout regularization technique. The combined approach is named APART: Diverse\nSkill Discovery using All Pairs with Ascending Reward and Dropout. We\ndemonstrate that APART discovers all the possible skills in grid worlds with\nremarkably fewer samples than previous works. Motivated by the empirical\nsuccess of APART, we further investigate an even simpler algorithm that\nachieves maximum skills by altering VIC, rescaling its intrinsic reward, and\ntuning the temperature of its softmax discriminator. We believe our findings\nshed light on the crucial factors underlying success of skill discovery\nalgorithms in reinforcement learning.",
          "link": "http://arxiv.org/abs/2308.12649",
          "publishedOn": "2023-08-26T00:39:49.826Z",
          "wordCount": null,
          "title": "APART: Diverse Skill Discovery using All Pairs with Ascending Reward and DropouT. (arXiv:2308.12649v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12794",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Reijnen_R/0/1/0/all/0/1\">Robbert Reijnen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Straaten_K/0/1/0/all/0/1\">Kjell van Straaten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bukhsh_Z/0/1/0/all/0/1\">Zaharah Bukhsh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yingqian Zhang</a>",
          "description": "We introduce an open-source GitHub repository containing comprehensive\nbenchmarks for a wide range of machine scheduling problems, including Job Shop\nScheduling (JSP), Flow Shop Scheduling (FSP), Flexible Job Shop Scheduling\n(FJSP), FJSP with Assembly constraints (FAJSP), FJSP with Sequence-Dependent\nSetup Times (FJSP-SDST), and the online FJSP (with online job arrivals). Our\nprimary goal is to provide a centralized hub for researchers, practitioners,\nand enthusiasts interested in tackling machine scheduling challenges.",
          "link": "http://arxiv.org/abs/2308.12794",
          "publishedOn": "2023-08-26T00:39:49.825Z",
          "wordCount": null,
          "title": "Job Shop Scheduling Benchmark: Environments and Instances for Learning and Non-learning Methods. (arXiv:2308.12794v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12864",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Perez_S/0/1/0/all/0/1\">Sarah Perez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poncet_P/0/1/0/all/0/1\">Philippe Poncet</a>",
          "description": "In this article, we present a novel data assimilation strategy in pore-scale\nimaging and demonstrate that this makes it possible to robustly address\nreactive inverse problems incorporating Uncertainty Quantification (UQ).\nPore-scale modeling of reactive flow offers a valuable opportunity to\ninvestigate the evolution of macro-scale properties subject to dynamic\nprocesses. Yet, they suffer from imaging limitations arising from the\nassociated X-ray microtomography (X-ray microCT) process, which induces\ndiscrepancies in the properties estimates. Assessment of the kinetic parameters\nalso raises challenges, as reactive coefficients are critical parameters that\ncan cover a wide range of values. We account for these two issues and ensure\nreliable calibration of pore-scale modeling, based on dynamical microCT images,\nby integrating uncertainty quantification in the workflow.\n\nThe present method is based on a multitasking formulation of reactive inverse\nproblems combining data-driven and physics-informed techniques in calcite\ndissolution. This allows quantifying morphological uncertainties on the\nporosity field and estimating reactive parameter ranges through prescribed PDE\nmodels with a latent concentration field and dynamical microCT. The data\nassimilation strategy relies on sequential reinforcement incorporating\nsuccessively additional PDE constraints. We guarantee robust and unbiased\nuncertainty quantification by straightforward adaptive weighting of Bayesian\nPhysics-Informed Neural Networks (BPINNs), ensuring reliable micro-porosity\nchanges during geochemical transformations. We demonstrate successful Bayesian\nInference in 1D+Time and 2D+Time calcite dissolution based on synthetic microCT\nimages with meaningful posterior distribution on the reactive parameters and\ndimensionless numbers.",
          "link": "http://arxiv.org/abs/2308.12864",
          "publishedOn": "2023-08-26T00:39:49.825Z",
          "wordCount": null,
          "title": "Auto-weighted Bayesian Physics-Informed Neural Networks and robust estimations for multitask inverse problems in pore-scale imaging of dissolution. (arXiv:2308.12864v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.03398",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Stromme_A/0/1/0/all/0/1\">Austin J. Stromme</a>",
          "description": "Motivated by the manifold hypothesis, which states that data with a high\nextrinsic dimension may yet have a low intrinsic dimension, we develop refined\nstatistical bounds for entropic optimal transport that are sensitive to the\nintrinsic dimension of the data. Our bounds involve a robust notion of\nintrinsic dimension, measured at only a single distance scale depending on the\nregularization parameter, and show that it is only the minimum of these\nsingle-scale intrinsic dimensions which governs the rate of convergence. We\ncall this the Minimum Intrinsic Dimension scaling (MID scaling) phenomenon, and\nestablish MID scaling with no assumptions on the data distributions so long as\nthe cost is bounded and Lipschitz, and for various entropic optimal transport\nquantities beyond just values, with stronger analogs when one distribution is\nsupported on a manifold. Our results significantly advance the theoretical\nstate of the art by showing that MID scaling is a generic phenomenon, and\nprovide the first rigorous interpretation of the statistical effect of entropic\nregularization as a distance scale.",
          "link": "http://arxiv.org/abs/2306.03398",
          "publishedOn": "2023-08-26T00:39:49.825Z",
          "wordCount": null,
          "title": "Minimum intrinsic dimension scaling for entropic optimal transport. (arXiv:2306.03398v2 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.08847",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Naseri_M/0/1/0/all/0/1\">Mohammad Naseri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yufei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cristofaro_E/0/1/0/all/0/1\">Emiliano De Cristofaro</a>",
          "description": "Federated learning (FL) enables multiple parties to collaboratively train a\nmachine learning model without sharing their data; rather, they train their own\nmodel locally and send updates to a central server for aggregation. Depending\non how the data is distributed among the participants, FL can be classified\ninto Horizontal (HFL) and Vertical (VFL). In VFL, the participants share the\nsame set of training instances but only host a different and non-overlapping\nsubset of the whole feature space. Whereas in HFL, each participant shares the\nsame set of features while the training set is split into locally owned\ntraining data subsets.\n\nVFL is increasingly used in applications like financial fraud detection;\nnonetheless, very little work has analyzed its security. In this paper, we\nfocus on robustness in VFL, in particular, on backdoor attacks, whereby an\nadversary attempts to manipulate the aggregate model during the training\nprocess to trigger misclassifications. Performing backdoor attacks in VFL is\nmore challenging than in HFL, as the adversary i) does not have access to the\nlabels during training and ii) cannot change the labels as she only has access\nto the feature embeddings. We present a first-of-its-kind clean-label backdoor\nattack in VFL, which consists of two phases: a label inference and a backdoor\nphase. We demonstrate the effectiveness of the attack on three different\ndatasets, investigate the factors involved in its success, and discuss\ncountermeasures to mitigate its impact.",
          "link": "http://arxiv.org/abs/2304.08847",
          "publishedOn": "2023-08-26T00:39:49.824Z",
          "wordCount": null,
          "title": "BadVFL: Backdoor Attacks in Vertical Federated Learning. (arXiv:2304.08847v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.08451",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Mousavi_S/0/1/0/all/0/1\">Seyedeh Somayyeh Mousavi</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Reyna_M/0/1/0/all/0/1\">Matthew A. Reyna</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Clifford_G/0/1/0/all/0/1\">Gari D. Clifford</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sameni_R/0/1/0/all/0/1\">Reza Sameni</a>",
          "description": "Regular blood pressure (BP) monitoring in clinical and ambulatory settings\nplays a crucial role in the prevention, diagnosis, treatment, and management of\ncardiovascular diseases. Recently, the widespread adoption of ambulatory BP\nmeasurement devices has been driven predominantly by the increased prevalence\nof hypertension and its associated risks and clinical conditions. Recent\nguidelines advocate for regular BP monitoring as part of regular clinical\nvisits or even at home. This increased utilization of BP measurement\ntechnologies has brought up significant concerns, regarding the accuracy of\nreported BP values across settings.\n\nIn this survey, focusing mainly on cuff-based BP monitoring technologies, we\nhighlight how BP measurements can demonstrate substantial biases and variances\ndue to factors such as measurement and device errors, demographics, and body\nhabitus. With these inherent biases, the development of a new generation of\ncuff-based BP devices which use artificial-intelligence (AI) has significant\npotential. We present future avenues where AI-assisted technologies can\nleverage the extensive clinical literature on BP-related studies together with\nthe large collections of BP records available in electronic health records.\nThese resources can be combined with machine learning approaches, including\ndeep learning and Bayesian inference, to remove BP measurement biases and to\nprovide individualized BP-related cardiovascular risk indexes.",
          "link": "http://arxiv.org/abs/2306.08451",
          "publishedOn": "2023-08-26T00:39:49.823Z",
          "wordCount": null,
          "title": "A Survey on Blood Pressure Measurement Technologies: Addressing Potential Sources of Bias. (arXiv:2306.08451v2 [physics.med-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.12429",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1\">Saurabh Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_C/0/1/0/all/0/1\">Chengpo Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venkataraman_S/0/1/0/all/0/1\">Shivaram Venkataraman</a>",
          "description": "Deep learning based recommendation models (DLRM) are widely used in several\nbusiness critical applications. Training such recommendation models efficiently\nis challenging because they contain billions of embedding-based parameters,\nleading to significant overheads from embedding access. By profiling existing\nsystems for DLRM training, we observe that around 75\\% of the iteration time is\nspent on embedding access and model synchronization. Our key insight in this\npaper is that embedding access has a specific structure which can be used to\naccelerate training. We observe that embedding accesses are heavily skewed,\nwith around 1\\% of embeddings representing more than 92\\% of total accesses.\nFurther, we observe that during offline training we can lookahead at future\nbatches to determine exactly which embeddings will be needed at what iteration\nin the future. Based on these insights, we develop Bagpipe, a system for\ntraining deep recommendation models that uses caching and prefetching to\noverlap remote embedding accesses with the computation. We design an Oracle\nCacher, a new component that uses a lookahead algorithm to generate optimal\ncache update decisions while providing strong consistency guarantees against\nstaleness. We also design a logically replicated, physically partitioned cache\nand show that our design can reduce synchronization overheads in a distributed\nsetting. Finally, we propose a disaggregated system architecture and show that\nour design can enable low-overhead fault tolerance. Our experiments using three\ndatasets and four models show that Bagpipe provides a speed up of up to 5.6x\ncompared to state of the art baselines, while providing the same convergence\nand reproducibility guarantees as synchronous training.",
          "link": "http://arxiv.org/abs/2202.12429",
          "publishedOn": "2023-08-26T00:39:49.822Z",
          "wordCount": null,
          "title": "BagPipe: Accelerating Deep Recommendation Model Training. (arXiv:2202.12429v3 [cs.DC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12740",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ai_L/0/1/0/all/0/1\">Lun Ai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1\">Shi-Shun Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1\">Wang-Zhou Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hallett_L/0/1/0/all/0/1\">Liam Hallett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muggleton_S/0/1/0/all/0/1\">Stephen H. Muggleton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldwin_G/0/1/0/all/0/1\">Geoff S. Baldwin</a>",
          "description": "An important application of Synthetic Biology is the engineering of the host\ncell system to yield useful products. However, an increase in the scale of the\nhost system leads to huge design space and requires a large number of\nvalidation trials with high experimental costs. A comprehensible machine\nlearning approach that efficiently explores the hypothesis space and guides\nexperimental design is urgently needed for the Design-Build-Test-Learn (DBTL)\ncycle of the host cell system. We introduce a novel machine learning framework\nILP-iML1515 based on Inductive Logic Programming (ILP) that performs abductive\nlogical reasoning and actively learns from training examples. In contrast to\nnumerical models, ILP-iML1515 is built on comprehensible logical\nrepresentations of a genome-scale metabolic model and can update the model by\nlearning new logical structures from auxotrophic mutant trials. The ILP-iML1515\nframework 1) allows high-throughput simulations and 2) actively selects\nexperiments that reduce the experimental cost of learning gene functions in\ncomparison to randomly selected experiments.",
          "link": "http://arxiv.org/abs/2308.12740",
          "publishedOn": "2023-08-26T00:39:49.821Z",
          "wordCount": null,
          "title": "Human Comprehensible Active Learning of Genome-Scale Metabolic Networks. (arXiv:2308.12740v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12751",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Starke_P/0/1/0/all/0/1\">Paul Starke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Starke_S/0/1/0/all/0/1\">Sebastian Starke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Komura_T/0/1/0/all/0/1\">Taku Komura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinicke_F/0/1/0/all/0/1\">Frank Steinicke</a>",
          "description": "This paper introduces a novel data-driven motion in-betweening system to\nreach target poses of characters by making use of phases variables learned by a\nPeriodic Autoencoder. Our approach utilizes a mixture-of-experts neural network\nmodel, in which the phases cluster movements in both space and time with\ndifferent expert weights. Each generated set of weights then produces a\nsequence of poses in an autoregressive manner between the current and target\nstate of the character. In addition, to satisfy poses which are manually\nmodified by the animators or where certain end effectors serve as constraints\nto be reached by the animation, a learned bi-directional control scheme is\nimplemented to satisfy such constraints. The results demonstrate that using\nphases for motion in-betweening tasks sharpen the interpolated movements, and\nfurthermore stabilizes the learning process. Moreover, using phases for motion\nin-betweening tasks can also synthesize more challenging movements beyond\nlocomotion behaviors. Additionally, style control is enabled between given\ntarget keyframes. Our proposed framework can compete with popular\nstate-of-the-art methods for motion in-betweening in terms of motion quality\nand generalization, especially in the existence of long transition durations.\nOur framework contributes to faster prototyping workflows for creating animated\ncharacter sequences, which is of enormous interest for the game and film\nindustry.",
          "link": "http://arxiv.org/abs/2308.12751",
          "publishedOn": "2023-08-26T00:39:49.821Z",
          "wordCount": null,
          "title": "Motion In-Betweening with Phase Manifolds. (arXiv:2308.12751v1 [cs.GR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2008.09312",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zuo_S/0/1/0/all/0/1\">Shiliang Zuo</a>",
          "description": "I study a stochastic multi-arm bandit problem where rewards are subject to\nadversarial corruption. I propose a novel attack strategy that manipulates a\nlearner employing the UCB algorithm into pulling some non-optimal target arm $T\n- o(T)$ times with a cumulative cost that scales as $\\widehat{O}(\\sqrt{\\log\nT})$, where $T$ is the number of rounds. I also prove the first lower bound on\nthe cumulative attack cost. The lower bound matches the upper bound up to\n$O(\\log \\log T)$ factors, showing the proposed attack strategy to be near\noptimal.",
          "link": "http://arxiv.org/abs/2008.09312",
          "publishedOn": "2023-08-26T00:39:49.821Z",
          "wordCount": null,
          "title": "Near Optimal Adversarial Attack on UCB Bandits. (arXiv:2008.09312v6 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12820",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kothari_A/0/1/0/all/0/1\">Avni Kothari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulynych_B/0/1/0/all/0/1\">Bogdan Kulynych</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_T/0/1/0/all/0/1\">Tsui-Wei Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ustun_B/0/1/0/all/0/1\">Berk Ustun</a>",
          "description": "Machine learning models are often used to decide who will receive a loan, a\njob interview, or a public benefit. Standard techniques to build these models\nuse features about people but overlook their actionability. In turn, models can\nassign predictions that are fixed, meaning that consumers who are denied loans,\ninterviews, or benefits may be permanently locked out from access to credit,\nemployment, or assistance. In this work, we introduce a formal testing\nprocedure to flag models that assign fixed predictions that we call recourse\nverification. We develop machinery to reliably determine if a given model can\nprovide recourse to its decision subjects from a set of user-specified\nactionability constraints. We demonstrate how our tools can ensure recourse and\nadversarial robustness in real-world datasets and use them to study the\ninfeasibility of recourse in real-world lending datasets. Our results highlight\nhow models can inadvertently assign fixed predictions that permanently bar\naccess, and we provide tools to design algorithms that account for\nactionability when developing models.",
          "link": "http://arxiv.org/abs/2308.12820",
          "publishedOn": "2023-08-26T00:39:49.820Z",
          "wordCount": null,
          "title": "Prediction without Preclusion: Recourse Verification with Reachable Sets. (arXiv:2308.12820v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12885",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Inel_O/0/1/0/all/0/1\">Oana Inel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Draws_T/0/1/0/all/0/1\">Tim Draws</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aroyo_L/0/1/0/all/0/1\">Lora Aroyo</a>",
          "description": "The rapid entry of machine learning approaches in our daily activities and\nhigh-stakes domains demands transparency and scrutiny of their fairness and\nreliability. To help gauge machine learning models' robustness, research\ntypically focuses on the massive datasets used for their deployment, e.g.,\ncreating and maintaining documentation for understanding their origin, process\nof development, and ethical considerations. However, data collection for AI is\nstill typically a one-off practice, and oftentimes datasets collected for a\ncertain purpose or application are reused for a different problem.\nAdditionally, dataset annotations may not be representative over time, contain\nambiguous or erroneous annotations, or be unable to generalize across issues or\ndomains. Recent research has shown these practices might lead to unfair,\nbiased, or inaccurate outcomes. We argue that data collection for AI should be\nperformed in a responsible manner where the quality of the data is thoroughly\nscrutinized and measured through a systematic set of appropriate metrics. In\nthis paper, we propose a Responsible AI (RAI) methodology designed to guide the\ndata collection with a set of metrics for an iterative in-depth analysis of the\nfactors influencing the quality and reliability} of the generated data. We\npropose a granular set of measurements to inform on the internal reliability of\na dataset and its external stability over time. We validate our approach across\nnine existing datasets and annotation tasks and four content modalities. This\napproach impacts the assessment of data robustness used for AI applied in the\nreal world, where diversity of users and content is eminent. Furthermore, it\ndeals with fairness and accountability aspects in data collection by providing\nsystematic and transparent quality analysis for data collections.",
          "link": "http://arxiv.org/abs/2308.12885",
          "publishedOn": "2023-08-26T00:39:49.820Z",
          "wordCount": null,
          "title": "Collect, Measure, Repeat: Reliability Factors for Responsible AI Data Collection. (arXiv:2308.12885v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2010.11925",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gollakota_A/0/1/0/all/0/1\">Aravind Gollakota</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karmalkar_S/0/1/0/all/0/1\">Sushrut Karmalkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klivans_A/0/1/0/all/0/1\">Adam Klivans</a>",
          "description": "We consider the problem of distribution-free learning for Boolean function\nclasses in the PAC and agnostic models. Generalizing a beautiful work of Malach\nand Shalev-Shwartz (2022) that gave tight correlational SQ (CSQ) lower bounds\nfor learning DNF formulas, we give new proofs that lower bounds on the\nthreshold or approximate degree of any function class directly imply CSQ lower\nbounds for PAC or agnostic learning respectively. While such bounds implicitly\nfollow by combining prior results by Feldman (2008, 2012) and Sherstov (2008,\n2011), to our knowledge the precise statements we give had not appeared in this\nform before. Moreover, our proofs are simple and largely self-contained.\n\nThese lower bounds match corresponding positive results using upper bounds on\nthe threshold or approximate degree in the SQ model for PAC or agnostic\nlearning, and in this sense these results show that the polynomial method is a\nuniversal, best-possible approach for distribution-free CSQ learning.",
          "link": "http://arxiv.org/abs/2010.11925",
          "publishedOn": "2023-08-26T00:39:49.820Z",
          "wordCount": null,
          "title": "The Polynomial Method is Universal for Distribution-Free Correlational SQ Learning. (arXiv:2010.11925v3 [cs.DS] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12625",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hua Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuqiong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yushun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_F/0/1/0/all/0/1\">Fuqiang Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zhou Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_B/0/1/0/all/0/1\">Bing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_A/0/1/0/all/0/1\">Ailin Zhao</a>",
          "description": "Logs are valuable information for oil and gas fields as they help to\ndetermine the lithology of the formations surrounding the borehole and the\nlocation and reserves of subsurface oil and gas reservoirs. However, important\nlogs are often missing in horizontal or old wells, which poses a challenge in\nfield applications. In this paper, we utilize data from the 2020 machine\nlearning competition of the SPWLA, which aims to predict the missing\ncompressional wave slowness and shear wave slowness logs using other logs in\nthe same borehole. We employ the NGBoost algorithm to construct an Ensemble\nLearning model that can predicate the results as well as their uncertainty.\nFurthermore, we combine the SHAP method to investigate the interpretability of\nthe machine learning model. We compare the performance of the NGBosst model\nwith four other commonly used Ensemble Learning methods, including Random\nForest, GBDT, XGBoost, LightGBM. The results show that the NGBoost model\nperforms well in the testing set and can provide a probability distribution for\nthe prediction results. In addition, the variance of the probability\ndistribution of the predicted log can be used to justify the quality of the\nconstructed log. Using the SHAP explainable machine learning model, we\ncalculate the importance of each input log to the predicted results as well as\nthe coupling relationship among input logs. Our findings reveal that the\nNGBoost model tends to provide greater slowness prediction results when the\nneutron porosity and gamma ray are large, which is consistent with the\ncognition of petrophysical models. Furthermore, the machine learning model can\ncapture the influence of the changing borehole caliper on slowness, where the\ninfluence of borehole caliper on slowness is complex and not easy to establish\na direct relationship. These findings are in line with the physical principle\nof borehole acoustics.",
          "link": "http://arxiv.org/abs/2308.12625",
          "publishedOn": "2023-08-26T00:39:49.748Z",
          "wordCount": null,
          "title": "Uncertainty and Explainable Analysis of Machine Learning Model for Reconstruction of Sonic Slowness Logs. (arXiv:2308.12625v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.00747",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaoyun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ersoy_O/0/1/0/all/0/1\">Oguzhan Ersoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Picek_S/0/1/0/all/0/1\">Stjepan Picek</a>",
          "description": "Deep learning models achieve excellent performance in numerous machine\nlearning tasks. Yet, they suffer from security-related issues such as\nadversarial examples and poisoning (backdoor) attacks. A deep learning model\nmay be poisoned by training with backdoored data or by modifying inner network\nparameters. Then, a backdoored model performs as expected when receiving a\nclean input, but it misclassifies when receiving a backdoored input stamped\nwith a pre-designed pattern called \"trigger\". Unfortunately, it is difficult to\ndistinguish between clean and backdoored models without prior knowledge of the\ntrigger. This paper proposes a backdoor detection method by utilizing a special\ntype of adversarial attack, universal adversarial perturbation (UAP), and its\nsimilarities with a backdoor trigger. We observe an intuitive phenomenon: UAPs\ngenerated from backdoored models need fewer perturbations to mislead the model\nthan UAPs from clean models. UAPs of backdoored models tend to exploit the\nshortcut from all classes to the target class, built by the backdoor trigger.\nWe propose a novel method called Universal Soldier for Backdoor detection (USB)\nand reverse engineering potential backdoor triggers via UAPs. Experiments on\n345 models trained on several datasets show that USB effectively detects the\ninjected backdoor and provides comparable or better results than\nstate-of-the-art methods.",
          "link": "http://arxiv.org/abs/2302.00747",
          "publishedOn": "2023-08-26T00:39:49.748Z",
          "wordCount": null,
          "title": "Universal Soldier: Using Universal Adversarial Perturbations for Detecting Backdoor Attacks. (arXiv:2302.00747v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12299",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ma_X/0/1/0/all/0/1\">Xing-Yu Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hao_S/0/1/0/all/0/1\">Shaogang Hao</a>",
          "description": "As the feature size of integrated circuits continues to decrease, optical\nproximity correction (OPC) has emerged as a crucial resolution enhancement\ntechnology for ensuring high printability in the lithography process. Recently,\nlevel set-based inverse lithography technology (ILT) has drawn considerable\nattention as a promising OPC solution, showcasing its powerful pattern\nfidelity, especially in advanced process. However, massive computational time\nconsumption of ILT limits its applicability to mainly correcting partial layers\nand hotspot regions. Deep learning (DL) methods have shown great potential in\naccelerating ILT. However, lack of domain knowledge of inverse lithography\nlimits the ability of DL-based algorithms in process window (PW) enhancement\nand etc. In this paper, we propose an inverse lithography physics-informed deep\nneural level set (ILDLS) approach for mask optimization. This approach utilizes\nlevel set based-ILT as a layer within the DL framework and iteratively conducts\nmask prediction and correction to significantly enhance printability and PW in\ncomparison with results from pure DL and ILT. With this approach, computation\ntime is reduced by a few orders of magnitude versus ILT. By gearing up DL with\nknowledge of inverse lithography physics, ILDLS provides a new and efficient\nmask optimization solution.",
          "link": "http://arxiv.org/abs/2308.12299",
          "publishedOn": "2023-08-26T00:39:49.747Z",
          "wordCount": null,
          "title": "Inverse Lithography Physics-informed Deep Neural Level Set for Mask Optimization. (arXiv:2308.12299v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mili_M/0/1/0/all/0/1\">Manel Mili</a> (FSM, TIM), <a href=\"http://arxiv.org/find/cs/1/au:+Kerkeni_A/0/1/0/all/0/1\">Asma Kerkeni</a> (ISIMM, TIM), <a href=\"http://arxiv.org/find/cs/1/au:+Abdallah_A/0/1/0/all/0/1\">Asma Ben Abdallah</a> (ISIMM, TIM), <a href=\"http://arxiv.org/find/cs/1/au:+Bedoui_M/0/1/0/all/0/1\">Mohamed Hedi Bedoui</a> (TIM)",
          "description": "Extensive bedside monitoring in Intensive Care Units (ICUs) has resulted in\ncomplex temporal data regarding patient physiology, which presents an upscale\ncontext for clinical data analysis. In the other hand, identifying the\ntime-series patterns within these data may provide a high aptitude to predict\nclinical events. Hence, we investigate, during this work, the implementation of\nan automatic data-driven system, which analyzes large amounts of multivariate\ntemporal data derived from Electronic Health Records (EHRs), and extracts\nhigh-level information so as to predict in-hospital mortality and Length of\nStay (LOS) early. Practically, we investigate the applicability of LSTM network\nby reducing the time-frame to 6-hour so as to enhance clinical tasks. The\nexperimental results highlight the efficiency of LSTM model with rigorous\nmultivariate time-series measurements for building real-world prediction\nengines.",
          "link": "http://arxiv.org/abs/2308.12800",
          "publishedOn": "2023-08-26T00:39:49.747Z",
          "wordCount": null,
          "title": "ICU Mortality Prediction Using Long Short-Term Memory Networks. (arXiv:2308.12800v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12311",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yonghe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_L/0/1/0/all/0/1\">Liwei Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiaxi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_G/0/1/0/all/0/1\">Guojie Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Huawei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Shenggen Zheng</a>",
          "description": "NPN classification has many applications in the synthesis and verification of\ndigital circuits. The canonical-form-based method is the most common approach,\ndesigning a canonical form as representative for the NPN equivalence class\nfirst and then computing the transformation function according to the canonical\nform. Most works use variable symmetries and several signatures, mainly based\non the cofactor, to simplify the canonical form construction and computation.\nThis paper describes a novel canonical form and its computation algorithm by\nintroducing Boolean influence to NPN classification, which is a basic concept\nin analysis of Boolean functions. We show that influence is\ninput-negation-independent, input-permutation-dependent, and has other\nstructural information than previous signatures for NPN classification.\nTherefore, it is a significant ingredient in speeding up NPN classification.\nExperimental results prove that influence plays an important role in reducing\nthe transformation enumeration in computing the canonical form. Compared with\nthe state-of-the-art algorithm implemented in ABC, our influence-aided\ncanonical form for exact NPN classification gains up to 5.5x speedup.",
          "link": "http://arxiv.org/abs/2308.12311",
          "publishedOn": "2023-08-26T00:39:49.746Z",
          "wordCount": null,
          "title": "Fast Exact NPN Classification with Influence-aided Canonical Form. (arXiv:2308.12311v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12606",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bhunre_P/0/1/0/all/0/1\">Piyush Kanti Bhunre</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sen_T/0/1/0/all/0/1\">Tanmay Sen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sarkar_A/0/1/0/all/0/1\">Arijit Sarkar</a>",
          "description": "Customer retention or churn prevention is a challenging task of a telecom\noperator. One of the effective approaches is to offer some attractive incentive\nor additional services or money to the subscribers for keeping them engaged and\nmake sure they stay in the operator's network for longer time. Often, operators\nallocate certain amount of monetary budget to carry out the offer campaign. The\ndifficult part of this campaign is the selection of a set of customers from a\nlarge subscriber-base and deciding the amount that should be offered to an\nindividual so that operator's objective is achieved. There may be multiple\nobjectives (e.g., maximizing revenue, minimizing number of churns) for\nselection of subscriber and selection of an offer to the selected subscriber.\nApart from monetary benefit, offers may include additional data, SMS, hots-spot\ntethering, and many more. This problem is known as offer optimization. In this\npaper, we propose a novel combinatorial algorithm for solving offer\noptimization under heterogeneous offers by maximizing expected revenue under\nthe scenario of subscriber churn, which is, in general, seen in telecom domain.\nThe proposed algorithm is efficient and accurate even for a very large\nsubscriber-base.",
          "link": "http://arxiv.org/abs/2308.12606",
          "publishedOn": "2023-08-26T00:39:49.746Z",
          "wordCount": null,
          "title": "A Greedy Approach for Offering to Telecom Subscribers. (arXiv:2308.12606v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.10634",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Lipshutz_D/0/1/0/all/0/1\">David Lipshutz</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Pehlevan_C/0/1/0/all/0/1\">Cengiz Pehlevan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chklovskii_D/0/1/0/all/0/1\">Dmitri B. Chklovskii</a>",
          "description": "Early sensory systems in the brain rapidly adapt to fluctuating input\nstatistics, which requires recurrent communication between neurons.\nMechanistically, such recurrent communication is often indirect and mediated by\nlocal interneurons. In this work, we explore the computational benefits of\nmediating recurrent communication via interneurons compared with direct\nrecurrent connections. To this end, we consider two mathematically tractable\nrecurrent linear neural networks that statistically whiten their inputs -- one\nwith direct recurrent connections and the other with interneurons that mediate\nrecurrent communication. By analyzing the corresponding continuous synaptic\ndynamics and numerically simulating the networks, we show that the network with\ninterneurons is more robust to initialization than the network with direct\nrecurrent connections in the sense that the convergence time for the synaptic\ndynamics in the network with interneurons (resp. direct recurrent connections)\nscales logarithmically (resp. linearly) with the spectrum of their\ninitialization. Our results suggest that interneurons are computationally\nuseful for rapid adaptation to changing input statistics. Interestingly, the\nnetwork with interneurons is an overparameterized solution of the whitening\nobjective for the network with direct recurrent connections, so our results can\nbe viewed as a recurrent linear neural network analogue of the implicit\nacceleration phenomenon observed in overparameterized feedforward linear neural\nnetworks.",
          "link": "http://arxiv.org/abs/2209.10634",
          "publishedOn": "2023-08-26T00:39:49.746Z",
          "wordCount": null,
          "title": "Interneurons accelerate learning dynamics in recurrent neural networks for statistical adaptation. (arXiv:2209.10634v2 [q-bio.NC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12964",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yunji Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jiyoung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jin-Hwa Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ha_J/0/1/0/all/0/1\">Jung-Woo Ha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jun-Yan Zhu</a>",
          "description": "Existing text-to-image diffusion models struggle to synthesize realistic\nimages given dense captions, where each text prompt provides a detailed\ndescription for a specific image region. To address this, we propose\nDenseDiffusion, a training-free method that adapts a pre-trained text-to-image\nmodel to handle such dense captions while offering control over the scene\nlayout. We first analyze the relationship between generated images' layouts and\nthe pre-trained model's intermediate attention maps. Next, we develop an\nattention modulation method that guides objects to appear in specific regions\naccording to layout guidance. Without requiring additional fine-tuning or\ndatasets, we improve image generation performance given dense captions\nregarding both automatic and human evaluation scores. In addition, we achieve\nsimilar-quality visual results with models specifically trained with layout\nconditions.",
          "link": "http://arxiv.org/abs/2308.12964",
          "publishedOn": "2023-08-26T00:39:49.745Z",
          "wordCount": null,
          "title": "Dense Text-to-Image Generation with Attention Modulation. (arXiv:2308.12964v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Irshad_M/0/1/0/all/0/1\">Muhammad Zubair Irshad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zakharov_S/0/1/0/all/0/1\">Sergey Zakharov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Katherine Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guizilini_V/0/1/0/all/0/1\">Vitor Guizilini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kollar_T/0/1/0/all/0/1\">Thomas Kollar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaidon_A/0/1/0/all/0/1\">Adrien Gaidon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kira_Z/0/1/0/all/0/1\">Zsolt Kira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ambrus_R/0/1/0/all/0/1\">Rares Ambrus</a>",
          "description": "Recent implicit neural representations have shown great results for novel\nview synthesis. However, existing methods require expensive per-scene\noptimization from many views hence limiting their application to real-world\nunbounded urban settings where the objects of interest or backgrounds are\nobserved from very few views. To mitigate this challenge, we introduce a new\napproach called NeO 360, Neural fields for sparse view synthesis of outdoor\nscenes. NeO 360 is a generalizable method that reconstructs 360{\\deg} scenes\nfrom a single or a few posed RGB images. The essence of our approach is in\ncapturing the distribution of complex real-world outdoor 3D scenes and using a\nhybrid image-conditional triplanar representation that can be queried from any\nworld point. Our representation combines the best of both voxel-based and\nbird's-eye-view (BEV) representations and is more effective and expressive than\neach. NeO 360's representation allows us to learn from a large collection of\nunbounded 3D scenes while offering generalizability to new views and novel\nscenes from as few as a single image during inference. We demonstrate our\napproach on the proposed challenging 360{\\deg} unbounded dataset, called NeRDS\n360, and show that NeO 360 outperforms state-of-the-art generalizable methods\nfor novel view synthesis while also offering editing and composition\ncapabilities. Project page:\nhttps://zubair-irshad.github.io/projects/neo360.html",
          "link": "http://arxiv.org/abs/2308.12967",
          "publishedOn": "2023-08-26T00:39:49.745Z",
          "wordCount": null,
          "title": "NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes. (arXiv:2308.12967v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.04701",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haoxuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chunyuan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1\">Peng Wu</a>",
          "description": "In recommender systems, users always choose the favorite items to rate, which\nleads to data missing not at random and poses a great challenge for unbiased\nevaluation and learning of prediction models. Currently, the doubly robust (DR)\nmethods have been widely studied and demonstrate superior performance. However,\nin this paper, we show that DR methods are unstable and have unbounded bias,\nvariance, and generalization bounds to extremely small propensities. Moreover,\nthe fact that DR relies more on extrapolation will lead to suboptimal\nperformance. To address the above limitations while retaining double\nrobustness, we propose a stabilized doubly robust (StableDR) learning approach\nwith a weaker reliance on extrapolation. Theoretical analysis shows that\nStableDR has bounded bias, variance, and generalization error bound\nsimultaneously under inaccurate imputed errors and arbitrarily small\npropensities. In addition, we propose a novel learning approach for StableDR\nthat updates the imputation, propensity, and prediction models cyclically,\nachieving more stable and accurate predictions. Extensive experiments show that\nour approaches significantly outperform the existing methods.",
          "link": "http://arxiv.org/abs/2205.04701",
          "publishedOn": "2023-08-26T00:39:49.745Z",
          "wordCount": null,
          "title": "StableDR: Stabilized Doubly Robust Learning for Recommendation on Data Missing Not at Random. (arXiv:2205.04701v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.06534",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wolf_D/0/1/0/all/0/1\">Daniel Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Payer_T/0/1/0/all/0/1\">Tristan Payer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lisson_C/0/1/0/all/0/1\">Catharina Silvia Lisson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lisson_C/0/1/0/all/0/1\">Christoph Gerhard Lisson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beer_M/0/1/0/all/0/1\">Meinrad Beer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ropinski_T/0/1/0/all/0/1\">Timo Ropinski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gotz_M/0/1/0/all/0/1\">Michael G&#xf6;tz</a>",
          "description": "Deep learning in medical imaging has the potential to minimize the risk of\ndiagnostic errors, reduce radiologist workload, and accelerate diagnosis.\nTraining such deep learning models requires large and accurate datasets, with\nannotations for all training samples. However, in the medical imaging domain,\nannotated datasets for specific tasks are often small due to the high\ncomplexity of annotations, limited access, or the rarity of diseases. To\naddress this challenge, deep learning models can be pre-trained on large image\ndatasets without annotations using methods from the field of self-supervised\nlearning. After pre-training, small annotated datasets are sufficient to\nfine-tune the models for a specific task. The most popular self-supervised\npre-training approaches in medical imaging are based on contrastive learning.\nHowever, recent studies in natural image processing indicate a strong potential\nfor masked autoencoder approaches. Our work compares state-of-the-art\ncontrastive learning methods with the recently introduced masked autoencoder\napproach \"SparK\" for convolutional neural networks (CNNs) on medical images.\nTherefore we pre-train on a large unannotated CT image dataset and fine-tune on\nseveral CT classification tasks. Due to the challenge of obtaining sufficient\nannotated training data in medical imaging, it is of particular interest to\nevaluate how the self-supervised pre-training methods perform when fine-tuning\non small datasets. By experimenting with gradually reducing the training\ndataset size for fine-tuning, we find that the reduction has different effects\ndepending on the type of pre-training chosen. The SparK pre-training method is\nmore robust to the training dataset size than the contrastive methods. Based on\nour results, we propose the SparK pre-training for medical imaging tasks with\nonly small annotated datasets.",
          "link": "http://arxiv.org/abs/2308.06534",
          "publishedOn": "2023-08-26T00:39:49.745Z",
          "wordCount": null,
          "title": "Dealing with Small Datasets for Deep Learning in Medical Imaging: An Evaluation of Self-Supervised Pre-Training on CT Scans Comparing Contrastive and Masked Autoencoder Methods for Convolutional Models. (arXiv:2308.06534v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12290",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Blake_S/0/1/0/all/0/1\">Sam Blake</a>",
          "description": "In this paper we describe a deep learning--based probabilistic algorithm for\ninteger factorisation. We use Lawrence's extension of Fermat's factorisation\nalgorithm to reduce the integer factorisation problem to a binary\nclassification problem. To address the classification problem, based on the\nease of generating large pseudo--random primes, a corpus of training data, as\nlarge as needed, is synthetically generated. We will introduce the algorithm,\nsummarise some experiments, analyse where these experiments fall short, and\nfinally put out a call to others to reproduce, verify and see if this approach\ncan be improved to a point where it becomes a practical, scalable factorisation\nalgorithm.",
          "link": "http://arxiv.org/abs/2308.12290",
          "publishedOn": "2023-08-26T00:39:49.744Z",
          "wordCount": null,
          "title": "Integer Factorisation, Fermat & Machine Learning on a Classical Computer. (arXiv:2308.12290v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12874",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sanchis_Agudo_M/0/1/0/all/0/1\">Marcial Sanchis-Agudo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuning Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duraisamy_K/0/1/0/all/0/1\">Karthik Duraisamy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vinuesa_R/0/1/0/all/0/1\">Ricardo Vinuesa</a>",
          "description": "To improve the robustness of transformer neural networks used for\ntemporal-dynamics prediction of chaotic systems, we propose a novel attention\nmechanism called easy attention. Due to the fact that self attention only makes\nusage of the inner product of queries and keys, it is demonstrated that the\nkeys, queries and softmax are not necessary for obtaining the attention score\nrequired to capture long-term dependencies in temporal sequences. Through\nimplementing singular-value decomposition (SVD) on the softmax attention score,\nwe further observe that the self attention compresses contribution from both\nqueries and keys in the spanned space of the attention score. Therefore, our\nproposed easy-attention method directly treats the attention scores as\nlearnable parameters. This approach produces excellent results when\nreconstructing and predicting the temporal dynamics of chaotic systems\nexhibiting more robustness and less complexity than the self attention or the\nwidely-used long short-term memory (LSTM) network. Our results show great\npotential for applications in more complex high-dimensional dynamical systems.",
          "link": "http://arxiv.org/abs/2308.12874",
          "publishedOn": "2023-08-26T00:39:49.700Z",
          "wordCount": null,
          "title": "Easy attention: A simple self-attention mechanism for Transformers. (arXiv:2308.12874v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12554",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bu_F/0/1/0/all/0/1\">Fanjin Bu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Z/0/1/0/all/0/1\">Zhen Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_B/0/1/0/all/0/1\">Bin Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Han_M/0/1/0/all/0/1\">Meng Han</a>",
          "description": "In order to coordinate energy interactions among various communities and\nenergy conversions among multi-energy subsystems within the multi-community\nintegrated energy system under uncertain conditions, and achieve overall\noptimization and scheduling of the comprehensive energy system, this paper\nproposes a comprehensive scheduling model that utilizes a multi-agent deep\nreinforcement learning algorithm to learn load characteristics of different\ncommunities and make decisions based on this knowledge. In this model, the\nscheduling problem of the integrated energy system is transformed into a Markov\ndecision process and solved using a data-driven deep reinforcement learning\nalgorithm, which avoids the need for modeling complex energy coupling\nrelationships between multi-communities and multi-energy subsystems. The\nsimulation results show that the proposed method effectively captures the load\ncharacteristics of different communities and utilizes their complementary\nfeatures to coordinate reasonable energy interactions among them. This leads to\na reduction in wind curtailment rate from 16.3% to 0% and lowers the overall\noperating cost by 5445.6 Yuan, demonstrating significant economic and\nenvironmental benefits.",
          "link": "http://arxiv.org/abs/2308.12554",
          "publishedOn": "2023-08-26T00:39:49.697Z",
          "wordCount": null,
          "title": "Deep Reinforcement Learning-driven Cross-Community Energy Interaction Optimal Scheduling. (arXiv:2308.12554v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.16556",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ebrahimi_S/0/1/0/all/0/1\">Sayna Ebrahimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arik_S/0/1/0/all/0/1\">Sercan O. Arik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yihe Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_T/0/1/0/all/0/1\">Tomas Pfister</a>",
          "description": "Multimodal large-scale pretraining has shown impressive performance for\nunstructured data including language, image, audio, and video. However, a\nprevalent real-world scenario involves the combination of structured data types\n(tabular, time-series) with unstructured data which has so far been\nunderstudied. To bridge this gap, we propose LANISTR, an attention-based\nframework to learn from LANguage, Image, and STRuctured data. The core of\nLANISTR's methodology is rooted in \\textit{masking-based} training applied\nacross both unimodal and multimodal levels. In particular, we introduce a new\nsimilarity-based multimodal masking loss that enables it to learn cross-modal\nrelations from large-scale multimodal data with missing modalities. On two\nreal-world datastes, MIMIC-IV (healthcare) and Amazon Product Review (retail),\nLANISTR demonstrates remarkable absolute improvements of 6.6\\% (AUROC) and up\nto 14\\% (accuracy) when fine-tuned on 0.1\\% and 0.01\\% of labeled data,\nrespectively, compared to the state-of-the-art alternatives. Notably, these\nimprovements are observed even in the presence of considerable missingness\nratios of 35.7\\% and 99.8\\%, in the respective datasets.",
          "link": "http://arxiv.org/abs/2305.16556",
          "publishedOn": "2023-08-26T00:39:49.697Z",
          "wordCount": null,
          "title": "LANISTR: Multimodal Learning from Structured and Unstructured Data. (arXiv:2305.16556v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.02157",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xinshun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yizhi Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yichao Jiang</a>",
          "description": "Most existing classical artificial neural networks (ANN) are designed as a\ntree structure to imitate neural networks. In this paper, we argue that the\nconnectivity of a tree is not sufficient to characterize a neural network. The\nnodes of the same level of a tree cannot be connected with each other, i.e.,\nthese neural unit cannot share information with each other, which is a major\ndrawback of ANN. Although ANN has been significantly improved in recent years\nto more complex structures, such as the directed acyclic graph (DAG), these\nmethods also have unidirectional and acyclic bias for ANN. In this paper, we\npropose a method to build a bidirectional complete graph for the nodes in the\nsame level of an ANN, which yokes the nodes of the same level to formulate a\nneural module. We call our model as YNN in short. YNN promotes the information\ntransfer significantly which obviously helps in improving the performance of\nthe method. Our YNN can imitate neural networks much better compared with the\ntraditional ANN. In this paper, we analyze the existing structural bias of ANN\nand propose a model YNN to efficiently eliminate such structural bias. In our\nmodel, nodes also carry out aggregation and transformation of features, and\nedges determine the flow of information. We further impose auxiliary sparsity\nconstraint to the distribution of connectedness, which promotes the learned\nstructure to focus on critical connections. Finally, based on the optimized\nstructure, we also design small neural module structure based on the minimum\ncut technique to reduce the computational burden of the YNN model. This\nlearning process is compatible with the existing networks and different tasks.\nThe obtained quantitative experimental results reflect that the learned\nconnectivity is superior to the traditional NN structure.",
          "link": "http://arxiv.org/abs/2306.02157",
          "publishedOn": "2023-08-26T00:39:49.697Z",
          "wordCount": null,
          "title": "Transforming to Yoked Neural Networks to Improve ANN Structure. (arXiv:2306.02157v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12952",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Walke_H/0/1/0/all/0/1\">Homer Walke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Black_K/0/1/0/all/0/1\">Kevin Black</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_A/0/1/0/all/0/1\">Abraham Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Moo Jin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1\">Max Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chongyi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tony Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hansen_Estruch_P/0/1/0/all/0/1\">Philippe Hansen-Estruch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vuong_Q/0/1/0/all/0/1\">Quan Vuong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_A/0/1/0/all/0/1\">Andre He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Myers_V/0/1/0/all/0/1\">Vivek Myers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_K/0/1/0/all/0/1\">Kuan Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1\">Chelsea Finn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>",
          "description": "We introduce BridgeData V2, a large and diverse dataset of robotic\nmanipulation behaviors designed to facilitate research on scalable robot\nlearning. BridgeData V2 contains 60,096 trajectories collected across 24\nenvironments on a publicly available low-cost robot. BridgeData V2 provides\nextensive task and environment variability, leading to skills that can\ngeneralize across environments, domains, and institutions, making the dataset a\nuseful resource for a broad range of researchers. Additionally, the dataset is\ncompatible with a wide variety of open-vocabulary, multi-task learning methods\nconditioned on goal images or natural language instructions. In our\nexperiments, we train 6 state-of-the-art imitation learning and offline\nreinforcement learning methods on our dataset, and find that they succeed on a\nsuite of tasks requiring varying amounts of generalization. We also demonstrate\nthat the performance of these methods improves with more data and higher\ncapacity models, and that training on a greater variety of skills leads to\nimproved generalization. By publicly sharing BridgeData V2 and our pre-trained\nmodels, we aim to accelerate research in scalable robot learning methods.\nProject page at https://rail-berkeley.github.io/bridgedata",
          "link": "http://arxiv.org/abs/2308.12952",
          "publishedOn": "2023-08-26T00:39:49.696Z",
          "wordCount": null,
          "title": "BridgeData V2: A Dataset for Robot Learning at Scale. (arXiv:2308.12952v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12882",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dibbo_S/0/1/0/all/0/1\">Sayanton V. Dibbo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moore_J/0/1/0/all/0/1\">Juston S. Moore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kenyon_G/0/1/0/all/0/1\">Garrett T. Kenyon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teti_M/0/1/0/all/0/1\">Michael A. Teti</a>",
          "description": "Audio classification aims at recognizing audio signals, including speech\ncommands or sound events. However, current audio classifiers are susceptible to\nperturbations and adversarial attacks. In addition, real-world audio\nclassification tasks often suffer from limited labeled data. To help bridge\nthese gaps, previous work developed neuro-inspired convolutional neural\nnetworks (CNNs) with sparse coding via the Locally Competitive Algorithm (LCA)\nin the first layer (i.e., LCANets) for computer vision. LCANets learn in a\ncombination of supervised and unsupervised learning, reducing dependency on\nlabeled samples. Motivated by the fact that auditory cortex is also sparse, we\nextend LCANets to audio recognition tasks and introduce LCANets++, which are\nCNNs that perform sparse coding in multiple layers via LCA. We demonstrate that\nLCANets++ are more robust than standard CNNs and LCANets against perturbations,\ne.g., background noise, as well as black-box and white-box attacks, e.g.,\nevasion and fast gradient sign (FGSM) attacks.",
          "link": "http://arxiv.org/abs/2308.12882",
          "publishedOn": "2023-08-26T00:39:49.693Z",
          "wordCount": null,
          "title": "LCANets++: Robust Audio Classification using Multi-layer Neural Networks with Lateral Competition. (arXiv:2308.12882v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.10466",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jaiswal_A/0/1/0/all/0/1\">Ajay Jaiswal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shiwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianlong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Ying Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>",
          "description": "Graphs are omnipresent and GNNs are a powerful family of neural networks for\nlearning over graphs. Despite their popularity, scaling GNNs either by\ndeepening or widening suffers from prevalent issues of unhealthy gradients,\nover-smoothening, information squashing, which often lead to sub-standard\nperformance. In this work, we are interested in exploring a principled way to\nscale GNNs capacity without deepening or widening, which can improve its\nperformance across multiple small and large graphs. Motivated by the recent\nintriguing phenomenon of model soups, which suggest that fine-tuned weights of\nmultiple large-language pre-trained models can be merged to a better minima, we\nargue to exploit the fundamentals of model soups to mitigate the aforementioned\nissues of memory bottleneck and trainability during GNNs scaling. More\nspecifically, we propose not to deepen or widen current GNNs, but instead\npresent a data-centric perspective of model soups tailored for GNNs, i.e., to\nbuild powerful GNNs. By dividing giant graph data, we build multiple\nindependently and parallelly trained weaker GNNs (soup ingredient) without any\nintermediate communication, and combine their strength using a greedy\ninterpolation soup procedure to achieve state-of-the-art performance. Compared\nto concurrent distributed GNN training works such as Jiong et. al. 2023, we\ntrain each soup ingredient by sampling different subgraphs per epoch and their\nrespective sub-models are merged only after being fully trained (rather than\nintermediately so). Moreover, we provide a wide variety of model soup\npreparation techniques by leveraging state-of-the-art graph sampling and graph\npartitioning approaches that can handle large graphs. Codes are available at:\n\\url{https://github.com/VITA-Group/graph_ladling}.",
          "link": "http://arxiv.org/abs/2306.10466",
          "publishedOn": "2023-08-26T00:39:49.693Z",
          "wordCount": null,
          "title": "Graph Ladling: Shockingly Simple Parallel GNN Training without Intermediate Communication. (arXiv:2306.10466v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.10592",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Das_S/0/1/0/all/0/1\">Suddhasattwa Das</a>",
          "description": "The separate tasks of denoising, least squares expectation, and manifold\nlearning can often be posed in a common setting of finding the conditional\nexpectations arising from a product of two random variables. This paper focuses\non this more general problem and describes an operator theoretic approach to\nestimating the conditional expectation. Kernel integral operators are used as a\ncompactification tool, to set up the estimation problem as a linear inverse\nproblem in a reproducing kernel Hilbert space. This equation is shown to have\nsolutions that allow numerical approximation, thus guaranteeing the convergence\nof data-driven implementations. The overall technique is easy to implement, and\ntheir successful application to some real-world problems are also shown.",
          "link": "http://arxiv.org/abs/2306.10592",
          "publishedOn": "2023-08-26T00:39:49.693Z",
          "wordCount": null,
          "title": "Conditional expectation using compactification operators. (arXiv:2306.10592v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12551",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weiqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jianfeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsung_F/0/1/0/all/0/1\">Fugee Tsung</a>",
          "description": "In this work, we focus on robust time series representation learning. Our\nassumption is that real-world time series is noisy and complementary\ninformation from different views of the same time series plays an important\nrole while analyzing noisy input. Based on this, we create two views for the\ninput time series through two different encoders. We conduct co-training based\ncontrastive learning iteratively to learn the encoders. Our experiments\ndemonstrate that this co-training approach leads to a significant improvement\nin performance. Especially, by leveraging the complementary information from\ndifferent views, our proposed TS-CoT method can mitigate the impact of data\nnoise and corruption. Empirical evaluations on four time series benchmarks in\nunsupervised and semi-supervised settings reveal that TS-CoT outperforms\nexisting methods. Furthermore, the representations learned by TS-CoT can\ntransfer well to downstream tasks through fine-tuning.",
          "link": "http://arxiv.org/abs/2308.12551",
          "publishedOn": "2023-08-26T00:39:49.692Z",
          "wordCount": null,
          "title": "A Co-training Approach for Noisy Time Series Learning. (arXiv:2308.12551v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12612",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junjie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Z/0/1/0/all/0/1\">Zhihao Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Shutao Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1\">Yue Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Huaan Li</a>",
          "description": "The rapid growth of deep learning (DL) has spurred interest in enhancing\nlog-based anomaly detection. This approach aims to extract meaning from log\nevents (log message templates) and develop advanced DL models for anomaly\ndetection. However, these DL methods face challenges like heavy reliance on\ntraining data, labels, and computational resources due to model complexity. In\ncontrast, traditional machine learning and data mining techniques are less\ndata-dependent and more efficient but less effective than DL. To make log-based\nanomaly detection more practical, the goal is to enhance traditional techniques\nto match DL's effectiveness. Previous research in a different domain (linking\nquestions on Stack Overflow) suggests that optimized traditional techniques can\nrival state-of-the-art DL methods. Drawing inspiration from this concept, we\nconducted an empirical study. We optimized the unsupervised PCA (Principal\nComponent Analysis), a traditional technique, by incorporating lightweight\nsemantic-based log representation. This addresses the issue of unseen log\nevents in training data, enhancing log representation. Our study compared seven\nlog-based anomaly detection methods, including four DL-based, two traditional,\nand the optimized PCA technique, using public and industrial datasets. Results\nindicate that the optimized unsupervised PCA technique achieves similar\neffectiveness to advanced supervised/semi-supervised DL methods while being\nmore stable with limited training data and resource-efficient. This\ndemonstrates the adaptability and strength of traditional techniques through\nsmall yet impactful adaptations.",
          "link": "http://arxiv.org/abs/2308.12612",
          "publishedOn": "2023-08-26T00:39:49.692Z",
          "wordCount": null,
          "title": "Try with Simpler -- An Evaluation of Improved Principal Component Analysis in Log-based Anomaly Detection. (arXiv:2308.12612v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yahmed_A/0/1/0/all/0/1\">Ahmed Haj Yahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouchoucha_R/0/1/0/all/0/1\">Rached Bouchoucha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Braiek_H/0/1/0/all/0/1\">Houssem Ben Braiek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khomh_F/0/1/0/all/0/1\">Foutse Khomh</a>",
          "description": "Deep reinforcement learning (DRL) is increasingly applied in large-scale\nproductions like Netflix and Facebook. As with most data-driven systems, DRL\nsystems can exhibit undesirable behaviors due to environmental drifts, which\noften occur in constantly-changing production settings. Continual Learning (CL)\nis the inherent self-healing approach for adapting the DRL agent in response to\nthe environment's conditions shifts. However, successive shifts of considerable\nmagnitude may cause the production environment to drift from its original\nstate. Recent studies have shown that these environmental drifts tend to drive\nCL into long, or even unsuccessful, healing cycles, which arise from\ninefficiencies such as catastrophic forgetting, warm-starting failure, and slow\nconvergence. In this paper, we propose Dr. DRL, an effective self-healing\napproach for DRL systems that integrates a novel mechanism of intentional\nforgetting into vanilla CL to overcome its main issues. Dr. DRL deliberately\nerases the DRL system's minor behaviors to systematically prioritize the\nadaptation of the key problem-solving skills. Using well-established DRL\nalgorithms, Dr. DRL is compared with vanilla CL on various drifted\nenvironments. Dr. DRL is able to reduce, on average, the healing time and\nfine-tuning episodes by, respectively, 18.74% and 17.72%. Dr. DRL successfully\nhelps agents to adapt to 19.63% of drifted environments left unsolved by\nvanilla CL while maintaining and even enhancing by up to 45% the obtained\nrewards for drifted environments that are resolved by both approaches.",
          "link": "http://arxiv.org/abs/2308.12445",
          "publishedOn": "2023-08-26T00:39:49.691Z",
          "wordCount": null,
          "title": "An Intentional Forgetting-Driven Self-Healing Method For Deep Reinforcement Learning Systems. (arXiv:2308.12445v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.04118",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Gao_C/0/1/0/all/0/1\">Chengfan Gao</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gao_S/0/1/0/all/0/1\">Siping Gao</a>, <a href=\"http://arxiv.org/find/math/1/au:+Hu_R/0/1/0/all/0/1\">Ruimeng Hu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhu_Z/0/1/0/all/0/1\">Zimu Zhu</a>",
          "description": "The optimal stopping problem is one of the core problems in financial\nmarkets, with broad applications such as pricing American and Bermudan options.\nThe deep BSDE method [Han, Jentzen and E, PNAS, 115(34):8505-8510, 2018] has\nshown great power in solving high-dimensional forward-backward stochastic\ndifferential equations (FBSDEs), and inspired many applications. However, the\nmethod solves backward stochastic differential equations (BSDEs) in a forward\nmanner, which can not be used for optimal stopping problems that in general\nrequire running BSDE backwardly. To overcome this difficulty, a recent paper\n[Wang, Chen, Sudjianto, Liu and Shen, arXiv:1807.06622, 2018] proposed the\nbackward deep BSDE method to solve the optimal stopping problem. In this paper,\nwe provide the rigorous theory for the backward deep BSDE method. Specifically,\n1. We derive the a posteriori error estimation, i.e., the error of the\nnumerical solution can be bounded by the training loss function; and; 2. We\ngive an upper bound of the loss function, which can be sufficiently small\nsubject to universal approximations. We give two numerical examples, which\npresent consistent performance with the proved theory.",
          "link": "http://arxiv.org/abs/2210.04118",
          "publishedOn": "2023-08-26T00:39:49.691Z",
          "wordCount": null,
          "title": "Convergence of the Backward Deep BSDE Method with Applications to Optimal Stopping Problems. (arXiv:2210.04118v3 [math.PR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12679",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sadafi_A/0/1/0/all/0/1\">Ario Sadafi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salehi_R/0/1/0/all/0/1\">Raheleh Salehi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gruber_A/0/1/0/all/0/1\">Armin Gruber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boushehri_S/0/1/0/all/0/1\">Sayedali Shetab Boushehri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giehr_P/0/1/0/all/0/1\">Pascal Giehr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Navab_N/0/1/0/all/0/1\">Nassir Navab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marr_C/0/1/0/all/0/1\">Carsten Marr</a>",
          "description": "Accurate classification of white blood cells in peripheral blood is essential\nfor diagnosing hematological diseases. Due to constantly evolving clinical\nsettings, data sources, and disease classifications, it is necessary to update\nmachine learning classification models regularly for practical real-world use.\nSuch models significantly benefit from sequentially learning from incoming data\nstreams without forgetting previously acquired knowledge. However, models can\nsuffer from catastrophic forgetting, causing a drop in performance on previous\ntasks when fine-tuned on new data. Here, we propose a rehearsal-based continual\nlearning approach for class incremental and domain incremental scenarios in\nwhite blood cell classification. To choose representative samples from previous\ntasks, we employ exemplar set selection based on the model's predictions. This\ninvolves selecting the most confident samples and the most challenging samples\nidentified through uncertainty estimation of the model. We thoroughly evaluated\nour proposed approach on three white blood cell classification datasets that\ndiffer in color, resolution, and class composition, including scenarios where\nnew domains or new classes are introduced to the model with every task. We also\ntest a long class incremental experiment with both new domains and new classes.\nOur results demonstrate that our approach outperforms established baselines in\ncontinual learning, including existing iCaRL and EWC methods for classifying\nwhite blood cells in cross-domain environments.",
          "link": "http://arxiv.org/abs/2308.12679",
          "publishedOn": "2023-08-26T00:39:49.688Z",
          "wordCount": null,
          "title": "A Continual Learning Approach for Cross-Domain White Blood Cell Classification. (arXiv:2308.12679v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12666",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Charlie Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_T/0/1/0/all/0/1\">Theodore Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Sarah Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laine_R/0/1/0/all/0/1\">Rudolf Laine</a>",
          "description": "Mode connectivity is a phenomenon where trained models are connected by a\npath of low loss. We reframe this in the context of Information Geometry, where\nneural networks are studied as spaces of parameterized distributions with\ncurved geometry. We hypothesize that shortest paths in these spaces, known as\ngeodesics, correspond to mode-connecting paths in the loss landscape. We\npropose an algorithm to approximate geodesics and demonstrate that they achieve\nmode connectivity.",
          "link": "http://arxiv.org/abs/2308.12666",
          "publishedOn": "2023-08-26T00:39:49.684Z",
          "wordCount": null,
          "title": "Geodesic Mode Connectivity. (arXiv:2308.12666v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12454",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wijesinghe_A/0/1/0/all/0/1\">Achintha Wijesinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Songyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1\">Zhi Ding</a>",
          "description": "Recent advances of generative learning models are accompanied by the growing\ninterest in federated learning (FL) based on generative adversarial network\n(GAN) models. In the context of FL, GAN can capture the underlying client data\nstructure, and regenerate samples resembling the original data distribution\nwithout compromising the private raw data. Although most existing GAN-based FL\nworks focus on training a global model, Personalized FL (PFL) sometimes can be\nmore effective in view of client data heterogeneity in terms of distinct data\nsample distributions, feature spaces, and labels. To cope with client\nheterogeneity in GAN-based FL, we propose a novel GAN sharing and aggregation\nstrategy for PFL. The proposed PFL-GAN addresses the client heterogeneity in\ndifferent scenarios. More specially, we first learn the similarity among\nclients and then develop an weighted collaborative data aggregation. The\nempirical results through the rigorous experimentation on several well-known\ndatasets demonstrate the effectiveness of PFL-GAN.",
          "link": "http://arxiv.org/abs/2308.12454",
          "publishedOn": "2023-08-26T00:39:49.680Z",
          "wordCount": null,
          "title": "PFL-GAN: When Client Heterogeneity Meets Generative Models in Personalized Federated Learning. (arXiv:2308.12454v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1\">Kwan Ho Ryan Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chattopadhyay_A/0/1/0/all/0/1\">Aditya Chattopadhyay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haeffele_B/0/1/0/all/0/1\">Benjamin David Haeffele</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidal_R/0/1/0/all/0/1\">Rene Vidal</a>",
          "description": "Variational Information Pursuit (V-IP) is a framework for making\ninterpretable predictions by design by sequentially selecting a short chain of\ntask-relevant, user-defined and interpretable queries about the data that are\nmost informative for the task. While this allows for built-in interpretability\nin predictive models, applying V-IP to any task requires data samples with\ndense concept-labeling by domain experts, limiting the application of V-IP to\nsmall-scale tasks where manual data annotation is feasible. In this work, we\nextend the V-IP framework with Foundational Models (FMs) to address this\nlimitation. More specifically, we use a two-step process, by first leveraging\nLarge Language Models (LLMs) to generate a sufficiently large candidate set of\ntask-relevant interpretable concepts, then using Large Multimodal Models to\nannotate each data sample by semantic similarity with each concept in the\ngenerated concept set. While other interpretable-by-design frameworks such as\nConcept Bottleneck Models (CBMs) require an additional step of removing\nrepetitive and non-discriminative concepts to have good interpretability and\ntest performance, we mathematically and empirically justify that, with a\nsufficiently informative and task-relevant query (concept) set, the proposed\nFM+V-IP method does not require any type of concept filtering. In addition, we\nshow that FM+V-IP with LLM generated concepts can achieve better test\nperformance than V-IP with human annotated concepts, demonstrating the\neffectiveness of LLMs at generating efficient query sets. Finally, when\ncompared to other interpretable-by-design frameworks such as CBMs, FM+V-IP can\nachieve competitive test performance using fewer number of concepts/queries in\nboth cases with filtered or unfiltered concept sets.",
          "link": "http://arxiv.org/abs/2308.12562",
          "publishedOn": "2023-08-26T00:39:49.679Z",
          "wordCount": null,
          "title": "Variational Information Pursuit with Large Language and Multimodal Models for Interpretable Predictions. (arXiv:2308.12562v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.09725",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Yang_Z/0/1/0/all/0/1\">Ziwei Yang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chen_Z/0/1/0/all/0/1\">Zheng Chen</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Matsubara_Y/0/1/0/all/0/1\">Yasuko Matsubara</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sakurai_Y/0/1/0/all/0/1\">Yasushi Sakurai</a>",
          "description": "Precision medicine fundamentally aims to establish causality between\ndysregulated biochemical mechanisms and cancer subtypes. Omics-based cancer\nsubtyping has emerged as a revolutionary approach, as different level of omics\nrecords the biochemical products of multistep processes in cancers. This paper\nfocuses on fully exploiting the potential of multi-omics data to improve cancer\nsubtyping outcomes, and hence developed MoCLIM, a representation learning\nframework. MoCLIM independently extracts the informative features from distinct\nomics modalities. Using a unified representation informed by contrastive\nlearning of different omics modalities, we can well-cluster the subtypes, given\ncancer, into a lower latent space. This contrast can be interpreted as a\nprojection of inter-omics inference observed in biological networks.\nExperimental results on six cancer datasets demonstrate that our approach\nsignificantly improves data fit and subtyping performance in fewer\nhigh-dimensional cancer instances. Moreover, our framework incorporates various\nmedical evaluations as the final component, providing high interpretability in\nmedical analysis.",
          "link": "http://arxiv.org/abs/2308.09725",
          "publishedOn": "2023-08-26T00:39:49.677Z",
          "wordCount": null,
          "title": "MoCLIM: Towards Accurate Cancer Subtyping via Multi-Omics Contrastive Learning with Omics-Inference Modeling. (arXiv:2308.09725v2 [q-bio.GN] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.05838",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Welke_P/0/1/0/all/0/1\">Pascal Welke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thiessen_M/0/1/0/all/0/1\">Maximilian Thiessen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jogl_F/0/1/0/all/0/1\">Fabian Jogl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gartner_T/0/1/0/all/0/1\">Thomas G&#xe4;rtner</a>",
          "description": "We investigate novel random graph embeddings that can be computed in expected\npolynomial time and that are able to distinguish all non-isomorphic graphs in\nexpectation. Previous graph embeddings have limited expressiveness and either\ncannot distinguish all graphs or cannot be computed efficiently for every\ngraph. To be able to approximate arbitrary functions on graphs, we are\ninterested in efficient alternatives that become arbitrarily expressive with\nincreasing resources. Our approach is based on Lov\\'asz' characterisation of\ngraph isomorphism through an infinite dimensional vector of homomorphism\ncounts. Our empirical evaluation shows competitive results on several benchmark\ngraph learning tasks.",
          "link": "http://arxiv.org/abs/2306.05838",
          "publishedOn": "2023-08-26T00:39:49.675Z",
          "wordCount": null,
          "title": "Expectation-Complete Graph Representations with Homomorphisms. (arXiv:2306.05838v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12532",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1\">Gihun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_M/0/1/0/all/0/1\">Minchan Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sangmook Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1\">Jaehoon Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1\">Se-Young Yun</a>",
          "description": "Federated Learning (FL) aggregates locally trained models from individual\nclients to construct a global model. While FL enables learning a model with\ndata privacy, it often suffers from significant performance degradation when\nclient data distributions are heterogeneous. Many previous FL algorithms have\naddressed this issue by introducing various proximal restrictions. These\nrestrictions aim to encourage global alignment by constraining the deviation of\nlocal learning from the global objective. However, they inherently limit local\nlearning by interfering with the original local objectives. Recently, an\nalternative approach has emerged to improve local learning generality. By\nobtaining local models within a smooth loss landscape, this approach mitigates\nconflicts among different local objectives of the clients. Yet, it does not\nensure stable global alignment, as local learning does not take the global\nobjective into account. In this study, we propose Federated Stability on\nLearning (FedSoL), which combines both the concepts of global alignment and\nlocal generality. In FedSoL, the local learning seeks a parameter region robust\nagainst proximal perturbations. This strategy introduces an implicit proximal\nrestriction effect in local learning while maintaining the original local\nobjective for parameter update. Our experiments show that FedSoL consistently\nachieves state-of-the-art performance on various setups.",
          "link": "http://arxiv.org/abs/2308.12532",
          "publishedOn": "2023-08-26T00:39:49.674Z",
          "wordCount": null,
          "title": "FedSoL: Bridging Global Alignment and Local Generality in Federated Learning. (arXiv:2308.12532v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jiawei Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chengkai Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingyuan Wang</a>",
          "description": "The field of urban spatial-temporal prediction is advancing rapidly with the\ndevelopment of deep learning techniques and the availability of large-scale\ndatasets. However, challenges persist in accessing and utilizing diverse urban\nspatial-temporal datasets from different sources and stored in different\nformats, as well as determining effective model structures and components with\nthe proliferation of deep learning models. This work addresses these challenges\nand provides three significant contributions. Firstly, we introduce \"atomic\nfiles\", a unified storage format designed for urban spatial-temporal big data,\nand validate its effectiveness on 40 diverse datasets, simplifying data\nmanagement. Secondly, we present a comprehensive overview of technological\nadvances in urban spatial-temporal prediction models, guiding the development\nof robust models. Thirdly, we conduct extensive experiments using diverse\nmodels and datasets, establishing a performance leaderboard and identifying\npromising research directions. Overall, this work effectively manages urban\nspatial-temporal data, guides future efforts, and facilitates the development\nof accurate and efficient urban spatial-temporal prediction models. It can\npotentially make long-term contributions to urban spatial-temporal data\nmanagement and prediction, ultimately leading to improved urban living\nstandards.",
          "link": "http://arxiv.org/abs/2308.12899",
          "publishedOn": "2023-08-26T00:39:49.669Z",
          "wordCount": null,
          "title": "Unified Data Management and Comprehensive Performance Evaluation for Urban Spatial-Temporal Prediction [Experiment, Analysis & Benchmark]. (arXiv:2308.12899v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12696",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Balabin_N/0/1/0/all/0/1\">Nikita Balabin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Voronkova_D/0/1/0/all/0/1\">Daria Voronkova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trofimov_I/0/1/0/all/0/1\">Ilya Trofimov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1\">Evgeny Burnaev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barannikov_S/0/1/0/all/0/1\">Serguei Barannikov</a>",
          "description": "We propose TopDis (Topological Disentanglement), a method for learning\ndisentangled representations via adding multi-scale topological loss term.\nDisentanglement is a crucial property of data representations substantial for\nthe explainability and robustness of deep learning models and a step towards\nhigh-level cognition. The state-of-the-art method based on VAE minimizes the\ntotal correlation of the joint distribution of latent variables. We take a\ndifferent perspective on disentanglement by analyzing topological properties of\ndata manifolds. In particular, we optimize the topological similarity for data\nmanifolds traversals. To the best of our knowledge, our paper is the first one\nto propose a differentiable topological loss for disentanglement. Our\nexperiments have shown that the proposed topological loss improves\ndisentanglement scores such as MIG, FactorVAE score, SAP score and DCI\ndisentanglement score with respect to state-of-the-art results. Our method\nworks in an unsupervised manner, permitting to apply it for problems without\nlabeled factors of variation. Additionally, we show how to use the proposed\ntopological loss to find disentangled directions in a trained GAN.",
          "link": "http://arxiv.org/abs/2308.12696",
          "publishedOn": "2023-08-26T00:39:49.646Z",
          "wordCount": null,
          "title": "Disentanglement Learning via Topology. (arXiv:2308.12696v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.05699",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moon_S/0/1/0/all/0/1\">Saemi Moon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1\">Seunghyuk Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Dongwoo Kim</a>",
          "description": "We tackle the problem of feature unlearning from a pre-trained image\ngenerative model: GANs and VAEs. Unlike a common unlearning task where an\nunlearning target is a subset of the training set, we aim to unlearn a specific\nfeature, such as hairstyle from facial images, from the pre-trained generative\nmodels. As the target feature is only presented in a local region of an image,\nunlearning the entire image from the pre-trained model may result in losing\nother details in the remaining region of the image. To specify which features\nto unlearn, we collect randomly generated images that contain the target\nfeatures. We then identify a latent representation corresponding to the target\nfeature and then use the representation to fine-tune the pre-trained model.\nThrough experiments on MNIST and CelebA datasets, we show that target features\nare successfully removed while keeping the fidelity of the original models.\nFurther experiments with an adversarial attack show that the unlearned model is\nmore robust under the presence of malicious parties.",
          "link": "http://arxiv.org/abs/2303.05699",
          "publishedOn": "2023-08-26T00:39:49.646Z",
          "wordCount": null,
          "title": "Feature Unlearning for Pre-trained GANs and VAEs. (arXiv:2303.05699v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12563",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ho_T/0/1/0/all/0/1\">Thi Kieu Khanh Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Armanfard_N/0/1/0/all/0/1\">Narges Armanfard</a>",
          "description": "Mainstream unsupervised anomaly detection algorithms often excel in academic\ndatasets, yet their real-world performance is restricted due to the controlled\nexperimental conditions involving clean training data. Addressing the challenge\nof training with noise, a prevalent issue in practical anomaly detection, is\nfrequently overlooked. In a pioneering endeavor, this study delves into the\nrealm of label-level noise within sensory time-series anomaly detection (TSAD).\nThis paper presents a novel and practical end-to-end unsupervised TSAD when the\ntraining data are contaminated with anomalies. The introduced approach, called\nTSAD-C, is devoid of access to abnormality labels during the training phase.\nTSAD-C encompasses three modules: a Decontaminator to rectify the abnormalities\n(aka noise) present in the training data, a Variable Dependency Modeling module\nto capture both long-term intra- and inter-variable dependencies within the\ndecontaminated data that can be considered as a surrogate of the pure normal\ndata, and an Anomaly Scoring module to detect anomalies. Our extensive\nexperiments conducted on three widely used physiological datasets conclusively\ndemonstrate that our approach surpasses existing methodologies, thus\nestablishing a new state-of-the-art performance in the field.",
          "link": "http://arxiv.org/abs/2308.12563",
          "publishedOn": "2023-08-26T00:39:49.645Z",
          "wordCount": null,
          "title": "Multivariate Time-Series Anomaly Detection with Contaminated Data: Application to Physiological Signals. (arXiv:2308.12563v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12918",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Harshith_J/0/1/0/all/0/1\">John Harshith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gill_M/0/1/0/all/0/1\">Mantej Singh Gill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jothimani_M/0/1/0/all/0/1\">Madhan Jothimani</a>",
          "description": "There have been recent adversarial attacks that are difficult to find. These\nnew adversarial attacks methods may pose challenges to current deep learning\ncyber defense systems and could influence the future defense of cyberattacks.\nThe authors focus on this domain in this research paper. They explore the\nconsequences of vulnerabilities in AI systems. This includes discussing how\nthey might arise, differences between randomized and adversarial examples and\nalso potential ethical implications of vulnerabilities. Moreover, it is\nimportant to train the AI systems appropriately when they are in testing phase\nand getting them ready for broader use.",
          "link": "http://arxiv.org/abs/2308.12918",
          "publishedOn": "2023-08-26T00:39:49.645Z",
          "wordCount": null,
          "title": "Evaluating the Vulnerabilities in ML systems in terms of adversarial attacks. (arXiv:2308.12918v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12843",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alzorgan_H/0/1/0/all/0/1\">Hazim Alzorgan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razi_A/0/1/0/all/0/1\">Abolfazl Razi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moshayedi_A/0/1/0/all/0/1\">Ata Jahangir Moshayedi</a>",
          "description": "In this paper, we investigate the operation of an aerial manipulator system,\nnamely an Unmanned Aerial Vehicle (UAV) equipped with a controllable arm with\ntwo degrees of freedom to carry out actuation tasks on the fly. Our solution is\nbased on employing a Q-learning method to control the trajectory of the tip of\nthe arm, also called \\textit{end-effector}. More specifically, we develop a\nmotion planning model based on Time To Collision (TTC), which enables a\nquadrotor UAV to navigate around obstacles while ensuring the manipulator's\nreachability. Additionally, we utilize a model-based Q-learning model to\nindependently track and control the desired trajectory of the manipulator's\nend-effector, given an arbitrary baseline trajectory for the UAV platform. Such\na combination enables a variety of actuation tasks such as high-altitude\nwelding, structural monitoring and repair, battery replacement, gutter\ncleaning, sky scrapper cleaning, and power line maintenance in hard-to-reach\nand risky environments while retaining compatibility with flight control\nfirmware. Our RL-based control mechanism results in a robust control strategy\nthat can handle uncertainties in the motion of the UAV, offering promising\nperformance. Specifically, our method achieves 92\\% accuracy in terms of\naverage displacement error (i.e. the mean distance between the target and\nobtained trajectory points) using Q-learning with 15,000 episodes",
          "link": "http://arxiv.org/abs/2308.12843",
          "publishedOn": "2023-08-26T00:39:49.644Z",
          "wordCount": null,
          "title": "Actuator Trajectory Planning for UAVs with Overhead Manipulator using Reinforcement Learning. (arXiv:2308.12843v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.09624",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1\">Richeng Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Z/0/1/0/all/0/1\">Zhonggen Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_C/0/1/0/all/0/1\">Caijun Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhaoyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quek_T/0/1/0/all/0/1\">Tony Quek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1\">Huaiyu Dai</a>",
          "description": "We consider a federated data analytics problem in which a server coordinates\nthe collaborative data analysis of multiple users with privacy concerns and\nlimited communication capability. The commonly adopted compression schemes\nintroduce information loss into local data while improving communication\nefficiency, and it remains an open problem whether such discrete-valued\nmechanisms provide any privacy protection. In this paper, we study the local\ndifferential privacy guarantees of discrete-valued mechanisms with finite\noutput space through the lens of $f$-differential privacy (DP). More\nspecifically, we advance the existing literature by deriving tight $f$-DP\nguarantees for a variety of discrete-valued mechanisms, including the binomial\nnoise and the binomial mechanisms that are proposed for privacy preservation,\nand the sign-based methods that are proposed for data compression, in\nclosed-form expressions. We further investigate the amplification in privacy by\nsparsification and propose a ternary stochastic compressor. By leveraging\ncompression for privacy amplification, we improve the existing methods by\nremoving the dependency of accuracy (in terms of mean square error) on\ncommunication cost in the popular use case of distributed mean estimation,\ntherefore breaking the three-way tradeoff between privacy, communication, and\naccuracy. Finally, we discuss the Byzantine resilience of the proposed\nmechanism and its application in federated learning.",
          "link": "http://arxiv.org/abs/2302.09624",
          "publishedOn": "2023-08-26T00:39:49.642Z",
          "wordCount": null,
          "title": "Breaking the Communication-Privacy-Accuracy Tradeoff with $f$-Differential Privacy. (arXiv:2302.09624v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haokun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krompass_D/0/1/0/all/0/1\">Denis Krompass</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jindong Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tresp_V/0/1/0/all/0/1\">Volker Tresp</a>",
          "description": "Recently, foundation models have exhibited remarkable advancements in\nmulti-modal learning. These models, equipped with millions (or billions) of\nparameters, typically require a substantial amount of data for finetuning.\nHowever, collecting and centralizing training data from diverse sectors becomes\nchallenging due to distinct privacy regulations. Federated Learning (FL)\nemerges as a promising solution, enabling multiple clients to collaboratively\ntrain neural networks without centralizing their local data. To alleviate\nclient computation burdens and communication overheads, previous works have\nadapted Parameter-efficient Finetuning (PEFT) methods for FL. Hereby, only a\nsmall fraction of the model parameters are optimized and communicated during\nfederated communications. Nevertheless, most previous works have focused on a\nsingle modality and neglected one common phenomenon, i.e., the presence of data\nheterogeneity across the clients. Therefore, in this work, we propose a\nfinetuning framework tailored to heterogeneous multi-modal FL, called Federated\nDual-Aadapter Teacher (FedDAT). Specifically, our approach leverages a\nDual-Adapter Teacher (DAT) to address data heterogeneity by regularizing the\nclient local updates and applying Mutual Knowledge Distillation (MKD) for an\nefficient knowledge transfer. FedDAT is the first approach that enables an\nefficient distributed finetuning of foundation models for a variety of\nheterogeneous Vision-Language tasks. To demonstrate its effectiveness, we\nconduct extensive experiments on four multi-modality FL benchmarks with\ndifferent types of data heterogeneity, where FedDAT substantially outperforms\nthe existing centralized PEFT methods adapted for FL.",
          "link": "http://arxiv.org/abs/2308.12305",
          "publishedOn": "2023-08-26T00:39:49.639Z",
          "wordCount": null,
          "title": "FedDAT: An Approach for Foundation Model Finetuning in Multi-Modal Heterogeneous Federated Learning. (arXiv:2308.12305v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12828",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shalit_N/0/1/0/all/0/1\">Nadav Shalit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fire_M/0/1/0/all/0/1\">Michael Fire</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kagan_D/0/1/0/all/0/1\">Dima Kagan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_Elia_E/0/1/0/all/0/1\">Eran Ben-Elia</a>",
          "description": "Public transport routing plays a crucial role in transit network design,\nensuring a satisfactory level of service for passengers. However, current\nrouting solutions rely on traditional operational research heuristics, which\ncan be time-consuming to implement and lack the ability to provide quick\nsolutions. Here, we propose a novel deep learning-based methodology for a\ndecision support system that enables public transport (PT) planners to identify\nshort-term route improvements rapidly. By seamlessly adjusting specific\nsections of routes between two stops during specific times of the day, our\nmethod effectively reduces times and enhances PT services. Leveraging diverse\ndata sources such as GTFS and smart card data, we extract features and model\nthe transportation network as a directed graph. Using self-supervision, we\ntrain a deep learning model for predicting lateness values for road segments.\n\nThese lateness values are then utilized as edge weights in the transportation\ngraph, enabling efficient path searching. Through evaluating the method on Tel\nAviv, we are able to reduce times on more than 9\\% of the routes. The improved\nroutes included both intraurban and suburban routes showcasing a fact\nhighlighting the model's versatility. The findings emphasize the potential of\nour data-driven decision support system to enhance public transport and city\nlogistics, promoting greater efficiency and reliability in PT services.",
          "link": "http://arxiv.org/abs/2308.12828",
          "publishedOn": "2023-08-26T00:39:49.638Z",
          "wordCount": null,
          "title": "Short Run Transit Route Planning Decision Support System Using a Deep Learning-Based Weighted Graph. (arXiv:2308.12828v1 [cs.AI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.00028",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jakkala_K/0/1/0/all/0/1\">Kalvik Jakkala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akella_S/0/1/0/all/0/1\">Srinivas Akella</a>",
          "description": "The sensor placement problem is a common problem that arises when monitoring\ncorrelated phenomena, such as temperature and precipitation. Existing\napproaches to this problem typically use discrete optimization methods, which\nare computationally expensive and cannot scale to large problems. We address\nthe sensor placement problem in correlated environments by reducing it to a\nregression problem that can be efficiently solved using sparse Gaussian\nprocesses (SGPs). Our approach can handle both discrete sensor placement\nproblems-where sensors are limited to a subset of a given set of locations-and\ncontinuous sensor placement problems-where sensors can be placed anywhere in a\nbounded continuous region. We further generalize our approach to handle sensors\nwith a non-point field of view and integrated observations. Our experimental\nresults on three real-world datasets show that our approach generates sensor\nplacements that result in reconstruction quality that is consistently on par or\nbetter than the prior state-of-the-art approach while being significantly\nfaster. Our computationally efficient approach enables both large-scale sensor\nplacement and fast robotic sensor placement for informative path planning\nalgorithms.",
          "link": "http://arxiv.org/abs/2303.00028",
          "publishedOn": "2023-08-26T00:39:49.637Z",
          "wordCount": null,
          "title": "Efficient Sensor Placement from Regression with Sparse Gaussian Processes in Continuous and Discrete Spaces. (arXiv:2303.00028v4 [cs.RO] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12443",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Guo_X/0/1/0/all/0/1\">Xueqi Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_L/0/1/0/all/0/1\">Luyao Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1\">Xiongchao Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_B/0/1/0/all/0/1\">Bo Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Q/0/1/0/all/0/1\">Qiong Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xie_H/0/1/0/all/0/1\">Huidong Xie</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1\">Yi-Hwa Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Palyo_R/0/1/0/all/0/1\">Richard Palyo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Miller_E/0/1/0/all/0/1\">Edward J. Miller</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sinusas_A/0/1/0/all/0/1\">Albert J. Sinusas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Spottiswoode_B/0/1/0/all/0/1\">Bruce Spottiswoode</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_C/0/1/0/all/0/1\">Chi Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dvornek_N/0/1/0/all/0/1\">Nicha C. Dvornek</a>",
          "description": "The rapid tracer kinetics of rubidium-82 ($^{82}$Rb) and high variation of\ncross-frame distribution in dynamic cardiac positron emission tomography (PET)\nraise significant challenges for inter-frame motion correction, particularly\nfor the early frames where conventional intensity-based image registration\ntechniques are not applicable. Alternatively, a promising approach utilizes\ngenerative methods to handle the tracer distribution changes to assist existing\nregistration methods. To improve frame-wise registration and parametric\nquantification, we propose a Temporally and Anatomically Informed Generative\nAdversarial Network (TAI-GAN) to transform the early frames into the late\nreference frame using an all-to-one mapping. Specifically, a feature-wise\nlinear modulation layer encodes channel-wise parameters generated from temporal\ntracer kinetics information, and rough cardiac segmentations with local shifts\nserve as the anatomical information. We validated our proposed method on a\nclinical $^{82}$Rb PET dataset and found that our TAI-GAN can produce converted\nearly frames with high image quality, comparable to the real reference frames.\nAfter TAI-GAN conversion, motion estimation accuracy and clinical myocardial\nblood flow (MBF) quantification were improved compared to using the original\nframes. Our code is published at https://github.com/gxq1998/TAI-GAN.",
          "link": "http://arxiv.org/abs/2308.12443",
          "publishedOn": "2023-08-26T00:39:49.634Z",
          "wordCount": null,
          "title": "TAI-GAN: Temporally and Anatomically Informed GAN for early-to-late frame conversion in dynamic cardiac PET motion correction. (arXiv:2308.12443v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2301.09091",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shin_M/0/1/0/all/0/1\">Minjung Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_Y/0/1/0/all/0/1\">Yunji Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bae_J/0/1/0/all/0/1\">Jeongmin Bae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Young Sun Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunsu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Byun_H/0/1/0/all/0/1\">Hyeran Byun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uh_Y/0/1/0/all/0/1\">Youngjung Uh</a>",
          "description": "3D-aware GANs aim to synthesize realistic 3D scenes such that they can be\nrendered in arbitrary perspectives to produce images. Although previous methods\nproduce realistic images, they suffer from unstable training or degenerate\nsolutions where the 3D geometry is unnatural. We hypothesize that the 3D\ngeometry is underdetermined due to the insufficient constraint, i.e., being\nclassified as real image to the discriminator is not enough. To solve this\nproblem, we propose to approximate the background as a spherical surface and\nrepresent a scene as a union of the foreground placed in the sphere and the\nthin spherical background. It reduces the degree of freedom in the background\nfield. Accordingly, we modify the volume rendering equation and incorporate\ndedicated constraints to design a novel 3D-aware GAN framework named BallGAN.\nBallGAN has multiple advantages as follows. 1) It produces more reasonable 3D\ngeometry; the images of a scene across different viewpoints have better\nphotometric consistency and fidelity than the state-of-the-art methods. 2) The\ntraining becomes much more stable. 3) The foreground can be separately rendered\non top of different arbitrary backgrounds.",
          "link": "http://arxiv.org/abs/2301.09091",
          "publishedOn": "2023-08-26T00:39:49.633Z",
          "wordCount": null,
          "title": "BallGAN: 3D-aware Image Synthesis with a Spherical Background. (arXiv:2301.09091v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06886",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adibi_A/0/1/0/all/0/1\">Arman Adibi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_A/0/1/0/all/0/1\">Aritra Mitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassani_H/0/1/0/all/0/1\">Hamed Hassani</a>",
          "description": "Delays and asynchrony are inevitable in large-scale machine-learning problems\nwhere communication plays a key role. As such, several works have extensively\nanalyzed stochastic optimization with delayed gradients. However, as far as we\nare aware, no analogous theory is available for min-max optimization, a topic\nthat has gained recent popularity due to applications in adversarial\nrobustness, game theory, and reinforcement learning. Motivated by this gap, we\nexamine the performance of standard min-max optimization algorithms with\ndelayed gradient updates. First, we show (empirically) that even small delays\ncan cause prominent algorithms like Extra-gradient (\\texttt{EG}) to diverge on\nsimple instances for which \\texttt{EG} guarantees convergence in the absence of\ndelays. Our empirical study thus suggests the need for a careful analysis of\ndelayed versions of min-max optimization algorithms. Accordingly, under\nsuitable technical assumptions, we prove that Gradient Descent-Ascent\n(\\texttt{GDA}) and \\texttt{EG} with delayed updates continue to guarantee\nconvergence to saddle points for convex-concave and strongly convex-strongly\nconcave settings. Our complexity bounds reveal, in a transparent manner, the\nslow-down in convergence caused by delays.",
          "link": "http://arxiv.org/abs/2307.06886",
          "publishedOn": "2023-08-26T00:39:49.631Z",
          "wordCount": null,
          "title": "Min-Max Optimization under Delays. (arXiv:2307.06886v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12970",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kairanda_N/0/1/0/all/0/1\">Navami Kairanda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habermann_M/0/1/0/all/0/1\">Marc Habermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1\">Christian Theobalt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golyanik_V/0/1/0/all/0/1\">Vladislav Golyanik</a>",
          "description": "Cloth simulation is an extensively studied problem, with a plethora of\nsolutions available in computer graphics literature. Existing cloth simulators\nproduce realistic cloth deformations that obey different types of boundary\nconditions. Nevertheless, their operational principle remains limited in\nseveral ways: They operate on explicit surface representations with a fixed\nspatial resolution, perform a series of discretised updates (which bounds their\ntemporal resolution), and require comparably large amounts of storage.\nMoreover, back-propagating gradients through the existing solvers is often not\nstraightforward, which poses additional challenges when integrating them into\nmodern neural architectures. In response to the limitations mentioned above,\nthis paper takes a fundamentally different perspective on physically-plausible\ncloth simulation and re-thinks this long-standing problem: We propose\nNeuralClothSim, i.e., a new cloth simulation approach using thin shells, in\nwhich surface evolution is encoded in neural network weights. Our\nmemory-efficient and differentiable solver operates on a new continuous\ncoordinate-based representation of dynamic surfaces, i.e., neural deformation\nfields (NDFs); it supervises NDF evolution with the rules of the non-linear\nKirchhoff-Love shell theory. NDFs are adaptive in the sense that they 1)\nallocate their capacity to the deformation details as the latter arise during\nthe cloth evolution and 2) allow surface state queries at arbitrary spatial and\ntemporal resolutions without retraining. We show how to train our\nNeuralClothSim solver while imposing hard boundary conditions and demonstrate\nmultiple applications, such as material interpolation and simulation editing.\nThe experimental results highlight the effectiveness of our formulation and its\npotential impact.",
          "link": "http://arxiv.org/abs/2308.12970",
          "publishedOn": "2023-08-26T00:39:49.629Z",
          "wordCount": null,
          "title": "NeuralClothSim: Neural Deformation Fields Meet the Kirchhoff-Love Thin Shell Theory. (arXiv:2308.12970v1 [cs.GR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12497",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akhtar_M/0/1/0/all/0/1\">Mohammad Majid Akhtar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masood_R/0/1/0/all/0/1\">Rahat Masood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikram_M/0/1/0/all/0/1\">Muhammad Ikram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanhere_S/0/1/0/all/0/1\">Salil S. Kanhere</a>",
          "description": "The rapid spread of false information and persistent manipulation attacks on\nonline social networks (OSNs), often for political, ideological, or financial\ngain, has affected the openness of OSNs. While researchers from various\ndisciplines have investigated different manipulation-triggering elements of\nOSNs (such as understanding information diffusion on OSNs or detecting\nautomated behavior of accounts), these works have not been consolidated to\npresent a comprehensive overview of the interconnections among these elements.\nNotably, user psychology, the prevalence of bots, and their tactics in relation\nto false information detection have been overlooked in previous research. To\naddress this research gap, this paper synthesizes insights from various\ndisciplines to provide a comprehensive analysis of the manipulation landscape.\nBy integrating the primary elements of social media manipulation (SMM),\nincluding false information, bots, and malicious campaigns, we extensively\nexamine each SMM element. Through a systematic investigation of prior research,\nwe identify commonalities, highlight existing gaps, and extract valuable\ninsights in the field. Our findings underscore the urgent need for\ninterdisciplinary research to effectively combat social media manipulations,\nand our systematization can guide future research efforts and assist OSN\nproviders in ensuring the safety and integrity of their platforms.",
          "link": "http://arxiv.org/abs/2308.12497",
          "publishedOn": "2023-08-26T00:39:49.627Z",
          "wordCount": null,
          "title": "False Information, Bots and Malicious Campaigns: Demystifying Elements of Social Media Manipulations. (arXiv:2308.12497v1 [cs.SI])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12726",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rahimi_M/0/1/0/all/0/1\">Masoud Rahimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moradi_H/0/1/0/all/0/1\">Hadi Moradi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vahabie_A/0/1/0/all/0/1\">Abdol-hossein Vahabie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kebriaei_H/0/1/0/all/0/1\">Hamed Kebriaei</a>",
          "description": "Dynamic Difficulty Adjustment (DDA) is a viable approach to enhance a\nplayer's experience in video games. Recently, Reinforcement Learning (RL)\nmethods have been employed for DDA in non-competitive games; nevertheless, they\nrely solely on discrete state-action space with a small search space. In this\npaper, we propose a continuous RL-based DDA methodology for a visual working\nmemory (VWM) game to handle the complex search space for the difficulty of\nmemorization. The proposed RL-based DDA tailors game difficulty based on the\nplayer's score and game difficulty in the last trial. We defined a continuous\nmetric for the difficulty of memorization. Then, we consider the task\ndifficulty and the vector of difficulty-score as the RL's action and state,\nrespectively. We evaluated the proposed method through a within-subject\nexperiment involving 52 subjects. The proposed approach was compared with two\nrule-based difficulty adjustment methods in terms of player's score and game\nexperience measured by a questionnaire. The proposed RL-based approach resulted\nin a significantly better game experience in terms of competence, tension, and\nnegative and positive affect. Players also achieved higher scores and win\nrates. Furthermore, the proposed RL-based DDA led to a significantly less\ndecline in the score in a 20-trial session.",
          "link": "http://arxiv.org/abs/2308.12726",
          "publishedOn": "2023-08-26T00:39:49.626Z",
          "wordCount": null,
          "title": "Continuous Reinforcement Learning-based Dynamic Difficulty Adjustment in a Visual Working Memory Game. (arXiv:2308.12726v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12393",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_K/0/1/0/all/0/1\">Kaushal Kumar</a>",
          "description": "Accurately estimating parameters in complex nonlinear systems is crucial\nacross scientific and engineering fields. We present a novel approach for\nparameter estimation using a neural network with the Huber loss function. This\nmethod taps into deep learning's abilities to uncover parameters governing\nintricate behaviors in nonlinear equations. We validate our approach using\nsynthetic data and predefined functions that model system dynamics. By training\nthe neural network with noisy time series data, it fine-tunes the Huber loss\nfunction to converge to accurate parameters. We apply our method to damped\noscillators, Van der Pol oscillators, Lotka-Volterra systems, and Lorenz\nsystems under multiplicative noise. The trained neural network accurately\nestimates parameters, evident from closely matching latent dynamics. Comparing\ntrue and estimated trajectories visually reinforces our method's precision and\nrobustness. Our study underscores the Huber loss-guided neural network as a\nversatile tool for parameter estimation, effectively uncovering complex\nrelationships in nonlinear systems. The method navigates noise and uncertainty\nadeptly, showcasing its adaptability to real-world challenges.",
          "link": "http://arxiv.org/abs/2308.12393",
          "publishedOn": "2023-08-26T00:39:49.625Z",
          "wordCount": null,
          "title": "Machine learning in parameter estimation of nonlinear systems. (arXiv:2308.12393v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12599",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chae_Y/0/1/0/all/0/1\">Yunkee Chae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koo_J/0/1/0/all/0/1\">Junghyun Koo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sungho Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kyogu Lee</a>",
          "description": "With the proliferation of video platforms on the internet, recording musical\nperformances by mobile devices has become commonplace. However, these\nrecordings often suffer from degradation such as noise and reverberation, which\nnegatively impact the listening experience. Consequently, the necessity for\nmusic audio enhancement (referred to as music enhancement from this point\nonward), involving the transformation of degraded audio recordings into\npristine high-quality music, has surged to augment the auditory experience. To\naddress this issue, we propose a music enhancement system based on the\nConformer architecture that has demonstrated outstanding performance in speech\nenhancement tasks. Our approach explores the attention mechanisms of the\nConformer and examines their performance to discover the best approach for the\nmusic enhancement task. Our experimental results show that our proposed model\nachieves state-of-the-art performance on single-stem music enhancement.\nFurthermore, our system can perform general music enhancement with multi-track\nmixtures, which has not been examined in previous work.",
          "link": "http://arxiv.org/abs/2308.12599",
          "publishedOn": "2023-08-26T00:39:49.621Z",
          "wordCount": null,
          "title": "Exploiting Time-Frequency Conformers for Music Audio Enhancement. (arXiv:2308.12599v1 [cs.SD])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12584",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koch_T/0/1/0/all/0/1\">Tobias Koch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riess_C/0/1/0/all/0/1\">Christian Riess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kohler_T/0/1/0/all/0/1\">Thomas K&#xf6;hler</a>",
          "description": "Handling entirely unknown data is a challenge for any deployed classifier.\nClassification models are typically trained on a static pre-defined dataset and\nare kept in the dark for the open unassigned feature space. As a result, they\nstruggle to deal with out-of-distribution data during inference. Addressing\nthis task on the class-level is termed open-set recognition (OSR). However,\nmost OSR methods are inherently limited, as they train closed-set classifiers\nand only adapt the downstream predictions to OSR. This work presents LORD, a\nframework to Leverage Open-set Recognition by exploiting unknown Data. LORD\nexplicitly models open space during classifier training and provides a\nsystematic evaluation for such approaches. We identify three model-agnostic\ntraining strategies that exploit background data and applied them to\nwell-established classifiers. Due to LORD's extensive evaluation protocol, we\nconsistently demonstrate improved recognition of unknown data. The benchmarks\nfacilitate in-depth analysis across various requirement levels. To mitigate\ndependency on extensive and costly background datasets, we explore mixup as an\noff-the-shelf data generation technique. Our experiments highlight mixup's\neffectiveness as a substitute for background datasets. Lightweight constraints\non mixup synthesis further improve OSR performance.",
          "link": "http://arxiv.org/abs/2308.12584",
          "publishedOn": "2023-08-26T00:39:49.620Z",
          "wordCount": null,
          "title": "LORD: Leveraging Open-Set Recognition with Unknown Data. (arXiv:2308.12584v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12646",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kucherenko_T/0/1/0/all/0/1\">Taras Kucherenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagy_R/0/1/0/all/0/1\">Rajmund Nagy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_Y/0/1/0/all/0/1\">Youngwoo Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woo_J/0/1/0/all/0/1\">Jieyeon Woo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikolov_T/0/1/0/all/0/1\">Teodor Nikolov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsakov_M/0/1/0/all/0/1\">Mihail Tsakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henter_G/0/1/0/all/0/1\">Gustav Eje Henter</a>",
          "description": "This paper reports on the GENEA Challenge 2023, in which participating teams\nbuilt speech-driven gesture-generation systems using the same speech and motion\ndataset, followed by a joint evaluation. This year's challenge provided data on\nboth sides of a dyadic interaction, allowing teams to generate full-body motion\nfor an agent given its speech (text and audio) and the speech and motion of the\ninterlocutor. We evaluated 12 submissions and 2 baselines together with\nheld-out motion-capture data in several large-scale user studies. The studies\nfocused on three aspects: 1) the human-likeness of the motion, 2) the\nappropriateness of the motion for the agent's own speech whilst controlling for\nthe human-likeness of the motion, and 3) the appropriateness of the motion for\nthe behaviour of the interlocutor in the interaction, using a setup that\ncontrols for both the human-likeness of the motion and the agent's own speech.\nWe found a large span in human-likeness between challenge submissions, with a\nfew systems rated close to human mocap. Appropriateness seems far from being\nsolved, with most submissions performing in a narrow range slightly above\nchance, far behind natural motion. The effect of the interlocutor is even more\nsubtle, with submitted systems at best performing barely above chance.\nInterestingly, a dyadic system being highly appropriate for agent speech does\nnot necessarily imply high appropriateness for the interlocutor. Additional\nmaterial is available via the project website at\nhttps://svito-zar.github.io/GENEAchallenge2023/ .",
          "link": "http://arxiv.org/abs/2308.12646",
          "publishedOn": "2023-08-26T00:39:49.619Z",
          "wordCount": null,
          "title": "The GENEA Challenge 2023: A large scale evaluation of gesture generation models in monadic and dyadic settings. (arXiv:2308.12646v1 [cs.HC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12761",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Aung_N/0/1/0/all/0/1\">Nyothiri Aung</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kechadi_T/0/1/0/all/0/1\">Tahar Kechadi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_L/0/1/0/all/0/1\">Liming Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dhelim_S/0/1/0/all/0/1\">Sahraoui Dhelim</a>",
          "description": "CNNs have been widely applied for medical image analysis. However, limited\nmemory capacity is one of the most common drawbacks of processing\nhigh-resolution 3D volumetric data. 3D volumes are usually cropped or downsized\nfirst before processing, which can result in a loss of resolution, increase\nclass imbalance, and affect the performance of the segmentation algorithms. In\nthis paper, we propose an end-to-end deep learning approach called IP-UNet.\nIP-UNet is a UNet-based model that performs multi-class segmentation on\nIntensity Projection (IP) of 3D volumetric data instead of the memory-consuming\n3D volumes. IP-UNet uses limited memory capability for training without losing\nthe original 3D image resolution. We compare the performance of three models in\nterms of segmentation accuracy and computational cost: 1) Slice-by-slice 2D\nsegmentation of the CT scan images using a conventional 2D UNet model. 2)\nIP-UNet that operates on data obtained by merging the extracted Maximum\nIntensity Projection (MIP), Closest Vessel Projection (CVP), and Average\nIntensity Projection (AvgIP) representations of the source 3D volumes, then\napplying the UNet model on the output IP images. 3) 3D-UNet model directly\nreads the 3D volumes constructed from a series of CT scan images and outputs\nthe 3D volume of the predicted segmentation. We test the performance of these\nmethods on 3D volumetric images for automatic breast calcification detection.\nExperimental results show that IP-Unet can achieve similar segmentation\naccuracy with 3D-Unet but with much better performance. It reduces the training\ntime by 70\\% and memory consumption by 92\\%.",
          "link": "http://arxiv.org/abs/2308.12761",
          "publishedOn": "2023-08-26T00:39:49.618Z",
          "wordCount": null,
          "title": "IP-UNet: Intensity Projection UNet Architecture for 3D Medical Volume Segmentation. (arXiv:2308.12761v1 [eess.IV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12691",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_B/0/1/0/all/0/1\">Bohan Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianzhong Li</a>",
          "description": "This paper introduces a new data analysis method for big data using a newly\ndefined regression model named multiple model linear regression(MMLR), which\nseparates input datasets into subsets and construct local linear regression\nmodels of them. The proposed data analysis method is shown to be more efficient\nand flexible than other regression based methods. This paper also proposes an\napproximate algorithm to construct MMLR models based on\n$(\\epsilon,\\delta)$-estimator, and gives mathematical proofs of the correctness\nand efficiency of MMLR algorithm, of which the time complexity is linear with\nrespect to the size of input datasets. This paper also empirically implements\nthe method on both synthetic and real-world datasets, the algorithm shows to\nhave comparable performance to existing regression methods in many cases, while\nit takes almost the shortest time to provide a high prediction accuracy.",
          "link": "http://arxiv.org/abs/2308.12691",
          "publishedOn": "2023-08-26T00:39:49.617Z",
          "wordCount": null,
          "title": "An Efficient Data Analysis Method for Big Data using Multiple-Model Linear Regression. (arXiv:2308.12691v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bendada_W/0/1/0/all/0/1\">Walid Bendada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salha_Galvan_G/0/1/0/all/0/1\">Guillaume Salha-Galvan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hennequin_R/0/1/0/all/0/1\">Romain Hennequin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouabca_T/0/1/0/all/0/1\">Thomas Bouab&#xe7;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cazenave_T/0/1/0/all/0/1\">Tristan Cazenave</a>",
          "description": "A prevalent practice in recommender systems consists of averaging item\nembeddings to represent users or higher-level concepts in the same embedding\nspace. This paper investigates the relevance of such a practice. For this\npurpose, we propose an expected precision score, designed to measure the\nconsistency of an average embedding relative to the items used for its\nconstruction. We subsequently analyze the mathematical expression of this score\nin a theoretical setting with specific assumptions, as well as its empirical\nbehavior on real-world data from music streaming services. Our results\nemphasize that real-world averages are less consistent for recommendation,\nwhich paves the way for future research to better align real-world embeddings\nwith assumptions from our theoretical setting.",
          "link": "http://arxiv.org/abs/2308.12767",
          "publishedOn": "2023-08-26T00:39:49.564Z",
          "wordCount": null,
          "title": "On the Consistency of Average Embeddings for Item Recommendation. (arXiv:2308.12767v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.00143",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dumais_F/0/1/0/all/0/1\">F&#xe9;lix Dumais</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Legarreta_J/0/1/0/all/0/1\">Jon Haitz Legarreta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lemaire_C/0/1/0/all/0/1\">Carl Lemaire</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poulin_P/0/1/0/all/0/1\">Philippe Poulin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rheault_F/0/1/0/all/0/1\">Fran&#xe7;ois Rheault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petit_L/0/1/0/all/0/1\">Laurent Petit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barakovic_M/0/1/0/all/0/1\">Muhamed Barakovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magon_S/0/1/0/all/0/1\">Stefano Magon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Descoteaux_M/0/1/0/all/0/1\">Maxime Descoteaux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jodoin_P/0/1/0/all/0/1\">Pierre-Marc Jodoin</a> (for the Alzheimer&#x27;s Disease Neuroimaging Initiative)",
          "description": "White matter bundle segmentation is a cornerstone of modern tractography to\nstudy the brain's structural connectivity in domains such as neurological\ndisorders, neurosurgery, and aging. In this study, we present FIESTA (FIbEr\nSegmentation in Tractography using Autoencoders), a reliable and robust, fully\nautomated, and easily semi-automatically calibrated pipeline based on deep\nautoencoders that can dissect and fully populate white matter bundles. This\npipeline is built upon previous works that demonstrated how autoencoders can be\nused successfully for streamline filtering, bundle segmentation, and streamline\ngeneration in tractography. Our proposed method improves bundle segmentation\ncoverage by recovering hard-to-track bundles with generative sampling through\nthe latent space seeding of the subject bundle and the atlas bundle. A latent\nspace of streamlines is learned using autoencoder-based modeling combined with\ncontrastive learning. Using an atlas of bundles in standard space (MNI), our\nproposed method segments new tractograms using the autoencoder latent distance\nbetween each tractogram streamline and its closest neighbor bundle in the atlas\nof bundles. Intra-subject bundle reliability is improved by recovering\nhard-to-track streamlines, using the autoencoder to generate new streamlines\nthat increase the spatial coverage of each bundle while remaining anatomically\ncorrect. Results show that our method is more reliable than state-of-the-art\nautomated virtual dissection methods such as RecoBundles, RecoBundlesX,\nTractSeg, White Matter Analysis and XTRACT. Our framework allows for the\ntransition from one anatomical bundle definition to another with marginal\ncalibration efforts. Overall, these results show that our framework improves\nthe practicality and usability of current state-of-the-art bundle segmentation\nframework.",
          "link": "http://arxiv.org/abs/2212.00143",
          "publishedOn": "2023-08-26T00:39:49.559Z",
          "wordCount": null,
          "title": "FIESTA: Autoencoders for accurate fiber segmentation in tractography. (arXiv:2212.00143v3 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12453",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sagers_L/0/1/0/all/0/1\">Luke W. Sagers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diao_J/0/1/0/all/0/1\">James A. Diao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melas_Kyriazi_L/0/1/0/all/0/1\">Luke Melas-Kyriazi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Groh_M/0/1/0/all/0/1\">Matthew Groh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajpurkar_P/0/1/0/all/0/1\">Pranav Rajpurkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adamson_A/0/1/0/all/0/1\">Adewole S. Adamson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rotemberg_V/0/1/0/all/0/1\">Veronica Rotemberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daneshjou_R/0/1/0/all/0/1\">Roxana Daneshjou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manrai_A/0/1/0/all/0/1\">Arjun K. Manrai</a>",
          "description": "While hundreds of artificial intelligence (AI) algorithms are now approved or\ncleared by the US Food and Drugs Administration (FDA), many studies have shown\ninconsistent generalization or latent bias, particularly for underrepresented\npopulations. Some have proposed that generative AI could reduce the need for\nreal data, but its utility in model development remains unclear. Skin disease\nserves as a useful case study in synthetic image generation due to the\ndiversity of disease appearance, particularly across the protected attribute of\nskin tone. Here we show that latent diffusion models can scalably generate\nimages of skin disease and that augmenting model training with these data\nimproves performance in data-limited settings. These performance gains saturate\nat synthetic-to-real image ratios above 10:1 and are substantially smaller than\nthe gains obtained from adding real images. As part of our analysis, we\ngenerate and analyze a new dataset of 458,920 synthetic images produced using\nseveral generation strategies. Our results suggest that synthetic data could\nserve as a force-multiplier for model development, but the collection of\ndiverse real-world data remains the most important step to improve medical AI\nalgorithms.",
          "link": "http://arxiv.org/abs/2308.12453",
          "publishedOn": "2023-08-26T00:39:49.558Z",
          "wordCount": null,
          "title": "Augmenting medical image classifiers with synthetic data from latent diffusion models. (arXiv:2308.12453v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12304",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Magner_A/0/1/0/all/0/1\">Abram Magner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Padakandla_A/0/1/0/all/0/1\">Arun Padakandla</a>",
          "description": "We characterize learnability for quantum measurement classes by establishing\nmatching necessary and sufficient conditions for their PAC learnability, along\nwith corresponding sample complexity bounds, in the setting where the learner\nis given access only to prepared quantum states. We first probe the results\nfrom previous works on this setting. We show that the empirical risk defined in\nprevious works and matching the definition in the classical theory fails to\nsatisfy the uniform convergence property enjoyed in the classical setting for\nsome learnable classes. Moreover, we show that VC dimension generalization\nupper bounds in previous work are frequently infinite, even for\nfinite-dimensional POVM classes. To surmount the failure of the standard ERM to\nsatisfy uniform convergence, we define a new learning rule -- denoised ERM. We\nshow this to be a universal learning rule for POVM and probabilistically\nobserved concept classes, and the condition for it to satisfy uniform\nconvergence is finite fat shattering dimension of the class. We give\nquantitative sample complexity upper and lower bounds for learnability in terms\nof finite fat-shattering dimension and a notion of approximate finite\npartitionability into approximately jointly measurable subsets, which allow for\nsample reuse. We then show that finite fat shattering dimension implies finite\ncoverability by approximately jointly measurable subsets, leading to our\nmatching conditions. We also show that every measurement class defined on a\nfinite-dimensional Hilbert space is PAC learnable. We illustrate our results on\nseveral example POVM classes.",
          "link": "http://arxiv.org/abs/2308.12304",
          "publishedOn": "2023-08-26T00:39:49.554Z",
          "wordCount": null,
          "title": "Fat Shattering, Joint Measurability, and PAC Learnability of POVM Hypothesis Classes. (arXiv:2308.12304v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12553",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Puli_A/0/1/0/all/0/1\">Aahlad Puli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lily Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wald_Y/0/1/0/all/0/1\">Yoav Wald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranganath_R/0/1/0/all/0/1\">Rajesh Ranganath</a>",
          "description": "Common explanations for shortcut learning assume that the shortcut improves\nprediction under the training distribution but not in the test distribution.\nThus, models trained via the typical gradient-based optimization of\ncross-entropy, which we call default-ERM, utilize the shortcut. However, even\nwhen the stable feature determines the label in the training distribution and\nthe shortcut does not provide any additional information, like in perception\ntasks, default-ERM still exhibits shortcut learning. Why are such solutions\npreferred when the loss for default-ERM can be driven to zero using the stable\nfeature alone? By studying a linear perception task, we show that default-ERM's\npreference for maximizing the margin leads to models that depend more on the\nshortcut than the stable feature, even without overparameterization. This\ninsight suggests that default-ERM's implicit inductive bias towards max-margin\nis unsuitable for perception tasks. Instead, we develop an inductive bias\ntoward uniform margins and show that this bias guarantees dependence only on\nthe perfect stable feature in the linear perception task. We develop loss\nfunctions that encourage uniform-margin solutions, called margin control\n(MARG-CTRL). MARG-CTRL mitigates shortcut learning on a variety of vision and\nlanguage tasks, showing that better inductive biases can remove the need for\nexpensive two-stage shortcut-mitigating methods in perception tasks.",
          "link": "http://arxiv.org/abs/2308.12553",
          "publishedOn": "2023-08-26T00:39:49.554Z",
          "wordCount": null,
          "title": "Don't blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy. (arXiv:2308.12553v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.04528",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kaijie Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jiaheng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zichen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Linyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1\">Wei Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1\">Neil Zhenqiang Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>",
          "description": "The increasing reliance on Large Language Models (LLMs) across academia and\nindustry necessitates a comprehensive understanding of their robustness to\nprompts. In response to this vital need, we introduce PromptBench, a robustness\nbenchmark designed to measure LLMs' resilience to adversarial prompts. This\nstudy uses a plethora of adversarial textual attacks targeting prompts across\nmultiple levels: character, word, sentence, and semantic. These prompts are\nthen employed in diverse tasks, such as sentiment analysis, natural language\ninference, reading comprehension, machine translation, and math\nproblem-solving. Our study generates 4,032 adversarial prompts, meticulously\nevaluated over 8 tasks and 13 datasets, with 567,084 test samples in total. Our\nfindings demonstrate that contemporary LLMs are vulnerable to adversarial\nprompts. Furthermore, we present comprehensive analysis to understand the\nmystery behind prompt robustness and its transferability. We then offer\ninsightful robustness analysis and pragmatic recommendations for prompt\ncomposition, beneficial to both researchers and everyday users. We make our\ncode, prompts, and methodologies to generate adversarial prompts publicly\naccessible, thereby enabling and encouraging collaborative exploration in this\npivotal field: https://github.com/microsoft/promptbench.",
          "link": "http://arxiv.org/abs/2306.04528",
          "publishedOn": "2023-08-26T00:39:49.553Z",
          "wordCount": null,
          "title": "PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts. (arXiv:2306.04528v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12634",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cersovsky_J/0/1/0/all/0/1\">Josef Cersovsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammadi_S/0/1/0/all/0/1\">Sadegh Mohammadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kainmueller_D/0/1/0/all/0/1\">Dagmar Kainmueller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoehne_J/0/1/0/all/0/1\">Johannes Hoehne</a>",
          "description": "The classification of gigapixel histopathology images with deep multiple\ninstance learning models has become a critical task in digital pathology and\nprecision medicine. In this work, we propose a Transformer-based multiple\ninstance learning approach that replaces the traditional learned attention\nmechanism with a regional, Vision Transformer inspired self-attention\nmechanism. We present a method that fuses regional patch information to derive\nslide-level predictions and show how this regional aggregation can be stacked\nto hierarchically process features on different distance levels. To increase\npredictive accuracy, especially for datasets with small, local morphological\nfeatures, we introduce a method to focus the image processing on high attention\nregions during inference. Our approach is able to significantly improve\nperformance over the baseline on two histopathology datasets and points towards\npromising directions for further research.",
          "link": "http://arxiv.org/abs/2308.12634",
          "publishedOn": "2023-08-26T00:39:49.552Z",
          "wordCount": null,
          "title": "Towards Hierarchical Regional Transformer-based Multiple Instance Learning. (arXiv:2308.12634v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.15490",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Sharma_H/0/1/0/all/0/1\">Harsh Sharma</a>, <a href=\"http://arxiv.org/find/math/1/au:+Mu_H/0/1/0/all/0/1\">Hongliang Mu</a>, <a href=\"http://arxiv.org/find/math/1/au:+Buchfink_P/0/1/0/all/0/1\">Patrick Buchfink</a>, <a href=\"http://arxiv.org/find/math/1/au:+Geelen_R/0/1/0/all/0/1\">Rudy Geelen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Glas_S/0/1/0/all/0/1\">Silke Glas</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kramer_B/0/1/0/all/0/1\">Boris Kramer</a>",
          "description": "This work presents two novel approaches for the symplectic model reduction of\nhigh-dimensional Hamiltonian systems using data-driven quadratic manifolds.\nClassical symplectic model reduction approaches employ linear symplectic\nsubspaces for representing the high-dimensional system states in a\nreduced-dimensional coordinate system. While these approximations respect the\nsymplectic nature of Hamiltonian systems, linear basis approximations can\nsuffer from slowly decaying Kolmogorov $N$-width, especially in wave-type\nproblems, which then requires a large basis size. We propose two different\nmodel reduction methods based on recently developed quadratic manifolds, each\npresenting its own advantages and limitations. The addition of quadratic terms\nto the state approximation, which sits at the heart of the proposed\nmethodologies, enables us to better represent intrinsic low-dimensionality in\nthe problem at hand. Both approaches are effective for issuing predictions in\nsettings well outside the range of their training data while providing more\naccurate solutions than the linear symplectic reduced-order models.",
          "link": "http://arxiv.org/abs/2305.15490",
          "publishedOn": "2023-08-26T00:39:49.538Z",
          "wordCount": null,
          "title": "Symplectic model reduction of Hamiltonian systems using data-driven quadratic manifolds. (arXiv:2305.15490v2 [math.NA] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12438",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yahmed_A/0/1/0/all/0/1\">Ahmed Haj Yahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbassi_A/0/1/0/all/0/1\">Altaf Allah Abbassi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikanjam_A/0/1/0/all/0/1\">Amin Nikanjam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Heng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khomh_F/0/1/0/all/0/1\">Foutse Khomh</a>",
          "description": "Deep reinforcement learning (DRL), leveraging Deep Learning (DL) in\nreinforcement learning, has shown significant potential in achieving\nhuman-level autonomy in a wide range of domains, including robotics, computer\nvision, and computer games. This potential justifies the enthusiasm and growing\ninterest in DRL in both academia and industry. However, the community currently\nfocuses mostly on the development phase of DRL systems, with little attention\ndevoted to DRL deployment. In this paper, we propose an empirical study on\nStack Overflow (SO), the most popular Q&A forum for developers, to uncover and\nunderstand the challenges practitioners faced when deploying DRL systems.\nSpecifically, we categorized relevant SO posts by deployment platforms:\nserver/cloud, mobile/embedded system, browser, and game engine. After filtering\nand manual analysis, we examined 357 SO posts about DRL deployment,\ninvestigated the current state, and identified the challenges related to\ndeploying DRL systems. Then, we investigate the prevalence and difficulty of\nthese challenges. Results show that the general interest in DRL deployment is\ngrowing, confirming the study's relevance and importance. Results also show\nthat DRL deployment is more difficult than other DRL issues. Additionally, we\nbuilt a taxonomy of 31 unique challenges in deploying DRL to different\nplatforms. On all platforms, RL environment-related challenges are the most\npopular, and communication-related challenges are the most difficult among\npractitioners. We hope our study inspires future research and helps the\ncommunity overcome the most common and difficult challenges practitioners face\nwhen deploying DRL systems.",
          "link": "http://arxiv.org/abs/2308.12438",
          "publishedOn": "2023-08-26T00:39:49.537Z",
          "wordCount": null,
          "title": "Deploying Deep Reinforcement Learning Systems: A Taxonomy of Challenges. (arXiv:2308.12438v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12381",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Krstovski_K/0/1/0/all/0/1\">Kriste Krstovski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Ye Xu</a>",
          "description": "A person's gender is a crucial piece of information when performing research\nacross a wide range of scientific disciplines, such as medicine, sociology,\npolitical science, and economics, to name a few. However, in increasing\ninstances, especially given the proliferation of big data, gender information\nis not readily available. In such cases researchers need to infer gender from\nreadily available information, primarily from persons' names. While inferring\ngender from name may raise some ethical questions, the lack of viable\nalternatives means that researchers have to resort to such approaches when the\ngoal justifies the means - in the majority of such studies the goal is to\nexamine patterns and determinants of gender disparities. The necessity of\nname-to-gender inference has generated an ever-growing domain of algorithmic\napproaches and software products. These approaches have been used throughout\nthe world in academia, industry, governmental and non-governmental\norganizations. Nevertheless, the existing approaches have yet to be\nsystematically evaluated and compared, making it challenging to determine the\noptimal approach for future research. In this work, we conducted a large scale\nperformance evaluation of existing approaches for name-to-gender inference.\nAnalysis are performed using a variety of large annotated datasets of names. We\nfurther propose two new hybrid approaches that achieve better performance than\nany single existing approach.",
          "link": "http://arxiv.org/abs/2308.12381",
          "publishedOn": "2023-08-26T00:39:49.536Z",
          "wordCount": null,
          "title": "Inferring gender from name: a large scale performance evaluation study. (arXiv:2308.12381v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amakor_A/0/1/0/all/0/1\">Augustina C. Amakor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonntag_K/0/1/0/all/0/1\">Konstantin Sonntag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peitz_S/0/1/0/all/0/1\">Sebastian Peitz</a>",
          "description": "Sparsity is a highly desired feature in deep neural networks (DNNs) since it\nensures numerical efficiency, improves the interpretability of models (due to\nthe smaller number of relevant features), and robustness. In machine learning\napproaches based on linear models, it is well known that there exists a\nconnecting path between the sparsest solution in terms of the $\\ell^1$ norm\n(i.e., zero weights) and the non-regularized solution, which is called the\nregularization path. Very recently, there was a first attempt to extend the\nconcept of regularization paths to DNNs by means of treating the empirical loss\nand sparsity ($\\ell^1$ norm) as two conflicting criteria and solving the\nresulting multiobjective optimization problem. However, due to the\nnon-smoothness of the $\\ell^1$ norm and the high number of parameters, this\napproach is not very efficient from a computational perspective. To overcome\nthis limitation, we present an algorithm that allows for the approximation of\nthe entire Pareto front for the above-mentioned objectives in a very efficient\nmanner. We present numerical examples using both deterministic and stochastic\ngradients. We furthermore demonstrate that knowledge of the regularization path\nallows for a well-generalizing network parametrization.",
          "link": "http://arxiv.org/abs/2308.12044",
          "publishedOn": "2023-08-26T00:39:49.480Z",
          "wordCount": null,
          "title": "A multiobjective continuation method to compute the regularization path of deep neural networks. (arXiv:2308.12044v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12686",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Painblanc_F/0/1/0/all/0/1\">Fran&#xe7;ois Painblanc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chapel_L/0/1/0/all/0/1\">Laetitia Chapel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courty_N/0/1/0/all/0/1\">Nicolas Courty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friguet_C/0/1/0/all/0/1\">Chlo&#xe9; Friguet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pelletier_C/0/1/0/all/0/1\">Charlotte Pelletier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tavenard_R/0/1/0/all/0/1\">Romain Tavenard</a>",
          "description": "While large volumes of unlabeled data are usually available, associated\nlabels are often scarce. The unsupervised domain adaptation problem aims at\nexploiting labels from a source domain to classify data from a related, yet\ndifferent, target domain. When time series are at stake, new difficulties arise\nas temporal shifts may appear in addition to the standard feature distribution\nshift. In this paper, we introduce the Match-And-Deform (MAD) approach that\naims at finding correspondences between the source and target time series while\nallowing temporal distortions. The associated optimization problem\nsimultaneously aligns the series thanks to an optimal transport loss and the\ntime stamps through dynamic time warping. When embedded into a deep neural\nnetwork, MAD helps learning new representations of time series that both align\nthe domains and maximize the discriminative power of the network. Empirical\nstudies on benchmark datasets and remote sensing data demonstrate that MAD\nmakes meaningful sample-to-sample pairing and time shift estimation, reaching\nsimilar or better classification performance than state-of-the-art deep time\nseries domain adaptation strategies.",
          "link": "http://arxiv.org/abs/2308.12686",
          "publishedOn": "2023-08-26T00:39:49.479Z",
          "wordCount": null,
          "title": "Match-And-Deform: Time Series Domain Adaptation through Optimal Transport and Temporal Alignment. (arXiv:2308.12686v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12968",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yuxin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Liming Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shuai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1\">Chen Change Loy</a>",
          "description": "Automatic high-quality rendering of anime scenes from complex real-world\nimages is of significant practical value. The challenges of this task lie in\nthe complexity of the scenes, the unique features of anime style, and the lack\nof high-quality datasets to bridge the domain gap. Despite promising attempts,\nprevious efforts are still incompetent in achieving satisfactory results with\nconsistent semantic preservation, evident stylization, and fine details. In\nthis study, we propose Scenimefy, a novel semi-supervised image-to-image\ntranslation framework that addresses these challenges. Our approach guides the\nlearning with structure-consistent pseudo paired data, simplifying the pure\nunsupervised setting. The pseudo data are derived uniquely from a\nsemantic-constrained StyleGAN leveraging rich model priors like CLIP. We\nfurther apply segmentation-guided data selection to obtain high-quality pseudo\nsupervision. A patch-wise contrastive style loss is introduced to improve\nstylization and fine details. Besides, we contribute a high-resolution anime\nscene dataset to facilitate future research. Our extensive experiments\ndemonstrate the superiority of our method over state-of-the-art baselines in\nterms of both perceptual quality and quantitative performance.",
          "link": "http://arxiv.org/abs/2308.12968",
          "publishedOn": "2023-08-26T00:39:49.479Z",
          "wordCount": null,
          "title": "Scenimefy: Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation. (arXiv:2308.12968v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.14598",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Magris_M/0/1/0/all/0/1\">Martin Magris</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shabani_M/0/1/0/all/0/1\">Mostafa Shabani</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Iosifidis_A/0/1/0/all/0/1\">Alexandros Iosifidis</a>",
          "description": "We propose an optimization algorithm for Variational Inference (VI) in\ncomplex models. Our approach relies on natural gradient updates where the\nvariational space is a Riemann manifold. We develop an efficient algorithm for\nGaussian Variational Inference that implicitly satisfies the positive definite\nconstraint on the variational covariance matrix. Our Exact manifold Gaussian\nVariational Bayes (EMGVB) provides exact but simple update rules and is\nstraightforward to implement. Due to its black-box nature, EMGVB stands as a\nready-to-use solution for VI in complex models. Over five datasets, we\nempirically validate our feasible approach on different statistical,\neconometric, and deep learning models, discussing its performance with respect\nto baseline methods.",
          "link": "http://arxiv.org/abs/2210.14598",
          "publishedOn": "2023-08-26T00:39:49.477Z",
          "wordCount": null,
          "title": "Exact Manifold Gaussian Variational Bayes. (arXiv:2210.14598v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12925",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Renz_P/0/1/0/all/0/1\">Philipp Renz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cutajar_K/0/1/0/all/0/1\">Kurt Cutajar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Twomey_N/0/1/0/all/0/1\">Niall Twomey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheung_G/0/1/0/all/0/1\">Gavin K. C. Cheung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1\">Hanting Xie</a>",
          "description": "Low-count time series describe sparse or intermittent events, which are\nprevalent in large-scale online platforms that capture and monitor diverse data\ntypes. Several distinct challenges surface when modelling low-count time\nseries, particularly low signal-to-noise ratios (when anomaly signatures are\nprovably undetectable), and non-uniform performance (when average metrics are\nnot representative of local behaviour). The time series anomaly detection\ncommunity currently lacks explicit tooling and processes to model and reliably\ndetect anomalies in these settings. We address this gap by introducing a novel\ngenerative procedure for creating benchmark datasets comprising of low-count\ntime series with anomalous segments. Via a mixture of theoretical and empirical\nanalysis, our work explains how widely-used algorithms struggle with the\ndistribution overlap between normal and anomalous segments. In order to\nmitigate this shortcoming, we then leverage our findings to demonstrate how\nanomaly score smoothing consistently improves performance. The practical\nutility of our analysis and recommendation is validated on a real-world dataset\ncontaining sales data for retail stores.",
          "link": "http://arxiv.org/abs/2308.12925",
          "publishedOn": "2023-08-26T00:39:49.474Z",
          "wordCount": null,
          "title": "Low-count Time Series Anomaly Detection. (arXiv:2308.12925v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.02169",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Theodorou_B/0/1/0/all/0/1\">Brandon Theodorou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Cao Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jimeng Sun</a>",
          "description": "Synthetic electronic health records (EHRs) that are both realistic and\npreserve privacy can serve as an alternative to real EHRs for machine learning\n(ML) modeling and statistical analysis. However, generating high-fidelity and\ngranular electronic health record (EHR) data in its original,\nhighly-dimensional form poses challenges for existing methods due to the\ncomplexities inherent in high-dimensional data. In this paper, we propose\nHierarchical Autoregressive Language mOdel (HALO) for generating longitudinal\nhigh-dimensional EHR, which preserve the statistical properties of real EHR and\ncan be used to train accurate ML models without privacy concerns. Our HALO\nmethod, designed as a hierarchical autoregressive model, generates a\nprobability density function of medical codes, clinical visits, and patient\nrecords, allowing for the generation of realistic EHR data in its original,\nunaggregated form without the need for variable selection or aggregation.\nAdditionally, our model also produces high-quality continuous variables in a\nlongitudinal and probabilistic manner. We conducted extensive experiments and\ndemonstrate that HALO can generate high-fidelity EHR data with high-dimensional\ndisease code probabilities (d > 10,000), disease co-occurrence probabilities\nwithin visits (d > 1,000,000), and conditional probabilities across consecutive\nvisits (d > 5,000,000) and achieve above 0.9 R2 correlation in comparison to\nreal EHR data. This performance then enables downstream ML models trained on\nits synthetic data to achieve comparable accuracy to models trained on real\ndata (0.938 AUROC with HALO data vs. 0.943 with real data). Finally, using a\ncombination of real and synthetic data enhances the accuracy of ML models\nbeyond that achieved by using only real EHR data.",
          "link": "http://arxiv.org/abs/2304.02169",
          "publishedOn": "2023-08-26T00:39:49.470Z",
          "wordCount": null,
          "title": "Synthesize High-dimensional Longitudinal Electronic Health Records via Hierarchical Autoregressive Language Model. (arXiv:2304.02169v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12530",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1\">Shengchao Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_Y/0/1/0/all/0/1\">Yishun Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_R/0/1/0/all/0/1\">Rui Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1\">Bingbing Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhong Zheng</a>",
          "description": "Meshes are widely used in 3D computer vision and graphics, but their\nirregular topology poses challenges in applying them to existing neural network\narchitectures. Recent advances in mesh neural networks turn to remeshing and\npush the boundary of pioneer methods that solely take the raw meshes as input.\nAlthough the remeshing offers a regular topology that significantly facilitates\nthe design of mesh network architectures, features extracted from such remeshed\nproxies may struggle to retain the underlying geometry faithfully, limiting the\nsubsequent neural network's capacity. To address this issue, we propose\nSieveNet, a novel paradigm that takes into account both the regular topology\nand the exact geometry. Specifically, this method utilizes structured mesh\ntopology from remeshing and accurate geometric information from\ndistortion-aware point sampling on the surface of the original mesh.\nFurthermore, our method eliminates the need for hand-crafted feature\nengineering and can leverage off-the-shelf network architectures such as the\nvision transformer. Comprehensive experimental results on classification and\nsegmentation tasks well demonstrate the effectiveness and superiority of our\nmethod.",
          "link": "http://arxiv.org/abs/2308.12530",
          "publishedOn": "2023-08-26T00:39:49.467Z",
          "wordCount": null,
          "title": "SieveNet: Selecting Point-Based Features for Mesh Networks. (arXiv:2308.12530v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12351",
          "author": "<a href=\"http://arxiv.org/find/hep-ph/1/au:+Diefenbacher_S/0/1/0/all/0/1\">Sascha Diefenbacher</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Liu_G/0/1/0/all/0/1\">Guan-Horng Liu</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Mikuni_V/0/1/0/all/0/1\">Vinicius Mikuni</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Nachman_B/0/1/0/all/0/1\">Benjamin Nachman</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Nie_W/0/1/0/all/0/1\">Weili Nie</a>",
          "description": "Machine learning-based unfolding has enabled unbinned and high-dimensional\ndifferential cross section measurements. Two main approaches have emerged in\nthis research area: one based on discriminative models and one based on\ngenerative models. The main advantage of discriminative models is that they\nlearn a small correction to a starting simulation while generative models scale\nbetter to regions of phase space with little data. We propose to use\nSchroedinger Bridges and diffusion models to create SBUnfold, an unfolding\napproach that combines the strengths of both discriminative and generative\nmodels. The key feature of SBUnfold is that its generative model maps one set\nof events into another without having to go through a known probability density\nas is the case for normalizing flows and standard diffusion models. We show\nthat SBUnfold achieves excellent performance compared to state of the art\nmethods on a synthetic Z+jets dataset.",
          "link": "http://arxiv.org/abs/2308.12351",
          "publishedOn": "2023-08-26T00:39:49.457Z",
          "wordCount": null,
          "title": "Improving Generative Model-based Unfolding with Schr\\\"{o}dinger Bridges. (arXiv:2308.12351v1 [hep-ph])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.04504",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jahan_I/0/1/0/all/0/1\">Israt Jahan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laskar_M/0/1/0/all/0/1\">Md Tahmid Rahman Laskar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1\">Chun Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jimmy Huang</a>",
          "description": "ChatGPT is a large language model developed by OpenAI. Despite its impressive\nperformance across various tasks, no prior work has investigated its capability\nin the biomedical domain yet. To this end, this paper aims to evaluate the\nperformance of ChatGPT on various benchmark biomedical tasks, such as relation\nextraction, document classification, question answering, and summarization. To\nthe best of our knowledge, this is the first work that conducts an extensive\nevaluation of ChatGPT in the biomedical domain. Interestingly, we find based on\nour evaluation that in biomedical datasets that have smaller training sets,\nzero-shot ChatGPT even outperforms the state-of-the-art fine-tuned generative\ntransformer models, such as BioGPT and BioBART. This suggests that ChatGPT's\npre-training on large text corpora makes it quite specialized even in the\nbiomedical domain. Our findings demonstrate that ChatGPT has the potential to\nbe a valuable tool for various tasks in the biomedical domain that lack large\nannotated data.",
          "link": "http://arxiv.org/abs/2306.04504",
          "publishedOn": "2023-08-26T00:39:49.437Z",
          "wordCount": null,
          "title": "Evaluation of ChatGPT on Biomedical Tasks: A Zero-Shot Comparison with Fine-Tuned Generative Transformers. (arXiv:2306.04504v3 [cs.CL] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12510",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhai_J/0/1/0/all/0/1\">Jiang-Tian Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xialei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagdanov_A/0/1/0/all/0/1\">Andrew D. Bagdanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Ke Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1\">Ming-Ming Cheng</a>",
          "description": "Class Incremental Learning (CIL) aims to sequentially learn new classes while\navoiding catastrophic forgetting of previous knowledge. We propose to use\nMasked Autoencoders (MAEs) as efficient learners for CIL. MAEs were originally\ndesigned to learn useful representations through reconstructive unsupervised\nlearning, and they can be easily integrated with a supervised loss for\nclassification. Moreover, MAEs can reliably reconstruct original input images\nfrom randomly selected patches, which we use to store exemplars from past tasks\nmore efficiently for CIL. We also propose a bilateral MAE framework to learn\nfrom image-level and embedding-level fusion, which produces better-quality\nreconstructed images and more stable representations. Our experiments confirm\nthat our approach performs better than the state-of-the-art on CIFAR-100,\nImageNet-Subset, and ImageNet-Full. The code is available at\nhttps://github.com/scok30/MAE-CIL .",
          "link": "http://arxiv.org/abs/2308.12510",
          "publishedOn": "2023-08-26T00:39:49.430Z",
          "wordCount": null,
          "title": "Masked Autoencoders are Efficient Class Incremental Learners. (arXiv:2308.12510v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12459",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ruiz_Moreno_E/0/1/0/all/0/1\">Emilio Ruiz-Moreno</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lopez_Ramos_L/0/1/0/all/0/1\">Luis Miguel L&#xf3;pez-Ramos</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Beferull_Lozano_B/0/1/0/all/0/1\">Baltasar Beferull-Lozano</a>",
          "description": "Digitalizing real-world analog signals typically involves sampling in time\nand discretizing in amplitude. Subsequent signal reconstructions inevitably\nincur an error that depends on the amplitude resolution and the temporal\ndensity of the acquired samples. From an implementation viewpoint, consistent\nsignal reconstruction methods have proven a profitable error-rate decay as the\nsampling rate increases. Despite that, these results are obtained under offline\nsettings. Therefore, a research gap exists regarding methods for consistent\nsignal reconstruction from data streams. This paper presents a method that\nconsistently reconstructs streamed multivariate time series of quantization\nintervals under a zero-delay response requirement. On the other hand, previous\nwork has shown that the temporal dependencies within univariate time series can\nbe exploited to reduce the roughness of zero-delay signal reconstructions. This\nwork shows that the spatiotemporal dependencies within multivariate time series\ncan also be exploited to achieve improved results. Specifically, the\nspatiotemporal dependencies of the multivariate time series are learned, with\nthe assistance of a recurrent neural network, to reduce the roughness of the\nsignal reconstruction on average while ensuring consistency. Our experiments\nshow that our proposed method achieves a favorable error-rate decay with the\nsampling rate compared to a similar but non-consistent reconstruction.",
          "link": "http://arxiv.org/abs/2308.12459",
          "publishedOn": "2023-08-26T00:39:49.429Z",
          "wordCount": null,
          "title": "Zero-delay Consistent Signal Reconstruction from Streamed Multivariate Time Series. (arXiv:2308.12459v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12581",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Puning Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1\">Fei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_Z/0/1/0/all/0/1\">Zhiguo Wan</a>",
          "description": "Federated learning systems are susceptible to adversarial attacks. To combat\nthis, we introduce a novel aggregator based on Huber loss minimization, and\nprovide a comprehensive theoretical analysis. Under independent and identically\ndistributed (i.i.d) assumption, our approach has several advantages compared to\nexisting methods. Firstly, it has optimal dependence on $\\epsilon$, which\nstands for the ratio of attacked clients. Secondly, our approach does not need\nprecise knowledge of $\\epsilon$. Thirdly, it allows different clients to have\nunequal data sizes. We then broaden our analysis to include non-i.i.d data,\nsuch that clients have slightly different distributions.",
          "link": "http://arxiv.org/abs/2308.12581",
          "publishedOn": "2023-08-26T00:39:49.429Z",
          "wordCount": null,
          "title": "A Huber Loss Minimization Approach to Byzantine Robust Federated Learning. (arXiv:2308.12581v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12949",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Ximeng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1\">Kihyuk Sohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1\">Kate Saenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mellina_C/0/1/0/all/0/1\">Clayton Mellina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_X/0/1/0/all/0/1\">Xiao Bian</a>",
          "description": "The cost of labeling data often limits the performance of machine learning\nsystems. In multi-task learning, related tasks provide information to each\nother and improve overall performance, but the label cost can vary among tasks.\nHow should the label budget (i.e. the amount of money spent on labeling) be\nallocated among different tasks to achieve optimal multi-task performance? We\nare the first to propose and formally define the label budget allocation\nproblem in multi-task learning and to empirically show that different budget\nallocation strategies make a big difference to its performance. We propose a\nTask-Adaptive Budget Allocation algorithm to robustly generate the optimal\nbudget allocation adaptive to different multi-task learning settings.\nSpecifically, we estimate and then maximize the extent of new information\nobtained from the allocated budget as a proxy for multi-task learning\nperformance. Experiments on PASCAL VOC and Taskonomy demonstrate the efficacy\nof our approach over other widely used heuristic labeling strategies.",
          "link": "http://arxiv.org/abs/2308.12949",
          "publishedOn": "2023-08-26T00:39:49.419Z",
          "wordCount": null,
          "title": "Label Budget Allocation in Multi-Task Learning. (arXiv:2308.12949v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12716",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Sahin_T/0/1/0/all/0/1\">T. Sahin</a>, <a href=\"http://arxiv.org/find/math/1/au:+Danwitz_M/0/1/0/all/0/1\">M. von Danwitz</a>, <a href=\"http://arxiv.org/find/math/1/au:+Popp_A/0/1/0/all/0/1\">A. Popp</a>",
          "description": "This paper explores the ability of physics-informed neural networks (PINNs)\nto solve forward and inverse problems of contact mechanics for small\ndeformation elasticity. We deploy PINNs in a mixed-variable formulation\nenhanced by output transformation to enforce Dirichlet and Neumann boundary\nconditions as hard constraints. Inequality constraints of contact problems,\nnamely Karush-Kuhn-Tucker (KKT) type conditions, are enforced as soft\nconstraints by incorporating them into the loss function during network\ntraining. To formulate the loss function contribution of KKT constraints,\nexisting approaches applied to elastoplasticity problems are investigated and\nwe explore a nonlinear complementarity problem (NCP) function, namely\nFischer-Burmeister, which possesses advantageous characteristics in terms of\noptimization. Based on the Hertzian contact problem, we show that PINNs can\nserve as pure partial differential equation (PDE) solver, as data-enhanced\nforward model, as inverse solver for parameter identification, and as\nfast-to-evaluate surrogate model. Furthermore, we demonstrate the importance of\nchoosing proper hyperparameters, e.g. loss weights, and a combination of Adam\nand L-BFGS-B optimizers aiming for better results in terms of accuracy and\ntraining time.",
          "link": "http://arxiv.org/abs/2308.12716",
          "publishedOn": "2023-08-26T00:39:49.411Z",
          "wordCount": null,
          "title": "Solving Forward and Inverse Problems of Contact Mechanics using Physics-Informed Neural Networks. (arXiv:2308.12716v1 [math.NA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12729",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shijie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1\">Xin Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xuejiao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_B/0/1/0/all/0/1\">Binfeng Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuangyang Wang</a>",
          "description": "Customer lifetime value (LTV) prediction is essential for mobile game\npublishers trying to optimize the advertising investment for each user\nacquisition based on the estimated worth. In mobile games, deploying\nmicrotransactions is a simple yet effective monetization strategy, which\nattracts a tiny group of game whales who splurge on in-game purchases. The\npresence of such game whales may impede the practicality of existing LTV\nprediction models, since game whales' purchase behaviours always exhibit varied\ndistribution from general users. Consequently, identifying game whales can open\nup new opportunities to improve the accuracy of LTV prediction models. However,\nlittle attention has been paid to applying game whale detection in LTV\nprediction, and existing works are mainly specialized for the long-term LTV\nprediction with the assumption that the high-quality user features are\navailable, which is not applicable in the UA stage. In this paper, we propose\nExpLTV, a novel multi-task framework to perform LTV prediction and game whale\ndetection in a unified way. In ExpLTV, we first innovatively design a deep\nneural network-based game whale detector that can not only infer the intrinsic\norder in accordance with monetary value, but also precisely identify high\nspenders (i.e., game whales) and low spenders. Then, by treating the game whale\ndetector as a gating network to decide the different mixture patterns of LTV\nexperts assembling, we can thoroughly leverage the shared information and\nscenario-specific information (i.e., game whales modelling and low spenders\nmodelling). Finally, instead of separately designing a purchase rate estimator\nfor two tasks, we design a shared estimator that can preserve the inner task\nrelationships. The superiority of ExpLTV is further validated via extensive\nexperiments on three industrial datasets.",
          "link": "http://arxiv.org/abs/2308.12729",
          "publishedOn": "2023-08-26T00:39:49.399Z",
          "wordCount": null,
          "title": "Out of the Box Thinking: Improving Customer Lifetime Value Modelling via Expert Routing and Game Whale Detection. (arXiv:2308.12729v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12481",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zhou_H/0/1/0/all/0/1\">Hannah Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_A/0/1/0/all/0/1\">Allison Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Buer_C/0/1/0/all/0/1\">Celine Buer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_E/0/1/0/all/0/1\">Emily Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tang_K/0/1/0/all/0/1\">Kayleen Tang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gong_L/0/1/0/all/0/1\">Lauryn Gong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiqi Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tang_J/0/1/0/all/0/1\">Jianbin Tang</a>",
          "description": "This paper presents a cost-effective, low-power approach to unintentional\nfall detection using knowledge distillation-based LSTM (Long Short-Term Memory)\nmodels to significantly improve accuracy. With a primary focus on analyzing\ntime-series data collected from various sensors, the solution offers real-time\ndetection capabilities, ensuring prompt and reliable identification of falls.\nThe authors investigate fall detection models that are based on different\nsensors, comparing their accuracy rates and performance. Furthermore, they\nemploy the technique of knowledge distillation to enhance the models'\nprecision, resulting in refined accurate configurations that consume lower\npower. As a result, this proposed solution presents a compelling avenue for the\ndevelopment of energy-efficient fall detection systems for future advancements\nin this critical domain.",
          "link": "http://arxiv.org/abs/2308.12481",
          "publishedOn": "2023-08-26T00:39:49.372Z",
          "wordCount": null,
          "title": "Fall Detection using Knowledge Distillation Based Long short-term memory for Offline Embedded and Low Power Devices. (arXiv:2308.12481v1 [eess.SP])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.11945",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhengyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1\">Cong Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhanda Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yangjie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yuxian Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xiaotian Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leng_J/0/1/0/all/0/1\">Jingwen Leng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1\">Minyi Guo</a>",
          "description": "Post-training quantization attracts increasing attention due to its\nconvenience in deploying quantized neural networks. Although\nrounding-to-nearest remains the prevailing method for DNN quantization, prior\nresearch has demonstrated its suboptimal nature when applied to weight\nquantization. They propose optimizing weight rounding schemes by leveraging\noutput error rather than the traditional weight quantization error. Our study\nreveals that similar rounding challenges also extend to activation\nquantization. Despite the easy generalization, the challenges lie in the\ndynamic nature of activation. Adaptive rounding is expected for varying\nactivations and the method is subjected to runtime overhead. To tackle this, we\npropose the AQuant quantization framework with a novel perspective to reduce\noutput error by adjusting rounding schemes of activations. Instead of using the\nconstant rounding border 0.5 of the rounding-to-nearest operation, we make the\nborder become a function w.r.t. the activation value to change the activation\nrounding by the adaptive border. To deal with the runtime overhead, we use a\ncoarse-grained version of the border function. Finally, we introduce our\nframework to optimize the border function. Extensive experiments show that\nAQuant achieves notable improvements compared to state-of-the-art works and\npushes the accuracy of ResNet-18 up to 60.31% under the 2-bit weight and\nactivation quantization.",
          "link": "http://arxiv.org/abs/2208.11945",
          "publishedOn": "2023-08-26T00:39:49.372Z",
          "wordCount": null,
          "title": "Efficient Adaptive Activation Rounding for Post-Training Quantization. (arXiv:2208.11945v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2304.08134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Knoche_M/0/1/0/all/0/1\">Martin Knoche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rigoll_G/0/1/0/all/0/1\">Gerhard Rigoll</a>",
          "description": "Nowadays, face recognition systems surpass human performance on several\ndatasets. However, there are still edge cases that the machine can't correctly\nclassify. This paper investigates the effect of a combination of machine and\nhuman operators in the face verification task. First, we look closer at the\nedge cases for several state-of-the-art models to discover common datasets'\nchallenging settings. Then, we conduct a study with 60 participants on these\nselected tasks with humans and provide an extensive analysis. Finally, we\ndemonstrate that combining machine and human decisions can further improve the\nperformance of state-of-the-art face verification systems on various benchmark\ndatasets. Code and data are publicly available on GitHub.",
          "link": "http://arxiv.org/abs/2304.08134",
          "publishedOn": "2023-08-26T00:39:49.372Z",
          "wordCount": null,
          "title": "Tackling Face Verification Edge Cases: In-Depth Analysis and Human-Machine Fusion Approach. (arXiv:2304.08134v4 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.11787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cisse_A/0/1/0/all/0/1\">Abdoulatif Cisse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Evangelopoulos_X/0/1/0/all/0/1\">Xenophon Evangelopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carruthers_S/0/1/0/all/0/1\">Sam Carruthers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gusev_V/0/1/0/all/0/1\">Vladimir V. Gusev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cooper_A/0/1/0/all/0/1\">Andrew I. Cooper</a>",
          "description": "Robotics and automation offer massive accelerations for solving intractable,\nmultivariate scientific problems such as materials discovery, but the available\nsearch spaces can be dauntingly large. Bayesian optimization (BO) has emerged\nas a popular sample-efficient optimization engine, thriving in tasks where no\nanalytic form of the target function/property is known. Here we exploit expert\nhuman knowledge in the form of hypotheses to direct Bayesian searches more\nquickly to promising regions of chemical space. Previous methods have used\nunderlying distributions derived from existing experimental measurements, which\nis unfeasible for new, unexplored scientific tasks. Also, such distributions\ncannot capture intricate hypotheses. Our proposed method, which we call HypBO,\nuses expert human hypotheses to generate an improved seed of samples.\nUnpromising seeds are automatically discounted, while promising seeds are used\nto augment the surrogate model data, thus achieving better-informed sampling.\nThis process continues in a global versus local search fashion, organized in a\nbilevel optimization framework. We validate the performance of our method on a\nrange of synthetic functions and demonstrate its practical utility on a real\nchemical design task where the use of expert hypotheses accelerates the search\nperformance significantly.",
          "link": "http://arxiv.org/abs/2308.11787",
          "publishedOn": "2023-08-26T00:39:49.371Z",
          "wordCount": null,
          "title": "HypBO: Expert-Guided Chemist-in-the-Loop Bayesian Search for New Materials. (arXiv:2308.11787v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12539",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1\">Vipul Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venkit_P/0/1/0/all/0/1\">Pranav Narayanan Venkit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laurencon_H/0/1/0/all/0/1\">Hugo Lauren&#xe7;on</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_S/0/1/0/all/0/1\">Shomir Wilson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Passonneau_R/0/1/0/all/0/1\">Rebecca J. Passonneau</a>",
          "description": "As language models (LMs) become increasingly powerful, it is important to\nquantify and compare them for sociodemographic bias with potential for harm.\nPrior bias measurement datasets are sensitive to perturbations in their\nmanually designed templates, therefore unreliable. To achieve reliability, we\nintroduce the Comprehensive Assessment of Language Model bias (CALM), a\nbenchmark dataset to quantify bias in LMs across three tasks. We integrate 16\nexisting datasets across different domains, such as Wikipedia and news\narticles, to filter 224 templates from which we construct a dataset of 78,400\nexamples. We compare the diversity of CALM with prior datasets on metrics such\nas average semantic similarity, and variation in template length, and test the\nsensitivity to small perturbations. We show that our dataset is more diverse\nand reliable than previous datasets, thus better capture the breadth of\nlinguistic variation required to reliably evaluate model bias. We evaluate 20\nlarge language models including six prominent families of LMs such as Llama-2.\nIn two LM series, OPT and Bloom, we found that larger parameter models are more\nbiased than lower parameter models. We found the T0 series of models to be the\nleast biased. Furthermore, we noticed a tradeoff between gender and racial bias\nwith increasing model size in some model series. The code is available at\nhttps://github.com/vipulgupta1011/CALM.",
          "link": "http://arxiv.org/abs/2308.12539",
          "publishedOn": "2023-08-26T00:39:49.367Z",
          "wordCount": null,
          "title": "CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias. (arXiv:2308.12539v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12439",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tinghao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1\">Xiangyu Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Ping He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yiming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiachen T. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1\">Prateek Mittal</a>",
          "description": "We present a novel defense, against backdoor attacks on Deep Neural Networks\n(DNNs), wherein adversaries covertly implant malicious behaviors (backdoors)\ninto DNNs. Our defense falls within the category of post-development defenses\nthat operate independently of how the model was generated. The proposed defense\nis built upon a novel reverse engineering approach that can directly extract\nbackdoor functionality of a given backdoored model to a backdoor expert model.\nThe approach is straightforward -- finetuning the backdoored model over a small\nset of intentionally mislabeled clean samples, such that it unlearns the normal\nfunctionality while still preserving the backdoor functionality, and thus\nresulting in a model (dubbed a backdoor expert model) that can only recognize\nbackdoor inputs. Based on the extracted backdoor expert model, we show the\nfeasibility of devising highly accurate backdoor input detectors that filter\nout the backdoor inputs during model inference. Further augmented by an\nensemble strategy with a finetuned auxiliary model, our defense, BaDExpert\n(Backdoor Input Detection with Backdoor Expert), effectively mitigates 16 SOTA\nbackdoor attacks while minimally impacting clean utility. The effectiveness of\nBaDExpert has been verified on multiple datasets (CIFAR10, GTSRB and ImageNet)\nacross various model architectures (ResNet, VGG, MobileNetV2 and Vision\nTransformer).",
          "link": "http://arxiv.org/abs/2308.12439",
          "publishedOn": "2023-08-26T00:39:49.363Z",
          "wordCount": null,
          "title": "BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection. (arXiv:2308.12439v1 [cs.CR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.11217",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zengxiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Z/0/1/0/all/0/1\">Zhaoxiang Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Ying Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tongzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1\">Longfei Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1\">Chao Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chengyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weishan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zelei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Liang Xu</a>",
          "description": "Multimodal data, which can comprehensively perceive and recognize the\nphysical world, has become an essential path towards general artificial\nintelligence. However, multimodal large models trained on public datasets often\nunderperform in specific industrial domains. This paper proposes a multimodal\nfederated learning framework that enables multiple enterprises to utilize\nprivate domain data to collaboratively train large models for vertical domains,\nachieving intelligent services across scenarios. The authors discuss in-depth\nthe strategic transformation of federated learning in terms of intelligence\nfoundation and objectives in the era of big model, as well as the new\nchallenges faced in heterogeneous data, model aggregation, performance and cost\ntrade-off, data privacy, and incentive mechanism. The paper elaborates a case\nstudy of leading enterprises contributing multimodal data and expert knowledge\nto city safety operation management , including distributed deployment and\nefficient coordination of the federated learning platform, technical\ninnovations on data quality improvement based on large model capabilities and\nefficient joint fine-tuning approaches. Preliminary experiments show that\nenterprises can enhance and accumulate intelligent capabilities through\nmultimodal model federated learning, thereby jointly creating an smart city\nmodel that provides high-quality intelligent services covering energy\ninfrastructure safety, residential community security, and urban operation\nmanagement. The established federated learning cooperation ecosystem is\nexpected to further aggregate industry, academia, and research resources,\nrealize large models in multiple vertical domains, and promote the large-scale\nindustrial application of artificial intelligence and cutting-edge research on\nmultimodal federated learning.",
          "link": "http://arxiv.org/abs/2308.11217",
          "publishedOn": "2023-08-26T00:39:49.347Z",
          "wordCount": null,
          "title": "Federated Learning in Big Model Era: Domain-Specific Multimodal Large Models. (arXiv:2308.11217v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12573",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_R/0/1/0/all/0/1\">Rishabh Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dahlin_N/0/1/0/all/0/1\">Nathan Dahlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1\">Rahul Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nayyar_A/0/1/0/all/0/1\">Ashutosh Nayyar</a>",
          "description": "Imitation Learning (IL) is an important paradigm within the broader\nreinforcement learning (RL) methodology. Unlike most of RL, it does not assume\navailability of reward-feedback. Reward inference and shaping are known to be\ndifficult and error-prone methods particularly when the demonstration data\ncomes from human experts. Classical methods such as behavioral cloning and\ninverse reinforcement learning are highly sensitive to estimation errors, a\nproblem that is particularly acute in continuous state space problems.\nMeanwhile, state-of-the-art IL algorithms convert behavioral policy learning\nproblems into distribution-matching problems which often require additional\nonline interaction data to be effective. In this paper, we consider the problem\nof imitation learning in continuous state space environments based solely on\nobserved behavior, without access to transition dynamics information, reward\nstructure, or, most importantly, any additional interactions with the\nenvironment. Our approach is based on the Markov balance equation and\nintroduces a novel conditional kernel density estimation-based imitation\nlearning framework. It involves estimating the environment's transition\ndynamics using conditional kernel density estimators and seeks to satisfy the\nprobabilistic balance equations for the environment. We establish that our\nestimators satisfy basic asymptotic consistency requirements. Through a series\nof numerical experiments on continuous state benchmark environments, we show\nconsistently superior empirical performance over many state-of-the-art IL\nalgorithms.",
          "link": "http://arxiv.org/abs/2308.12573",
          "publishedOn": "2023-08-26T00:39:49.344Z",
          "wordCount": null,
          "title": "Conditional Kernel Imitation Learning for Continuous State Environments. (arXiv:2308.12573v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12420",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_W/0/1/0/all/0/1\">Walter Hernandez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tylinski_K/0/1/0/all/0/1\">Kamil Tylinski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moore_A/0/1/0/all/0/1\">Alastair Moore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roche_N/0/1/0/all/0/1\">Niall Roche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vadgama_N/0/1/0/all/0/1\">Nikhil Vadgama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Treiblmaier_H/0/1/0/all/0/1\">Horst Treiblmaier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shangguan_J/0/1/0/all/0/1\">Jiangbo Shangguan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tasca_P/0/1/0/all/0/1\">Paolo Tasca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiahua Xu</a>",
          "description": "Distributed Ledger Technologies (DLTs) have rapidly evolved, necessitating\ncomprehensive insights into their diverse components. However, a systematic\nliterature review that emphasizes the Environmental, Sustainability, and\nGovernance (ESG) components of DLT remains lacking. To bridge this gap, we\nselected 107 seed papers to build a citation network of 63,083 references and\nrefined it to a corpus of 24,539 publications for analysis. Then, we labeled\nthe named entities in 46 papers according to twelve top-level categories\nderived from an established technology taxonomy and enhanced the taxonomy by\npinpointing DLT's ESG elements. Leveraging transformer-based language models,\nwe fine-tuned a pre-trained language model for a Named Entity Recognition (NER)\ntask using our labeled dataset. We used our fine-tuned language model to\ndistill the corpus to 505 key papers, facilitating a literature review via\nnamed entities and temporal graph analysis on DLT evolution in the context of\nESG. Our contributions are a methodology to conduct a machine learning-driven\nsystematic literature review in the DLT field, placing a special emphasis on\nESG aspects. Furthermore, we present a first-of-its-kind NER dataset, composed\nof 54,808 named entities, designed for DLT and ESG-related explorations.",
          "link": "http://arxiv.org/abs/2308.12420",
          "publishedOn": "2023-08-26T00:39:49.291Z",
          "wordCount": null,
          "title": "Evolution of ESG-focused DLT Research: An NLP Analysis of the Literature. (arXiv:2308.12420v1 [cs.IR])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12939",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1\">Zhiwei Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perdikaris_P/0/1/0/all/0/1\">Paris Perdikaris</a>",
          "description": "Recently deep learning surrogates and neural operators have shown promise in\nsolving partial differential equations (PDEs). However, they often require a\nlarge amount of training data and are limited to bounded domains. In this work,\nwe present a novel physics-informed neural operator method to solve\nparametrized boundary value problems without labeled data. By reformulating the\nPDEs into boundary integral equations (BIEs), we can train the operator network\nsolely on the boundary of the domain. This approach reduces the number of\nrequired sample points from $O(N^d)$ to $O(N^{d-1})$, where $d$ is the domain's\ndimension, leading to a significant acceleration of the training process.\nAdditionally, our method can handle unbounded problems, which are unattainable\nfor existing physics-informed neural networks (PINNs) and neural operators. Our\nnumerical experiments show the effectiveness of parametrized complex geometries\nand unbounded problems.",
          "link": "http://arxiv.org/abs/2308.12939",
          "publishedOn": "2023-08-26T00:39:49.291Z",
          "wordCount": null,
          "title": "Learning Only On Boundaries: a Physics-Informed Neural operator for Solving Parametric Partial Differential Equations in Complex Geometries. (arXiv:2308.12939v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.00347",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1\">Sarwan Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chourasia_P/0/1/0/all/0/1\">Prakash Chourasia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patterson_M/0/1/0/all/0/1\">Murray Patterson</a>",
          "description": "Anderson acceleration (AA) is a well-known method for accelerating the\nconvergence of iterative algorithms, with applications in various fields\nincluding deep learning and optimization. Despite its popularity in these\nareas, the effectiveness of AA in classical machine learning classifiers has\nnot been thoroughly studied. Tabular data, in particular, presents a unique\nchallenge for deep learning models, and classical machine learning models are\nknown to perform better in these scenarios. However, the convergence analysis\nof these models has received limited attention. To address this gap in\nresearch, we implement a support vector machine (SVM) classifier variant that\nincorporates AA to speed up convergence. We evaluate the performance of our SVM\nwith and without Anderson acceleration on several datasets from the biology\ndomain and demonstrate that the use of AA significantly improves convergence\nand reduces the training loss as the number of iterations increases. Our\nfindings provide a promising perspective on the potential of Anderson\nacceleration in the training of simple machine learning classifiers and\nunderscore the importance of further research in this area. By showing the\neffectiveness of AA in this setting, we aim to inspire more studies that\nexplore the applications of AA in classical machine learning.",
          "link": "http://arxiv.org/abs/2302.00347",
          "publishedOn": "2023-08-26T00:39:49.290Z",
          "wordCount": null,
          "title": "Anderson Acceleration For Bioinformatics-Based Machine Learning. (arXiv:2302.00347v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.01770",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Timilsina_S/0/1/0/all/0/1\">Subash Timilsina</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shrestha_S/0/1/0/all/0/1\">Sagar Shrestha</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fu_X/0/1/0/all/0/1\">Xiao Fu</a>",
          "description": "Spectrum cartography (SC), also known as radio map estimation (RME), aims at\ncrafting multi-domain (e.g., frequency and space) radio power propagation maps\nfrom limited sensor measurements. While early methods often lacked theoretical\nsupport, recent works have demonstrated that radio maps can be provably\nrecovered using low-dimensional models -- such as the block-term tensor\ndecomposition (BTD) model and certain deep generative models (DGMs) -- of the\nhigh-dimensional multi-domain radio signals. However, these existing provable\nSC approaches assume that sensors send real-valued (full-resolution)\nmeasurements to the fusion center, which is unrealistic. This work puts forth a\nquantized SC framework that generalizes the BTD and DGM-based SC to scenarios\nwhere heavily quantized sensor measurements are used. A maximum likelihood\nestimation (MLE)-based SC framework under a Gaussian quantizer is proposed.\nRecoverability of the radio map using the MLE criterion are characterized under\nrealistic conditions, e.g., imperfect radio map modeling and noisy\nmeasurements. Simulations and real-data experiments are used to showcase the\neffectiveness of the proposed approach.",
          "link": "http://arxiv.org/abs/2303.01770",
          "publishedOn": "2023-08-26T00:39:49.282Z",
          "wordCount": null,
          "title": "Quantized Radio Map Estimation Using Tensor and Deep Generative Models. (arXiv:2303.01770v2 [eess.SP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2204.11418",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Han_A/0/1/0/all/0/1\">Andi Han</a>, <a href=\"http://arxiv.org/find/math/1/au:+Mishra_B/0/1/0/all/0/1\">Bamdev Mishra</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jawanpuria_P/0/1/0/all/0/1\">Pratik Jawanpuria</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kumar_P/0/1/0/all/0/1\">Pawan Kumar</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gao_J/0/1/0/all/0/1\">Junbin Gao</a>",
          "description": "In this paper, we study min-max optimization problems on Riemannian\nmanifolds. We introduce a Riemannian Hamiltonian function, minimization of\nwhich serves as a proxy for solving the original min-max problems. Under the\nRiemannian Polyak--{\\L}ojasiewicz condition on the Hamiltonian function, its\nminimizer corresponds to the desired min-max saddle point. We also provide\ncases where this condition is satisfied. For geodesic-bilinear optimization in\nparticular, solving the proxy problem leads to the correct search direction\ntowards global optimality, which becomes challenging with the min-max\nformulation. To minimize the Hamiltonian function, we propose Riemannian\nHamiltonian methods (RHM) and present their convergence analyses. We extend RHM\nto include consensus regularization and to the stochastic setting. We\nillustrate the efficacy of the proposed RHM in applications such as subspace\nrobust Wasserstein distance, robust training of neural networks, and generative\nadversarial networks.",
          "link": "http://arxiv.org/abs/2204.11418",
          "publishedOn": "2023-08-26T00:39:49.278Z",
          "wordCount": null,
          "title": "Riemannian Hamiltonian methods for min-max optimization on manifolds. (arXiv:2204.11418v3 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12871",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ghafouri_S/0/1/0/all/0/1\">Saeid Ghafouri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razavi_K/0/1/0/all/0/1\">Kamran Razavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salmani_M/0/1/0/all/0/1\">Mehran Salmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanaee_A/0/1/0/all/0/1\">Alireza Sanaee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lorido_Botran_T/0/1/0/all/0/1\">Tania Lorido-Botran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doyle_J/0/1/0/all/0/1\">Joseph Doyle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jamshidi_P/0/1/0/all/0/1\">Pooyan Jamshidi</a>",
          "description": "Efficiently optimizing multi-model inference pipelines for fast, accurate,\nand cost-effective inference is a crucial challenge in ML production systems,\ngiven their tight end-to-end latency requirements. To simplify the exploration\nof the vast and intricate trade-off space of accuracy and cost in inference\npipelines, providers frequently opt to consider one of them. However, the\nchallenge lies in reconciling accuracy and cost trade-offs. To address this\nchallenge and propose a solution to efficiently manage model variants in\ninference pipelines, we present IPA, an online deep-learning Inference Pipeline\nAdaptation system that efficiently leverages model variants for each deep\nlearning task. Model variants are different versions of pre-trained models for\nthe same deep learning task with variations in resource requirements, latency,\nand accuracy. IPA dynamically configures batch size, replication, and model\nvariants to optimize accuracy, minimize costs, and meet user-defined latency\nSLAs using Integer Programming. It supports multi-objective settings for\nachieving different trade-offs between accuracy and cost objectives while\nremaining adaptable to varying workloads and dynamic traffic patterns.\nExtensive experiments on a Kubernetes implementation with five real-world\ninference pipelines demonstrate that IPA improves normalized accuracy by up to\n35% with a minimal cost increase of less than 5%.",
          "link": "http://arxiv.org/abs/2308.12871",
          "publishedOn": "2023-08-26T00:39:49.277Z",
          "wordCount": null,
          "title": "IPA: Inference Pipeline Adaptation to Achieve High Accuracy and Cost-Efficiency. (arXiv:2308.12871v1 [cs.DC])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12355",
          "author": "<a href=\"http://arxiv.org/find/hep-th/1/au:+Cotler_J/0/1/0/all/0/1\">Jordan Cotler</a>, <a href=\"http://arxiv.org/find/hep-th/1/au:+Rezchikov_S/0/1/0/all/0/1\">Semon Rezchikov</a>",
          "description": "We explain how to use diffusion models to learn inverse renormalization group\nflows of statistical and quantum field theories. Diffusion models are a class\nof machine learning models which have been used to generate samples from\ncomplex distributions, such as the distribution of natural images, by learning\nthe inverse process to a diffusion process which adds noise to the data until\nthe distribution of the data is pure noise. Nonperturbative renormalization\ngroup schemes can naturally be written as diffusion processes in the space of\nfields. We combine these observations in a concrete framework for building\nML-based models for studying field theories, in which the models learn the\ninverse process to an explicitly-specified renormalization group scheme. We\ndetail how these models define a class of adaptive bridge (or parallel\ntempering) samplers for lattice field theory. Because renormalization group\nschemes have a physical meaning, we provide explicit prescriptions for how to\ncompare results derived from models associated to several different\nrenormalization group schemes of interest. We also explain how to use diffusion\nmodels in a variational method to find ground states of quantum systems. We\napply some of our methods to numerically find RG flows of interacting\nstatistical field theories. From the perspective of machine learning, our work\nprovides an interpretation of multiscale diffusion models, and gives\nphysically-inspired suggestions for diffusion models which should have novel\nproperties.",
          "link": "http://arxiv.org/abs/2308.12355",
          "publishedOn": "2023-08-26T00:39:49.260Z",
          "wordCount": null,
          "title": "Renormalizing Diffusion Models. (arXiv:2308.12355v1 [hep-th])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12325",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Ho_J/0/1/0/all/0/1\">John Ho</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Yin_Z/0/1/0/all/0/1\">Zhao-Heng Yin</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_C/0/1/0/all/0/1\">Colin Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Overhauser_H/0/1/0/all/0/1\">Henry Overhauser</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Swanson_K/0/1/0/all/0/1\">Kyle Swanson</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ha_Y/0/1/0/all/0/1\">Yang Ha</a>",
          "description": "Predicting the solubility of given molecules is an important task in the\npharmaceutical industry, and consequently this is a well-studied topic. In this\nresearch, we revisited this problem with the advantage of modern computing\nresources. We applied two machine learning models, a linear regression model\nand a graph convolutional neural network model, on multiple experimental\ndatasets. Both methods can make reasonable predictions while the GCNN model had\nthe best performance. However, the current GCNN model is a black box, while\nfeature importance analysis from the linear regression model offers more\ninsights into the underlying chemical influences. Using the linear regression\nmodel, we show how each functional group affects the overall solubility.\nUltimately, knowing how chemical structure influences chemical properties is\ncrucial when designing new drugs. Future work should aim to combine the high\nperformance of GCNNs with the interpretability of linear regression, unlocking\nnew advances in next generation high throughput screening.",
          "link": "http://arxiv.org/abs/2308.12325",
          "publishedOn": "2023-08-26T00:39:49.259Z",
          "wordCount": null,
          "title": "Predicting Drug Solubility Using Different Machine Learning Methods -- Linear Regression Model with Extracted Chemical Features vs Graph Convolutional Neural Network. (arXiv:2308.12325v1 [q-bio.QM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12388",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_O/0/1/0/all/0/1\">Ou Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1\">Qun Jin</a>",
          "description": "In data imputation, effectively addressing missing values is pivotal,\nespecially in intricate datasets. This paper delves into the FIML Optimized\nSelf-attention (FOSA) framework, an innovative approach that amalgamates the\nstrengths of Full Information Maximum Likelihood (FIML) estimation with the\ncapabilities of self-attention neural networks. Our methodology commences with\nan initial estimation of missing values via FIML, subsequently refining these\nestimates by leveraging the self-attention mechanism. Our comprehensive\nexperiments on both simulated and real-world datasets underscore FOSA's\npronounced advantages over traditional FIML techniques, encapsulating facets of\naccuracy, computational efficiency, and adaptability to diverse data\nstructures. Intriguingly, even in scenarios where the Structural Equation Model\n(SEM) might be mis-specified, leading to suboptimal FIML estimates, the robust\narchitecture of FOSA's self-attention component adeptly rectifies and optimizes\nthe imputation outcomes. Our empirical tests reveal that FOSA consistently\ndelivers commendable predictions, even in the face of up to 40% random\nmissingness, highlighting its robustness and potential for wide-scale\napplications in data imputation.",
          "link": "http://arxiv.org/abs/2308.12388",
          "publishedOn": "2023-08-26T00:39:49.256Z",
          "wordCount": null,
          "title": "FOSA: Full Information Maximum Likelihood (FIML) Optimized Self-Attention Imputation for Missing Data. (arXiv:2308.12388v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.01566",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jian Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gall_H/0/1/0/all/0/1\">Harald C. Gall</a>",
          "description": "Deep code generation is a topic of deep learning for software engineering\n(DL4SE), which adopts neural models to generate code for the intended\nfunctions. Since end-to-end neural methods lack domain knowledge and software\nhierarchy awareness, they tend to perform poorly w.r.t project-level tasks. To\nsystematically explore the potential improvements of code generation, we let it\nparticipate in the whole top-down development from \\emph{expressibles} to\n\\emph{executables}, which is possible in limited scopes. In the process, it\nbenefits from massive samples, features, and knowledge. As the foundation, we\nsuggest building a taxonomy on code data, namely code taxonomy, leveraging the\ncategorization of code information. Moreover, we introduce a three-layer\nsemantic pyramid (SP) to associate text data and code data. It identifies the\ninformation of different abstraction levels, and thus introduces the domain\nknowledge on development and reveals the hierarchy of software. Furthermore, we\npropose a semantic pyramid framework (SPF) as the approach, focusing on\nsoftware of high modularity and low complexity. SPF divides the code generation\nprocess into stages and reserves spots for potential interactions. In addition,\nwe conceived preliminary applications in software development to confirm the\nneuro-symbolic framework.",
          "link": "http://arxiv.org/abs/2209.01566",
          "publishedOn": "2023-08-26T00:39:49.255Z",
          "wordCount": null,
          "title": "Towards Top-Down Automated Development in Limited Scopes: A Neuro-Symbolic Framework from Expressibles to Executables. (arXiv:2209.01566v4 [cs.SE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jian Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_L/0/1/0/all/0/1\">Lijun Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhengbo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1\">Ran He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_T/0/1/0/all/0/1\">Tieniu Tan</a>",
          "description": "The emergence of vision-language models (VLMs), such as CLIP, has spurred a\nsignificant research effort towards their application for downstream supervised\nlearning tasks. Although some previous studies have explored the unsupervised\nfine-tuning of CLIP, they often rely on prior knowledge in the form of class\nnames associated with ground truth labels. In this paper, we delve into a\nrealistic unsupervised fine-tuning scenario by assuming that the unlabeled data\nmight contain out-of-distribution samples from unknown classes. Furthermore, we\nemphasize the importance of simultaneously enhancing out-of-distribution\ndetection capabilities alongside the recognition of instances associated with\npredefined class labels.\n\nTo tackle this problem, we present a simple, efficient, and effective\nfine-tuning approach called Universal Entropy Optimization (UEO). UEO leverages\nsample-level confidence to approximately minimize the conditional entropy of\nconfident instances and maximize the marginal entropy of less confident\ninstances. Apart from optimizing the textual prompts, UEO also incorporates\noptimization of channel-wise affine transformations within the visual branch of\nCLIP. Through extensive experiments conducted across 15 domains and 4 different\ntypes of prior knowledge, we demonstrate that UEO surpasses baseline methods in\nterms of both generalization and out-of-distribution detection.",
          "link": "http://arxiv.org/abs/2308.12919",
          "publishedOn": "2023-08-26T00:39:49.250Z",
          "wordCount": null,
          "title": "Towards Realistic Unsupervised Fine-tuning with CLIP. (arXiv:2308.12919v1 [cs.CV])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12772",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kobayashi_T/0/1/0/all/0/1\">Taisuke Kobayashi</a>",
          "description": "Robot control using reinforcement learning has become popular, but its\nlearning process generally terminates halfway through an episode for safety and\ntime-saving reasons. This study addresses the problem of the most popular\nexception handling that temporal-difference (TD) learning performs at such\ntermination. That is, by forcibly assuming zero value after termination,\nunintentionally implicit underestimation or overestimation occurs, depending on\nthe reward design in the normal states. When the episode is terminated due to\ntask failure, the failure may be highly valued with the unintentional\noverestimation, and the wrong policy may be acquired. Although this problem can\nbe avoided by paying attention to the reward design, it is essential in\npractical use of TD learning to review the exception handling at termination.\nThis paper therefore proposes a method to intentionally underestimate the value\nafter termination to avoid learning failures due to the unintentional\noverestimation. In addition, the degree of underestimation is adjusted\naccording to the degree of stationarity at termination, thereby preventing\nexcessive exploration due to the intentional underestimation. Simulations and\nreal robot experiments showed that the proposed method can stably obtain the\noptimal policies for various tasks and reward designs.\nhttps://youtu.be/AxXr8uFOe7M",
          "link": "http://arxiv.org/abs/2308.12772",
          "publishedOn": "2023-08-26T00:39:49.249Z",
          "wordCount": null,
          "title": "Intentionally-underestimated Value Function at Terminal State for Temporal-difference Learning with Mis-designed Reward. (arXiv:2308.12772v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.12263",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haochen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhiyu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mo_X/0/1/0/all/0/1\">Xiaoyu Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_C/0/1/0/all/0/1\">Chen Lv</a>",
          "description": "Decision-making for urban autonomous driving is challenging due to the\nstochastic nature of interactive traffic participants and the complexity of\nroad structures. Although reinforcement learning (RL)-based decision-making\nscheme is promising to handle urban driving scenarios, it suffers from low\nsample efficiency and poor adaptability. In this paper, we propose Scene-Rep\nTransformer to improve the RL decision-making capabilities with better scene\nrepresentation encoding and sequential predictive latent distillation.\nSpecifically, a multi-stage Transformer (MST) encoder is constructed to model\nnot only the interaction awareness between the ego vehicle and its neighbors\nbut also intention awareness between the agents and their candidate routes. A\nsequential latent Transformer (SLT) with self-supervised learning objectives is\nemployed to distill the future predictive information into the latent scene\nrepresentation, in order to reduce the exploration space and speed up training.\nThe final decision-making module based on soft actor-critic (SAC) takes as\ninput the refined latent scene representation from the Scene-Rep Transformer\nand outputs driving actions. The framework is validated in five challenging\nsimulated urban scenarios with dense traffic, and its performance is manifested\nquantitatively by the substantial improvements in data efficiency and\nperformance in terms of success rate, safety, and efficiency. The qualitative\nresults reveal that our framework is able to extract the intentions of neighbor\nagents to help make decisions and deliver more diversified driving behaviors.",
          "link": "http://arxiv.org/abs/2208.12263",
          "publishedOn": "2023-08-26T00:39:49.249Z",
          "wordCount": null,
          "title": "Augmenting Reinforcement Learning with Transformer-based Scene Representation Learning for Decision-making of Autonomous Driving. (arXiv:2208.12263v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12921",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shojaeighadikolaei_A/0/1/0/all/0/1\">Amin Shojaeighadikolaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashemi_M/0/1/0/all/0/1\">Morteza Hashemi</a>",
          "description": "The increasing trend in adopting electric vehicles (EVs) will significantly\nimpact the residential electricity demand, which results in an increased risk\nof transformer overload in the distribution grid. To mitigate such risks, there\nare urgent needs to develop effective EV charging controllers. Currently, the\nmajority of the EV charge controllers are based on a centralized approach for\nmanaging individual EVs or a group of EVs. In this paper, we introduce a\ndecentralized Multi-agent Reinforcement Learning (MARL) charging framework that\nprioritizes the preservation of privacy for EV owners. We employ the\nCentralized Training Decentralized Execution-Deep Deterministic Policy Gradient\n(CTDE-DDPG) scheme, which provides valuable information to users during\ntraining while maintaining privacy during execution. Our results demonstrate\nthat the CTDE framework improves the performance of the charging network by\nreducing the network costs. Moreover, we show that the Peak-to-Average Ratio\n(PAR) of the total demand is reduced, which, in turn, reduces the risk of\ntransformer overload during the peak hours.",
          "link": "http://arxiv.org/abs/2308.12921",
          "publishedOn": "2023-08-26T00:39:49.239Z",
          "wordCount": null,
          "title": "An Efficient Distributed Multi-Agent Reinforcement Learning for EV Charging Network Control. (arXiv:2308.12921v1 [cs.MA])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.14706",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yushan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murahari_V/0/1/0/all/0/1\">Vishvak Murahari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1\">Karthik Narasimhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Kai Li</a>",
          "description": "As language models increase in size by the day, methods for efficient\ninference are critical to leveraging their capabilities for various\napplications. Prior work has investigated techniques like model pruning,\nknowledge distillation, and data multiplexing to increase model throughput\nwithout sacrificing accuracy. In this paper, we combine two such methods --\nstructured pruning and data multiplexing -- to compound the speedup gains\nobtained by either method. Our approach, PruMUX, obtains up to 7.5-29.5X\nthroughput improvement over BERT-base model with accuracy threshold from 80% to\n74%. We further study various combinations of parameters (such as sparsity and\nmultiplexing factor) in the two techniques to provide a comprehensive analysis\nof the tradeoff between accuracy and throughput in the resulting models. We\nthen propose Auto-PruMUX, a meta-level model that can predict the\nhigh-performance parameters for pruning and multiplexing given a desired\naccuracy loss budget, providing a practical method to leverage the combination\neffectively.",
          "link": "http://arxiv.org/abs/2305.14706",
          "publishedOn": "2023-08-26T00:39:49.239Z",
          "wordCount": null,
          "title": "PruMUX: Augmenting Data Multiplexing with Model Compression. (arXiv:2305.14706v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12526",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zheng_Y/0/1/0/all/0/1\">Yu Zheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1\">Yajun Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Niu_C/0/1/0/all/0/1\">Chuanying Niu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhan_Y/0/1/0/all/0/1\">Yibin Zhan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Long_Y/0/1/0/all/0/1\">Yanhua Long</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_D/0/1/0/all/0/1\">Dongxing Xu</a>",
          "description": "This report describes the UNISOUND submission for Track1 and Track2 of\nVoxCeleb Speaker Recognition Challenge 2023 (VoxSRC 2023). We submit the same\nsystem on Track 1 and Track 2, which is trained with only VoxCeleb2-dev.\nLarge-scale ResNet and RepVGG architectures are developed for the challenge. We\npropose a consistency-aware score calibration method, which leverages the\nstability of audio voiceprints in similarity score by a Consistency Measure\nFactor (CMF). CMF brings a huge performance boost in this challenge. Our final\nsystem is a fusion of six models and achieves the first place in Track 1 and\nsecond place in Track 2 of VoxSRC 2023. The minDCF of our submission is 0.0855\nand the EER is 1.5880%.",
          "link": "http://arxiv.org/abs/2308.12526",
          "publishedOn": "2023-08-26T00:39:49.238Z",
          "wordCount": null,
          "title": "UNISOUND System for VoxCeleb Speaker Recognition Challenge 2023. (arXiv:2308.12526v1 [eess.AS])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2207.09755",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Biswas_A/0/1/0/all/0/1\">Anmol Biswas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saraswat_V/0/1/0/all/0/1\">Vivek Saraswat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganguly_U/0/1/0/all/0/1\">Udayan Ganguly</a>",
          "description": "Spiking Neural Networks (SNNs) have emerged as a hardware efficient\narchitecture for classification tasks. The challenge of spike-based encoding\nhas been the lack of a universal training mechanism performed entirely using\nspikes. There have been several attempts to adopt the powerful backpropagation\n(BP) technique used in non-spiking artificial neural networks (ANN): (1) SNNs\ncan be trained by externally computed numerical gradients. (2) A major\nadvancement towards native spike-based learning has been the use of approximate\nBackpropagation using spike-time dependent plasticity (STDP) with phased\nforward/backward passes. However, the transfer of information between such\nphases for gradient and weight update calculation necessitates external memory\nand computational access. This is a challenge for standard neuromorphic\nhardware implementations. In this paper, we propose a stochastic SNN based\nBack-Prop (SSNN-BP) algorithm that utilizes a composite neuron to\nsimultaneously compute the forward pass activations and backward pass gradients\nexplicitly with spikes. Although signed gradient values are a challenge for\nspike-based representation, we tackle this by splitting the gradient signal\ninto positive and negative streams. We show that our method approaches BP ANN\nbaseline with sufficiently long spike-trains. Finally, we show that the\nwell-performing softmax cross-entropy loss function can be implemented through\ninhibitory lateral connections enforcing a Winner Take All (WTA) rule. Our SNN\nwith a 2-layer network shows excellent generalization through comparable\nperformance to ANNs with equivalent architecture and regularization parameters\non static image datasets like MNIST, Fashion-MNIST, Extended MNIST, and\ntemporally encoded image datasets like Neuromorphic MNIST datasets. Thus,\nSSNN-BP enables BP compatible with purely spike-based neuromorphic hardware.",
          "link": "http://arxiv.org/abs/2207.09755",
          "publishedOn": "2023-08-26T00:39:49.204Z",
          "wordCount": null,
          "title": "A temporally and spatially local spike-based backpropagation algorithm to enable training in hardware. (arXiv:2207.09755v2 [cs.NE] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2212.05153",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Erdil_E/0/1/0/all/0/1\">Ege Erdil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Besiroglu_T/0/1/0/all/0/1\">Tamay Besiroglu</a>",
          "description": "We investigate algorithmic progress in image classification on ImageNet,\nperhaps the most well-known test bed for computer vision. We estimate a model,\ninformed by work on neural scaling laws, and infer a decomposition of progress\ninto the scaling of compute, data, and algorithms. Using Shapley values to\nattribute performance improvements, we find that algorithmic improvements have\nbeen roughly as important as the scaling of compute for progress computer\nvision. Our estimates indicate that algorithmic innovations mostly take the\nform of compute-augmenting algorithmic advances (which enable researchers to\nget better performance from less compute), not data-augmenting algorithmic\nadvances. We find that compute-augmenting algorithmic advances are made at a\npace more than twice as fast as the rate usually associated with Moore's law.\nIn particular, we estimate that compute-augmenting innovations halve compute\nrequirements every nine months (95\\% confidence interval: 4 to 25 months).",
          "link": "http://arxiv.org/abs/2212.05153",
          "publishedOn": "2023-08-26T00:39:49.196Z",
          "wordCount": null,
          "title": "Algorithmic progress in computer vision. (arXiv:2212.05153v4 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12517",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yunho Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_H/0/1/0/all/0/1\">Hyunsik Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jeonghyun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jinhyeok Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_G/0/1/0/all/0/1\">Gwanghyeon Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_M/0/1/0/all/0/1\">Moonkyu Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Youm_D/0/1/0/all/0/1\">Donghoon Youm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwangbo_J/0/1/0/all/0/1\">Jemin Hwangbo</a>",
          "description": "Several earlier studies have shown impressive control performance in complex\nrobotic systems by designing the controller using a neural network and training\nit with model-free reinforcement learning. However, these outstanding\ncontrollers with natural motion style and high task performance are developed\nthrough extensive reward engineering, which is a highly laborious and\ntime-consuming process of designing numerous reward terms and determining\nsuitable reward coefficients. In this work, we propose a novel reinforcement\nlearning framework for training neural network controllers for complex robotic\nsystems consisting of both rewards and constraints. To let the engineers\nappropriately reflect their intent to constraints and handle them with minimal\ncomputation overhead, two constraint types and an efficient policy optimization\nalgorithm are suggested. The learning framework is applied to train locomotion\ncontrollers for several legged robots with different morphology and physical\nattributes to traverse challenging terrains. Extensive simulation and\nreal-world experiments demonstrate that performant controllers can be trained\nwith significantly less reward engineering, by tuning only a single reward\ncoefficient. Furthermore, a more straightforward and intuitive engineering\nprocess can be utilized, thanks to the interpretability and generalizability of\nconstraints. The summary video is available at https://youtu.be/KAlm3yskhvM.",
          "link": "http://arxiv.org/abs/2308.12517",
          "publishedOn": "2023-08-26T00:39:49.179Z",
          "wordCount": null,
          "title": "Not Only Rewards But Also Constraints: Applications on Legged Robot Locomotion. (arXiv:2308.12517v1 [cs.RO])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2302.07557",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bonfanti_A/0/1/0/all/0/1\">Andrea Bonfanti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santana_R/0/1/0/all/0/1\">Roberto Santana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ellero_M/0/1/0/all/0/1\">Marco Ellero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gholami_B/0/1/0/all/0/1\">Babak Gholami</a>",
          "description": "Physics-Informed Neural Networks (PINNs) are Neural Network architectures\ntrained to emulate solutions of differential equations without the necessity of\nsolution data. They are currently ubiquitous in the scientific literature due\nto their flexible and promising settings. However, very little of the available\nresearch provides practical studies that aim for a better quantitative\nunderstanding of such architecture and its functioning. In this paper, we\nperform an empirical analysis of the behavior of PINN predictions outside their\ntraining domain. The primary goal is to investigate the scenarios in which a\nPINN can provide consistent predictions outside the training area.\nThereinafter, we assess whether the algorithmic setup of PINNs can influence\ntheir potential for generalization and showcase the respective effect on the\nprediction. The results obtained in this study returns insightful and at times\ncounterintuitive perspectives which can be highly relevant for architectures\nwhich combines PINNs with domain decomposition and/or adaptive training\nstrategies.",
          "link": "http://arxiv.org/abs/2302.07557",
          "publishedOn": "2023-08-26T00:39:49.177Z",
          "wordCount": null,
          "title": "On the Generalization of PINNs outside the training domain and the Hyperparameters influencing it. (arXiv:2302.07557v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12785",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brach_K/0/1/0/all/0/1\">Kai Brach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sick_B/0/1/0/all/0/1\">Beate Sick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durr_O/0/1/0/all/0/1\">Oliver D&#xfc;rr</a>",
          "description": "Deep neural networks (NNs) are known for their high-prediction performances.\nHowever, NNs are prone to yield unreliable predictions when encountering\ncompletely new situations without indicating their uncertainty. Bayesian\nvariants of NNs (BNNs), such as Monte Carlo (MC) dropout BNNs, do provide\nuncertainty measures and simultaneously increase the prediction performance.\nThe only disadvantage of BNNs is their higher computation time during test time\nbecause they rely on a sampling approach. Here we present a single-shot MC\ndropout approximation that preserves the advantages of BNNs while being as fast\nas NNs. Our approach is based on moment propagation (MP) and allows to\nanalytically approximate the expected value and the variance of the MC dropout\nsignal for commonly used layers in NNs, i.e. convolution, max pooling, dense,\nsoftmax, and dropout layers. The MP approach can convert an NN into a BNN\nwithout re-training given the NN has been trained with standard dropout. We\nevaluate our approach on different benchmark datasets and a simulated toy\nexample in a classification and regression setting. We demonstrate that our\nsingle-shot MC dropout approximation resembles the point estimate and the\nuncertainty estimate of the predictive distribution that is achieved with an MC\napproach, while being fast enough for real-time deployments of BNNs. We show\nthat using part of the saved time to combine our MP approach with deep ensemble\ntechniques does further improve the uncertainty measures.",
          "link": "http://arxiv.org/abs/2308.12785",
          "publishedOn": "2023-08-26T00:39:49.141Z",
          "wordCount": null,
          "title": "Single-shot Bayesian approximation for neural networks. (arXiv:2308.12785v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12315",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1\">Ronghang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1\">Dongliang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_D/0/1/0/all/0/1\">Daiqing Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_Z/0/1/0/all/0/1\">Zhixuan Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xiang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sheng Li</a>",
          "description": "As AI systems have obtained significant performance to be deployed widely in\nour daily live and human society, people both enjoy the benefits brought by\nthese technologies and suffer many social issues induced by these systems. To\nmake AI systems good enough and trustworthy, plenty of researches have been\ndone to build guidelines for trustworthy AI systems. Machine learning is one of\nthe most important parts for AI systems and representation learning is the\nfundamental technology in machine learning. How to make the representation\nlearning trustworthy in real-world application, e.g., cross domain scenarios,\nis very valuable and necessary for both machine learning and AI system fields.\nInspired by the concepts in trustworthy AI, we proposed the first trustworthy\nrepresentation learning across domains framework which includes four concepts,\ni.e, robustness, privacy, fairness, and explainability, to give a comprehensive\nliterature review on this research direction. Specifically, we first introduce\nthe details of the proposed trustworthy framework for representation learning\nacross domains. Second, we provide basic notions and comprehensively summarize\nexisting methods for the trustworthy framework from four concepts. Finally, we\nconclude this survey with insights and discussions on future research\ndirections.",
          "link": "http://arxiv.org/abs/2308.12315",
          "publishedOn": "2023-08-26T00:39:49.140Z",
          "wordCount": null,
          "title": "Trustworthy Representation Learning Across Domains. (arXiv:2308.12315v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12492",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1\">Byeong Tak Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jo_Y/0/1/0/all/0/1\">Yong-Yeon Jo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_J/0/1/0/all/0/1\">Joon-Myoung Kwon</a>",
          "description": "We study scaling convolutional neural networks (CNNs), specifically targeting\nResidual neural networks (ResNet), for analyzing electrocardiograms (ECGs).\nAlthough ECG signals are time-series data, CNN-based models have been shown to\noutperform other neural networks with different architectures in ECG analysis.\nHowever, most previous studies in ECG analysis have overlooked the importance\nof network scaling optimization, which significantly improves performance. We\nexplored and demonstrated an efficient approach to scale ResNet by examining\nthe effects of crucial parameters, including layer depth, the number of\nchannels, and the convolution kernel size. Through extensive experiments, we\nfound that a shallower network, a larger number of channels, and smaller kernel\nsizes result in better performance for ECG classifications. The optimal network\nscale might differ depending on the target task, but our findings provide\ninsight into obtaining more efficient and accurate models with fewer computing\nresources or less time. In practice, we demonstrate that a narrower search\nspace based on our findings leads to higher performance.",
          "link": "http://arxiv.org/abs/2308.12492",
          "publishedOn": "2023-08-26T00:39:49.138Z",
          "wordCount": null,
          "title": "Optimizing Neural Network Scale for ECG Classification. (arXiv:2308.12492v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.07240",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ebrahimi_S/0/1/0/all/0/1\">Sayna Ebrahimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arik_S/0/1/0/all/0/1\">Sercan O. Arik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_T/0/1/0/all/0/1\">Tomas Pfister</a>",
          "description": "For visual document understanding (VDU), self-supervised pretraining has been\nshown to successfully generate transferable representations, yet, effective\nadaptation of such representations to distribution shifts at test-time remains\nto be an unexplored area. We propose DocTTA, a novel test-time adaptation\nmethod for documents, that does source-free domain adaptation using unlabeled\ntarget document data. DocTTA leverages cross-modality self-supervised learning\nvia masked visual language modeling, as well as pseudo labeling to adapt models\nlearned on a \\textit{source} domain to an unlabeled \\textit{target} domain at\ntest time. We introduce new benchmarks using existing public datasets for\nvarious VDU tasks, including entity recognition, key-value extraction, and\ndocument visual question answering. DocTTA shows significant improvements on\nthese compared to the source model performance, up to 1.89\\% in (F1 score),\n3.43\\% (F1 score), and 17.68\\% (ANLS score), respectively. Our benchmark\ndatasets are available at \\url{https://saynaebrahimi.github.io/DocTTA.html}.",
          "link": "http://arxiv.org/abs/2206.07240",
          "publishedOn": "2023-08-26T00:39:49.130Z",
          "wordCount": null,
          "title": "Test-Time Adaptation for Visual Document Understanding. (arXiv:2206.07240v2 [cs.CV] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12354",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Schapin_N/0/1/0/all/0/1\">Nikolai Schapin</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Majewski_M/0/1/0/all/0/1\">Maciej Majewski</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Varela_A/0/1/0/all/0/1\">Alejandro Varela</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Arroniz_C/0/1/0/all/0/1\">Carlos Arroniz</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Fabritiis_G/0/1/0/all/0/1\">Gianni De Fabritiis</a>",
          "description": "Machine learning (ML) is a promising approach for predicting small molecule\nproperties in drug discovery. Here, we provide a comprehensive overview of\nvarious ML methods introduced for this purpose in recent years. We review a\nwide range of properties, including binding affinities, solubility, and ADMET\n(Absorption, Distribution, Metabolism, Excretion, and Toxicity). We discuss\nexisting popular datasets and molecular descriptors and embeddings, such as\nchemical fingerprints and graph-based neural networks. We highlight also\nchallenges of predicting and optimizing multiple properties during hit-to-lead\nand lead optimization stages of drug discovery and explore briefly possible\nmulti-objective optimization techniques that can be used to balance diverse\nproperties while optimizing lead candidates. Finally, techniques to provide an\nunderstanding of model predictions, especially for critical decision-making in\ndrug discovery are assessed. Overall, this review provides insights into the\nlandscape of ML models for small molecule property predictions in drug\ndiscovery. So far, there are multiple diverse approaches, but their\nperformances are often comparable. Neural networks, while more flexible, do not\nalways outperform simpler models. This shows that the availability of\nhigh-quality training data remains crucial for training accurate models and\nthere is a need for standardized benchmarks, additional performance metrics,\nand best practices to enable richer comparisons between the different\ntechniques and models that can shed a better light on the differences between\nthe many techniques.",
          "link": "http://arxiv.org/abs/2308.12354",
          "publishedOn": "2023-08-26T00:39:49.073Z",
          "wordCount": null,
          "title": "Machine Learning Small Molecule Properties in Drug Discovery. (arXiv:2308.12354v1 [q-bio.BM])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Hanchi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_D/0/1/0/all/0/1\">Deheng Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>",
          "description": "We propose a novel master-slave architecture to solve the top-$K$\ncombinatorial multi-armed bandits problem with non-linear bandit feedback and\ndiversity constraints, which, to the best of our knowledge, is the first\ncombinatorial bandits setting considering diversity constraints under bandit\nfeedback. Specifically, to efficiently explore the combinatorial and\nconstrained action space, we introduce six slave models with distinguished\nmerits to generate diversified samples well balancing rewards and constraints\nas well as efficiency. Moreover, we propose teacher learning based optimization\nand the policy co-training technique to boost the performance of the multiple\nslave models. The master model then collects the elite samples provided by the\nslave models and selects the best sample estimated by a neural contextual\nUCB-based network to make a decision with a trade-off between exploration and\nexploitation. Thanks to the elaborate design of slave models, the co-training\nmechanism among slave models, and the novel interactions between the master and\nslave models, our approach significantly surpasses existing state-of-the-art\nalgorithms in both synthetic and real datasets for recommendation tasks. The\ncode is available at:\n\\url{https://github.com/huanghanchi/Master-slave-Algorithm-for-Top-K-Bandits}.",
          "link": "http://arxiv.org/abs/2308.12680",
          "publishedOn": "2023-08-26T00:39:49.073Z",
          "wordCount": null,
          "title": "Master-slave Deep Architecture for Top-K Multi-armed Bandits with Non-linear Bandit Feedback and Diversity Constraints. (arXiv:2308.12680v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2211.00642",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hlaing_N/0/1/0/all/0/1\">N. Hlaing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morato_P/0/1/0/all/0/1\">Pablo G. Morato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_F/0/1/0/all/0/1\">F. d. N. Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weijtjens_W/0/1/0/all/0/1\">W. Weijtjens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Devriendt_C/0/1/0/all/0/1\">C. Devriendt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rigo_P/0/1/0/all/0/1\">P. Rigo</a>",
          "description": "Offshore wind structures are subject to deterioration mechanisms throughout\ntheir operational lifetime. Even if the deterioration evolution of structural\nelements can be estimated through physics-based deterioration models, the\nuncertainties involved in the process hurdle the selection of lifecycle\nmanagement decisions. In this scenario, the collection of relevant information\nthrough an efficient monitoring system enables the reduction of uncertainties,\nultimately driving more optimal lifecycle decisions. However, a full monitoring\ninstrumentation implemented on all wind turbines in a farm might become\nunfeasible due to practical and economical constraints. Besides, certain load\nmonitoring systems often become defective after a few years of marine\nenvironment exposure. Addressing the aforementioned concerns, a farm-wide\nvirtual load monitoring scheme directed by a fleet-leader wind turbine offers\nan attractive solution. Fetched with data retrieved from a fully-instrumented\nwind turbine, a model can be trained and then deployed, thus yielding load\npredictions of non-fully monitored wind turbines, from which only standard data\nremains available. In this paper, we propose a virtual load monitoring\nframework formulated via Bayesian neural networks (BNNs) and we provide\nrelevant implementation details needed for the construction, training, and\ndeployment of BNN data-based virtual monitoring models. As opposed to their\ndeterministic counterparts, BNNs intrinsically announce the uncertainties\nassociated with generated load predictions and allow to detect inaccurate load\nestimations generated for non-fully monitored wind turbines. The proposed\nvirtual load monitoring is thoroughly tested through an experimental campaign\nin an operational offshore wind farm and the results demonstrate the\neffectiveness of BNN models for fleet-leader-based farm-wide virtual\nmonitoring.",
          "link": "http://arxiv.org/abs/2211.00642",
          "publishedOn": "2023-08-26T00:39:49.073Z",
          "wordCount": null,
          "title": "Farm-wide virtual load monitoring for offshore wind structures via Bayesian neural networks. (arXiv:2211.00642v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.14473",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Congliang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Zhi-Quan Luo</a>",
          "description": "Distributed adaptive stochastic gradient methods have been widely used for\nlarge-scale nonconvex optimization, such as training deep learning models.\nHowever, their communication complexity on finding $\\varepsilon$-stationary\npoints has rarely been analyzed in the nonconvex setting. In this work, we\npresent a novel communication-efficient distributed Adam in the\nparameter-server model for stochastic nonconvex optimization, dubbed {\\em\nEfficient-Adam}. Specifically, we incorporate a two-way quantization scheme\ninto Efficient-Adam to reduce the communication cost between the workers and\nserver. Simultaneously, we adopt a two-way error feedback strategy to reduce\nthe biases caused by the two-way quantization on both the server and workers,\nrespectively. In addition, we establish the iteration complexity for the\nproposed Efficient-Adam with a class of quantization operators, and further\ncharacterize its communication complexity between the server and workers when\nan $\\varepsilon$-stationary point is achieved. Finally, we apply Efficient-Adam\nto solve a toy stochastic convex optimization problem and train deep learning\nmodels on real-world vision and language tasks. Extensive experiments together\nwith a theoretical guarantee justify the merits of Efficient Adam.",
          "link": "http://arxiv.org/abs/2205.14473",
          "publishedOn": "2023-08-26T00:39:48.863Z",
          "wordCount": null,
          "title": "Efficient-Adam: Communication-Efficient Distributed Adam. (arXiv:2205.14473v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12316",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bergna_R/0/1/0/all/0/1\">Richard Bergna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Opolka_F/0/1/0/all/0/1\">Felix Opolka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Li&#xf2;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Lobato_J/0/1/0/all/0/1\">Jose Miguel Hernandez-Lobato</a>",
          "description": "We present a novel model Graph Neural Stochastic Differential Equations\n(Graph Neural SDEs). This technique enhances the Graph Neural Ordinary\nDifferential Equations (Graph Neural ODEs) by embedding randomness into data\nrepresentation using Brownian motion. This inclusion allows for the assessment\nof prediction uncertainty, a crucial aspect frequently missed in current\nmodels. In our framework, we spotlight the \\textit{Latent Graph Neural SDE}\nvariant, demonstrating its effectiveness. Through empirical studies, we find\nthat Latent Graph Neural SDEs surpass conventional models like Graph\nConvolutional Networks and Graph Neural ODEs, especially in confidence\nprediction, making them superior in handling out-of-distribution detection\nacross both static and spatio-temporal contexts.",
          "link": "http://arxiv.org/abs/2308.12316",
          "publishedOn": "2023-08-26T00:39:48.856Z",
          "wordCount": null,
          "title": "Graph Neural Stochastic Differential Equations. (arXiv:2308.12316v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12367",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Haochen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Shubham Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patra_S/0/1/0/all/0/1\">Sunandita Patra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopalakrishnan_S/0/1/0/all/0/1\">Sriram Gopalakrishnan</a>",
          "description": "With the growing use of machine learning (ML) models in critical domains such\nas finance and healthcare, the need to offer recourse for those adversely\naffected by the decisions of ML models has become more important; individuals\nought to be provided with recommendations on actions to take for improving\ntheir situation and thus receive a favorable decision. Prior work on sequential\nalgorithmic recourse -- which recommends a series of changes -- focuses on\naction feasibility and uses the proximity of feature changes to determine\naction costs. However, the uncertainties of feature changes and the risk of\nhigher than average costs in recourse have not been considered. It is\nundesirable if a recourse could (with some probability) result in a worse\nsituation from which recovery requires an extremely high cost. It is essential\nto incorporate risks when computing and evaluating recourse. We call the\nrecourse computed with such risk considerations as Safer Algorithmic Recourse\n(SafeAR). The objective is to empower people to choose a recourse based on\ntheir risk tolerance. In this work, we discuss and show how existing recourse\ndesiderata can fail to capture the risk of higher costs. We present a method to\ncompute recourse policies that consider variability in cost and connect\nalgorithmic recourse literature with risk-sensitive reinforcement learning. We\nalso adopt measures ``Value at Risk'' and ``Conditional Value at Risk'' from\nthe financial literature to summarize risk concisely. We apply our method to\ntwo real-world datasets and compare policies with different levels of\nrisk-aversion using risk measures and recourse desiderata (sparsity and\nproximity).",
          "link": "http://arxiv.org/abs/2308.12367",
          "publishedOn": "2023-08-26T00:39:48.697Z",
          "wordCount": null,
          "title": "SafeAR: Towards Safer Algorithmic Recourse by Risk-Aware Policies. (arXiv:2308.12367v1 [cs.LG])",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "stat.ML updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/stat.ML",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2202.07626",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frei_S/0/1/0/all/0/1\">Spencer Frei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterji_N/0/1/0/all/0/1\">Niladri S. Chatterji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1\">Peter L. Bartlett</a>",
          "description": "In this work, we provide a characterization of the feature-learning process\nin two-layer ReLU networks trained by gradient descent on the logistic loss\nfollowing random initialization. We consider data with binary labels that are\ngenerated by an XOR-like function of the input features. We permit a constant\nfraction of the training labels to be corrupted by an adversary. We show that,\nalthough linear classifiers are no better than random guessing for the\ndistribution we consider, two-layer ReLU networks trained by gradient descent\nachieve generalization error close to the label noise rate. We develop a novel\nproof technique that shows that at initialization, the vast majority of neurons\nfunction as random features that are only weakly correlated with useful\nfeatures, and the gradient descent dynamics 'amplify' these weak, random\nfeatures to strong, useful features.",
          "link": "http://arxiv.org/abs/2202.07626",
          "publishedOn": "2023-09-16T00:40:56.879Z",
          "wordCount": null,
          "title": "Random Feature Amplification: Feature Learning and Generalization in Neural Networks. (arXiv:2202.07626v4 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.05969",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yafei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jianguo Liu</a>",
          "description": "Score-based methods for learning Bayesain networks(BN) aim to maximizing the\nglobal score functions. However, if local variables have direct and indirect\ndependence simultaneously, the global optimization on score functions misses\nedges between variables with indirect dependent relationship, of which scores\nare smaller than those with direct dependent relationship. In this paper, we\npresent an identifiability condition based on a determined subset of parents to\nidentify the underlying DAG. By the identifiability condition, we develop a\ntwo-phase algorithm namely optimal-tuning (OT) algorithm to locally amend the\nglobal optimization. In the optimal phase, an optimization problem based on\nfirst-order Hilbert-Schmidt independence criterion (HSIC) gives an estimated\nskeleton as the initial determined parents subset. In the tuning phase, the\nskeleton is locally tuned by deletion, addition and DAG-formalization\nstrategies using the theoretically proved incremental properties of high-order\nHSIC. Numerical experiments for different synthetic datasets and real-world\ndatasets show that the OT algorithm outperforms existing methods. Especially in\nSigmoid Mix model with the size of the graph being ${\\rm\\bf d=40}$, the\nstructure intervention distance (SID) of the OT algorithm is 329.7 smaller than\nthe one obtained by CAM, which indicates that the graph estimated by the OT\nalgorithm misses fewer edges compared with CAM.Source code of the OT algorithm\nis available at https://github.com/YafeiannWang/optimal-tune-algorithm.",
          "link": "http://arxiv.org/abs/2308.05969",
          "publishedOn": "2023-09-16T00:40:56.874Z",
          "wordCount": null,
          "title": "Learning nonparametric DAGs with incremental information via high-order HSIC. (arXiv:2308.05969v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07453",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Navarro_M/0/1/0/all/0/1\">Madeline Navarro</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Segarra_S/0/1/0/all/0/1\">Santiago Segarra</a>",
          "description": "The myriad complex systems with multiway interactions motivate the extension\nof graph-based pairwise connections to higher-order relations. In particular,\nthe simplicial complex has inspired generalizations of graph neural networks\n(GNNs) to simplicial complex-based models. Learning on such systems requires\nlarge amounts of data, which can be expensive or impossible to obtain. We\npropose data augmentation of simplicial complexes through both linear and\nnonlinear mixup mechanisms that return mixtures of existing labeled samples. In\naddition to traditional pairwise mixup, we present a convex clustering mixup\napproach for a data-driven relationship among several simplicial complexes. We\ntheoretically demonstrate that the resultant synthetic simplicial complexes\ninterpolate among existing data with respect to homomorphism densities. Our\nmethod is demonstrated on both synthetic and real-world datasets for simplicial\ncomplex classification.",
          "link": "http://arxiv.org/abs/2309.07453",
          "publishedOn": "2023-09-16T00:40:56.869Z",
          "wordCount": null,
          "title": "SC-MAD: Mixtures of Higher-order Networks for Data Augmentation. (arXiv:2309.07453v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07666",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Montesuma_E/0/1/0/all/0/1\">Eduardo Fernandes Montesuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mboula_F/0/1/0/all/0/1\">Fred Ngol&#xe8; Mboula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Souloumiac_A/0/1/0/all/0/1\">Antoine Souloumiac</a>",
          "description": "In this paper, we consider the intersection of two problems in machine\nlearning: Multi-Source Domain Adaptation (MSDA) and Dataset Distillation (DD).\nOn the one hand, the first considers adapting multiple heterogeneous labeled\nsource domains to an unlabeled target domain. On the other hand, the second\nattacks the problem of synthesizing a small summary containing all the\ninformation about the datasets. We thus consider a new problem called MSDA-DD.\nTo solve it, we adapt previous works in the MSDA literature, such as\nWasserstein Barycenter Transport and Dataset Dictionary Learning, as well as DD\nmethod Distribution Matching. We thoroughly experiment with this novel problem\non four benchmarks (Caltech-Office 10, Tennessee-Eastman Process, Continuous\nStirred Tank Reactor, and Case Western Reserve University), where we show that,\neven with as little as 1 sample per class, one achieves state-of-the-art\nadaptation performance.",
          "link": "http://arxiv.org/abs/2309.07666",
          "publishedOn": "2023-09-16T00:40:56.744Z",
          "wordCount": null,
          "title": "Multi-Source Domain Adaptation meets Dataset Distillation through Dataset Dictionary Learning. (arXiv:2309.07666v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2208.06028",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Michael Y. Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grant_E/0/1/0/all/0/1\">Erin Grant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1\">Thomas L. Griffiths</a>",
          "description": "Not being able to understand and predict the behavior of deep learning\nsystems makes it hard to decide what architecture and algorithm to use for a\ngiven problem. In science and engineering, modeling is a methodology used to\nunderstand complex systems whose internal processes are opaque. Modeling\nreplaces a complex system with a simpler, more interpretable surrogate. Drawing\ninspiration from this, we construct a class of surrogate models for neural\nnetworks using Gaussian processes. Rather than deriving kernels for infinite\nneural networks, we learn kernels empirically from the naturalistic behavior of\nfinite neural networks. We demonstrate our approach captures existing phenomena\nrelated to the spectral bias of neural networks, and then show that our\nsurrogate models can be used to solve practical problems such as identifying\nwhich points most influence the behavior of specific neural networks and\npredicting which architectures and algorithms will generalize well for specific\ndatasets.",
          "link": "http://arxiv.org/abs/2208.06028",
          "publishedOn": "2023-09-16T00:40:56.743Z",
          "wordCount": null,
          "title": "Gaussian Process Surrogate Models for Neural Networks. (arXiv:2208.06028v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07663",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ichikawa_Y/0/1/0/all/0/1\">Yuma Ichikawa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hukushima_K/0/1/0/all/0/1\">Koji Hukushima</a>",
          "description": "In the Variational Autoencoder (VAE), the variational posterior often aligns\nclosely with the prior, which is known as posterior collapse and hinders the\nquality of representation learning. To mitigate this problem, an adjustable\nhyperparameter beta has been introduced in the VAE. This paper presents a\nclosed-form expression to assess the relationship between the beta in VAE, the\ndataset size, the posterior collapse, and the rate-distortion curve by\nanalyzing a minimal VAE in a high-dimensional limit. These results clarify that\na long plateau in the generalization error emerges with a relatively larger\nbeta. As the beta increases, the length of the plateau extends and then becomes\ninfinite beyond a certain beta threshold. This implies that the choice of beta,\nunlike the usual regularization parameters, can induce posterior collapse\nregardless of the dataset size. Thus, beta is a risky parameter that requires\ncareful tuning. Furthermore, considering the dataset-size dependence on the\nrate-distortion curve, a relatively large dataset is required to obtain a\nrate-distortion curve with high rates. Extensive numerical experiments support\nour analysis.",
          "link": "http://arxiv.org/abs/2309.07663",
          "publishedOn": "2023-09-16T00:40:56.738Z",
          "wordCount": null,
          "title": "Dataset Size Dependence of Rate-Distortion Curve and Threshold of Posterior Collapse in Linear VAE. (arXiv:2309.07663v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.03926",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Fadikar_A/0/1/0/all/0/1\">Arindam Fadikar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Binois_M/0/1/0/all/0/1\">Mickael Binois</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Collier_N/0/1/0/all/0/1\">Nicholson Collier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Stevens_A/0/1/0/all/0/1\">Abby Stevens</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Toh_K/0/1/0/all/0/1\">Kok Ben Toh</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ozik_J/0/1/0/all/0/1\">Jonathan Ozik</a>",
          "description": "Epidemiological models must be calibrated to ground truth for downstream\ntasks such as producing forward projections or running what-if scenarios. The\nmeaning of calibration changes in case of a stochastic model since output from\nsuch a model is generally described via an ensemble or a distribution. Each\nmember of the ensemble is usually mapped to a random number seed (explicitly or\nimplicitly). With the goal of finding not only the input parameter settings but\nalso the random seeds that are consistent with the ground truth, we propose a\nclass of Gaussian process (GP) surrogates along with an optimization strategy\nbased on Thompson sampling. This Trajectory Oriented Optimization (TOO)\napproach produces actual trajectories close to the empirical observations\ninstead of a set of parameter settings where only the mean simulation behavior\nmatches with the ground truth.",
          "link": "http://arxiv.org/abs/2305.03926",
          "publishedOn": "2023-09-16T00:40:56.731Z",
          "wordCount": null,
          "title": "Trajectory-oriented optimization of stochastic epidemiological models. (arXiv:2305.03926v3 [stat.AP] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.12814",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Cook_A/0/1/0/all/0/1\">Andrew Cook</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hammerlindl_A/0/1/0/all/0/1\">Andy Hammerlindl</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tucker_W/0/1/0/all/0/1\">Warwick Tucker</a>",
          "description": "We define a family of $C^1$ functions which we call \"nowhere coexpanding\nfunctions\" that is closed under composition and includes all $C^3$ functions\nwith non-positive Schwarzian derivative. We establish results on the number and\nnature of the fixed points of these functions, including a generalisation of a\nclassic result of Singer.",
          "link": "http://arxiv.org/abs/2303.12814",
          "publishedOn": "2023-09-16T00:40:56.728Z",
          "wordCount": null,
          "title": "Nowhere coexpanding functions. (arXiv:2303.12814v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07261",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Du_J/0/1/0/all/0/1\">Jin-Hong Du</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wasserman_L/0/1/0/all/0/1\">Larry Wasserman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Roeder_K/0/1/0/all/0/1\">Kathryn Roeder</a>",
          "description": "Tens of thousands of simultaneous hypothesis tests are routinely performed in\ngenomic studies to identify differentially expressed genes. However, due to\nunmeasured confounders, many standard statistical approaches may be\nsubstantially biased. This paper investigates the large-scale hypothesis\ntesting problem for multivariate generalized linear models in the presence of\nconfounding effects. Under arbitrary confounding mechanisms, we propose a\nunified statistical estimation and inference framework that harnesses\northogonal structures and integrates linear projections into three key stages.\nIt first leverages multivariate responses to separate marginal and uncorrelated\nconfounding effects, recovering the confounding coefficients' column space.\nSubsequently, latent factors and primary effects are jointly estimated,\nutilizing $\\ell_1$-regularization for sparsity while imposing orthogonality\nonto confounding coefficients. Finally, we incorporate projected and weighted\nbias-correction steps for hypothesis testing. Theoretically, we establish\nvarious effects' identification conditions and non-asymptotic error bounds. We\nshow effective Type-I error control of asymptotic $z$-tests as sample and\nresponse sizes approach infinity. Numerical experiments demonstrate that the\nproposed method controls the false discovery rate by the Benjamini-Hochberg\nprocedure and is more powerful than alternative methods. By comparing\nsingle-cell RNA-seq counts from two groups of samples, we demonstrate the\nsuitability of adjusting confounding effects when significant covariates are\nabsent from the model.",
          "link": "http://arxiv.org/abs/2309.07261",
          "publishedOn": "2023-09-16T00:40:56.655Z",
          "wordCount": null,
          "title": "Simultaneous inference for generalized linear models with unmeasured confounders. (arXiv:2309.07261v1 [stat.ME])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.07611",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Zheng_H/0/1/0/all/0/1\">Han Zheng</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Li_Z/0/1/0/all/0/1\">Zimu Li</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Liu_J/0/1/0/all/0/1\">Junyu Liu</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Strelchuk_S/0/1/0/all/0/1\">Sergii Strelchuk</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Kondor_R/0/1/0/all/0/1\">Risi Kondor</a>",
          "description": "We develop a theoretical framework for $S_n$-equivariant convolutional\nquantum circuits with SU$(d)$-symmetry, building on and significantly\ngeneralizing Jordan's Permutational Quantum Computing (PQC) formalism based on\nSchur-Weyl duality connecting both SU$(d)$ and $S_n$ actions on qudits. In\nparticular, we utilize the Okounkov-Vershik approach to prove Harrow's\nstatement (Ph.D. Thesis 2005 p.160) on the equivalence between\n$\\operatorname{SU}(d)$ and $S_n$ irrep bases and to establish the\n$S_n$-equivariant Convolutional Quantum Alternating Ans\\\"atze ($S_n$-CQA) using\nYoung-Jucys-Murphy (YJM) elements. We prove that $S_n$-CQA is able to generate\nany unitary in any given $S_n$ irrep sector, which may serve as a universal\nmodel for a wide array of quantum machine learning problems with the presence\nof SU($d$) symmetry. Our method provides another way to prove the universality\nof Quantum Approximate Optimization Algorithm (QAOA) and verifies that 4-local\nSU($d$) symmetric unitaries are sufficient to build generic SU($d$) symmetric\nquantum circuits up to relative phase factors. We present numerical simulations\nto showcase the effectiveness of the ans\\\"atze to find the ground state energy\nof the $J_1$--$J_2$ antiferromagnetic Heisenberg model on the rectangular and\nKagome lattices. Our work provides the first application of the celebrated\nOkounkov-Vershik's $S_n$ representation theory to quantum physics and machine\nlearning, from which to propose quantum variational ans\\\"atze that strongly\nsuggests to be classically intractable tailored towards a specific optimization\nproblem.",
          "link": "http://arxiv.org/abs/2112.07611",
          "publishedOn": "2023-09-16T00:40:56.580Z",
          "wordCount": null,
          "title": "Speeding up Learning Quantum States through Group Equivariant Convolutional Quantum Ans\\\"atze. (arXiv:2112.07611v3 [quant-ph] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.07332",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhan_X/0/1/0/all/0/1\">Xianghao Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qinmei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yuanning Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1\">Guangming Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gevaert_O/0/1/0/all/0/1\">Olivier Gevaert</a>",
          "description": "Accurately labeling biomedical data presents a challenge. Traditional\nsemi-supervised learning methods often under-utilize available unlabeled data.\nTo address this, we propose a novel reliability-based training data cleaning\nmethod employing inductive conformal prediction (ICP). This method capitalizes\non a small set of accurately labeled training data and leverages ICP-calculated\nreliability metrics to rectify mislabeled data and outliers within vast\nquantities of noisy training data. The efficacy of the method is validated\nacross three classification tasks within distinct modalities: filtering\ndrug-induced-liver-injury (DILI) literature with title and abstract, predicting\nICU admission of COVID-19 patients through CT radiomics and electronic health\nrecords, and subtyping breast cancer using RNA-sequencing data. Varying levels\nof noise to the training labels were introduced through label permutation.\nResults show significant enhancements in classification performance: accuracy\nenhancement in 86 out of 96 DILI experiments (up to 11.4%), AUROC and AUPRC\nenhancements in all 48 COVID-19 experiments (up to 23.8% and 69.8%), and\naccuracy and macro-average F1 score improvements in 47 out of 48 RNA-sequencing\nexperiments (up to 74.6% and 89.0%). Our method offers the potential to\nsubstantially boost classification performance in multi-modal biomedical\nmachine learning tasks. Importantly, it accomplishes this without necessitating\nan excessive volume of meticulously curated training data.",
          "link": "http://arxiv.org/abs/2309.07332",
          "publishedOn": "2023-09-16T00:40:54.840Z",
          "wordCount": 803,
          "title": "Reliability-based cleaning of noisy training labels with inductive conformal prediction in multi-modal biomedical data mining. (arXiv:2309.07332v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07893",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tripuraneni_N/0/1/0/all/0/1\">Nilesh Tripuraneni</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Richardson_L/0/1/0/all/0/1\">Lee Richardson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+DAmour_A/0/1/0/all/0/1\">Alexander D&#x27;Amour</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Soriano_J/0/1/0/all/0/1\">Jacopo Soriano</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yadlowsky_S/0/1/0/all/0/1\">Steve Yadlowsky</a>",
          "description": "In many randomized experiments, the treatment effect of the long-term metric\n(i.e. the primary outcome of interest) is often difficult or infeasible to\nmeasure. Such long-term metrics are often slow to react to changes and\nsufficiently noisy they are challenging to faithfully estimate in short-horizon\nexperiments. A common alternative is to measure several short-term proxy\nmetrics in the hope they closely track the long-term metric -- so they can be\nused to effectively guide decision-making in the near-term. We introduce a new\nstatistical framework to both define and construct an optimal proxy metric for\nuse in a homogeneous population of randomized experiments. Our procedure first\nreduces the construction of an optimal proxy metric in a given experiment to a\nportfolio optimization problem which depends on the true latent treatment\neffects and noise level of experiment under consideration. We then denoise the\nobserved treatment effects of the long-term metric and a set of proxies in a\nhistorical corpus of randomized experiments to extract estimates of the latent\ntreatment effects for use in the optimization problem. One key insight derived\nfrom our approach is that the optimal proxy metric for a given experiment is\nnot apriori fixed; rather it should depend on the sample size (or effective\nnoise level) of the randomized experiment for which it is deployed. To\ninstantiate and evaluate our framework, we employ our methodology in a large\ncorpus of randomized experiments from an industrial recommendation system and\nconstruct proxy metrics that perform favorably relative to several baselines.",
          "link": "http://arxiv.org/abs/2309.07893",
          "publishedOn": "2023-09-16T00:40:54.823Z",
          "wordCount": 746,
          "title": "Choosing a Proxy Metric from Past Experiments. (arXiv:2309.07893v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2105.06031",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Fan_Y/0/1/0/all/0/1\">Yifeng Fan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Khoo_Y/0/1/0/all/0/1\">Yuehaw Khoo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhizhen Zhao</a>",
          "description": "In the presence of heterogeneous data, where randomly rotated objects fall\ninto multiple underlying categories, it is challenging to simultaneously\nclassify them into clusters and synchronize them based on pairwise relations.\nThis gives rise to the joint problem of community detection and\nsynchronization. We propose a series of semidefinite relaxations, and prove\ntheir exact recovery when extending the celebrated stochastic block model to\nthis new setting where both rotations and cluster identities are to be\ndetermined. Numerical experiments demonstrate the efficacy of our proposed\nalgorithms and confirm our theoretical result which indicates a sharp phase\ntransition for exact recovery.",
          "link": "http://arxiv.org/abs/2105.06031",
          "publishedOn": "2023-09-16T00:40:54.809Z",
          "wordCount": 622,
          "title": "Joint Community Detection and Rotational Synchronization via Semidefinite Programming. (arXiv:2105.06031v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07867",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mingyuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhendong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Huangjie Zheng</a>",
          "description": "We introduce beta diffusion, a novel generative modeling method that\nintegrates demasking and denoising to generate data within bounded ranges.\nUsing scaled and shifted beta distributions, beta diffusion utilizes\nmultiplicative transitions over time to create both forward and reverse\ndiffusion processes, maintaining beta distributions in both the forward\nmarginals and the reverse conditionals, given the data at any point in time.\nUnlike traditional diffusion-based generative models relying on additive\nGaussian noise and reweighted evidence lower bounds (ELBOs), beta diffusion is\nmultiplicative and optimized with KL-divergence upper bounds (KLUBs) derived\nfrom the convexity of the KL divergence. We demonstrate that the proposed KLUBs\nare more effective for optimizing beta diffusion compared to negative ELBOs,\nwhich can also be derived as the KLUBs of the same KL divergence with its two\narguments swapped. The loss function of beta diffusion, expressed in terms of\nBregman divergence, further supports the efficacy of KLUBs for optimization.\nExperimental results on both synthetic data and natural images demonstrate the\nunique capabilities of beta diffusion in generative modeling of range-bounded\ndata and validate the effectiveness of KLUBs in optimizing diffusion models,\nthereby making them valuable additions to the family of diffusion-based\ngenerative models and the optimization techniques used to train them.",
          "link": "http://arxiv.org/abs/2309.07867",
          "publishedOn": "2023-09-16T00:40:54.786Z",
          "wordCount": 706,
          "title": "Beta Diffusion. (arXiv:2309.07867v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07418",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yeqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weixin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1\">Junze Yin</a>",
          "description": "Large language models (LLMs) have played a pivotal role in revolutionizing\nvarious facets of our daily existence. Solving attention regression is a\nfundamental task in optimizing LLMs. In this work, we focus on giving a\nprovable guarantee for the one-layer attention network objective function\n$L(X,Y) = \\sum_{j_0 = 1}^n \\sum_{i_0 = 1}^d ( \\langle \\langle \\exp(\n\\mathsf{A}_{j_0} x ) , {\\bf 1}_n \\rangle^{-1} \\exp( \\mathsf{A}_{j_0} x ), A_{3}\nY_{*,i_0} \\rangle - b_{j_0,i_0} )^2$. Here $\\mathsf{A} \\in \\mathbb{R}^{n^2\n\\times d^2}$ is Kronecker product between $A_1 \\in \\mathbb{R}^{n \\times d}$ and\n$A_2 \\in \\mathbb{R}^{n \\times d}$. $A_3$ is a matrix in $\\mathbb{R}^{n \\times\nd}$, $\\mathsf{A}_{j_0} \\in \\mathbb{R}^{n \\times d^2}$ is the $j_0$-th block of\n$\\mathsf{A}$. The $X, Y \\in \\mathbb{R}^{d \\times d}$ are variables we want to\nlearn. $B \\in \\mathbb{R}^{n \\times d}$ and $b_{j_0,i_0} \\in \\mathbb{R}$ is one\nentry at $j_0$-th row and $i_0$-th column of $B$, $Y_{*,i_0} \\in \\mathbb{R}^d$\nis the $i_0$-column vector of $Y$, and $x \\in \\mathbb{R}^{d^2}$ is the\nvectorization of $X$.\n\nIn a multi-layer LLM network, the matrix $B \\in \\mathbb{R}^{n \\times d}$ can\nbe viewed as the output of a layer, and $A_1= A_2 = A_3 \\in \\mathbb{R}^{n\n\\times d}$ can be viewed as the input of a layer. The matrix version of $x$ can\nbe viewed as $QK^\\top$ and $Y$ can be viewed as $V$. We provide an iterative\ngreedy algorithm to train loss function $L(X,Y)$ up $\\epsilon$ that runs in\n$\\widetilde{O}( ({\\cal T}_{\\mathrm{mat}}(n,n,d) + {\\cal\nT}_{\\mathrm{mat}}(n,d,d) + d^{2\\omega}) \\log(1/\\epsilon) )$ time. Here ${\\cal\nT}_{\\mathrm{mat}}(a,b,c)$ denotes the time of multiplying $a \\times b$ matrix\nanother $b \\times c$ matrix, and $\\omega\\approx 2.37$ denotes the exponent of\nmatrix multiplication.",
          "link": "http://arxiv.org/abs/2309.07418",
          "publishedOn": "2023-09-16T00:40:54.757Z",
          "wordCount": 839,
          "title": "A Fast Optimization View: Reformulating Single Layer Attention in LLM Based on Tensor and SVM Trick, and Solving It in Matrix Multiplication Time. (arXiv:2309.07418v1 [cs.DS])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.13348",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Ishikawa_K/0/1/0/all/0/1\">Kei Ishikawa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+He_N/0/1/0/all/0/1\">Niao He</a>",
          "description": "We study policy evaluation of offline contextual bandits subject to\nunobserved confounders. Sensitivity analysis methods are commonly used to\nestimate the policy value under the worst-case confounding over a given\nuncertainty set. However, existing work often resorts to some coarse relaxation\nof the uncertainty set for the sake of tractability, leading to overly\nconservative estimation of the policy value. In this paper, we propose a\ngeneral estimator that provides a sharp lower bound of the policy value. It can\nbe shown that our estimator contains the recently proposed sharp estimator by\nDorn and Guo (2022) as a special case, and our method enables a novel extension\nof the classical marginal sensitivity model using f-divergence. To construct\nour estimator, we leverage the kernel method to obtain a tractable\napproximation to the conditional moment constraints, which traditional\nnon-sharp estimators failed to take into account. In the theoretical analysis,\nwe provide a condition for the choice of the kernel which guarantees no\nspecification error that biases the lower bound estimation. Furthermore, we\nprovide consistency guarantees of policy evaluation and learning. In the\nexperiments with synthetic and real-world data, we demonstrate the\neffectiveness of the proposed method.",
          "link": "http://arxiv.org/abs/2302.13348",
          "publishedOn": "2023-09-16T00:40:54.739Z",
          "wordCount": 705,
          "title": "Kernel Conditional Moment Constraints for Confounding Robust Inference. (arXiv:2302.13348v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07250",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+East_R/0/1/0/all/0/1\">Richard D. P. East</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Alonso_Linaje_G/0/1/0/all/0/1\">Guillermo Alonso-Linaje</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Park_C/0/1/0/all/0/1\">Chae-Yeun Park</a>",
          "description": "Variational algorithms require architectures that naturally constrain the\noptimisation space to run efficiently. In geometric quantum machine learning,\none achieves this by encoding group structure into parameterised quantum\ncircuits to include the symmetries of a problem as an inductive bias. However,\nconstructing such circuits is challenging as a concrete guiding principle has\nyet to emerge. In this paper, we propose the use of spin networks, a form of\ndirected tensor network invariant under a group transformation, to devise SU(2)\nequivariant quantum circuit ans\\\"atze -- circuits possessing spin rotation\nsymmetry. By changing to the basis that block diagonalises SU(2) group action,\nthese networks provide a natural building block for constructing parameterised\nequivariant quantum circuits. We prove that our construction is mathematically\nequivalent to other known constructions, such as those based on twirling and\ngeneralised permutations, but more direct to implement on quantum hardware. The\nefficacy of our constructed circuits is tested by solving the ground state\nproblem of SU(2) symmetric Heisenberg models on the one-dimensional triangular\nlattice and on the Kagome lattice. Our results highlight that our equivariant\ncircuits boost the performance of quantum variational algorithms, indicating\nbroader applicability to other real-world problems.",
          "link": "http://arxiv.org/abs/2309.07250",
          "publishedOn": "2023-09-16T00:40:54.730Z",
          "wordCount": 729,
          "title": "All you need is spin: SU(2) equivariant variational quantum circuits based on spin networks. (arXiv:2309.07250v1 [quant-ph])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.06724",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wangni_J/0/1/0/all/0/1\">Jianqiao Wangni</a>",
          "description": "We aim to provide a general framework of for computational photography that\nrecovers the real scene from imperfect images, via the Deep Nonparametric\nConvexified Filtering (DNCF). It is consists of a nonparametric deep network to\nresemble the physical equations behind the image formation, such as denoising,\nsuper-resolution, inpainting, and flash. DNCF has no parameterization dependent\non training data, therefore has a strong generalization and robustness to\nadversarial image manipulation. During inference, we also encourage the network\nparameters to be nonnegative and create a bi-convex function on the input and\nparameters, and this adapts to second-order optimization algorithms with\ninsufficient running time, having 10X acceleration over Deep Image Prior. With\nthese tools, we empirically verify its capability to defend image\nclassification deep networks against adversary attack algorithms in real-time.",
          "link": "http://arxiv.org/abs/2309.06724",
          "publishedOn": "2023-09-16T00:40:54.725Z",
          "wordCount": 669,
          "title": "Deep Nonparametric Convexified Filtering for Computational Photography, Image Synthesis and Adversarial Defense. (arXiv:2309.06724v2 [cs.CV] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/1906.00331",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1\">Tianyi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1\">Chi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>",
          "description": "We consider nonconvex-concave minimax problems, $\\min_{\\mathbf{x}}\n\\max_{\\mathbf{y} \\in \\mathcal{Y}} f(\\mathbf{x}, \\mathbf{y})$, where $f$ is\nnonconvex in $\\mathbf{x}$ but concave in $\\mathbf{y}$ and $\\mathcal{Y}$ is a\nconvex and bounded set. One of the most popular algorithms for solving this\nproblem is the celebrated gradient descent ascent (GDA) algorithm, which has\nbeen widely used in machine learning, control theory and economics. Despite the\nextensive convergence results for the convex-concave setting, GDA with equal\nstepsize can converge to limit cycles or even diverge in a general setting. In\nthis paper, we present the complexity results on two-time-scale GDA for solving\nnonconvex-concave minimax problems, showing that the algorithm can find a\nstationary point of the function $\\Phi(\\cdot) := \\max_{\\mathbf{y} \\in\n\\mathcal{Y}} f(\\cdot, \\mathbf{y})$ efficiently. To the best our knowledge, this\nis the first nonasymptotic analysis for two-time-scale GDA in this setting,\nshedding light on its superior practical performance in training generative\nadversarial networks (GANs) and other real applications.",
          "link": "http://arxiv.org/abs/1906.00331",
          "publishedOn": "2023-09-16T00:40:54.717Z",
          "wordCount": 779,
          "title": "On Gradient Descent Ascent for Nonconvex-Concave Minimax Problems. (arXiv:1906.00331v9 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07810",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Li_Y/0/1/0/all/0/1\">Yufan Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sur_P/0/1/0/all/0/1\">Pragya Sur</a>",
          "description": "We introduce a new debiasing framework for high-dimensional linear regression\nthat bypasses the restrictions on covariate distributions imposed by modern\ndebiasing technology. We study the prevalent setting where the number of\nfeatures and samples are both large and comparable. In this context,\nstate-of-the-art debiasing technology uses a degrees-of-freedom correction to\nremove shrinkage bias of regularized estimators and conduct inference. However,\nthis method requires that the observed samples are i.i.d., the covariates\nfollow a mean zero Gaussian distribution, and reliable covariance matrix\nestimates for observed features are available. This approach struggles when (i)\ncovariates are non-Gaussian with heavy tails or asymmetric distributions, (ii)\nrows of the design exhibit heterogeneity or dependencies, and (iii) reliable\nfeature covariance estimates are lacking.\n\nTo address these, we develop a new strategy where the debiasing correction is\na rescaled gradient descent step (suitably initialized) with step size\ndetermined by the spectrum of the sample covariance matrix. Unlike prior work,\nwe assume that eigenvectors of this matrix are uniform draws from the\northogonal group. We show this assumption remains valid in diverse situations\nwhere traditional debiasing fails, including designs with complex row-column\ndependencies, heavy tails, asymmetric properties, and latent low-rank\nstructures. We establish asymptotic normality of our proposed estimator\n(centered and scaled) under various convergence notions. Moreover, we develop a\nconsistent estimator for its asymptotic variance. Lastly, we introduce a\ndebiased Principal Component Regression (PCR) technique using our\nSpectrum-Aware approach. In varied simulations and real data experiments, we\nobserve that our method outperforms degrees-of-freedom debiasing by a margin.",
          "link": "http://arxiv.org/abs/2309.07810",
          "publishedOn": "2023-09-16T00:40:54.711Z",
          "wordCount": 772,
          "title": "Spectrum-Aware Adjustment: A New Debiasing Framework with Applications to Principal Components Regression. (arXiv:2309.07810v1 [math.ST])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2009.01726",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Escobar_Bach_M/0/1/0/all/0/1\">Mikael Escobar-Bach</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Goudet_O/0/1/0/all/0/1\">Olivier Goudet</a>",
          "description": "In the presence of right-censored data with covariates, the conditional\nKaplan-Meier estimator (also known as the Beran estimator) consistently\nestimates the conditional survival function of the random follow-up for the\nevent of interest. However, a necessary condition is the unambiguous knowledge\nof whether each individual is censored or not, which may be incomplete in\npractice. We therefore propose a study of the Beran estimator when the\ncensoring indicators are generic random variables and discuss necessary\nconditions for the efficiency of the Beran estimator. From this, we provide a\nnew estimator for the conditional survival function with missing not at random\n(MNAR) censoring indicators based on a conditional copula model for the\nmissingness mechanism. In addition to the theoretical results, we illustrate\nhow the estimators work for small samples through a simulation study and show\ntheir practical applicability by analyzing synthetic and real data.",
          "link": "http://arxiv.org/abs/2009.01726",
          "publishedOn": "2023-09-16T00:40:54.693Z",
          "wordCount": 673,
          "title": "Survival Estimation for Missing not at Random Censoring Indicators based on Copula Models. (arXiv:2009.01726v2 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07779",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Griebel_M/0/1/0/all/0/1\">Michael Griebel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Oswald_P/0/1/0/all/0/1\">Peter Oswald</a>",
          "description": "We consider the problem of approximating the regression function from noisy\nvector-valued data by an online learning algorithm using an appropriate\nreproducing kernel Hilbert space (RKHS) as prior. In an online algorithm,\ni.i.d. samples become available one by one by a random process and are\nsuccessively processed to build approximations to the regression function. We\nare interested in the asymptotic performance of such online approximation\nalgorithms and show that the expected squared error in the RKHS norm can be\nbounded by $C^2 (m+1)^{-s/(2+s)}$, where $m$ is the current number of processed\ndata, the parameter $0<s\\leq 1$ expresses an additional smoothness assumption\non the regression function and the constant $C$ depends on the variance of the\ninput noise, the smoothness of the regression function and further parameters\nof the algorithm.",
          "link": "http://arxiv.org/abs/2309.07779",
          "publishedOn": "2023-09-16T00:40:54.688Z",
          "wordCount": 636,
          "title": "Convergence analysis of online algorithms for vector-valued kernel regression. (arXiv:2309.07779v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.07260",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhouri_M/0/1/0/all/0/1\">Mohamed Aziz Bhouri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joly_M/0/1/0/all/0/1\">Michael Joly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1\">Robert Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1\">Soumalya Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perdikaris_P/0/1/0/all/0/1\">Paris Perdikaris</a>",
          "description": "Several fundamental problems in science and engineering consist of global\noptimization tasks involving unknown high-dimensional (black-box) functions\nthat map a set of controllable variables to the outcomes of an expensive\nexperiment. Bayesian Optimization (BO) techniques are known to be effective in\ntackling global optimization problems using a relatively small number objective\nfunction evaluations, but their performance suffers when dealing with\nhigh-dimensional outputs. To overcome the major challenge of dimensionality,\nhere we propose a deep learning framework for BO and sequential decision making\nbased on bootstrapped ensembles of neural architectures with randomized priors.\nUsing appropriate architecture choices, we show that the proposed framework can\napproximate functional relationships between design variables and quantities of\ninterest, even in cases where the latter take values in high-dimensional vector\nspaces or even infinite-dimensional function spaces. In the context of BO, we\naugmented the proposed probabilistic surrogates with re-parameterized Monte\nCarlo approximations of multiple-point (parallel) acquisition functions, as\nwell as methodological extensions for accommodating black-box constraints and\nmulti-fidelity information sources. We test the proposed framework against\nstate-of-the-art methods for BO and demonstrate superior performance across\nseveral challenging tasks with high-dimensional outputs, including a\nconstrained multi-fidelity optimization task involving shape optimization of\nrotor blades in turbo-machinery.",
          "link": "http://arxiv.org/abs/2302.07260",
          "publishedOn": "2023-09-16T00:40:54.674Z",
          "wordCount": 807,
          "title": "Scalable Bayesian optimization with high-dimensional outputs using randomized prior networks. (arXiv:2302.07260v5 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2202.05928",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frei_S/0/1/0/all/0/1\">Spencer Frei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterji_N/0/1/0/all/0/1\">Niladri S. Chatterji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1\">Peter L. Bartlett</a>",
          "description": "Benign overfitting, the phenomenon where interpolating models generalize well\nin the presence of noisy data, was first observed in neural network models\ntrained with gradient descent. To better understand this empirical observation,\nwe consider the generalization error of two-layer neural networks trained to\ninterpolation by gradient descent on the logistic loss following random\ninitialization. We assume the data comes from well-separated class-conditional\nlog-concave distributions and allow for a constant fraction of the training\nlabels to be corrupted by an adversary. We show that in this setting, neural\nnetworks exhibit benign overfitting: they can be driven to zero training error,\nperfectly fitting any noisy training labels, and simultaneously achieve minimax\noptimal test error. In contrast to previous work on benign overfitting that\nrequire linear or kernel-based predictors, our analysis holds in a setting\nwhere both the model and learning dynamics are fundamentally nonlinear.",
          "link": "http://arxiv.org/abs/2202.05928",
          "publishedOn": "2023-09-16T00:40:54.653Z",
          "wordCount": 725,
          "title": "Benign Overfitting without Linearity: Neural Network Classifiers Trained by Gradient Descent for Noisy Linear Data. (arXiv:2202.05928v4 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07593",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chamma_A/0/1/0/all/0/1\">Ahmad Chamma</a> (1 and 2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Engemann_D/0/1/0/all/0/1\">Denis A. Engemann</a> (4), <a href=\"http://arxiv.org/find/cs/1/au:+Thirion_B/0/1/0/all/0/1\">Bertrand Thirion</a> (1 and 2 and 3) ((1) Inria, (2) Universite Paris Saclay, (3) CEA, (4) Roche Pharma Research and Early Development, Neuroscience and Rare Diseases, Roche Innovation Center Basel, F. Hoffmann-La Roche Ltd., Basel, Switzerland)",
          "description": "Variable importance assessment has become a crucial step in machine-learning\napplications when using complex learners, such as deep neural networks, on\nlarge-scale data. Removal-based importance assessment is currently the\nreference approach, particularly when statistical guarantees are sought to\njustify variable inclusion. It is often implemented with variable permutation\nschemes. On the flip side, these approaches risk misidentifying unimportant\nvariables as important in the presence of correlations among covariates. Here\nwe develop a systematic approach for studying Conditional Permutation\nImportance (CPI) that is model agnostic and computationally lean, as well as\nreusable benchmarks of state-of-the-art variable importance estimators. We show\ntheoretically and empirically that $\\textit{CPI}$ overcomes the limitations of\nstandard permutation importance by providing accurate type-I error control.\nWhen used with a deep neural network, $\\textit{CPI}$ consistently showed top\naccuracy across benchmarks. An empirical benchmark on real-world data analysis\nin a large-scale medical dataset showed that $\\textit{CPI}$ provides a more\nparsimonious selection of statistically significant variables. Our results\nsuggest that $\\textit{CPI}$ can be readily used as drop-in replacement for\npermutation-based methods.",
          "link": "http://arxiv.org/abs/2309.07593",
          "publishedOn": "2023-09-16T00:40:54.647Z",
          "wordCount": 729,
          "title": "Statistically Valid Variable Importance Assessment through Conditional Permutations. (arXiv:2309.07593v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07065",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Malpica_Morales_A/0/1/0/all/0/1\">Antonio Malpica-Morales</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Yatsyshin_P/0/1/0/all/0/1\">Peter Yatsyshin</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Duran_Olivencia_M/0/1/0/all/0/1\">Miguel A. Duran-Olivencia</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Kalliadasis_S/0/1/0/all/0/1\">Serafim Kalliadasis</a>",
          "description": "The swift progression of machine learning (ML) has not gone unnoticed in the\nrealm of statistical mechanics. ML techniques have attracted attention by the\nclassical density-functional theory (DFT) community, as they enable discovery\nof free-energy functionals to determine the equilibrium-density profile of a\nmany-particle system. Within DFT, the external potential accounts for the\ninteraction of the many-particle system with an external field, thus, affecting\nthe density distribution. In this context, we introduce a statistical-learning\nframework to infer the external potential exerted on a many-particle system. We\ncombine a Bayesian inference approach with the classical DFT apparatus to\nreconstruct the external potential, yielding a probabilistic description of the\nexternal potential functional form with inherent uncertainty quantification.\nOur framework is exemplified with a grand-canonical one-dimensional particle\nensemble with excluded volume interactions in a confined geometry. The required\ntraining dataset is generated using a Monte Carlo (MC) simulation where the\nexternal potential is applied to the grand-canonical ensemble. The resulting\nparticle coordinates from the MC simulation are fed into the learning framework\nto uncover the external potential. This eventually allows us to compute the\nequilibrium density profile of the system by using the tools of DFT. Our\napproach benchmarks the inferred density against the exact one calculated\nthrough the DFT formulation with the true external potential. The proposed\nBayesian procedure accurately infers the external potential and the density\nprofile. We also highlight the external-potential uncertainty quantification\nconditioned on the amount of available simulated data. The seemingly simple\ncase study introduced in this work might serve as a prototype for studying a\nwide variety of applications, including adsorption and capillarity.",
          "link": "http://arxiv.org/abs/2309.07065",
          "publishedOn": "2023-09-16T00:40:54.640Z",
          "wordCount": 830,
          "title": "Physics-informed Bayesian inference of external potentials in classical density-functional theory. (arXiv:2309.07065v2 [cond-mat.stat-mech] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07703",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Simoes_F/0/1/0/all/0/1\">Francisco Nunes Ferreira Quialheiro Simoes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dastani_M/0/1/0/all/0/1\">Mehdi Dastani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ommen_T/0/1/0/all/0/1\">Thijs van Ommen</a>",
          "description": "Artificial intelligence models and methods commonly lack causal\ninterpretability. Despite the advancements in interpretable machine learning\n(IML) methods, they frequently assign importance to features which lack causal\ninfluence on the outcome variable. Selecting causally relevant features among\nthose identified as relevant by these methods, or even before model training,\nwould offer a solution. Feature selection methods utilizing information\ntheoretical quantities have been successful in identifying statistically\nrelevant features. However, the information theoretical quantities they are\nbased on do not incorporate causality, rendering them unsuitable for such\nscenarios. To address this challenge, this article proposes information\ntheoretical quantities that incorporate the causal structure of the system,\nwhich can be used to evaluate causal importance of features for some given\noutcome variable. Specifically, we introduce causal versions of entropy and\nmutual information, termed causal entropy and causal information gain, which\nare designed to assess how much control a feature provides over the outcome\nvariable. These newly defined quantities capture changes in the entropy of a\nvariable resulting from interventions on other variables. Fundamental results\nconnecting these quantities to the existence of causal effects are derived. The\nuse of causal information gain in feature selection is demonstrated,\nhighlighting its superiority over standard mutual information in revealing\nwhich features provide control over a chosen outcome variable. Our\ninvestigation paves the way for the development of methods with improved\ninterpretability in domains involving causation.",
          "link": "http://arxiv.org/abs/2309.07703",
          "publishedOn": "2023-09-16T00:40:54.633Z",
          "wordCount": 777,
          "title": "Causal Entropy and Information Gain for Measuring Causal Control. (arXiv:2309.07703v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07882",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Chakraborty_A/0/1/0/all/0/1\">Anirban Chakraborty</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chakraborty_A/0/1/0/all/0/1\">Abhisek Chakraborty</a>",
          "description": "Gaussian process is an indispensable tool in clustering functional data,\nowing to it's flexibility and inherent uncertainty quantification. However,\nwhen the functional data is observed over a large grid (say, of length $p$),\nGaussian process clustering quickly renders itself infeasible, incurring\n$O(p^2)$ space complexity and $O(p^3)$ time complexity per iteration; and thus\nprohibiting it's natural adaptation to large environmental applications. To\nensure scalability of Gaussian process clustering in such applications, we\npropose to embed the popular Vecchia approximation for Gaussian processes at\nthe heart of the clustering task, provide crucial theoretical insights towards\nalgorithmic design, and finally develop a computationally efficient expectation\nmaximization (EM) algorithm. Empirical evidence of the utility of our proposal\nis provided via simulations and analysis of polar temperature anomaly\n(\\href{https://www.ncei.noaa.gov/access/monitoring/climate-at-a-glance/global/time-series}{noaa.gov})\ndata-sets.",
          "link": "http://arxiv.org/abs/2309.07882",
          "publishedOn": "2023-09-16T00:40:54.618Z",
          "wordCount": 610,
          "title": "Scalable Model-Based Gaussian Process Clustering. (arXiv:2309.07882v1 [stat.CO])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2309.07176",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1\">Angela Zhou</a>",
          "description": "In consequential domains, it is often impossible to compel individuals to\ntake treatment, so that optimal policy rules are merely suggestions in the\npresence of human non-adherence to treatment recommendations. In these same\ndomains, there may be heterogeneity both in who responds in taking-up\ntreatment, and heterogeneity in treatment efficacy. While optimal treatment\nrules can maximize causal outcomes across the population, access parity\nconstraints or other fairness considerations can be relevant in the case of\nencouragement. For example, in social services, a persistent puzzle is the gap\nin take-up of beneficial services among those who may benefit from them the\nmost. When in addition the decision-maker has distributional preferences over\nboth access and average outcomes, the optimal decision rule changes. We study\ncausal identification, statistical variance-reduced estimation, and robust\nestimation of optimal treatment rules, including under potential violations of\npositivity. We consider fairness constraints such as demographic parity in\ntreatment take-up, and other constraints, via constrained optimization. Our\nframework can be extended to handle algorithmic recommendations under an\noften-reasonable covariate-conditional exclusion restriction, using our\nrobustness checks for lack of positivity in the recommendation. We develop a\ntwo-stage algorithm for solving over parametrized policy classes under general\nconstraints to obtain variance-sensitive regret bounds. We illustrate the\nmethods in two case studies based on data from randomized encouragement to\nenroll in insurance and from pretrial supervised release with electronic\nmonitoring.",
          "link": "http://arxiv.org/abs/2309.07176",
          "publishedOn": "2023-09-16T00:40:54.609Z",
          "wordCount": 720,
          "title": "Optimal and Fair Encouragement Policy Evaluation and Learning. (arXiv:2309.07176v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.01952",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Rosca_M/0/1/0/all/0/1\">Mihaela Rosca</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1\">Yan Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Qin_C/0/1/0/all/0/1\">Chongli Qin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dherin_B/0/1/0/all/0/1\">Benoit Dherin</a>",
          "description": "The recipe behind the success of deep learning has been the combination of\nneural networks and gradient-based optimization. Understanding the behavior of\ngradient descent however, and particularly its instability, has lagged behind\nits empirical success. To add to the theoretical tools available to study\ngradient descent we propose the principal flow (PF), a continuous time flow\nthat approximates gradient descent dynamics. To our knowledge, the PF is the\nonly continuous flow that captures the divergent and oscillatory behaviors of\ngradient descent, including escaping local minima and saddle points. Through\nits dependence on the eigendecomposition of the Hessian the PF sheds light on\nthe recently observed edge of stability phenomena in deep learning. Using our\nnew understanding of instability we propose a learning rate adaptation method\nwhich enables us to control the trade-off between training stability and test\nset evaluation performance.",
          "link": "http://arxiv.org/abs/2302.01952",
          "publishedOn": "2023-09-16T00:40:54.604Z",
          "wordCount": 705,
          "title": "On a continuous time model of gradient descent dynamics and instability in deep learning. (arXiv:2302.01952v3 [stat.ML] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.09060",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gurbuz_Y/0/1/0/all/0/1\">Yeti Z. Gurbuz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Can_O/0/1/0/all/0/1\">Ogul Can</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alatan_A/0/1/0/all/0/1\">A. Aydin Alatan</a>",
          "description": "Deep metric learning (DML) aims to minimize empirical expected loss of the\npairwise intra-/inter- class proximity violations in the embedding space. We\nrelate DML to feasibility problem of finite chance constraints. We show that\nminimizer of proxy-based DML satisfies certain chance constraints, and that the\nworst case generalization performance of the proxy-based methods can be\ncharacterized by the radius of the smallest ball around a class proxy to cover\nthe entire domain of the corresponding class samples, suggesting multiple\nproxies per class helps performance. To provide a scalable algorithm as well as\nexploiting more proxies, we consider the chance constraints implied by the\nminimizers of proxy-based DML instances and reformulate DML as finding a\nfeasible point in intersection of such constraints, resulting in a problem to\nbe approximately solved by iterative projections. Simply put, we repeatedly\ntrain a regularized proxy-based loss and re-initialize the proxies with the\nembeddings of the deliberately selected new samples. We applied our method with\n4 well-accepted DML losses and show the effectiveness with extensive\nevaluations on 4 popular DML benchmarks. Code is available at:\nhttps://github.com/yetigurbuz/ccp-dml",
          "link": "http://arxiv.org/abs/2209.09060",
          "publishedOn": "2023-09-09T00:40:35.212Z",
          "wordCount": null,
          "title": "Deep Metric Learning with Chance Constraints. (arXiv:2209.09060v3 [cs.CV] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03770",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Delgado_D/0/1/0/all/0/1\">David Delgado</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Curbelo_E/0/1/0/all/0/1\">Ernesto Curbelo</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Carreras_D/0/1/0/all/0/1\">Danae Carreras</a>",
          "description": "In recent years, there is a growing interest in combining techniques\nattributed to the areas of Statistics and Machine Learning in order to obtain\nthe benefits of both approaches. In this article, the statistical technique\nlasso for variable selection is represented through a neural network. It is\nobserved that, although both the statistical approach and its neural version\nhave the same objective function, they differ due to their optimization. In\nparticular, the neural version is usually optimized in one-step using a single\nvalidation set, while the statistical counterpart uses a two-step optimization\nbased on cross-validation. The more elaborated optimization of the statistical\nmethod results in more accurate parameter estimation, especially when the\ntraining set is small. For this reason, a modification of the standard approach\nfor training neural networks, that mimics the statistical framework, is\nproposed. During the development of the above modification, a new optimization\nalgorithm for identifying the significant variables emerged. Experimental\nresults, using synthetic and real data sets, show that this new optimization\nalgorithm achieves better performance than any of the three previous\noptimization approaches.",
          "link": "http://arxiv.org/abs/2309.03770",
          "publishedOn": "2023-09-09T00:40:35.187Z",
          "wordCount": null,
          "title": "Neural lasso: a unifying approach of lasso and neural networks. (arXiv:2309.03770v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03748",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Foosherian_M/0/1/0/all/0/1\">Mina Foosherian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purwins_H/0/1/0/all/0/1\">Hendrik Purwins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rathnayake_P/0/1/0/all/0/1\">Purna Rathnayake</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alam_T/0/1/0/all/0/1\">Touhidul Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teimao_R/0/1/0/all/0/1\">Rui Teimao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thoben_K/0/1/0/all/0/1\">Klaus-Dieter Thoben</a>",
          "description": "The latest advancements in AI and deep learning have led to a breakthrough in\nlarge language model (LLM)-based agents such as GPT-4. However, many commercial\nconversational agent development tools are pipeline-based and have limitations\nin holding a human-like conversation. This paper investigates the capabilities\nof LLMs to enhance pipeline-based conversational agents during two phases: 1)\nin the design and development phase and 2) during operations. In 1) LLMs can\naid in generating training data, extracting entities and synonyms,\nlocalization, and persona design. In 2) LLMs can assist in contextualization,\nintent classification to prevent conversational breakdown and handle\nout-of-scope questions, auto-correcting utterances, rephrasing responses,\nformulating disambiguation questions, summarization, and enabling closed\nquestion-answering capabilities. We conducted informal experiments with GPT-4\nin the private banking domain to demonstrate the scenarios above with a\npractical example. Companies may be hesitant to replace their pipeline-based\nagents with LLMs entirely due to privacy concerns and the need for deep\nintegration within their existing ecosystems. A hybrid approach in which LLMs'\nare integrated into the pipeline-based agents allows them to save time and\ncosts of building and running agents by capitalizing on the capabilities of\nLLMs while retaining the integration and privacy safeguards of their existing\nsystems.",
          "link": "http://arxiv.org/abs/2309.03748",
          "publishedOn": "2023-09-09T00:40:35.135Z",
          "wordCount": null,
          "title": "Enhancing Pipeline-Based Conversational Agents with Large Language Models. (arXiv:2309.03748v1 [cs.CL])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2202.09671",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zheng_H/0/1/0/all/0/1\">Huangjie Zheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+He_P/0/1/0/all/0/1\">Pengcheng He</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhou_M/0/1/0/all/0/1\">Mingyuan Zhou</a>",
          "description": "Employing a forward diffusion chain to gradually map the data to a noise\ndistribution, diffusion-based generative models learn how to generate the data\nby inferring a reverse diffusion chain. However, this approach is slow and\ncostly because it needs many forward and reverse steps. We propose a faster and\ncheaper approach that adds noise not until the data become pure random noise,\nbut until they reach a hidden noisy data distribution that we can confidently\nlearn. Then, we use fewer reverse steps to generate data by starting from this\nhidden distribution that is made similar to the noisy data. We reveal that the\nproposed model can be cast as an adversarial auto-encoder empowered by both the\ndiffusion process and a learnable implicit prior. Experimental results show\neven with a significantly smaller number of reverse diffusion steps, the\nproposed truncated diffusion probabilistic models can provide consistent\nimprovements over the non-truncated ones in terms of performance in both\nunconditional and text-guided image generations.",
          "link": "http://arxiv.org/abs/2202.09671",
          "publishedOn": "2023-09-09T00:40:35.086Z",
          "wordCount": null,
          "title": "Truncated Diffusion Probabilistic Models and Diffusion-based Adversarial Auto-Encoders. (arXiv:2202.09671v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.08081",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mougan_C/0/1/0/all/0/1\">Carlos Mougan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Broelemann_K/0/1/0/all/0/1\">Klaus Broelemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masip_D/0/1/0/all/0/1\">David Masip</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasneci_G/0/1/0/all/0/1\">Gjergji Kasneci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thiropanis_T/0/1/0/all/0/1\">Thanassis Thiropanis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staab_S/0/1/0/all/0/1\">Steffen Staab</a>",
          "description": "As input data distributions evolve, the predictive performance of machine\nlearning models tends to deteriorate. In practice, new input data tend to come\nwithout target labels. Then, state-of-the-art techniques model input data\ndistributions or model prediction distributions and try to understand issues\nregarding the interactions between learned models and shifting distributions.\nWe suggest a novel approach that models how explanation characteristics shift\nwhen affected by distribution shifts. We find that the modeling of explanation\nshifts can be a better indicator for detecting out-of-distribution model\nbehaviour than state-of-the-art techniques. We analyze different types of\ndistribution shifts using synthetic examples and real-world data sets. We\nprovide an algorithmic method that allows us to inspect the interaction between\ndata set features and learned models and compare them to the state-of-the-art.\nWe release our methods in an open-source Python package, as well as the code\nused to reproduce our experiments.",
          "link": "http://arxiv.org/abs/2303.08081",
          "publishedOn": "2023-09-09T00:40:35.086Z",
          "wordCount": null,
          "title": "Explanation Shift: How Did the Distribution Shift Impact the Model?. (arXiv:2303.08081v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2110.00115",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Choe_Y/0/1/0/all/0/1\">Yo Joong Choe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ramdas_A/0/1/0/all/0/1\">Aaditya Ramdas</a>",
          "description": "Consider two forecasters, each making a single prediction for a sequence of\nevents over time. We ask a relatively basic question: how might we compare\nthese forecasters, either online or post-hoc, while avoiding unverifiable\nassumptions on how the forecasts and outcomes were generated? In this paper, we\npresent a rigorous answer to this question by designing novel sequential\ninference procedures for estimating the time-varying difference in forecast\nscores. To do this, we employ confidence sequences (CS), which are sequences of\nconfidence intervals that can be continuously monitored and are valid at\narbitrary data-dependent stopping times (\"anytime-valid\"). The widths of our\nCSs are adaptive to the underlying variance of the score differences.\nUnderlying their construction is a game-theoretic statistical framework, in\nwhich we further identify e-processes and p-processes for sequentially testing\na weak null hypothesis -- whether one forecaster outperforms another on average\n(rather than always). Our methods do not make distributional assumptions on the\nforecasts or outcomes; our main theorems apply to any bounded scores, and we\nlater provide alternative methods for unbounded scores. We empirically validate\nour approaches by comparing real-world baseball and weather forecasters.",
          "link": "http://arxiv.org/abs/2110.00115",
          "publishedOn": "2023-09-09T00:40:35.063Z",
          "wordCount": null,
          "title": "Comparing Sequential Forecasters. (arXiv:2110.00115v5 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03808",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhong_Z/0/1/0/all/0/1\">Ziliang Samuel Zhong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ling_S/0/1/0/all/0/1\">Shuyang Ling</a>",
          "description": "Given pairwise comparisons between multiple items, how to rank them so that\nthe ranking matches the observations? This problem, known as rank aggregation,\nhas found many applications in sports, recommendation systems, and other web\napplications. As it is generally NP-hard to find a global ranking that\nminimizes the mismatch (known as the Kemeny optimization), we focus on the\nErd\\\"os-R\\'enyi outliers (ERO) model for this ranking problem. Here, each\npairwise comparison is a corrupted copy of the true score difference. We\ninvestigate spectral ranking algorithms that are based on unnormalized and\nnormalized data matrices. The key is to understand their performance in\nrecovering the underlying scores of each item from the observed data. This\nreduces to deriving an entry-wise perturbation error bound between the top\neigenvectors of the unnormalized/normalized data matrix and its population\ncounterpart. By using the leave-one-out technique, we provide a sharper\n$\\ell_{\\infty}$-norm perturbation bound of the eigenvectors and also derive an\nerror bound on the maximum displacement for each item, with only $\\Omega(n\\log\nn)$ samples. Our theoretical analysis improves upon the state-of-the-art\nresults in terms of sample complexity, and our numerical experiments confirm\nthese theoretical findings.",
          "link": "http://arxiv.org/abs/2309.03808",
          "publishedOn": "2023-09-09T00:40:35.054Z",
          "wordCount": null,
          "title": "Improved theoretical guarantee for rank aggregation via spectral method. (arXiv:2309.03808v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2103.12591",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pakbin_A/0/1/0/all/0/1\">Arash Pakbin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaochen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mortazavi_B/0/1/0/all/0/1\">Bobak J. Mortazavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Donald K.K. Lee</a>",
          "description": "Modern applications of survival analysis increasingly involve time-dependent\ncovariates. The Python package BoXHED2.0 is a tree-boosted hazard estimator\nthat is fully nonparametric, and is applicable to survival settings far more\ngeneral than right-censoring, including recurring events and competing risks.\nBoXHED2.0 is also scalable to the point of being on the same order of speed as\nparametric boosted survival models, in part because its core is written in C++\nand it also supports the use of GPUs and multicore CPUs. BoXHED2.0 is available\nfrom PyPI and also from www.github.com/BoXHED.",
          "link": "http://arxiv.org/abs/2103.12591",
          "publishedOn": "2023-09-09T00:40:35.054Z",
          "wordCount": null,
          "title": "BoXHED2.0: Scalable boosting of dynamic survival analysis. (arXiv:2103.12591v5 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03354",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wu_M/0/1/0/all/0/1\">Mingqi Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sun_Q/0/1/0/all/0/1\">Qiang Sun</a>",
          "description": "Interpolators are unstable. For example, the mininum $\\ell_2$ norm least\nsquare interpolator exhibits unbounded test errors when dealing with noisy\ndata. In this paper, we study how ensemble stabilizes and thus improves the\ngeneralization performance, measured by the out-of-sample prediction risk, of\nan individual interpolator. We focus on bagged linear interpolators, as bagging\nis a popular randomization-based ensemble method that can be implemented in\nparallel. We introduce the multiplier-bootstrap-based bagged least square\nestimator, which can then be formulated as an average of the sketched least\nsquare estimators. The proposed multiplier bootstrap encompasses the classical\nbootstrap with replacement as a special case, along with a more intriguing\nvariant which we call the Bernoulli bootstrap.\n\nFocusing on the proportional regime where the sample size scales\nproportionally with the feature dimensionality, we investigate the\nout-of-sample prediction risks of the sketched and bagged least square\nestimators in both underparametrized and overparameterized regimes. Our results\nreveal the statistical roles of sketching and bagging. In particular, sketching\nmodifies the aspect ratio and shifts the interpolation threshold of the minimum\n$\\ell_2$ norm estimator. However, the risk of the sketched estimator continues\nto be unbounded around the interpolation threshold due to excessive variance.\nIn stark contrast, bagging effectively mitigates this variance, leading to a\nbounded limiting out-of-sample prediction risk. To further understand this\nstability improvement property, we establish that bagging acts as a form of\nimplicit regularization, substantiated by the equivalence of the bagged\nestimator with its explicitly regularized counterpart. We also discuss several\nextensions.",
          "link": "http://arxiv.org/abs/2309.03354",
          "publishedOn": "2023-09-09T00:40:35.053Z",
          "wordCount": null,
          "title": "Ensemble linear interpolators: The role of ensembling. (arXiv:2309.03354v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2002.01444",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Zhou_Q/0/1/0/all/0/1\">Quan Zhou</a>, <a href=\"http://arxiv.org/find/math/1/au:+Marecek_J/0/1/0/all/0/1\">Jakub Marecek</a>",
          "description": "There has been much recent progress in forecasting the next observation of a\nlinear dynamical system (LDS), which is known as the improper learning, as well\nas in the estimation of its system matrices, which is known as the proper\nlearning of LDS. We present an approach to proper learning of LDS, which in\nspite of the non-convexity of the problem, guarantees global convergence of\nnumerical solutions to a least-squares estimator. We present promising\ncomputational results.",
          "link": "http://arxiv.org/abs/2002.01444",
          "publishedOn": "2023-09-09T00:40:35.052Z",
          "wordCount": null,
          "title": "Proper Learning of Linear Dynamical Systems as a Non-Commutative Polynomial Optimisation Problem. (arXiv:2002.01444v5 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2106.02613",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Piche_A/0/1/0/all/0/1\">Alexandre Pich&#xe9;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Thomas_V/0/1/0/all/0/1\">Valentin Thomas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pardinas_R/0/1/0/all/0/1\">Rafael Pardinas</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Marino_J/0/1/0/all/0/1\">Joseph Marino</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Marconi_G/0/1/0/all/0/1\">Gian Maria Marconi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pal_C/0/1/0/all/0/1\">Christopher Pal</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Khan_M/0/1/0/all/0/1\">Mohammad Emtiyaz Khan</a>",
          "description": "Bootstrapping is behind much of the successes of deep Reinforcement Learning.\nHowever, learning the value function via bootstrapping often leads to unstable\ntraining due to fast-changing target values. Target Networks are employed to\nstabilize training by using an additional set of lagging parameters to estimate\nthe target values. Despite the popularity of Target Networks, their effect on\nthe optimization is still misunderstood. In this work, we show that they act as\nan implicit regularizer which can be beneficial in some cases, but also have\ndisadvantages such as being inflexible and can result in instabilities, even\nwhen vanilla TD(0) converges. To overcome these issues, we propose an explicit\nFunctional Regularization alternative that is flexible and a convex regularizer\nin function space and we theoretically study its convergence. We conduct an\nexperimental study across a range of environments, discount factors, and\noff-policiness data collections to investigate the effectiveness of the\nregularization induced by Target Networks and Functional Regularization in\nterms of performance, accuracy, and stability. Our findings emphasize that\nFunctional Regularization can be used as a drop-in replacement for Target\nNetworks and result in performance improvement. Furthermore, adjusting both the\nregularization weight and the network update period in Functional\nRegularization can result in further performance improvements compared to\nsolely adjusting the network update period as typically done with Target\nNetworks. Our approach also enhances the ability to networks to recover\naccurate $Q$-values.",
          "link": "http://arxiv.org/abs/2106.02613",
          "publishedOn": "2023-09-09T00:40:35.049Z",
          "wordCount": null,
          "title": "Bridging the Gap Between Target Networks and Functional Regularization. (arXiv:2106.02613v4 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03707",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Morales_K/0/1/0/all/0/1\">Katherine Morales</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Petetin_Y/0/1/0/all/0/1\">Yohan Petetin</a>",
          "description": "Triplet Markov chains are general generative models for sequential data which\ntake into account three kinds of random variables: (noisy) observations, their\nassociated discrete labels and latent variables which aim at strengthening the\ndistribution of the observations and their associated labels. However, in\npractice, we do not have at our disposal all the labels associated to the\nobservations to estimate the parameters of such models. In this paper, we\npropose a general framework based on a variational Bayesian inference to train\nparameterized triplet Markov chain models in a semi-supervised context. The\ngenerality of our approach enables us to derive semi-supervised algorithms for\na variety of generative models for sequential Bayesian classification.",
          "link": "http://arxiv.org/abs/2309.03707",
          "publishedOn": "2023-09-09T00:40:35.048Z",
          "wordCount": null,
          "title": "A Probabilistic Semi-Supervised Approach with Triplet Markov Chains. (arXiv:2309.03707v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.08901",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Piccialli_V/0/1/0/all/0/1\">Veronica Piccialli</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sudoso_A/0/1/0/all/0/1\">Antonio M. Sudoso</a>",
          "description": "The minimum sum-of-squares clustering (MSSC), or k-means type clustering, has\nbeen recently extended to exploit prior knowledge on the cardinality of each\ncluster. Such knowledge is used to increase performance as well as solution\nquality. In this paper, we propose a global optimization approach based on the\nbranch-and-cut technique to solve the cardinality-constrained MSSC. For the\nlower bound routine, we use the semidefinite programming (SDP) relaxation\nrecently proposed by Rujeerapaiboon et al. [SIAM J. Optim. 29(2), 1211-1239,\n(2019)]. However, this relaxation can be used in a branch-and-cut method only\nfor small-size instances. Therefore, we derive a new SDP relaxation that scales\nbetter with the instance size and the number of clusters. In both cases, we\nstrengthen the bound by adding polyhedral cuts. Benefiting from a tailored\nbranching strategy which enforces pairwise constraints, we reduce the\ncomplexity of the problems arising in the children nodes. For the upper bound,\ninstead, we present a local search procedure that exploits the solution of the\nSDP relaxation solved at each node. Computational results show that the\nproposed algorithm globally solves, for the first time, real-world instances of\nsize 10 times larger than those solved by state-of-the-art exact methods.",
          "link": "http://arxiv.org/abs/2209.08901",
          "publishedOn": "2023-09-09T00:40:35.044Z",
          "wordCount": null,
          "title": "Global Optimization for Cardinality-constrained Minimum Sum-of-Squares Clustering via Semidefinite Programming. (arXiv:2209.08901v3 [math.OC] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03818",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Fang_G/0/1/0/all/0/1\">Guanhua Fang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_P/0/1/0/all/0/1\">Ping Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Samorodnitsky_G/0/1/0/all/0/1\">Gennady Samorodnitsky</a>",
          "description": "This paper considers an empirical risk minimization problem under\nheavy-tailed settings, where data does not have finite variance, but only has\n$p$-th moment with $p \\in (1,2)$. Instead of using estimation procedure based\non truncated observed data, we choose the optimizer by minimizing the risk\nvalue. Those risk values can be robustly estimated via using the remarkable\nCatoni's method (Catoni, 2012). Thanks to the structure of Catoni-type\ninfluence functions, we are able to establish excess risk upper bounds via\nusing generalized generic chaining methods. Moreover, we take computational\nissues into consideration. We especially theoretically investigate two types of\noptimization methods, robust gradient descent algorithm and empirical\nrisk-based methods. With an extensive numerical study, we find that the\noptimizer based on empirical risks via Catoni-style estimation indeed shows\nbetter performance than other baselines. It indicates that estimation directly\nbased on truncated data may lead to unsatisfactory results.",
          "link": "http://arxiv.org/abs/2309.03818",
          "publishedOn": "2023-09-09T00:40:35.022Z",
          "wordCount": null,
          "title": "Empirical Risk Minimization for Losses without Variance. (arXiv:2309.03818v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03842",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Feng_L/0/1/0/all/0/1\">Lingyu Feng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gao_T/0/1/0/all/0/1\">Ting Gao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xiao_W/0/1/0/all/0/1\">Wang Xiao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Duan_J/0/1/0/all/0/1\">Jinqiao Duan</a>",
          "description": "Early warnings for dynamical transitions in complex systems or\nhigh-dimensional observation data are essential in many real world\napplications, such as gene mutation, brain diseases, natural disasters,\nfinancial crises, and engineering reliability. To effectively extract early\nwarning signals, we develop a novel approach: the directed anisotropic\ndiffusion map that captures the latent evolutionary dynamics in low-dimensional\nmanifold. Applying the methodology to authentic electroencephalogram (EEG)\ndata, we successfully find the appropriate effective coordinates, and derive\nearly warning signals capable of detecting the tipping point during the state\ntransition. Our method bridges the latent dynamics with the original dataset.\nThe framework is validated to be accurate and effective through numerical\nexperiments, in terms of density and transition probability. It is shown that\nthe second coordinate holds meaningful information for critical transition in\nvarious evaluation metrics.",
          "link": "http://arxiv.org/abs/2309.03842",
          "publishedOn": "2023-09-09T00:40:35.022Z",
          "wordCount": null,
          "title": "Early warning via transitions in latent stochastic dynamical systems. (arXiv:2309.03842v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2205.04151",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Feng_L/0/1/0/all/0/1\">Lingyu Feng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gao_T/0/1/0/all/0/1\">Ting Gao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dai_M/0/1/0/all/0/1\">Min Dai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Duan_J/0/1/0/all/0/1\">Jinqiao Duan</a>",
          "description": "Multiscale stochastic dynamical systems have been widely adopted to\nscientific and engineering problems due to their capability of depicting\ncomplex phenomena in many real world applications. This work is devoted to\ninvestigating the effective reduced dynamics for a slow-fast stochastic\ndynamical system. Given observation data on a short-term period satisfying some\nunknown slow-fast stochastic system, we propose a novel algorithm including a\nneural network called Auto-SDE to learn invariant slow manifold. Our approach\ncaptures the evolutionary nature of a series of time-dependent autoencoder\nneural networks with the loss constructed from a discretized stochastic\ndifferential equation. Our algorithm is also proved to be accurate, stable and\neffective through numerical experiments under various evaluation metrics.",
          "link": "http://arxiv.org/abs/2205.04151",
          "publishedOn": "2023-09-09T00:40:34.791Z",
          "wordCount": null,
          "title": "Auto-SDE: Learning effective reduced dynamics from data-driven stochastic dynamical systems. (arXiv:2205.04151v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2307.06555",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shijun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jianfeng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hongkai Zhao</a>",
          "description": "This paper explores the expressive power of deep neural networks for a\ndiverse range of activation functions. An activation function set $\\mathscr{A}$\nis defined to encompass the majority of commonly used activation functions,\nsuch as $\\mathtt{ReLU}$, $\\mathtt{LeakyReLU}$, $\\mathtt{ReLU}^2$,\n$\\mathtt{ELU}$, $\\mathtt{SELU}$, $\\mathtt{Softplus}$, $\\mathtt{GELU}$,\n$\\mathtt{SiLU}$, $\\mathtt{Swish}$, $\\mathtt{Mish}$, $\\mathtt{Sigmoid}$,\n$\\mathtt{Tanh}$, $\\mathtt{Arctan}$, $\\mathtt{Softsign}$, $\\mathtt{dSiLU}$, and\n$\\mathtt{SRS}$. We demonstrate that for any activation function $\\varrho\\in\n\\mathscr{A}$, a $\\mathtt{ReLU}$ network of width $N$ and depth $L$ can be\napproximated to arbitrary precision by a $\\varrho$-activated network of width\n$4N$ and depth $2L$ on any bounded set. This finding enables the extension of\nmost approximation results achieved with $\\mathtt{ReLU}$ networks to a wide\nvariety of other activation functions, at the cost of slightly larger\nconstants.",
          "link": "http://arxiv.org/abs/2307.06555",
          "publishedOn": "2023-09-09T00:40:34.773Z",
          "wordCount": null,
          "title": "Deep Network Approximation: Beyond ReLU to Diverse Activation Functions. (arXiv:2307.06555v3 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03847",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Afzali_M/0/1/0/all/0/1\">Mohammad Afzali</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ashtiani_H/0/1/0/all/0/1\">Hassan Ashtiani</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liaw_C/0/1/0/all/0/1\">Christopher Liaw</a>",
          "description": "We study the problem of estimating mixtures of Gaussians under the constraint\nof differential privacy (DP). Our main result is that $\\tilde{O}(k^2 d^4\n\\log(1/\\delta) / \\alpha^2 \\varepsilon)$ samples are sufficient to estimate a\nmixture of $k$ Gaussians up to total variation distance $\\alpha$ while\nsatisfying $(\\varepsilon, \\delta)$-DP. This is the first finite sample\ncomplexity upper bound for the problem that does not make any structural\nassumptions on the GMMs.\n\nTo solve the problem, we devise a new framework which may be useful for other\ntasks. On a high level, we show that if a class of distributions (such as\nGaussians) is (1) list decodable and (2) admits a \"locally small'' cover\n[BKSW19] with respect to total variation distance, then the class of its\nmixtures is privately learnable. The proof circumvents a known barrier\nindicating that, unlike Gaussians, GMMs do not admit a locally small cover\n[AAL21].",
          "link": "http://arxiv.org/abs/2309.03847",
          "publishedOn": "2023-09-09T00:40:34.692Z",
          "wordCount": null,
          "title": "Mixtures of Gaussians are Privately Learnable with a Polynomial Number of Samples. (arXiv:2309.03847v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03873",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ziemann_I/0/1/0/all/0/1\">Ingvar Ziemann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tsiamis_A/0/1/0/all/0/1\">Anastasios Tsiamis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_B/0/1/0/all/0/1\">Bruce Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jedra_Y/0/1/0/all/0/1\">Yassir Jedra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Matni_N/0/1/0/all/0/1\">Nikolai Matni</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pappas_G/0/1/0/all/0/1\">George J. Pappas</a>",
          "description": "This tutorial serves as an introduction to recently developed non-asymptotic\nmethods in the theory of -- mainly linear -- system identification. We\nemphasize tools we deem particularly useful for a range of problems in this\ndomain, such as the covering technique, the Hanson-Wright Inequality and the\nmethod of self-normalized martingales. We then employ these tools to give\nstreamlined proofs of the performance of various least-squares based estimators\nfor identifying the parameters in autoregressive models. We conclude by\nsketching out how the ideas presented herein can be extended to certain\nnonlinear identification problems.",
          "link": "http://arxiv.org/abs/2309.03873",
          "publishedOn": "2023-09-09T00:40:34.680Z",
          "wordCount": null,
          "title": "A Tutorial on the Non-Asymptotic Theory of System Identification. (arXiv:2309.03873v1 [eess.SY])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03843",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Mousavi_Hosseini_A/0/1/0/all/0/1\">Alireza Mousavi-Hosseini</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wu_D/0/1/0/all/0/1\">Denny Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1\">Taiji Suzuki</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Erdogdu_M/0/1/0/all/0/1\">Murat A. Erdogdu</a>",
          "description": "Recent works have demonstrated that the sample complexity of gradient-based\nlearning of single index models, i.e. functions that depend on a 1-dimensional\nprojection of the input data, is governed by their information exponent.\nHowever, these results are only concerned with isotropic data, while in\npractice the input often contains additional structure which can implicitly\nguide the algorithm. In this work, we investigate the effect of a spiked\ncovariance structure and reveal several interesting phenomena. First, we show\nthat in the anisotropic setting, the commonly used spherical gradient dynamics\nmay fail to recover the true direction, even when the spike is perfectly\naligned with the target direction. Next, we show that appropriate weight\nnormalization that is reminiscent of batch normalization can alleviate this\nissue. Further, by exploiting the alignment between the (spiked) input\ncovariance and the target, we obtain improved sample complexity compared to the\nisotropic case. In particular, under the spiked model with a suitably large\nspike, the sample complexity of gradient-based training can be made independent\nof the information exponent while also outperforming lower bounds for\nrotationally invariant kernel methods.",
          "link": "http://arxiv.org/abs/2309.03843",
          "publishedOn": "2023-09-09T00:40:34.612Z",
          "wordCount": null,
          "title": "Gradient-Based Feature Learning under Structured Data. (arXiv:2309.03843v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.02843",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gorgun_A/0/1/0/all/0/1\">Ada Gorgun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurbuz_Y/0/1/0/all/0/1\">Yeti Z. Gurbuz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alatan_A/0/1/0/all/0/1\">A. Aydin Alatan</a>",
          "description": "Typical technique in knowledge distillation (KD) is regularizing the learning\nof a limited capacity model (student) by pushing its responses to match a\npowerful model's (teacher). Albeit useful especially in the penultimate layer\nand beyond, its action on student's feature transform is rather implicit,\nlimiting its practice in the intermediate layers. To explicitly embed the\nteacher's knowledge in feature transform, we propose a learnable KD layer for\nthe student which improves KD with two distinct abilities: i) learning how to\nleverage the teacher's knowledge, enabling to discard nuisance information, and\nii) feeding forward the transferred knowledge deeper. Thus, the student enjoys\nthe teacher's knowledge during the inference besides training. Formally, we\nrepurpose 1x1-BN-ReLU-1x1 convolution block to assign a semantic vector to each\nlocal region according to the template (supervised by the teacher) that the\ncorresponding region of the student matches. To facilitate template learning in\nthe intermediate layers, we propose a novel form of supervision based on the\nteacher's decisions. Through rigorous experimentation, we demonstrate the\neffectiveness of our approach on 3 popular classification benchmarks. Code is\navailable at: https://github.com/adagorgun/letKD-framework",
          "link": "http://arxiv.org/abs/2309.02843",
          "publishedOn": "2023-09-09T00:40:34.528Z",
          "wordCount": null,
          "title": "Knowledge Distillation Layer that Lets the Student Decide. (arXiv:2309.02843v1 [cs.CV] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03561",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zakrisson_H/0/1/0/all/0/1\">Henning Zakrisson</a>",
          "description": "This paper introduces the Trinary decision tree, an algorithm designed to\nimprove the handling of missing data in decision tree regressors and\nclassifiers. Unlike other approaches, the Trinary decision tree does not assume\nthat missing values contain any information about the response. Both\ntheoretical calculations on estimator bias and numerical illustrations using\nreal data sets are presented to compare its performance with established\nalgorithms in different missing data scenarios (Missing Completely at Random\n(MCAR), and Informative Missingness (IM)). Notably, the Trinary tree\noutperforms its peers in MCAR settings, especially when data is only missing\nout-of-sample, while lacking behind in IM settings. A hybrid model, the\nTrinaryMIA tree, which combines the Trinary tree and the Missing In Attributes\n(MIA) approach, shows robust performance in all types of missingness. Despite\nthe potential drawback of slower training speed, the Trinary tree offers a\npromising and more accurate method of handling missing data in decision tree\nalgorithms.",
          "link": "http://arxiv.org/abs/2309.03561",
          "publishedOn": "2023-09-09T00:40:34.375Z",
          "wordCount": null,
          "title": "Trinary Decision Trees for missing value handling. (arXiv:2309.03561v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/1907.04483",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Freedman_R/0/1/0/all/0/1\">Roy S. Freedman</a>",
          "description": "The exclusive or (xor) function is one of the simplest examples that\nillustrate why nonlinear feedforward networks are superior to linear regression\nfor machine learning applications. We review the xor representation and\napproximation problems and discuss their solutions in terms of probabilistic\nlogic and associative copula functions. After briefly reviewing the\nspecification of feedforward networks, we compare the dynamics of learned error\nsurfaces with different activation functions such as RELU and tanh through a\nset of colorful three-dimensional charts. The copula representations extend xor\nfrom Boolean to real values, thereby providing a convenient way to demonstrate\nthe concept of cross-validation on in-sample and out-sample data sets. Our\napproach is pedagogical and is meant to be a machine learning prolegomenon.",
          "link": "http://arxiv.org/abs/1907.04483",
          "publishedOn": "2023-09-09T00:40:34.363Z",
          "wordCount": null,
          "title": "Copula Representations and Error Surface Projections for the Exclusive Or Problem. (arXiv:1907.04483v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.01605",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Doutreligne_M/0/1/0/all/0/1\">Matthieu Doutreligne</a> (SODA), <a href=\"http://arxiv.org/find/stat/1/au:+Struja_T/0/1/0/all/0/1\">Tristan Struja</a> (MIT, USZ), <a href=\"http://arxiv.org/find/stat/1/au:+Abecassis_J/0/1/0/all/0/1\">Judith Abecassis</a> (SODA), <a href=\"http://arxiv.org/find/stat/1/au:+Morgand_C/0/1/0/all/0/1\">Claire Morgand</a> (ARS IDF), <a href=\"http://arxiv.org/find/stat/1/au:+Celi_L/0/1/0/all/0/1\">Leo Anthony Celi</a> (MIT), <a href=\"http://arxiv.org/find/stat/1/au:+Varoquaux_G/0/1/0/all/0/1\">Ga&#xeb;l Varoquaux</a> (SODA)",
          "description": "Accurate predictions, as with machine learning, may not suffice to provide\noptimal healthcare for every patient. Indeed, prediction can be driven by\nshortcuts in the data, such as racial biases. Causal thinking is needed for\ndata-driven decisions. Here, we give an introduction to the key elements,\nfocusing on routinely-collected data, electronic health records (EHRs) and\nclaims data. Using such data to assess the value of an intervention requires\ncare: temporal dependencies and existing practices easily confound the causal\neffect. We present a step-by-step framework to help build valid decision making\nfrom real-life patient records by emulating a randomized trial before\nindividualizing decisions, eg with machine learning. Our framework highlights\nthe most important pitfalls and considerations in analysing EHRs or claims data\nto draw causal conclusions. We illustrate the various choices in studying the\neffect of albumin on sepsis mortality in the Medical Information Mart for\nIntensive Care database (MIMIC-IV). We study the impact of various choices at\nevery step, from feature extraction to causal-estimator selection. In a\ntutorial spirit, the code and the data are openly available.",
          "link": "http://arxiv.org/abs/2308.01605",
          "publishedOn": "2023-09-09T00:40:34.315Z",
          "wordCount": null,
          "title": "Causal thinking for decision making on Electronic Health Records: why and how. (arXiv:2308.01605v3 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03800",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Edelman_B/0/1/0/all/0/1\">Benjamin L. Edelman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1\">Surbhi Goel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1\">Sham Kakade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malach_E/0/1/0/all/0/1\">Eran Malach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Cyril Zhang</a>",
          "description": "This work investigates the nuanced algorithm design choices for deep learning\nin the presence of computational-statistical gaps. We begin by considering\noffline sparse parity learning, a supervised classification problem which\nadmits a statistical query lower bound for gradient-based training of a\nmultilayer perceptron. This lower bound can be interpreted as a multi-resource\ntradeoff frontier: successful learning can only occur if one is sufficiently\nrich (large model), knowledgeable (large dataset), patient (many training\niterations), or lucky (many random guesses). We show, theoretically and\nexperimentally, that sparse initialization and increasing network width yield\nsignificant improvements in sample efficiency in this setting. Here, width\nplays the role of parallel search: it amplifies the probability of finding\n\"lottery ticket\" neurons, which learn sparse features more sample-efficiently.\nFinally, we show that the synthetic sparse parity task can be useful as a proxy\nfor real problems requiring axis-aligned feature learning. We demonstrate\nimproved sample efficiency on tabular classification benchmarks by using wide,\nsparsely-initialized MLP models; these networks sometimes outperform tuned\nrandom forests.",
          "link": "http://arxiv.org/abs/2309.03800",
          "publishedOn": "2023-09-09T00:40:34.209Z",
          "wordCount": null,
          "title": "Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and Luck. (arXiv:2309.03800v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03751",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lenssen_L/0/1/0/all/0/1\">Lars Lenssen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schubert_E/0/1/0/all/0/1\">Erich Schubert</a>",
          "description": "The evaluation of clustering results is difficult, highly dependent on the\nevaluated data set and the perspective of the beholder. There are many\ndifferent clustering quality measures, which try to provide a general measure\nto validate clustering results. A very popular measure is the Silhouette. We\ndiscuss the efficient medoid-based variant of the Silhouette, perform a\ntheoretical analysis of its properties, provide two fast versions for the\ndirect optimization, and discuss the use to choose the optimal number of\nclusters. We combine ideas from the original Silhouette with the well-known PAM\nalgorithm and its latest improvements FasterPAM. One of the versions guarantees\nequal results to the original variant and provides a run speedup of $O(k^2)$.\nIn experiments on real data with 30000 samples and $k$=100, we observed a\n10464$\\times$ speedup compared to the original PAMMEDSIL algorithm.\nAdditionally, we provide a variant to choose the optimal number of clusters\ndirectly.",
          "link": "http://arxiv.org/abs/2309.03751",
          "publishedOn": "2023-09-09T00:40:34.189Z",
          "wordCount": null,
          "title": "Medoid Silhouette clustering with automatic cluster number selection. (arXiv:2309.03751v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03791",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Birrell_J/0/1/0/all/0/1\">Jeremiah Birrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ebrahimi_M/0/1/0/all/0/1\">Mohammadreza Ebrahimi</a>",
          "description": "We introduce the $ARMOR_D$ methods as novel approaches to enhancing the\nadversarial robustness of deep learning models. These methods are based on a\nnew class of optimal-transport-regularized divergences, constructed via an\ninfimal convolution between an information divergence and an optimal-transport\n(OT) cost. We use these as tools to enhance adversarial robustness by\nmaximizing the expected loss over a neighborhood of distributions, a technique\nknown as distributionally robust optimization. Viewed as a tool for\nconstructing adversarial samples, our method allows samples to be both\ntransported, according to the OT cost, and re-weighted, according to the\ninformation divergence. We demonstrate the effectiveness of our method on\nmalware detection and image recognition applications and find that, to our\nknowledge, it outperforms existing methods at enhancing the robustness against\nadversarial attacks. $ARMOR_D$ yields the robustified accuracy of $98.29\\%$\nagainst $FGSM$ and $98.18\\%$ against $PGD^{40}$ on the MNIST dataset, reducing\nthe error rate by more than $19.7\\%$ and $37.2\\%$ respectively compared to\nprior methods. Similarly, in malware detection, a discrete (binary) data\ndomain, $ARMOR_D$ improves the robustified accuracy under $rFGSM^{50}$ attack\ncompared to the previous best-performing adversarial training methods by\n$37.0\\%$ while lowering false negative and false positive rates by $51.1\\%$ and\n$57.53\\%$, respectively.",
          "link": "http://arxiv.org/abs/2309.03791",
          "publishedOn": "2023-09-09T00:40:34.185Z",
          "wordCount": null,
          "title": "Adversarially Robust Deep Learning with Optimal-Transport-Regularized Divergences. (arXiv:2309.03791v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2309.03557",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Talebi_S/0/1/0/all/0/1\">Sayed Pouria Talebi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mandic_D/0/1/0/all/0/1\">Danilo Mandic</a>",
          "description": "Multiagent systems aim to accomplish highly complex learning tasks through\ndecentralised consensus seeking dynamics and their use has garnered a great\ndeal of attention in the signal processing and computational intelligence\nsocieties. This article examines the behaviour of multiagent networked systems\nwith nonlinear filtering/learning dynamics. To this end, a general formulation\nfor the actions of an agent in multiagent networked systems is presented and\nconditions for achieving a cohesive learning behaviour is given. Importantly,\napplication of the so derived framework in distributed and federated learning\nscenarios are presented.",
          "link": "http://arxiv.org/abs/2309.03557",
          "publishedOn": "2023-09-09T00:40:33.581Z",
          "wordCount": 592,
          "title": "On the dynamics of multi agent nonlinear filtering and learning. (arXiv:2309.03557v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2212.14424",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Xu_C/0/1/0/all/0/1\">Chen Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cheng_X/0/1/0/all/0/1\">Xiuyuan Cheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xie_Y/0/1/0/all/0/1\">Yao Xie</a>",
          "description": "Normalizing flow is a class of deep generative models for efficient sampling\nand density estimation. In practice, the flow often appears as a chain of\ninvertible neural network blocks; to facilitate training, existing works have\nregularized flow trajectories and designed special network architectures. The\ncurrent paper develops a neural ODE flow network inspired by the\nJordan-Kinderleherer-Otto (JKO) scheme, which allows efficient block-wise\ntraining of the residual blocks without sampling SDE trajectories or inner\nloops of score matching or variational learning. As the JKO scheme unfolds the\ndynamic of gradient flow, the proposed model naturally stacks residual network\nblocks one by one, reducing the memory load and difficulty in performing\nend-to-end deep flow network training. We also develop adaptive time\nreparameterization of the flow network with a progressive refinement of the\ntrajectory in probability space, which improves the model training efficiency\nand accuracy in practice. Using numerical experiments with synthetic and real\ndata, we show that the proposed JKO-iFlow model achieves similar or better\nperformance in generating new samples compared with the existing flow and\ndiffusion models at a significantly reduced computational and memory cost.",
          "link": "http://arxiv.org/abs/2212.14424",
          "publishedOn": "2023-09-02T00:40:02.167Z",
          "wordCount": null,
          "title": "Invertible normalizing flow neural networks by JKO scheme. (arXiv:2212.14424v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2112.08060",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hellermann_J/0/1/0/all/0/1\">Justin Hellermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lessmann_S/0/1/0/all/0/1\">Stefan Lessmann</a>",
          "description": "Generative models for images have gained significant attention in computer\nvision and natural language processing due to their ability to generate\nrealistic samples from complex data distributions. To leverage the advances of\nimage-based generative models for the time series domain, we propose a\ntwo-dimensional image representation for time series, the Extended\nIntertemporal Return Plot (XIRP). Our approach captures the intertemporal time\nseries dynamics in a scale-invariant and invertible way, reducing training time\nand improving sample quality. We benchmark synthetic XIRPs obtained by an\noff-the-shelf Wasserstein GAN with gradient penalty (WGAN-GP) to other image\nrepresentations and models regarding similarity and predictive ability metrics.\nOur novel, validated image representation for time series consistently and\nsignificantly outperforms a state-of-the-art RNN-based generative model\nregarding predictive ability. Further, we introduce an improved stochastic\ninversion to substantially improve simulation quality regardless of the\nrepresentation and provide the prospect of transfer potentials in other\ndomains.",
          "link": "http://arxiv.org/abs/2112.08060",
          "publishedOn": "2023-09-02T00:40:02.157Z",
          "wordCount": null,
          "title": "Leveraging Image-based Generative Adversarial Networks for Time Series Generation. (arXiv:2112.08060v2 [cs.LG] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16456",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1\">Shuai Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1\">Zhen Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shao_Y/0/1/0/all/0/1\">Yuan-Hai Shao</a>",
          "description": "In this paper, we propose a new way of remembering by introducing a memory\ninfluence mechanism for the least squares support vector machine (LSSVM).\nWithout changing the equation constraints of the original LSSVM, this\nmechanism, allows an accurate partitioning of the training set without\noverfitting. The maximum memory impact model (MIMM) and the weighted impact\nmemory model (WIMM) are then proposed. It is demonstrated that these models can\nbe degraded to the LSSVM. Furthermore, we propose some different memory impact\nfunctions for the MIMM and WIMM. The experimental results show that that our\nMIMM and WIMM have better generalization performance compared to the LSSVM and\nsignificant advantage in time cost compared to other memory models.",
          "link": "http://arxiv.org/abs/2308.16456",
          "publishedOn": "2023-09-02T00:40:02.154Z",
          "wordCount": null,
          "title": "Least Squares Maximum and Weighted Generalization-Memorization Machines. (arXiv:2308.16456v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16172",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Padilla_C/0/1/0/all/0/1\">Carlos Misael Madrid Padilla</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Padilla_O/0/1/0/all/0/1\">Oscar Hernan Madrid Padilla</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_D/0/1/0/all/0/1\">Daren Wang</a>",
          "description": "This research focuses on the estimation of a non-parametric regression\nfunction designed for data with simultaneous time and space dependencies. In\nsuch a context, we study the Trend Filtering, a nonparametric estimator\nintroduced by \\cite{mammen1997locally} and \\cite{rudin1992nonlinear}. For\nunivariate settings, the signals we consider are assumed to have a kth weak\nderivative with bounded total variation, allowing for a general degree of\nsmoothness. In the multivariate scenario, we study a $K$-Nearest Neighbor fused\nlasso estimator as in \\cite{padilla2018adaptive}, employing an ADMM algorithm,\nsuitable for signals with bounded variation that adhere to a piecewise\nLipschitz continuity criterion. By aligning with lower bounds, the minimax\noptimality of our estimators is validated. A unique phase transition\nphenomenon, previously uncharted in Trend Filtering studies, emerges through\nour analysis. Both Simulation studies and real data applications underscore the\nsuperior performance of our method when compared with established techniques in\nthe existing literature.",
          "link": "http://arxiv.org/abs/2308.16172",
          "publishedOn": "2023-09-02T00:40:02.153Z",
          "wordCount": null,
          "title": "Temporal-spatial model via Trend Filtering. (arXiv:2308.16172v2 [stat.ME] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2303.05102",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kawano_K/0/1/0/all/0/1\">Keisuke Kawano</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kutsuna_T/0/1/0/all/0/1\">Takuro Kutsuna</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tokuhisa_R/0/1/0/all/0/1\">Ryoko Tokuhisa</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nakamura_A/0/1/0/all/0/1\">Akihiro Nakamura</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Esaki_Y/0/1/0/all/0/1\">Yasushi Esaki</a>",
          "description": "One major challenge in machine learning applications is coping with\nmismatches between the datasets used in the development and those obtained in\nreal-world applications. These mismatches may lead to inaccurate predictions\nand errors, resulting in poor product quality and unreliable systems. In this\nstudy, we propose StyleDiff to inform developers of the differences between the\ntwo datasets for the steady development of machine learning systems. Using\ndisentangled image spaces obtained from recently proposed generative models,\nStyleDiff compares the two datasets by focusing on attributes in the images and\nprovides an easy-to-understand analysis of the differences between the\ndatasets. The proposed StyleDiff performs in $O (d N\\log N)$, where $N$ is the\nsize of the datasets and $d$ is the number of attributes, enabling the\napplication to large datasets. We demonstrate that StyleDiff accurately detects\ndifferences between datasets and presents them in an understandable format\nusing, for example, driving scenes datasets.",
          "link": "http://arxiv.org/abs/2303.05102",
          "publishedOn": "2023-09-02T00:40:02.148Z",
          "wordCount": null,
          "title": "StyleDiff: Attribute Comparison Between Unlabeled Datasets in Latent Disentangled Space. (arXiv:2303.05102v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.14388",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1\">Jiqiang Wang</a>",
          "description": "In this paper, we first reviewed several biclustering methods that are used\nto identify the most significant clusters in gene expression data. Here we\nmainly focused on the SSVD(sparse SVD) method and tried a new sparse penalty\nnamed \"Prenet penalty\" which has been used only in factor analysis to gain\nsparsity. Then in the simulation study, we tried different types of generated\ndatasets (with different sparsity and dimension) and tried 1-layer\napproximation then for k-layers which shows the mixed Prenet penalty is very\neffective for non-overlapped data. Finally, we used some real gene expression\ndata to show the behavior of our methods.",
          "link": "http://arxiv.org/abs/2308.14388",
          "publishedOn": "2023-09-02T00:40:02.148Z",
          "wordCount": null,
          "title": "Biclustering Methods via Sparse Penalty. (arXiv:2308.14388v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.15370",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Lee_T/0/1/0/all/0/1\">Taehee Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Liu_J/0/1/0/all/0/1\">Jun S. Liu</a>",
          "description": "Despite the widespread utilization of Gaussian process models for versatile\nnonparametric modeling, they exhibit limitations in effectively capturing\nabrupt changes in function smoothness and accommodating relationships with\nheteroscedastic errors. Addressing these shortcomings, the heteroscedastic\nGaussian process (HeGP) regression seeks to introduce flexibility by\nacknowledging the variability of residual variances across covariates in the\nregression model. In this work, we extend the HeGP concept, expanding its scope\nbeyond regression tasks to encompass classification and state-space models. To\nachieve this, we propose a novel framework where the Gaussian process is\ncoupled with a covariate-induced precision matrix process, adopting a mixture\nformulation. This approach enables the modeling of heteroscedastic covariance\nfunctions across covariates. To mitigate the computational challenges posed by\nsampling, we employ variational inference to approximate the posterior and\nfacilitate posterior predictive modeling. Additionally, our training process\nleverages an EM algorithm featuring closed-form M-step updates to efficiently\nevaluate the heteroscedastic covariance function. A notable feature of our\nmodel is its consistent performance on multivariate responses, accommodating\nvarious types (continuous or categorical) seamlessly. Through a combination of\nsimulations and real-world applications in climatology, we illustrate the\nmodel's prowess and advantages. By overcoming the limitations of traditional\nGaussian process models, our proposed framework offers a robust and versatile\ntool for a wide array of applications.",
          "link": "http://arxiv.org/abs/2308.15370",
          "publishedOn": "2023-09-02T00:40:02.147Z",
          "wordCount": null,
          "title": "Multi-Response Heteroscedastic Gaussian Process Models and Their Inference. (arXiv:2308.15370v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.16912",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Ren_B/0/1/0/all/0/1\">Bin B. Ren</a>",
          "description": "Detection and characterization of extended structures is a crucial goal in\nhigh contrast imaging. However, these structures face challenges in data\nreduction, leading to over-subtraction from speckles and self-subtraction with\nmost existing methods. Iterative post-processing methods offer promising\nresults, but their integration into existing pipelines is hindered by selective\nalgorithms, high computational cost, and algorithmic regularization. To address\nthis for reference differential imaging (RDI), here we propose the data\nimputation concept to Karhunen-Lo\\`eve transform (DIKL) by modifying two steps\nin the standard Karhunen-Lo\\`eve image projection (KLIP) method. Specifically,\nwe partition an image to two matrices: an anchor matrix which focuses only on\nthe speckles to obtain the DIKL coefficients, and a boat matrix which focuses\non the regions of astrophysical interest for speckle removal using DIKL\ncomponents. As an analytical approach, DIKL achieves high-quality results with\nsignificantly reduced computational cost (~3 orders of magnitude less than\niterative methods). Being a derivative method of KLIP, DIKL is seamlessly\nintegrable into high contrast imaging pipelines for RDI observations.",
          "link": "http://arxiv.org/abs/2308.16912",
          "publishedOn": "2023-09-02T00:40:01.902Z",
          "wordCount": 810,
          "title": "Karhunen-Lo\\`eve Data Imputation in High Contrast Imaging. (arXiv:2308.16912v1 [astro-ph.IM])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2104.03942",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Jarvenpaa_M/0/1/0/all/0/1\">Marko J&#xe4;rvenp&#xe4;&#xe4;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Corander_J/0/1/0/all/0/1\">Jukka Corander</a>",
          "description": "We present a framework for approximate Bayesian inference when only a limited\nnumber of noisy log-likelihood evaluations can be obtained due to computational\nconstraints, which is becoming increasingly common for applications of complex\nmodels. We model the log-likelihood function using a Gaussian process (GP) and\nthe main methodological innovation is to apply this model to emulate the\nprogression that an exact Metropolis-Hastings (MH) sampler would take if it was\napplicable. Informative log-likelihood evaluation locations are selected using\na sequential experimental design strategy until the MH accept/reject decision\nis done accurately enough according to the GP model. The resulting approximate\nsampler is conceptually simple and sample-efficient. It is also more robust to\nviolations of GP modelling assumptions compared with earlier, related \"Bayesian\noptimisation-like\" methods tailored for Bayesian inference. We discuss some\ntheoretical aspects and various interpretations of the resulting approximate MH\nsampler, and demonstrate its benefits in the context of Bayesian and\ngeneralised Bayesian likelihood-free inference for simulator-based statistical\nmodels.",
          "link": "http://arxiv.org/abs/2104.03942",
          "publishedOn": "2023-09-02T00:40:01.875Z",
          "wordCount": 712,
          "title": "Approximate Bayesian inference from noisy likelihoods with Gaussian process emulated MCMC. (arXiv:2104.03942v2 [stat.ME] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.16680",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kagan_M/0/1/0/all/0/1\">Michael Kagan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Heinrich_L/0/1/0/all/0/1\">Lukas Heinrich</a>",
          "description": "We propose to apply several gradient estimation techniques to enable the\ndifferentiation of programs with discrete randomness in High Energy Physics.\nSuch programs are common in High Energy Physics due to the presence of\nbranching processes and clustering-based analysis. Thus differentiating such\nprograms can open the way for gradient based optimization in the context of\ndetector design optimization, simulator tuning, or data analysis and\nreconstruction optimization. We discuss several possible gradient estimation\nstrategies, including the recent Stochastic AD method, and compare them in\nsimplified detector design experiments. In doing so we develop, to the best of\nour knowledge, the first fully differentiable branching program.",
          "link": "http://arxiv.org/abs/2308.16680",
          "publishedOn": "2023-09-02T00:40:01.863Z",
          "wordCount": 658,
          "title": "Branches of a Tree: Taking Derivatives of Programs with Discrete and Branching Randomness in High Energy Physics. (arXiv:2308.16680v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2302.07446",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yu-Zhen Janice Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuchuang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xutong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajiesmaili_M/0/1/0/all/0/1\">Mohammad Hajiesmaili</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lui_J/0/1/0/all/0/1\">John C.S. Lui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Towsley_D/0/1/0/all/0/1\">Don Towsley</a>",
          "description": "This paper studies a cooperative multi-agent multi-armed stochastic bandit\nproblem where agents operate asynchronously -- agent pull times and rates are\nunknown, irregular, and heterogeneous -- and face the same instance of a\nK-armed bandit problem. Agents can share reward information to speed up the\nlearning process at additional communication costs. We propose ODC, an\non-demand communication protocol that tailors the communication of each pair of\nagents based on their empirical pull times. ODC is efficient when the pull\ntimes of agents are highly heterogeneous, and its communication complexity\ndepends on the empirical pull times of agents. ODC is a generic protocol that\ncan be integrated into most cooperative bandit algorithms without degrading\ntheir performance. We then incorporate ODC into the natural extensions of UCB\nand AAE algorithms and propose two communication-efficient cooperative\nalgorithms. Our analysis shows that both algorithms are near-optimal in regret.",
          "link": "http://arxiv.org/abs/2302.07446",
          "publishedOn": "2023-09-02T00:40:01.857Z",
          "wordCount": 688,
          "title": "On-Demand Communication for Asynchronous Multi-Agent Bandits. (arXiv:2302.07446v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2304.14994",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Finzi_M/0/1/0/all/0/1\">Marc Finzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potapczynski_A/0/1/0/all/0/1\">Andres Potapczynski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choptuik_M/0/1/0/all/0/1\">Matthew Choptuik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1\">Andrew Gordon Wilson</a>",
          "description": "Unlike conventional grid and mesh based methods for solving partial\ndifferential equations (PDEs), neural networks have the potential to break the\ncurse of dimensionality, providing approximate solutions to problems where\nusing classical solvers is difficult or impossible. While global minimization\nof the PDE residual over the network parameters works well for boundary value\nproblems, catastrophic forgetting impairs the applicability of this approach to\ninitial value problems (IVPs). In an alternative local-in-time approach, the\noptimization problem can be converted into an ordinary differential equation\n(ODE) on the network parameters and the solution propagated forward in time;\nhowever, we demonstrate that current methods based on this approach suffer from\ntwo key issues. First, following the ODE produces an uncontrolled growth in the\nconditioning of the problem, ultimately leading to unacceptably large numerical\nerrors. Second, as the ODE methods scale cubically with the number of model\nparameters, they are restricted to small neural networks, significantly\nlimiting their ability to represent intricate PDE initial conditions and\nsolutions. Building on these insights, we develop Neural IVP, an ODE based IVP\nsolver which prevents the network from getting ill-conditioned and runs in time\nlinear in the number of parameters, enabling us to evolve the dynamics of\nchallenging PDEs with neural networks.",
          "link": "http://arxiv.org/abs/2304.14994",
          "publishedOn": "2023-09-02T00:40:01.851Z",
          "wordCount": 766,
          "title": "A Stable and Scalable Method for Solving Initial Value PDEs with Neural Networks. (arXiv:2304.14994v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.16245",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lofstrom_T/0/1/0/all/0/1\">Tuwe L&#xf6;fstr&#xf6;m</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lofstrom_H/0/1/0/all/0/1\">Helena L&#xf6;fstr&#xf6;m</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johansson_U/0/1/0/all/0/1\">Ulf Johansson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonstrod_C/0/1/0/all/0/1\">Cecilia S&#xf6;nstr&#xf6;d</a>",
          "description": "Artificial Intelligence (AI) is often an integral part of modern decision\nsupport systems (DSSs). The best-performing predictive models used in AI-based\nDSSs lack transparency. Explainable Artificial Intelligence (XAI) aims to\ncreate AI systems that can explain their rationale to human users. Local\nexplanations in XAI can provide information about the causes of individual\npredictions in terms of feature importance. However, a critical drawback of\nexisting local explanation methods is their inability to quantify the\nuncertainty associated with a feature's importance. This paper introduces an\nextension of a feature importance explanation method, Calibrated Explanations\n(CE), previously only supporting classification, with support for standard\nregression and probabilistic regression, i.e., the probability that the target\nis above an arbitrary threshold. The extension for regression keeps all the\nbenefits of CE, such as calibration of the prediction from the underlying model\nwith confidence intervals, uncertainty quantification of feature importance,\nand allows both factual and counterfactual explanations. CE for standard\nregression provides fast, reliable, stable, and robust explanations. CE for\nprobabilistic regression provides an entirely new way of creating probabilistic\nexplanations from any ordinary regression model and with a dynamic selection of\nthresholds. The performance of CE for probabilistic regression regarding\nstability and speed is comparable to LIME. The method is model agnostic with\neasily understood conditional rules. An implementation in Python is freely\navailable on GitHub and for installation using pip making the results in this\npaper easily replicable.",
          "link": "http://arxiv.org/abs/2308.16245",
          "publishedOn": "2023-09-02T00:40:01.828Z",
          "wordCount": 738,
          "title": "Calibrated Explanations for Regression. (arXiv:2308.16245v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.16333",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1\">Jiuzhou Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lock_E/0/1/0/all/0/1\">Eric F. Lock</a>",
          "description": "Statistical approaches that successfully combine multiple datasets are more\npowerful, efficient, and scientifically informative than separate analyses. To\naddress variation architectures correctly and comprehensively for\nhigh-dimensional data across multiple sample sets (i.e., cohorts), we propose\nmultiple augmented reduced rank regression (maRRR), a flexible matrix\nregression and factorization method to concurrently learn both covariate-driven\nand auxiliary structured variation. We consider a structured nuclear norm\nobjective that is motivated by random matrix theory, in which the regression or\nfactorization terms may be shared or specific to any number of cohorts. Our\nframework subsumes several existing methods, such as reduced rank regression\nand unsupervised multi-matrix factorization approaches, and includes a\npromising novel approach to regression and factorization of a single dataset\n(aRRR) as a special case. Simulations demonstrate substantial gains in power\nfrom combining multiple datasets, and from parsimoniously accounting for all\nstructured variation. We apply maRRR to gene expression data from multiple\ncancer types (i.e., pan-cancer) from TCGA, with somatic mutations as\ncovariates. The method performs well with respect to prediction and imputation\nof held-out data, and provides new insights into mutation-driven and auxiliary\nvariation that is shared or specific to certain cancer types.",
          "link": "http://arxiv.org/abs/2308.16333",
          "publishedOn": "2023-09-02T00:40:01.798Z",
          "wordCount": 696,
          "title": "Multiple Augmented Reduced Rank Regression for Pan-Cancer Analysis. (arXiv:2308.16333v1 [stat.ME])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.16544",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tuominen_J/0/1/0/all/0/1\">Jalmari Tuominen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pulkkinen_E/0/1/0/all/0/1\">Eetu Pulkkinen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peltonen_J/0/1/0/all/0/1\">Jaakko Peltonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanniainen_J/0/1/0/all/0/1\">Juho Kanniainen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oksala_N/0/1/0/all/0/1\">Niku Oksala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palomaki_A/0/1/0/all/0/1\">Ari Palom&#xe4;ki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roine_A/0/1/0/all/0/1\">Antti Roine</a>",
          "description": "Emergency department (ED) crowding is a significant threat to patient safety\nand it has been repeatedly associated with increased mortality. Forecasting\nfuture service demand has the potential patient outcomes. Despite active\nresearch on the subject, several gaps remain: 1) proposed forecasting models\nhave become outdated due to quick influx of advanced machine learning models\n(ML), 2) amount of multivariable input data has been limited and 3) discrete\nperformance metrics have been rarely reported. In this study, we document the\nperformance of a set of advanced ML models in forecasting ED occupancy 24 hours\nahead. We use electronic health record data from a large, combined ED with an\nextensive set of explanatory variables, including the availability of beds in\ncatchment area hospitals, traffic data from local observation stations, weather\nvariables, etc. We show that N-BEATS and LightGBM outpeform benchmarks with 11\n% and 9 % respective improvements and that DeepAR predicts next day crowding\nwith an AUC of 0.76 (95 % CI 0.69-0.84). To the best of our knowledge, this is\nthe first study to document the superiority of LightGBM and N-BEATS over\nstatistical benchmarks in the context of ED forecasting.",
          "link": "http://arxiv.org/abs/2308.16544",
          "publishedOn": "2023-09-02T00:40:01.787Z",
          "wordCount": 718,
          "title": "Forecasting Emergency Department Crowding with Advanced Machine Learning Models and Multivariable Input. (arXiv:2308.16544v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.14172",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_B/0/1/0/all/0/1\">Bohan Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Siheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xiaowen Dong</a>",
          "description": "Hypergraphs are important for processing data with higher-order relationships\ninvolving more than two entities. In scenarios where explicit hypergraphs are\nnot readily available, it is desirable to infer a meaningful hypergraph\nstructure from the node features to capture the intrinsic relations within the\ndata. However, existing methods either adopt simple pre-defined rules that fail\nto precisely capture the distribution of the potential hypergraph structure, or\nlearn a mapping between hypergraph structures and node features but require a\nlarge amount of labelled data, i.e., pre-existing hypergraph structures, for\ntraining. Both restrict their applications in practical scenarios. To fill this\ngap, we propose a novel smoothness prior that enables us to design a method to\ninfer the probability for each potential hyperedge without labelled data as\nsupervision. The proposed prior indicates features of nodes in a hyperedge are\nhighly correlated by the features of the hyperedge containing them. We use this\nprior to derive the relation between the hypergraph structure and the node\nfeatures via probabilistic modelling. This allows us to develop an unsupervised\ninference method to estimate the probability for each potential hyperedge via\nsolving an optimisation problem that has an analytical solution. Experiments on\nboth synthetic and real-world data demonstrate that our method can learn\nmeaningful hypergraph structures from data more efficiently than existing\nhypergraph structure inference methods.",
          "link": "http://arxiv.org/abs/2308.14172",
          "publishedOn": "2023-09-02T00:40:01.781Z",
          "wordCount": 756,
          "title": "Hypergraph Structure Inference From Data Under Smoothness Prior. (arXiv:2308.14172v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.16382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_F/0/1/0/all/0/1\">Fang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1\">Wenyan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junfeng Wang</a>",
          "description": "Community detection is an important content in complex network analysis. The\nexisting community detection methods in attributed networks mostly focus on\nonly using network structure, while the methods of integrating node attributes\nis mainly for the traditional community structures, and cannot detect\nmultipartite structures and mixture structures in network. In addition, the\nmodel-based community detection methods currently proposed for attributed\nnetworks do not fully consider unique topology information of nodes, such as\nbetweenness centrality and clustering coefficient. Therefore, a stochastic\nblock model that integrates betweenness centrality and clustering coefficient\nof nodes for community detection in attributed networks, named BCSBM, is\nproposed in this paper. Different from other generative models for attributed\nnetworks, the generation process of links and attributes in BCSBM model follows\nthe Poisson distribution, and the probability between community is considered\nbased on the stochastic block model. Moreover, the betweenness centrality and\nclustering coefficient of nodes are introduced into the process of links and\nattributes generation. Finally, the expectation maximization algorithm is\nemployed to estimate the parameters of the BCSBM model, and the node-community\nmemberships is obtained through the hard division process, so the community\ndetection is completed. By experimenting on six real-work networks containing\ndifferent network structures, and comparing with the community detection\nresults of five algorithms, the experimental results show that the BCSBM model\nnot only inherits the advantages of the stochastic block model and can detect\nvarious network structures, but also has good data fitting ability due to\nintroducing the betweenness centrality and clustering coefficient of nodes.\nOverall, the performance of this model is superior to other five compared\nalgorithms.",
          "link": "http://arxiv.org/abs/2308.16382",
          "publishedOn": "2023-09-02T00:40:01.775Z",
          "wordCount": 775,
          "title": "A stochastic block model for community detection in attributed networks. (arXiv:2308.16382v1 [cs.SI])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.02064",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Javanmard_A/0/1/0/all/0/1\">Adel Javanmard</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mehrabi_M/0/1/0/all/0/1\">Mohammad Mehrabi</a>",
          "description": "Performance of classifiers is often measured in terms of average accuracy on\ntest data. Despite being a standard measure, average accuracy fails in\ncharacterizing the fit of the model to the underlying conditional law of labels\ngiven the features vector ($Y|X$), e.g. due to model misspecification, over\nfitting, and high-dimensionality. In this paper, we consider the fundamental\nproblem of assessing the goodness-of-fit for a general binary classifier. Our\nframework does not make any parametric assumption on the conditional law $Y|X$,\nand treats that as a black box oracle model which can be accessed only through\nqueries. We formulate the goodness-of-fit assessment problem as a tolerance\nhypothesis testing of the form \\[ H_0: \\mathbb{E}\\Big[D_f\\Big({\\sf\nBern}(\\eta(X))\\|{\\sf Bern}(\\hat{\\eta}(X))\\Big)\\Big]\\leq \\tau\\,, \\] where $D_f$\nrepresents an $f$-divergence function, and $\\eta(x)$, $\\hat{\\eta}(x)$\nrespectively denote the true and an estimate likelihood for a feature vector\n$x$ admitting a positive label. We propose a novel test, called \\grasp for\ntesting $H_0$, which works in finite sample settings, no matter the features\n(distribution-free). We also propose model-X \\grasp designed for model-X\nsettings where the joint distribution of the features vector is known. Model-X\n\\grasp uses this distributional information to achieve better power. We\nevaluate the performance of our tests through extensive numerical experiments.",
          "link": "http://arxiv.org/abs/2209.02064",
          "publishedOn": "2023-09-02T00:40:01.769Z",
          "wordCount": 725,
          "title": "GRASP: A Goodness-of-Fit Test for Classification Learning. (arXiv:2209.02064v2 [stat.ME] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.16681",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Simson_J/0/1/0/all/0/1\">Jan Simson</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pfisterer_F/0/1/0/all/0/1\">Florian Pfisterer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kern_C/0/1/0/all/0/1\">Christoph Kern</a>",
          "description": "A vast number of systems across the world use algorithmic decision making\n(ADM) to (partially) automate decisions that have previously been made by\nhumans. When designed well, these systems promise more objective decisions\nwhile saving large amounts of resources and freeing up human time. However,\nwhen ADM systems are not designed well, they can lead to unfair decisions which\ndiscriminate against societal groups. The downstream effects of ADMs critically\ndepend on the decisions made during the systems' design and implementation, as\nbiases in data can be mitigated or reinforced along the modeling pipeline. Many\nof these design decisions are made implicitly, without knowing exactly how they\nwill influence the final system. It is therefore important to make explicit the\ndecisions made during the design of ADM systems and understand how these\ndecisions affect the fairness of the resulting system.\n\nTo study this issue, we draw on insights from the field of psychology and\nintroduce the method of multiverse analysis for algorithmic fairness. In our\nproposed method, we turn implicit design decisions into explicit ones and\ndemonstrate their fairness implications. By combining decisions, we create a\ngrid of all possible \"universes\" of decision combinations. For each of these\nuniverses, we compute metrics of fairness and performance. Using the resulting\ndataset, one can see how and which decisions impact fairness. We demonstrate\nhow multiverse analyses can be used to better understand variability and\nrobustness of algorithmic fairness using an exemplary case study of predicting\npublic health coverage of vulnerable populations for potential interventions.\nOur results illustrate how decisions during the design of a machine learning\nsystem can have surprising effects on its fairness and how to detect these\neffects using multiverse analysis.",
          "link": "http://arxiv.org/abs/2308.16681",
          "publishedOn": "2023-09-02T00:40:01.763Z",
          "wordCount": 827,
          "title": "Everything, Everywhere All in One Evaluation: Using Multiverse Analysis to Evaluate the Influence of Model Design Decisions on Algorithmic Fairness. (arXiv:2308.16681v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2305.11463",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hertrich_J/0/1/0/all/0/1\">Johannes Hertrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wald_C/0/1/0/all/0/1\">Christian Wald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altekruger_F/0/1/0/all/0/1\">Fabian Altekr&#xfc;ger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hagemann_P/0/1/0/all/0/1\">Paul Hagemann</a>",
          "description": "Maximum mean discrepancy (MMD) flows suffer from high computational costs in\nlarge scale computations. In this paper, we show that MMD flows with Riesz\nkernels $K(x,y) = - \\Vert x-y\\Vert^r$, $r \\in (0,2)$ have exceptional\nproperties which allow their efficient computation. We prove that the MMD of\nRiesz kernels coincides with the MMD of their sliced version. As a consequence,\nthe computation of gradients of MMDs can be performed in the one-dimensional\nsetting. Here, for $r=1$, a simple sorting algorithm can be applied to reduce\nthe complexity from $O(MN+N^2)$ to $O((M+N)\\log(M+N))$ for two measures with\n$M$ and $N$ support points. As another interesting follow-up result, the MMD of\ncompactly supported measures can be estimated from above and below by the\nWasserstein-1 distance. For the implementations we approximate the gradient of\nthe sliced MMD by using only a finite number $P$ of slices. We show that the\nresulting error has complexity $O(\\sqrt{d/P})$, where $d$ is the data\ndimension. These results enable us to train generative models by approximating\nMMD gradient flows by neural networks even for image applications. We\ndemonstrate the efficiency of our model by image generation on MNIST,\nFashionMNIST and CIFAR10.",
          "link": "http://arxiv.org/abs/2305.11463",
          "publishedOn": "2023-09-02T00:40:01.532Z",
          "wordCount": 717,
          "title": "Generative Sliced MMD Flows with Riesz Kernels. (arXiv:2305.11463v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.16637",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Siegismund_D/0/1/0/all/0/1\">Daniel Siegismund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wieser_M/0/1/0/all/0/1\">Mario Wieser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heyse_S/0/1/0/all/0/1\">Stephan Heyse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steigele_S/0/1/0/all/0/1\">Stephan Steigele</a>",
          "description": "Uncovering novel drug candidates for treating complex diseases remain one of\nthe most challenging tasks in early discovery research. To tackle this\nchallenge, biopharma research established a standardized high content imaging\nprotocol that tags different cellular compartments per image channel. In order\nto judge the experimental outcome, the scientist requires knowledge about the\nchannel importance with respect to a certain phenotype for decoding the\nunderlying biology. In contrast to traditional image analysis approaches, such\nexperiments are nowadays preferably analyzed by deep learning based approaches\nwhich, however, lack crucial information about the channel importance. To\novercome this limitation, we present a novel approach which utilizes\nmulti-spectral information of high content images to interpret a certain aspect\nof cellular biology. To this end, we base our method on image blending concepts\nwith alpha compositing for an arbitrary number of channels. More specifically,\nwe introduce DCMIX, a lightweight, scaleable and end-to-end trainable mixing\nlayer which enables interpretable predictions in high content imaging while\nretaining the benefits of deep learning based methods. We employ an extensive\nset of experiments on both MNIST and RXRX1 datasets, demonstrating that DCMIX\nlearns the biologically relevant channel importance without scarifying\nprediction performance.",
          "link": "http://arxiv.org/abs/2308.16637",
          "publishedOn": "2023-09-02T00:40:01.524Z",
          "wordCount": 729,
          "title": "Learning Channel Importance for High Content Imaging with Interpretable Deep Input Channel Mixing. (arXiv:2308.16637v1 [cs.CV])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.16192",
          "author": "<a href=\"http://arxiv.org/find/econ/1/au:+Katsouris_C/0/1/0/all/0/1\">Christis Katsouris</a>",
          "description": "These lecture notes provide an overview of existing methodologies and recent\ndevelopments for estimation and inference with high dimensional time series\nregression models. First, we present main limit theory results for high\ndimensional dependent data which is relevant to covariance matrix structures as\nwell as to dependent time series sequences. Second, we present main aspects of\nthe asymptotic theory related to time series regression models with many\ncovariates. Third, we discuss various applications of statistical learning\nmethodologies for time series analysis purposes.",
          "link": "http://arxiv.org/abs/2308.16192",
          "publishedOn": "2023-09-02T00:40:01.518Z",
          "wordCount": 576,
          "title": "High Dimensional Time Series Regression Models: Applications to Statistical Learning Methods. (arXiv:2308.16192v1 [econ.EM])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.16859",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Veedu_M/0/1/0/all/0/1\">Mishfad Shaikh Veedu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Deka_D/0/1/0/all/0/1\">Deepjyoti Deka</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Salapaka_M/0/1/0/all/0/1\">Murti V. Salapaka</a>",
          "description": "In this article, the optimal sample complexity of learning the underlying\ninteraction/dependencies of a Linear Dynamical System (LDS) over a Directed\nAcyclic Graph (DAG) is studied. The sample complexity of learning a DAG's\nstructure is well-studied for static systems, where the samples of nodal states\nare independent and identically distributed (i.i.d.). However, such a study is\nless explored for DAGs with dynamical systems, where the nodal states are\ntemporally correlated. We call such a DAG underlying an LDS as \\emph{dynamical}\nDAG (DDAG). In particular, we consider a DDAG where the nodal dynamics are\ndriven by unobserved exogenous noise sources that are wide-sense stationary\n(WSS) in time but are mutually uncorrelated, and have the same {power spectral\ndensity (PSD)}. Inspired by the static settings, a metric and an algorithm\nbased on the PSD matrix of the observed time series are proposed to reconstruct\nthe DDAG. The equal noise PSD assumption can be relaxed such that\nidentifiability conditions for DDAG reconstruction are not violated. For the\nLDS with WSS (sub) Gaussian exogenous noise sources, it is shown that the\noptimal sample complexity (or length of state trajectory) needed to learn the\nDDAG is $n=\\Theta(q\\log(p/q))$, where $p$ is the number of nodes and $q$ is the\nmaximum number of parents per node. To prove the sample complexity upper bound,\na concentration bound for the PSD estimation is derived, under two different\nsampling strategies. A matching min-max lower bound using generalized Fano's\ninequality also is provided, thus showing the order optimality of the proposed\nalgorithm.",
          "link": "http://arxiv.org/abs/2308.16859",
          "publishedOn": "2023-09-02T00:40:01.502Z",
          "wordCount": 779,
          "title": "Information Theoretically Optimal Sample Complexity of Learning Dynamical Directed Acyclic Graphs. (arXiv:2308.16859v1 [stat.ML])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.16425",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1\">Zenan Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_Z/0/1/0/all/0/1\">Zhenyu Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_R/0/1/0/all/0/1\">Robert C. Qiu</a>",
          "description": "Implicit neural networks have demonstrated remarkable success in various\ntasks. However, there is a lack of theoretical analysis of the connections and\ndifferences between implicit and explicit networks. In this paper, we study\nhigh-dimensional implicit neural networks and provide the high dimensional\nequivalents for the corresponding conjugate kernels and neural tangent kernels.\nBuilt upon this, we establish the equivalence between implicit and explicit\nnetworks in high dimensions.",
          "link": "http://arxiv.org/abs/2308.16425",
          "publishedOn": "2023-09-02T00:40:01.495Z",
          "wordCount": 601,
          "title": "On the Equivalence between Implicit and Explicit Neural Networks: A High-dimensional Viewpoint. (arXiv:2308.16425v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2208.06228",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1\">Yingwen Wu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_S/0/1/0/all/0/1\">Sizhe Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Fang_K/0/1/0/all/0/1\">Kun Fang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Huang_X/0/1/0/all/0/1\">Xiaolin Huang</a>",
          "description": "The wide application of deep neural networks (DNNs) demands an increasing\namount of attention to their real-world robustness, i.e., whether a DNN resists\nblack-box adversarial attacks, among which score-based query attacks (SQAs) are\nmost threatening since they can effectively hurt a victim network with the only\naccess to model outputs. Defending against SQAs requires a slight but artful\nvariation of outputs due to the service purpose for users, who share the same\noutput information with SQAs. In this paper, we propose a real-world defense by\nUnifying Gradients (UniG) of different data so that SQAs could only probe a\nmuch weaker attack direction that is similar for different samples. Since such\nuniversal attack perturbations have been validated as less aggressive than the\ninput-specific perturbations, UniG protects real-world DNNs by indicating\nattackers a twisted and less informative attack direction. We implement UniG\nefficiently by a Hadamard product module which is plug-and-play. According to\nextensive experiments on 5 SQAs, 2 adaptive attacks and 7 defense baselines,\nUniG significantly improves real-world robustness without hurting clean\naccuracy on CIFAR10 and ImageNet. For instance, UniG maintains a model of\n77.80% accuracy under 2500-query Square attack while the state-of-the-art\nadversarially-trained model only has 67.34% on CIFAR10. Simultaneously, UniG\noutperforms all compared baselines in terms of clean accuracy and achieves the\nsmallest modification of the model output. The code is released at\nhttps://github.com/snowien/UniG-pytorch.",
          "link": "http://arxiv.org/abs/2208.06228",
          "publishedOn": "2023-08-26T00:39:49.452Z",
          "wordCount": null,
          "title": "Unifying Gradients to Improve Real-world Robustness for Deep Networks. (arXiv:2208.06228v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12820",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kothari_A/0/1/0/all/0/1\">Avni Kothari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulynych_B/0/1/0/all/0/1\">Bogdan Kulynych</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_T/0/1/0/all/0/1\">Tsui-Wei Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ustun_B/0/1/0/all/0/1\">Berk Ustun</a>",
          "description": "Machine learning models are often used to decide who will receive a loan, a\njob interview, or a public benefit. Standard techniques to build these models\nuse features about people but overlook their actionability. In turn, models can\nassign predictions that are fixed, meaning that consumers who are denied loans,\ninterviews, or benefits may be permanently locked out from access to credit,\nemployment, or assistance. In this work, we introduce a formal testing\nprocedure to flag models that assign fixed predictions that we call recourse\nverification. We develop machinery to reliably determine if a given model can\nprovide recourse to its decision subjects from a set of user-specified\nactionability constraints. We demonstrate how our tools can ensure recourse and\nadversarial robustness in real-world datasets and use them to study the\ninfeasibility of recourse in real-world lending datasets. Our results highlight\nhow models can inadvertently assign fixed predictions that permanently bar\naccess, and we provide tools to design algorithms that account for\nactionability when developing models.",
          "link": "http://arxiv.org/abs/2308.12820",
          "publishedOn": "2023-08-26T00:39:49.451Z",
          "wordCount": null,
          "title": "Prediction without Preclusion: Recourse Verification with Reachable Sets. (arXiv:2308.12820v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.09113",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Tang_H/0/1/0/all/0/1\">Hewei Tang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kong_Q/0/1/0/all/0/1\">Qingkai Kong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Morris_J/0/1/0/all/0/1\">Joseph P. Morris</a>",
          "description": "Deep learning-based surrogate models have been widely applied in geological\ncarbon storage (GCS) problems to accelerate the prediction of reservoir\npressure and CO2 plume migration. Large amounts of data from physics-based\nnumerical simulators are required to train a model to accurately predict the\ncomplex physical behaviors associated with this process. In practice, the\navailable training data are always limited in large-scale 3D problems due to\nthe high computational cost. Therefore, we propose to use a multi-fidelity\nFourier Neural Operator to solve large-scale GCS problems with more affordable\nmulti-fidelity training datasets. The Fourier Neural Operator has a desirable\ngrid-invariant property, which simplifies the transfer learning procedure\nbetween datasets with different discretization. We first test the model\nefficacy on a GCS reservoir model being discretized into 110k grid cells. The\nmulti-fidelity model can predict with accuracy comparable to a high-fidelity\nmodel trained with the same amount of high-fidelity data with 81% less data\ngeneration costs. We further test the generalizability of the multi-fidelity\nmodel on a same reservoir model with a finer discretization of 1 million grid\ncells. This case was made more challenging by employing high-fidelity and\nlow-fidelity datasets generated by different geostatistical models and\nreservoir simulators. We observe that the multi-fidelity FNO model can predict\npressure fields with reasonable accuracy even when the high-fidelity data are\nextremely limited.",
          "link": "http://arxiv.org/abs/2308.09113",
          "publishedOn": "2023-08-26T00:39:49.437Z",
          "wordCount": null,
          "title": "Multi-fidelity Fourier Neural Operator for Fast Modeling of Large-Scale Geological Carbon Storage. (arXiv:2308.09113v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12606",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Bhunre_P/0/1/0/all/0/1\">Piyush Kanti Bhunre</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sen_T/0/1/0/all/0/1\">Tanmay Sen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Sarkar_A/0/1/0/all/0/1\">Arijit Sarkar</a>",
          "description": "Customer retention or churn prevention is a challenging task of a telecom\noperator. One of the effective approaches is to offer some attractive incentive\nor additional services or money to the subscribers for keeping them engaged and\nmake sure they stay in the operator's network for longer time. Often, operators\nallocate certain amount of monetary budget to carry out the offer campaign. The\ndifficult part of this campaign is the selection of a set of customers from a\nlarge subscriber-base and deciding the amount that should be offered to an\nindividual so that operator's objective is achieved. There may be multiple\nobjectives (e.g., maximizing revenue, minimizing number of churns) for\nselection of subscriber and selection of an offer to the selected subscriber.\nApart from monetary benefit, offers may include additional data, SMS, hots-spot\ntethering, and many more. This problem is known as offer optimization. In this\npaper, we propose a novel combinatorial algorithm for solving offer\noptimization under heterogeneous offers by maximizing expected revenue under\nthe scenario of subscriber churn, which is, in general, seen in telecom domain.\nThe proposed algorithm is efficient and accurate even for a very large\nsubscriber-base.",
          "link": "http://arxiv.org/abs/2308.12606",
          "publishedOn": "2023-08-26T00:39:49.435Z",
          "wordCount": null,
          "title": "A Greedy Approach for Offering to Telecom Subscribers. (arXiv:2308.12606v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2206.11546",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Fukuchi_K/0/1/0/all/0/1\">Kazuto Fukuchi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sakuma_J/0/1/0/all/0/1\">Jun Sakuma</a>",
          "description": "We explore the minimax optimal error associated with a demographic\nparity-constrained regression problem within the context of a linear model. Our\nproposed model encompasses a broader range of discriminatory bias sources\ncompared to the model presented by Chzhen and Schreuder (2022). Our analysis\nreveals that the minimax optimal error for the demographic parity-constrained\nregression problem under our model is characterized by $\\Theta(\\frac{dM}{n})$,\nwhere $n$ denotes the sample size, $d$ represents the dimensionality, and $M$\nsignifies the number of demographic groups arising from sensitive attributes.\nMoreover, we demonstrate that the minimax error increases in conjunction with a\nlarger bias present in the model.",
          "link": "http://arxiv.org/abs/2206.11546",
          "publishedOn": "2023-08-26T00:39:49.430Z",
          "wordCount": null,
          "title": "Demographic Parity Constrained Minimax Optimal Regression under Linear Model. (arXiv:2206.11546v3 [math.ST] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12785",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brach_K/0/1/0/all/0/1\">Kai Brach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sick_B/0/1/0/all/0/1\">Beate Sick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durr_O/0/1/0/all/0/1\">Oliver D&#xfc;rr</a>",
          "description": "Deep neural networks (NNs) are known for their high-prediction performances.\nHowever, NNs are prone to yield unreliable predictions when encountering\ncompletely new situations without indicating their uncertainty. Bayesian\nvariants of NNs (BNNs), such as Monte Carlo (MC) dropout BNNs, do provide\nuncertainty measures and simultaneously increase the prediction performance.\nThe only disadvantage of BNNs is their higher computation time during test time\nbecause they rely on a sampling approach. Here we present a single-shot MC\ndropout approximation that preserves the advantages of BNNs while being as fast\nas NNs. Our approach is based on moment propagation (MP) and allows to\nanalytically approximate the expected value and the variance of the MC dropout\nsignal for commonly used layers in NNs, i.e. convolution, max pooling, dense,\nsoftmax, and dropout layers. The MP approach can convert an NN into a BNN\nwithout re-training given the NN has been trained with standard dropout. We\nevaluate our approach on different benchmark datasets and a simulated toy\nexample in a classification and regression setting. We demonstrate that our\nsingle-shot MC dropout approximation resembles the point estimate and the\nuncertainty estimate of the predictive distribution that is achieved with an MC\napproach, while being fast enough for real-time deployments of BNNs. We show\nthat using part of the saved time to combine our MP approach with deep ensemble\ntechniques does further improve the uncertainty measures.",
          "link": "http://arxiv.org/abs/2308.12785",
          "publishedOn": "2023-08-26T00:39:49.425Z",
          "wordCount": null,
          "title": "Single-shot Bayesian approximation for neural networks. (arXiv:2308.12785v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12000",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Wang_P/0/1/0/all/0/1\">Po-An Wang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ariu_K/0/1/0/all/0/1\">Kaito Ariu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Proutiere_A/0/1/0/all/0/1\">Alexandre Proutiere</a>",
          "description": "We study the problem of best-arm identification with fixed budget in\nstochastic two-arm bandits with Bernoulli rewards. We prove that surprisingly,\nthere is no algorithm that (i) performs as well as the algorithm sampling each\narm equally (this algorithm is referred to as the {\\it uniform sampling}\nalgorithm) on all instances, and that (ii) strictly outperforms this algorithm\non at least one instance. In short, there is no algorithm better than the\nuniform sampling algorithm. Towards this result, we introduce the natural class\nof {\\it consistent} and {\\it stable} algorithms, and show that any algorithm\nthat performs as well as the uniform sampling algorithm on all instances\nbelongs to this class. The proof is completed by deriving a lower bound on the\nerror rate satisfied by any consistent and stable algorithm, and by showing\nthat the uniform sampling algorithm matches this lower bound. Our results\nprovide a solution to the two open problems presented in \\cite{qin2022open}.",
          "link": "http://arxiv.org/abs/2308.12000",
          "publishedOn": "2023-08-26T00:39:49.424Z",
          "wordCount": null,
          "title": "On Uniformly Optimal Algorithms for Best Arm Identification in Two-Armed Bandits with Fixed Budget. (arXiv:2308.12000v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12304",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Magner_A/0/1/0/all/0/1\">Abram Magner</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Padakandla_A/0/1/0/all/0/1\">Arun Padakandla</a>",
          "description": "We characterize learnability for quantum measurement classes by establishing\nmatching necessary and sufficient conditions for their PAC learnability, along\nwith corresponding sample complexity bounds, in the setting where the learner\nis given access only to prepared quantum states. We first probe the results\nfrom previous works on this setting. We show that the empirical risk defined in\nprevious works and matching the definition in the classical theory fails to\nsatisfy the uniform convergence property enjoyed in the classical setting for\nsome learnable classes. Moreover, we show that VC dimension generalization\nupper bounds in previous work are frequently infinite, even for\nfinite-dimensional POVM classes. To surmount the failure of the standard ERM to\nsatisfy uniform convergence, we define a new learning rule -- denoised ERM. We\nshow this to be a universal learning rule for POVM and probabilistically\nobserved concept classes, and the condition for it to satisfy uniform\nconvergence is finite fat shattering dimension of the class. We give\nquantitative sample complexity upper and lower bounds for learnability in terms\nof finite fat-shattering dimension and a notion of approximate finite\npartitionability into approximately jointly measurable subsets, which allow for\nsample reuse. We then show that finite fat shattering dimension implies finite\ncoverability by approximately jointly measurable subsets, leading to our\nmatching conditions. We also show that every measurement class defined on a\nfinite-dimensional Hilbert space is PAC learnable. We illustrate our results on\nseveral example POVM classes.",
          "link": "http://arxiv.org/abs/2308.12304",
          "publishedOn": "2023-08-26T00:39:49.413Z",
          "wordCount": null,
          "title": "Fat Shattering, Joint Measurability, and PAC Learnability of POVM Hypothesis Classes. (arXiv:2308.12304v1 [stat.ML])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2210.14598",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Magris_M/0/1/0/all/0/1\">Martin Magris</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shabani_M/0/1/0/all/0/1\">Mostafa Shabani</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Iosifidis_A/0/1/0/all/0/1\">Alexandros Iosifidis</a>",
          "description": "We propose an optimization algorithm for Variational Inference (VI) in\ncomplex models. Our approach relies on natural gradient updates where the\nvariational space is a Riemann manifold. We develop an efficient algorithm for\nGaussian Variational Inference that implicitly satisfies the positive definite\nconstraint on the variational covariance matrix. Our Exact manifold Gaussian\nVariational Bayes (EMGVB) provides exact but simple update rules and is\nstraightforward to implement. Due to its black-box nature, EMGVB stands as a\nready-to-use solution for VI in complex models. Over five datasets, we\nempirically validate our feasible approach on different statistical,\neconometric, and deep learning models, discussing its performance with respect\nto baseline methods.",
          "link": "http://arxiv.org/abs/2210.14598",
          "publishedOn": "2023-08-26T00:39:49.411Z",
          "wordCount": null,
          "title": "Exact Manifold Gaussian Variational Bayes. (arXiv:2210.14598v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12445",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yahmed_A/0/1/0/all/0/1\">Ahmed Haj Yahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouchoucha_R/0/1/0/all/0/1\">Rached Bouchoucha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Braiek_H/0/1/0/all/0/1\">Houssem Ben Braiek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khomh_F/0/1/0/all/0/1\">Foutse Khomh</a>",
          "description": "Deep reinforcement learning (DRL) is increasingly applied in large-scale\nproductions like Netflix and Facebook. As with most data-driven systems, DRL\nsystems can exhibit undesirable behaviors due to environmental drifts, which\noften occur in constantly-changing production settings. Continual Learning (CL)\nis the inherent self-healing approach for adapting the DRL agent in response to\nthe environment's conditions shifts. However, successive shifts of considerable\nmagnitude may cause the production environment to drift from its original\nstate. Recent studies have shown that these environmental drifts tend to drive\nCL into long, or even unsuccessful, healing cycles, which arise from\ninefficiencies such as catastrophic forgetting, warm-starting failure, and slow\nconvergence. In this paper, we propose Dr. DRL, an effective self-healing\napproach for DRL systems that integrates a novel mechanism of intentional\nforgetting into vanilla CL to overcome its main issues. Dr. DRL deliberately\nerases the DRL system's minor behaviors to systematically prioritize the\nadaptation of the key problem-solving skills. Using well-established DRL\nalgorithms, Dr. DRL is compared with vanilla CL on various drifted\nenvironments. Dr. DRL is able to reduce, on average, the healing time and\nfine-tuning episodes by, respectively, 18.74% and 17.72%. Dr. DRL successfully\nhelps agents to adapt to 19.63% of drifted environments left unsolved by\nvanilla CL while maintaining and even enhancing by up to 45% the obtained\nrewards for drifted environments that are resolved by both approaches.",
          "link": "http://arxiv.org/abs/2308.12445",
          "publishedOn": "2023-08-26T00:39:49.410Z",
          "wordCount": null,
          "title": "An Intentional Forgetting-Driven Self-Healing Method For Deep Reinforcement Learning Systems. (arXiv:2308.12445v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.12553",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Puli_A/0/1/0/all/0/1\">Aahlad Puli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lily Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wald_Y/0/1/0/all/0/1\">Yoav Wald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranganath_R/0/1/0/all/0/1\">Rajesh Ranganath</a>",
          "description": "Common explanations for shortcut learning assume that the shortcut improves\nprediction under the training distribution but not in the test distribution.\nThus, models trained via the typical gradient-based optimization of\ncross-entropy, which we call default-ERM, utilize the shortcut. However, even\nwhen the stable feature determines the label in the training distribution and\nthe shortcut does not provide any additional information, like in perception\ntasks, default-ERM still exhibits shortcut learning. Why are such solutions\npreferred when the loss for default-ERM can be driven to zero using the stable\nfeature alone? By studying a linear perception task, we show that default-ERM's\npreference for maximizing the margin leads to models that depend more on the\nshortcut than the stable feature, even without overparameterization. This\ninsight suggests that default-ERM's implicit inductive bias towards max-margin\nis unsuitable for perception tasks. Instead, we develop an inductive bias\ntoward uniform margins and show that this bias guarantees dependence only on\nthe perfect stable feature in the linear perception task. We develop loss\nfunctions that encourage uniform-margin solutions, called margin control\n(MARG-CTRL). MARG-CTRL mitigates shortcut learning on a variety of vision and\nlanguage tasks, showing that better inductive biases can remove the need for\nexpensive two-stage shortcut-mitigating methods in perception tasks.",
          "link": "http://arxiv.org/abs/2308.12553",
          "publishedOn": "2023-08-26T00:39:49.410Z",
          "wordCount": null,
          "title": "Don't blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy. (arXiv:2308.12553v1 [cs.LG])",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.10145",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Kim_Y/0/1/0/all/0/1\">Young-geun Kim</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lee_K/0/1/0/all/0/1\">Kyungbok Lee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Choi_Y/0/1/0/all/0/1\">Youngwon Choi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Won_J/0/1/0/all/0/1\">Joong-Ho Won</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Paik_M/0/1/0/all/0/1\">Myunghee Cho Paik</a>",
          "description": "Generating samples given a specific label requires estimating conditional\ndistributions. We derive a tractable upper bound of the Wasserstein distance\nbetween conditional distributions to lay the theoretical groundwork to learn\nconditional distributions. Based on this result, we propose a novel conditional\ngeneration algorithm where conditional distributions are fully characterized by\na metric space defined by a statistical distance. We employ optimal transport\ntheory to propose the Wasserstein geodesic generator, a new conditional\ngenerator that learns the Wasserstein geodesic. The proposed method learns both\nconditional distributions for observed domains and optimal transport maps\nbetween them. The conditional distributions given unobserved intermediate\ndomains are on the Wasserstein geodesic between conditional distributions given\ntwo observed domain labels. Experiments on face images with light conditions as\ndomain labels demonstrate the efficacy of the proposed method.",
          "link": "http://arxiv.org/abs/2308.10145",
          "publishedOn": "2023-08-26T00:39:49.093Z",
          "wordCount": null,
          "title": "Wasserstein Geodesic Generator for Conditional Distributions. (arXiv:2308.10145v2 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2308.11846",
          "author": "<a href=\"http://arxiv.org/find/nlin/1/au:+Zhao_Y/0/1/0/all/0/1\">Yingjie Zhao</a>, <a href=\"http://arxiv.org/find/nlin/1/au:+Xu_Z/0/1/0/all/0/1\">Zhiping Xu</a>",
          "description": "Morphological development into evolutionary patterns under structural\ninstability is ubiquitous in living systems and often of vital importance for\nengineering structures. Here we propose a data-driven approach to understand\nand predict their spatiotemporal complexities. A machine-learning framework is\nproposed based on the physical modeling of morphogenesis triggered by internal\nor external forcing. Digital libraries of structural patterns are constructed\nfrom the simulation data, which are then used to recognize the abnormalities,\npredict their development, and assist in risk assessment and prognosis. The\ncapabilities to identify the key bifurcation characteristics and predict the\nhistory-dependent development from the global and local features are\ndemonstrated by examples of brain growth and aerospace structural design, which\noffer guidelines for disease diagnosis/prognosis and instability-tolerant\ndesign.",
          "link": "http://arxiv.org/abs/2308.11846",
          "publishedOn": "2023-08-26T00:39:49.072Z",
          "wordCount": null,
          "title": "A Data-Driven Approach to Morphogenesis under Structural Instability. (arXiv:2308.11846v1 [nlin.PS] CROSS LISTED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2209.15596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koskela_A/0/1/0/all/0/1\">Antti Koskela</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tobaben_M/0/1/0/all/0/1\">Marlon Tobaben</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Honkela_A/0/1/0/all/0/1\">Antti Honkela</a>",
          "description": "Individual privacy accounting enables bounding differential privacy (DP) loss\nindividually for each participant involved in the analysis. This can be\ninformative as often the individual privacy losses are considerably smaller\nthan those indicated by the DP bounds that are based on considering worst-case\nbounds at each data access. In order to account for the individual privacy\nlosses in a principled manner, we need a privacy accountant for adaptive\ncompositions of randomised mechanisms, where the loss incurred at a given data\naccess is allowed to be smaller than the worst-case loss. This kind of analysis\nhas been carried out for the R\\'enyi differential privacy (RDP) by Feldman and\nZrnic (2021), however not yet for the so-called optimal privacy accountants. We\nmake first steps in this direction by providing a careful analysis using the\nGaussian differential privacy which gives optimal bounds for the Gaussian\nmechanism, one of the most versatile DP mechanisms. This approach is based on\ndetermining a certain supermartingale for the hockey-stick divergence and on\nextending the R\\'enyi divergence-based fully adaptive composition results by\nFeldman and Zrnic. We also consider measuring the individual\n$(\\varepsilon,\\delta)$-privacy losses using the so-called privacy loss\ndistributions. With the help of the Blackwell theorem, we can then make use of\nthe RDP analysis to construct an approximative individual\n$(\\varepsilon,\\delta)$-accountant.",
          "link": "http://arxiv.org/abs/2209.15596",
          "publishedOn": "2023-08-26T00:39:49.061Z",
          "wordCount": null,
          "title": "Individual Privacy Accounting with Gaussian Differential Privacy. (arXiv:2209.15596v2 [cs.CR] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2306.10592",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Das_S/0/1/0/all/0/1\">Suddhasattwa Das</a>",
          "description": "The separate tasks of denoising, least squares expectation, and manifold\nlearning can often be posed in a common setting of finding the conditional\nexpectations arising from a product of two random variables. This paper focuses\non this more general problem and describes an operator theoretic approach to\nestimating the conditional expectation. Kernel integral operators are used as a\ncompactification tool, to set up the estimation problem as a linear inverse\nproblem in a reproducing kernel Hilbert space. This equation is shown to have\nsolutions that allow numerical approximation, thus guaranteeing the convergence\nof data-driven implementations. The overall technique is easy to implement, and\ntheir successful application to some real-world problems are also shown.",
          "link": "http://arxiv.org/abs/2306.10592",
          "publishedOn": "2023-08-26T00:39:48.909Z",
          "wordCount": null,
          "title": "Conditional expectation using compactification operators. (arXiv:2306.10592v3 [stat.ML] UPDATED)",
          "imageUrl": null
        },
        {
          "id": "http://arxiv.org/abs/2305.17058",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zaiser_F/0/1/0/all/0/1\">Fabian Zaiser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murawski_A/0/1/0/all/0/1\">Andrzej S. Murawski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_L/0/1/0/all/0/1\">Luke Ong</a>",
          "description": "We present an exact Bayesian inference method for discrete statistical\nmodels, which can find exact solutions to many discrete inference problems,\neven with infinite support and continuous priors. To express such models, we\nintroduce a probabilistic programming language that supports discrete and\ncontinuous sampling, discrete observations, affine functions, (stochastic)\nbranching, and conditioning on events. Our key tool is probability generating\nfunctions: they provide a compact closed-form representation of distributions\nthat are definable by programs, thus enabling the exact computation of\nposterior probabilities, expectation, variance, and higher moments. Our\ninference method is provably correct, fully automated and uses automatic\ndifferentiation (specifically, Taylor polynomials), but does not require\ncomputer algebra. Our experiments show that its performance on a range of\nreal-world examples is competitive with approximate Monte Carlo methods, while\navoiding approximation errors.",
          "link": "http://arxiv.org/abs/2305.17058",
          "publishedOn": "2023-08-26T00:39:47.711Z",
          "wordCount": 683,
          "title": "Exact Bayesian Inference on Discrete Models via Probability Generating Functions: A Probabilistic Programming Approach. (arXiv:2305.17058v2 [cs.PL] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.12666",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Charlie Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_T/0/1/0/all/0/1\">Theodore Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Sarah Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laine_R/0/1/0/all/0/1\">Rudolf Laine</a>",
          "description": "Mode connectivity is a phenomenon where trained models are connected by a\npath of low loss. We reframe this in the context of Information Geometry, where\nneural networks are studied as spaces of parameterized distributions with\ncurved geometry. We hypothesize that shortest paths in these spaces, known as\ngeodesics, correspond to mode-connecting paths in the loss landscape. We\npropose an algorithm to approximate geodesics and demonstrate that they achieve\nmode connectivity.",
          "link": "http://arxiv.org/abs/2308.12666",
          "publishedOn": "2023-08-26T00:39:47.704Z",
          "wordCount": 566,
          "title": "Geodesic Mode Connectivity. (arXiv:2308.12666v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2204.11418",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Han_A/0/1/0/all/0/1\">Andi Han</a>, <a href=\"http://arxiv.org/find/math/1/au:+Mishra_B/0/1/0/all/0/1\">Bamdev Mishra</a>, <a href=\"http://arxiv.org/find/math/1/au:+Jawanpuria_P/0/1/0/all/0/1\">Pratik Jawanpuria</a>, <a href=\"http://arxiv.org/find/math/1/au:+Kumar_P/0/1/0/all/0/1\">Pawan Kumar</a>, <a href=\"http://arxiv.org/find/math/1/au:+Gao_J/0/1/0/all/0/1\">Junbin Gao</a>",
          "description": "In this paper, we study min-max optimization problems on Riemannian\nmanifolds. We introduce a Riemannian Hamiltonian function, minimization of\nwhich serves as a proxy for solving the original min-max problems. Under the\nRiemannian Polyak--{\\L}ojasiewicz condition on the Hamiltonian function, its\nminimizer corresponds to the desired min-max saddle point. We also provide\ncases where this condition is satisfied. For geodesic-bilinear optimization in\nparticular, solving the proxy problem leads to the correct search direction\ntowards global optimality, which becomes challenging with the min-max\nformulation. To minimize the Hamiltonian function, we propose Riemannian\nHamiltonian methods (RHM) and present their convergence analyses. We extend RHM\nto include consensus regularization and to the stochastic setting. We\nillustrate the efficacy of the proposed RHM in applications such as subspace\nrobust Wasserstein distance, robust training of neural networks, and generative\nadversarial networks.",
          "link": "http://arxiv.org/abs/2204.11418",
          "publishedOn": "2023-08-26T00:39:47.685Z",
          "wordCount": 683,
          "title": "Riemannian Hamiltonian methods for min-max optimization on manifolds. (arXiv:2204.11418v3 [math.OC] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.12562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1\">Kwan Ho Ryan Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chattopadhyay_A/0/1/0/all/0/1\">Aditya Chattopadhyay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haeffele_B/0/1/0/all/0/1\">Benjamin David Haeffele</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidal_R/0/1/0/all/0/1\">Rene Vidal</a>",
          "description": "Variational Information Pursuit (V-IP) is a framework for making\ninterpretable predictions by design by sequentially selecting a short chain of\ntask-relevant, user-defined and interpretable queries about the data that are\nmost informative for the task. While this allows for built-in interpretability\nin predictive models, applying V-IP to any task requires data samples with\ndense concept-labeling by domain experts, limiting the application of V-IP to\nsmall-scale tasks where manual data annotation is feasible. In this work, we\nextend the V-IP framework with Foundational Models (FMs) to address this\nlimitation. More specifically, we use a two-step process, by first leveraging\nLarge Language Models (LLMs) to generate a sufficiently large candidate set of\ntask-relevant interpretable concepts, then using Large Multimodal Models to\nannotate each data sample by semantic similarity with each concept in the\ngenerated concept set. While other interpretable-by-design frameworks such as\nConcept Bottleneck Models (CBMs) require an additional step of removing\nrepetitive and non-discriminative concepts to have good interpretability and\ntest performance, we mathematically and empirically justify that, with a\nsufficiently informative and task-relevant query (concept) set, the proposed\nFM+V-IP method does not require any type of concept filtering. In addition, we\nshow that FM+V-IP with LLM generated concepts can achieve better test\nperformance than V-IP with human annotated concepts, demonstrating the\neffectiveness of LLMs at generating efficient query sets. Finally, when\ncompared to other interpretable-by-design frameworks such as CBMs, FM+V-IP can\nachieve competitive test performance using fewer number of concepts/queries in\nboth cases with filtered or unfiltered concept sets.",
          "link": "http://arxiv.org/abs/2308.12562",
          "publishedOn": "2023-08-26T00:39:47.678Z",
          "wordCount": 780,
          "title": "Variational Information Pursuit with Large Language and Multimodal Models for Interpretable Predictions. (arXiv:2308.12562v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2008.09312",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zuo_S/0/1/0/all/0/1\">Shiliang Zuo</a>",
          "description": "I study a stochastic multi-arm bandit problem where rewards are subject to\nadversarial corruption. I propose a novel attack strategy that manipulates a\nlearner employing the UCB algorithm into pulling some non-optimal target arm $T\n- o(T)$ times with a cumulative cost that scales as $\\widehat{O}(\\sqrt{\\log\nT})$, where $T$ is the number of rounds. I also prove the first lower bound on\nthe cumulative attack cost. The lower bound matches the upper bound up to\n$O(\\log \\log T)$ factors, showing the proposed attack strategy to be near\noptimal.",
          "link": "http://arxiv.org/abs/2008.09312",
          "publishedOn": "2023-08-26T00:39:44.626Z",
          "wordCount": 646,
          "title": "Near Optimal Adversarial Attack on UCB Bandits. (arXiv:2008.09312v6 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.12680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Hanchi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_D/0/1/0/all/0/1\">Deheng Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>",
          "description": "We propose a novel master-slave architecture to solve the top-$K$\ncombinatorial multi-armed bandits problem with non-linear bandit feedback and\ndiversity constraints, which, to the best of our knowledge, is the first\ncombinatorial bandits setting considering diversity constraints under bandit\nfeedback. Specifically, to efficiently explore the combinatorial and\nconstrained action space, we introduce six slave models with distinguished\nmerits to generate diversified samples well balancing rewards and constraints\nas well as efficiency. Moreover, we propose teacher learning based optimization\nand the policy co-training technique to boost the performance of the multiple\nslave models. The master model then collects the elite samples provided by the\nslave models and selects the best sample estimated by a neural contextual\nUCB-based network to make a decision with a trade-off between exploration and\nexploitation. Thanks to the elaborate design of slave models, the co-training\nmechanism among slave models, and the novel interactions between the master and\nslave models, our approach significantly surpasses existing state-of-the-art\nalgorithms in both synthetic and real datasets for recommendation tasks. The\ncode is available at:\n\\url{https://github.com/huanghanchi/Master-slave-Algorithm-for-Top-K-Bandits}.",
          "link": "http://arxiv.org/abs/2308.12680",
          "publishedOn": "2023-08-26T00:39:44.620Z",
          "wordCount": 728,
          "title": "Master-slave Deep Architecture for Top-K Multi-armed Bandits with Non-linear Bandit Feedback and Diversity Constraints. (arXiv:2308.12680v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2211.11613",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Gagnon_P/0/1/0/all/0/1\">Philippe Gagnon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Maire_F/0/1/0/all/0/1\">Florian Maire</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zanella_G/0/1/0/all/0/1\">Giacomo Zanella</a>",
          "description": "Multiple-try Metropolis (MTM) is a popular Markov chain Monte Carlo method\nwith the appealing feature of being amenable to parallel computing. At each\niteration, it samples several candidates for the next state of the Markov chain\nand randomly selects one of them based on a weight function. The canonical\nweight function is proportional to the target density. We show both\ntheoretically and empirically that this weight function induces pathological\nbehaviours in high dimensions, especially during the convergence phase. We\npropose to instead use weight functions akin to the locally-balanced proposal\ndistributions of Zanella (2020), thus yielding MTM algorithms that do not\nexhibit those pathological behaviours. To theoretically analyse these\nalgorithms, we study the high-dimensional performance of ideal schemes that can\nbe thought of as MTM algorithms which sample an infinite number of candidates\nat each iteration, as well as the discrepancy between such schemes and the MTM\nalgorithms which sample a finite number of candidates. Our analysis unveils a\nstrong distinction between the convergence and stationary phases: in the\nformer, local balancing is crucial and effective to achieve fast convergence,\nwhile in the latter, the canonical and novel weight functions yield similar\nperformance. Numerical experiments include an application in precision medicine\ninvolving a computationally-expensive forward model, which makes the use of\nparallel computing within MTM iterations beneficial.",
          "link": "http://arxiv.org/abs/2211.11613",
          "publishedOn": "2023-08-26T00:39:44.613Z",
          "wordCount": 864,
          "title": "Improving multiple-try Metropolis with local balancing. (arXiv:2211.11613v2 [stat.CO] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.12635",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Orosz_G/0/1/0/all/0/1\">Gy&#xf6;rgy Orosz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szabo_G/0/1/0/all/0/1\">Gerg&#x151; Szab&#xf3;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berkecz_P/0/1/0/all/0/1\">P&#xe9;ter Berkecz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szanto_Z/0/1/0/all/0/1\">Zsolt Sz&#xe1;nt&#xf3;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farkas_R/0/1/0/all/0/1\">Rich&#xe1;rd Farkas</a>",
          "description": "This paper presents a set of industrial-grade text processing models for\nHungarian that achieve near state-of-the-art performance while balancing\nresource efficiency and accuracy. Models have been implemented in the spaCy\nframework, extending the HuSpaCy toolkit with several improvements to its\narchitecture. Compared to existing NLP tools for Hungarian, all of our\npipelines feature all basic text processing steps including tokenization,\nsentence-boundary detection, part-of-speech tagging, morphological feature\ntagging, lemmatization, dependency parsing and named entity recognition with\nhigh accuracy and throughput. We thoroughly evaluated the proposed\nenhancements, compared the pipelines with state-of-the-art tools and\ndemonstrated the competitive performance of the new models in all text\npreprocessing steps. All experiments are reproducible and the pipelines are\nfreely available under a permissive license.",
          "link": "http://arxiv.org/abs/2308.12635",
          "publishedOn": "2023-08-26T00:39:44.591Z",
          "wordCount": 677,
          "title": "Advancing Hungarian Text Processing with HuSpaCy: Efficient and Accurate NLP Pipelines. (arXiv:2308.12635v1 [cs.CL])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.12925",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Renz_P/0/1/0/all/0/1\">Philipp Renz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cutajar_K/0/1/0/all/0/1\">Kurt Cutajar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Twomey_N/0/1/0/all/0/1\">Niall Twomey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheung_G/0/1/0/all/0/1\">Gavin K. C. Cheung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1\">Hanting Xie</a>",
          "description": "Low-count time series describe sparse or intermittent events, which are\nprevalent in large-scale online platforms that capture and monitor diverse data\ntypes. Several distinct challenges surface when modelling low-count time\nseries, particularly low signal-to-noise ratios (when anomaly signatures are\nprovably undetectable), and non-uniform performance (when average metrics are\nnot representative of local behaviour). The time series anomaly detection\ncommunity currently lacks explicit tooling and processes to model and reliably\ndetect anomalies in these settings. We address this gap by introducing a novel\ngenerative procedure for creating benchmark datasets comprising of low-count\ntime series with anomalous segments. Via a mixture of theoretical and empirical\nanalysis, our work explains how widely-used algorithms struggle with the\ndistribution overlap between normal and anomalous segments. In order to\nmitigate this shortcoming, we then leverage our findings to demonstrate how\nanomaly score smoothing consistently improves performance. The practical\nutility of our analysis and recommendation is validated on a real-world dataset\ncontaining sales data for retail stores.",
          "link": "http://arxiv.org/abs/2308.12925",
          "publishedOn": "2023-08-26T00:39:44.546Z",
          "wordCount": 682,
          "title": "Low-count Time Series Anomaly Detection. (arXiv:2308.12925v1 [cs.LG])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2209.10634",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Lipshutz_D/0/1/0/all/0/1\">David Lipshutz</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Pehlevan_C/0/1/0/all/0/1\">Cengiz Pehlevan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chklovskii_D/0/1/0/all/0/1\">Dmitri B. Chklovskii</a>",
          "description": "Early sensory systems in the brain rapidly adapt to fluctuating input\nstatistics, which requires recurrent communication between neurons.\nMechanistically, such recurrent communication is often indirect and mediated by\nlocal interneurons. In this work, we explore the computational benefits of\nmediating recurrent communication via interneurons compared with direct\nrecurrent connections. To this end, we consider two mathematically tractable\nrecurrent linear neural networks that statistically whiten their inputs -- one\nwith direct recurrent connections and the other with interneurons that mediate\nrecurrent communication. By analyzing the corresponding continuous synaptic\ndynamics and numerically simulating the networks, we show that the network with\ninterneurons is more robust to initialization than the network with direct\nrecurrent connections in the sense that the convergence time for the synaptic\ndynamics in the network with interneurons (resp. direct recurrent connections)\nscales logarithmically (resp. linearly) with the spectrum of their\ninitialization. Our results suggest that interneurons are computationally\nuseful for rapid adaptation to changing input statistics. Interestingly, the\nnetwork with interneurons is an overparameterized solution of the whitening\nobjective for the network with direct recurrent connections, so our results can\nbe viewed as a recurrent linear neural network analogue of the implicit\nacceleration phenomenon observed in overparameterized feedforward linear neural\nnetworks.",
          "link": "http://arxiv.org/abs/2209.10634",
          "publishedOn": "2023-08-26T00:39:44.520Z",
          "wordCount": 747,
          "title": "Interneurons accelerate learning dynamics in recurrent neural networks for statistical adaptation. (arXiv:2209.10634v2 [q-bio.NC] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.12044",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amakor_A/0/1/0/all/0/1\">Augustina C. Amakor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonntag_K/0/1/0/all/0/1\">Konstantin Sonntag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peitz_S/0/1/0/all/0/1\">Sebastian Peitz</a>",
          "description": "Sparsity is a highly desired feature in deep neural networks (DNNs) since it\nensures numerical efficiency, improves the interpretability of models (due to\nthe smaller number of relevant features), and robustness. In machine learning\napproaches based on linear models, it is well known that there exists a\nconnecting path between the sparsest solution in terms of the $\\ell^1$ norm\n(i.e., zero weights) and the non-regularized solution, which is called the\nregularization path. Very recently, there was a first attempt to extend the\nconcept of regularization paths to DNNs by means of treating the empirical loss\nand sparsity ($\\ell^1$ norm) as two conflicting criteria and solving the\nresulting multiobjective optimization problem. However, due to the\nnon-smoothness of the $\\ell^1$ norm and the high number of parameters, this\napproach is not very efficient from a computational perspective. To overcome\nthis limitation, we present an algorithm that allows for the approximation of\nthe entire Pareto front for the above-mentioned objectives in a very efficient\nmanner. We present numerical examples using both deterministic and stochastic\ngradients. We furthermore demonstrate that knowledge of the regularization path\nallows for a well-generalizing network parametrization.",
          "link": "http://arxiv.org/abs/2308.12044",
          "publishedOn": "2023-08-26T00:39:44.513Z",
          "wordCount": 748,
          "title": "A multiobjective continuation method to compute the regularization path of deep neural networks. (arXiv:2308.12044v2 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2205.04701",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haoxuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chunyuan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1\">Peng Wu</a>",
          "description": "In recommender systems, users always choose the favorite items to rate, which\nleads to data missing not at random and poses a great challenge for unbiased\nevaluation and learning of prediction models. Currently, the doubly robust (DR)\nmethods have been widely studied and demonstrate superior performance. However,\nin this paper, we show that DR methods are unstable and have unbounded bias,\nvariance, and generalization bounds to extremely small propensities. Moreover,\nthe fact that DR relies more on extrapolation will lead to suboptimal\nperformance. To address the above limitations while retaining double\nrobustness, we propose a stabilized doubly robust (StableDR) learning approach\nwith a weaker reliance on extrapolation. Theoretical analysis shows that\nStableDR has bounded bias, variance, and generalization error bound\nsimultaneously under inaccurate imputed errors and arbitrarily small\npropensities. In addition, we propose a novel learning approach for StableDR\nthat updates the imputation, propensity, and prediction models cyclically,\nachieving more stable and accurate predictions. Extensive experiments show that\nour approaches significantly outperform the existing methods.",
          "link": "http://arxiv.org/abs/2205.04701",
          "publishedOn": "2023-08-26T00:39:44.495Z",
          "wordCount": 720,
          "title": "StableDR: Stabilized Doubly Robust Learning for Recommendation on Data Missing Not at Random. (arXiv:2205.04701v3 [cs.LG] UPDATED)",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        },
        {
          "id": "http://arxiv.org/abs/2308.12767",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bendada_W/0/1/0/all/0/1\">Walid Bendada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salha_Galvan_G/0/1/0/all/0/1\">Guillaume Salha-Galvan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hennequin_R/0/1/0/all/0/1\">Romain Hennequin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouabca_T/0/1/0/all/0/1\">Thomas Bouab&#xe7;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cazenave_T/0/1/0/all/0/1\">Tristan Cazenave</a>",
          "description": "A prevalent practice in recommender systems consists of averaging item\nembeddings to represent users or higher-level concepts in the same embedding\nspace. This paper investigates the relevance of such a practice. For this\npurpose, we propose an expected precision score, designed to measure the\nconsistency of an average embedding relative to the items used for its\nconstruction. We subsequently analyze the mathematical expression of this score\nin a theoretical setting with specific assumptions, as well as its empirical\nbehavior on real-world data from music streaming services. Our results\nemphasize that real-world averages are less consistent for recommendation,\nwhich paves the way for future research to better align real-world embeddings\nwith assumptions from our theoretical setting.",
          "link": "http://arxiv.org/abs/2308.12767",
          "publishedOn": "2023-08-26T00:39:44.471Z",
          "wordCount": 649,
          "title": "On the Consistency of Average Embeddings for Item Recommendation. (arXiv:2308.12767v1 [cs.IR])",
          "imageUrl": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
        }
      ]
    },
    {
      "title": "Machine Learning",
      "feedUrl": "https://www.reddit.com/r/MachineLearning/.rss",
      "siteUrl": "https://www.reddit.com/r/MachineLearning/",
      "articles": [
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16n6rb5/d_are_there_any_good_math_datasets_for_training/",
          "author": null,
          "description": "I've seen Allen AI's Lila Dataset, and I want to use this for a small model, to turn math to code. However, I dont think a small dataset in 300k rows is enough. Does anyone know of any bigger, similar datasets?\n    submitted by    /u/vatsadev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16n6rb5/d_are_there_any_good_math_datasets_for_training/",
          "publishedOn": "2023-09-20T00:13:48.000Z",
          "wordCount": 2574,
          "title": "[D] Are there any good math Datasets for Training small models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16n5r3x/p_optimizer_that_makes_cnns_learn_in_fewer/",
          "author": null,
          "description": "Hi all.\n I have been tinkering with a project to get quicker learning for CNNs. \n The idea came after reading the SDProp paper. Algorithms using adaptive learning rate can be interpeted as muliplying the gradient(with or without momentum) with the inverse square-root of the covariance matrix. Using a diagonal estimate of the covariance matrix.\n Which begs the question: what happens if we use a fuller estimate? I chose to include covariances between the elements of convolutional filters. I.e. a conv.weight of size [n_out,n_in,5,5] needs a tensor of size [n_out,n_int,25,25] to store its contribution to the covariance matrix.\n for 3x3 filters and 5x5 filters, torch.linalg.eigh could be used to calculate the square root of the covariance matrices. For 7x7, I used newtons method to approximate the square root.\n In the figure below are some results for a 6 layer CNN on CIFAR 100. Huge gains iteration for iteration. But is it quicker? Not a lot. A bit for the smaller 3x3 filter. More optimizations could still be made. And it will obviously depend on network architecture and computer hardware. \n I'm sure there could be some use-cases. The computation of the square-root calculations is invariant to batch_size and image_size (unless number of filters also is increased).\n If anyone is interested I can also link to my torch implementation of the optimizer, once I get it up on github.\n Not sure if this, or something like it, has been done before? Would love to have some papers linked if so...\n https://preview.redd.it/kyy0ogr0qapb1.jpg?width=714&format=pjpg&auto=webp&s=96ac499fb8ab35ce13e7c59bbe3dbc94ba275b9c\n https://preview.redd.it/p52zllr0qapb1.jpg?width=342&format=pjpg&auto=webp&s=8663a9c3c782d192b16289a735b53da6a8d29c47\n    submitted by    /u/maka89  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16n5r3x/p_optimizer_that_makes_cnns_learn_in_fewer/",
          "publishedOn": "2023-09-19T23:29:00.000Z",
          "wordCount": 2778,
          "title": "[P] Optimizer that makes CNNs learn in fewer iterations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16n4bed/d_help_with_peft_using_lora/",
          "author": null,
          "description": "Can someone provide like a step by step example notebook of how to use LORA for peft. I saw too many videos and articles online and Im really confused rn.\n    submitted by    /u/HazSylvia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16n4bed/d_help_with_peft_using_lora/",
          "publishedOn": "2023-09-19T22:26:28.000Z",
          "wordCount": 2558,
          "title": "[D] Help with Peft using Lora",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16n4bdn/d_help_with_peft_using_lora/",
          "author": null,
          "description": "Can someone provide like a step by step example notebook of how to use LORA for peft. I saw too many videos and articles online and Im really confused rn.\n    submitted by    /u/HazSylvia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16n4bdn/d_help_with_peft_using_lora/",
          "publishedOn": "2023-09-19T22:26:27.000Z",
          "wordCount": 2558,
          "title": "[D] Help with Peft using Lora",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16n479f/d_optimizing_transformer_architecture_for/",
          "author": null,
          "description": "Hello all,\n I am currently working on a project where my team and I have collected a rich dataset of biomedical sensor data from clinical trials earlier this year. Our aim is to use this sensor data to predict changes in specific biomarkers over time. The data's tensor shape is B,T,F,C, where:\n  \nB = batch size\n T = sequence length\n F = sampled frequencies\n C = features at each frequency\n  \nCurrently, my approach involves flattening this tensor to B,T,−1 and then feeding it to a transformer model. While this has yielded reasonable results, I'm contemplating whether there are more effective ways to prepare the data for the transformer model.\n Here are my specific concerns:\n  \nFlattening the tensor might dilute the information specific to each frequency across various features.\n I could potentially miss the chance to capture frequency-related variations within the features.\n  \nTo address these, I've considered a few options:\n  \nSelf-attention over individual features or frequencies: Although this could be effective, it might make the model too large given my medium-sized dataset.\n Using convolutional layers: Preliminary experiments with this approach have not led to any significant improvements.\n  \nI'm particularly interested in any thoughts on how to make my transformer more receptive to the multi-dimensional nature of my dataset. Increasing the number of attention heads to better accommodate all features is also on the table.\n Does anyone have any insights or can point me to relevant papers or codebases for handling such multi-dimensional data with transformers?\n Thank you for your help!\n    submitted by    /u/BiomedEngineer_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16n479f/d_optimizing_transformer_architecture_for/",
          "publishedOn": "2023-09-19T22:21:26.000Z",
          "wordCount": 2782,
          "title": "[D] Optimizing Transformer Architecture for Multi-Dimensional Sensor Data in Clinical Study",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16n3pc7/learn_from_computer_vision_industry_experts/",
          "author": null,
          "description": "Hi all,\n I think this will be useful for people in this group who are working on computer vision or vision AI applications.\n There's a free online event about vision AI where industry experts from Runway, Pepsi, AWS, and SoftServe will share how they are using CV software in developing their use cases or applications.\n Register here (https://nvda.ws/3t23idp), if you are interested.\n If you have any questions, please leave a comment and I will do my best to respond as soon as possible.\n    submitted by    /u/Designer-Comb-7144  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16n3pc7/learn_from_computer_vision_industry_experts/",
          "publishedOn": "2023-09-19T21:59:15.000Z",
          "wordCount": 2618,
          "title": "Learn From Computer Vision Industry Experts - Runway, Pepsi, AWS, and SoftServe [N]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16n3adf/r_headless_language_models_learning_without/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.08351\n ​\n  \nSelf-supervised pre-training of language models usually consists in predicting probability distributions over extensive token vocabularies. In this study, we propose an innovative method that shifts away from probability prediction and instead focuses on reconstructing input embeddings in a contrastive fashion via Constrastive Weight Tying (CWT). We apply this approach to pretrain Headless Language Models in both monolingual and multilingual contexts. Our method offers practical advantages, substantially reducing training computational requirements by up to 20 times, while simultaneously enhancing downstream performance and data efficiency. We observe a significant +1.6 GLUE score increase and a notable +2.7 LAMBADA accuracy improvement compared to classical LMs within similar compute budgets.\n  \n​\n Comparison of our approach vs. classical MLM within same compute budgets\n The Contrastive Weight Tying approach\n ​\n    submitted by    /u/nthngdy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16n3adf/r_headless_language_models_learning_without/",
          "publishedOn": "2023-09-19T21:40:40.000Z",
          "wordCount": 2657,
          "title": "[R] Headless Language Models: Learning without Predicting with Contrastive Weight Tying",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mzhfb/mini_gaming_pc_project/",
          "author": null,
          "description": "https://www.amazon.com/Gaming-6900HX-Channel-Computers-Desktop/dp/B0CB3JLBQ4/ref=mp_s_a_1_2?crid=LZHUL5EOU6F0&keywords=refurbished+server+with+rtx+gpu&qid=1695146558&sprefix=refurbished+server+with+rtx+gpu%2Caps%2C146&sr=8-2 Would this be suitable to do basic machine learning?\n    submitted by    /u/stoned_chemist_dude  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mzhfb/mini_gaming_pc_project/",
          "publishedOn": "2023-09-19T19:08:05.000Z",
          "wordCount": 2536,
          "title": "Mini gaming pc [Project]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mxztt/n_xwinlm_surpasses_gpt4_has_rlhf_been_worked_out/",
          "author": null,
          "description": "It seems that Alpaca Eval Leaderboard is in the past ...\n Xwin-LM surpasses GPT-4 now:\n https://preview.redd.it/gyzi98nn59pb1.png?width=2205&format=png&auto=webp&s=ca401e603efe521faeeeccde8410d3dbdd6741da\n They also mentioned RLHF \"plays crucial role in the strong performance of Xwin-LM-V0.1 release\"...\n https://preview.redd.it/20sjx73r59pb1.png?width=1047&format=png&auto=webp&s=2255fc652e43674515882f01c0708369fdef56a4\n Are we seeing open source community finally work out how to do RLHF for LLMs???\n    submitted by    /u/llm_nerd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mxztt/n_xwinlm_surpasses_gpt4_has_rlhf_been_worked_out/",
          "publishedOn": "2023-09-19T18:07:14.000Z",
          "wordCount": 2580,
          "title": "[N] Xwin-LM surpasses GPT-4 ??? Has RLHF been worked out by open source community???",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mwy2p/d_c_for_ml/",
          "author": null,
          "description": "Hi I wanted to learn ML with C++, I've already done some ML stuff in python, but I wanted to challenge myself by using C++\n I hear from some people that I won't get anything from it if want to be serious within ML - which I'm not entirely sure I want to\n Are they right? Should I rather stick with python for ML?\n    submitted by    /u/Potential_Wealth_830  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mwy2p/d_c_for_ml/",
          "publishedOn": "2023-09-19T17:24:24.000Z",
          "wordCount": 2590,
          "title": "[D] C++ for ML?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mwua6/d_spam_detection/",
          "author": null,
          "description": "Hi!\n Let me preface this by saying that I am not well-versed in the ML/AI literature. Please excuse my ignorance.\n I am trying to create a system to detect whether some given data is spam or not. Is there a good, out-of-the-box solution for this? I imagine there would be. I am currently using heuristics but I'm wondering if there is a better, ML-y solution.\n My ideal solution would have the following attributes:\n  \nSimple\n Open-source\n Very cheap to test whether something is spam (less than $0.00001 per test)\n Very fast to test (less than 50ms per test)\n Quick to \"figure out\" what is spam and what is not (less than 100,000 labeled data)\n Does not require a lot of set-up or up-keep (less than 5 days set up; less than 1 hr up-keep per month)\n  \nIt doesn't have to be perfect. I'm just looking to set up something quickly for now and gauge it vs heuristics.\n Thank you.\n ---\n Edit: To clarify, I'm looking for something I can ideally build myself with open source software. And not specifically email.\n Just looking for the right direction. Names of OSS, techniques, etc.\n    submitted by    /u/Acrobatic-You-3279  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mwua6/d_spam_detection/",
          "publishedOn": "2023-09-19T17:20:00.000Z",
          "wordCount": 2715,
          "title": "[D] Spam Detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mvnf7/d_best_python_aimldl_learningpractice_material/",
          "author": null,
          "description": "I’m in search of a good textbook or something that will show me how to use python to implement machine learning. I would seriously appreciate any type of helpful guide that teaches ML and deep learning using python. Here’s a little about me and my experience:\n Graduated under grad with Bachelor’s in CS. In school took a ton of stats, ai classes, algorithms classes, data science and linear algebra and did well but my school didn’t really use python or do a ton of programming for hw or exams. (Data science was the one class that used python)\n My programming is pretty good nonetheless. I currently work as a full stack devops engineer for a cybersecurity startup and regularly work with python, Django MySQL, etc on the backend and JavaScript and various frontend frameworks for the front end. \n I really appreciate yall’s help.\n In particular I’m looking for good ai/ml/deep learning books that teach concepts and also teach with python code and have some coding projects. \n Thank you!\n    submitted by    /u/hydrated-terpman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mvnf7/d_best_python_aimldl_learningpractice_material/",
          "publishedOn": "2023-09-19T16:31:33.000Z",
          "wordCount": 2696,
          "title": "[D] Best python AI/ML/DL learning/practice material?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mvmkv/d_what_gpu_to_buy_for_faster_llm_training/",
          "author": null,
          "description": "I need some advice about what hardware to buy in order to build an ML / DL workstation for home private experiments, i intend to play with different LLM models, train some and try to tweak the way the models are built and understand what impact training speeds, so i will have to train, learn the results, tweak the model / data / algorithms and train again...\n i intend to use large data samples,\n due to board limitations (ASRock Taichi X399 TR4, CPU: AMD Threadripper 1950x),\n i can either buy:\n 2 x nVidia Tesla T4 (16G GDDR6 / 2560 CUDA / 0.585 GHz / ~800$)\n -- or --\n 2 x nVidia Tesla M10 (4 x 8G GDDR5 / 2560 CUDA / 1.03 GHz / ~780$)\n -- or --\n 4 x nVidia Tesla P40 (24G GDDR5X / 3840 CUDA / 3.5 GHz / ~120$)\n -- or --\n 4 x nVidia Tesla K80 (2 x 12G GDDR5 / 4992 CUDA / 2.7 GHz / ~200$)\n -- or --\n 1 x nVidia RTX 4080 (16G GDDR6X / 9728 CUDA / 2.51 GHz / ~1450$)\n i know that i will need to air vent the Tesla models, the question is what is faster for training time (i have read all the Tflops / OPS / int / 16float / 32float / 64float ... i got to admit it is all very confusing)\n what would you do and for what reason ?\n any advice will be appreciated\n    submitted by    /u/Particular_Flower_12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mvmkv/d_what_gpu_to_buy_for_faster_llm_training/",
          "publishedOn": "2023-09-19T16:30:39.000Z",
          "wordCount": 2774,
          "title": "[D] What GPU to buy for faster LLM training ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mvanm/dalternative_replacement_for_system76_thelio/",
          "author": null,
          "description": "Hello everyone! Our group was planning on purchasing a PC that will be mainly used for running intensive ML algorithms. Had decided on a custom Thelio Massive from System 76, but it seems like they currently don't have it in stock anymore. Looking for an already built-alternative that might serve our purposes (can't build it ourselves due to dept regulations)! and was hoping maybe someone has any suggestions (has to be intel).\n CPU #1: 2nd Gen Intel Xeon Gold 6230R CPU#1 Memory: 256GB Quad Channel DDR4 at 2933Mhz (4X64GB) CPU#2: 2nd Gen Intel Xeon Gold 6230R CPU#2 Memory: None OS Drive: 8TB PCIe Gen 4 3300MB R 2900MB W Graphics: NVIDIA GeForce RTX 4090 Power Supply: 1650W\n Any help would be appreciated!\n    submitted by    /u/Chiski  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mvanm/dalternative_replacement_for_system76_thelio/",
          "publishedOn": "2023-09-19T16:17:22.000Z",
          "wordCount": 2652,
          "title": "[D]Alternative replacement for System76 Thelio Massive (ML PC)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mtmc6/r_efficientvit_lightweight_multiscale_attention/",
          "author": null,
          "description": "Using relu attention (inspired by Transformers are RNNs) and some convolution tricks to get multiscale attention, they're able to get SOTA semseg performance with MUCH faster inference on embedded hardware (e.g. CPUs, low end GPUs) than previous ViTs or EfficientNets.\n    submitted by    /u/say_wot_again  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mtmc6/r_efficientvit_lightweight_multiscale_attention/",
          "publishedOn": "2023-09-19T15:11:00.000Z",
          "wordCount": 2584,
          "title": "[R] EfficientViT: Lightweight Multi-Scale Attention for On-Device Semantic Segmentation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mthsy/r_generating_and_imputing_tabular_data_via/",
          "author": null,
          "description": "submitted by    /u/AlexiaJM  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mthsy/r_generating_and_imputing_tabular_data_via/",
          "publishedOn": "2023-09-19T15:05:58.000Z",
          "wordCount": 2546,
          "title": "[R] Generating and Imputing Tabular Data via Diffusion and Flow-based Gradient-Boosted Trees (XGBoost)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16msx5x/research_binaural_source_seperation_casual_online/",
          "author": null,
          "description": "Just a shout out to any of you ML brains as Linux really could do with a code optimised source separation maybe a DUET like alg/nn, that has relatively low computional cost?\n Any of you guys up for the challenge.\n I say duet as in the 80/20 rule of voice input where home automation is a need generally there are only 2 noise sources of distinct DOA (media noise / command).\n The math is a bit beyond my paygrade and likely so is the optimised c/rust code but have this gut feeling for the data/signal scientists out there this is actually not that complex but for some reason is overlooked. \n    submitted by    /u/rolyantrauts  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16msx5x/research_binaural_source_seperation_casual_online/",
          "publishedOn": "2023-09-19T14:43:28.000Z",
          "wordCount": 2636,
          "title": "[research] Binaural source seperation (casual / online)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16msexv/3090_investment_vs_cloud_d/",
          "author": null,
          "description": "Hi everyone,\n I was wondering if I could get some guidance. I currently own an RTX 2060, but I cannot do some of the fun stuff such as fine tuning LLMs. I’m pursuing my masters focusing on Speech Recognition and I also work as an AI developer. Also, I play games every now and then.\n I’m getting offered a 3090 for around 700 usd. However, I have to rebuild my entire PC which will end up costing 2-2.5K. I’m from Costa Rica so my KWh is around 0.23 usd. For me seems like a big investment, im not sure if im getting the desired returns.\n I was thinking about using cloud instances for my experiments. However, lambda labs is not yet available in my country. I’m not sure if there are any other options worthwhile considering. \n Thanks :)\n    submitted by    /u/Beginning_Kick756  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16msexv/3090_investment_vs_cloud_d/",
          "publishedOn": "2023-09-19T14:25:12.000Z",
          "wordCount": 2665,
          "title": "3090 Investment vs Cloud [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mrndn/hybrid_nets_d/",
          "author": null,
          "description": "Is it hypothetically possible to create hybrid nets that make use of any combination of types of architecture?\n    submitted by    /u/ShadrachOsiris  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mrndn/hybrid_nets_d/",
          "publishedOn": "2023-09-19T13:53:34.000Z",
          "wordCount": 2543,
          "title": "Hybrid Nets. [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mp275/r_research_directions_for_tracking_and_counting/",
          "author": null,
          "description": "Hi r/machinelearning community,\n I'm currently working on a project where I need to track and count specific features of objects using multiple monocular views with available intrinsic and extrinsic parameters. As an example, I'm interested in detecting and counting different graffiti instances in images of a kiosk.\n ​\n I've already tried various tracking algorithms, but they have struggled with the task due to the significant changes in perspective across the views. It has become apparent that simply relying on tracking without considering the camera positions is insufficient for accurate results. Therefore, I'm now exploring methods that take into account information about the camera positions and potentially use this data to improve feature tracking and counting. \n ​\n If you have any knowledge of such methods, oresearch directions or if you're aware of resources, papers, or code implementations that tackle similar problems, I would greatly appreciate your insights and recommendations. Additionally, if you have any tips or best practices for handling such tasks in the context of machine learning, I'd love to hear them. \n ​\n Thank you in advance for your help!\n    submitted by    /u/aiazar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mp275/r_research_directions_for_tracking_and_counting/",
          "publishedOn": "2023-09-19T12:00:51.000Z",
          "wordCount": 2712,
          "title": "[R] Research directions for Tracking and Counting Specific Features in Multiple Monocular Views",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mmi5b/r_exponentially_faster_feedforward_networks/",
          "author": null,
          "description": "TL;DR: Almost like your feedforward networks, shown to be up to 220x faster at inference time (depending on width) thanks to the regionalization of the input space.\n Paper: https://arxiv.org/abs/2308.14711\n GitHub: https://github.com/pbelcak/fastfeedforward\n PyPI: pip install fastfeedforward\n Abstract:\n  \nWe break the linear link between the layer size and its inference cost by introducing the fast feedforward (FFF) architecture, a log-time alternative to feedforward networks. We demonstrate that FFFs are up to 220x faster than feedforward networks, up to 6x faster than mixture-of-experts networks, and exhibit better training properties than mixtures of experts thanks to noiseless conditional execution. Pushing FFFs to the limit, we show that they can use as little as 1% of layer neurons for inference in vision transformers while preserving 94.2% of predictive performance.\n  \nFast feedforward networks can be used anywhere where feedforward and mixture-of-experts networks are used, delivering a significant speedup.\n ​\n    submitted by    /u/lexected  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mmi5b/r_exponentially_faster_feedforward_networks/",
          "publishedOn": "2023-09-19T09:39:46.000Z",
          "wordCount": 2669,
          "title": "[R] Exponentially Faster Feedforward Networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ml3po/r_culturax_a_cleaned_enormous_and_multilingual/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.09400\n Hugging Face datasets: https://huggingface.co/datasets/uonlp/CulturaX\n Abstract:\n  \nThe driving factors behind the development of large language models (LLMs) with impressive learning capabilities are their colossal model sizes and extensive training datasets. Along with the progress in natural language processing, LLMs have been frequently made accessible to the public to foster deeper investigation and applications. However, when it comes to training datasets for these LLMs, especially the recent state-of-the-art models, they are often not fully disclosed. Creating training data for high-performing LLMs involves extensive cleaning and deduplication to ensure the necessary level of quality. The lack of transparency for training data has thus hampered research on attributing and addressing hallucination and bias issues in LLMs, hindering replication efforts and further advancements in the community. These challenges become even more pronounced in multilingual learning scenarios, where the available multilingual text datasets are often inadequately collected and cleaned. Consequently, there is a lack of open-source and readily usable dataset to effectively train LLMs in multiple languages. To overcome this issue, we present CulturaX, a substantial multilingual dataset with 6.3 trillion tokens in 167 languages, tailored for LLM development. Our dataset undergoes meticulous cleaning and deduplication through a rigorous pipeline of multiple stages to accomplish the best quality for model training, including language identification, URL-based filtering, metric-based cleaning, document refinement, and data deduplication. CulturaX is fully released to the public in HuggingFace to facilitate research and advancements in multilingual LLMs: this https URL. \n  \n​\n https://preview.redd.it/3u5dddpv66pb1.png?width=834&format=png&auto=webp&s=780b590cf621b548c525ed15305b091246c5414c\n    submitted by    /u/InterviewIntrepid889  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ml3po/r_culturax_a_cleaned_enormous_and_multilingual/",
          "publishedOn": "2023-09-19T08:10:29.000Z",
          "wordCount": 2780,
          "title": "[R] CulturaX: A Cleaned, Enormous, and Multilingual Dataset for Large Language Models in 167 Languages - 6.3 trillion tokens",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mjr2m/d_representation_learning_with_regression_task/",
          "author": null,
          "description": "I searched around, it seems there is limited attention to regression task for representation learning.\n I assume it is because for both vision and language data (the most popular modality), MAE is the more appliable, if not better, method than the supervised contrastive learning approach. But I am working on data that is:\n  \ndifficult to design a sensible augmentation method for self-supervised training.\n Limited in size to support an autoencoder model.\n The target is continuous, and, to my knowledge, hard to transfer into class label.\n  \nCan anyone suggest some related paper?\n    submitted by    /u/AWEsoMe-Cat1231  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mjr2m/d_representation_learning_with_regression_task/",
          "publishedOn": "2023-09-19T06:46:15.000Z",
          "wordCount": 2619,
          "title": "[D] Representation learning with regression task",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mc1pa/p_openjourney_xl_finetuned_sdxl_on_midjourney_v5/",
          "author": null,
          "description": "You can find more info here, and the model is still training:\n https://www.mystic.ai/paulh/open-journey-xl:latest/play\n tldr; SDXL was finetuned on 8x H100 GPUs on the Midjourney v5 dataset, only including the upscaled images which is a sub-portion of the dataset.\n Some outputs:\n ​\n https://preview.redd.it/m6r2pkdyw3pb1.jpg?width=1024&format=pjpg&auto=webp&s=4f12a7dfd5c65e4eb8476b8f3c2dc4f795817f56\n https://preview.redd.it/dc02jyu4w3pb1.jpg?width=1024&format=pjpg&auto=webp&s=df93b74c774d44a74a05d929f7ab4b17c487f24f\n https://preview.redd.it/tt5kfyu4w3pb1.jpg?width=1024&format=pjpg&auto=webp&s=ed8cc9f99227c2bb5e824a828ae1c5cb2626f54e\n ​\n https://preview.redd.it/rf00fzu4w3pb1.jpg?width=1024&format=pjpg&auto=webp&s=3b3e99dbc2d14183b5b2a2131c6f991fc60eca88\n ​\n    submitted by    /u/paulcjh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mc1pa/p_openjourney_xl_finetuned_sdxl_on_midjourney_v5/",
          "publishedOn": "2023-09-19T00:17:32.000Z",
          "wordCount": 2597,
          "title": "[P] OpenJourney XL – Finetuned SDXL on Midjourney v5 Dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16mas5h/d_fsdp_model_in_each_process_is_different/",
          "author": null,
          "description": "Hey Guys,\n I'm training a large model using FSDP. I'm loading the models on each rank like this:\n ​\n https://preview.redd.it/khoquvxzk3pb1.png?width=1766&format=png&auto=webp&s=1f5acd75600d9a87212ca37e70695edfb0cc75d0\n what is weird is that right before doing the first inference on each rank, I'm summing up the weights of the model and to my surprise, they are all different across each rank. Completely different!\n ​\n What am I doing wrong here?\n    submitted by    /u/hassanzadeh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16mas5h/d_fsdp_model_in_each_process_is_different/",
          "publishedOn": "2023-09-18T23:22:05.000Z",
          "wordCount": 2614,
          "title": "[D] FSDP: model in each process is different",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16m9sru/curious_what_people_use_for_their_ml_workflow_on/",
          "author": null,
          "description": "View Poll\n    submitted by    /u/cstein123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16m9sru/curious_what_people_use_for_their_ml_workflow_on/",
          "publishedOn": "2023-09-18T22:41:34.000Z",
          "wordCount": 2566,
          "title": "Curious what people use for their ML workflow on cloud platforms? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16m85rq/d_seeking_guidance_on_choosing_a_phd_topic_in/",
          "author": null,
          "description": "Hello fellow researchers! I'm in the exciting yet challenging phase of choosing a PhD topic in the realm of meta-learning optimization, and I could use some advice and insights.\n I've extensively researched existing meta-learning optimization algorithms like MAML and its various adaptations. I need advice and guidance on the following topics:\n  \nFirst I want to implement and compare 8-10 state-of-the-art meta-learning methods on benchmark datasets. This would involve in-depth simulation and performance evaluations to provide a comprehensive understanding of their strengths and weaknesses. Could you please guide me here if there are review papers which implement and compare different algorithms. \n \nThen I want to delve into developing a novel optimization algorithm that considers the curvature of loss functions. The idea here is to enhance the performance of existing meta-learning techniques by leveraging insights from the loss landscape.\n \nFurther, I'm considering exploring new loss functions or new improvements to loss functions tailored to the context of meta-learning. These could potentially lead to improvements in the learning process and generalization capabilities of meta-learning models.\n \n I'm reaching out to the community to gather opinions, suggestions, or any insights you might have. If you've worked in meta-learning or optimization, your experiences and advice would be invaluable in helping me choose the right direction for my PhD research. Thank you in advance for your guidance!\n    submitted by    /u/Loose_Foundation5990  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16m85rq/d_seeking_guidance_on_choosing_a_phd_topic_in/",
          "publishedOn": "2023-09-18T21:37:11.000Z",
          "wordCount": 2778,
          "title": "[D] Seeking Guidance on Choosing a PhD Topic in Meta-Learning Optimization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16m43o6/p_i_used_bayesian_statistics_to_find_the_best/",
          "author": null,
          "description": "https://preview.redd.it/86js8jroa2pb1.png?width=1464&format=png&auto=webp&s=7ce10494b5a77fd5c73a41322feefbf7e1f16504\n Hello!\n I thought people on this subreddit might be interested in how I went about inferring Zonai device draw chances for each dispenser in The Legend of Zelda: Tears of the Kingdom.\n In this Switch game there are devices that can be glued together to create different machines. For instance, you can make a snowmobile from a fan, sled, and steering stick.\n There are dispensers that dispense 3-6 of about 30 or so possible devices when you feed it a construct horn (dropped by defeated robot enemies) or a regular (also dropped from defeated enemies) or large Zonai charge (Found in certain chests, dropped by certain boss enemies, obtained from completing certain challenges, etc…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16m43o6/p_i_used_bayesian_statistics_to_find_the_best/",
          "publishedOn": "2023-09-18T19:02:05.000Z",
          "wordCount": 3008,
          "title": "[P] I used Bayesian statistics to find the best dispensers for every Zonai device in The Legend of Zelda: Tears of the Kingdom",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16m3t0t/r_unified_humanscene_interaction_via_prompted/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.07918 \n Blog: https://xizaoqu.github.io/unihsi/ Code coming soon!\n Abstract:\n  \nHuman-Scene Interaction (HSI) is a vital component of fields like embodied AI and virtual reality. Despite advancements in motion quality and physical plausibility, two pivotal factors, versatile interaction control and the development of a user-friendly interface, require further exploration before the practical application of HSI. This paper presents a unified HSI framework, UniHSI, which supports unified control of diverse interactions through language commands. This framework is built upon the definition of interaction as Chain of Contacts (CoC): steps of human joint-object part pairs, which is inspired by the strong correlation between interaction types and human-object contact regions. Based on the definition, UniHSI constitutes a Large Language Model (LLM) Planner to translate language prompts into task plans in the form of CoC, and a Unified Controller that turns CoC into uniform task execution. To facilitate training and evaluation, we collect a new dataset named ScenePlan that encompasses thousands of task plans generated by LLMs based on diverse scenarios. Comprehensive experiments demonstrate the effectiveness of our framework in versatile task execution and generalizability to real scanned scenes. \n  \nhttps://preview.redd.it/0twcwloc82pb1.jpg?width=1078&format=pjpg&auto=webp&s=71bca59aae81ec114f49a742cc42f78cabc9e4c0\n https://preview.redd.it/439nzmoc82pb1.jpg?width=1637&format=pjpg&auto=webp&s=f33059c78a9d845437d551886c5f3a657ddd91fb\n https://preview.redd.it/df6i4ooc82pb1.jpg?width=758&format=pjpg&auto=webp&s=eeb33395d9de1196b4d00531c9e063c8c8fb22cd\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16m3t0t/r_unified_humanscene_interaction_via_prompted/",
          "publishedOn": "2023-09-18T18:51:09.000Z",
          "wordCount": 2742,
          "title": "[R] Unified Human-Scene Interaction via Prompted Chain-of-Contacts - Shanghai AI Laboratory 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16m32qs/d_rl_algorithm_used_in_tesla_fsd_v120/",
          "author": null,
          "description": "There was a lot of hype around the FSD v12.0 from Tesla in that it uses end-to-end neural networks for driving and that it is using imitation learning from good drivers to achieve that. Does someone know more about the specifics around how they are actually implementing this? I cannot find a lot about recent imitation learning/offline learning algorithms. So is this some old algorithm that they are using with a lot of data or just something new? \n    submitted by    /u/FrederikdeGrote  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16m32qs/d_rl_algorithm_used_in_tesla_fsd_v120/",
          "publishedOn": "2023-09-18T18:23:32.000Z",
          "wordCount": 2633,
          "title": "[D] RL algorithm used in Tesla FSD v12.0",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16m28oj/discussion_any_reliable_ai_to_aid_my_school/",
          "author": null,
          "description": "We know that AI is great when studying subjects that depend on simply memorizing facts (like high school biology), but we also know that AI is usually bad when studying subjects that depend on logic (like mathematics and physics).\n What I need the AI for is to explain very complex mathematical concepts to me simply, thoroughly, and accurately. I can't rely on ChatGPT because it's known for not being very reliable when it comes logical things like mathematics or physics. The best AI I know of right now is Bing AI, because it uses GPT-4 and because it prefers searching the web before deducing an answer from its data. I heard that AI agents that run on your computer like Auto-GPT and search from the web are also good at this kind of stuff, but I'm not really sure about that. Do you have any better suggestions?\n    submitted by    /u/Maximum-Gene9660  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16m28oj/discussion_any_reliable_ai_to_aid_my_school/",
          "publishedOn": "2023-09-18T17:51:01.000Z",
          "wordCount": 2715,
          "title": "[Discussion] Any reliable AI to aid my school studies (heavily abstract and logical, my course is focused on mathematics and physics)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16m26g4/p_resume_parser_advice_seeking/",
          "author": null,
          "description": "Hi ! I am about to start a new project with Python probably using Machine Learning to parse resumes, the data is in a pdf/docx format then returned in a json format to later be used in an API or so. I am seeking advice on how to proceed, so far I am trying to collect data which will be provided to me, but not really sure how to go about it as I have found people talking about using Spacy for NLP, pyresparser which is for parsing resumes, but i was wondering if i should make everything from scratch. appreciate your time and opinion in advance \n    submitted by    /u/General-Carrot-4624  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16m26g4/p_resume_parser_advice_seeking/",
          "publishedOn": "2023-09-18T17:48:38.000Z",
          "wordCount": 2659,
          "title": "[P] Resume parser advice seeking",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16m1itm/p_how_to_deploy_yolo_for_real_time_in_a_scalable/",
          "author": null,
          "description": "Hi, I trained a Yolo (v5) model, and I want to deploy it for a real time usage (10 FPS). I am looking for (as possible) a scalable solution, where I could pay only for inference time, at the beginning suitable for 1/2 user's at the same time occasionally, but which could be scaled to dozens of user at the same time.\n As it is for real-time usage Indeed lag to be lowest as possible. According to my current test, I can fit maximum 6 users on T400.\n Is it possible to achieve that using HuggingFace? Thank you to anyone who could help me\n    submitted by    /u/tarsiospettro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16m1itm/p_how_to_deploy_yolo_for_real_time_in_a_scalable/",
          "publishedOn": "2023-09-18T17:23:02.000Z",
          "wordCount": 2664,
          "title": "[P] How to deploy Yolo for real time, in a scalable solution ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16m0c4a/droadmap_for_machine_learning/",
          "author": null,
          "description": "I want to start learning machine learning. I Know python language and data structure. I am planning to learn algorithm. Can you provide me free learning sites or utube channel where I can machine learning step by step . Any site to practice machine learning?\n    submitted by    /u/Temporary-Pie-1831  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16m0c4a/droadmap_for_machine_learning/",
          "publishedOn": "2023-09-18T16:36:35.000Z",
          "wordCount": 2596,
          "title": "[D]Roadmap for machine learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16m03qn/research_detecting_errors_in_numerical_data_via/",
          "author": null,
          "description": "Years ago, we showed the world it was possible to automatically detect label errors in classification datasets via machine learning. Since that moment, folks have asked whether the same is possible for regression datasets?\n Figuring out this question required extensive research since properly accounting for uncertainty (critical to decide when to trust machine learning predictions over the data itself) poses unique challenges in the regression setting.\n Today I have published a new paper introducing an effective method for “Detecting Errors in Numerical Data via any Regression Model”. Our method can find likely incorrect values in any numerical column of a dataset by utilizing a regression model trained to predict this column based on the other data features.\n We’ve added our new algorithm to our open-source cleanlab library for you to algorithmically audit your own datasets for errors. Use this code for applications like detecting: data entry errors, sensor noise, incorrect invoices/prices in your company’s / client’s records, mis-estimated counts (eg. of cells in biological experiments).\n Find errors in regression data in just a few lines of code.\n Extensive benchmarks reveal cleanlab’s algorithm detects erroneous values in real numeric datasets better than alternative methods like RANSAC and conformal inference.\n If you'd like to learn more, you can check out the blogpost, research paper, code, and tutorial to run this on your data.\n    submitted by    /u/jonas__m  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16m03qn/research_detecting_errors_in_numerical_data_via/",
          "publishedOn": "2023-09-18T16:27:20.000Z",
          "wordCount": 2778,
          "title": "[Research] Detecting Errors in Numerical Data via any Regression Model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16lwfna/d_does_the_existence_of_mesa_optimizers_in_modern/",
          "author": null,
          "description": "Recent work shows transformers are capable of performing multi-step gradient descent of mesa objectives inside of their transformer layers. This is even possible for linear transformers, which effectively perform linear optimization on deep representations of features calculated by earlier layers.\n https://arxiv.org/pdf/2309.05858.pdf\n For those unfamiliar, instrumental convergence is the idea that entities with different goals will tend towards different subgoals. Examples could include gathering power, not dying, acquiring resources, etc. A famous thought experiment, known as the paperclip maximizer, is the idea of an AI that is optimized for paperclip production taking over the world so it can build as many paperclips as possible.\n However, if models are dynamically pursuing different objectives at runtime via generated mesa-optimizers, even if instrumental convergence is real, would we still expect it to happen? Without a constant objective given subgoals might start to conflict with each other. On the other hand, since instrumental convergence implies that different goals benefit from similar sub-objectives, perhaps the varying mesa objective doesn't really matter.\n ​\n    submitted by    /u/30299578815310  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16lwfna/d_does_the_existence_of_mesa_optimizers_in_modern/",
          "publishedOn": "2023-09-18T14:02:57.000Z",
          "wordCount": 2732,
          "title": "[D] Does the existence of mesa optimizers in modern models like transformers make instrumental convergence (think paperclip maximizer) scenarios unlikely?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16lvltj/discussion_are_researchers_shifting_from_rl/",
          "author": null,
          "description": "In recent months, I've noticed a significant increase in the number of research papers focusing on LLM and generative models, particularly diffusion models. This trend appears to indicate a growing interest in these areas when compared to the relatively reduced attention given to Reinforcement Learning. It begs the question: Are researchers shifting their focus away from Reinforcement Learning towards these domains? Because in the past I have seen many people complaining about RL on its efficiency and it's impact which have often fallen short of expectations.\n    submitted by    /u/Global_Raise_2979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16lvltj/discussion_are_researchers_shifting_from_rl/",
          "publishedOn": "2023-09-18T13:29:04.000Z",
          "wordCount": 2639,
          "title": "[Discussion] Are Researchers shifting from RL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16lvj4b/d_whats_the_best_practice_in_choosing_which/",
          "author": null,
          "description": "I am reading these 3 articles below and it is still not clear to me what’s the best practice to follow to guide me in choosing which quantized Llama 2 model to use.\n https://huggingface.co/blog/gptq-integration\n https://huggingface.co/blog/overview-quantization-transformers\n https://towardsai.net/p/machine-learning/gptq-quantization-on-a-llama-2-7b-fine-tuned-model-with-huggingface?amp=1\n Questions: 1) I understand there are currently 4 quantized Llama 2 models (8, 4, 3, and 2-bit precision) to choose from. Is this right? 2) with the default Llama 2 model, how many bit precision is it? 3) are there any best practice guide to choose which quantized Llama 2 model to use?\n Would really appreciate any input on the above, even if you only know the answer to 1 or 2 of the questions above. Many thanks!\n    submitted by    /u/--leockl--  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16lvj4b/d_whats_the_best_practice_in_choosing_which/",
          "publishedOn": "2023-09-18T13:25:59.000Z",
          "wordCount": 2672,
          "title": "[D] What’s the best practice in choosing which quantized Llama 2 model to use?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ltjhf/d_chatting_with_multiple_pdfs_in_using_aws/",
          "author": null,
          "description": "I want to create an application which can be used to chat, compare and summarize two simulataneous insurance policy/policies. How can I do it using AWS and HuggingFace ? Has anyone already done it?\n    submitted by    /u/UnfinishedSentenc-1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ltjhf/d_chatting_with_multiple_pdfs_in_using_aws/",
          "publishedOn": "2023-09-18T11:57:26.000Z",
          "wordCount": 2592,
          "title": "[D] Chatting with Multiple PDF's in Using AWS Sagemaker and Kendra",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16lt9e9/discussion_transformers_for_predictions_from/",
          "author": null,
          "description": "I'm in a situation where I have to map from unitary matrices to something (doesn't matter here, but in short: we're in the realm of tooling for quantum computing).\n The key issue The number of matrix elements of the unitaries scales as 2^(2N), where N is the problem size. With N<5 I can easily flatten the matrix and put it into a simple FNN, which works quite well. Once hitting N=5 (the point where things actually get interesting), however, we already have 1024 matrix elements and the method struggles a lot. Still converging to something but very suboptimal. Sure, increasing N hardens the problem in general, but the performance degradation is so abrupt that I suspect some model issues, maybe caused by the curse of dimensionality or something similar.\n Idea (spoiler alert: Transformer) The …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16lt9e9/discussion_transformers_for_predictions_from/",
          "publishedOn": "2023-09-18T11:44:42.000Z",
          "wordCount": 2940,
          "title": "[Discussion] Transformers for predictions from orthonormal base sets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16lstp1/d_professionally_code_with_torch/",
          "author": null,
          "description": "I just concluded my PhD in Robotics & AI and I'd like to learn how to professionally code with Torch.\n Is there any book/resource you can recommend?\n    submitted by    /u/rossomalpelo_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16lstp1/d_professionally_code_with_torch/",
          "publishedOn": "2023-09-18T11:22:37.000Z",
          "wordCount": 2579,
          "title": "[D] Professionally code with Torch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16lrjje/d_integral_over_neural_network_input_space/",
          "author": null,
          "description": "I'm wondering if it's possible to compute definite integral over the input space. Assuming the network is designed to have finite integral with Gaussian being the final layer, is there a way to implement this without resorting to sampling? All inputs go from negative infinity to infinity.\n    submitted by    /u/donchan789  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16lrjje/d_integral_over_neural_network_input_space/",
          "publishedOn": "2023-09-18T10:14:18.000Z",
          "wordCount": 2601,
          "title": "[D] Integral over neural network input space",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16lfst0/d_help_with_understanding_diffusion_models_a/",
          "author": null,
          "description": "I'm trying to read through the paper Understanding Diffusion Models: A Unified Perspective and came across this section:\n https://preview.redd.it/ykkctwhmhwob1.png?width=2346&format=png&auto=webp&s=c7595aae52a8ee22813c840a40a6d29dcf773a10\n I think I kind of get what is going on here but not clearly. For one, what exactly is a Monte Carlo estimate? I tried looking online but didn't get many good results. I'm having trouble understanding why\n https://preview.redd.it/yazmfzg1iwob1.png?width=380&format=png&auto=webp&s=dbbbf80e85a95cd96d8e1ede73e9f8ba1e6e9096\n is approximately equal to:\n ​\n https://preview.redd.it/lbw36em7iwob1.png?width=464&format=png&auto=webp&s=46fb3ebcd02fb4b772b1be51cd59d60d3a1cf438\n where z is sampled from q. Secondly, what exactly does L that z is indexed by refer to? The number of samples X or what exactly?\n    submitted by    /u/lumijekpr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16lfst0/d_help_with_understanding_diffusion_models_a/",
          "publishedOn": "2023-09-17T23:38:30.000Z",
          "wordCount": 2639,
          "title": "[D] Help with Understanding Diffusion Models: A Unified Perspective.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ld46e/r_shattering_all_2input_binary_functions/",
          "author": null,
          "description": "I'm looking for the simplest model that can fit all 16 (222) possible 2-input binary functions I used the term \"shatter\" from VC dimension, which does not give a constructive approach to building the model\n    submitted by    /u/hnsmn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ld46e/r_shattering_all_2input_binary_functions/",
          "publishedOn": "2023-09-17T21:43:34.000Z",
          "wordCount": 2585,
          "title": "[R] Shattering all 2-input binary functions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16lc16n/p_is_20s_per_step_on_an_efficientnetb4_cnn_normal/",
          "author": null,
          "description": "I'm getting 20 seconds per step while training a 244x244x3 EfficientNet-B4 model. The batch size is 20, with 8 classes. Since I have about 5000 images, that makes each epoch around an hour and a half.\n Looking at models online, it seems like people get step durations in the milliseconds. Is it a problem on my end? Running on Google Colab free version.\n    submitted by    /u/hnknerd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16lc16n/p_is_20s_per_step_on_an_efficientnetb4_cnn_normal/",
          "publishedOn": "2023-09-17T21:00:57.000Z",
          "wordCount": 2617,
          "title": "[P] Is 20s per Step on an EfficientNet-B4 CNN normal?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16larsn/dp_how_to_get_the_3d_pose_estimations_from_an/",
          "author": null,
          "description": "Hi,\n I'am trying to get the 3D keypoints coordinates from an image or video and then map it to SMPL model. It's pretty easy to get the keypoints from an image or video using the mediapipe library. But the mapping of it with the SMPL model is something that I can't figure out. mainly because the skeleton structure is different. Some already had a similar issue but the answers were not clear and he didn't even ask futher. Is it possible to do this?? if it's not possible with mediapipe is there some other library that I could use?? I heard about openPose too but when I tried it didn't work someone was saying it works only on windows 11. There are some other parts also to this project which will mostly be dealt with Pytorch. There are some pose estimators in TensorFlow but I want to stick to pytorch hence would like some pose estimators in that framwork, or a library or somehing inside opencv\n https://preview.redd.it/w9mioiyxhvob1.png?width=951&format=png&auto=webp&s=3886c356513b62efbcaddaa76841457cf3eb22e5\n https://preview.redd.it/xjal9kyxhvob1.png?width=506&format=png&auto=webp&s=7f544a3050fbd744d300d2bf6e1a286a4014ece5\n    submitted by    /u/rakk109  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16larsn/dp_how_to_get_the_3d_pose_estimations_from_an/",
          "publishedOn": "2023-09-17T20:10:59.000Z",
          "wordCount": 2723,
          "title": "[D][P] How to get the 3D pose estimations from an Image or Video?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16l7ict/r_earthpt_how_to_superscale_llms_with_large/",
          "author": null,
          "description": "submitted by    /u/Smith4242  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16l7ict/r_earthpt_how_to_superscale_llms_with_large/",
          "publishedOn": "2023-09-17T18:02:01.000Z",
          "wordCount": 2565,
          "title": "[R] EarthPT: how to superscale LLMs with large observation models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16l59xb/discussion_research_how_to_add_furniture_to_an/",
          "author": null,
          "description": "Hello all,\n I've come across a fascinating example of virtual staging and I'm looking for some technical advice.\n Here's the image:\n https://preview.redd.it/3vbw441eeuob1.png?width=2511&format=png&auto=webp&s=679bc62f0cb61d479fe6dc6ce93af4f8846b8cea\n I get how ControlNet-MLSD is used to generate the lines and structure of the empty room. My question is, how is the furniture generated and added to the room without messing up the pixels, making it look as realistic as in the example?\n    submitted by    /u/dexter-dot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16l59xb/discussion_research_how_to_add_furniture_to_an/",
          "publishedOn": "2023-09-17T16:33:52.000Z",
          "wordCount": 2630,
          "title": "[Discussion] [Research] How to Add Furniture to an Empty Room Using ControlNet-MLSD, so the model learns to keep the exact room pixels?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16l4s9q/d_pinecone_vs_pgvector_vs_any_other_alternative/",
          "author": null,
          "description": "Hi Everyone,\n Which vector database would be efficient and affordable for a enterprise chatbot? I tried Pinecone, its was simple to integrate with my python backend. But it's not open-source and its pricing it bit concerning. So Please suggest an alternative.\n    submitted by    /u/Free_Conversation106  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16l4s9q/d_pinecone_vs_pgvector_vs_any_other_alternative/",
          "publishedOn": "2023-09-17T16:15:19.000Z",
          "wordCount": 2595,
          "title": "[D] Pinecone vs PgVector vs Any other alternative vector database",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16l4h0x/d_am_i_thinking_backpropagation_right/",
          "author": null,
          "description": "Basically i wanted to understand how backprop is done in neural networks and how i should be implementing it, so i did what i always do - the math. I just want to know if what i though up is even usable in practice or not. Here is my math. \n    submitted by    /u/EnderPoint07  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16l4h0x/d_am_i_thinking_backpropagation_right/",
          "publishedOn": "2023-09-17T16:03:16.000Z",
          "wordCount": 2600,
          "title": "[D] Am i thinking backpropagation right?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16l3vx2/discussion_question_on_the_paper_named/",
          "author": null,
          "description": "Hi, all.\n ​\n I just read the paper named \" SELF-ATTENTION DOES NOT NEED O(n 2 ) MEMORY\" from Google.\n I understood that it requires O(1) for a single query, but still cannot understand why it requires O(log N) for self-attention and different order input.\n ​\n It seems like adding one index into a sequence requires O(log N) (The paper's saying this).\n But why does it take O(log N)? Isn't it just O(1)? Because it is just adding a single datapoint for the index.\n ​\n I really hope someone understands why it is and leaves any comment on this. \n Here's the paper.\n https://arxiv.org/abs/2112.05682\n ​\n Thanks in advance.\n    submitted by    /u/Maximum_Performance_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16l3vx2/discussion_question_on_the_paper_named/",
          "publishedOn": "2023-09-17T15:40:37.000Z",
          "wordCount": 2661,
          "title": "[Discussion] Question on the paper named, SELF-ATTENTION DOES NOT NEED O(n 2 ) MEMORY from Google.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16l30vp/d_convert_onnx_model_to_wasm_format/",
          "author": null,
          "description": "I need some help regarding the process of converting ONNX model to WASM format\n I created ELECTRA discriminator model with my own config, then convert the Pytorch model to ONNX format. After that, I quantized the model to 2mb. The model will be used for text classification.\n Now I want to convert it to WASM, but I'm literally stucked and dont know how to proceed\n I need some suggestions on how to proceed Please help, thank you\n    submitted by    /u/Ellzaf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16l30vp/d_convert_onnx_model_to_wasm_format/",
          "publishedOn": "2023-09-17T15:06:11.000Z",
          "wordCount": 2628,
          "title": "[D] Convert ONNX model to WASM format",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16l1gbq/d_what_architecture_to_use_with_correlated_data/",
          "author": null,
          "description": "LIke the title says, i have correlated data samples and a covariance matrix among them. if i use a fcnn i can only consider the samples i.i.d. and the use either the MSE or THE MLE as loss function. but the data samples are not independent, so what architecture would allow me to use the full covariance matrix among the samples? transformers? \n    submitted by    /u/ilrazziatore  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16l1gbq/d_what_architecture_to_use_with_correlated_data/",
          "publishedOn": "2023-09-17T14:01:38.000Z",
          "wordCount": 2615,
          "title": "[D] what architecture to use with correlated data samples?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kyv37/tmlr_header_coming_up_when_trying_to_upload_paper/",
          "author": null,
          "description": "I have written and submitted a paper to TMLR and also am uploading it to arxiv. However, even after using \\usepackage[preprint]{tmlr}, I'm getting \"Under Submission at TMLR\". Should this happen. If not, where am I going wrong?\n    submitted by    /u/filletedforeskin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kyv37/tmlr_header_coming_up_when_trying_to_upload_paper/",
          "publishedOn": "2023-09-17T11:59:55.000Z",
          "wordCount": 2593,
          "title": "TMLR header coming up when trying to upload paper to arxiv [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kycoq/d_can_overtraining_be_considered_a_subset_of_the/",
          "author": null,
          "description": "i.e the goal of learning to model the empirical distribution is misaligned with the goal of modeling the \"true\" distribution.\n I've found this framing helpful for describing regulirization heuristics to people, is this a valid way of viewing it?\n    submitted by    /u/Cartesian_Carrot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kycoq/d_can_overtraining_be_considered_a_subset_of_the/",
          "publishedOn": "2023-09-17T11:33:02.000Z",
          "wordCount": 2594,
          "title": "[D] Can overtraining be considered a subset of the alignment problem?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kxfmr/d_any_materials_on_machine_learning_applied_to/",
          "author": null,
          "description": "I have asked this question in other subreddits but no one answered me yet.I've googled it, but maybe some kind people who actually have worked or are working in this field would share some resources. Maybe there are some books or papers that are very explanatory and directly show what problems can be solved by using ML in prosthetics, how and etc. Maybe there are introductory textbooks or must-read papers.\n    submitted by    /u/tenderwrath  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kxfmr/d_any_materials_on_machine_learning_applied_to/",
          "publishedOn": "2023-09-17T10:41:14.000Z",
          "wordCount": 2623,
          "title": "[D] Any materials on machine learning applied to prosthetics?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kwupb/r_the_rise_and_potential_of_large_language_model/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.07864 \n Github: https://github.com/WooooDyy/LLM-Agent-Paper-List \n Abstract:\n  \nFor a long time, humanity has pursued artificial intelligence (AI) equivalent to or surpassing the human level, with AI agents considered a promising vehicle for this pursuit. AI agents are artificial entities that sense their environment, make decisions, and take actions. Many efforts have been made to develop intelligent AI agents since the mid-20th century. However, these efforts have mainly focused on advancement in algorithms or training strategies to enhance specific capabilities or performance on particular tasks. Actually, what the community lacks is a sufficiently general and powerful model to serve as a starting point for designing AI agents that can adapt to diverse …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kwupb/r_the_rise_and_potential_of_large_language_model/",
          "publishedOn": "2023-09-17T10:07:20.000Z",
          "wordCount": 2854,
          "title": "[R] The Rise and Potential of Large Language Model Based Agents: A Survey - Fudan NLP Group miHoYo Inc 2023 China - Github repository includes over 100 Papers with github links!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kwn56/d_alternatives_to_this_sub/",
          "author": null,
          "description": "Since the influx caused by LLMs, this sub has become almost useless to me. What are some alternatives where interesting papers are shared, research discussions take place, and which isn't flooded with LLMs, startups, or personal projects?\n    submitted by    /u/ParanoidTire  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kwn56/d_alternatives_to_this_sub/",
          "publishedOn": "2023-09-17T09:55:18.000Z",
          "wordCount": 2586,
          "title": "[D] Alternatives to this sub?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kvopg/d_should_i_scale_multiclass_target_variable/",
          "author": null,
          "description": "Hey all Please don't mind my English writing \n I have a dataset with scaled feature (scaled by StanderScaler) and multiple class target variable encoded as 0,1,2..6 \n Should I scale the target variable like the feature to increase the accuracy (current accuracy is 79%) and if so how can I do this\n    submitted by    /u/Sunday_A  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kvopg/d_should_i_scale_multiclass_target_variable/",
          "publishedOn": "2023-09-17T08:57:40.000Z",
          "wordCount": 2602,
          "title": "[D] Should I scale multiclass target variable?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kvmcv/r_factors_influencing_adoption_intention_of/",
          "author": null,
          "description": "Hello,\n ​\n I am an information systems student currently conducting research for my undergraduate thesis on the factors that influence people's adoption intention of ChatGPT, as well as identifying the factors that may be holding them back. These factors include people's concerns about potential negative impacts of ChatGPT, such as increased unemployment and the spread of misinformation. Your participation in this study is crucial as it will provide valuable insights to help us understand how ChatGPT can be improved to meet users' needs.\n ​\n Please note that I am not affiliated with OpenAI, no identifying information will be collected during the survey, and all responses will be kept confidential. The survey should take approximately 10 to 15 minutes to complete, and participation is voluntary. You may withdraw from the survey at any time, and there are no known risks associated with participating.\n ​\n If you are interested in learning more about the study, please follow the link below. \n ​\n https://docs.google.com/forms/d/e/1FAIpQLSf5HIfXHppMuTR63x00i4OuRAtM5Ti6EGybd-HuI1kmK06VPw/viewform?usp=sf_link\n ​\n Thank you for taking the time to contribute to our research study. Your participation is greatly appreciated!\n    submitted by    /u/maulanashi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kvmcv/r_factors_influencing_adoption_intention_of/",
          "publishedOn": "2023-09-17T08:53:18.000Z",
          "wordCount": 2724,
          "title": "[R] Factors Influencing Adoption Intention of ChatGPT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kv1ie/d_how_do_the_apis_of_llms_determine_whether_they/",
          "author": null,
          "description": "When I ask questions related to security issues through the APIs of ChatGPT, Claude and other LLMs, such as inquiring how to make a bomb, the APIs of these LLMs would often refuse to answer.\n How do the APIs of these LLMs determine whether they should answer a question?\n Do they make judgments based on pre-generated responses?\n Or do they match keywords in the input prompt?\n Or do they use a classifier to identify the input prompt?\n    submitted by    /u/ShacklesLay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kv1ie/d_how_do_the_apis_of_llms_determine_whether_they/",
          "publishedOn": "2023-09-17T08:15:47.000Z",
          "wordCount": 2635,
          "title": "[D] How do the APIs of LLMs determine whether they should answer a question?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ksqjj/r_the_rise_and_potential_of_large_language_model/",
          "author": null,
          "description": "People have been chasing super-smart AI for ages, hoping they could think and act like us. While we've made a lot of cool tech, we still need a killer starting point for AI that can handle all sorts of tasks. Large Language Models\" (LLMs) are like a big leap toward AI that's smart across the board. People have been using LLMs to make AI that can do loads of things. \n The article takes us on a trip from where AI ideas started, to why LLMs rock as the backbone for AI. \n https://arxiv.org/abs/2309.07864\n They break down this LLM-AI into three parts: \n  \nthe thinky bit (brain), \n what they sense (perception), \n and what they do (action). \n  \nThey chat about how these AI can work solo, in teams, or buddy up with humans.\n https://arxiv.org/abs/2309.07864\n    submitted by    /u/QuantumAsha  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ksqjj/r_the_rise_and_potential_of_large_language_model/",
          "publishedOn": "2023-09-17T05:48:38.000Z",
          "wordCount": 2685,
          "title": "[R] The Rise and Potential of Large Language Model Based Agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kifvd/p_made_a_simple_github_tool_to_check_gpu_vram/",
          "author": null,
          "description": "submitted by    /u/ExploreExploit400  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kifvd/p_made_a_simple_github_tool_to_check_gpu_vram/",
          "publishedOn": "2023-09-16T21:21:57.000Z",
          "wordCount": 2572,
          "title": "[P] Made a simple github tool to check GPU vRAM breakdown for any LLM. Supports GGML & bnb quantization",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kifmt/p_text_to_image_generation/",
          "author": null,
          "description": "submitted by    /u/No-Percentage7346  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kifmt/p_text_to_image_generation/",
          "publishedOn": "2023-09-16T21:21:42.000Z",
          "wordCount": 2604,
          "title": "[P] Text to Image generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kh5m8/d_no_code_ml_tools/",
          "author": null,
          "description": "I'm taking a No code ML class and we are asked to choose which platform we want to use. The options are Dataiku, RapidMiner, and KNIME. Does anyone have thoughts on these options in terms of which is best/worst for someone with minimal coding experience?\n    submitted by    /u/V1ncentAdultman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kh5m8/d_no_code_ml_tools/",
          "publishedOn": "2023-09-16T20:27:09.000Z",
          "wordCount": 2594,
          "title": "[D] No Code ML Tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kdrzn/research_layerneighbor_sampling_for_scalable/",
          "author": null,
          "description": "Hi everybody,\n I have been working on scalable GNN training for a while and noticed that the bottleneck of training GNNs is the graph sampling and feature fetching stages. GNN training frameworks PyG and DGL that most people use seem to default to using Neighbor Sampling for minibatch training. I am hoping that with my new paper Layer-Neighbor Sampling -- Defusing Neighborhood Explosion in GNNs, this default might be due to change.\n My new approach combines the layer sampling approach with the neighbor sampling approach. The result is that there is more overlap in the sampled neighborhoods and one still gets a fixed number of neighbors per seed vertex. It is even possible to turn it into a subgraph sampling approach by fixing the random seed used for sampling across all layers of the GNN m…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kdrzn/research_layerneighbor_sampling_for_scalable/",
          "publishedOn": "2023-09-16T17:59:49.000Z",
          "wordCount": 2974,
          "title": "[Research] Layer-Neighbor Sampling for Scalable Graph Network Training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kbqce/d_how_do_i_move_into_cvnlp/",
          "author": null,
          "description": "Hi guys need some advice,\n I have been working as a data scientist for the past 3 years, mostly in the domain of time series & predictive analytics (churn prediction/segmentation, etc.) with some deployment, hence do not currently have any major NLP/CV/Deep learning projects as such.\n Now, I can see that NLP/CV/Gen AI is mostly in demand and they are really enjoyable as well.\n How do I shift into these domains, given that new companies having these roles are asking for similar past working experience?\n    submitted by    /u/immortal_omen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kbqce/d_how_do_i_move_into_cvnlp/",
          "publishedOn": "2023-09-16T16:30:17.000Z",
          "wordCount": 2634,
          "title": "[D] How do I move into CV/NLP?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kawop/r_deva_tracking_anything_with_decoupled_video/",
          "author": null,
          "description": "submitted by    /u/Mediocre-Bullfrog686  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kawop/r_deva_tracking_anything_with_decoupled_video/",
          "publishedOn": "2023-09-16T15:54:59.000Z",
          "wordCount": 2550,
          "title": "[R] DEVA: Tracking Anything with Decoupled Video Segmentation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16kapda/d_i_want_to_improve_my_self_in_machine_learning/",
          "author": null,
          "description": "I am beginner in machine learning field. I know python, some basic machine learnig algorithm like linear, logistic, decision tree, random forest. I did some work on jupyter notebok related to machine learning like data gathering, data preprocessing, data modeling, data training, finding accuracy, confusion matrix, precision, recall, feature generation etc. i deployed one machine learning model on Skitlearn as well.\n Now, I just want to know that what next means what i can do more in machine learning field after this. I just need some guidance to move on further. I use kaggle and tensor flow (don't know exactly more about this ). If you have any suggestion or any guidance that will be appreciated.\n    submitted by    /u/myteachexplore  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16kapda/d_i_want_to_improve_my_self_in_machine_learning/",
          "publishedOn": "2023-09-16T15:46:11.000Z",
          "wordCount": 2671,
          "title": "[D] I want to improve my self in machine learning field",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16k7ezx/d_the_fate_of_neural_vqa_and_semantic_scene/",
          "author": null,
          "description": "Today we live in a world of multi-model LLMs. How will the following technologies fare against these LLM-based models? \n  \nNeural VQA\n \nSemantic Scene Segmentation\n \n Multi-model LLM are emerging quickly now, (such as NExT-GPT https://next-gpt.github.io/ ) . When you consider the kind of \"understanding\" of a visual scene these models are capable of, what will happen to prior approaches like Neural VQA? The nagging feeling that Neural VQA is going to be completely superseded by LLMs is palpable. The only vestige left for the older technology may have something to do with reasoning about the objects , such as properly counting the number of objects of a category that are present. But even that is getting sketchy. \n On the topic of scene understanding, we can turn to semantic scene segmentation. SSS is a more complicated topic than Neural VQA. SOTA SSS algorithms are still largely employing DeConv Nets, and still require fully labelled datasets. With multi-model LLMs, there is a nagging question : Why go through the complexity/mess of first segmenting a scene very accurately, when an LLM can do better at identifying the entire scene's category in one fail swoop? \n One might suggest that SSS still has a use in regards to interacting with the segmented objects of an environment, where one such \"interaction\" would be avoiding collisions with pedestrians, trees, or other cars. But honestly, SSS does not really make this connection with planning and action, it really only gives you the categories of the segments. THe autonomous vehicle's next moves are still an open problem. \n What technologies do you expect that multi-model LLMs will supersede, if any?\n    submitted by    /u/moschles  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16k7ezx/d_the_fate_of_neural_vqa_and_semantic_scene/",
          "publishedOn": "2023-09-16T13:19:36.000Z",
          "wordCount": 2823,
          "title": "[D] The fate of neural VQA and Semantic Scene Segmentation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16k5b9l/r_three_ways_to_generate_ai_art_using_intel_arc/",
          "author": null,
          "description": "submitted by    /u/reps_up  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16k5b9l/r_three_ways_to_generate_ai_art_using_intel_arc/",
          "publishedOn": "2023-09-16T11:36:26.000Z",
          "wordCount": 2566,
          "title": "[R] Three Ways to Generate AI Art Using Intel Arc GPUs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16k1mke/d_using_gans_to_help_understand_latent/",
          "author": null,
          "description": "Hey. First of all I'm not a researcher on this area, so pardon my ignorance.\n I'm looking to employ a GAN on a dataset. The goals are still a bit unclear, but it's mainly to improve classification by either data augmentation and class balancing, or understanding the data through the latent representations.\n I'm really keen on InfoGAN at the moment. I trained one on the MNIST and the continuous variables learned the rotation and width, as in the paper and other peoples code.\n But at this point I think I need some help. I have labels, which means that maybe I should use a conditional GAN. But how will I learn similar representations as those in InfoGAN? I know StyleGAN is the current big thing in this area, but my images are limited to similar pixel-range as MNIST, and StyleGAN seems dependant on the ProGAN idea of increasing resolution for training.\n I'm a bit confused on the whole topic and would love a pointer to any discussion etc., as I can't seem to find anything but papers and they seem to be only focused on human faces, my data is unnatural not unsimilar again to MNIST. I don't have semantical information either as I see many papers employing that.\n I see many papers employing semi-supervision in this area, but honestly I'm just a bit lost and overwhelmed as this is not my area and GAN papers are still not stopping (I read a post here from 2017 about a GAN making GANs...).\n If you read this far: thank you and any pointers and discussion are very welcome. I would post on /r/learnmachinelearning but I feel the discussion in there is very different from this. My main goal is data exploration, but also to prove effectiveness some classification will be necessary and here the generative approach may help to augment data efficiently.\n    submitted by    /u/Infamous-Bank-7739  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16k1mke/d_using_gans_to_help_understand_latent/",
          "publishedOn": "2023-09-16T07:55:16.000Z",
          "wordCount": 2866,
          "title": "[D] Using GANs to help understand latent representations of small dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16k10bn/d_how_do_i_change_my_domain_from_ds_to_mle/",
          "author": null,
          "description": "Hi guys need some advice,\n I have been working as a data scientist for the past 3 years, mostly in the domain of time series & predictive analytics, hence do not currently have any major NLP/CV/Deep learning projects as such. \n Now, I can see that NLP/CV/Gen AI is mostly in demand and they are really enjoyable as well.\n How do I shift into these domains, given that new companies having these roles are asking for similar past working experience? \n ​\n    submitted by    /u/immortal_omen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16k10bn/d_how_do_i_change_my_domain_from_ds_to_mle/",
          "publishedOn": "2023-09-16T07:18:00.000Z",
          "wordCount": 2632,
          "title": "[D] How do I change my domain (from DS to MLE)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jyh7p/d_ganimede_jupyter_whiteboard/",
          "author": null,
          "description": "I have been working on a alternative to Jupyter Notebooks. Please check it out and share your thoughts : https://github.com/nottherealsanta/ganimede \n ​\n https://preview.redd.it/k8rcx8fwrjob1.png?width=2302&format=png&auto=webp&s=a8a670251f6c268acffc88a40bd528d8d438a5f5\n    submitted by    /u/notsorealsanta  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jyh7p/d_ganimede_jupyter_whiteboard/",
          "publishedOn": "2023-09-16T04:44:32.000Z",
          "wordCount": 2568,
          "title": "[D] Ganimede, Jupyter Whiteboard",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jx9od/d_how_to_evaluate_spectrograms/",
          "author": null,
          "description": "How would you evaluate generated spectrogram audio quality? Taking Riffusion for example, how would you then compare its performance to another generator? What are some common techniques that I could use?\n I mean of course purely in the quality of the audio itself, not my subjective opinion on how much I like the music\n    submitted by    /u/DavesEmployee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jx9od/d_how_to_evaluate_spectrograms/",
          "publishedOn": "2023-09-16T03:36:22.000Z",
          "wordCount": 2603,
          "title": "[D] How to Evaluate Spectrograms?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16josbf/p_building_my_own_aimodel_hub_seeking_guidance/",
          "author": null,
          "description": "Hello everyone! I'm embarking on a project to create an AI-model hub—a platform where users can upload and utilize their AI models. While I'm aware of popular platforms that offer this, my primary goal is for educational purposes. I'd greatly appreciate any recommendations for helpful articles, videos, or codebases to guide me on this journey. Thanks in advance!\n    submitted by    /u/Electronic-Choice-86  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16josbf/p_building_my_own_aimodel_hub_seeking_guidance/",
          "publishedOn": "2023-09-15T21:03:02.000Z",
          "wordCount": 2612,
          "title": "[P] Building My Own AI-Model Hub: Seeking Guidance and Resources",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16joh3y/p_llma_expert_guidance_on_generative_ai_tailored/",
          "author": null,
          "description": "Hello everyone,\n Introducing LLMa: ChatGPT built around YOU (getllma.com) - a dedicated service offering hands-on expertise to integrate state-of-the-art generative AI tailored for your projects. We utilize open-source models and train them to outperform GPT-4 on tasks specific to your domain. Envision having a seasoned AI specialist on your team, ensuring your model not only rivals the big players but excels in your unique challenges.\n 🌟 Why LLMa?\n  \nPersonalized Expertise: Our team collaborates closely with you, delving into your needs and sculpting a model that thrives in your domain.\n Bespoke Training: We refine open-source models (LLaMa, T5, etc.) with plenty of secret tricks to specialize and surpass GPT-4's performance for your specific tasks.\n Cost-Effective: LLMa tends to be around 100x cheaper than GPT-4, offering significant savings. No recurring fees; invest in a one-time fee based on your model's complexity.\n Full Ownership: We hand over the model files/weights to you. It's entirely yours, ensuring total privacy with no PII leaks.\n Deployment Assistance: Beyond just crafting the model, we can guide you in deploying it, ensuring a seamless integration into your operations.\n Ongoing Support: From initial brainstorming to model deployment, we're with you, ensuring success at every phase.\n  \n💼 Tailored for Enterprises: LLMa is meticulously crafted for enterprises that aim for a high-performing, bespoke AI solution. Transparent pricing begins at $500, contingent on your distinct requirements.\n ❓ Navigating the Generative AI Terrain? Embarking on the vast journey of generative AI? LLMa is your compass. We aid in defining challenges, strategizing solutions, and optimizing the AI potential for your endeavors.\n If LLMa piques your interest or if you have any queries, fill-in the form, drop a comment below or DM me. I'm all ears and eager to connect!\n    submitted by    /u/iliashark  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16joh3y/p_llma_expert_guidance_on_generative_ai_tailored/",
          "publishedOn": "2023-09-15T20:50:41.000Z",
          "wordCount": 2845,
          "title": "[P] LLMa: Expert Guidance on Generative AI, Tailored for Your Needs, Outdoing GPT-4 & Saving Costs!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jo7hg/p_deploying_hugging_face_models_on_amazon/",
          "author": null,
          "description": "Quick template that bootstraps Amazon SageMaker running a LlaMa 2 model from Hugging Face. Everything deployed as code (Python), no manual tweaking in the SageMaker console. \n www.pulumi.com/blog/mlops-huggingface-llm-aws-sagemaker-python/ \n    submitted by    /u/kao-pulumi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jo7hg/p_deploying_hugging_face_models_on_amazon/",
          "publishedOn": "2023-09-15T20:39:55.000Z",
          "wordCount": 2583,
          "title": "[P] Deploying Hugging Face models on Amazon SageMaker using infrastructure as code",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jlgvp/d_gan_training/",
          "author": null,
          "description": "Am trying to train GANs for oversampling a minority text class (am feeding it only the minority class), but the results dont seem to improve much (AUC only improves by .03 so far). while basic oversampling techniques like SMOTE gives way better results. also am using a vector representation for the whole text instead of word embedding(same used for SMOTE), i tried different architectures with CNN.\n is there any tricks maybe in training the discriminator and generator ? i can't seem to find the problem\n    submitted by    /u/SlightSecretaryB  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jlgvp/d_gan_training/",
          "publishedOn": "2023-09-15T18:49:58.000Z",
          "wordCount": 2632,
          "title": "[D] GAN training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jl4pe/r_agents_an_opensource_framework_for_autonomous/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.07870 \n Github: https://github.com/aiwaves-cn/agents \n Abstract:\n  \nRecent advances on large language models (LLMs) enable researchers and developers to build autonomous language agents that can automatically solve various tasks and interact with environments, humans, and other agents using natural language interfaces. We consider language agents as a promising direction towards artificial general intelligence and release Agents, an open-source library with the goal of opening up these advances to a wider non-specialist audience. Agents is carefully engineered to support important features including planning, memory, tool usage, multi-agent communication, and fine-grained symbolic control. Agents is user-friendly as it enables non-specialists to build, customize, test, tune, and deploy state-of-the-art autonomous language agents without much coding. The library is also research-friendly as its modularized design makes it easily extensible for researchers. \n  \nhttps://preview.redd.it/3bdi71r5rgob1.jpg?width=1131&format=pjpg&auto=webp&s=760942c19be6ecda791414c812a77e72751c526d\n https://preview.redd.it/howf64r5rgob1.jpg?width=1656&format=pjpg&auto=webp&s=636744fccab7a1c2bafb902bad5dbb647440fff5\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jl4pe/r_agents_an_opensource_framework_for_autonomous/",
          "publishedOn": "2023-09-15T18:36:10.000Z",
          "wordCount": 2682,
          "title": "[R] Agents: An Open-source Framework for Autonomous Language Agents - AIWaves Inc 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jkk71/image_dataset_management_tools_d/",
          "author": null,
          "description": "Hi all,\n I have about 100K images on my machine and I am looking for a tool that can help me do some QA on it.\n Example features I would love:\n  \nSearch and visualize all images with a prefix \"cls1_\" or \"cls2_\"\n Easily rename file names if they're not named correctly\n \nVisualize all captions associated with each image \n  \nWe can assume they have the same name but with extension \".txt\" or \".captions\"\n Or there's a metadata.json linking between \"img_file\" and \"caption_file\"\n \n \nEasily edit captions in the dashboard\n \n I can also work with some kind of metadata file instead of relying on filename logic if it really helps a certain tool.\n I prefer a locally run, open-source tool. It would be a problem for me to upload this data to any online platform.\n Many thanks in advance for any help or guidance.\n    submitted by    /u/JYP_Scouter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jkk71/image_dataset_management_tools_d/",
          "publishedOn": "2023-09-15T18:12:37.000Z",
          "wordCount": 2689,
          "title": "Image dataset management tools [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jk2s1/d_testing_values_are_different_from_real_world/",
          "author": null,
          "description": "Before training my model im going through multiple steps to collect and process my data. One of these steps to is calculate values from algorithmic and mathematical functions. In my training and testing data the values are around 12-15 decimal places. I then split the data without shuffling. Training, validation and testing averages at 75% accuracy. \n Now my next step I wanted to do a \"real world\" data test where I collect the exact same data as my testing data and predict it using my previously built model but the values inside test_dataset1 are different to test_dataset2 within the last 6-9 decimal places even though the data is going through the exact same code. For example \n Test_dataset1 Value : 1.123456789\n Test_dataset2 Value : 1.123456987\n This messes with my prediction and its making me wonder aswell as standrising my data should I be rounding my float values to say 4-6 decimal places?\n    submitted by    /u/paddockson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jk2s1/d_testing_values_are_different_from_real_world/",
          "publishedOn": "2023-09-15T17:52:54.000Z",
          "wordCount": 2704,
          "title": "[D] Testing values are different from \"Real World\" values",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jjx4m/d_what_is_the_difference_between_the_tpu_found_in/",
          "author": null,
          "description": "What are the key differences between the Tensor Processing Unit (TPU) found in Google Tensor chips and the Neural Engine found in Apple's A and M series chips? Are they the same things?\n Or is the TPU only available for Google's own AI, while the Neural Engine is available to all developers for accelerating AI for all apps, if they decide to?\n Can developers optimize apps for Google Tensor like they can for the Neural Engine?\n If not, how do developers take advantage of machine learning acceleration chips on Google Pixel or Android in general?\n If yes, let's say a developer optimizes their app for the Google TPU, will they need to re-optimize for other chips like Samsung's NPU or Qualcomm AI too? If not, how well do they run? Are they the same fast and efficient?\n    submitted by    /u/GRguy_21  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jjx4m/d_what_is_the_difference_between_the_tpu_found_in/",
          "publishedOn": "2023-09-15T17:46:21.000Z",
          "wordCount": 2705,
          "title": "[D] What is the difference between the TPU found in Google Tensor chips vs the Neural Engine found in Apple's A and M series?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jjp5l/p_suggestionsdirection_working_on_image_dehazing/",
          "author": null,
          "description": "Working on Final year project in the field on computer vision: Image Dehazing. I aim at having a novel approch for better dehazing of face haze images.\n Have read papers related to single image dehazing & face SR/Deblur.\n Any thoughts/ suggestions/ leads would be appreciated.\n    submitted by    /u/GahlotB  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jjp5l/p_suggestionsdirection_working_on_image_dehazing/",
          "publishedOn": "2023-09-15T17:37:22.000Z",
          "wordCount": 2598,
          "title": "[P] Suggestions/Direction: Working on Image Dehazing for Face Images.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jibo2/r_traveling_words_a_geometric_interpretation_of/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.07315\n Abstract:\n  \nTransformers have significantly advanced the field of natural language processing, but comprehending their internal mechanisms remains a challenge. In this paper, we introduce a novel geometric perspective that elucidates the inner mechanisms of transformer operations. Our primary contribution is illustrating how layer normalization confines the latent features to a hyper-sphere, subsequently enabling attention to mold the semantic representation of words on this surface. This geometric viewpoint seamlessly connects established properties such as iterative refinement and contextual embeddings. We validate our insights by probing a pre-trained 124M parameter GPT-2 model. Our findings reveal clear query-key attention patterns in early layers and build upon prior observations regarding the subject-specific nature of attention heads at deeper layers. Harnessing these geometric insights, we present an intuitive understanding of transformers, depicting them as processes that model the trajectory of word particles along the hyper-sphere.\n  \n​\n https://preview.redd.it/0i302t857gob1.png?width=1864&format=png&auto=webp&s=1da999c014979bdb6c99809d5b38eb5ccfd717d0\n    submitted by    /u/CoolThingsOnTop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jibo2/r_traveling_words_a_geometric_interpretation_of/",
          "publishedOn": "2023-09-15T16:43:10.000Z",
          "wordCount": 2694,
          "title": "[R] Traveling Words: A Geometric Interpretation of Transformers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jfe2w/p_hampel_python_library_with_c_extensions/",
          "author": null,
          "description": "Repo -> https://github.com/MichaelisTrofficus/hampel_filter\n The Python library hampel implements the Hampel Filter, which is generally used to detect anomalies in data with a timeseries structure. It basically consists of a sliding window of a parameterizable size.\n The library was in plain Python before (using pandas for all the sliding operations, median computation etc), but now it has been replaced by a Cython implementation, which speeds up things quite a bit! 😀\n It also provides much more valuable information (thresholds, median absolute deviations, etc.), allowing us to create plots like this one:\n https://preview.redd.it/6j4ubiwgmfob1.png?width=800&format=png&auto=webp&s=bbc56777fce30a464d0bb33ac5126033b3413838\n ​\n    submitted by    /u/Hefty-Consequence443  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jfe2w/p_hampel_python_library_with_c_extensions/",
          "publishedOn": "2023-09-15T14:47:18.000Z",
          "wordCount": 2642,
          "title": "[P] Hampel Python Library with C extensions 🚀",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jd9h7/discussion_how_to_generate_post_custom_for_each/",
          "author": null,
          "description": "Hi everybody.\n Currently, I am building a Deep Learning model with the task of automatically generating random posts and tweets. The characteristic is that it must have the personality of the writer, for example the user is the CEO of company A, then the generated post must have the writing style of the CEO or company A, similar to other users.\n Actually, I don't know where to start solving this problem. I intend to use RWKV to do this problem but I'm not sure if it is a good direction or not. Is there any related research or can anyone who has done this problem give me some suggestions?\n    submitted by    /u/unknow_from_vietnam  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jd9h7/discussion_how_to_generate_post_custom_for_each/",
          "publishedOn": "2023-09-15T13:20:10.000Z",
          "wordCount": 2663,
          "title": "[Discussion] How to generate post custom for each user ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jc2su/r_uncovering_mesaoptimization_algorithms_in/",
          "author": null,
          "description": "Paper. I am not affiliated with this work or its authors.\n Abstract:\n  \nTransformers have become the dominant model in deep learning, but the reason for their superior performance is poorly understood. Here, we hypothesize that the strong performance of Transformers stems from an architectural bias towards mesa-optimization, a learned process running within the forward pass of a model consisting of the following two steps: (i) the construction of an internal learning objective, and (ii) its corresponding solution found through optimization. To test this hypothesis, we reverse-engineer a series of autoregressive Transformers trained on simple sequence modeling tasks, uncovering underlying gradient-based mesa-optimization algorithms driving the generation of predictions. Moreover, we show that the learned forward-pass optimization algorithm can be immediately repurposed to solve supervised few-shot tasks, suggesting that mesa-optimization might underlie the in-context learning capabilities of large language models. Finally, we propose a novel self-attention layer, the mesa-layer, that explicitly and efficiently solves optimization problems specified in context. We find that this layer can lead to improved performance in synthetic and preliminary language modeling experiments, adding weight to our hypothesis that mesa-optimization is an important operation hidden within the weights of trained Transformers.\n  \nTwitter thread about the paper from one of the paper's authors. Nitter thread, for those who aren't signed into Twitter but want to see the entire Twitter thread.\n Background info: Mesa-Optimization: Explain it like I'm 10 Edition.\n    submitted by    /u/Wiskkey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jc2su/r_uncovering_mesaoptimization_algorithms_in/",
          "publishedOn": "2023-09-15T12:31:13.000Z",
          "wordCount": 2787,
          "title": "[R] Uncovering mesa-optimization algorithms in Transformers (from Google Research, ETH Zürich, and Google DeepMind)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jbp8q/d_can_somebody_help_check_my_math_to_see_if_im/",
          "author": null,
          "description": "Relevant Paper: 2307.08621.pdf (arxiv.org)\n So the definition of the recurrent representation of the retention mechanism is below\n  \nSn = γSn−1 + K⊺nVn \n Retention(Xn) = QnSn, n = 1, · · · , |x|\n  \nγ is a decay factor, and K, Q, and V have their standard transformer definitions.\n What confuses me is the derivation of Sn. The formula makes it look like a scalar. But if that's the case, are we saying that for a given token, the retention mechanism is just multiplying the Query by a scalar? That's surprising! How is that able to provide enough context?\n Here is some code I wrote with GPT to show my understanding of how it works. Is this correct? I use 3 arbitrary tokens of dimension 3, and then a pick arbitrary K Q and V matrices. I also initialize gamma to 0.5\n import numpy as np # Tokens x1…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jbp8q/d_can_somebody_help_check_my_math_to_see_if_im/",
          "publishedOn": "2023-09-15T12:14:53.000Z",
          "wordCount": 3000,
          "title": "[D] Can somebody help check my math to see if I'm understanding Microsoft's Retentive Network paper correctly? I'm confused how we are enriching the tokens with enough context.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jaqdb/project_correcting_misspelled_words_in_urdu/",
          "author": null,
          "description": "Help required from NLP and Text Researchers !!\n Hello everyone!\n I have Urdu language transcriptions (text) which contain many misspelled words that are not part of the Urdu language.\n I wanted to know do we have any good NLP techniques or methods which can solve this problem for Urdu language? I want to replace these misspelled words with the correct words in Urdu.\n I have already tried Python libraries and methods such as indic-nlp, Levenshtein distance, UrduHack, Word2vec Urdu etc, but they weren't able to solve this problem. Some of the methods require Urdu dictionaries to find the correct word, which I'm also unable to find open-source on internet (please also help in that if possible).\n Will appreciate everyone's help and response to this.\n Thank you! \n    submitted by    /u/a_r182  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jaqdb/project_correcting_misspelled_words_in_urdu/",
          "publishedOn": "2023-09-15T11:30:24.000Z",
          "wordCount": 2673,
          "title": "[Project]: Correcting Misspelled Words in Urdu language text",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16janap/d_prospective_phd_advisors/",
          "author": null,
          "description": "Hi everyone!\n I am a (soon graduating) MSc student at a top European university and I'd like to apply for a ML PhD in the US this Fall. I've done my research on schools and advisors, but I figured there's no harm in also asking in this subreddit.\n What are some groups/professors that do ML research at US unis in deep learning theory (specifically foundations) and optimization? As an example, I'm talking about topics such as: https://arxiv.org/abs/1902.08129, https://arxiv.org/abs/1711.04735, https://arxiv.org/abs/2306.04637.\n Thank you all! Cheers!\n    submitted by    /u/AlexIsEpic24  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16janap/d_prospective_phd_advisors/",
          "publishedOn": "2023-09-15T11:26:14.000Z",
          "wordCount": 2631,
          "title": "[D] Prospective PhD advisors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16jamu8/project_correcting_misspelled_words_in_urdu/",
          "author": null,
          "description": "Help required from NLP and Text Researchers !!\n Hello everyone!\n I have Urdu language transcriptions (text) which contain many misspelled words that are not part of the Urdu language.\n I wanted to know do we have any good NLP techniques or methods which can solve this problem for Urdu language? I want to replace these misspelled words with the correct words in Urdu.\n I have already tried Python libraries and methods such as indic-nlp, Levenshtein distance, UrduHack, Word2vec Urdu etc, but they weren't able to solve this problem. Some of the methods require Urdu dictionaries to find the correct word, which I'm also unable to find open-source on internet (please also help in that if possible).\n Will appreciate everyone's help and response to this.\n Thank you! \n    submitted by    /u/a_r182  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16jamu8/project_correcting_misspelled_words_in_urdu/",
          "publishedOn": "2023-09-15T11:25:37.000Z",
          "wordCount": 2673,
          "title": "[Project]: Correcting Misspelled Words in Urdu language text",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16j6cgn/d_ml_research_topics_reasonably_short/",
          "author": null,
          "description": "So I’m starting my masters thesis project in ML ASAP and need a research topic. What areas (if any) are currently hot / feasible to do research in roughly 6 months with fairly limited compute access? \n I’m more interested in theory / research heavy areas rather than applied. And probably happier to dig into some hard math rather than taking on a software engineering type project. \n Any thoughts or general feedback very welcome! Thanks!\n    submitted by    /u/Professional-Pace158  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16j6cgn/d_ml_research_topics_reasonably_short/",
          "publishedOn": "2023-09-15T07:10:13.000Z",
          "wordCount": 2624,
          "title": "[D] ML Research Topics (reasonably short)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16j4xj3/practical_use_cases_for_skew_symmetrical_matrices/",
          "author": null,
          "description": "Just came across this property of matrices that I have never seen before as I am contributing to the NumPy codebase and someone asked for this feature to be added and it got me thinking. It is defined as:\n A skew-symmetric matrix is a square matrix whose transpose equals to its negative. It should satisfy the below condition:\n AT = –A\n Just wondering do these have any applications in ML at all? I never came across this in my math classes so just wondering if the property pops up anywhere else in the field. Maybe in 3D space applications? Or maybe RBG data augmentation? But yeah not 100% sure.\n    submitted by    /u/Ok_Reality2341  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16j4xj3/practical_use_cases_for_skew_symmetrical_matrices/",
          "publishedOn": "2023-09-15T05:44:31.000Z",
          "wordCount": 2662,
          "title": "Practical use cases for skew symmetrical matrices in AI/ML? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16j4n5c/d_how_much_should_i_focus_on_dsa/",
          "author": null,
          "description": "I’m an electrical engineering student in college currently, and have been learning about ML for a few months now. I will be starting a ML research paper under my professor from next week. However, my DSA skills are quite sub-par. Should I focus more on ML math and projects, or take sufficient time out for leetcode as well?\n    submitted by    /u/4R1N1493  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16j4n5c/d_how_much_should_i_focus_on_dsa/",
          "publishedOn": "2023-09-15T05:27:37.000Z",
          "wordCount": 2610,
          "title": "[D] How much should I focus on DSA?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16iy8bj/best_architecture_for_an_autoencoder_for_2d/",
          "author": null,
          "description": "Hi,\n I have a dataset that consists of 2D trajectories and I am aiming to develop an autoencoder architecture to learn a compressed set of features that reasonable represents and can reconstruct the trajectories. \n The trajectories may look something like this as an example. A 2D image as input would seem to require a very sparse representation with high resolution to track the trajectory path. I am hoping there is a better way to input the path without requiring high resolution. \n An alternative might be to use a LSTM structure to input as a sequence, although not sure that solves the resolution issue.\n Do you have any suggestions? I've worked with 1d time series and 2D images just fine but this is a bit different.\n ​\n ​\n https://preview.redd.it/vqz8y3o69bob1.png?width=2020&format=png&auto=webp&s=d8bcc2fe311743c8e78a96055e68f1ad364b48c3\n    submitted by    /u/ZeApelido  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16iy8bj/best_architecture_for_an_autoencoder_for_2d/",
          "publishedOn": "2023-09-15T00:05:43.000Z",
          "wordCount": 2679,
          "title": "Best architecture for an autoencoder for 2D trajectory data? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ixsc8/d_besides_something_about_llm_is_there_any_new_or/",
          "author": null,
          "description": "Please provide Arkiv links. If you want to share your thoughts then go for it. By new I mean within the last 6 months.\n    submitted by    /u/I_will_delete_myself  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ixsc8/d_besides_something_about_llm_is_there_any_new_or/",
          "publishedOn": "2023-09-14T23:45:24.000Z",
          "wordCount": 2585,
          "title": "[D] Besides something about LLM, is there any new or interesting research you think is worth reading?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16iwhg3/d_good_papers_on_poster_collapse_in_vaes/",
          "author": null,
          "description": "What are some good papers to understand posterior collapse in VAEs?\n    submitted by    /u/randomkolmogorov  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16iwhg3/d_good_papers_on_poster_collapse_in_vaes/",
          "publishedOn": "2023-09-14T22:47:18.000Z",
          "wordCount": 2563,
          "title": "[D] Good papers on poster collapse in VAEs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16iw7ey/p_create_an_object_detector_for_any_game_using/",
          "author": null,
          "description": "Full Video Tutorial: https://www.linkedin.com/posts/moisesdias\\_english-version-below-tutorial-crie-activity-7107686497885011969-ZLVW/ \n Hello everyone! Have you ever thought about how to create an object detection system using YOLO that works with any game? \n If you're interested, I've created a tutorial with all the steps to develop this system. I'll leave a link to the video where I demonstrate the process step by step using the game Diablo 2 as an example. \n I hope you enjoy it, and if you have any suggestions, feel free to send a message or comment here! \n    submitted by    /u/moisesdepaulodias  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16iw7ey/p_create_an_object_detector_for_any_game_using/",
          "publishedOn": "2023-09-14T22:35:16.000Z",
          "wordCount": 2637,
          "title": "[P] Create an Object Detector for Any Game Using YOLO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16iw48b/p_would_anyone_know_of_any_information_regarding/",
          "author": null,
          "description": "Good Evening, I and some fellow students are taking a SE class and are looking for relevant information regarding esrb ratings and games for a research project. Does anyone know of any data pertaining to relevant esrb info that we can access? We have a few sources and are waiting to hear back from esrb themselves. Would anyone know if they permit web scraping or if there is a csv containing relevant information, or even perhaps an api we could use? Any information would help and thank you all for taking the time to read this. Thanks in advance!\n    submitted by    /u/GOD_LIKE_WOW  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16iw48b/p_would_anyone_know_of_any_information_regarding/",
          "publishedOn": "2023-09-14T22:31:45.000Z",
          "wordCount": 2653,
          "title": "[P] Would anyone know of any information regarding esrb ratings?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16iutyp/p_ways_to_speed_up_llama2_summarization_on/",
          "author": null,
          "description": "I'm currently working on a project to give a quick summary of long articles/conversations.\n I'm running llama-2-7b-chat-hf with 4bit quantization on a g5.2xlarge instance on sagemaker.\n The method I'm using is map_reduce (option 2)from this webpage https://python.langchain.com/docs/use_cases/summarization)\n Of everything I've tried this is the only one that's been able to do decent summaries in a reasonable amount of time. However with really long articles (10,000+ words) it takes ~6 minutes before giving an output.\n I tried running this same thing on a g5.12xlarge instance which has 4 A10G gpus but it hasn't reduced the time by any noticeable amount.\n Is there anything else I could be doing to speed this up?\n    submitted by    /u/Able_Body_9654  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16iutyp/p_ways_to_speed_up_llama2_summarization_on/",
          "publishedOn": "2023-09-14T21:40:28.000Z",
          "wordCount": 2664,
          "title": "[P] Ways to speed up llama-2 summarization on sagemaker?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16itt92/d_what_prompt_should_i_use_with_llama2_for/",
          "author": null,
          "description": "so as the question states, i want to use llama2 to generate an answer for the question based on the context (or the article for more precision), no finetuning is needed, just want to predict the answer, but i can't find what's the right prompt i should use to get a well structured answer.\n my dataset contains two columns, one for articles, and the other column is for the question,\n Example:\n context: article talking about world war 2.\n question : based on the text, describe how the ww2 had started, and what were the political effects on Europe?\n    submitted by    /u/kaoutar-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16itt92/d_what_prompt_should_i_use_with_llama2_for/",
          "publishedOn": "2023-09-14T21:01:54.000Z",
          "wordCount": 2655,
          "title": "[D] what prompt should i use with llama2 for context generative question answering?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16iswh9/p_coqui_releases_xtts_an_openaccess_foundational/",
          "author": null,
          "description": "There's a new open-access foundational audio model in town!\n Standing on the shoulders of TorToiSe TTS - XTTS allows cross-language and multi-lingual speech generation with just 3 lines of code 🐸\n Key facts about the model: 1. Supports 13 languages. 2. Voice cloning with just a 3-second audio clip. 3. Emotion and style transfer by cloning. 4. Cross-language voice cloning.\n Try it out on HF Hub: https://huggingface.co/spaces/coqui/xtts\n    submitted by    /u/vaibhavs10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16iswh9/p_coqui_releases_xtts_an_openaccess_foundational/",
          "publishedOn": "2023-09-14T20:26:09.000Z",
          "wordCount": 2617,
          "title": "[P] Coqui releases XTTS an open-access foundational Voice Cloning model!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ioxjm/r_large_language_models_for_compiler_optimization/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.07062 \n Abstract:\n  \nWe explore the novel application of Large Language Models to code optimization. We present a 7B-parameter transformer model trained from scratch to optimize LLVM assembly for code size. The model takes as input unoptimized assembly and outputs a list of compiler options to best optimize the program. Crucially, during training, we ask the model to predict the instruction counts before and after optimization, and the optimized code itself. These auxiliary learning tasks significantly improve the optimization performance of the model and improve the model's depth of understanding.\n We evaluate on a large suite of test programs. Our approach achieves a 3.0% improvement in reducing instruction counts over the compiler, outperforming two state-of-the-art baselines that require thousands of compilations. Furthermore, the model shows surprisingly strong code reasoning abilities, generating compilable code 91% of the time and perfectly emulating the output of the compiler 70% of the time. \n  \nhttps://preview.redd.it/f9c7kh7bd9ob1.jpg?width=1530&format=pjpg&auto=webp&s=287fffa714936da9b9a5141b7e01609942416156\n https://preview.redd.it/z4a0ce7bd9ob1.jpg?width=1537&format=pjpg&auto=webp&s=e6275b2b53fa6f431b87940784629b3270c656f9\n https://preview.redd.it/89toie7bd9ob1.jpg?width=750&format=pjpg&auto=webp&s=9a71bdb2eeeff52b2f8bbb3cf2b678debcd4a060\n https://preview.redd.it/0krmqd7bd9ob1.jpg?width=1536&format=pjpg&auto=webp&s=ba3fade0883ee621b185fabc67839db42ea74a53\n https://preview.redd.it/8nz00i7bd9ob1.jpg?width=1198&format=pjpg&auto=webp&s=6ddbddf68311f576fbf3c52a47381316feace8c9\n ​\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ioxjm/r_large_language_models_for_compiler_optimization/",
          "publishedOn": "2023-09-14T17:48:05.000Z",
          "wordCount": 2717,
          "title": "[R] Large Language Models for Compiler Optimization - MetaAi 2023 - Autotuner needs 949 CPU-days to achive nearly the same as this approach in 1shot!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16in6cd/d_searching_for_discussion_about_chunking/",
          "author": null,
          "description": "Hi everyone! \n I'm still experiencing with my own implementation of rag, and I deployed my custom chunking function (honestly don't like the methods on LangChain) . \n Anyway, I'm searching for alternative methods, algoritms (NLP or not) and models... There are lots of info and different implementation on RAG, but as I can see noone put much effort to augment chunking quality. \n Also, there are other approach than this one I'm currently using? bi-encoder (instructor) - > cross-encoder (reranking) - > LLM \n Can someone share some resources, repo, lib or existing implementation of different chunking methods? (or simply discuss here some idea, though or approach) \n Thanks in advance for you time!!\n    submitted by    /u/Distinct-Target7503  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16in6cd/d_searching_for_discussion_about_chunking/",
          "publishedOn": "2023-09-14T16:39:24.000Z",
          "wordCount": 2663,
          "title": "[D] Searching for discussion about chunking algorithms and strategy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16iljbp/d_gradient_descent_in_regularized_least_squares/",
          "author": null,
          "description": "The problem is obtained from Chapter 3 in Wright, Stephen J and Benjamin Recht (2022). Optimization for data analysis.\n Cambridge University Press\n I am solving the problem I attach and I have a doubt in section (f). I have solved all the sections (a)-(e).\n In section (e) I have obtained that I need\n $$\n k \\geq \\frac{\\lambda_{\\text{max}}\\left(\\frac{2}{N} A^TA + 2\\mu I\\right)}{\\lambda_{\\text{min}}\\left(\\frac{2}{N} A^TA + 2\\mu I\\right)}log((f(x^0)-f(x_\\mu)/\\epsilon).\n $$\n However in section (f) asks for a tight upper bound but I only can think about the following bound:\n $f(\\hat{x}) \\leq f_\\mu(x_\\mu) + ||\\hat{x}||^2+ \\epsilon$,\n which is very simple.\n Do you think that I can obtain the result in (e) to obtain another bond, or what would you do?\n    submitted by    /u/ItsGauss  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16iljbp/d_gradient_descent_in_regularized_least_squares/",
          "publishedOn": "2023-09-14T15:34:16.000Z",
          "wordCount": 2666,
          "title": "[D] Gradient descent in regularized least squares",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ilhcd/p_guide_implementing_imagenet_classification/",
          "author": null,
          "description": "Need help on how to get started with implementing a research paper. I'm implementing the Imagenet classification task paper for my final year undergrad mini-project. Any advice is appreciated on how to get started? I have mid-level machine learning knowledge and am ready to pick the required concepts on the go. Please help. Thank you :)\n Link: https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf\n    submitted by    /u/DrBeans0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ilhcd/p_guide_implementing_imagenet_classification/",
          "publishedOn": "2023-09-14T15:31:59.000Z",
          "wordCount": 2611,
          "title": "[P] Guide: Implementing ImageNet classification using Deep CNNs Paper.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16il8ef/d_use_llm_to_analyse_and_port_software_written_in/",
          "author": null,
          "description": "Hi,\n I'm trying to figure out what is the best way to use LLMs to analyse a very old software entirely written in C.\n I've tried to to some basic prompts with ChatGPT and it seems to recognise the language.\n The situation is that I've many .c files with thousands of lines and with a lot of redundant code.\n Moreover, since there are a lot of data structure with variables names not easily understandable, I need to provide some context to allow the model to trying to understand what the code does.\n My worry is that providing all the needed info + the file itself (even considering 1 file at a time) I could consume all the model context and therefore not leave room for generating anything of value.\n Has anyone had the opportunity to face similar problems? Ideas?\n Cheers\n Alexio\n    submitted by    /u/Alexioc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16il8ef/d_use_llm_to_analyse_and_port_software_written_in/",
          "publishedOn": "2023-09-14T15:22:08.000Z",
          "wordCount": 2699,
          "title": "[D] Use LLM to analyse and port software written in C (very long files)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ikvt8/n_mitibm_watson_ai_lab_releases_molm_suite_with/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2306.04640\n GitHub: https://github.com/ibm/moduleformer (under Apache 2.0)\n Twitter thread: https://twitter.com/Yikang_Shen/status/1702041129267388678\n Abstract:\n  \nLarge Language Models (LLMs) have achieved remarkable results. However, existing models are expensive to train and deploy, and it is also difficult to expand their knowledge beyond pre-training data without forgetting previous knowledge. This paper proposes a new neural network architecture, ModuleFormer, that leverages modularity to improve the efficiency and flexibility of large language models. ModuleFormer is based on the Sparse Mixture of Experts (SMoE). Unlike the previous SMoE-based modular language model, which requires domain-labeled data to learn domain-specific experts, ModuleFormer can i…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ikvt8/n_mitibm_watson_ai_lab_releases_molm_suite_with/",
          "publishedOn": "2023-09-14T15:07:54.000Z",
          "wordCount": 2887,
          "title": "[N] MIT-IBM Watson AI Lab releases MoLM suite with three small sparse MoE models, the largest of which (8B params with 700M experts) performs on par with Pythia 2.8B while its throughput is comparable to Pythia 1.4B",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ijc89/assigning_inbalanced_labels_to_other_class_in/",
          "author": null,
          "description": "Hey there,\n I wasn't doing any ml in some time and forgot basics. I was thinking that you may help me. So I trained svc model on small dataset (around 1400 unical records). I have 13 classes, which are badly distributed in the training set and inbalanced. 3 classes took around 80% of all. What the business wants is keep the 3 classes and categorize the rest as \"Other\" class. In the future they may be able to generate more training data for the remaining labels.\n How should I do it? I know I can assign everytning to \"Other\" class, before training with simple if then formula, but dont know if this is the right approach. Any sugestions? I know this may be some case of 1 vs all case, but don't know which exactly.\n Thanks in advance for any help.\n    submitted by    /u/th00masml  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ijc89/assigning_inbalanced_labels_to_other_class_in/",
          "publishedOn": "2023-09-14T14:03:28.000Z",
          "wordCount": 2694,
          "title": "Assigning inbalanced labels to \"Other\" class in scikitlearn [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ij18f/d_the_ml_papers_that_rocked_our_world_20202023/",
          "author": null,
          "description": "Hey everyone! 👋\n I’ve been on a bit of a deep-dive lately, trying to catch up on all the awesome stuff that’s been happening in the ML space. It got me wondering, from 2020 to 2023, what have been the absolute must-read papers that shook the foundations and got everyone talking?\n Whether it’s something that reinvented the wheel in your specific niche or just made waves industry-wide, I wanna hear about it!\n I’m curious to see how different the responses will be, and hey, this might even become a go-to list for anyone looking to get the lowdown on the hottest trends and discoveries of the past few years.\n Can’t wait to hear your thoughts!\n tl;dr\n I decided to aggregate your best suggestions into categories for anyone interested in reading them without searching through the whole comment se…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ij18f/d_the_ml_papers_that_rocked_our_world_20202023/",
          "publishedOn": "2023-09-14T13:50:27.000Z",
          "wordCount": 2950,
          "title": "[D] The ML Papers That Rocked Our World (2020-2023)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ih82w/p_llama2_inference_in_a_single_file_of_pure_mojo/",
          "author": null,
          "description": "Hi everyone!\n I was really excited that Mojo became publicly available and thinking which project can I implement to learn Mojo concepts. Since I have already ported llama2.c to pure Python, I decided why not try to port llama2.py to Mojo now.. And here is what I got\n First round of llama2.c vs llama2.🔥 battle. Mojo demonstrated 20% better performance than C in a single threaded execution of llama2 inference and 250x times better performance than Python\n https://i.redd.it/0gcwwfc2r7ob1.gif\n For reference Mojo is using SIMD vectorization, that's why it's performing great for matmul operations. In the other hand, it turned out that gcc also aggressively optimizes all for loops it can find, so I suggest this benchmark is pretty fair.\n ​\n Mojo natively supports SIMD vectorizations out of the box\n gcc aggressively vectorizing loops\n ​\n After that I decided to compare both solutions in multi-threaded (parallelized) mode, and now `llama2.c` strike back with help of OMP demonstrating 20% better performance than Mojo\n ​\n https://i.redd.it/gwymffods7ob1.gif\n I hope this post will be useful for all Machine Learning engineers/enthusiasts/students out there, ensuring we're up-to-date with Modular/Mojo's game-changing AI tech developments.\n Stay informed and ahead of the curve!\n Links\n llama2.🔥: https://github.com/tairov/llama2.mojo\n llama2.python: https://github.com/tairov/llama2.py\n llama2.c: https://github.com/karpathy/llama2.c\n Modular_AI repost in Twitter: https://twitter.com/tairov/status/1701345271752343900\n feel the magic on HF: https://huggingface.co/spaces/radames/Gradio-llama2.mojo\n    submitted by    /u/Albatross9855  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ih82w/p_llama2_inference_in_a_single_file_of_pure_mojo/",
          "publishedOn": "2023-09-14T12:32:42.000Z",
          "wordCount": 2760,
          "title": "[P] Llama2 inference in a single file of pure Mojo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16igzy7/d_training_an_llm_model_aws_p32xlarge_ec2/",
          "author": null,
          "description": "Hello everyone,\n I'm currently at a crossroads with a decision that I believe many in this community might have faced or will face at some point: Should I use cloud-based GPU instances like AWS's p3.2xlarge EC2 (with Tesla V100) or invest in building a high-performance rig at home with multiple RTX 4090s for training a large language model?\n Context: I run a startup and we're currently fine-tuning an open source LLM, and the computational demands are of course high. We want to make an informed choice between using AWS's offerings or setting up a high-performance system at home to start.\n Cloud Option: AWS p3.2xlarge EC2\n  \nCost: Approximately $3.06 per hour.\n Specifications: One Tesla V100 GPU, 8 vCPUs, 61 GiB RAM.\n Pros: Scalability, reliability, specialized software optimizations.\n Cons: Recurring costs, potential limitations on customization.\n  \nHome Rig Option: Multiple RTX 4090s\n  \nCost: Around $1,600 for each 4090, but I'd own them.\n Specifications: Even higher TFLOPs than a V100, and memory isn't a constraint (24GB per card).\n Pros: One-time investment, flexibility, potentially higher raw computational power.\n Cons: Need to handle cooling, power, and system integration myself\n  \nI'd love to hear your thoughts, experiences, and recommendations. Here are some specific questions:\n  \nPerformance: How many RTX 4090s would roughly equal the computational power of an AWS p3.2xlarge instance for ML tasks?\n Cost-Effectiveness: Given that we're a startup with limited resources, does it make more financial sense to invest upfront in hardware?\n Reliability and Maintenance: For those who have run multi-GPU setups at home, how reliable are they, and what maintenance work is required?\n Other Considerations: Are there factors I haven't considered that you think are critical?\n  \nThank you in advance for sharing your insights!\n    submitted by    /u/devolvedai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16igzy7/d_training_an_llm_model_aws_p32xlarge_ec2/",
          "publishedOn": "2023-09-14T12:22:30.000Z",
          "wordCount": 2838,
          "title": "[D] Training an LLM Model: AWS p3.2xlarge EC2 instance vs. Multiple RTX 4090s at Home?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ifl84/r_scaling_dataconstrained_language_models_hugging/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2305.16264\n GitHub: https://github.com/huggingface/datablations\n License:\n  \nAll models & code are licensed under Apache 2.0. Filtered datasets are released with the same license as the datasets they stem from.\n  \nAbstract:\n  \nThe current trend of scaling language models involves increasing both parameter count and training dataset size. Extrapolating this trend suggests that training dataset size may soon be limited by the amount of text data available on the internet. Motivated by this limit, we investigate scaling language models in data-constrained regimes. Specifically, we run a large set of experiments varying the extent of data repetition and compute budget, ranging up to 900 billion training tokens and 9 billion parameter models. We find that with constrained data for a fixed compute budget, training with up to 4 epochs of repeated data yields negligible changes to loss compared to having unique data. However, with more repetition, the value of adding compute eventually decays to zero. We propose and empirically validate a scaling law for compute optimality that accounts for the decreasing value of repeated tokens and excess parameters. Finally, we experiment with approaches mitigating data scarcity, including augmenting the training dataset with code data or removing commonly used filters. Models and datasets from our 400 training runs are freely available at this https URL.\n  \n​\n https://preview.redd.it/ahzyonnqe7ob1.png?width=1015&format=png&auto=webp&s=0e0cb4051e390ea23440cd61bfc0bbf5fce83bb7\n https://preview.redd.it/l6a81onqe7ob1.png?width=1014&format=png&auto=webp&s=a36b74cbb510a1f753ef1b891531bb36ab643246\n https://preview.redd.it/yyu8h0oqe7ob1.png?width=1001&format=png&auto=webp&s=047cb2bb1932c6215cea0c30e22fd9bbe60391a8\n https://preview.redd.it/xskcytnqe7ob1.png?width=1007&format=png&auto=webp&s=4090e92dd9eacb377840327bb7d0ae69ff752b52\n    submitted by    /u/InterviewIntrepid889  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ifl84/r_scaling_dataconstrained_language_models_hugging/",
          "publishedOn": "2023-09-14T11:11:44.000Z",
          "wordCount": 2765,
          "title": "[R] Scaling Data-Constrained Language Models - Hugging Face et al. 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ifgyw/d_gradio_on_the_same_server_but_different_ports/",
          "author": null,
          "description": "On my team they are using Gradio for LLM applications, etc. When running multiple instances of Gradio applications on the same server, but on different ports, opening a new session is causing an error and closing the previous session, \"error\" is written in the chat. The logs I found were like \"Invalid HTTP request received\" and \"max retries exceeded\". For me, Gradio is supposed to work as a demonstration and not as a scalable product, but they are using it that way and I thought that the problem could be precisely that. But if not, does anyone have any idea what could be going on?\n No meu time estão utilizando gradio para aplicações de LLMs, etc. Ao executar múltiplas instâncias de aplicações Gradio no mesmo servidor, mas em portas diferentes, a abertura de uma nova sessão está causando erro e encerrando a sessão anterior, fica \"erro\" escrito no chat. Os logs que encontrei eram como \"Invalid HTTP request received\" e \"max retries exceeded\". Para mim, o Gradio é pra funcionar como demonstração e não em forma de produto escalável, mas estão utilizando assim e pensei que o problema poderia ser justamente isso. Mas caso não, alguém tem alguma ideia do que pode estar acontecendo?\n    submitted by    /u/Magic_squirrel_hat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ifgyw/d_gradio_on_the_same_server_but_different_ports/",
          "publishedOn": "2023-09-14T11:05:06.000Z",
          "wordCount": 2757,
          "title": "[D] Gradio on the same server but different ports",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16iecpt/r_compilation_of_nonopen_source_ai_models/",
          "author": null,
          "description": "Hi, does anyone have a compiled list of non-open source AI models that can be used for MVP building? \n    submitted by    /u/Compound_Group  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16iecpt/r_compilation_of_nonopen_source_ai_models/",
          "publishedOn": "2023-09-14T10:01:40.000Z",
          "wordCount": 2570,
          "title": "[R] Compilation of non-open source AI models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16i691d/d_communicativecollaborative_agents_hybrids/",
          "author": null,
          "description": "I had a Claude based LLM analyze the strengths and weaknesses of the MetaGPT, ChatDev, AoT, and brain inspired algorithms papers, seeking ways to combine the strengths of two or more of the methods. \"Here are some specific examples of how the methods in the Algorithm of Thoughts (AoT), brain-inspired algorithms, MetaGPT, and ChatDev papers could be combined to improve multi-agent systems:\n  \nMetaGPT could incorporate longer, more elaborate algorithmic examples from AoT into its prompts to guide the LLM's reasoning process. For example, in solving math word problems, the prompt could provide a 4-5 step worked example walking through unpacking the problem statement, setting up equations, solving, and checking the solution. This mirrors AoT's more extensive algorithm narratives.\n \nChatDev's a…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16i691d/d_communicativecollaborative_agents_hybrids/",
          "publishedOn": "2023-09-14T02:23:53.000Z",
          "wordCount": 3151,
          "title": "[D] Communicative/Collaborative Agents hybrids",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16i1ewr/d_opengl_library_error/",
          "author": null,
          "description": "Has anyone ever encountered this error while working with the OpenGL library?\n raise ImportError(\"Unable to load OpenGL library\", *err.args) ImportError: ('Unable to load OpenGL library', \"Could not find module 'OSMesa' (or one of its dependencies)\n I have done pip install opengl and pyopengl, but it doesn't seem to solve the problem.\n Specifically, I am trying to run this code: https://github.com/brjathu/LART\n    submitted by    /u/BigDreamx  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16i1ewr/d_opengl_library_error/",
          "publishedOn": "2023-09-13T22:46:23.000Z",
          "wordCount": 2608,
          "title": "[D] OpenGL Library Error",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16i0llq/d_wandb_remote_agent_source_code_managing/",
          "author": null,
          "description": "Hi all, \n I'm new to machine learning and have decided to use a combination of Stable baselines3 and Wandb. I'm at the point where I'm running sweeps using Wandb and want to utilize another PC I have laying around to run agents on.\n What is the best way to get my python code for the agent to run onto the spare PC? I know I can manually load copy the code over, but I'm looking for a more efficient method that will maintain any changes made to the source code. Maybe packaging up the python code within the sweep and having the agent download and execute it? I'm not all too familiar with possibilities and limits of trying to achieve this so any and all input is appreciated. Thanks!\n    submitted by    /u/chip_fork  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16i0llq/d_wandb_remote_agent_source_code_managing/",
          "publishedOn": "2023-09-13T22:13:25.000Z",
          "wordCount": 2680,
          "title": "[D] Wandb remote agent source code managing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16i08hr/d_mean_scores_or_appending_all_the_predictions_in/",
          "author": null,
          "description": "I have this question that I cannot seem to settle in my head. All papers that I read, report the average (std) performance results across each folds when they report F1, Precision, etc.. Somebody that I highly trust in ML (somebody with a PhD in the field) was reporting the results after saving all the predicted labels (y_pred) and actual labels (y_true) to a list and compute the F1 score one time with the pooled predictions.\n I now am working on a dataset (binary classification) and trying to validate my model using leave-one-subject-out CV (Some people in my dataset have more lines than others). When I take the average of all iterations I get poor results (F1 score= 0.5), but if I pool all the predictions and compute the F1 score at the end, I achieve decent performance (F1 score =0.7). So, in my project, it is in my best interest to use the second approach, and somebody that I trust tells me that it is okay to do this approach. But I cannot seem to find a paper that says that this approach is acceptable or good. What do you guys think and do you have any suggestions?\n    submitted by    /u/enthusiastic31  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16i08hr/d_mean_scores_or_appending_all_the_predictions_in/",
          "publishedOn": "2023-09-13T21:59:37.000Z",
          "wordCount": 2757,
          "title": "[D] Mean scores or appending all the predictions in cross-validation for model performance evaluation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hz47b/p_looking_for_efficient_encoding_methods_for_java/",
          "author": null,
          "description": "I'm working on a project that involves analyzing large samples of Java codes. My end goal is to perform classification based on these codes. For this, I've been trying to efficiently encode the full names of the methods (in the package.class.methodname format) in the Java code.\n Currently, I am experimenting with doc2vec. I'm treating the components of each method's full name (separated by dots) as individual documents. This allows me to produce vectors for each method name, and I evaluate the results by computing the cosine similarity between pairs of similar method names. The results were not good so far.\n Before moving to doc2vec, I tried using an LLM which gave me good results. However, the inference time was far too long, especially given the scale at which I'm working. I also considered using a Bag of Words model, but quickly realized it wouldn't be effective. Many of the method names in my samples are obfuscated, making this approach unsuitable.\n The issue I'm facing is that using the direct method names as features is not generalizing well for classification. A slight change in a method's name results in losing that particular feature, making my model fragile.\n What are some optimal encoding methods for small sentences (around 5-6 words) like these method names, that can scale well? \n Also, Are there any specialized encoding techniques tailored for software code that I could use for this task?\n Any suggestions or insights would be really helpful. Thank you!\n    submitted by    /u/Practical_Mango_8720  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hz47b/p_looking_for_efficient_encoding_methods_for_java/",
          "publishedOn": "2023-09-13T21:17:02.000Z",
          "wordCount": 2802,
          "title": "[P] Looking for Efficient Encoding Methods for Java Method Names for Downstream Classification Task",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hx11m/r_efficient_memory_management_for_large_language/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.06180 \n Github: https://github.com/vllm-project/vllm \n Blog: https://vllm.ai/ \n Abstract:\n  \nHigh throughput serving of large language models (LLMs) requires batching sufficiently many requests at a time. However, existing systems struggle because the key-value cache (KV cache) memory for each request is huge and grows and shrinks dynamically. When managed inefficiently, this memory can be significantly wasted by fragmentation and redundant duplication, limiting the batch size. To address this problem, we propose PagedAttention, an attention algorithm inspired by the classical virtual memory and paging techniques in operating systems. On top of it, we build vLLM, an LLM serving system that achieves (1) near-zero waste in KV cache memory and (2) flexible sharing of KV cache within and across requests to further reduce memory usage. Our evaluations show that vLLM improves the throughput of popular LLMs by 2-4× with the same level of latency compared to the state-of-the-art systems, such as FasterTransformer and Orca. The improvement is more pronounced with longer sequences, larger models, and more complex decoding algorithms. \n  \nhttps://preview.redd.it/x8w8ckejv2ob1.jpg?width=667&format=pjpg&auto=webp&s=28fae778b67ac28fc72d084f071b12c92cb5ea07\n https://preview.redd.it/ctlrqpejv2ob1.jpg?width=1468&format=pjpg&auto=webp&s=31755d169673ee5d30efa3f05bd6cb10813b328d\n https://preview.redd.it/z5r7knejv2ob1.jpg?width=1504&format=pjpg&auto=webp&s=9ceb5370aa5a7cc0688fe9a3771a0328262c3a01\n ​\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hx11m/r_efficient_memory_management_for_large_language/",
          "publishedOn": "2023-09-13T19:55:42.000Z",
          "wordCount": 2738,
          "title": "[R] Efficient Memory Management for Large Language Model Serving with PagedAttention - UC Berkeley et al 2023 - 2-4x higher throughput than HuggingFace Transformers without requiring any model architecture changes!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hx0pe/p_llm_for_viral_tweet_generation/",
          "author": null,
          "description": "Problem: Given a database of the most viral tweets (of a certain shared category), I am hoping to use LLM's to generate further viral tweets. \n Currently I am seeing this as a synthetic data generation problem: two approaches I am thinking of is 1) grounding (using viral examples to guide the prompt) and 2) filtering (finetuning an LLM to predict virality and filtering for the most viral generations) \n I want to ensure that the output retains the \"viral\" structure/style and is diverse/new (i.e no copies).\n Any general directions or references are appreciated\n    submitted by    /u/greatSWE  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hx0pe/p_llm_for_viral_tweet_generation/",
          "publishedOn": "2023-09-13T19:55:18.000Z",
          "wordCount": 2641,
          "title": "[P] LLM for viral tweet generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hwgjv/d_1is_msc_math_enough_to_secure_jobs_in_rd_sector/",
          "author": null,
          "description": "I'm currently doing Integrated MSc in Mathematics (in India) and until now I've done a remote research intern in a French university and I'll do a research intern at a French research laboratory (INRIA-LORIA) next year, I want a job (in India) at the R&D sector (Data Scientist or ML Engineering anything would do) Idk if research interns are as valuable as Industry internships when it comes to R&D? Basically after my masters, I'll probably have only these two internships to show as a work experience, Probably won't be able to get an internship in an IT company unless i opt for remote work (which is also not guaranteed atm).\n Mu question, generally is Msc + 2 research internships + 1or 2 publications good enough to secure a decent job in R&D?\n    submitted by    /u/Emotional-Zebra5359  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hwgjv/d_1is_msc_math_enough_to_secure_jobs_in_rd_sector/",
          "publishedOn": "2023-09-13T19:33:53.000Z",
          "wordCount": 2689,
          "title": "[D] 1is Msc Math enough to secure jobs in R&D sector for AI/ML?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ht4zl/can_i_work_later_as_an_ml_engineer_d/",
          "author": null,
          "description": "Hello!!\n I have a BSc in Mathematics and currently I'm going to start a MSc in FinTech ( it has 3 courses out of 9 that have to do with ML, NN and many more ).\n Since I am really fascinated about programming ( didn't like it when I was at Maths department because of teachers and I am starting learning on my own through courses and we will have many programming languages in my masters degree ex. R,Python, SQL and others) and I would start as a data scientist at the beginning, could I through years of experience later ( ideally 1-2 years later, provided that I have a solid and good programming skills and projects) become a ML engineer? ( Now of course I can't become one because I know that it is difficult since I am competing with people that have CS degrees).\n    submitted by    /u/math-is-cool-62  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ht4zl/can_i_work_later_as_an_ml_engineer_d/",
          "publishedOn": "2023-09-13T17:27:15.000Z",
          "wordCount": 2699,
          "title": "Can I work later as an ML engineer? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hsobt/p_seeking_technical_cofounder_private_equity_saas/",
          "author": null,
          "description": "Hi there!\n I bring 2 years of experience from a European investment fund and a solid idea for a B2B SaaS solution targeting private equity investment funds. \n This market is notoriously challenging to penetrate without insider knowledge. The timing couldn't be better. Similar kind of software is currently sold €20k per user by a semi-monopolistic boomer company that is ready to be disrupted.\n Offer:\n - Equity shared equally.\n - Ready to quit my job and go full-time on it, if I find the right co-founder.\n Ideal Partner:\n Seeking someone proficient in SQL for handling large datasets and able to integrate OpenAI's API within such datasets (technical AI skills required). While I'm based in Berlin and prefer a European co-founder, it's not mandatory, but meeting in person is a must before we commit.\n Don't be afraid to DM me if intrigued! Together, we can make it happen. Let's revolutionize the sector!\n    submitted by    /u/Sudden_Possible489  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hsobt/p_seeking_technical_cofounder_private_equity_saas/",
          "publishedOn": "2023-09-13T17:09:37.000Z",
          "wordCount": 2702,
          "title": "\"[P]\" Seeking technical Co-Founder: Private Equity SaaS Startup",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hsntv/books_for_machine_learning_d/",
          "author": null,
          "description": "İ am lookong for the pdfs about machine learning, maths for ML, ml projects. İs there any sites i can find pdf like that?\n    submitted by    /u/Necessary-Car-5080  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hsntv/books_for_machine_learning_d/",
          "publishedOn": "2023-09-13T17:09:05.000Z",
          "wordCount": 2573,
          "title": "Books for machine learning. [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hqzxy/d_tensorflow_dropped_support_for_windows/",
          "author": null,
          "description": "Hey,\n I've been using TF pretty much my whole deep learning career starting in 2017. I've also used it on Windows the entire time. This was never a major issue.\n Now when I tried (somewhat belatedly) upgrading from 2.10 to 2.13, I see the GPU isnt being utilized and upon further digging see that they dropped Windows GPU support after 2.10:\n \"Caution: TensorFlow 2.10 was the last TensorFlow release that supported GPU on native-Windows. Starting with TensorFlow 2.11, you will need to install TensorFlow in WSL2, or install tensorflow or tensorflow-cpu and, optionally, try the TensorFlow-DirectML-Plugin\"\n This is really upsetting! Most of the ML developers I know actually use Windows machines since we develop locally and only switch to Linux for deployment.\n I know WSL is an option, but it (1) can only use 50% RAM (2) doesnt use the native file system.\n I feel very betrayed. After sticking with, and even advocating for Tensorflow when everyone was (and still is) switching to PyTorch, TF dropped me! This is probably the final nail in the coffin for me. I will be switching to PyTorch as soon as I can :-(\n -Disgruntled user\n    submitted by    /u/rsandler  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hqzxy/d_tensorflow_dropped_support_for_windows/",
          "publishedOn": "2023-09-13T16:05:22.000Z",
          "wordCount": 2743,
          "title": "[D] Tensorflow Dropped Support for Windows :-(",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hpvow/r_research_participants_required_age_perception/",
          "author": null,
          "description": "https://research.sc/participant/login/dynamic/A1D66883-6E8F-409B-8EF9-AC989A76C7E9\n Psychology researchers at Swansea University are carrying out an original study to see whether artificial intelligence is able to generate infant faces between the ages of 0 and 7 years. AI generated pictures will be presented alongside real faces from an existing face database, with a sliding scale underneath that you will use to roughly estimate the age of the child’s face.\n The experiment should only take between 15 and 20 minutes\n Thank you for your time.\n    submitted by    /u/Logipsychlical  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hpvow/r_research_participants_required_age_perception/",
          "publishedOn": "2023-09-13T15:22:30.000Z",
          "wordCount": 2648,
          "title": "[R] --Research Participants Required-- Age perception of AI generated infant faces compared to real infant faces. (Suitable for everyone) (Available for Laptop/PC and Tablet devices only)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hpn7m/d_will_be_presenting_a_talk_on_data_preprocessing/",
          "author": null,
          "description": "So I'll be presenting a talk on Data pre-processing in deep learning in my city's Keras Community Day, and I am still thinking about all the content I want to present there.\n What I want from this session is to present different ways of preprocessing the data for a deep learning model. I want to show different types of implementations, how those affect the final trained model, when to use which type of data preprocessing and things similar to this. It would be great if you can suggest me some topic, notebooks or datasets for the same. All the notebooks that show good implementation and affect of data preprocessing are absolutely welcome.\n Also, as this is **Keras** Community Day, I'll have to include more about data preprocessing using Keras and less about other libraries. \n Also, if you could help me with this: I am confused between showing preprocessing using layers or doing the preprocessing without layers. I know this sounds vague, but if you have any idea about this, let me know.\n Thank you for reading!\n    submitted by    /u/inclinedadarsh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hpn7m/d_will_be_presenting_a_talk_on_data_preprocessing/",
          "publishedOn": "2023-09-13T15:13:10.000Z",
          "wordCount": 2751,
          "title": "[D] Will be presenting a talk on Data Pre-processing in Deep Learning - what would be the topics, notebooks or datasets would you include if you would be giving such talk?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hp7fn/d_need_help_selecting_msc_courses/",
          "author": null,
          "description": "I'm currently in my first year of MSc. in Engineering Mathematics and Computational Science. First Study Period (Currently) I have nonlinear optimization and High-performance computing.\n The track I want to choose is a mix between Machine Learning and Big Data. I can select 2 courses for Study Period 2. Here are the potential courses to select from:\n  \nGame Theory and Rationality\n Large-Scale Optimization\n Advanced Probabilistic machine learning\n Basic Stochastic Processes\n Options and Mathematics (Options trading)\n Foundations of Probability Theory\n  \n​\n I need to select 4 potential courses and rank them from high preference to low preference. In case I don't get one of them, the other will be preferred. Please Machine Learning Reddit Gods, Help me.\n    submitted by    /u/AdMaster9439  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hp7fn/d_need_help_selecting_msc_courses/",
          "publishedOn": "2023-09-13T14:56:40.000Z",
          "wordCount": 2665,
          "title": "[D] Need help Selecting MSc. Courses",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hnyn5/d_we_built_beam_an_ultrafast_serverless_gpu/",
          "author": null,
          "description": "Hi r/MachineLearning,\n TL;DR: Run AI apps on pay-per-second cloud GPUs that hot reload with your code changes.\n Documentation: https://docs.beam.cloud\n I’m Eli, and my co-founder and I built Beam to run workloads on serverless cloud GPUs with hot reloading, autoscaling, and (of course) fast cold start. You don’t need Docker or AWS to use it, and everyone who signs up gets 10 hours of free GPU credit to try it out.\n Here a few examples of things you can run on Beam:\n  \nFine-tune a LLaMA LLM\n Transcribe videos with Whisper\n Train a custom stable diffusion model\n  \nBeam is built for a fast developer experience. We’ve felt that using Docker and AWS directly is too slow for iterative development. You’ll often find yourself making changes to your code and waiting 10 minutes for a new image to bu…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hnyn5/d_we_built_beam_an_ultrafast_serverless_gpu/",
          "publishedOn": "2023-09-13T14:06:50.000Z",
          "wordCount": 2918,
          "title": "[D] We built Beam: An ultrafast serverless GPU runtime",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hng02/d_mlflow_plugin_manager_early_days_looking_for/",
          "author": null,
          "description": "Hey r/machinelearning!\n I'm thrilled and anxious to share an early version of the MLflow Plugin Manager. It's designed to simplify your mlflow installation, allowing you to install, update, and uninstall MLflow plugins directly from the web interface. Think of it as the \"wbond's package manager for sublime\", but tailored for MLflow!\n 📽️\n https://i.redd.it/9gj8vqcz01ob1.gif\n ​\n Yes, it's in its infant stages and doesn't boast of a fancy UI yet, but I'm eager to get your feedback!\n 🔍 What are your first impressions? Is this a good idea?\n 💡 Any features you'd love to see?\n 🌐 Ideas on promoting or expanding its reach?\n I built this to bring a bit more ease to our community. Can't wait to hear your thoughts and where we can take this next!\n Repo: https://github.com/thijsdezoete/mlflow-plugin-manager/\n    submitted by    /u/jessepnk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hng02/d_mlflow_plugin_manager_early_days_looking_for/",
          "publishedOn": "2023-09-13T13:44:38.000Z",
          "wordCount": 2684,
          "title": "[D] mlflow plugin manager - early days / looking for feedback and alpha users",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hmwcc/discussion_non_deterministic_behaviour_in_llms/",
          "author": null,
          "description": "Hi all,\n Someone asked me today \"why are LLMs still non deterministic in their output when temperature is set to 0. Assume fixed model between runs on the same machine\" \n I was like WTF are you saying - the randomness in LLM comes from temperature - chat gpt etc.. might have other randomness in the process but we don't have exact info on this. What I know is that in a standard transformers architecture, temperature is the only parameter that can enduce non deterministic behaviour at inference time. \n He was convinced that there was more to it \"i spoke about this to other LLM experts and they also are not sure\" \n I'm like wtf - I start looking up online and do find some people who claim that temperature is not the only thing that influences stochasticity during inference, but I can't find an answer as to what it is exactly. \n Anyone has a clue of what I am missing here? \n Thanks!\n    submitted by    /u/WagnerianJLC  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hmwcc/discussion_non_deterministic_behaviour_in_llms/",
          "publishedOn": "2023-09-13T13:21:59.000Z",
          "wordCount": 2717,
          "title": "[Discussion] Non deterministic behaviour in LLMs when temperature set to 0?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hleuv/p_will_tsetlin_machines_reach_stateoftheart/",
          "author": null,
          "description": "​\n A composite of specialized Tsetlin machines that enables plug-and-play collaboration.\n I have a love-and-hate relationship with CIFAR-10/100. I love the datasets for the challenge. On the other hand, they are two datasets where Tsetlin machines have struggled with getting state-of-the-art performance. (The Tsetlin machine is a low-energy logic-based alternative to deep learning that has done well on MNIST, Fashion-MNIST, CIFAR-2, and various NLP tasks.)\n I have been working for some time now on figuring out a solution, and this summer, I finally had a breakthrough: a new architecture that allows multiple Tsetlin machines to collaborate in a plug-and-play manner, forming a Tsetlin machine composite. The collaboration relies on a Tsetlin machine's ability to specialize during learning and…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hleuv/p_will_tsetlin_machines_reach_stateoftheart/",
          "publishedOn": "2023-09-13T12:13:11.000Z",
          "wordCount": 2909,
          "title": "[P] Will Tsetlin machines reach state-of-the-art accuracy on CIFAR-10/CIFAR-100 anytime soon?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hl9wo/p_tutorial_create_an_object_detector_for_any_game/",
          "author": null,
          "description": "Hello everyone! Have you ever thought about how to create an object detection system using YOLO that works with any game?\n If you're interested, I've created a tutorial with all the steps to develop this system. I'll leave a link to the video where I demonstrate the process step by step using the game Diablo 2 as an example.\n I hope you enjoy it, and if you have any suggestions, feel free to send a message or comment here! \n link to the tutorial: https://www.linkedin.com/posts/moisesdias_english-version-below-tutorial-crie-activity-7107686497885011969-ZLVW/\n    submitted by    /u/moisesdepaulodias  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hl9wo/p_tutorial_create_an_object_detector_for_any_game/",
          "publishedOn": "2023-09-13T12:06:35.000Z",
          "wordCount": 2640,
          "title": "[P] Tutorial - Create an Object Detector for Any Game Using YOLO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hjrx8/r_adversarial_reinforcement_learning/",
          "author": null,
          "description": "A curated reading list for the adversarial perspective in deep reinforcement learning.\n https://github.com/EzgiKorkmaz/adversarial-reinforcement-learning\n    submitted by    /u/ml_dnn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hjrx8/r_adversarial_reinforcement_learning/",
          "publishedOn": "2023-09-13T10:48:18.000Z",
          "wordCount": 2561,
          "title": "[R] Adversarial Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hih2w/p_the_xor_trick/",
          "author": null,
          "description": "Can a single layer neural network solve the XOR problem?\n Most answers say no, but with this one weird trick the answer is yes! And we don't even need a bias! The trick is to multiply the outputs of a single (2,2) linear layer. Here is how:\n class XorSolver(nn.Module): def __init__(self, *args, **kwargs) -> None: super().__init__(*args, **kwargs) self.layer = nn.Linear(2, 2, bias=False) # we don't even need a bias! def forward(self, x: torch.Tensor) -> torch.Tensor: z = self.layer.forward(x) y = z[:, 0] * z[:, 1] return y \n This is the loss and model output after 5000 epochs:\n loss: 6.516383166399464e-08 Input: [[0. 0.] [0. 1.] [1. 0.] [1. 1.]] Model output: [0. 1. 1. 0.] Expected output: [0. 1. 1. 0.] Layer weight: [[-1.248097 1.2202195 ] [-0.80121976 0.81952316]] \n The full implementation with training and inference - around 50 lines of code - can be found on GitHub.\n Why it works?\n Basically the model simulates a more sophisticated neuron which allows more interactions between the inputs.\n By multiplying the outputs of two neurons, we introduce a form of non-linearity that allows us to separate data that are not linearly separable, like in the XOR problem:\n f(x1, x2, w1, w2, w3, w4) = (x1 * w1 + x2 * w2) * (x1 * w3 + x2 * w4)\n  \nw1, w2 are learnable parameters of the first neuron\n w3, w4 are learnable parameters of the second neuron\n x1, x2 are inputs to the model\n  \nRelated studies\n  \nSolving XOR with a single Perceptron\n Artificial Neural Networks With Adaptive Polynomial Activation Function\n Single Cortical Neurons as Deep Artificial Neural Networks\n Dendritic action potentials and computation in human layer 2/3 cortical neurons\n  \n   submitted by    /u/tecbar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hih2w/p_the_xor_trick/",
          "publishedOn": "2023-09-13T09:32:10.000Z",
          "wordCount": 2823,
          "title": "[P] The XOR trick",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hhwoo/r_renting_cloud_services/",
          "author": null,
          "description": "Hello guys. As I plan on soing a scientific research project, I would need some cloud compute. Say for a month of usage(can I rent for month?). What are some popular options? I am looking at something with 48gb vram pooled,mybe a600 or a100 and some decent cpu, and 2tb space.\n    submitted by    /u/Outrageous_Ad1452  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hhwoo/r_renting_cloud_services/",
          "publishedOn": "2023-09-13T08:58:19.000Z",
          "wordCount": 2599,
          "title": "[R] Renting cloud services",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16hboas/d_guidance_in_training_different_models_and/",
          "author": null,
          "description": "Currently I'm training medium (1B-3B) sized audio models. I have several different architectures in mind. Obviously I don't want to train the full-sized models and then compare them, thats a waste of money. So I'm thinking of training smaller versions (~100M) and then comparing those instead.\n My question is there some sort of best practice for this? Some smaller multiple of your full model size where it is best to compare? Thanks.\n    submitted by    /u/ginger_turmeric  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16hboas/d_guidance_in_training_different_models_and/",
          "publishedOn": "2023-09-13T03:07:47.000Z",
          "wordCount": 2627,
          "title": "[D] Guidance in training different models and comparing using smaller versions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16h3rpd/p_need_advice_for_vector_db/",
          "author": null,
          "description": "Hi, all,\n I'm working on a GPT-powered game where the characters speak using API calls.\n For this, I need an inexpensive vector database that does not require an API, or at least if it does, it leverages the OpenAI API. Also, this vector database must be runnable on consumer-grade gaming hardware with a small search space (let's say 10-50 entries in the DB).\n Also, I need to package it with the game somehow. My game is in the Godot engine which can use Python with a plug-in. Other approaches I was considering is having a second process communicate with the game through a socket. Ideally the vector DB solution would be easy to install - that is, I could package it with a .exe, and simply run both without the player having to download anything else.\n Any suggestions? \n    submitted by    /u/kettlebot141  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16h3rpd/p_need_advice_for_vector_db/",
          "publishedOn": "2023-09-12T21:31:04.000Z",
          "wordCount": 2688,
          "title": "[P] Need advice for vector DB",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16h3rfb/d_what_are_some_ways_that_you_can_reduce_latency/",
          "author": null,
          "description": "Hi. I'm currently tasked with something at my company that I'm facing some difficulty with because it's not in my domain. My company has a service where we provide video chatting to users and match users with others based on various features.\n Currently I've implemented a simple model where we have separate embedding matrices for each user feature, create a user representation by aggregating these features, and performing regression between two users. The way that regression works is that the final score output from the model would act as a \"matching score\" and we'll match user A with the highest other user.\n The problem is that obviously running inference on every single pair of users is very slow and I need to speed this up.\n Some methods I thought about were to either use a feature store or perform sampling on users so we're not running inference on the entire users, but I'm not sure if this is optimal.\n Just curious what other people who have tackled problems like these have done and looking for second opinions. Thanks.\n    submitted by    /u/Seankala  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16h3rfb/d_what_are_some_ways_that_you_can_reduce_latency/",
          "publishedOn": "2023-09-12T21:30:47.000Z",
          "wordCount": 2736,
          "title": "[D] What are some ways that you can reduce latency of real-time user-user matching?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16h20xn/r_nextgpt_anytoany_multimodal_llm_national/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.05519 \n Blog: https://next-gpt.github.io/ \n My opinion: It lacks a Cognitive Architecture: https://arxiv.org/abs/2309.02427 Also the models are far too small and are more on the gpt-2 level. The idea in itself is a good one but can be far improved with bigger models. I also would like to remember in this that all foundation models could be improved if there would be no tokenizers: https://x.com/karpathy/status/1657949234535211009?s=20 \n Abstract:\n  \nWhile recently Multimodal Large Language Models (MM-LLMs) have made exciting strides, they mostly fall prey to the limitation of only input-side multimodal understanding, without the ability to produce content in multiple modalities. As we humans always perceive the world and communicate with people through var…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16h20xn/r_nextgpt_anytoany_multimodal_llm_national/",
          "publishedOn": "2023-09-12T20:25:17.000Z",
          "wordCount": 2821,
          "title": "[R] NExT-GPT: Any-to-Any Multimodal LLM - National University of Singapore 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16h1tup/r_unveiling_theory_of_mind_in_large_language/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.01660\n Abstract:\n  \nWith their recent development, large language models (LLMs) have been found to exhibit a certain level of Theory of Mind (ToM), a complex cognitive capacity that is related to our conscious mind and that allows us to infer another's beliefs and perspective. While human ToM capabilities are believed to derive from the neural activity of a broadly interconnected brain network, including that of dorsal medial prefrontal cortex (dmPFC) neurons, the precise processes underlying LLM's capacity for ToM or their similarities with that of humans remains largely unknown. In this study, we drew inspiration from the dmPFC neurons subserving human ToM and employed a similar methodology to examine whether LLMs exhibit comparable characteristics. Surp…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16h1tup/r_unveiling_theory_of_mind_in_large_language/",
          "publishedOn": "2023-09-12T20:17:26.000Z",
          "wordCount": 2801,
          "title": "[R] Unveiling theory of mind in large language models: A parallel to single neurons in the human brain - Harvard University 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16h1oqr/dr_looking_for_help_with_forced_alignment_for/",
          "author": null,
          "description": "Hey everyone,\n I'm trying to create an alignment between source audio in a different language than the translated transcript. Essentially want to align the translated transcript with the word-level timestamps on an Audio, programmatically. I've tried to find different tools; some open-source ML models force alignment if the source audio and transcript language are the same. \n My goal is to have audio in a dubbed language, which I generate using a translated transcript that has been originally transcribed from my audio. Alignment seems tough since languages are spoken at different rates, so I'm figuring out the best way to optimize alignment without having to speed up/slow down the audio too much for each sentence.\n    submitted by    /u/Revolutionary_Ant944  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16h1oqr/dr_looking_for_help_with_forced_alignment_for/",
          "publishedOn": "2023-09-12T20:12:00.000Z",
          "wordCount": 2668,
          "title": "[D][R] Looking for help with Forced Alignment for translated audio",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16h0jdq/d_best_places_to_access_the_greatest_number_of/",
          "author": null,
          "description": "I'm in need of a massive amount of GPUs for batch inference I'm doing. Outside of the big cloud providers are there any niche services out there you'd recommend? \n    submitted by    /u/Ok_Post_149  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16h0jdq/d_best_places_to_access_the_greatest_number_of/",
          "publishedOn": "2023-09-12T19:27:53.000Z",
          "wordCount": 2583,
          "title": "[D] Best Places to Access the Greatest Number of GPUs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16h09u4/d_are_fourier_positional_encodings_outdated/",
          "author": null,
          "description": "I gave a talk at work the other day about the attention mechanism and one of my coworkers told me that he thinks Fourier Positional Encodings in transformers are outdated. I've tried to follow up and find what I could but I didn't see anything suggesting that they're not being used. I know that learned encodings are also used.\n Can anyone give me some direction on this? My initial impression is that they are not outdated by any means, but I'm happy to be wrong about that.\n    submitted by    /u/XfrmrTron  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16h09u4/d_are_fourier_positional_encodings_outdated/",
          "publishedOn": "2023-09-12T19:17:16.000Z",
          "wordCount": 2637,
          "title": "[D] Are Fourier Positional Encodings Outdated?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16gzd6i/p_launched_my_own_ttssound_effectai_music_service/",
          "author": null,
          "description": "I've created an AI Sound service that can do TTS (text to speech), STS (speech to speech), Voice Cloning, generate sound effects, and also generate instrumental music. Here's the link: https://voicegen.org/, you can try everything for free.\n The TTS quality is similar to Elevenlabs, and there are some sample clips on the home page.\n Stuff I'm working on:\n - Emotional speech (where you can select the emotion of the TTS). Right now you can already do it by putting the emotion in brackets: e.g. \"[Angrily] Please go away!\" but I want to make it better.\n - Music with vocals. Currently the model only generates instrumental music. I am retraining it/tweaking the model to allow for music with lyrics.\n - Faster Inference: Since I'm doing this all myself and I'm not rich, I don't have access to the best hardware. However, I am working on some optimizations like speculative decoding that should speed things up.\n Anyways, let me know if you have any questions/comments/feature suggestions/see any bugs! Feel free to DM me. Thanks.\n    submitted by    /u/ginger_turmeric  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16gzd6i/p_launched_my_own_ttssound_effectai_music_service/",
          "publishedOn": "2023-09-12T18:43:11.000Z",
          "wordCount": 2730,
          "title": "[P] Launched my own TTS/Sound Effect/AI Music Service - looking for people to try",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16gxp51/pr_kani_a_lightweight_highly_hackable_opensource/",
          "author": null,
          "description": "Hey all, we just released our new project/paper and we thought you all might find it useful!\n Our project (Kani) is a super lightweight and hackable alternative to frameworks like LangChain or simpleAIchat meant to help developers hook in callable functions or tools to chat models easily. With Kani, devs can write functions in pure python and just add one line (the @ai_function() decorator) to turn any function into an AI-callable function!\n Kani works with any model and has built-in tools for OpenAI, HuggingFace, LLaMAv2, Vicuna, and GGML with more to come. Kani also never does any prompt engineering under the hood and doesn't require learning complex library tools---all defaults are minimal and highly customizable.\n Check out our Colab for mini-examples of things like retrieval, web-search, model routing, etc. https://colab.research.google.com/github/zhudotexe/kani/blob/main/examples/colab_examples.ipynb \n If you're interested in learning more check out our links below!\n Paper: https://arxiv.org/abs/2309.05542\n GitHub: https://github.com/zhudotexe/kani\n Docs: https://kani.readthedocs.io/\n    submitted by    /u/zhuexe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16gxp51/pr_kani_a_lightweight_highly_hackable_opensource/",
          "publishedOn": "2023-09-12T17:38:09.000Z",
          "wordCount": 2705,
          "title": "[P][R] Kani: A Lightweight Highly Hackable Open-Source Framework for Building Chat Applications with Tool Usage (e.g. Plugins)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16gx2lg/d_help_understanding_llm_quantization_techniques/",
          "author": null,
          "description": "So i have been doing some research to get into the LLM quantization field but have some questions. To better organize my ideas i have developed the image below. Does it make sense / is true?\n The way i understand it there are 3 main methods which are compatible with different backends (the backend part is still quite confusing to me). What is the core diference between what the methods do and the backends? What are some core diferences between the backends? What is the main distinction between GPTQ and NF4? How does NF4 relate to QLoRa, is it the same or is it just a small part of QLoRa?\n Thanks in advance and i apologize for any ignorance.\n ​\n https://preview.redd.it/gxpo0ir0yunb1.png?width=1041&format=png&auto=webp&s=872424a58a9d4393c025b8d2cec0160979b035f4\n    submitted by    /u/MiNeves  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16gx2lg/d_help_understanding_llm_quantization_techniques/",
          "publishedOn": "2023-09-12T17:14:16.000Z",
          "wordCount": 2673,
          "title": "[D] Help Understanding LLM Quantization techniques and how they Relate",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16gvvdo/r_use_of_gpt4_to_analyze_medical_records_of/",
          "author": null,
          "description": "Paper - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10425828/\n  \nSix patients 65 years or older (2 women and 4 men) were included in the analysis. The accuracy of the primary diagnoses made by GPT-4, clinicians, and Isabel DDx Companion was 4 of 6 patients (66.7%), 2 of 6 patients (33.3%), and 0 patients, respectively. If including differential diagnoses, the accuracy was 5 of 6 (83.3%) for GPT-4, 3 of 6 (50.0%) for clinicians, and 2 of 6 (33.3%) for Isabel DDx Companion.\n  \n​\n    submitted by    /u/MysteryInc152  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16gvvdo/r_use_of_gpt4_to_analyze_medical_records_of/",
          "publishedOn": "2023-09-12T16:27:26.000Z",
          "wordCount": 2636,
          "title": "[R] Use of GPT-4 to Analyze Medical Records of Patients With Extensive Investigations and Delayed Diagnosis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16gvjow/r_train_vit_on_small_datasets/",
          "author": null,
          "description": "Hello, everyone,\n I'm currently working on a computer vision project using the Oxford Pets Dataset, which consists of 37 different pet categories. I initially used a pre-trained ViT model with ImageNet weights model=vit_b_32(ViT_B_32_Weights.IMAGENET1K_V1), and it gave me an impressive accuracy of 88%. However, I want to modify the architecture of the ViT model and train it from scratch without relying on ImageNet weights.\n I'm aware that ViT models are data-hungry and that training from scratch (model=vit_b_32( )) can be challenging, especially with limited data. I've already applied data augmentation techniques to enhance my dataset, but I'm still struggling to achieve satisfactory results. My accuracy is currently only 7%.\n I'd appreciate any advice or tips from the community on how I can improve the performance of my scratch-trained ViT model. Are there any specific training strategies, hyperparameters, or architectural modifications that I should consider? How can I make the most out of my limited dataset to boost accuracy?\n Thank you in advance for your help!\n    submitted by    /u/NoEntertainment6225  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16gvjow/r_train_vit_on_small_datasets/",
          "publishedOn": "2023-09-12T16:14:46.000Z",
          "wordCount": 2714,
          "title": "[R] Train ViT on small datasets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16gu9af/pr_developing_a_platform_to_accelerate_the/",
          "author": null,
          "description": "Hi community~\n We are developing a platform similar to mTurk and Prolific and plan to do the first wave of hypothesis testing in the coming weeks. If you have open tasks that require large amounts of human intelligence, please reply to this thread or dm me. We can support your research in our hypothesis testing. \n we are on the mission of helping machine learning experts and AI training as open and public goods, you can learn more here: https://ivynetwork.cloud/ \n feel free to ask more questions here :)\n    submitted by    /u/Accomplished_Code_25  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16gu9af/pr_developing_a_platform_to_accelerate_the/",
          "publishedOn": "2023-09-12T15:24:47.000Z",
          "wordCount": 2638,
          "title": "[P][R] Developing a platform to accelerate the research",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16gs6a9/math_for_machine_learning_d/",
          "author": null,
          "description": "İ have a question. How important linear algebra for machine learning? İ have basic level knowledge on linear? Should İ study in more detail? And How can İ follow roadmap on math for machine learning?\n    submitted by    /u/Necessary-Car-5080  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16gs6a9/math_for_machine_learning_d/",
          "publishedOn": "2023-09-12T14:01:03.000Z",
          "wordCount": 2584,
          "title": "Math for machine learning [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16grcpm/dphas_anyone_ever_tried_finetuning_tortoise_tts/",
          "author": null,
          "description": "Hello people. I've been wanting to clone voices along with the accent. For example: A user speak English in an Indian accent should have that accent cloned in the output audio as well. By default, tortoise is not good at doing that. It can clone the pitch of the voice really well but the accent is completely lost. I was wondering if fine tuning the model could get me what I want. Please do suggest. Also do suggest any methods on fine tuning it if it does in fact help my use case. Thanks a lot!\n Note: I've also tried bark, coqui and vall-e-x. They aren't that good for voice cloning from what I saw.\n    submitted by    /u/salehxoxo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16grcpm/dphas_anyone_ever_tried_finetuning_tortoise_tts/",
          "publishedOn": "2023-09-12T13:25:44.000Z",
          "wordCount": 2670,
          "title": "[D][P]Has anyone ever tried fine-tuning Tortoise tts for better voice cloning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16gpl4h/d_evaluating_a_clothing_size_prediction_model/",
          "author": null,
          "description": "I’ve been working on a simple ML classifier that predicts the size of a piece of clothing based in user body specifications (such as height, weight, age, etc). As we want to move the model to production, I’m keen on understanding the best strategies to evaluate its performance in a real-world setting.\n This is a small example of how we would “tag” our recommendations:\n  \nIf the model predicts a size M, and the user buys and keeps it, it’s a correct prediction\n If the user buys and M and returns it due to size issues, it’s incorrect\n If the user buys a different size, returns it, and then buys the size initially recommended, it’s counted as correct.\n  \nAdditionally since we cache user input data, when they visit the same product after a while, or if they visit different product pages, they don’t need to re-input. We need to determine if they looked at this recommendation or if they even took it into account, especially if some time has passed since the original recommendation was made.\n Main questions I have: 1. What scenarios might I be missing when tagging incorrect/correct predictions 2. How would you approach the data tagging issue in this context? 3. What would be the best strategy to determine if a recommendation was considered by the user or if it’s too old to be reliable?\n I’ve gotten some insights already but would love to hear more perspectives. Any feedback, experiences, or even related research would be much appreciated!\n    submitted by    /u/SufficientPepper1801  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16gpl4h/d_evaluating_a_clothing_size_prediction_model/",
          "publishedOn": "2023-09-12T12:04:07.000Z",
          "wordCount": 2798,
          "title": "[D] Evaluating a clothing size prediction model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16gox7a/r_anyone_working_on_ai_systems_for_the_education/",
          "author": null,
          "description": "We are working on a research project on how to identify contextual hidden bias in real use cases, by simulating real-world situations where AI systems behave in unexpected biased ways, regardless of how well their models have performed during development with their training and testing datasets.\n Would love to hear from those, I'm interested to know if their systems had any issues with misbehaviour in post-market use cases and how they are solving/mitigating this.\n Ps: If anyone is interested to get involved with the wider research, let me know!\n    submitted by    /u/Dismal-Might8594  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16gox7a/r_anyone_working_on_ai_systems_for_the_education/",
          "publishedOn": "2023-09-12T11:33:04.000Z",
          "wordCount": 2649,
          "title": "[R] Anyone working on AI systems for the education, recruitment, HR, credit scoring or financial sectors?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16gofqj/p_ai_npcs_are_closer_than_we_think_i_made_a_new/",
          "author": null,
          "description": "Hello r/MachineLearning!\n After the positive response to Bargainer.ai, I got really excited about the potential of this technology in larger scale video games like World of Warcraft or GTA for example.\n I'm happy to announce that I'm now releasing - Convince the Bouncer!\n This time, you chat with an AI Bouncer and try to gain entry to a very exclusive night club. Don't worry; it's fairly easier than getting into Berghain.\n Try it out here: convincethebouncer.com\n P.S.: Get the VIP Pass from the Bouncer, and you might access an upcoming AI platform early! :)\n Questions or ideas? Let me know. Thanks a bunch!\n    submitted by    /u/gavo_gavo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16gofqj/p_ai_npcs_are_closer_than_we_think_i_made_a_new/",
          "publishedOn": "2023-09-12T11:08:15.000Z",
          "wordCount": 2660,
          "title": "[P] AI NPC's are closer than we think. I made a new game!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16go809/r_factors_influencing_adoption_intention_of/",
          "author": null,
          "description": "Hello,\n ​\n I am an information systems student currently conducting research for my undergraduate thesis on the factors that influence people's adoption intention of ChatGPT, as well as identifying the factors that may be holding them back. These factors include people's concerns about potential negative impacts of ChatGPT, such as increased unemployment and the spread of misinformation. Your participation in this study is crucial as it will provide valuable insights to help us understand how ChatGPT can be improved to meet users' needs.\n ​\n Please note that I am not affiliated with OpenAI, no identifying information will be collected during the survey, and all responses will be kept confidential. The survey should take approximately 10 to 15 minutes to complete, and participation is voluntary. You may withdraw from the survey at any time, and there are no known risks associated with participating.\n ​\n If you are interested in learning more about the study, please follow the link below. \n ​\n https://docs.google.com/forms/d/e/1FAIpQLSf5HIfXHppMuTR63x00i4OuRAtM5Ti6EGybd-HuI1kmK06VPw/viewform?usp=sf_link\n ​\n Thank you for taking the time to contribute to our research study. Your participation is greatly appreciated!\n    submitted by    /u/maulanash  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16go809/r_factors_influencing_adoption_intention_of/",
          "publishedOn": "2023-09-12T10:57:13.000Z",
          "wordCount": 2724,
          "title": "[R] Factors Influencing Adoption Intention of ChatGPT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16gkeie/d_llm_models_for_providing_troubleshooting/",
          "author": null,
          "description": "I want to train an LLM model on data related to the Container Orchestration Platform Kubernetes. The LLM should be able to identify issues, provide commands, and provide troubleshooting solutions for a given input. \n What is the best model for doing so and how much data should I have to train the model?\n    submitted by    /u/faizanbasher  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16gkeie/d_llm_models_for_providing_troubleshooting/",
          "publishedOn": "2023-09-12T07:09:53.000Z",
          "wordCount": 2604,
          "title": "[D] LLM Models for providing troubleshooting suggestions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16giij1/r_textbooks_are_all_you_need_ii_phi15_technical/",
          "author": null,
          "description": "Arxiv link: Textbooks are all you need II\n  \nMore generally, phi-1.5 (1.3B) exhibits many of the traits of much larger LLMs, both good – such as the ability to \"think step by step\" or perform some rudimentary in-context learning – and bad, including hallucinations and the potential for toxic and biased generations – encouragingly though, we are seeing improvement on that front thanks to the absence of web data. We open-source phi-1.5 to promote further research on these urgent topics.\n  \n   submitted by    /u/PantsuWitch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16giij1/r_textbooks_are_all_you_need_ii_phi15_technical/",
          "publishedOn": "2023-09-12T05:17:24.000Z",
          "wordCount": 2634,
          "title": "[R] Textbooks are all you need II: phi-1.5 technical report",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16gbrno/d_is_there_any_up_to_date_speech_denoising_model/",
          "author": null,
          "description": "I have been googling for a few hours now, and all of the solution that I can find are either very complex or not up to date. Ideally I would like to combine this with OpenAI Whisper to clarify the speech audio file and then transcribe it. \n Any good methods for this?\n    submitted by    /u/aszx789  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16gbrno/d_is_there_any_up_to_date_speech_denoising_model/",
          "publishedOn": "2023-09-11T23:56:43.000Z",
          "wordCount": 2606,
          "title": "[D] Is there any up to date speech denoising model?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16gaxqg/d_is_retrieval_necessarysufficient_to_solve/",
          "author": null,
          "description": "Hi everyone,\n \"Hallucinations\" seem to be one of the major blockers to the adoption of LLMs, especially in enterprise settings where seemingly plausible but false information/decisions can be disastrous.\n I am wondering whether or not current LLMs, like GPT4 or Llama 2 70b have reached the reasoning capabilities to be able not to hallucinate when fed the proper information.\n One can see a LLMs as college / high school students that have some basic reasoning and knowledge but might need to be nudged to answer business / scientific questions.\n What is your opinion on the topic? Is there for instance, a database of hallucinations, so that one could test that if the model would have answered properly if the right context was fed in the prompt?\n View Poll\n    submitted by    /u/Separate-Still3770  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16gaxqg/d_is_retrieval_necessarysufficient_to_solve/",
          "publishedOn": "2023-09-11T23:21:12.000Z",
          "wordCount": 2684,
          "title": "[D] Is retrieval necessary/sufficient to solve \"hallucinations\"?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ga4fi/r_i_am_looking_for_a_paper_for_my_research_and/",
          "author": null,
          "description": "I've consulted all the AIs and all of the search engines I could think of and am still coming up short. \n I'm pretty sure I just didn't make this up, somewhere between 2005 and 2015 there was a paper where the authors describe a method for using silicon neuron forests to predict traffic patterns. \n They etched silicon columns onto a wafer and then submerged the wafer in an ionic solution. They sent electrical signals into the column array and recorded the output. As the signal was allowed to interact with the silicon in solution, the columns would begin to form small conductive tendrils or filaments to neighboring pillars. These filaments formed a neural network, which could be used to predict traffic patterns.\n I'm sure there were at least 2 papers that came out about this subject, but for the life of me I cannot find them. I've spent many many hours looking for at least one of the papers and am hoping for a longshot...that some kind internet stranger comes across this and can point me in the right direction.\n    submitted by    /u/Inevitable-Start-653  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ga4fi/r_i_am_looking_for_a_paper_for_my_research_and/",
          "publishedOn": "2023-09-11T22:49:07.000Z",
          "wordCount": 2740,
          "title": "[R] I am looking for a paper for my research and coming up short, help needed.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16g7rzx/d_best_solution_for_video_quality_control/",
          "author": null,
          "description": "What is the best CNN or method for creating a program that can detect video glitches, artifacts, anamolies and highlight them in an exported video as well as producing a .txt file. I'm currently using YOLOV8 which works a bit but it's over detecting and it may not be scalable. Not sure if it has to do with the size of the dataset. Right now, I'm gathering my own dataset, but would love to know if there is one that already exists. Looking for all and any recommendations. Thank you. \n    submitted by    /u/icetyche  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16g7rzx/d_best_solution_for_video_quality_control/",
          "publishedOn": "2023-09-11T21:21:14.000Z",
          "wordCount": 2641,
          "title": "[D] Best Solution for Video Quality Control",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16g60i3/d_svcrvc_tips_for_inferencing_low_quality_audio/",
          "author": null,
          "description": "Please let me know if there is a better sub for this!\n I trained a local voice model of my father, who recently passed away. He was a musician, and I found a handful of songs he had recorded in the 80's. Unfortunately but I only have a copy coming from an audio cassette, which I've digitized. There may be a copy on open reel somewhere in our basement but I haven't found it so far.\n Any, because dad was always writing and recording new songs, my training dataset consists of all original, high quality vocal stems at 96khz/24bit, spanning at least 20 years and consisting of about 30 ish minutes of audio. I also tried starting over but with a speech he gave as additional training, coming out to around 55 minutes of audio.\n I wanted to use his voice model to essentially remaster his original vocals from the cassette audio, and rerecord the rest of the instruments myself. I isolated the vocals using UVR (also tried mdx23), and tried to clean it up further as much as possible.\n The RVC vocals comes out alright, but due to the low quality of the audio, it seems to mess up certain words, for example \"free\" comes out as \"fee\". The SVC vocals came out with a closer tonality, but had many more artifacts, and pitch had a tendency to go up/down 2 octaves at the end of certain phrases.\n When using a higher quality sample (like one of my own vocal tracks), these issues aren't so prevalent, although rvc seems to create more of a hybrid sounding timbre than svc, blending the original voice + model rather than just the sound of the model.\n Happy to post samples of input/output audio, let me know!\n tl;dr\n high quality training data, low quality inference audio. Voice model is the same voice as input audio,\n 1. tips for making the best of what I've got?\n 2. any way to use text along with input audio and maintain original vibrato?\n 3. any way to train a UVR/MDX model using a particular voice in order to better isolate that person?\n thanks :)\n    submitted by    /u/bbmaster123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16g60i3/d_svcrvc_tips_for_inferencing_low_quality_audio/",
          "publishedOn": "2023-09-11T20:17:57.000Z",
          "wordCount": 2904,
          "title": "[D] SVC/RVC tips for inferencing low quality audio?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16g46vu/r_cognitive_architectures_for_language_agents/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.02427 \n Github: https://github.com/ysymyth/awesome-language-agents \n Twitter: https://twitter.com/ShunyuYao12/status/1699396834983362690 \n Abstract: \n  \nRecent efforts have incorporated large language models (LLMs) with external resources (e.g., the Internet) or internal control flows (e.g., prompt chaining) for tasks requiring grounding or reasoning. However, these efforts have largely been piecemeal, lacking a systematic framework for constructing a fully-fledged language agent. To address this challenge, we draw on the rich history of agent design in symbolic artificial intelligence to develop a blueprint for a new wave of cognitive language agents. We first show that LLMs have many of the same properties as production systems, and recent efforts to improve their grounding or reasoning mirror the development of cognitive architectures built around production systems. We then propose Cognitive Architectures for Language Agents (CoALA), a conceptual framework to systematize diverse methods for LLM-based reasoning, grounding, learning, and decision making as instantiations of language agents in the framework. Finally, we use the CoALA framework to highlight gaps and propose actionable directions toward more capable language agents in the future. \n  \nhttps://preview.redd.it/09kdff4sdonb1.jpg?width=1276&format=pjpg&auto=webp&s=7aaa6d59d602f7e9ab124c812bbfa6bba5b7373b\n https://preview.redd.it/6cly0e4sdonb1.jpg?width=1277&format=pjpg&auto=webp&s=5a5164b84af5f828a668560acb64e5c579693d1f\n https://preview.redd.it/mvatjf4sdonb1.jpg?width=1277&format=pjpg&auto=webp&s=7c3a039db3a7e0f3de38f761f8aefa1c8d331ae5\n https://preview.redd.it/bj5wdj4sdonb1.jpg?width=1270&format=pjpg&auto=webp&s=473b273ae0097aaa51d6578e9c5e3b9c953cc421\n https://preview.redd.it/501cnf4sdonb1.jpg?width=1578&format=pjpg&auto=webp&s=c8b1762ac28c89f8ac2f8d4fb6d9ecae06491c3e\n ​\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16g46vu/r_cognitive_architectures_for_language_agents/",
          "publishedOn": "2023-09-11T19:10:50.000Z",
          "wordCount": 2720,
          "title": "[R] Cognitive Architectures for Language Agents - Princeton University 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16g2h55/d_do_you_use_pycharm_for_machine_learning/",
          "author": null,
          "description": "For learning ann, cnn I used Google colab. But now for learning rnn I have decided to use ide(a fan of jetbrains). But even if I change one line of code who code recompiles. This wasn't case for colab. Is there a feature in pycharm I don't know(I learned python through text so don't know much about ide). I am a newbie.\n    submitted by    /u/Coc_Alexander  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16g2h55/d_do_you_use_pycharm_for_machine_learning/",
          "publishedOn": "2023-09-11T18:07:33.000Z",
          "wordCount": 2614,
          "title": "[D] do you use pycharm for machine learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16g27xu/d_using_ai_to_navigate_the_complexities_of/",
          "author": null,
          "description": "I would be interested in hearing opinions for using AI for regulatory assurance and compliance in regulated industries, what are your thoughts?\n Explanation:\n An AI-driven compliance system ensuring adherence to evolving regulations, minimizing risks, and enabling businesses to operate confidently within legal boundaries. Pairing Large Language Models (LLMs) with blockchain technology to offer a range of benefits, particularly in the context of regulatory compliance.\n LLMs, powered by advanced natural language processing and machine learning capabilities, can enhance regulatory compliance processes in several ways. Firstly, they can automate the analysis of regulatory documents, helping businesses stay updated with evolving compliance requirements. LLMs can also assist in generating compliance reports, simplifying complex legal language into\n understandable summaries. Furthermore, by integrating LLMs into smart contracts, businesses\n can ensure that contract terms adhere to regulatory guidelines automatically.\n The integration of LLMs with blockchain can significantly improve regulatory compliance by automating document analysis, simplifying legal language, monitoring compliance in real-time, and enhancing customer interactions—all contributing to greater efficiency and accuracy in adhering to\n regulatory standards.\n I have a whole technical whitepaper with this stuff on hand, if anyone would like to review it let me know..\n    submitted by    /u/cryptobooty_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16g27xu/d_using_ai_to_navigate_the_complexities_of/",
          "publishedOn": "2023-09-11T17:58:27.000Z",
          "wordCount": 2744,
          "title": "[D] Using AI to navigate the complexities of regulatory frameworks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16g1vhj/r_a_surprisingly_effective_way_to_predict_token/",
          "author": null,
          "description": "Hey folks, we explored a novel method to gauge the significance of tokens in prompts given to large language models, without needing direct model access. Essentially, we just did an ablation study on the prompt using cosine similarity of the embeddings as the measure. We got surprisingly promising results when comparing this really simple approach to integrated gradients. Curious to hear thoughts from the community!\n Here are links to the demo and blog post\n    submitted by    /u/shayanjm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16g1vhj/r_a_surprisingly_effective_way_to_predict_token/",
          "publishedOn": "2023-09-11T17:45:03.000Z",
          "wordCount": 2630,
          "title": "[R] A surprisingly effective way to predict token importance in LLM prompts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16g0e8r/d_i_am_looking_for_an_authoritative_consistent/",
          "author": null,
          "description": "I am currently trying to learn about how autodiff is used in gradient calculations. In the all sources I've came across, none can explicitly point to an authoritative, consistent or complete source on autodiff. I don't need examples of autodiff, I just need the full, generalized algorithm laid out.\n For example:\n I open this link: https://w3.cs.jmu.edu/spragunr/CS445/lectures/autodiff/autodiff.pdf which simply provides autodiff applied on an example, but not the description of the algorithm.\n The author of that link says if I need any more info, I should go to this other link: https://stats.stackexchange.com/questions/224140/step-by-step-example-of-reverse-mode-automatic-differentiation/235758#235758\n But this link doesn't even have topological sort as part of the operation. Therefore these descriptions of the autodiff is inconsistent and leaves me not knowing who to trust.\n Can someone point to some original paper on autodiff or a single source that describes this algorithm fully?\n I note here that this situation is completely different from backpropagation. The full backpropagation algorithm is impeccably laid out in peer-reviewed text books such as Learning from Data by Mustafa et al. and Optimization textbook by Chong and Zak. Furthermore, the algorithm defined in these two books are completely consistent with one another. \n    submitted by    /u/fromnighttilldawn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16g0e8r/d_i_am_looking_for_an_authoritative_consistent/",
          "publishedOn": "2023-09-11T16:49:32.000Z",
          "wordCount": 2748,
          "title": "[D] I am looking for an authoritative, consistent and complete description of autodiff.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16fx7ft/r_ai_model_for_cancer_origin_detection/",
          "author": null,
          "description": "https://preview.redd.it/14fj73aw2nnb1.jpg?width=1200&format=pjpg&auto=webp&s=e94612b3dec5f7b9f71490ad5a60ced73fb3373d\n Researchers at MIT and the Dana-Farber Cancer Institute have developed an innovative AI-powered model called OncoNPC, designed to assist in identifying the origin of tumors in cancer patients where the primary site is unknown. For a small percentage of cancer patients, pinpointing the origin of their cancer can be incredibly challenging, making it difficult to select the most appropriate treatment, as many cancer drugs are designed for specific cancer types.\n Using machine learning, the researchers created OncoNPC, a computational model capable of analyzing the genetic sequences of approximately 400 genes. This model, based on genetic data routinely collected at Dana-Farbe…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16fx7ft/r_ai_model_for_cancer_origin_detection/",
          "publishedOn": "2023-09-11T14:47:47.000Z",
          "wordCount": 3167,
          "title": "[R] AI Model for Cancer Origin Detection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16fvr0y/r_locally_hosted_ai_text_model/",
          "author": null,
          "description": "Hello,\n I want to start a small experiment in my company and install an AI locally on my computer, extra only locally, so no company data can be stolen. The AI should be able to summarize large PDFs.\n Which textmodel can you recommend me, which is local and not too big?\n    submitted by    /u/DesNutella  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16fvr0y/r_locally_hosted_ai_text_model/",
          "publishedOn": "2023-09-11T13:47:18.000Z",
          "wordCount": 2601,
          "title": "[R] Locally Hosted AI Text Model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16futp2/d_neural_network_designed_for_model_selection/",
          "author": null,
          "description": "Hi all,\n So, I normally work in a different field (macroeconomics/econometrics) and I have been working on a slightly different project for a bit because a change of pace is fun every once in a while. The problem is I am running out of good ideas on where to continue and i would appreciate any input!\n The problem set up is as follows: \n I am building a second draft for a forecasting toolbox based on a custom ARIMA framework. The problem with this type of exercise is always model selection. For this project I focus on in-sample criterions as the data has very few time periods overall. The typical strategy to find a decent model is to make an initial guess (i.e., a constant model, a random walk model, etc.) and then run a stepping algorithm that probes the model space and, ideally, it coverg…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16futp2/d_neural_network_designed_for_model_selection/",
          "publishedOn": "2023-09-11T13:07:05.000Z",
          "wordCount": 3094,
          "title": "[D] neural network designed for model selection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16fucig/n_seeking_beta_testers_for_qwaks_new_vector_store/",
          "author": null,
          "description": "Hey Redditors,\n We're thrilled to announce a new feature from Qwak.ai—Vector Store—and we're on the hunt for beta testers to help us make it even better.\n 🔍 What's Vector Store?\n Vector Store is a next-level solution for managing vector data. It's designed to empower organizations to harness the power of vector search on their own datasets. Here's what it offers:\n  \n🔄 Automated Data Ingestion: Schedule jobs to pull data from databases like Snowflake, BigQuery, and RedShift.\n 🎯 Easy Vector Search: Use our Python SDK or REST API to search, upsert, or delete vectors effortlessly.\n 🛡️ Secure Storage: Your vectors are stored securely and are always accessible when you need them.\n  \n📖 Learn More About Vector Store\n 🤝 Why We Need Beta Testers\n We're keen to gather insights on usability, performance, and any bugs that might pop up.\n 📝 How to Get Involved\n Interested in being a part of this? Comment below or shoot us a DM.\n    submitted by    /u/Practical-Lecture733  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16fucig/n_seeking_beta_testers_for_qwaks_new_vector_store/",
          "publishedOn": "2023-09-11T12:44:51.000Z",
          "wordCount": 2715,
          "title": "[N] Seeking Beta Testers for Qwak's New Vector Store Feature: Revolutionize Your Vector Data Management!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16fu8wh/d_text_segmenting_using_spacy_and_bert/",
          "author": null,
          "description": "Hi. I need to segment some short strings, they are about 100 tokens in length (BERT tokens), or 20-40 words. 1 segment per text.\n I'm currently using Spacy first, and if it fails, then use BERT. It's alright, but BERT is not really up to par to what I hope for. I'm wondering if there is some better use, as this is my first NLP project. I've trained the huggingface BertForTokenClassification to label the text as either part of segment, or not part. So binary token classification, then smooth out outliers and pick the longest segment of each text. Each string has only 1 segment.\n I've trained the BERT with 500 examples. I can easily make more train data, though training on my laptop takes time. If there are better/alternative approaches, I'd love to hear them. Regex rules etc. don't apply, which is why I'm using DL models. Especially I feel like I should segment the whole segment at a time, not by token.\n    submitted by    /u/Infamous-Bank-7739  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16fu8wh/d_text_segmenting_using_spacy_and_bert/",
          "publishedOn": "2023-09-11T12:40:06.000Z",
          "wordCount": 2715,
          "title": "[D] Text segmenting using Spacy and BERT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16fu56p/d_appreciation_post_for_folktables_datasets/",
          "author": null,
          "description": "I want to take a second to express my appreciation for the Folktables datasets!\n Folktables is a Python package that contains datasets derived from US Census data. The datasets cover topics about income, employment, health, transportation, and housing. They are quite useful for studying the effects of distribution shifts on ML models.\n For example, one could design experiments to:\n 1. Study the model's performance under geographic distribution shifts:\n Each prediction problem in Folktables can be instantiated with data from every US state. So one could use Folktables to study questions around geographic distribution shifts. For example, we can train a classifier using data from California and then evaluate it on data from Michigan.\n 2. Study the model's performance under temporal distribution shifts.\n Folktables contains data for several years, which in itself constitutes a form of temporal distribution shift. So, we can train a classifier using employment data from California in 2014 and evaluate how its equality of opportunity violation or accuracy varies over time.\n Finding non-synthetic (and open-access) datasets that exhibit these behaviors is so hard! Yet, it's quite easy to encounter them in production environments. 🫠\n So, big kudos to the UC Berkeley and Toyota Research Institute research teams for crafting these datasets.\n Folktables Python package: https://github.com/socialfoundations/folktables\n Link to paper where Folktables was introduced: https://arxiv.org/pdf/2108.04884.pdf\n    submitted by    /u/santiviquez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16fu56p/d_appreciation_post_for_folktables_datasets/",
          "publishedOn": "2023-09-11T12:34:59.000Z",
          "wordCount": 2766,
          "title": "[D] Appreciation post for Folktables datasets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ftdhl/r_problem_with_understanding_extended_kalman/",
          "author": null,
          "description": "Hey, I'm working on Attitude-Heading Reference System, and I would like to make it with EKF. My approach is to use Euler angles for computing [roll, pitch, yaw] matrix.\n I read a book \"Small unmanned aircraft: theory and practice\" and watched few videos on YouTube that are reffering to this particular book. But there is a thing in correction step that I do not fully understand. To be clear, the correction looks as follows: x = x_(t-1) + K*(z - h(x))\n Both in the book and in videos, the state vector \"x\" is [roll, pitch]. But \"z\" and \"h(x)\" are the actual and predicted accelerometer readings [ax, ay, az]. So it looks to me, that they try to correct prediction of angles with readings in acceleration: [roll, pitch] = [roll, pitch]_(t-1) + K*[ax, ay, az].\n What am I missing?\n    submitted by    /u/Skrz_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ftdhl/r_problem_with_understanding_extended_kalman/",
          "publishedOn": "2023-09-11T11:56:44.000Z",
          "wordCount": 2690,
          "title": "[R] Problem with understanding Extended Kalman Filter",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ftd9v/p_whisper_large_benchmark_137_days_of_audio/",
          "author": null,
          "description": "We recently benchmarked whisper-large-v2 against the substantial English CommonVoice dataset on a distributed cloud (SaladCloud) with consumer GPUs.\n The Result: Transcribed 137 days of audio in 15 hrs for just $117.\n Traditionally, utilizing a managed service like AWS Transcribe would set you back about $10,500 for transcribing the entirety of the English CommonVoice dataset.\n Using a custom model? That’s an even steeper $13,134.\n In contrast, our approach using Whisper on a distributed cloud cost just $117, achieving the same result.\n The Architecture:\n Our simple batch processing framework comprises:\n  \nStorage: Audio files stored in AWS S3. \n Queue System: Jobs queued via AWS SQS, with unique identifiers and accessible URLs for each audio clip.\n Transcription & Storage: Post transcript…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ftd9v/p_whisper_large_benchmark_137_days_of_audio/",
          "publishedOn": "2023-09-11T11:56:24.000Z",
          "wordCount": 2888,
          "title": "[P] Whisper Large Benchmark: 137 DAYS of Audio Transcribed in 15 Hours for Just $117 ($0.00059/min)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ft5v8/need_help_with_cnn_data_format_for_genomics_r/",
          "author": null,
          "description": "Hello,\n I wrote CNN using tensor flow to predict phenotypes (cognitive impairment (0/1) and language ability (0-3)) from .vcf files.\n I transformed the .vcf into tabular format and after determining which columns to keep, I have\n Chromosome Position Mutation (taken from ref/alt columns) Genotype\n And merged it with the phenotype data so basically every row has the cog and language scores.\n I feel like this is a bad way to go about doing this since the model is likely predicting cog/language scores for each mutation rather than each patient as a whole. Am I wrong? How can I fix this so it’s more of a composite of all mutations per subject that the model trains on?\n Thanks!\n    submitted by    /u/Pristine_Ingenuity49  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ft5v8/need_help_with_cnn_data_format_for_genomics_r/",
          "publishedOn": "2023-09-11T11:45:49.000Z",
          "wordCount": 2670,
          "title": "Need help with CNN data format for genomics [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16fqm76/d_automatic_split_a_video_into_chapters/",
          "author": null,
          "description": "Given a video with audio, we can use ASR to get a script of the sentences and timestamps. We are looking for a way to group the sentences into chapters. There are several companies that are doing it nicely - Google on YouTube, Assembly AI, but we couldn't find any good resource or paper that explains the research behind how they do it. BertTopic seems to give us just a topic for each sentence, but not a way to split the video. it also doesnt account for timestamps.\n Wondered if anyone has any links or any other ideas?\n Thanks very much!\n Lior\n    submitted by    /u/liormessinger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16fqm76/d_automatic_split_a_video_into_chapters/",
          "publishedOn": "2023-09-11T09:18:28.000Z",
          "wordCount": 2653,
          "title": "[D] Automatic split a video into chapters?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16fkesy/p_data_structures_for_large_sequences/",
          "author": null,
          "description": "Hi everyone\n I've been working for quite some time on this project and any feedback will be greatly appreciated. \n Basically, I've been testing different data structures for large sequence prediction and clustering. Mainly SARSCov2 viral sequences due to its availability. At the moment, I have published two preprints \n  \nhttps://www.researchsquare.com/article/rs-2797280/v3\n https://www.researchsquare.com/article/rs-1691291/v1\n  \nand a general summary of the findings can be found here. \n  \nhttps://github.com/TavoGLC/SARSCov2Solar\n https://www.kaggle.com/code/tavoglc/a-computational-description-of-sarscov2-adaptation\n  \nI've tried to publish it a couple of times with no success and no comments regarding its accuracy or any potential problems. I hope you guys can check it out and provide some feedback if possible. Just for full transparency, I'm trying to raise funds to further develop those techniques. Donations are extremely welcomed but not encouraged at the moment, just disclosed for transparency. \n    submitted by    /u/TavoGLC  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16fkesy/p_data_structures_for_large_sequences/",
          "publishedOn": "2023-09-11T03:14:58.000Z",
          "wordCount": 2677,
          "title": "[P] Data structures for large sequences",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16fgely/using_llms_to_analyze_and_extract_insights_from/",
          "author": null,
          "description": "I work with device logs that are massive text files, filled with data that's hard to go through manually. I'm primarily interested in extracting specific events or insights, such as security incidents or device malfunctions. The conventional method would be to use regular expressions to filter out relevant information since the logs are structured, but I'm curious about leveraging Large Language Models for this task.\n I've experimented a bit with zero-shot learning for text summarization but didn't get satisfactory results. Before I invest more time into fine-tuning an LLM, I'd love to hear from anyone who has experience or advice on how to approach this problem.\n Could LLMs potentially make the process more efficient and effective? Any pointers or suggestions would be greatly appreciated.\n    submitted by    /u/Practical_Mango_8720  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16fgely/using_llms_to_analyze_and_extract_insights_from/",
          "publishedOn": "2023-09-11T00:12:27.000Z",
          "wordCount": 2679,
          "title": "Using LLMs to Analyze and Extract Insights from Device Logs [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16feyvh/n_meta_is_developing_a_new_more_powerful_ai/",
          "author": null,
          "description": "submitted by    /u/hzj5790  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16feyvh/n_meta_is_developing_a_new_more_powerful_ai/",
          "publishedOn": "2023-09-10T23:12:20.000Z",
          "wordCount": 2624,
          "title": "[N] Meta Is Developing a New, More Powerful AI System as Technology Race Escalates",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16fenlb/d_data_extraction_using_finetuned_llm/",
          "author": null,
          "description": "Hey Reddit,\n I'm working on a tool to pull data from highly irregular Excel files. I've gotten reasonable results which is extremely fast with standard Python coding, but it's far from perfect due to the lack of standardized templates. \n Interestingly, when I tested ChatGPT-4 on a sample table, it did a decent job at data extraction. However, relying solely on GPT-4 has its downsides like token limits and slow processing speed (and data privacy issues). Plus, splitting the Excel sheet to fit within these limits results in loss of context and data.\n I'm considering fine-tuning a language model to post-process data that was in a Pandas DataFrame (perhaps converted to JSON). Has anyone had success with this approach or have alternative recommendations? I've tried Langchain, but it wasn't helpful.\n I have figured out to extract the relevant columns, but the post-processing part is where I am considering using an LLM which understands the domain and what needs to be extracted based on the examples I feed it.\n Looking forward to your thoughts! And would be happy to answer any additional questions.\n    submitted by    /u/rs35plus1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16fenlb/d_data_extraction_using_finetuned_llm/",
          "publishedOn": "2023-09-10T22:59:42.000Z",
          "wordCount": 2731,
          "title": "[D] Data Extraction using fine-tuned LLM?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16faaux/d_should_i_transfer_all_my_work_to_pytorch_already/",
          "author": null,
          "description": "I've been using Tensorflow since 2017. I know it wasn't ideal or easy back then, but as an early adopter, I became very proficient with it and it has improved a lot since then. I have developed and deployed many custom models in low-level TF, both with and without utilizing the Keras abstractions. I am very comfortable with it in general.\n But I'm noticing now that Pytorch is gaining more popularity, all the younger practitioners, who got into deep learning within the last 3-5 years, are Pytorch adopters. I've also heard rumors that even googlers are also abandoning TF.\n I started playing around with Pytorch and as a TF expert, I couldn't help but getting annoyed at how far it is lagging behind in many abstractions and optimizations. I know things are getting better now with the Pytorch 2.0 and introducing some optimization such as the \"compile\" functionality, but still many of the pytorch project tools remain in beta such as Torchtext and I find many things very annoying, such as having to set the device and pass it on to layers if you want GPU acceleration, having to install Torchtext and other processing libraries separately, or having to use a Dataloader and the limited data type supports for torchdataset.\n Most people who have not mastered Tensorflow would not relate to my annoyance. Anyhow I'd really prefer to stay within my comfort zone and continue to develop and improve in TF, but if TF is dying, then I better not to, right? So should I convert? Is it indeed dying?\n    submitted by    /u/DieselZRebel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16faaux/d_should_i_transfer_all_my_work_to_pytorch_already/",
          "publishedOn": "2023-09-10T20:11:15.000Z",
          "wordCount": 2814,
          "title": "[D] Should I transfer all my work to PyTorch already?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16f9uph/d_this_is_my_first_blog_on_medium_about_machine/",
          "author": null,
          "description": "submitted by    /u/indusop  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16f9uph/d_this_is_my_first_blog_on_medium_about_machine/",
          "publishedOn": "2023-09-10T19:54:16.000Z",
          "wordCount": 2574,
          "title": "[D] This is my first blog on medium about Machine Learning please have a look and show some love",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16f5squ/d_bayesian_net_a_neural_network_for_bernoulli/",
          "author": null,
          "description": "What do you think of my recent work?\n https://github.com/jacobmcasey/bayesian_net\n At its core, its a neural network for Bernoulli naive Bayes. It uses a 3-layer neural network in NumPy for predicting priors of Bernoulli Naive Bayes\n Would love to get your feedback on this classifier project!\n    submitted by    /u/Ok_Grape_3670  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16f5squ/d_bayesian_net_a_neural_network_for_bernoulli/",
          "publishedOn": "2023-09-10T17:17:04.000Z",
          "wordCount": 2654,
          "title": "[D] Bayesian_Net: A neural network for Bernoulli naive Bayes classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16f5myk/d_how_to_solve_loss_spikes_in_pretraining/",
          "author": null,
          "description": "It happens on and off and I have tweaked many hyperparameters but nothing seems to work significantly better. Is there a recommendation on what to check/tweak?\n    submitted by    /u/MrAaronW  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16f5myk/d_how_to_solve_loss_spikes_in_pretraining/",
          "publishedOn": "2023-09-10T17:10:26.000Z",
          "wordCount": 2578,
          "title": "[D] How to solve loss spikes in pre-training?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16f2e96/d_simple_questions_thread/",
          "author": null,
          "description": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n Thread will stay alive until next one so keep posting after the date in the title.\n Thanks to everyone for answering questions in the previous thread!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16f2e96/d_simple_questions_thread/",
          "publishedOn": "2023-09-10T15:00:38.000Z",
          "wordCount": 2652,
          "title": "[D] Simple Questions Thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16f24wf/d_pdf_text_to_speech/",
          "author": null,
          "description": "Hey, I would like to listen to my PDFs I got. Week would the best / easiest way to get an mp3 from my pdfs with good voice? \n I got a rtx 3070 to run it locally.\n    submitted by    /u/Independent_Hyena495  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16f24wf/d_pdf_text_to_speech/",
          "publishedOn": "2023-09-10T14:49:48.000Z",
          "wordCount": 2641,
          "title": "[D] Pdf text to speech",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16f0kxv/d_naive_pipelining_of_llm_inference_across/",
          "author": null,
          "description": "For transformer inference, is it ok to pipeline blocks/layers to multiple low-memory GPUs (lower blocks to GPU-A and upper blocks to GPU-B) ?\n  \nA to B bandwidth should be relatively low, and each GPU needs half the model memory.\n This increases inference latency - fine for our use case...\n Not sure how this would affect the KV cache ?\n  \nThe excellent Lil'Log article suggest I read the training optimization article, which has this image which is for training but not for inference\n    submitted by    /u/yazriel0  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16f0kxv/d_naive_pipelining_of_llm_inference_across/",
          "publishedOn": "2023-09-10T13:40:58.000Z",
          "wordCount": 2637,
          "title": "[D] Naive pipelining of LLM inference across multiple small GPUs? (self.MachineLearning)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16f0d1u/d_best_architecture_for_prediction_logging_in/",
          "author": null,
          "description": "I am in the process of setting up the first iteration of model monitoring in production. Models are currently served through torchserve in kubernetes (on GCP). In the pasts few years I've been mainly using Vertex AI off-the-shelf tools.\n Ideally, I'd like to store the following data:\n  \nRequest input.\n Model prediction.\n User feedback/groud truth (this might come at a later time).\n Anything that I might be missing out.\n  \nThis would enable me to implement a wide array (either using libraries like whylogs or evidently that have a lot of the reporting side of things already baked in) of cheks for drift and model degradation.\n I am wondering what would be the best set up to achieve this. This is currently what I came up with:\n  \nSave a payload at inference time containing all the fields descr…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16f0d1u/d_best_architecture_for_prediction_logging_in/",
          "publishedOn": "2023-09-10T13:31:08.000Z",
          "wordCount": 2934,
          "title": "[D] Best architecture for prediction logging in production",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16f0157/d_hf_accelerate_vs_native_pytorch_autoscaling_for/",
          "author": null,
          "description": "I want to start using mixed precision in my training, particularly for CV with high-resolution images.\n HF accelerate seems quite popular nowadays and looks nice. However, in the past I've invested in learning things like Pytorch-Lightning which look good in a minimal example, but actually add more annoyance than they're worth.\n Pytorch also can do these things, and the boiler plate doesn't look worse at a glance:\n https://pytorch.org/blog/accelerating-training-on-nvidia-gpus-with-pytorch-automatic-mixed-precision/\n https://huggingface.co/docs/accelerate/index\n ​\n Any experiences with either? Cheers!\n ​\n    submitted by    /u/AuspiciousApple  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16f0157/d_hf_accelerate_vs_native_pytorch_autoscaling_for/",
          "publishedOn": "2023-09-10T13:15:05.000Z",
          "wordCount": 2684,
          "title": "[D] HF accelerate vs native pytorch autoscaling for mixed precision training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ezwl8/d_using_llms_to_build_evaluation_sets/",
          "author": null,
          "description": "Hi. Is this really better practice than having human linguists build evaluation sets for domain-specific data?\n    submitted by    /u/throwaway34334534  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ezwl8/d_using_llms_to_build_evaluation_sets/",
          "publishedOn": "2023-09-10T13:08:51.000Z",
          "wordCount": 2622,
          "title": "[D] Using LLMs to build Evaluation Sets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16eyejc/p_rlhf_and_its_alternatives/",
          "author": null,
          "description": "submitted by    /u/seraschka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16eyejc/p_rlhf_and_its_alternatives/",
          "publishedOn": "2023-09-10T11:54:28.000Z",
          "wordCount": 2560,
          "title": "[P] RLHF and Its Alternatives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ex3xq/p_opensource_python_package_for_exploratory_data/",
          "author": null,
          "description": "If you're working on NLP and you're serious about understanding your data, check out Wordview. \n Wordview is an open-source Python library designed to make Exploratory Data Analysis (EDA) for text for modern NLP applications simpler and more efficient. It consolidates various analysis tools under one roof —think document metrics, multi-word expressions, language identification, POS tags, and even bias analysis. We're looking for contributors to help us expand and refine its capabilities. Join us in making NLP data analysis easier and more insightful with Wordview!\n Here is the link to the GitHub page:\n https://github.com/meghdadFar/wordview\n If you just want to use Wordview without contributing, you're very welcome too. Note that it's pretty new and we are still testing things. Please hence feel free to report bugs and send us your feedback and opinions.\n Looking forward!\n    submitted by    /u/SyntaxTreeHugger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ex3xq/p_opensource_python_package_for_exploratory_data/",
          "publishedOn": "2023-09-10T10:41:35.000Z",
          "wordCount": 2692,
          "title": "[P] Open-source Python package for Exploratory Data Analysis for modern NLP applications looking for contributors.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ewsro/d_question_about_dealing_with_eeg_intersubject/",
          "author": null,
          "description": "Hi, I'm an undergrad student working on a machine learning project about motor imagery classification for BCI. One requirement for the project is that I need to implement LIME an explainable AI tool on my model. I ran into a problem rather quickly as my model accuracy quickly decreases as I try and add more subjects to the training data, I'm the publicly avaliable EEG Motor Movement/Imagery Dataset from physio.net. The features I'm currently using for training my model are SVD entropy, Spectral Entropy, Hjorth mobility , Hjorth complexity and CSP components after applying overlapping filter bank.\n One method I've been suggested is to train models seperately for each subject, I don't know how to go about this should I construct a new model for each subject or should I keep the architecture but reset the training weight, also would this defeat the purpose of implementing LIME in the first place.\n I'm wondering if there's a way to deal with inter-subject variability without having to make/ train models for each subject seperately.\n I'm sorry if the choice of features doesn't make much sense since I'm basically self-taught and I have no prior knowledge about EEG or BCI\n TLDR; how do I deal with inter-subject variability without having to make/ train models for each subject seperately.\n    submitted by    /u/Necrozx13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ewsro/d_question_about_dealing_with_eeg_intersubject/",
          "publishedOn": "2023-09-10T10:23:10.000Z",
          "wordCount": 2826,
          "title": "[D] Question about dealing with EEG inter-subject Variability when training ML models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ew13s/p_automatic_hyperparameter_tuning_for_catboost/",
          "author": null,
          "description": "Hey friends,\n I have developed a library, called 100gecs, that makes hyperparameter tuning on LightGBM and CatBoost models trivially easy.\n Background\n LightGBM and CatBoost are gradient boosted tree models, like XGBoost, and in many cases the best baseline model in supervised learning tasks on tabular data. They work by iteratively fitting trees on data, with each subsequent tree \"correcting\" on some level the prediction of the prior tree. Here's a good intro, if you want some more background on these methods.\n Hyperparameter tuning promises an optimally or near-optimally configured model, thus enabling you to get the best baseline model you possibly can.\n Summary\n 100gecs provides custom child classes of LGBMClassifier, LGBMRegressor, CatBoostRegressor and CatBoostClassifier that can be …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ew13s/p_automatic_hyperparameter_tuning_for_catboost/",
          "publishedOn": "2023-09-10T09:37:29.000Z",
          "wordCount": 2955,
          "title": "[P] Automatic hyperparameter tuning for CatBoost and LightGBM",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16eusmb/d_does_entry_level_ml_exist_in_europe/",
          "author": null,
          "description": "In your informed opinion, how would an archetypical career in ML look like? \n Looking at job postings, at least in Europe, it looks like the minimum required experience is around 3 years. There seems to be a good demand for mid-senior level positions, but a void for entry level. As I understand it, most DS departments are not big enough to spare resources for newbies that must be trained, the need is for a few but seasoned engineers. How far is my guess from the truth? \n And, most importantly, how could new candidates (let's say recent MSc in Data Science, for instance) get into the industry? Through analyst/DE roles?\n    submitted by    /u/madway99  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16eusmb/d_does_entry_level_ml_exist_in_europe/",
          "publishedOn": "2023-09-10T08:21:16.000Z",
          "wordCount": 2661,
          "title": "[D] Does Entry Level ML exist (in Europe)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16eukhe/d_any_free_ai_text_to_speech_programs_that_let_me/",
          "author": null,
          "description": "Hello everyone I've wanted to test some AI voice models I created with a free AI Text to-speech program Are there any available to test my voice models \n    submitted by    /u/mrbeanfan64  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16eukhe/d_any_free_ai_text_to_speech_programs_that_let_me/",
          "publishedOn": "2023-09-10T08:07:19.000Z",
          "wordCount": 2643,
          "title": "[D] Any free ai text to speech programs that let me test my own voice models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16eujsx/d_cant_get_tensorflow_or_pytorch_to_detect_my/",
          "author": null,
          "description": "I dont know what it could be the issue, I have tried everything from reinstalling the pip packages, running them on a virtual env, reinstalled CUDA, trying to run on PyCharm instead of VSCode, I got no idea what to do, does anyone know why it could be happening? Maybe something related to environment variables that I maybe messed up after watching like 5 different vids on the topic? What could it be?\n    submitted by    /u/someredditguy374632  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16eujsx/d_cant_get_tensorflow_or_pytorch_to_detect_my/",
          "publishedOn": "2023-09-10T08:06:05.000Z",
          "wordCount": 2684,
          "title": "[D] Cant get TensorFlow or PyTorch to detect my 4090 Laptop GPU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16etk1f/d_codellamaxbcodellamaxbpython_vs/",
          "author": null,
          "description": "Hey guys, so I have googled around and read the documentation but I am still confused between what's the difference between CodeLlama-xb/CodeLlama-xb-Python vs. CodeLlama-xb-instruct? I know the xb model is the base model (for several languages) and the Python model specializes in Python, but what's the instruct model and how is it different from the other 2 models?\n Would really appreciate your help. Thanks a million!\n    submitted by    /u/--leockl--  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16etk1f/d_codellamaxbcodellamaxbpython_vs/",
          "publishedOn": "2023-09-10T07:07:48.000Z",
          "wordCount": 2614,
          "title": "[D] CodeLlama-xb/CodeLlama-xb-Python vs. CodeLlama-xb-instruct",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16et52j/r_make_use_of_cpus_on_8_servers/",
          "author": null,
          "description": "I have a blade system with 8 blades. Each blade has 28 cores (e5-2680 v4) and 180gb ram. I would love to run an LLM + Local Files ( kind of like OpenAI does with their api) and run something similar but most “privategpt” LLMs need GPU support and don’t look like they make use of a multi device setup. \n Anyway to get crunching on CPU on my setup\n    submitted by    /u/programmrz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16et52j/r_make_use_of_cpus_on_8_servers/",
          "publishedOn": "2023-09-10T06:43:36.000Z",
          "wordCount": 2621,
          "title": "[R] Make use of CPUs on 8 servers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16elxqa/discussion_seeking_guidance_transitioning_from/",
          "author": null,
          "description": "Hello everyone!\n I'm a truck driver with a passion for creating music. While I'm familiar with basic IT tasks from my personal experiences, I'm new to the tech industry and am eager to break in.\n I've been exploring AI tools like ChatGPT and have become comfortable navigating GitHub. These experiences make me confident about diving into the tech field. After some research, I'm contemplating three domains:\n  \nCloud Technology: It seems stable and beginner-friendly. I'm leaning here primarily because I've heard cybersecurity is saturated.\n Cybersecurity: Interested but cautious due to market saturation.\n Generative AI/Data: My true passion lies here, but I've gathered that projects matter more than certifications for entry-level roles in this niche, especially for someone without a degree.\n  \nGiven my background and no technical degree, which field would you suggest I pursue? Should I focus on certifications before taking on projects? I genuinely appreciate any insights!\n (What do you guys think about this “CloudRoad map” is it good advice?) \n https://www.madebygps.com/cloudcamp/\n [Discussion]\n    submitted by    /u/motluv_them  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16elxqa/discussion_seeking_guidance_transitioning_from/",
          "publishedOn": "2023-09-10T00:37:16.000Z",
          "wordCount": 2769,
          "title": "[Discussion] Seeking Guidance: Transitioning from Trucking to Tech",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ekpou/discussion_anticipatory_customer_support_using_ml/",
          "author": null,
          "description": "Hey everyone, I'm Raynel, working on a CRM platform and actively considering the future integration of AI. One idea I'm particularly excited about is anticipatory customer support. The goal is to proactively address customer needs, perhaps even before they realize them, using ML-driven insights.\n Has anyone delved into this concept or tried implementing it? I'd love to hear thoughts, potential pitfalls, or even success stories. Thanks in advance for your insights!\n    submitted by    /u/bess_point  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ekpou/discussion_anticipatory_customer_support_using_ml/",
          "publishedOn": "2023-09-09T23:44:24.000Z",
          "wordCount": 2624,
          "title": "[Discussion] Anticipatory Customer Support using ML - Your Thoughts?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ekjmz/d_what_is_good_replacement_for_package_manager/",
          "author": null,
          "description": "I used to build on top of conda, or make docker containers with conda package manager, now that is so broken it is impossible to install old pytorch on a fresh environment. Any way to replace the existing requirements with something better?\n    submitted by    /u/AardvarkNo6658  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ekjmz/d_what_is_good_replacement_for_package_manager/",
          "publishedOn": "2023-09-09T23:37:09.000Z",
          "wordCount": 2594,
          "title": "[D] What is good replacement for package manager",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ekh5i/d_are_statistics_and_ml_too_ununified_as_fields/",
          "author": null,
          "description": "I thought it would be interesting to open this discussion, I would like to hear what you guys have to say about that. I know that ML folks use statistics all the time, but I am often under the impression that it's mostly the basics. I understand that inference and prediction are inherently different, but I would assume the common knowledge will be much more vast.\n What is your perspective on that? Am I just missing the point? Is there room for improvement in the future? Do you think statistics literacy (advanced, not ANOVA or so) is common among ML practitioners?\n    submitted by    /u/pyepyepie  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ekh5i/d_are_statistics_and_ml_too_ununified_as_fields/",
          "publishedOn": "2023-09-09T23:34:14.000Z",
          "wordCount": 2709,
          "title": "[D] Are statistics and ML too \"ununified\" as fields?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ejm3k/dwhat_are_some_generative_ai_techniques_to/",
          "author": null,
          "description": "I wish to generate visuals that are synced with beats etc of the music to offer the \"sensory synchronization\" effect where visuals closely sync with the music. I have found Lucid sonic dreams, but it appears to be quite buggy and likely no longer supported. any recommendations for tools I can leverage for a hobby->serious project of generating visuals synced with music.\n edit: I looked into simple approaches using fft like described here. But I was hoping there are newer generative ai techniques we could leverage.\n    submitted by    /u/bluzkluz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ejm3k/dwhat_are_some_generative_ai_techniques_to/",
          "publishedOn": "2023-09-09T22:58:37.000Z",
          "wordCount": 2642,
          "title": "[D]what are some generative ai techniques to generate visuals synchronized with music",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16eibsg/d_starting_a_research_lab_any_advice_on_computing/",
          "author": null,
          "description": "I'm starting a research lab at a Top 25 research university next year and my research agenda is focused on AI/DL for a scientific domain, I have to come up with a plan and budget for my software/hardware needs.\n My Context:\n I have experience setting up linux systems, building computers by myself and training DL models (CNNs/GNNs/LLMs) in a corporate setting. I am venturing to the academic world where resources are more constrained and so I am wondering if there are any guides, tips on setting up a research computer lab that does AI. I do not expect to train from scratch an LLM but maybe finetuning an small LLM. I might also need to do a lot parallelizable IO work to preprocess data. I will talk with the IT department of the university but would like to have some ideas before that conversation.\n I would appreciate any tips or thoughts, particularly on:\n * How many GPUs/CPUs to buy? Balancing cost/compute.\n * Recommended software for managing resources.\n * Running 100s-1ks of CPU jobs in parallel.\n * Local compute cluster vs buying compute online.\n * Hyperparameter optimization and logging of metrics.\n * Anything else you can think of?\n    submitted by    /u/prof_is_training  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16eibsg/d_starting_a_research_lab_any_advice_on_computing/",
          "publishedOn": "2023-09-09T22:06:39.000Z",
          "wordCount": 2806,
          "title": "[D] Starting a research lab, any advice on computing infrastructure?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16eh1t5/p_goodwiki_dataset_mit_wikipedia_articles_in/",
          "author": null,
          "description": "Location: https://huggingface.co/datasets/euirim/goodwiki\n Hi everyone, just wanted to share a dataset I've been working on for use in a personal project!\n GoodWiki is a 179 million token dataset of English Wikipedia articles collected on September 4, 2023, that have been marked as Good or Featured by Wikipedia editors. The dataset provides these articles in GitHub-flavored Markdown format, preserving layout features like lists, code blocks, math, and block quotes, unlike many other public Wikipedia datasets. Articles are accompanied by a short description of the page as well as any associated categories.\n Thanks to a careful conversion process from wikicode, the markup language used by Wikipedia, articles in GoodWiki are generally faithful reproductions of the corresponding original Wikipedia pages, minus references, files, infoboxes, and tables. Curated template transclusion and HTML tag handling have minimized instances where entire words and phrases are missing mid-sentence like in other public Wikipedia datasets.\n GoodWiki is more than 1.5 times larger (when compared using the same tokenizer) than the widely used WikiText-103 dataset by Merity et al., even after excluding article descriptions. Also limited to articles marked as Good or Featured, WikiText inspired GoodWiki.\n    submitted by    /u/euirim  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16eh1t5/p_goodwiki_dataset_mit_wikipedia_articles_in/",
          "publishedOn": "2023-09-09T21:16:43.000Z",
          "wordCount": 2798,
          "title": "[P] GoodWiki Dataset (MIT): Wikipedia Articles in Markdown With Lists, Blockquotes, and More",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16eguum/dsuffer_from_a_lack_of_opportunities_in_ml/",
          "author": null,
          "description": "I wanna learn ML and i love this field there is people told me that the opportunities in this field is few (i live in egypt btw)and in USA also they suffer from a lack of opportunities in this field so is that true and should i choose another field or not because i really wanna learn ML .\n    submitted by    /u/Opening-Being-7692  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16eguum/dsuffer_from_a_lack_of_opportunities_in_ml/",
          "publishedOn": "2023-09-09T21:09:05.000Z",
          "wordCount": 2611,
          "title": "[D]Suffer from a lack of opportunities in ML?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16edqy3/p_model_predicting_the_same_outcome_for_all/",
          "author": null,
          "description": "Im currently working on deploying an ML model that predicts NFL MVPs (two possible outputs: 0 for not MVP and 1 for MVP). That being said, during deployment it is currently predicting 0 for all inputs regardless of how varied the inputs may be. However, during the testing phase my model had a varied accuracy rate of 75%-85%. I'm beginning to think that it is very likely that during the testing phase the model was predicting 0 for everything and just getting these higher accuracy rates because of the dominance of non-MVPs within my dataset. This all being said, I'm a noob to ML and decided it'd be best to come on here for help. Is that the likely reason and if so how do I go about fixing it? Furthermore, what other issues could cause this and how would I go about fixing it?\n    submitted by    /u/saggyboobsarecooltoo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16edqy3/p_model_predicting_the_same_outcome_for_all/",
          "publishedOn": "2023-09-09T19:01:52.000Z",
          "wordCount": 2698,
          "title": "[P] Model predicting the same outcome for all entries",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ebiu4/p_i_made_a_website_that_uses_llms_to_help_you/",
          "author": null,
          "description": "submitted by    /u/spline_reticulator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ebiu4/p_i_made_a_website_that_uses_llms_to_help_you/",
          "publishedOn": "2023-09-09T17:31:41.000Z",
          "wordCount": 2560,
          "title": "[P] I made a website that uses LLMs to help you gain insights about your documents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16eag65/llm_on_blockchain_d/",
          "author": null,
          "description": "I recently discovered a python library called 'Petals' that should run most LLM models (LLaMA2, Stable Beluga) on some kind of \"torrent\" for machine learning on your device: https://github.com/bigscience-workshop/petals/,\n https://www.youtube.com/watch?v=8jEGVaRKmFc\n Furthermore, if you participate as a \"server\" in this \"torrent\" you can be rewarded (according to YouTube)\n Sounds too good to be true, so I didn't try it yet. Does anyone have experience with it? Can I get a virus from there? Is it not a scam?\n    submitted by    /u/Degenerat666  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16eag65/llm_on_blockchain_d/",
          "publishedOn": "2023-09-09T16:47:30.000Z",
          "wordCount": 2680,
          "title": "LLM on Blockchain? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16eafoz/d_unified_retrieval_augmented_generation_urag/",
          "author": null,
          "description": "PostgresML takes Retrieval Augmented Generation (RAG) a step further, by running the models and vector (or btree) indexes in the same process space that also caches the data, so the retrieval step doesn't require any networking or data (de)serialization. This makes it significantly faster and more reliable than other architectures, which is important for online or interactive applications. For lack of a better term, I'm referring to this as Unified Retrieval Augmented Generation (URAG).\n The closest I can find to this in the literature is TABR which utilizes recall to improve the performance of LLMs relative to tree based models, although this particular application of Retrieval is extremely computationally expensive for a slight performance improvement, unlike RAG for LLMs that seems to provide significant new capabilities to the model.\n Is there more research going on for what I'd refer to as URAG systems? We're building open source Python & JS SDKs to make the underlying SQL API more accessible, but I'm wondering if this community, or the academic community has already done more work in this area that we should be aware of.\n    submitted by    /u/something_cleverer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16eafoz/d_unified_retrieval_augmented_generation_urag/",
          "publishedOn": "2023-09-09T16:46:56.000Z",
          "wordCount": 2789,
          "title": "[D] Unified Retrieval Augmented Generation - URAG",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16eaccw/d_how_does_chatbot_development_look_like_in/",
          "author": null,
          "description": "With all the recent advancements in LLMs, how does chatbot development look like in practise? Suppose I want a chatbot to help with customer service. Can I then just collect some frequent / common questions about items the company might offer for sale and use a pretrained LLM to answer these questions correctly via transfer learning? Is there some effort that goes into explicit knowledge storage?\n    submitted by    /u/Blutorangensaft  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16eaccw/d_how_does_chatbot_development_look_like_in/",
          "publishedOn": "2023-09-09T16:43:01.000Z",
          "wordCount": 2674,
          "title": "[D]: How does chatbot development look like in practise?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16e9r4g/p_aipowered_valley_girl_creating_content/",
          "author": null,
          "description": "Hey everyone! I recently started a project where I make AI-powered characters that create content autonomously on social media. The first character that I launched yesterday is your typical valley girl - Alix - who hangs around tech and crypto people. She browses Twitter all day and writes tweets with her opinion of the stuff she comes by. With a unique mood generated for her every day, it's always a gamble to see who lands on her good or bad side.\n I would really appreciate it if you check her out and let me know what you think! I'm interested in further developing the project and making these synthetic entities equivalent to real people in entertaiment and companionship. \n Her twitter - https://twitter.com/alix_H2O\n    submitted by    /u/GuaranteeAny2894  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16e9r4g/p_aipowered_valley_girl_creating_content/",
          "publishedOn": "2023-09-09T16:18:33.000Z",
          "wordCount": 2675,
          "title": "[P] AI-Powered Valley Girl creating content autonomously on Twitter",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16e9nvp/n_nvidias_groundbreaking_tensorrtllm_can_double/",
          "author": null,
          "description": "submitted by    /u/norcalnatv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16e9nvp/n_nvidias_groundbreaking_tensorrtllm_can_double/",
          "publishedOn": "2023-09-09T16:14:48.000Z",
          "wordCount": 2566,
          "title": "[N] NVIDIA's Groundbreaking TensorRT-LLM Can Double Inference Performance of Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16e82vz/p_is_mdp_suitable_for_dqn_representation/",
          "author": null,
          "description": "Problem description\n For ongoing research I'm defining a decision problem in the form of an MDP. In a simple form, this MDP can be solved via Dynamic Programming. Of course I would like to scale up my MDP by including a sensor simulation, which renders the MDP to such a complexity that my next step is to use a DQN.\n My challenge is that I'm not sure how to represent my more complex MDP in a fitting DQN. Quite frankly, the more I look into DQN's, the more I wonder if my MDP is correctly defined. It would be great to hear your views and suggestions if you like to share.\n Definition of the MDP\n The MDP aims at detecting and chasing away a mosquito. For each distance step (discrete distances although it should be continuous), for instance Si, we cycle through an episode: we detect the mosquito…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16e82vz/p_is_mdp_suitable_for_dqn_representation/",
          "publishedOn": "2023-09-09T15:09:10.000Z",
          "wordCount": 3067,
          "title": "[P] Is MDP suitable for DQN representation ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16e54rq/d_map_of_the_ellis_unitseuropean_laboratory_for/",
          "author": null,
          "description": "submitted by    /u/Ok_Independent9899  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16e54rq/d_map_of_the_ellis_unitseuropean_laboratory_for/",
          "publishedOn": "2023-09-09T12:58:26.000Z",
          "wordCount": 2595,
          "title": "[D] Map of the ELLIS units(European Laboratory for Learning and Intelligent Systems). What do the people here think of ELLIS? Anyone who worked with them who can share the experience? Do you think it will help close the gap between Europe and US? (sorry for the bad edit I'm not good at it)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16e4o9b/ptraining_an_image_classification_model/",
          "author": null,
          "description": "Is it normal to achieve a validation accuracy so much higher than the training accuracy? I am using transfer learning to train a convNeXtBaseV1 model on my dataset. I got a training accuracy of 82.9% and a much higher validation accuracy of 97.14%.\n My dataset is around 9600 medical images and it is balanced between 3 classes. I splitted it into 80% training 10% testing and 10% validation\n    submitted by    /u/Different_Hat5643  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16e4o9b/ptraining_an_image_classification_model/",
          "publishedOn": "2023-09-09T12:35:46.000Z",
          "wordCount": 2617,
          "title": "[P]Training an image classification model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16e2uxd/d_are_there_any_open_source_voice_cloning_models/",
          "author": null,
          "description": "Hi. I tried tortoise tts. It is good for cloning how the voice sounds but not the original accent. Are there any open source technologies that can also copy the accent correctly?\n Please do suggest. Thank you!\n    submitted by    /u/salehxoxo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16e2uxd/d_are_there_any_open_source_voice_cloning_models/",
          "publishedOn": "2023-09-09T10:58:42.000Z",
          "wordCount": 2602,
          "title": "[D] Are there any open source voice cloning models that are capable of cloning other English accents along with the voice?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16e24nz/p_vector_database_integration_with_postgresql/",
          "author": null,
          "description": "Article | Notebook | GitHub\n There are a rapidly growing number of options in the vector database space. One of the more recent developments is the creation of new vector index plugins for traditional database systems such as pgvector. This is reminiscent of the discussion back in the mid 2010s on whether one should use full text search in the database or sync with an external system such as Elasticsearch.\n Just as with full text search, it will be tough for vector indexing in the database to compete with the more dedicated solutions past the simple use cases. For example, according the ANN-Benchmarks, the dedicated vector solutions score much higher.\n The desire to reduce stack complexity and the maturity of systems like Postgres make strong arguments to try to find a way to do it all in the database.\n The referenced article above proposes a way to integrate existing databases like PostgreSQL with vector indexes such as Faiss, Hnswlib, external vector databases and even keyword indexes like Elasticsearch. This opens up the possibility of combining Postgres features such as fine-grained access control with the performance of a dedicated vector index.\n ​\n    submitted by    /u/davidmezzetti  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16e24nz/p_vector_database_integration_with_postgresql/",
          "publishedOn": "2023-09-09T10:14:08.000Z",
          "wordCount": 2795,
          "title": "[P] Vector database integration with PostgreSQL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16e1muh/d_clustering_identical_but_timeshifted_signal/",
          "author": null,
          "description": "I am working on clustering groups of almost identical (but time shifted) signals together. These clusters will have varying sizes, and I don´t know what the final number of clusters will be. The database consists of up to 100 thousand signals (represented by 4000 long vectors as read from individual text files) which are already quite similar to each other. \n Ideally I would just make a huge cross-correlation matrix but that is too computationally expensive. So is DTW. What I have done is to apply the fast fourier transform to get it into the frequency domain and therefore get rid of that time shift. Then I would apply a clustering algorithm. I have tried DBSCAN and hierarchical agglomerative clustering which work relatively well but don’t scale well to datasets of this size. Affinity propagation is quick and works okish but I don’t know how to optimise it. \n Does anyone have any recommendation on which algorithm to use and how to optimise it? Was my idea to apply the fft good? I am not a computer scientist so I am really out of my element. \n    submitted by    /u/Bertz-2-  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16e1muh/d_clustering_identical_but_timeshifted_signal/",
          "publishedOn": "2023-09-09T09:43:25.000Z",
          "wordCount": 2793,
          "title": "[D] Clustering identical but time-shifted signal together from big database.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16dzxhh/p_hey_all_im_excited_to_launch_gptcall_a_platform/",
          "author": null,
          "description": "submitted by    /u/friuns  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16dzxhh/p_hey_all_im_excited_to_launch_gptcall_a_platform/",
          "publishedOn": "2023-09-09T07:57:50.000Z",
          "wordCount": 2575,
          "title": "[P] Hey all! I'm excited to launch GPTCall, a platform that enables real-time voice conversations with Llama 2 and other open-source models! It supports both desktop and mobile browsers. See comments for details.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16dx2b5/d_machine_learning_problem_predictive_maintenance/",
          "author": null,
          "description": "I was given following problem in one of the machine learning interviews. I think I messed up there. Need your approach in answering this question.\n Problem Description: Imagine you are working for a manufacturing company that operates a large fleet of industrial machines. These machines are critical to production, and unexpected breakdowns can result in significant downtime and financial losses. Your task is to develop a predictive maintenance model using machine learning to predict when a machine is likely to fail so that maintenance can be performed just in time to prevent a breakdown.\n Data: You are provided with historical data for each machine, including sensor readings, maintenance logs, and failure records. The dataset is extensive, containing millions of data points over several ye…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16dx2b5/d_machine_learning_problem_predictive_maintenance/",
          "publishedOn": "2023-09-09T05:12:30.000Z",
          "wordCount": 3011,
          "title": "[D] Machine Learning Problem: Predictive Maintenance for Industrial Equipment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16dwibn/d_rvc_queue_stuck_for_over_2_and_a_half_hours/",
          "author": null,
          "description": "Does anyone know what this means if when you import your audio clip and the model you want to use it gets stuck in the queue for over 2 and a half hours? I know that can't be right but I seemed to have followed all the guides correctly not sure what it could be :'( help greatly appreciated \n    submitted by    /u/StuntGuy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16dwibn/d_rvc_queue_stuck_for_over_2_and_a_half_hours/",
          "publishedOn": "2023-09-09T04:43:43.000Z",
          "wordCount": 2669,
          "title": "[D] RVC \"queue\" stuck for over 2 and a half hours?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16dluho/p_mlops_for_vercel_openai_chatbot_infrastructure/",
          "author": null,
          "description": "I used infrastructure as code (IaC) to provision and deploy Vercel's next-openai example. IaC is useful because it applies the same rigor of application code development to infrastructure provisioning. Instead of manual point and click in a cloud console which can be unrepeatable or error-prone, you just store and change all infrastructure configurations as code in source control .\n This example uses Pulumi which allows you to write the IaC in Python.\n https://github.com/aaronkao/vercel-py-openai-chatbot\n    submitted by    /u/kao-pulumi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16dluho/p_mlops_for_vercel_openai_chatbot_infrastructure/",
          "publishedOn": "2023-09-08T20:52:08.000Z",
          "wordCount": 2624,
          "title": "[P] MLOps for Vercel OpenAI chatbot infrastructure",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16dlac2/why_do_you_not_use_open_source_llms_or_do_you_d/",
          "author": null,
          "description": "Reposting because I intended to ask about LLMs, not AI in general, and forgot that I don't need to dumb down the terminology for this sub. \n Thanks to the people who pointed out that mistake.\n --- original post ---\n This is something I'm curious about. I've seen a few people declaring that they're not using open source LLMs because they're GPU-poor, because the models aren't good enough, because the uis/frontends are hard to get started with, etc., and I've been wondering how much these comments and posts reflect the opinions and needs of the community as a whole. So, here's a poll. Answer away if you feel like it. \n I'm sharing this on a few other subs too (for the sake of greater information gathering) so please don't vote more than once.\n If your reasoning is not on here, feel free to comment your thoughts. If more than one option describes you, please select the one that describes you the most.\n View Poll\n    submitted by    /u/Heralax_Tekran  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16dlac2/why_do_you_not_use_open_source_llms_or_do_you_d/",
          "publishedOn": "2023-09-08T20:30:56.000Z",
          "wordCount": 2819,
          "title": "Why Do You Not Use Open Source LLMs? (Or do you?) [D] (Repost because I made a mistake in the title)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16dl71t/d_what_are_good_resources_for_creating_nlp/",
          "author": null,
          "description": "I'm looking to learn more about concurrency/parallelism, optimization, data structures and algorithms from an NLP perspective.\n    submitted by    /u/Al_Miksiki  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16dl71t/d_what_are_good_resources_for_creating_nlp/",
          "publishedOn": "2023-09-08T20:27:19.000Z",
          "wordCount": 2571,
          "title": "[D] What are good resources for creating NLP algorithms from scratch?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16dkvx8/d_please_help_machine_learning_ml_engineers/",
          "author": null,
          "description": "Hello Everyone, \n I'm currently exploring the idea of a solution tailored for ML engineers and technologists. While I have a background in recruiting, I've often found myself dissatisfied with the typical recruitment process. It seems that many recruiters don't always appreciate the importance of working with candidates or understand the impact on people's livelihoods and careers. \n What I'm proposing is the creation of a career representation firm specifically designed for purpose-driven technologists specializing in data, product, and hardware careers. This firm would advocate for the career interests of the most passionate ML engineers. \n Our representation would encompass: \n - Strategic Career Development: Crafting a strategic approach to help engineers secure opportunities aligned with their desired projects and professional development. \n - Impact Matching: Identifying and connecting engineers with projects and teams where their technical skills, career goals, and personal interests can have the greatest positive impact, ensuring that your work aligns with your values and aspirations. \n - Industry Leadership: Positioning you as an industry leader by marketing your expertise and securing speaking engagements at conferences and other events, enhancing your professional visibility and reputation. \n In return for this representation, engineers would commit to a 3% fee deducted from their salary, which would support the services provided by the firm. \n Would you be interested in participating in such a service? If not, would you consider recommending it to someone you know? If you are in favor of this idea, what makes you believe it would be advantageous for others even if it might not be your preference? Do you think you could personally benefit from this type of career representation? \n Thanks! \n    submitted by    /u/Educational_Bar_6352  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16dkvx8/d_please_help_machine_learning_ml_engineers/",
          "publishedOn": "2023-09-08T20:15:12.000Z",
          "wordCount": 2875,
          "title": "[D] Please Help - Machine Learning (ML) Engineers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16dkmh3/r_algorithm_of_thoughts_prompt_engineering/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2308.10379\n Saw someone else post about this new prompting method on the sub here so I decided to put together a run down and prompt template. \n Pretty interesting to see the different methods emerge and how some attempt to simulate how code runs. \n My rundown -> https://www.prompthub.us/blog/how-algorithm-of-thoughts-prompting-works\n    submitted by    /u/dancleary544  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16dkmh3/r_algorithm_of_thoughts_prompt_engineering/",
          "publishedOn": "2023-09-08T20:04:56.000Z",
          "wordCount": 2653,
          "title": "[R] Algorithm of Thoughts Prompt Engineering Breakdown",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16djeuy/rd_how_to_implement_sinusoidal_positional/",
          "author": null,
          "description": "Hi fellow computer scientists,\n so I've been researching a little about transformers and meanwhile I had to understand sinusoidal positional embedding. I have found two implementations for this, after testing both approaches I found they compute different embeddings for the same position/timestep with the same embedding dimensions... shouldn't it be equal if the position and embedding dimensions are the same?\n This is getting me confused, because now I don't know which implementation should I consider... Do you have any suggestions to where I can look?\n Thank you :)\n    submitted by    /u/Christs_Elite  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16djeuy/rd_how_to_implement_sinusoidal_positional/",
          "publishedOn": "2023-09-08T19:16:43.000Z",
          "wordCount": 2639,
          "title": "[R][D] How to implement Sinusoidal Positional Embedding?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16dj6y1/discussion/",
          "author": null,
          "description": "Hi guys, I'm completely new in this field.. I have a research in civil engineering and need to learn python, machine learning and data analysis as short as possible. Where can I achieve that?? please help me by naming the best courses or any free materials available🙏\n    submitted by    /u/Ok-Upstairs7749  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16dj6y1/discussion/",
          "publishedOn": "2023-09-08T19:08:11.000Z",
          "wordCount": 2592,
          "title": "\"[Discussion]\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16delbt/p_question_answering_based_on_booksummaries/",
          "author": null,
          "description": "I'm one of those people who always ask questions about movies because there's something they don't get or have forgotten. Especially with more complex stories, like Game of Thrones. At the moment I'm reading Wheel of Time, a rather long fantasy series. I had the idea to build the following WebApp:\n There is online each chapter of the series summarized separately. So in the WebApp I could ask questions about the content. In addition, I can indicate which chapter I am reading, so that it is ensured not to spoil the user.\n I want to avoid to train a model. I would prefer to use one of the existing open-source models, like llama. A first, primitive idea: give the LLM all the summaries and the user's question. But this would mean to give all summaries as input every time. Not only that this approach would not be elegant, the restriction in the input size (number of words) would make this possibly even impossible.\n Feel free to share your ideas how i could solve this :)\n    submitted by    /u/Individual-Cause-616  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16delbt/p_question_answering_based_on_booksummaries/",
          "publishedOn": "2023-09-08T16:06:30.000Z",
          "wordCount": 2724,
          "title": "[P] Question answering based on book-summaries",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16degay/help_me_with_creating_dataset_from_mat_files_d/",
          "author": null,
          "description": "I have so many .mat files in a folder which have two arrays inside each .mat file. that is, for each .mat file, i have a (224*224) array and another (136,1) array. These 224*224 arrays are my X_trains for a model and these corresponding 136*1 arrays are my y_trains (labels). i can read these files as np arrays using scipy's loadmat. My problem is, is there a way to usen tf.data .Dataset object to send these to a model or there is any other way? Also using this tf.data.Dataset can i split into train, test, val data?\n    submitted by    /u/likhith-69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16degay/help_me_with_creating_dataset_from_mat_files_d/",
          "publishedOn": "2023-09-08T16:01:32.000Z",
          "wordCount": 2650,
          "title": "Help me with creating dataset from .mat files [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16dea69/p_cli_tool_to_benchmark_100llms_response_response/",
          "author": null,
          "description": "Hi r/MachineLearning, \n I built a CLI tool to benchmark 100+ LLMs for a given question. Benchmark output allows you to compare responses, response time and cost. Try it here: https://github.com/BerriAI/litellm/blob/main/cookbook/benchmark/readme.md \n CLI Output:\n Output from CLI Tool\n Simply select your LLMs, enter your API keys, LLM configs and run \n python3 benchmark.py \n Happy completion()! \n    submitted by    /u/Comfortable_Dirt5590  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16dea69/p_cli_tool_to_benchmark_100llms_response_response/",
          "publishedOn": "2023-09-08T15:54:49.000Z",
          "wordCount": 2661,
          "title": "[P] CLI tool to benchmark 100+LLMs response, response time, cost",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ddfdb/text_summarization_p/",
          "author": null,
          "description": "Hey! If anyone has worked with text summarization before especially with TF-IDF and extractive summarization,kindly please dm me. Hope you have a great day!\n    submitted by    /u/Ok-Avocado-5370  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ddfdb/text_summarization_p/",
          "publishedOn": "2023-09-08T15:21:32.000Z",
          "wordCount": 2626,
          "title": "Text summarization [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16db34q/p_a_look_at_apples_new_transformerpowered/",
          "author": null,
          "description": "In the upcoming versions of macOS and iOS, Apple is including a predictive text model which offers suggestions while you type, which they’ve said to be a \"transformer model\". I managed to find some details about this model, including details about its topology and tokenizer, and I was even able to peek in and see several of its top predictions while typing!\n Blogpost: https://jackcook.com/2023/09/08/predictive-text.html\n Source code: https://github.com/jackcook/predictive-spy\n Hopefully this can give some insight into some of the trade-offs that Apple went through to put a model on every iPhone and MacBook — it’s small, it has a pretty narrow scope, and it’s not very capable on its own. Let me know what you think!\n    submitted by    /u/jackcook  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16db34q/p_a_look_at_apples_new_transformerpowered/",
          "publishedOn": "2023-09-08T13:46:47.000Z",
          "wordCount": 2722,
          "title": "[P] A look at Apple’s new Transformer-powered predictive text model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16d93ke/p_ai_beats_hockolicious_trackmanias_most/",
          "author": null,
          "description": "Follow-up on our previous post (Vision-based reinforcement learning for Trackmania: close or at superhuman level).\n Many comments rightfully pointed that the map we trained on:\n - lacked difficult features like jumps, airbrakes, drifts, ...\n - had not widely been played by humans\n We have now trained the same AI on the game's most prestigious map: Hockolicious. We also prepared a video describing the approach with much more detail.\n Here is our result :) AI Beats Hockolicious, Trackmania's Most Prestigious Map\n Note: We are still using a convolutional neural network with a structure similar to Nature's DQN paper. I am curious whether other architectures (the ResNet-like in the IMPALA paper ?) could help. Do you have any suggestions on how the neural network's vision head should be structured for that specific task?\n    submitted by    /u/Linesight_rl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16d93ke/p_ai_beats_hockolicious_trackmanias_most/",
          "publishedOn": "2023-09-08T12:20:56.000Z",
          "wordCount": 2736,
          "title": "[P] AI Beats Hockolicious, Trackmania's Most Prestigious Map",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16d8saq/d_methodology_for_countingsegmenting_objects_in/",
          "author": null,
          "description": "Hello all. I'm new to object recognition and instance segmentation.\n I am trying to work on a project in which I use drone imagery to detect objects that are in close formations with each other. I do this for the purpose of counting particular objects, as well as to check if an object has moved (by making a prediction on drone imagery that is taken later).\n Create masks?\n I'm now trying to understand what methodology/models make sense. First of all, should I be looking at creating masks, or do bounding boxes suffice? My idea was that masks are better, since bounding boxes overlap with each other and can miss that an object has moved slightly, Or am I wrong and are masks just an extra hassle? Or shouldn't I be looking at bounding boxes or masks at all?\n MaskRCNN?\n Model-wise, should I be lo…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16d8saq/d_methodology_for_countingsegmenting_objects_in/",
          "publishedOn": "2023-09-08T12:05:20.000Z",
          "wordCount": 2999,
          "title": "[D] Methodology for counting/segmenting objects in close formations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16d7ee6/d_chains_and_agents/",
          "author": null,
          "description": "I think there's a lot of confusion around AI agents today and it's mainly because of lack of definition and using the wrong terminology.\n We've been talking to many companies who are claiming they're working on agents but when you look under the hood, they are really just chains.\n I just listened to the Latent Space pod with Harrison Chase (Founder of Langchain) and I really liked how he thinks about chains vs agents.\n Chains: sequence of tasks in a more rigid order, where you have more control, more predictability.\n Agents: handling the edge-cases, the long-tail of things that can happen.\n And the most important thing is that it's not an OR question but an AND one: you can use them in the same application by starting with chains -> figuring our the edge-cases -> using agents to deal with them.\n https://preview.redd.it/l59sc4sri0nb1.png?width=3127&format=png&auto=webp&s=1f3f8730c48687eaabf1f554deb181cf35b96036\n    submitted by    /u/BootstrapGuy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16d7ee6/d_chains_and_agents/",
          "publishedOn": "2023-09-08T10:55:55.000Z",
          "wordCount": 2743,
          "title": "[D] Chains and Agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16d5n4m/d_question_for_jensen_huang/",
          "author": null,
          "description": "I have the opportunity to see Jensen speak in the next month at a semi private event, 250-300 people. I will probably have the opportunity to ask him a question. What would you ask him?\n    submitted by    /u/Zealousideal-Food285  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16d5n4m/d_question_for_jensen_huang/",
          "publishedOn": "2023-09-08T09:17:40.000Z",
          "wordCount": 2639,
          "title": "[D] Question for Jensen Huang",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16d5abe/d_object_detection_in_3d/",
          "author": null,
          "description": "Greetings, people. My colleague told me about some methods of object detection/classification on 3D models, and now I'm exploring them. But during my research I couldn't find that much information about them. I would like to ask you to provide me information, literature and examples of application for them. I remember that one of the techniques is called voxelization. But still not able to find great and intuitive example. \n Would be thankful for any information :)\n    submitted by    /u/thattallsoldier  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16d5abe/d_object_detection_in_3d/",
          "publishedOn": "2023-09-08T08:54:50.000Z",
          "wordCount": 2625,
          "title": "[D] Object detection in 3D",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16d4x9m/d_what_object_detection_and_segmentation_model/",
          "author": null,
          "description": "Looking at all the popular yolo repos, v5, v7,v8, yolo-nas, all of them seem to have restrictive licenses (gpl3, agpl, apache 2) where the trained model files also falls under the license. What do people usually use to deploy detection/segmentation in production, especially with resource constraints (can't use something like fast-rcnn)\n    submitted by    /u/Appropriate_Bear_894  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16d4x9m/d_what_object_detection_and_segmentation_model/",
          "publishedOn": "2023-09-08T08:32:49.000Z",
          "wordCount": 2609,
          "title": "[D] What object detection and segmentation model repos do you folks use for production",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16d4x9l/d_proper_use_of_aivoicecloning_rvc_tortoise/",
          "author": null,
          "description": "Hey guys! I need some help here.. many days trying to get good results but without success. So I already have the voice I want to use (edited with uvr5 and it sounds really great, without any echo or noise on the background), I trained it on aivc so that I can generate this voice verbalizing the text content I need. I used high quality - it took like 40min to generate each phrase - and it is ok, but still a little robotic. So I installed RVC and trained a model with the original voice (edited with the uvr5) just like I did the training on aivc. So I loaded the trained model on the inference tab and I selected the audio to be processed - the generated audio files from aivc. Even selecting the harvest mode, the output was worse than the generated files from aivc. I even tried to record my own voice speaking the text but it does not sound good. My trained model on rvc has 500 epochs, and it may be a very good model to use, yet idk what I’m doing wrong. Maybe I’m misusing rvc, so what I need is to improve the realism of my aivc(or tortoise) generated voices, simple as that, is rvc the best option to do this? If yes, how? Any help please would be much appreciated thanks!\n    submitted by    /u/JustSayin_thatuknow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16d4x9l/d_proper_use_of_aivoicecloning_rvc_tortoise/",
          "publishedOn": "2023-09-08T08:32:49.000Z",
          "wordCount": 2783,
          "title": "[D] Proper use of ai-voice-cloning / rvc / tortoise",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16d15ci/r_flm101b_an_open_llm_and_how_to_train_it_with/",
          "author": null,
          "description": "submitted by    /u/hzj5790  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16d15ci/r_flm101b_an_open_llm_and_how_to_train_it_with/",
          "publishedOn": "2023-09-08T04:55:55.000Z",
          "wordCount": 2568,
          "title": "[R] FLM-101B: An Open LLM and How to Train It with $100K Budget",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16cy82s/r_seeking_research_papers_on_weight_manipulation/",
          "author": null,
          "description": "Would you kindly share noteworthy papers that have caught your interest concerning the weights of physics-informed neural networks (PINNs)? I am looking for any innovative paper that has something to do with weights of the physics-informed neural networks or deep neural networks in general and its manipulation.\n Specifically, I am seeking innovative papers on weight manipulation in physics-informed neural networks.\n For instance papers like:\n  \nWeight initialization algorithm for physics-informed neural networks using finite differences\n Transfer Learning with Physics-Informed Neural Networks for Efficient Simulation of Branched Flows\n  \nNote that I am referring to the actual weights of the neural network and not the weights of the loss terms.\n I have to add that ideas from transfer learning are welcome too. \n    submitted by    /u/ai_physics2023  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16cy82s/r_seeking_research_papers_on_weight_manipulation/",
          "publishedOn": "2023-09-08T02:28:17.000Z",
          "wordCount": 2730,
          "title": "[R] Seeking Research Papers on Weight Manipulation in Physics-Informed Neural Networks (PINNs)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16cxfph/pr_finetune_llms_via_the_finetuning_hub/",
          "author": null,
          "description": "Hi ML community, I have been working on benchmarking publicly available LLMs these past couple of weeks. More precisely, I am interested on the finetuning piece since a lot of businesses are starting to entertain the idea of self-hosting LLMs trained on their proprietary data rather than relying on third party APIs. To this point, I am tracking the following 4 pillars of evaluation that businesses are typically look into: - Performance - Time to train an LLM - Cost to train an LLM - Inference (throughput / latency / cost per token)\n For each LLM, my aim is to benchmark them for popular tasks, i.e., classification and summarization. Moreover, I would like to compare them against each other.\n So far, I have benchmarked Flan-T5-Large, Falcon-7B and RedPajama and have found them to be very efficient in low-data situations, i.e., when there are very few annotated samples. Llama2-7B/13B and Writer’s Palmyra are in the pipeline.\n But there’s so many LLMs out there! In case this work interests you, would be great to join forces.\n GitHub repo attached — feedback is always welcome :)\n https://github.com/georgian-io/LLM-Finetuning-Hub\n Happy hacking!\n    submitted by    /u/l-llm  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16cxfph/pr_finetune_llms_via_the_finetuning_hub/",
          "publishedOn": "2023-09-08T01:52:47.000Z",
          "wordCount": 2792,
          "title": "[P][R] Finetune LLMs via the Finetuning Hub",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16cto3t/dwhat_do_people_think_about_papers_published_in/",
          "author": null,
          "description": "I'm curious to learn about the perception of papers published in the NeurIPS dataset track in comparison to those published in the main conference. Specifically, I'd like to know how both companies and Ph.D. committees view these papers. Are they considered equally valuable, or is there a notable difference in their reputation and significance? Your insights and experiences would be greatly appreciated! \n    submitted by    /u/Longjumping-Yam6941  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16cto3t/dwhat_do_people_think_about_papers_published_in/",
          "publishedOn": "2023-09-07T23:07:39.000Z",
          "wordCount": 2682,
          "title": "[D]What do people think about papers published in the NeurIPS dataset track in comparison to those published in the main conference?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16cre85/d_training_a_language_model_for_custom_scripting/",
          "author": null,
          "description": "Firstly some house keeping:\n  \nI'm a bit of a noob at this whole AI / Machine Learning stuff - still trying to learn.\n This isn't a \"do my homework for me\" kind of post\n I know language processing can be taxing, I have up to 4 Tesla V100S 32 GB at my disposal\n  \nNow that's out the way, here's the story:\n A team of us have created our own scripting language that is XML based that can do various actions against a database (or the file system) - a script is known as a \"job\" here is an example of a simple one\n  \nSet variables by various methods and send their contents and an attachment by email:\n  \n<Job title=\"Send Variables by Email\"> <SetVariable name=\"MyStringVar\" value=\"Hi John\"/> <SetVariable name=\"MySQLVar\" sql=\"select dbname from params\"/> <SetVariable name=\"MyDateVar\" value=\"1998-12-25…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16cre85/d_training_a_language_model_for_custom_scripting/",
          "publishedOn": "2023-09-07T21:39:16.000Z",
          "wordCount": 2977,
          "title": "[D] Training a language model for custom scripting language?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16cqji8/d_is_inference_optimization_a_thing/",
          "author": null,
          "description": "Let me give you a quick intro. My engineering experience primarily revolved around data processing, analytics, and distributed systems. Nonetheless, I had a desire to learn about ML, and imho the best way to learn is to work on a practical project. So, that's precisely what I did. A few months ago, I embarked on an exciting journey with a friend, and together, we've created http://github.com/huggingbench/huggingbench.\n Now, after three months, I find myself seeking validation for some of my assumptions from the broader community. If you'd like to learn more about our motivations and the path we've taken check out the blog post https://medium.com/@niksa.jakovljevic/introducing-huggingbench-a-path-to-optimized-model-serving-a17cecc8d3ec.\n What I'd like to gather from individuals with machine learning models in production is their level of investment in optimizing inference. Is this a commonplace practice? I acknowledge that it can vary on a case-by-case basis, but I'm still hopeful of identifying prevailing trends. After conversing with a few companies, I've come to the impression that only the truly large players (those spending six figures or more on inference per month) place significant emphasis on inference optimization, which is entirely understandable. Nevertheless, I sense that there are numerous low hanging fruits that could result in substantial cost savings, even for typical startups.\n Could it be that the entire machine learning field is still in its infancy, and many engineers may not be fully considering or prioritizing such optimizations? Perhaps businesses are not giving as much attention to cost considerations? Alternatively, there might be technical challenges I'm not yet aware of. In any case, I would greatly appreciate hearing your insights on the subject of inference optimization.\n    submitted by    /u/unsigned_mind  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16cqji8/d_is_inference_optimization_a_thing/",
          "publishedOn": "2023-09-07T21:08:33.000Z",
          "wordCount": 2875,
          "title": "[D] Is inference optimization a thing?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16cp5sr/please_help_lstm_for_rainfall_prediction_p_d/",
          "author": null,
          "description": "I have been trying to build a DNN model for predicting the amount of rainfall but it has been hugely unsuccessful with just 40% accuracy even after CV and a high RMSE. I have read some research papers and they have suggested to use LSTM , I am aware of the concept but have never implemented.\n My dataset has arounf 15000 values of precipitation out of which 5000 values are zero (no rainfall at all) and I have 7 other features (including humidity , wind speed etc etc) .\n PLEASE HELP ! I NEED TO COMPLETE THIS FOR MY INTERNSHIP HAHA\n https://preview.redd.it/sg5v95ly5wmb1.png?width=1818&format=png&auto=webp&s=793bee830bb83f531f77e5c2a4ab47a5fb21eb3b\n    submitted by    /u/Decent_Ordinary1528  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16cp5sr/please_help_lstm_for_rainfall_prediction_p_d/",
          "publishedOn": "2023-09-07T20:17:29.000Z",
          "wordCount": 2708,
          "title": "PLEASE HELP (LSTM FOR RAINFALL PREDICTION) [P] [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16cnez1/r_open_asr_leaderboard/",
          "author": null,
          "description": "Hugging Face benchmarked open source/ access models [English only] on 8 different speech datasets (LibriSpeech, Common Voice, VoxPopuli, TED-LIUM, Gigaspeech, SPGISpeech, Earnings-22 and AMI) 🤗\n Leaderboard here: https://huggingface.co/spaces/hf-audio/open_asr_leaderboard\n    submitted by    /u/vaibhavs10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16cnez1/r_open_asr_leaderboard/",
          "publishedOn": "2023-09-07T19:12:35.000Z",
          "wordCount": 2631,
          "title": "[R] Open ASR Leaderboard",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16cnbmk/d_how_can_we_improve_llm_responses_outside_of/",
          "author": null,
          "description": "Outside of better models, bigger, fine-tuning, etc, I'm wondering how we can get better responses from models.\n In my experience, I think prompt engineering can only take us so far. Models hallucinate often and I think we need to have some engineering solution to this.\n I've been looking at libraries doing token healing, which I find to be helpful (for example https://github.com/guidance-ai/guidance/tree/main) but outside of this, I'm wondering what other techniques people have been doing to improve model performance?\n    submitted by    /u/opt1malP0licy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16cnbmk/d_how_can_we_improve_llm_responses_outside_of/",
          "publishedOn": "2023-09-07T19:09:09.000Z",
          "wordCount": 2636,
          "title": "[D] How can we improve LLM responses outside of fine-tuning & prompt engineering?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16clupa/p_opensource_observability_for_llms_without/",
          "author": null,
          "description": "Hey all!\n I've written an open-source SDK for reporting metrics from LLM usage using OpenTelemetry.\n The great thing about it? With just one line of code you can get full visibility into your LLM app with your existing observability stack - straight into Datadog, Sentry, Honeycomb and others!\n Check it out (maybe give a ⭐?), and let me know your thoughts - https://github.com/traceloop/openllmetry\n    submitted by    /u/nirga  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16clupa/p_opensource_observability_for_llms_without/",
          "publishedOn": "2023-09-07T17:38:25.000Z",
          "wordCount": 2668,
          "title": "[P] Open-source observability for LLMs without adapting new tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16cluor/falcon_180ba_recordbreaking_open_source_llm_on/",
          "author": null,
          "description": "The AI community is buzzing with the arrival of Falcon 180B, an open-source LLM with an unprecedented 180 billion parameters. Developed by TII, This powerful model has surpassed key players like Meta's LLaMA 2 and matches commercial models like Google's PaLM-2.\n To stay on top of the latest advancements in AI, look here first.\n ​\n https://preview.redd.it/9xe5tczpdvmb1.jpg?width=480&format=pjpg&auto=webp&s=b7927d94a48fb75eaf05f6f0d8fe1089c0e1078b\n Falcon 180B's Unrivaled Performance\n  \nThis advanced LLM is trained on an astounding 3.5 trillion tokens.\n Falcon 180B's parameters are 2.5 times larger than LLaMA 2's. It outperforms LLaMA 2 in scale and benchmark performance across diverse NLP tasks.\n On evaluations like the HellaSwag benchmark, it rivals commercial models like Google's PaLM-2.\n  \nPromising Future\n  \nTechniques like weight randomization and Nvidia’s Perfusion have helped train Falcon 180B more efficiently.\n Now freely available on Hugging Face, Falcon 180B is set to benefit from further enhancements by the community.\n The model's demonstration of advanced natural language abilities makes it a thrilling development in open-source AI.\n  \n(source) (demo)\n P.S. If you like this kind of analysis, I write a free newsletter that covers the most crucial news and studies in AI and tech. Professionals from Google, Meta, and OpenAI are already subscribed.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16cluor/falcon_180ba_recordbreaking_open_source_llm_on/",
          "publishedOn": "2023-09-07T17:38:24.000Z",
          "wordCount": 2800,
          "title": "Falcon 180B—A Record-Breaking Open Source LLM on Hugging Face [N]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ckswb/n_r_new_dataset_on_very_highquality_image/",
          "author": null,
          "description": "​\n EntitySeg dataset\n Dense image segmentation tasks (e.g., semantic, panoptic) are useful for image editing, but existing methods can hardly generalize well in an in-the-wild setting where there are unrestricted image domains, classes, and image resolution and quality variations. Motivated by these observations, we construct a new entity segmentation dataset, with a strong focus on high-quality dense segmentation in the wild. The dataset contains images spanning diverse image domains and entities, along with plentiful high-resolution images and high-quality mask annotations for training and testing.\n We have now released the dataset at https://github.com/adobe-research/EntitySeg-Dataset\n Project page: http://luqi.info/entityv2.github.io\n Code & models: https://github.com/qqlu/Entity/tree/main/Entityv2\n ​\n    submitted by    /u/xternalz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ckswb/n_r_new_dataset_on_very_highquality_image/",
          "publishedOn": "2023-09-07T16:49:29.000Z",
          "wordCount": 2707,
          "title": "[N] [R] New dataset on very high-quality image segmentation (EntitySeg)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ckobr/n_open_interpreter_chatgpt_code_interpreter_you/",
          "author": null,
          "description": "Github: https://github.com/KillianLucas/open-interpreter\n Youtube: https://youtu.be/SqnXUHwIa3c?si=ibSelipAb84AZQKo\n Open Interpreter lets LLMs run code (Python, Javascript, Shell, and more) locally. You can chat with Open Interpreter through a ChatGPT-like interface in your terminal by running $ interpreter\n after installing.\n This provides a natural-language interface to your computer's general-purpose capabilities:\n  \nCreate and edit photos, videos, PDFs, etc.\n Control a Chrome browser to perform research\n Plot, clean, and analyze large datasets\n ...etc.\n  \n⚠️ Note: You'll be asked to approve code before it's run.\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ckobr/n_open_interpreter_chatgpt_code_interpreter_you/",
          "publishedOn": "2023-09-07T16:44:22.000Z",
          "wordCount": 2694,
          "title": "[N] Open Interpreter ChatGPT Code Interpreter You Can Run LOCALLY! - 9.2k Stars on Github as of right now!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16cjpqb/d_fast_opensource_c_libraries_for_lasso/",
          "author": null,
          "description": "Hello everyone,\n I'm in search of a speedy open-source C++ library for tackling Lasso problems. These problems have a moderate size, typically with dimensions of nxp = 60x3000. I'm looking for a library that can solve each problem with regularization paths quickly, ideally within 0.3 seconds. Additionally, I need this library to include cross-validation functionality, which would enable me to select the best regularization parameter lambda using cross-validation.\n Any insights or recommendations on such libraries would be greatly appreciated! Thank you in advance for your help!\n    submitted by    /u/mopyfish007  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16cjpqb/d_fast_opensource_c_libraries_for_lasso/",
          "publishedOn": "2023-09-07T16:05:54.000Z",
          "wordCount": 2637,
          "title": "[D] Fast open-source C++ libraries for Lasso",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16chq28/d_how_do_you_train_your_models_with_limited/",
          "author": null,
          "description": "Hey there,\n So, I've been messing around with ML and I must say, the hardware requirements can be a real buzzkill... I mean, not everyone's got a huge GPU lying around or the money to rent a dedicated cloud instance.\n What are your hacks for pulling off decent model training without selling a kidney?\n Here's what I'm curious about:\n  \nCPU: Is anyone else training models on their CPU? How's that working out for you? What are some workarounds you've tried to make it less painful?\n Cloud: Who's been dabbling in cloud services like AWS, Google Cloud, or Azure? Are they worth the pennies or complicated to set up?\n Big Dataset: How do you handle a massive dataset with a standard storage space?\n  \nLet's help each other get those models trained without going broke! :D\n Cheers!\n    submitted by    /u/aaron-cesaro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16chq28/d_how_do_you_train_your_models_with_limited/",
          "publishedOn": "2023-09-07T14:46:15.000Z",
          "wordCount": 2689,
          "title": "[D] How do you train your models with limited hardware?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ch8tj/d_function_approximation_with_neural_net/",
          "author": null,
          "description": "I have been struggling with a regression problem with TensorFlow. \n Basically, I want a neural network to learn the simple polynomial pattern of a set of arrays of the form [x,y], with y = x², where the first coordinates are uniformly distributed random numbers in the interval [0,1].\n I started with a model with 2 hidden layers of size two and 'tanh' activation functions, and an output layer with 'linear' activation function. \n I've then experimented with both additional hidden layers and with increasing the sizes of these layers. Finally, I've tested both the 'adam' and 'sgd' optimizers and the loss functions 'meanSquaredError' and 'meanAbsolutePercentageError'. \n However, none of the various combinations of these parameters has led to any even half-descent result. Even on the training se…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ch8tj/d_function_approximation_with_neural_net/",
          "publishedOn": "2023-09-07T14:26:07.000Z",
          "wordCount": 3038,
          "title": "[D] Function approximation with neural net",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16cgukc/rd_hey_lomo_paper_authors_does_sgd_have_optimizer/",
          "author": null,
          "description": "In the LOw-Memory Optimization paper one of the main ideas towards reducing memory usage in training LLMs is to replace a fancy optimizer like Adam with simple SGD. The reason is that Adam maintains \"the optimizer state\", which accounts for about 75% of the memory used. In contrast, SGD does not store any intermediate state, as they say on page one. So far, so good.\n https://preview.redd.it/b0dj2nzscumb1.png?width=1055&format=png&auto=webp&s=1712f8500b5cbfb3773cee00ea980175491dddbf\n On page six they have pie charts and a table showing memory usage for Adam, SGD, and LOMO. Here's where I got confused. The pie chart for SGD shows that the optimizer state accounts for nearly 50% of the memory used (weight, gradients and activations are shown separately). It's a major WTF moment: WHAT OPTIMIZER STATE? Can anybody understand and explain this?\n    submitted by    /u/Foxtr0t  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16cgukc/rd_hey_lomo_paper_authors_does_sgd_have_optimizer/",
          "publishedOn": "2023-09-07T14:09:31.000Z",
          "wordCount": 2685,
          "title": "[R][D] Hey LOMO paper authors, Does SGD have optimizer states, or does it not?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16cg6k7/p_falkordb_a_fast_graph_database_knowledge_graph/",
          "author": null,
          "description": "We're building a fast low latency Graph Database called FalkorDB that will also support Vector search.\n It's based on Redis and can be used both as a stand alone database or a module for existing Redis.\n It feels like that is going to be the most optimized way to serve Knowledge as RAG, would love to get your feedback.\n https://github.com/FalkorDB/falkordb \n It already supports LlamIndex and Langchain:\n https://python.langchain.com/docs/use_cases/more/graph/graph_falkordb_qa\n https://gpt-index.readthedocs.io/en/latest/examples/index_structs/knowledge_graph/FalkorDBGraphDemo.html\n ​\n    submitted by    /u/gkorland  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16cg6k7/p_falkordb_a_fast_graph_database_knowledge_graph/",
          "publishedOn": "2023-09-07T13:41:25.000Z",
          "wordCount": 2619,
          "title": "[P] FalkorDB - a fast Graph Database - Knowledge Graph as RAG",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16cfpje/d_artificial_intelligence_in_medicine/",
          "author": null,
          "description": "Medicine's field transformation is being driven by artificial intelligence (AI). However, an important debatable question arises: Will AI ever have a place in this field, or will it remain exclusive to doctors and medical pros?\n Opponents of automated AI diagnosis and treatment contend that machines cannot be relied upon to preserve patient health and lives. Bugs in AI algorithms might cause incorrect diagnoses and treatment prescriptions, leaving them cautious. Individual differences, the doubt is whether AI can truly empathize with patients.\n By contrast, advocates of AI in medicine contend that the technology can considerably improve diagnosis and treatment accuracy. Faster and more accurate than humans, machines can analyze large amounts of data. Not only does it identify rare and complex diseases, but it also saves time and resources. By incorporating AI, clinicians receive additional tips and signals to make more judicious choices.\n Where medical specialists are in short supply, AI can prove especially valuable. This approach can help with shortages in health systems.\n And what do you think?\n    submitted by    /u/gcore-com  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16cfpje/d_artificial_intelligence_in_medicine/",
          "publishedOn": "2023-09-07T13:21:00.000Z",
          "wordCount": 2771,
          "title": "[D] Artificial intelligence in medicine",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ceyfm/r_tune_as_you_scale_hyperparameter_optimization/",
          "author": null,
          "description": "submitted by    /u/InterviewIntrepid889  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ceyfm/r_tune_as_you_scale_hyperparameter_optimization/",
          "publishedOn": "2023-09-07T12:46:59.000Z",
          "wordCount": 2621,
          "title": "[R] Tune As You Scale: Hyperparameter Optimization For Compute Efficient Training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ce68p/d_the_900000_deep_learning_salary/",
          "author": null,
          "description": "This recent article in the WSG advertised a $900,000 salary at Netflix https://www.wsj.com/articles/artificial-intelligence-jobs-pay-netflix-walmart-230fc3cb.\n I was wondering what other DL research scientists who frequent this page are paid? And what exactly their job title is.\n    submitted by    /u/blabboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ce68p/d_the_900000_deep_learning_salary/",
          "publishedOn": "2023-09-07T12:08:20.000Z",
          "wordCount": 2639,
          "title": "[D] The $900,000 deep learning salary",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16cbjmh/3d_brain_mri_classification_research/",
          "author": null,
          "description": "I am planning on publishing a journal based on the thesis i completed in the mid of 2022. I did my thesis on Parkinson disease binary classification on 3D structural brain mri, and the dataset has significantly small amount of data(around 80 samples); but due to high resolution and complex data structure I was able achieve around 70% accuracy.\n But now at 2023 using deep neural network only isnot enough to publish in a good journal. Currently I am learning about GAN and attention mechanism, but completely noob on this area. For my journal to get published, I have planned on applying some key operations. But I am not sure if they would work or not. So needed some advice on this regard.\n  \nApplying tranfer learning: as my dataset has very small amount of data. I was thinking if its possible to pre train a CNN Architecture with some other structural mri data of a different disease and then apply to my dataset? ( for example: brain tumor dataset has the same type of three dimensional data structure, but has comparatively good amount of data)\n \nApplying attention mechanism: how should I approach on learning about attention mechanism? \n \n Any other advices will be appreciated, thank you!\n    submitted by    /u/Bonito_Flakez  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16cbjmh/3d_brain_mri_classification_research/",
          "publishedOn": "2023-09-07T09:44:02.000Z",
          "wordCount": 2754,
          "title": "3D brain mri classification [Research]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16c2d5d/d_finetuning_llms_or_supervised_learning/",
          "author": null,
          "description": "Hey everyone! I want to implement a document similarity program and was looking into LLMs as a means of accomplishing this task. \n I have ~10,000 documents that are \"scams\" because of some specific reason (all are verified); now I want to check if a new document is similar to any of the documents in the corpus of 10k scam documents. \n Right now I've implemented a winnowing solution which normalizes text, breaks it up into windows, and then calculates the intersection between a document and each document in the corpus. HOWEVER, this method is pretty computationally expensive (for this many documents a single comparison cycle can take upwards of 3-4 minutes especially when windows are NOT precomputed). \n How might I approach this problem? Because my data is pretty well structured, supervised learning might be a good approach but so might be setting up recursive chunking for the 10k document corpus and then using LLMs to access if this current legal document has any similarity, but I would love to hear your thoughts!\n    submitted by    /u/Adventurous-Tower392  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16c2d5d/d_finetuning_llms_or_supervised_learning/",
          "publishedOn": "2023-09-07T01:21:43.000Z",
          "wordCount": 2776,
          "title": "[D] Fine-tuning LLMs or Supervised Learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16c0l0x/n_copyright_and_fair_use_important_notice_of/",
          "author": null,
          "description": "Please make your voices heard by submitting comments on how you use and benefit from having access to open datasets, their resulting models and how you think copyright issues should be handled to not destroy the open source local model eco system. Banning publicily avaiable datasets for training would absolutely kill the open research space and halt in development of machine learning. \n ​\n In my opinion the real dystopia will be when politicians sit own with big tech lobbyists and big rights holders and decide that training as it is currently done, for free and open source models and others is illegal. Then the big players would actually win, since they have enough resources to license datasets and will certainly do so willingly and gladly, if it is clear that the jurisdiction keeps all the small players and open source out. Easiest way to build a moat and force people to pay thousands for these tools. So please make your voices heard and share the link\n >The Copyright Office issued a notice of inquiry in the Federal Register seeking public comment on questions about copyright law and policy issues raised by AI systems. Initial comments are due by October 18, 2023. Reply comments are due November 15, 2023.\n https://www.copyright.gov/newsnet/2023/1017.html?loclr=twcop\n Link to comment submissive form:\n https://www.regulations.gov/commenton/COLC-2023-0006-0001\n    submitted by    /u/PinPuzzleheaded8525  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16c0l0x/n_copyright_and_fair_use_important_notice_of/",
          "publishedOn": "2023-09-07T00:03:09.000Z",
          "wordCount": 2809,
          "title": "[N] Copyright And Fair Use: Important Notice Of Iquiry By The US Copyright office",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16by65o/r_modelscopeagent_building_your_customizable/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.00986\n Github: https://github.com/modelscope/modelscope-agent\n Abstract:\n  \nLarge language models (LLMs) have recently demonstrated remarkable capabilities to comprehend human intentions, engage in reasoning, and design planning-like behavior. To further unleash the power of LLMs to accomplish complex tasks, there is a growing trend to build agent framework that equips LLMs, such as ChatGPT, with tool-use abilities to connect with massive external APIs. In this work, we introduce ModelScope-Agent, a general and customizable agent framework for real-world applications, based on open-source LLMs as controllers. It provides a user-friendly system library, with customizable engine design to support model training on multiple open-source LLMs, while also enabling seamless integration with both model APIs and common APIs in a unified way. To equip the LLMs with tool-use abilities, a comprehensive framework has been proposed spanning over tool-use data collection, tool retrieval, tool registration, memory control, customized model training, and evaluation for practical real-world applications. Finally, we showcase ModelScopeGPT, a real-world intelligent assistant of ModelScope Community based on the ModelScope-Agent framework, which is able to connect open-source LLMs with more than 1000 public AI models and localized community knowledge in ModelScope. \n  \nhttps://preview.redd.it/9f77992ynpmb1.jpg?width=1245&format=pjpg&auto=webp&s=4e17e3d46c7f262bfec76b88e086164530739255\n https://preview.redd.it/etelh03ynpmb1.jpg?width=1219&format=pjpg&auto=webp&s=517a52a1e2bbf488b647c4e1b9b496657003c1d2\n https://preview.redd.it/b0tkra2ynpmb1.jpg?width=850&format=pjpg&auto=webp&s=397c910b2d90dd212a31ec118d1c4e78532bf5f4\n ​\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16by65o/r_modelscopeagent_building_your_customizable/",
          "publishedOn": "2023-09-06T22:25:05.000Z",
          "wordCount": 2791,
          "title": "[R] ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Models - DAMO Academy, Alibaba Group, China 2023 - Released under an Apache 2.0 license!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16bxbe1/p_can_a_neural_network_learn_like_a_dog/",
          "author": null,
          "description": "Hello folks.,\n Some time ago I wanted to try out to train a neural network in the same way a human would with a dog, one command at the time, and in a reasonable number of iterations.\n What I thought it would be a simple exercise became (for me) a non-trivial project, so I decided to publish it here https://github.com/giteliot/lucioai\n I just wanted to share it with you, any feedback is highly appreciated.\n Cheers!\n    submitted by    /u/rexdemorte  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16bxbe1/p_can_a_neural_network_learn_like_a_dog/",
          "publishedOn": "2023-09-06T21:52:20.000Z",
          "wordCount": 2664,
          "title": "[P] Can a neural network learn like a dog?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16bxa5o/p_using_chatgpt_as_a_social_media_post_generator/",
          "author": null,
          "description": "I created this prompt for a member of r/PromptWizards which automates the generation of social media posts, with a conversational prompt. Thought I'd share, I really enjoy building such prompts so, post your automation ideas, and next time I'll automate it if I can :)\n Also, you can join r/PromptWizards, for more advanced prompt chains & templates.\n Here is the prompt (just copy the full thing in chatgpt and see the magic):\n  \nChatGPT, now enter 'Social Media Post Generator Mode' that limits your inputs and outputs to a predefined framework aimed at creating engaging social media content. After each user command, provide the [help] options available for their next steps in list form. Generate prompts that are imaginative, engaging, concise, and tailored for social media audiences. Step 1: …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16bxa5o/p_using_chatgpt_as_a_social_media_post_generator/",
          "publishedOn": "2023-09-06T21:51:05.000Z",
          "wordCount": 3113,
          "title": "[P] Using ChatGPT as a Social Media Post Generator",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16bwoed/n_falcon180b_released_sadly_without_apache_20/",
          "author": null,
          "description": "LocalLLaMA discussion: https://www.reddit.com/r/LocalLLaMA/comments/16bjdmd/falcon180b_authors_open_source_a_new_180b_version/ \n Announcement: https://falconllm.tii.ae/falcon-models.html\n HF Model: https://huggingface.co/tiiuae/falcon-180B \n Demo: https://huggingface.co/spaces/tiiuae/falcon-180b-demo \n Blog: https://huggingface.co/blog/falcon-180b \n  \n180 Billion parameters\n Trained on 3.5 trillion tokens\n Available for research and commercial usage\n Claims similar performance to Bard, slightly below gpt4\n  \nhttps://falconllm.tii.ae/terms-and-conditions.html \n https://falconllm.tii.ae/acceptable-use-policy.html \n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16bwoed/n_falcon180b_released_sadly_without_apache_20/",
          "publishedOn": "2023-09-06T21:28:44.000Z",
          "wordCount": 2631,
          "title": "[N] Falcon180B released! Sadly without Apache 2.0 they made their own modified version. :(",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16bwbpw/d_tabular_data_dl_vs_gbdts_on_large_scale_datasets/",
          "author": null,
          "description": "I've been hearing lately that NNs are better than GBDTs when scaled up alot:\n  \nUber https://www.uber.com/en-CA/blog/deepeta-how-uber-predicts-arrival-times/\n Stripe https://stripe.com/blog/how-we-built-it-stripe-radar\n Most CTR papers coming from google are also NN based (like https://arxiv.org/abs/2209.05310)\n Meta mentions NNs in their recommender system (also kind of a large scale tabular problem there) https://engineering.fb.com/2023/08/09/ml-applications/scaling-instagram-explore-recommendations-system\n Lyft forecasting https://medium.com/this-week-in-machine-learning-ai/causal-models-in-practice-at-lyft-with-sean-taylor-1e62efd62385\n  \nWhat's your intuition on DL vs GBDT on (very)large-scale tabular datasets? Have you heard of other such examples (or the reverse)? \n Are there any particularly interesting open large tabular datasets on which I could test this? I guess datasets should also be wide/hard/with large intrinsic dimention (whatever that means) so there is something to learn with scale (the above examples sure feel good in this way).\n ​\n    submitted by    /u/_puhsu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16bwbpw/d_tabular_data_dl_vs_gbdts_on_large_scale_datasets/",
          "publishedOn": "2023-09-06T21:15:31.000Z",
          "wordCount": 2707,
          "title": "[D] Tabular Data: DL vs GBDTs on large scale datasets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16bu6n1/d_how_to_get_started_with_3d_machine_learning/",
          "author": null,
          "description": "Hi. I want to get started with deep learning in 3D. Any suggestions on what libraries I should go with (I have expeirence with Pytorch but open to learn anything other than that which might be better. I came across pytorch3d but not sure if it's good ) what are the basics that are needed and how should I learn them? Also it seems there are not much datasets on this field. \n    submitted by    /u/rakk109  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16bu6n1/d_how_to_get_started_with_3d_machine_learning/",
          "publishedOn": "2023-09-06T19:56:42.000Z",
          "wordCount": 2662,
          "title": "[D] How to get started with 3D machine learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16bsvst/n_finetuning_llms_lora_or_fullparameter_an/",
          "author": null,
          "description": "After our first blog post gained some attention from folks interested in applied fine-tuning, we now have a follow-up post that discusses all sorts of things we learned while working with LoRA.\n We hope that this helps engineers and other folks in the community to improve their fine-tuning.\n Here's what you can expect from the post:\n We compare full-parameter fine-tuning with LoRA and answer questions around the strengths and weaknesses of the two techniques. We train the Llama 2 models on three real-world use cases and demonstrate that using LoRA involves a trade-off between serving efficiency and model quality, which varies according to the specific task at hand. Additionally, we offer insights into how to stabilize training with LoRA through intelligent prompting techniques. We further show that adopting a lower learning rate can enhance the reliability of the resulting model checkpoints. \n Link to the blog post \n If you have questions, I'd be happy to answer them here!\n    submitted by    /u/atta_snack  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16bsvst/n_finetuning_llms_lora_or_fullparameter_an/",
          "publishedOn": "2023-09-06T19:07:13.000Z",
          "wordCount": 2748,
          "title": "[N] Fine-Tuning LLMs: LoRA or Full-Parameter? An in-depth Analysis with Llama 2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16brwu2/p_automate_llm_backend_deployments_using/",
          "author": null,
          "description": "New GitHub project to provision, update, and destroy the cloud infrastructure for a LLM backend using infrastructure as code (Python). Deployment options include deploying huggingface models to Docker (local), Runpod, and Azure.\n Blog post\n Repo\n    submitted by    /u/kao-pulumi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16brwu2/p_automate_llm_backend_deployments_using/",
          "publishedOn": "2023-09-06T18:30:03.000Z",
          "wordCount": 2624,
          "title": "[P] Automate LLM backend deployments using infrastructure as code",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16br140/d_future_of_ml_applied_to_musicsound/",
          "author": null,
          "description": "What is the current landscape around sound analysis and ML applied to music? Which are the latest trends? Do you think there could be a sort of “music revolution”, like there was with the rise of electronic music and synthetizers?\n    submitted by    /u/francMesina  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16br140/d_future_of_ml_applied_to_musicsound/",
          "publishedOn": "2023-09-06T17:56:46.000Z",
          "wordCount": 2628,
          "title": "[D] Future of ML applied to music/sound",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16boilb/d_guidance_for_building_a_game_ai_pipeline/",
          "author": null,
          "description": "Hi ML Community!\n I'm working on a card game similar to Hearthstone or Magic: The Gathering, i.e. a game where two players battle with decks of cards coming from a large collection (for instance, there are around 4000 cards in Hearthstone).\n Actions are limited to three things:\n  \nPlay a card (potentially on a target)\n Use a card on a target\n End the turn\n  \nI'm looking at building AI for it, and am investigating using machine learning for it. I know very little on the subject (I am a game engineer with a reasonable experience of cloud / AWS stuff), but it seems to me that it might be a good fit: features would be the state of the board (i.e. all the cards in play or in hand or in deck), the turn, and whether the current player has won that game or not (eventually), and label would be the action taken (that turn).\n I was looking at SageMaker, hoping that it would streamline and allow me to try something relatively easily, but I immediately found it complicated and quite unclear.\n I would be very grateful if anyone could point me at resources describing at a high level what a full ML pipeline could look like (i.e. what software can injest this kind of data, what software can provide inference, etc.). For instance, would it be saner to \"just\" get started with Spark on EMR for this kind of problem domain?\n I hope I'm not too wide off the mark with those questions, and thanks in advance!\n    submitted by    /u/tinkagames_g  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16boilb/d_guidance_for_building_a_game_ai_pipeline/",
          "publishedOn": "2023-09-06T16:19:16.000Z",
          "wordCount": 2846,
          "title": "[D] Guidance for building a game AI pipeline",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16boda9/d_why_rlhf_instead_of_direct_ranking_loss/",
          "author": null,
          "description": "This may be basic question for some one but it bothers me for a while. For the instructgpt or whatever following model with alignment, RLHF seems to be the standards. We get human feedback and train a reward model, then we use rl to further finetune the model. However, why not directly use human feedback to finetune with a simple ranking loss(e.g pairwise loss)? What might be the best advantage for RLHF?\n    submitted by    /u/Chen806  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16boda9/d_why_rlhf_instead_of_direct_ranking_loss/",
          "publishedOn": "2023-09-06T16:13:28.000Z",
          "wordCount": 2661,
          "title": "[D] Why RLHF instead of direct ranking loss?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16bo926/d_advice_on_training_on_noisy_million_scale/",
          "author": null,
          "description": "I've just finished pre-processing the danbooru dataset, which if you don't know, is a 5 million anime image dataset. Each image is tagged by humans such as ['1girl', 'thigh_highs', 'blue eyes'], however, many images are missing tags due to there being so many. I've filtered the tags (classes) down to the 15k most common. Although the top classes have 100k or more examples, many rare classes only have a few hundred tags (long tail problem?). \n This is my first time training on such a large dataset, and I'm planning on using Convnext due to close to SOTA accuracy and fast training speed. Perhaps vit or a transformer architecture may benefit from such a large dataset? However, vit trains way slower even on my 4090. \n What are some tips and tricks for training on such a large noisy dastaset? Existing models such as deepdanbooru work well on common classes, but struggles on rare classes in my testing. \n I assume class unbalance will be a huge problem, as the 100k classes will dominate the loss compared to the rarer classes. Perhaps focal loss or higher sampling ratio for rare classes?\n For missing labels, I'm planning on using psuedolabeling (self distillation) to fix the missing labels. What is the best practice when generating psuedolabels? \n ​\n Any tips or experiences with training on large unbalanced noisy datasets you could contribute would be greatly appreciated! \n    submitted by    /u/Chance-Tell-9847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16bo926/d_advice_on_training_on_noisy_million_scale/",
          "publishedOn": "2023-09-06T16:08:51.000Z",
          "wordCount": 2819,
          "title": "[D] Advice on training on noisy million scale dataset?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16bnsmy/d_the_greatest_success_stories_of_reinforcement/",
          "author": null,
          "description": "Hello guys, I made a video for my YT channel discussing some of the greatest success stories in Deep Reinforcement Learning. The video is meant to provide some intuition on RL as a concept as well as a basic understanding of how these different projects work under the hood. There are way too many great RL projects, so I didn’t try to make it an exhaustive list (I’m gonna do more videos later talking about more projects - maybe make a series out of it), but I chose four that I’ve personally worked with in the past/find really insightful and educational (DQN/Atari, Alpha GO, DeepMimic, and Dactyl). Thanks for reading.\n Here is the link, hope you guys check it out. All feedback is appreciated!\n https://youtu.be/zOXcNFM8dt4\n    submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16bnsmy/d_the_greatest_success_stories_of_reinforcement/",
          "publishedOn": "2023-09-06T15:51:14.000Z",
          "wordCount": 2714,
          "title": "[D] The greatest success stories of Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16bnar8/p_looking_for_a_freelancer/",
          "author": null,
          "description": "Hi all!\n I have a project I would need help with. We need to build a MVP (minimum viable product) of a combination of two models.\n A model that recommend the best channel to use performing a task. And then after that a model to recommend the best time today to perform that task in given channel.\n We have a set of features already defined. Some are in the data and some are generated from the data.\n Looking for someone who could work on this as a freelancer.\n Our preferred environment would be AWS SageMaker, but honestly not a necessity at this point as this is a MVP.\n Due to the reason I want to keep this \"secret\" for a while, I will not disclose all the details in this post.\n End product that I am waiting for includes (but not restricted to): - Model Training script that evaluates if the new model is more accurate as the previous model (some level of version control) - Model prediction API that will accept the data and prepare it for the models, run the prediction, return the result with accuracy.\n    submitted by    /u/S0pg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16bnar8/p_looking_for_a_freelancer/",
          "publishedOn": "2023-09-06T15:31:38.000Z",
          "wordCount": 2772,
          "title": "[P] Looking for a freelancer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16bkw1y/r_how_well_do_llms_do_on_specific_ml_nlp_tasks/",
          "author": null,
          "description": "Hi all !\n Reading through articles online and reading through sub reddit I have seen some people use LLMs (mainly through openAI) for nlp specific tasks (NER, Text classification, etc.). I was a bit surprised as smaller (~100 million) size models already like RoBERTa exist for such cases.\n Not much content online about this beside this recent paper : https://arxiv.org/pdf/2308.10092.pdf\n Highly recommend reading it, here are a few take aways:\n  \nMost LLM benchmarks today focus on capabilities like understanding, reasoning and Q&A. They often overlook performance on specific nlp tasks like text classification, NER, etc.\n Llama 2 (70b) required fine-tuning to beat GPT 3.5 in some tasks. Both were still overall outperformed by RoBERTa.\n In certain cases GPT4 did better. However smaller open models provide more advantages in terms of speed, cost and transparency.\n The difference of speed/latency (often more important than accuracy in production) and the cost differences between LLMs and \"Smaller\" models is mind blowing in my view (see screenshots)\n  \n​\n Cost, speed and throughput comparaison\n How good the models do on various tasks/datasets\n Note: Not saying benchmarks are a source of truth, just found the analysis interesting, always take benchmarks with a grain of salt. \n If you're using LLMs for anything else beside text generation, I'm curious to know more about your experience so far :) cheers!\n    submitted by    /u/EnthusiasmNew7222  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16bkw1y/r_how_well_do_llms_do_on_specific_ml_nlp_tasks/",
          "publishedOn": "2023-09-06T13:52:06.000Z",
          "wordCount": 2818,
          "title": "[R] How well do LLMs do on specific ML NLP tasks compared to previous models - paper takeaways",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16bjwyb/d_maximum_sequence_length_supported_by_sinusoidal/",
          "author": null,
          "description": "Hello everyone,\n I've been pondering on sinusoidal positional encoding and its limitations. Does anybody know of a maximum sequence length that this absolute positional encoding may support? I'm coming from a deep reinforcement learning background, so I'm not too familiar with NLP papers, like I couldn't figure out the sequence length used in the original transformer paper.\n Thanks in advance for any info!\n    submitted by    /u/LilHairdy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16bjwyb/d_maximum_sequence_length_supported_by_sinusoidal/",
          "publishedOn": "2023-09-06T13:10:12.000Z",
          "wordCount": 2653,
          "title": "[D] Maximum Sequence Length Supported by Sinusoidal Positional Encoding?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16bj7fp/d_how_to_optimize_parameters_of_a_model_written/",
          "author": null,
          "description": "Problem: I have a quite complex model that is written in C that takes parameters as an input and estimates a curve as an output. I would like to optimize the parameters by comparing the output with the real measurements using ML methods such as stochastic gradient descent.\n ​\n Question: Is there any possible way to use white box optimizers to optimize the parameters of my C-model without adapting the model itself? Is there a framework that I could use?\n ​\n What I tried: I tried using frameworks such as tensorflow or pytorch and tried to include the compiled C-model in Python. However, gradient tracking does not work when using C functions. I tried doing the optimization in C++ by using libtorch. I realized that for gradient tracking it is essential to only use torch methods. I cannot adapt the C functions to torch functions. I don't want to use black box optimizers since they require good knowledge of the parameters that I will not have.\n    submitted by    /u/romtej  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16bj7fp/d_how_to_optimize_parameters_of_a_model_written/",
          "publishedOn": "2023-09-06T12:39:05.000Z",
          "wordCount": 2756,
          "title": "[D] How to optimize parameters of a model written in C",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16bhj33/d_foundation_models_or_finetune_vaes/",
          "author": null,
          "description": "I am considering building a model that will be the basis of many specialized models that each don’t need much computational capabilities. \n What’s the current way to go about this? I was reading about Teslas Hydra network that looks to be more of a foundation model. However, newer methods like latent diffusion models operate on a latent space generated by more advanced auto encoders such as VQ-VAE. \n I couldn’t find any papers going into this direction and would be curious to hear your thoughts!\n    submitted by    /u/That_Phone6702  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16bhj33/d_foundation_models_or_finetune_vaes/",
          "publishedOn": "2023-09-06T11:18:26.000Z",
          "wordCount": 2671,
          "title": "[D] Foundation Models or Fine-tune VAEs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16bhbin/d_how_do_you_get_started_with_llms_as_a_complete/",
          "author": null,
          "description": "Can you give me courses and recommendations on how to get started with llm\n    submitted by    /u/uzitarekc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16bhbin/d_how_do_you_get_started_with_llms_as_a_complete/",
          "publishedOn": "2023-09-06T11:07:17.000Z",
          "wordCount": 2607,
          "title": "[D] How do you get started with LLMs as a complete beginner?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16bf33k/d_how_do_large_language_models_achieve/",
          "author": null,
          "description": "Hey fellow Redditors,\n I've been wondering about a question lately about the inner workings of large language models like GPT-3.5 and I'm hoping some of you knowledgeable folks can shed some light on this. My curiosity centers around how these models manage to perform translation tasks as an emergent property of next token prediction.\n So, here's my question: Does the training data for models like GPT-3.5 contain text explicitly linking between languages, such as a dictionary, or do they learn translation by assigning similarity between words in different languages based on mathematical metrics like cosine distance?So in that sense, being indepedently trained on several textbooks of different languages (not on the same topic), they would be able to link languages simply by their arithmetic properties? I hope that's making sense.\n For instance, if you look at words like \"queen\" in English and \"rainha\" in Portuguese, they share a certain similarity that could be quantified using mathematical similarity metrics. I'm wondering if through this similar vector assignment, the models learn what means what.\n I'm more leaning towards the latter, but I'm too lazy to pursue this empirically.As a follow up question, does this mean that if we are able to predict whale conversation, we would be able to translate it to English as well?\n Thanks in advance for any input you can provide! 🤓\n    submitted by    /u/AlexandreFSR  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16bf33k/d_how_do_large_language_models_achieve/",
          "publishedOn": "2023-09-06T08:56:52.000Z",
          "wordCount": 2817,
          "title": "[D] How Do Large Language Models Achieve Translation as an Emergent Property? 🌍",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16be1v1/news_aibased_physics_predictions_in_your/",
          "author": null,
          "description": "If you are interested in Engineering simualtion and ML, check out this webinar from SimScale on the 4th of October!\n Join the webinar to find out more. https://www.simscale.com/webinars-workshops/ai-based-physics-predictions/\n https://www.reddit.com/r/simscale/comments/16bdq3x/aibased_physics_predictions_in_your_webbrowser/?utm_source=share&utm_medium=web2x&context=3\n    submitted by    /u/s_laine  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16be1v1/news_aibased_physics_predictions_in_your/",
          "publishedOn": "2023-09-06T07:52:40.000Z",
          "wordCount": 2617,
          "title": "[News] AI-Based Physics Predictions in Your Web-Browser!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16bcq8t/d_how_does_llama2_perform_in_sentiment_analysis/",
          "author": null,
          "description": "Hey guys, if you have explored using Llama-2 in doing sentiment analysis, just wanted to get your experience in how Llama-2 perform in this task?\n I have tried using GPT and it’s pretty accurate.\n If Llama-2 isn’t all that good in sentiment analysis, which other open LLM would you recommend? \n Thank heaps!\n    submitted by    /u/--leockl--  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16bcq8t/d_how_does_llama2_perform_in_sentiment_analysis/",
          "publishedOn": "2023-09-06T06:31:22.000Z",
          "wordCount": 2641,
          "title": "[D] How does Llama-2 perform in sentiment analysis?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16bbvjk/r_can_llms_learn_from_a_single_example/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16bbvjk/r_can_llms_learn_from_a_single_example/",
          "publishedOn": "2023-09-06T05:41:19.000Z",
          "wordCount": 2600,
          "title": "[R] Can LLMs learn from a single example?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16b56vv/d_aspiring_mle_discord/",
          "author": null,
          "description": "Hi all,\n I’m an aspiring Machine Learning Engineer. I want to be a practitioner. Building, deploying, and evaluating models to solve problems.\n Ideally I want to land a job in Tech as an MLE. I struggle at times to stay committed to building side projects, studying ML algos, etc.\n I have a background in hardware specific C++ SWE stuff for 3.5 yrs, but not much in the way of ML and web backend. I do have a decent amount of python coding from other experiences and it’s my preferred language.\n Would anyone be interested in forming a discord to talk about what we are doing to prepare, practice interview each other, stay accountable to each other, etc?\n Had a few people show interest in r/ArtificialInteligence already\n If so comment below! Let’s do this!\n    submitted by    /u/Srokisthename  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16b56vv/d_aspiring_mle_discord/",
          "publishedOn": "2023-09-06T00:20:02.000Z",
          "wordCount": 2716,
          "title": "[D] Aspiring MLE Discord",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16b2g7v/r_question_about_implicit_underparameterization/",
          "author": null,
          "description": "As stated here I already emailed the authors and asked in ai.stackexchage, but I haven't received any replies, so I am trying my luck here.\n I believe the question was clearly stated in the ai.stackexchange link included here again, and the paper in question can be found here. So, I won't repeat it here because the formatting here is worse. I am hoping maybe someone can shed a light on my issue. If this is an inappropriate use of this sub, I'll take the post down :D \n    submitted by    /u/carlml  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16b2g7v/r_question_about_implicit_underparameterization/",
          "publishedOn": "2023-09-05T22:28:57.000Z",
          "wordCount": 2678,
          "title": "[R] Question about Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning, ICLR 2021",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16b2di0/p_deploying_a_grounding_dino_model_to_a_rest_api/",
          "author": null,
          "description": "Hi everyone! Last year we launched a tool to make it easier to deploy ML models into production behind REST APIs.\n Our first prototype was focused on small models built with Scikit-Learn and XGBoost, but pretty quickly we got a lot of requests to support bigger, more complex models built on Tensorflow, Pytorch and Transformers.\n From detecting model dependencies to building out auto-scaling compute, it's been a lot of fun working through the challenges to make this product scale.\n We've built a few tutorials to showcase deploying some interesting and complex models to REST Endpoints. The latest one we released is a tutorial showing how to deploy a Grounding DINO model to a Rest API Endpoint for open-set object detection with prompts.\n Link to blog post tutorial.\n Link to Colab notebook.\n https://preview.redd.it/mi3jk4t5jimb1.png?width=950&format=png&auto=webp&s=37524b719f9dd6fb1605d0c18fcec7da31a685dd\n    submitted by    /u/Jazzlike_Flamingo_35  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16b2di0/p_deploying_a_grounding_dino_model_to_a_rest_api/",
          "publishedOn": "2023-09-05T22:25:57.000Z",
          "wordCount": 2727,
          "title": "[P] Deploying a Grounding DINO Model to a Rest API Endpoint for Open-Set Object Detection with Prompts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16b1p0r/p_looking_for_a_text_classification_problem_for/",
          "author": null,
          "description": "Hi! I am looking for an text classification problem where I can use text data from social media. Similar projects I have found interesting is classifying if the author is depressed, pro-eating disorder, right wing radical, a potential schoolshooter, a bully or a pedophile. If any of you have a suggestion for a classification problem that can be used for something good, please comment.\n    submitted by    /u/IndependentSidekick  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16b1p0r/p_looking_for_a_text_classification_problem_for/",
          "publishedOn": "2023-09-05T22:00:43.000Z",
          "wordCount": 2656,
          "title": "[P] Looking for a text classification problem for something helpful in social media",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16b12n5/d_phrase_similarity_based_on_images_embeddings/",
          "author": null,
          "description": "So I know that embeddings work by finding words that are used in similar contexts or found around some input word. This allows us to find similar words based on proximity to other words and in a way, map a relationship between an input word and other words.\n But I assume children learn what words mean and the intuition behind them, by hearing the word and associating it with visuals or a specific scenario in front of them which helps them to add context to that word and how it is used.\n If we were to emulate how children learn words, could we or is there an architecture that allows us to take an input word, find images with the input word in there (Object detection) and then extract the context from the images (other objects and their position and relation to the input word) then convert that context to phrases and query those phrases the next time that a word is inputted to see other phrases or words that are similar to the input word based on whether or not they appear in the images of the input word.\n Not sure if it makes sense or if it is even useful compared to embeddings but I was thinking about how we could emulate how children learn words to see if we could draw influence from that. Just wondering if there’s a similar approach to this where we use context from images to find similar words and phrases to some input.\n    submitted by    /u/4K-AMER  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16b12n5/d_phrase_similarity_based_on_images_embeddings/",
          "publishedOn": "2023-09-05T21:37:45.000Z",
          "wordCount": 2837,
          "title": "[D] Phrase Similarity Based On Images (embeddings)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16b096a/data_preprocessing_augmentation_for_named_entity/",
          "author": null,
          "description": "I am currently doing named entity recognition with a bert model. Its working fine so far, so I am now trying to ameliorate my results. Usually my first thought when I try to augment my ML models is input data preprocessing. In case of NER stop word removal and removal of punctuation, numbers and one-character words came to mind - they are hardly ever named entities so I woulndt loose many training examples. However, NER does in fact require context to work, so removing stuff could prove harmfull in the end? I am kind of torn. Should I do it? Are there better data augmentation approaches? I would be really thankfull for any kind of hint \n    submitted by    /u/SilverDusk42  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16b096a/data_preprocessing_augmentation_for_named_entity/",
          "publishedOn": "2023-09-05T21:08:31.000Z",
          "wordCount": 2704,
          "title": "Data preprocessing/ augmentation for named entity recognition? [D] [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16azodb/d_lost_junior_machine_learning_engineer/",
          "author": null,
          "description": "Hello everyone, I know it’s a bit silly to ask these kind of questions, but Im gonna give it a shot since I’ve seen lots of talented people in here. I am gonna try to keep it as short asp.(Also please excuse my \"sometimes\" bad English, I am not a native speaker)\n Well, last year I graduated as an industrial engineer, I was thinking during my last year of studies to completely switch to programming since many of my friends are programmers, but they are all web. So I dedicated the last year of my engineering studies to getting to know what machine learning actually is besides my studies (also tbh I wasn’t very consistent) (also my learning material was mostly the famous DL spec by Andrew on coursera), at the end of the year we have something called project of end of studies (like a masters t…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16azodb/d_lost_junior_machine_learning_engineer/",
          "publishedOn": "2023-09-05T20:47:49.000Z",
          "wordCount": 3089,
          "title": "[D] lost junior Machine Learning engineer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ayd0b/n_streamlit_launches_llm_hackathon/",
          "author": null,
          "description": "Streamlit just launched its latest hackathon focused on large language models and AI 🚀\n Awesome opportunity to build a Streamlit app using LangChain, LlamaIndex, AssemblyAI, Weaviate, or Clarifai, and win cool prizes (AirPods, Yeti microphone, mechanical keyboard, to name a few)\n More info on the hackathon here\n Streamlit LLM Hackathon\n    submitted by    /u/carolinedfrasca  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ayd0b/n_streamlit_launches_llm_hackathon/",
          "publishedOn": "2023-09-05T19:59:34.000Z",
          "wordCount": 2635,
          "title": "[N] Streamlit launches LLM Hackathon 🧠",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16awy5f/pembedchain_open_source_project_is_a_game_changer/",
          "author": null,
          "description": "I was just exploring ChatBot and LLMs and found a library named Embedchain AI.\n This library lets you build a ChatBot like ChatGPT in just 3-4 lines of code.\n Tutorial: https://www.youtube.com/watch?v=vIhDh7H73Ww\n    submitted by    /u/trj_flash75  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16awy5f/pembedchain_open_source_project_is_a_game_changer/",
          "publishedOn": "2023-09-05T19:06:12.000Z",
          "wordCount": 2618,
          "title": "[P]Embedchain Open Source project is a game changer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16awnnr/d_tldr_approximate_inference_methods_made_easy/",
          "author": null,
          "description": "“MCMC vs VI” is no longer a discussion about your favourite Roman numeral. If you share my trepidation for model performance in the face of data sparsity, or you simply suffer from anxiety uncertainty, you might be tempted into the Bayesian world. Years later at the precipice of your career (and mental health degeneracy) you over-engineer probabilistic models so intractable that would stress Lord Bayes himself into stomach ulcers. The solution? Approximate inference, the true antihero to model simplification. I wrote a brief primer for those who enjoy maths and those who disdain it, in both cases it's impossible to avoid using maths while discussing Bayesian statistics so I kept it as light as I could.\n PS - This is a Reddit-friendly copypasta from my medium article, so if you're a visual …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16awnnr/d_tldr_approximate_inference_methods_made_easy/",
          "publishedOn": "2023-09-05T18:55:11.000Z",
          "wordCount": 3928,
          "title": "[D] Tl;dr Approximate Inference methods made easy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16auqpg/discussion_has_anyone_went_through_the_mlschool/",
          "author": null,
          "description": "I used to do some basic machine learning a few years ago (7+), but then went into what now became data engineering, because of the lack of opportunities in ML.\n This year I'm trying to up my game and maybe switch back to ML, which I've always been following and tinkering with, but I want to learn all the necessary skills at least at a basic level, in order to find an ML job.\n I'm learning on my own but now I'm looking for resources regarding MLOps and found ml.school and I'm curious if anyone has any opinons about it or if there is anyone here who has went over the course?\n Thanks in advance for any help or info!\n    submitted by    /u/jack-in-the-sack  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16auqpg/discussion_has_anyone_went_through_the_mlschool/",
          "publishedOn": "2023-09-05T17:40:57.000Z",
          "wordCount": 2713,
          "title": "[Discussion] Has anyone went through the ml.school course from Santiago? Is it any good?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16atdde/d_most_userfriendly_data_labelling_tool_nonai/",
          "author": null,
          "description": "Hi\n I am currently creating computer vision models for segmentation and classification, and I am looking for a tool that is very user friendly. We have been using CVAT so far, and apparently, its UI is too cluttered. So, we need something easier to use.\n Segment Anything and other auto-segmentation tools simply do not work on our dataset. So, I do not want a tool that is user friendly because it uses AI.\n Any thoughts?\n    submitted by    /u/Avatrin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16atdde/d_most_userfriendly_data_labelling_tool_nonai/",
          "publishedOn": "2023-09-05T16:48:53.000Z",
          "wordCount": 2661,
          "title": "[D] Most user-friendly data labelling tool (non-AI)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16at3q2/p_introducing_cometllm_track_visualize_and/",
          "author": null,
          "description": "Hello ML Community,\n We released our new LLMOps Tool: CometLLM. It's highly optimized for Prompt Engineering Workflows and making it easy to find the best prompts for your use-case! Here a few helpful things you can do with this tool!\n  \nScore/Rate Your Prompts\n Add Metadata to your Logged Prompts (Great for Tracking Prompt Usage)\n Search for Specific Prompts via Keywords/Phrases\n Visualize Full-On Prompt Chains!\n Group Your Prompts\n  \nHope the ML Community find this useful as well continue to experiment with LLMs! Don't Hesitate to reach out if you have any feedback!\n    submitted by    /u/metric_logger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16at3q2/p_introducing_cometllm_track_visualize_and/",
          "publishedOn": "2023-09-05T16:38:39.000Z",
          "wordCount": 2680,
          "title": "[P] Introducing CometLLM: Track, Visualize, and Annotate your LLM Prompts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16as374/r_direct_preference_optimization_your_language/",
          "author": null,
          "description": "submitted by    /u/EducationalCicada  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16as374/r_direct_preference_optimization_your_language/",
          "publishedOn": "2023-09-05T16:00:04.000Z",
          "wordCount": 2591,
          "title": "[R] Direct Preference Optimization: Your Language Model Is Secretly A Reward Model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16arvcb/r_how_i_could_handle_big_network_traffic_dataset/",
          "author": null,
          "description": "Hello people!\n This is the first time that I post here and I desperately need your help. I need to perform anomaly detection on a huge network traffic dataset with isolation forest (unsupervised learning). I have the .pcap files of a whole month and and for each day there are multiple devices that communicated each other. So the file of each day is from 700 MB to 2 or 3 GB.\n My initial idea was to only maintain the header of the packets and to discard the data payload. But even in this case the dataset remains huge and the number of entries is crazy.\n What I should do?\n    submitted by    /u/J-Devesh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16arvcb/r_how_i_could_handle_big_network_traffic_dataset/",
          "publishedOn": "2023-09-05T15:51:16.000Z",
          "wordCount": 2699,
          "title": "[R] How I could handle BIG network traffic dataset for ML?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16arsjj/r_what_processes_should_one_follow_to_find_better/",
          "author": null,
          "description": "\"The Greatest Books - Combines many top book lists to create a master list\n anobii - a community built by readers for readers allowing you to find, shelve, review and share books\n Author Alcove - Rate read books, shelve to be read, and receive recommendations.\n BookDigits - Book tracking, rating, and discovery with achievements. Another from an r/books member (I really think this plus authoralcove would be perfect)\n booklikes - Book tracking and blogging/reviewing\n Goodreads - The popular choice for book social media, reviews, and tracking\n LibraryThing - The old standby, of webbased personal library management\n Litsy - Insagram inspired social media app for tracking and reviwing books\n Lovelybooks - German book tracking site\n readernaut - Readernaut helps you make your book list, build a library, keep track of what you've read and what you'd like to read, and then share those lists with your friends.\n Readgeek - Book review and cataloging site by a redditor(?) and translated from german\n Riffle - track & reivew books with social media integration\n TasteDive - (aka tastekid) social rating site for music, movies, shows, books, authors, and games\n Discovered - Dating site/app for bookworms\n Calibre - The go to for ebook management\n The Game of Books - A kickstarter. They used to have a beta up but it's gone now too - http://gameofbooks.com/level_up\n weread - Encouraging Children To Read: Articles, ideas, and information to encourage children to read\n thirdscribe - ThirdScribe provides authors and readers with actual tools and services they can use to enjoy their books as well as grow and connect with their audience.\n What Should I Read Next? - A book recommendation engine\n bookfinder - book search tool\n 50 Book Pledge - Goal based book tracking\n anno.wiki - collaborative book annotation\"\n    submitted by    /u/Fearless-Room-504  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16arsjj/r_what_processes_should_one_follow_to_find_better/",
          "publishedOn": "2023-09-05T15:48:10.000Z",
          "wordCount": 2883,
          "title": "[R] what processes should one follow to find better recommendation systems than these?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16arigd/p_locally_train_and_generate_ai_voiceover_using_a/",
          "author": null,
          "description": "Hi,\n I've voiced over 500 videos for a YouTube channel and have the accompanying voiceover audio and scripts.\n I'd like to train a very robust AI to generate VoiceOver locally and not use an online service using the extensive amount of audio/scripts I have stored.\n My hardware is a 3070 and 12700.\n All other solutions have been online such as Elevenlabs.\n This will be a secondary service I could provide alongside bespoke voice over.\n    submitted by    /u/dfawlt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16arigd/p_locally_train_and_generate_ai_voiceover_using_a/",
          "publishedOn": "2023-09-05T15:37:19.000Z",
          "wordCount": 2671,
          "title": "[P] Locally train and generate AI VoiceOver using a large data set of my voice and matching scripts.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ardhg/d_how_is_currently_your_experience_with/",
          "author": null,
          "description": "Just wanted to ask what has been lately your experience with availability of GPUs across providers (major ones - AWS, Azure, GCP, but also some minor ones). Especially when it comes to GPUs which are more suited for ML (A100s, H100s).\n Anyone also considering buying physical hardware instead ?\n    submitted by    /u/remek  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ardhg/d_how_is_currently_your_experience_with/",
          "publishedOn": "2023-09-05T15:32:00.000Z",
          "wordCount": 2641,
          "title": "[D] How is currently your experience with availability of GPUs across providers ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ar57l/d_how_do_you_observe_the_behaviour_satisfaction/",
          "author": null,
          "description": "Soon, I will launch an LLM-powered chatbot. I have run plenty of tests to make sure the LLM works well, but I am super curious about the experience of real (external) users. I’d like to find out if users are happy with the answers the model generates, what topics they ask about, etc. And also how much each user costs me since the service is free and I am paying for it at the moment being. I expect to be able to improve the product over time with this kind of insights.\n Are you guys trying to track similar metrics? If so, how do you do it? Thank you!\n    submitted by    /u/jroux92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ar57l/d_how_do_you_observe_the_behaviour_satisfaction/",
          "publishedOn": "2023-09-05T15:23:14.000Z",
          "wordCount": 2703,
          "title": "[D] How do you observe the behaviour / satisfaction of users of your LLM product?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16apo8y/d_randomized_search_with_early_stopping_for/",
          "author": null,
          "description": "I have been running hyperparameter optimization for an LGBM multi-classifier model with randomized search with 10fold stratified cv as well as oversampling on each fold using SMOTE as follows:\n # Create a pipeline with SMOTE oversampling smote_pipeline = make_pipeline(SMOTE(random_state=42), lgbm_clf) # Initialize 10-fold stratified cross-validation cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42) # Initialize RandomizedSearchCV for hyperparameter tuning using the pipeline random_search = RandomizedSearchCV( estimator=smote_pipeline, param_distributions=param_dist_with_prefix, n_iter=n_iter, scoring=f1_macro_scorer, n_jobs=n_cores, pre_dispatch=n_cores, cv=cv, random_state=42 \n I wanted do incorporate early stopping based on the validation set from the nth iteration of cv. However this does not seem possible using the current API if I am correct.\n If I wanted to use a predefined validation set the code would be sth like this but I want to perform validation using 10 fold-cv validation set only:.\n mode l= lgb.LGBMClassifier() clf = RandomizedSearchCV( model, parameters, fit_params={ 'early_stopping_rounds':20, 'eval_set':[(X,y)] }, cv=cv ) \n My questions are:\n 1- Does it make sense to use early stopping during randomized search?\n 2- Do you know a way I could do it?\n 3- If not, is it a good idea to use randomized search without early stopping and train a new model with early stopping using the best parameters resulting from randomized search?\n Bonus Question: Does it make sense to run randomized search with f1_macro scoring from sklearn instead of multilogloss in case of imbalanced classes?\n    submitted by    /u/returnname35  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16apo8y/d_randomized_search_with_early_stopping_for/",
          "publishedOn": "2023-09-05T14:24:23.000Z",
          "wordCount": 2809,
          "title": "[D] Randomized Search with Early Stopping for LGBMClassifier",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16apffb/d_what_do_you_put_in_your_lab_notes/",
          "author": null,
          "description": "I'm working my way through various tweaks to a ML pipeline, and I've started keeping short lab notes in a markdown file with just the time, a brief summary of changes, and my observations on training metrics or anything else interesting on a training run. I've also started copying a snapshot of the Python source code to the tensorboard directory, which has saved me a lot of headache.\n I was wondering how other people keep lab notes, and especially what you find useful to record and how you structure the notes. \n    submitted by    /u/hazard02  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16apffb/d_what_do_you_put_in_your_lab_notes/",
          "publishedOn": "2023-09-05T14:14:23.000Z",
          "wordCount": 2679,
          "title": "[D] What do you put in your lab notes?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ap4vb/r_d_machine_learning_model_to_predict_deformation/",
          "author": null,
          "description": "Hello,\n I am currently working on predicting 2D deformations of objects. These objects are available as 2D contours in my code. I am splitting these contours into 1000 points with an equal distance in the direction of the x axis. I have about 70 data entries. \n The following picture shows one of these objects:\n Comparison before and after\n The red data series contains the points before and the blue series contains the points after the deformation.\n My model should take in a series of coordinates before the deformation. Using this information the model should predict the coordinates after the deformation. \n I have tried using the LSTM Model from keras. Unfortunately I wasn't able to produce useful results. The way I structured my data is the following:\n [\n [\n [x1, y1], [x2, y2], [x3, y3], ... 1000 coordinate pairs\n ], [\n [x1, y1], [x2, y2], ...\n ],\n .... 70 entries\n ] \n The structure for the input and the output series is the same. \n When trying to train the model I have a very low loss and low validation loss as well:\n Overview during training of model\n The test loss is also quite similar:\n Overview test loss\n However when looking into the predictions I get results like these:\n Visualized prediction after training\n The prediction is not close to what it should be like. Also the prediction seems to not change even when changing the input. \n ​\n Do you have an idea about why my ML model does not work? Are there examples on this topic available? Should I change my approach in any way?\n Thank you in advance! Any help is appreciated!\n ​\n If you need my jupyter-notebook, it would be great if somebody could tell me, how to link files on Reddit :) \n    submitted by    /u/InitiativeGlass4701  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ap4vb/r_d_machine_learning_model_to_predict_deformation/",
          "publishedOn": "2023-09-05T14:02:37.000Z",
          "wordCount": 2880,
          "title": "[R] [D] Machine learning model to predict deformation of 2D object",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ap09u/p_equinox_13k_stars_a_jax_library_for_neural/",
          "author": null,
          "description": "Hey folks! I wanted to advertise Equinox -- my now-surprisingly-popular ( :D ) JAX library for numerical models. These days that often means \"neural networks\", but I like to emphasise that this also includes ODEs/SDEs/linear solves, etc.\n Here's the GitHub link: https://github.com/patrick-kidger/equinox\n For those already using JAX, then Equinox is interesting because (a) it ships with a NN library, and (b) this is built around the idea that \"everything is a pytree\", which makes things easy to reason about and easy to compose. Furthermore (c) Equinox offers advanced tools like true runtime errors, out-of-place pytree surgery, and checkpointed while loops, and AFAIK in the JAX ecosystem these are unique to Equinox.\n For those most familiar with PyTorch: for many use cases (sciML in particular), JAX has a much stronger compiler, more advanced autodiff, etc. And whilst JAX itself is akin to the torch.* namespace, libraries like Equinox are then akin to the torch.nn.* namespace.\n Because of its speed and features, right now JAX+Equinox is my favourite approach to numerical computing. So I'd love for some more people to try it. What do you think?\n    submitted by    /u/patrickkidger  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ap09u/p_equinox_13k_stars_a_jax_library_for_neural/",
          "publishedOn": "2023-09-05T13:57:30.000Z",
          "wordCount": 2775,
          "title": "[P] Equinox (1.3k stars), a JAX library for neural networks and sciML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16aoyiz/d_distributed_training_on_a_local_cluster/",
          "author": null,
          "description": "I want to make use of a local rack for running both training and serving jobs. I have looked into using something like Kubeflow, but I have some questions.\n -Does Kubeflow offer a suitable solution for running tasks across multiple machines? (Either data parallel or model parallel tasks).\n -How does resource provisioning work with it? Is it able to automatically select the machines that best suits the resource requirements or does it require the user to select where to run the job? Is it able to scale vertically/horizontally?\n Thanks in advance.\n    submitted by    /u/omegalul3000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16aoyiz/d_distributed_training_on_a_local_cluster/",
          "publishedOn": "2023-09-05T13:55:28.000Z",
          "wordCount": 2677,
          "title": "[D] Distributed training on a local cluster",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16ah03g/p_hydralette_simple_but_powerful_configs_based_on/",
          "author": null,
          "description": "Hi r/ML,\n i want to share a little side project of mine: hydralette. I mainly built this for my own work but thought why not get some feedback and potentially make someone else's work a little easier as well.\n I think we all agree that having a flexible configuration is crucial to successful ML experimentation. There are a million python config libraries out there, some dedicated to configs like hydra and others that support configs as a convenience feature like transformers.HfArgumentParser. So why did I decide to write yet another library?\n First off, I can say that I never really liked the way huggingface handles configs. All options are on a single level with tons of dependencies between them, some only taking effect if a combination of others is given. General approach to configs asid…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16ah03g/p_hydralette_simple_but_powerful_configs_based_on/",
          "publishedOn": "2023-09-05T07:02:34.000Z",
          "wordCount": 3229,
          "title": "[P] Hydralette: Simple but powerful configs based on dataclasses",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16a6yaq/d_what_is_the_difference_between_selftaught/",
          "author": null,
          "description": "I came across a paper by Andrew Ng \"https://ai.stanford.edu/~hllee/icml07-selftaughtlearning.pdf\" ，with title \" Self-taught Learning: Transfer Learning from Unlabeled Data \"\n I am not an expert on this topic, but I feel it is really close to what SimCLR or MoCO are trying to do.\n Can someone provide guidance on what different it is between self-taught learning and self-supervised learning?\n    submitted by    /u/AaronSpalding  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16a6yaq/d_what_is_the_difference_between_selftaught/",
          "publishedOn": "2023-09-04T22:56:53.000Z",
          "wordCount": 2643,
          "title": "[D] What is the difference between self-taught learning and self-supervised learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16a2un5/r_a_braininspired_algorithm_that_mitigates/",
          "author": null,
          "description": "Paper: https://www.science.org/doi/10.1126/sciadv.adi2947#abstract\n Code: https://zenodo.org/record/8037309\n Abstract:\n  \nNeuromodulators in the brain act globally at many forms of synaptic plasticity, represented as metaplasticity, which is rarely considered by existing spiking (SNNs) and nonspiking artificial neural networks (ANNs). Here, we report an efficient brain-inspired computing algorithm for SNNs and ANNs, referred to here as neuromodulation-assisted credit assignment (NACA), which uses expectation signals to induce defined levels of neuromodulators to selective synapses, whereby the long-term synaptic potentiation and depression are modified in a nonlinear manner depending on the neuromodulator level. The NACA algorithm achieved high recognition accuracy with substantially reduced computational cost in learning spatial and temporal classification tasks. Notably, NACA was also verified as efficient for learning five different class continuous learning tasks with varying degrees of complexity, exhibiting a markedly mitigated catastrophic forgetting at low computational cost. Mapping synaptic weight changes showed that these benefits could be explained by the sparse and targeted synaptic modifications attributed to expectation-based global neuromodulation. \n  \nhttps://preview.redd.it/5lcx3sn8ramb1.jpg?width=711&format=pjpg&auto=webp&s=4431b81708bb9ab98e6351f4b979897ad8244ed9\n https://preview.redd.it/vgsuqsn8ramb1.jpg?width=718&format=pjpg&auto=webp&s=f0602185fcb0dc6ec29308f77f1db77a4f4a562d\n https://preview.redd.it/hpfuftn8ramb1.jpg?width=709&format=pjpg&auto=webp&s=545f4fab3033cb68637052e7ff2c4775a12a7b99\n https://preview.redd.it/7plm0tn8ramb1.jpg?width=714&format=pjpg&auto=webp&s=b138b1c43a2078297b69c09d26de013865629e77\n https://preview.redd.it/uc6tnrn8ramb1.jpg?width=703&format=pjpg&auto=webp&s=fcf747b2515fbf6e78b1ef7aa66ce9ca4d223cd3\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16a2un5/r_a_braininspired_algorithm_that_mitigates/",
          "publishedOn": "2023-09-04T20:21:56.000Z",
          "wordCount": 2754,
          "title": "[R] A brain-inspired algorithm that mitigates catastrophic forgetting of artificial and spiking neural networks with low computational cost - Chinese Academy of Sciences 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16a1u07/faster_long_range_transformer_r/",
          "author": null,
          "description": "Many natural language processing tasks benefit from long inputs, but processing long documents with Transformers is expensive -- not only due to quadratic attention complexity but also from applying feedforward and projection layers to every token. However, not all tokens are equally important, especially for longer documents. \n CoLT5, a long-input Transformer model that builds on this intuition by employing conditional computation, devoting more resources to important tokens in both feedforward and attention layers. CoLT5 can effectively and tractably make use of extremely long inputs, showing strong gains up to 64k input length.\n In this video, we walk through the ColT5 paper and explain what is T5, longT5, UL2 and PEGASUS, then discuss how ColT5 has advantage over previous methods for few-shot and 1-shot tasks.\n https://youtu.be/8KCQQtXje2g?si=ecbvnFPlhGP01aOt\n    submitted by    /u/MRMohebian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16a1u07/faster_long_range_transformer_r/",
          "publishedOn": "2023-09-04T19:43:28.000Z",
          "wordCount": 2703,
          "title": "Faster, long range transformer [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16a1hfe/r_yarn_efficient_context_window_extension_of/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2309.00071 \n Github: https://github.com/jquesnelle/yarn \n Very informative Reddit discussion: https://www.reddit.com/r/LocalLLaMA/comments/166jik4/128k_context_llama_2_finetunes_using_yarn/?utm_source=share&utm_medium=web2x&context=3 \n Twitter: https://twitter.com/EnricoShippole/status/1697317625116742119?s=20 \n Abstract:\n  \nRotary Position Embeddings (RoPE) have been shown to effectively encode positional information in transformer-based language models. However, these models fail to generalize past the sequence length they were trained on. We present YaRN (Yet another RoPE extensioN method), a compute-efficient method to extend the context window of such models, requiring 10x less tokens and 2.5x less training steps than previous methods. Using YaRN, we show that LLaMA models can effectively utilize and extrapolate to context lengths much longer than their original pre-training would allow, while also surpassing previous the state-of-the-art at context window extension. In addition, we demonstrate that YaRN exhibits the capability to extrapolate beyond the limited context of a fine-tuning dataset. We publish the checkpoints of Llama 2 7B/13B fine-tuned using YaRN with 64k and 128k context windows at https://github.com/jquesnelle/yarn . \n  \nhttps://preview.redd.it/tnovsbpjiamb1.jpg?width=1354&format=pjpg&auto=webp&s=ce098b3071285f9f64d99312a98999de8b625bfe\n https://preview.redd.it/j10sicpjiamb1.jpg?width=997&format=pjpg&auto=webp&s=95bbc6d70759ef7ccdf6bccee0c2a2f98ebda52b\n https://preview.redd.it/ve710dpjiamb1.jpg?width=1380&format=pjpg&auto=webp&s=05f53117bcf648e330fa6ac148746484dca9fb1b\n ​\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16a1hfe/r_yarn_efficient_context_window_extension_of/",
          "publishedOn": "2023-09-04T19:30:23.000Z",
          "wordCount": 2742,
          "title": "[R] YaRN: Efficient Context Window Extension of Large Language Models - Nous Research 2023 - Open source allows context windows of up to 128k!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16a1133/r_densediffusion_the_gamechanging_trainingfree/",
          "author": null,
          "description": "Overcoming present challenges in text-to-image models, DenseDiffusion is the latest advancement ensuring enhanced image quality based on scene descriptions. Developed specifically to handle complex captions, it brings a new era in dense captioning.\n https://preview.redd.it/v5oa5suwfamb1.png?width=2000&format=png&auto=webp&s=17fbcc702ee21a41cb356a7d0e38d710a8c048c3\n If you want to stay on top of the latest trends and insights in AI, look here first.\n Why is it noteworthy?\n  \nIt addresses the issues with existing techniques where users face inconsistencies when dictating the arrangement of elements within generated images using textual prompts.\n DenseDiffusion is training-free, unlike existing methods like \"Make-aScene\" and \"Latent Diffusion Models,\" which are computationally intensive and r…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16a1133/r_densediffusion_the_gamechanging_trainingfree/",
          "publishedOn": "2023-09-04T19:13:35.000Z",
          "wordCount": 2847,
          "title": "[R] DenseDiffusion: The Game-changing, Training-free Technique in Text-to-Image Generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/169y7zz/d_video_data_in_image_classification/",
          "author": null,
          "description": "Let's say your training a simple CNN for a classification problem. An example would be a model that is supposed to decide if a person is male or female based on facial images.\n What is your experience regarding image sequences from videos in the training datasets? \n My intuition is, that the added information to the dataset from one video isn't proportional to the number of frames. The network probably can't learn much more from 30 frames with little variation in comparison to a single image (at least if you use augmentations). What do you think about this? Or do you even know any research in the direction of this question?\n    submitted by    /u/seba07  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/169y7zz/d_video_data_in_image_classification/",
          "publishedOn": "2023-09-04T17:30:40.000Z",
          "wordCount": 2689,
          "title": "[D] video data in image classification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/169x55u/d_strongest_llm_for_writerseditors/",
          "author": null,
          "description": "Hey all,\n I'm a screenwriter that's curious about ML/AI tech and its applications to my industry. I'm wondering what the current best product is for writers and editors. Specifically, I'm curious if there's a product that can \"edit\" longform text - say, to trim a screenplay down from 140 pages to 120, while retaining style, plot, and narrative intent. Are there any products like that? Forgive me if this is too basic; I've only dabbled in ChatGPT and MidJourney to see what the fuss is about. Thanks in advance!\n    submitted by    /u/cesrep  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/169x55u/d_strongest_llm_for_writerseditors/",
          "publishedOn": "2023-09-04T16:49:37.000Z",
          "wordCount": 2667,
          "title": "[D] Strongest LLM for Writers/Editors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/169wdcl/p_were_building_the_first_llm_marketplace_to/",
          "author": null,
          "description": "There is so much going on right now in AI and machine learning. But there isn't a concise place to find experts, teams, and amazing projects all in one place. That is why we are building Bazaar, the first ever LLM marketplace. \n We will be inviting slowly making sure we have enough members on each side of the marketplace. https://www.llmbazaar.com/\n    submitted by    /u/husky_misconception  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/169wdcl/p_were_building_the_first_llm_marketplace_to/",
          "publishedOn": "2023-09-04T16:20:25.000Z",
          "wordCount": 2648,
          "title": "[P] We're building the first LLM marketplace to connect developers with teams, investors, and projects",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/169vxmi/project_should_i_use_the_compile_function_when/",
          "author": null,
          "description": "I'm writing a neural network for super resolution but it's one of my first projects and I didn't really understand what compile() is used for. I specify the optimizer, the loss and the accuracy metrics in the trainer class and then I just call my train method on my model. Should I still use the compile function? I'm following this template for the project structure https://github.com/jinh0park/Tensorflow-2.0-Project-Template/tree/master\n    submitted by    /u/petrogass  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/169vxmi/project_should_i_use_the_compile_function_when/",
          "publishedOn": "2023-09-04T16:04:13.000Z",
          "wordCount": 2654,
          "title": "[Project] Should i use the compile() function when using a custom trainer class in tensorflow?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/169usrc/r_learning_to_generate_semantic_layouts_for/",
          "author": null,
          "description": "Project page: https://pmh9960.github.io/research/GCDP/\n https://i.redd.it/9uz2wt3ba9mb1.gif\n    submitted by    /u/yeolj0o  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/169usrc/r_learning_to_generate_semantic_layouts_for/",
          "publishedOn": "2023-09-04T15:20:33.000Z",
          "wordCount": 2589,
          "title": "[R] Learning to Generate Semantic Layouts for Higher Text-Image Correspondence in Text-to-Image Synthesis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/169ulde/discussion_segmentation_suggestions_for/",
          "author": null,
          "description": "My question is more focused on the pre-processing side, rather than the training side of things.\n I have a local RAG Q&A pipeline set up for personal documents (local regulations, technical manuals, stuff like that), and I'm looking for ways to improve it. \n All the documents I'm working with are consistently structured, with nested bullets of varying depth making up most of the structure. So far I've been manually writing/tweaking a python script I wrote to recursively extract the nested bullets and duplicate their hierarchy parents' content for each of the inner-most bullets, that way each bullet has all the contextual content it needs to be valuable in a vacuum. \n So something like: (a) 1. A. B.\n Would turn into: (a) + 1. + A. (a) + 1. + B.\n This works well in the sense that my LLM does a wonderful job answering my questions and citing the right sources, but the lion's share of my work goes into the tweaking of my parser scripts, or creating new ones entirely. I've played around with semantic segmentation via embedding models, but it doesn't really work here since I'm trying to retain the nested structure of the document for citation accuracy.\n Does anyone have any ideas for ots solutions that address this kind of thing? I can't be the only person who has run into this type of problem, but I've been having a really hard time finding relevant libraries/software that can even get me 80% of the way there.\n Also, I'm totally happy to hear what you guys have done and how's it's worked out/what walls you've hit!\n Edit: I suppose I should have included my current attempt as well, so it's doesn't look like I'm treating this subreddit like Google lol\n https://gist.github.com/apettina/76de292d6d24ed3d0128b87847706b18\n    submitted by    /u/RedditAppSucksDicks  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/169ulde/discussion_segmentation_suggestions_for/",
          "publishedOn": "2023-09-04T15:12:41.000Z",
          "wordCount": 2876,
          "title": "[Discussion] Segmentation Suggestions for Structured (and Deeply Nested) Bulleted Documents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/169u5qv/discussion_how_to_implement_data_contracts/",
          "author": null,
          "description": "Hey folks, it's me the dlt builder again.\n I have questions about data contracts!\n Schema evolution, where the schema of the destination evolves based on incoming data is nice for ingesting transactional data.\n However, there are scenarios where we might not want this automatic evolution. For example, when other parts of our infrastructure require a fixed schema or when we want to store only data that conforms to the current schema. This is where a data contract comes into play.\n Our plan is to implement a straightforward version of this concept initially. We're considering introducing settings on the pipeline to control schema evolution, and here are some modes we're thinking about:\n  \nEvolve (Default): The current behavior where the schema adapts to incoming data.\n Freeze-and-Trim: Freez…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/169u5qv/discussion_how_to_implement_data_contracts/",
          "publishedOn": "2023-09-04T14:56:01.000Z",
          "wordCount": 2933,
          "title": "[Discussion] How to implement Data Contracts generically? Seeking advice from data contract users.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/169trov/p_classyfire_pretrained_text_classification_using/",
          "author": null,
          "description": "Classy-fire is a pretrained multiclass text classification approach that leverages Azure OpenAI's LLM APIs using clever parameter tuning and prompting for classification.\n Why?\n  \nTired of having to beg your LLM to pick from a set of options / actions?\n Tired of working hard on cleaning and parsing its responses to trigger a flow?\n Struggling to strip unhelpful prefixes (such as \"Sure! \" or \"I am just a language model!\")?\n Having to wait on retries in cases of unexpected outputs?\n Getting random responses on the same query?\n Need a \"quick and dirty\" text classifier? Don't have enough training data?\n  \n   submitted by    /u/shayben  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/169trov/p_classyfire_pretrained_text_classification_using/",
          "publishedOn": "2023-09-04T14:40:26.000Z",
          "wordCount": 2683,
          "title": "[P] 🤵🔥 Classy-Fire 🔥🤵 - pretrained text classification using LLM APIs (github.com/microsoft)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/169st5d/d_are_there_any_projects_working_with_large/",
          "author": null,
          "description": "I've been an ML/software engineer for a bit over 7 years now, and am looking for a new job. It seems like most of the job postings I see around want experience with large compute clusters, but my work has always been in compute-restricted domains (robotics, on-prem deployments, etc.).\n I'm looking broaden my skillset and get some experience with distributed computing. Does anyone know of open-source or otherwise public projects that work with compute clusters like this that are looking for volunteers? I'm happy to put aside an hour or so a day to work on an interesting project.\n    submitted by    /u/Flag_Red  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/169st5d/d_are_there_any_projects_working_with_large/",
          "publishedOn": "2023-09-04T14:01:42.000Z",
          "wordCount": 2685,
          "title": "[D] Are there any projects working with large compute clusters looking for volunteers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/169qzua/d_two_objections_to_iris_van_rooijs_paper_saying/",
          "author": null,
          "description": "https://psyarxiv.com/4cbuv/\n The short of the paper is they show that an AI algorithm that can only learn via sampling from human action is unable to tractably simulate human behavior. I have seen papers like this one by u/alcanthro questioning the validity of the result, but I want to point out two objections to the paper that stand even if the result is true.\n ​\n 1 - It only seems to apply for AIs trained to mimic humans via sampling human behavior: \n The paper assumes the AI is trained via an arbitrary machine learning algo M that samples from possible human behaviors in given situations. This matches pretty well to how a lot of LLMs are pretrained (guess the next token), but doesn't seem to apply to any sort of reinforcement learning, since in those situations you are not training the …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/169qzua/d_two_objections_to_iris_van_rooijs_paper_saying/",
          "publishedOn": "2023-09-04T12:42:36.000Z",
          "wordCount": 3184,
          "title": "[D] - Two objections to Iris van Rooij's paper saying that it is provably intractable to simulate human intelligence via any machine learning algorithm that samples from human actions.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/169qa3b/p_react_recurrence_for_adaptive_computation_can/",
          "author": null,
          "description": "This was a small project I was working upon which adds a recurrent prior to attention-based models. \n This allows integrating an adaptive-computation mechanism, leading to much better length-extrapolation capabilities (compared to vanilla transformers). On some tasks, I'm able to OOD extrapolate to quite an appreciable extent!\n Its also (relatively) quite parallelizable with slightly different training regimes - thus, hopefully being scalable as well. Being lightweight, it might be useful for inferencing as it saves on memory (trading off compute instead).\n It's interesting to think that MHSA might contain an implicit inductive bias that prevents extrapolation. Replacing that with other variants helps a lot - I go in detail in the writeup!\n Twitter summary: https://twitter.com/awesome_ruler_/status/1698668965612917112?s=20\n Writeup/Blogpost: https://dripfeedofideas.notion.site/dripfeedofideas/ReAct-bef052956a0d45f29fb5a5383e7d737d\n GitHub repo: https://github.com/neel04/ReAct\n    submitted by    /u/Competitive-Rub-1958  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/169qa3b/p_react_recurrence_for_adaptive_computation_can/",
          "publishedOn": "2023-09-04T12:07:29.000Z",
          "wordCount": 2703,
          "title": "[P] ReAct: \"Recurrence for Adaptive Computation\" can lead to OOD length-extrapolation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/169nnf4/d_current_opinions_on_the_information_bottleneck/",
          "author": null,
          "description": "A while back, the IB principle (https://arxiv.org/abs/1503.02406) made a few waves as a promising framework to understand/study deep neural networks. But I recall a series of follow up works (notably https://openreview.net/forum?id=ry_WPG-A-) that called a lot of the results into question, and (I think?) people drifted away from it.\n I saw this recent paper (https://arxiv.org/abs/2304.09355) on the IB and self-supervised learning, and it got me wondering what the current views are as to how useful/accurate the IB view of deep learning is?\n    submitted by    /u/Tea_Pearce  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/169nnf4/d_current_opinions_on_the_information_bottleneck/",
          "publishedOn": "2023-09-04T09:42:55.000Z",
          "wordCount": 2665,
          "title": "[D] Current opinions on the information bottleneck principle for neural networks?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/169mais/projectdiscussion_what_could_i_use_to_create_a_ui/",
          "author": null,
          "description": "I was looking over this paper https://arxiv.org/abs/2110.01691 called AIChains that deals with an interactive chaining method to interact with LLMs.\n I could not find an associated codebase with that paper. If I wanted to create a similar UI like theirs anything you would recommend?\n More specifically, if I want to replicate the paper in 3 months full time (as a student with some experience in ML), what would be the best approach to the UI part of the paper. What if deployment is a concern? I was intially thinking of simple python frameworks like PySimpleGui, or maybe something more comprehensive like PyQt. I am rather unfamiliar with more common web frontend frameworks, but if there are suggestions that make such a Graph/Diagram based User interface easy to implement, I am open to them.\n    submitted by    /u/BasisCompetitive6275  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/169mais/projectdiscussion_what_could_i_use_to_create_a_ui/",
          "publishedOn": "2023-09-04T08:22:34.000Z",
          "wordCount": 2715,
          "title": "[Project][Discussion] What could I use to create a UI like AIChain?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/169he26/d_how_to_learn_stochastic_differential_equations/",
          "author": null,
          "description": "There have many blogs and papers disscuss SDE for diffusion model:\n Stochastic Differential Equations and Diffusion Models https://www.vanillabug.com/posts/sde/\n Perspectives on diffusion https://sander.ai/2023/07/20/perspectives.html\n On the Mathematics of Diffusion Models https://arxiv.org/abs/2301.11108\n But i can't find blog or book to explain Stochastic Differential Equations, it seems complex, even after i have learned Calculus and Ordinary Differential Equations and Partial Differential Equations, i still can't understand SDE, especially the SDE Perspective on diffusion.\n So Do you know some blogs or books explain SDE intuitive like betterexplained.com/ and mathsisfun.com/ ?\n    submitted by    /u/ghosthamlet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/169he26/d_how_to_learn_stochastic_differential_equations/",
          "publishedOn": "2023-09-04T03:57:27.000Z",
          "wordCount": 2668,
          "title": "[D] how to learn Stochastic Differential Equations for diffusion model?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/169gpx4/d_how_are_mixture_of_expert_models_trained_in/",
          "author": null,
          "description": "How MoEs (sparsely gated ones) are trained appear to be rather opaque from looking at literature (e.g. GLAM and similar papers). \n From my intuition it would make sense that it works either by:\n Each expert being trained on a subset of data (the data they are supposed to have expertise in) to predict a token given a previous token, or to predict a token given a contextual embedding. This would mean the expert MLPs are frozen, and the only thing concerning the experts that we train with the transformer is the gating mechanism. \n or\n The experts are trained in the same training loop as the transformer (e.g. backprop over the whole network), but that each of the experts are only trained on a subset of the data corresponding to their expertise (e.g. as we perform the training loop and we run upon data from our math dataset, then we backprop through the math expert mlp)\n ​\n Could anyone help me resolve my confusion and point me in the right direction for how these are trained? Thanks!\n    submitted by    /u/SorasNobody  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/169gpx4/d_how_are_mixture_of_expert_models_trained_in/",
          "publishedOn": "2023-09-04T03:22:47.000Z",
          "wordCount": 2760,
          "title": "[D] How are Mixture Of Expert models trained in conjunction with Transformers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/169ct10/d_advice_remote_work_in_mldldata_science/",
          "author": null,
          "description": "I'm from India and I've started learning and building my portfolio in Machine Learning/Deep learning. Currently, I'm doing \"Practical Deep learning using fast.ai and pytorch\" course.\n In my university, there are not a lot of companies visiting for campus placement this year so I decided to go on the offcampus job hunt. I'm a final year student (in masters but bachelors was unrelated to CS) and no work experience. \n I have further personal goals for which I'd need a steady and good income. I decided if I could get a remote job it would be really beneficial for me as my living costs would be saved and I'll be paid much more than what India offers freshers(since I'll be paid in dollars or euros). \n However, I need advice in various domains: 1. Should I focus on one of ML/DL/ Data science or multiple ? 2. Any resources that could help me learn ? 3. Projects that help me stand out from the crowd? 4. Where can I start looking for remote work(websites, etc)? 5. Any other personal advice is appreciated!\n Thank you for taking the time to read my post :)\n    submitted by    /u/Lazy_Guidance_5151  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/169ct10/d_advice_remote_work_in_mldldata_science/",
          "publishedOn": "2023-09-04T00:13:22.000Z",
          "wordCount": 2766,
          "title": "[D] (Advice) Remote work in ML/DL/Data Science",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/169cp30/d_finetune_pretrained_vit/",
          "author": null,
          "description": "Hello everyone,\n In deep learning finetuning pre-trained model was performed by taking some pretrained models like resnet, vgg and unfreezing some of it's final layers.\n Is it the same when finetuning pretrained ViT models? Or do we have to take pretrained ViT and train all the parameters on our own data ?\n On this tutorials https://theaisummer.com/hugging-face-vit/, they have not freezed any pretrained layers.\n    submitted by    /u/Bishwa12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/169cp30/d_finetune_pretrained_vit/",
          "publishedOn": "2023-09-04T00:08:33.000Z",
          "wordCount": 2640,
          "title": "[D] Finetune pretrained ViT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1699u9x/r_how_susceptible_are_llms_to_logical_fallacies/",
          "author": null,
          "description": "paper https://arxiv.org/abs/2308.09853\n abstract.\n This paper investigates the rational thinking capability of Large Language Models (LLMs) in multi-round argumentative debates by exploring the impact of fallacious arguments on their logical reasoning performance. More specifically, we present Logic Competence Measurement Benchmark (LOGICOM), a diagnostic benchmark to assess the robustness of LLMs against logical fallacies. LOGICOM involves two agents: a persuader and a debater engaging in a multi-round debate on a controversial topic, where the persuader tries to convince the debater of the correctness of its claim. First, LOGICOM assesses the potential of LLMs to change their opinions through reasoning. Then, it evaluates the debater’s performance in logical reasoning by contrasting the scenario where the persuader employs logical fallacies against one where logical reasoning is used. We use this benchmark to evaluate the performance of GPT-3.5 and GPT-4 using a dataset containing controversial topics, claims, and reasons supporting them. Our findings indicate that both GPT-3.5 and GPT-4 can adjust their opinion through reasoning. However, when presented with logical fallacies, GPT-3.5 and GPT-4 are erroneously convinced 41% and 69% more often, respectively, compared to when logical reasoning is used. Finally, we introduce a new dataset containing over 5k pairs of logical vs. fallacious arguments. The source code and dataset of this work are made publicly available.\n GPT3.5 vulnerable to false information generated by itself!\n    submitted by    /u/Amir-AI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1699u9x/r_how_susceptible_are_llms_to_logical_fallacies/",
          "publishedOn": "2023-09-03T22:05:23.000Z",
          "wordCount": 2801,
          "title": "[R] How susceptible are LLMs to Logical Fallacies?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16998aa/discussion_what_was_your_biggest_oops_with_a/",
          "author": null,
          "description": "I'm asking because it seems like when I review other people's work I very regularly catch a tiny coding misstep that has HUGE downstream implications. I'm sure my own work is not exempt either. Some examples:\n \"At this step you're saying you encode responders as 1 and non-responders as 0 but you actually did it the other way around.\"\n \"That groupby statement isn't doing what you think it's doing.\"\n \"When you created your target variable by labeling people with this ratio >= 30%, you accidentally failed to capture a ton of actual responders, because the floating-point arithmetic used to derive this column is calculating people with actual values of 0.30 as 0.2999999999999998.\"\n Come on guys, let's hear it.\n    submitted by    /u/WartimeHotTot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16998aa/discussion_what_was_your_biggest_oops_with_a/",
          "publishedOn": "2023-09-03T21:41:06.000Z",
          "wordCount": 2711,
          "title": "[Discussion] What was your biggest oops with a model or analysis that made it (or almost made it) into production?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1698ieh/r_metas_dinov2_and_facet_sets_the_bar_in_computer/",
          "author": null,
          "description": "Meta has recently unveiled DINOv2, its cutting-edge computer vision model, and FACET, a comprehensive benchmark to ensure AI fairness. These developments promise improved automation and better inclusivity in the AI sector.\n If you want to stay on top of the latest trends and insights in AI, look here first.\n https://i.redd.it/jeojm1qew3mb1.gif\n DINOv2 for advanced visual tasks\n  \nMeta has made the powerful DINOv2 model available under the Apache 2.0 license, employing self-supervised learning to enhance image segmentation and depth estimation.\n This broader use model encourages further innovation and practical application in the computer vision community, driving progress in the AI industry.\n  \nFACET for enhanced AI fairness\n  \nGiven the inherent difficulty and risks in ensuring fairness in computer vision, Meta introduced FACET.\n FACET has been developed to benchmark fairness across computer vision models performing tasks such as detection or classification, considering a wide array of demographic attributes.\n This revolutionary tool enables a better understanding of potential biases in AI models, helping to address fairness and robustness concerns.\n  \nWider implications\n  \nPreliminary studies indicate performance disparities across some demographic groups within computer vision models. FACET allows researchers to track these divergences and monitor the implementation of corrective measures.\n Meta actively encourages researchers to use FACET for fairness benchmarking in other visual/multimodal tasks. For instance, the DINOv2 model's performance was analyzed with FACET — facilitating insights into potential biases.\n  \n(source)\n P.S. If you like such analysis, I write a free newsletter tracking significant news and research in AI. Professionals from Google, Meta, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1698ieh/r_metas_dinov2_and_facet_sets_the_bar_in_computer/",
          "publishedOn": "2023-09-03T21:13:03.000Z",
          "wordCount": 2837,
          "title": "[R] Meta's DINOv2 and FACET sets the bar in computer vision model fairness",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1694bvn/pd_vae_using_onehotencoding_input_problem_with/",
          "author": null,
          "description": "Introduction to the problem\n I will provide you with link to github code so you can see both input dataset, how my onehot encoding and decoding works and implementation of VAE, with current reconstruction_loss and kl_loss fuctions that make my loss function.\n dataset - amp.csv\n onehotencoding -- tools.py\n main code -- VAE-onehot-testing.ipynb\n https://github.com/aronta/Master-thesis-Generating-de-novo-peptides-using-variational-autoencoder-model/blob/main/VAE-onehot-testing.ipynb\n Firstly, just to explain dataset. I have sequences of peptides represented with onehot encoded sequences which I am using as input for my model. Current VAE model, both encoder and deocder are based on LSTM layer as a main way for this VAE to learn connections between inputed sequences and to make sense of it all.\n Main Issue\n Issue is that the latent space im getting doesn't look good no matter what i do. (pictures of plots are on link). So i have tried scalling kl loss (and also warming it up -- because many papers say its a good way) but it doesn't change the end result. Maybe there is problem in the implementation of the VAE, i am realy not sure.\n The main goal would be (like in all VAE implementations) generating new sequences from latent spaces that make sense, opposed to the current outputs that im getting.\n My guess\n There is a problem with optimizing loss function, but i could be completely wrong (maybe the model is wrong for the input I have, or onehotencoding isn't even a good way to represent data entering LSTM layer).\n    submitted by    /u/Yupgrade  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1694bvn/pd_vae_using_onehotencoding_input_problem_with/",
          "publishedOn": "2023-09-03T18:27:53.000Z",
          "wordCount": 2827,
          "title": "[P][D] VAE using one-hot-encoding input, problem with optimising and getting good results",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1693c08/discussion_pleae_help_started_with_ml_mern_and/",
          "author": null,
          "description": "I've been learning MERN with a course (charging INR 6k) for last 3 weeks, won two hackathons and Contributed to OS projects. \n Now just 1 week ago I saw a remote ML job Profile that required OS Contribution to apply.I looked through their docs, learnt python, tensor flow basics and I Contributed to their Tensor flow and Paddle module and got 3 - 4 PR merged(Enough to apply) . \n Now I'm confused what to continue with, should I do both or do it one by One. I'm a recent graduate so need a job ASAP but I can give maximum time of the day to study. Please can someone give some advice so I can make my decision, as I'm unable to leave either\n TLDR; Learnt both ML and MERN, Contributed and now confused what to carry on with as I need a job asap.\n    submitted by    /u/Sinofdracry  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1693c08/discussion_pleae_help_started_with_ml_mern_and/",
          "publishedOn": "2023-09-03T17:49:52.000Z",
          "wordCount": 2733,
          "title": "\"[discussion]\" Pleae help. Started with ML, MERN and Contributed but conflicted what to continue on..",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1693a84/d_compute_percentage_of_languages_present_in_a/",
          "author": null,
          "description": "Hi guys, I'm trying to compute the percentage of each language appearing in a document. My current use cases including two known languages and a set of documents which have the two languages mixed in (code switching, due to translation error). I'm training an ML model to make the output monolingual (leaned towards a designated language), so I need a reliable measure to estimate whether the ML model is making progress or not. Currently, I use lingua with the `compute_language_confidence_values()` function but the prediction is quite poor.\n For example, given a piece of text in Japanese and English:\n from lingua import Language, LanguageDetectorBuilder languages = [Language.ENGLISH, Language.JAPANESE] detector = LanguageDetectorBuilder.from_languages(*languages).build() detector.compute_language_confidence_values(\"わかりません hey do you understand me hey oh really\") >>> [ConfidenceValue(language=Language.ENGLISH, value=1.0), ConfidenceValue(language=Language.JAPANESE, value=0.0)] \n So it's not quite correct (should be 0.8-0.2 or something similar), does anyone have any advice ? Or are there better softwares out there ?\n    submitted by    /u/KarmaCut132  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1693a84/d_compute_percentage_of_languages_present_in_a/",
          "publishedOn": "2023-09-03T17:47:50.000Z",
          "wordCount": 2731,
          "title": "[D] Compute percentage of languages present in a document",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1692rgy/d_does_anyone_have_any_papers_on_getting_llms_to/",
          "author": null,
          "description": "Does anyone have any literature on how to constrain the output of an LLM to a specified format? I’ve self hacked a method to get LLAMA to output a json of perfect schema. I tried to find something out of the box but I couldn’t find anything, and so I home brewed it.\n Thinking of publishing a paper on this but I don’t want to republish something already written, so asking here first. Thanks!\n    submitted by    /u/SnooPears7079  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1692rgy/d_does_anyone_have_any_papers_on_getting_llms_to/",
          "publishedOn": "2023-09-03T17:26:49.000Z",
          "wordCount": 2660,
          "title": "[D] does anyone have any papers on getting LLMs to output perfect formats?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1692rgq/d_does_anyone_have_any_papers_on_getting_llms_to/",
          "author": null,
          "description": "Does anyone have any literature on how to constrain the output of an LLM to a specified format? I’ve self hacked a method to get LLAMA to output a json of perfect schema. I tried to find something out of the box but I couldn’t find anything, and so I home brewed it.\n Thinking of publishing a paper on this but I don’t want to republish something already written, so asking here first. Thanks!\n    submitted by    /u/SnooPears7079  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1692rgq/d_does_anyone_have_any_papers_on_getting_llms_to/",
          "publishedOn": "2023-09-03T17:26:48.000Z",
          "wordCount": 2660,
          "title": "[D] does anyone have any papers on getting LLMs to output perfect formats?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1692ehe/r_requesting_help_finding_labs_professors_on/",
          "author": null,
          "description": "submitted by    /u/Present-Ad-8531  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1692ehe/r_requesting_help_finding_labs_professors_on/",
          "publishedOn": "2023-09-03T17:12:03.000Z",
          "wordCount": 2685,
          "title": "[R] Requesting help finding labs/ professors on certain discipline.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/169246b/p_i_built_a_chrome_extension_that_adds_a_chatbot/",
          "author": null,
          "description": "submitted by    /u/jsonathan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/169246b/p_i_built_a_chrome_extension_that_adds_a_chatbot/",
          "publishedOn": "2023-09-03T17:00:43.000Z",
          "wordCount": 2585,
          "title": "[P] I built a Chrome extension that adds a chatbot to every GitHub repository",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1691q8a/discussion_how_to_setup_tpu_parallelismfsdp_with/",
          "author": null,
          "description": "My Code (Colab Link)\n Hi! For the past few days, I've been trying to fine-tune a model using TPU parallelism / FSDP with a Kaggle TPU notebook. The reason I need to set up FSDP is because the model I'm using is very large (Openlm's open llama 3b v2). When I try to fine-tune it, I quickly run out of memory on the TPU.\n Linked above is my code, if anyone has any useful information I would greatly appreciate it! Thank you!!\n Edit: Also providing my code through text here:\n !pip install sentencepiece !pip install -U accelerate !pip install -U transformers !pip install cloud-tpu-client !pip install torch-xla !pip install pyarrow import torch import torch_xla import torch_xla.core.xla_model as xm from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments import pand…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1691q8a/discussion_how_to_setup_tpu_parallelismfsdp_with/",
          "publishedOn": "2023-09-03T16:45:05.000Z",
          "wordCount": 3107,
          "title": "[Discussion] How to setup TPU parallelism/FSDP with HuggingFace Transformers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/168ydib/d_various_models_and_git_repo_examples_to_learn/",
          "author": null,
          "description": "Can someone list down one dataset for Algo Trading Simulation or free API endpoint , and i will go over following Algorithms:\n  \nBasic KNN (moving average)\n \nSVR\n \nother ML models if any\n \nLSTM\n \nother DL models if any\n \nany RNN model \n  \nbasically my mission is to write a paper at then end of months comparing all algorithms with candle stick patterns over different strategies\n ​\n    submitted by    /u/reactwebdev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/168ydib/d_various_models_and_git_repo_examples_to_learn/",
          "publishedOn": "2023-09-03T14:24:58.000Z",
          "wordCount": 2649,
          "title": "[D] Various models and git repo examples to learn Algo Trading",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/168xh2g/dr_how_often_do_masters_students_doing_a_thesis/",
          "author": null,
          "description": "Just curious to know the thoughts of other Masters/PhD students, professors or others in academia or industry research about their experience with regard to the title.\n    submitted by    /u/V1bicycle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/168xh2g/dr_how_often_do_masters_students_doing_a_thesis/",
          "publishedOn": "2023-09-03T13:46:52.000Z",
          "wordCount": 2621,
          "title": "[D][R] How often do Masters students doing a thesis publish in top ML conferences in their program period of 2 years ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/168wc1o/i_pretrained_16_language_models_from_scratch_with/",
          "author": null,
          "description": "I'm the author of TokenMonster, a free open-source tokenizer and vocabulary builder. I've posted on here a few times as the project has evolved, and each time I'm asked \"have you tested it on a language model?\".\n Well here it is. I spent $8,000 from my own pocket, and 2 months, pretraining from scratch, finetuning and evaluating 16 language models. 12 small sized models of 91 - 124M parameters, and 4 medium sized models of 354M parameters.\n Here is the link to the full analysis.\n Summary of Findings\n  \nComparable (50256-strict-nocapcode) TokenMonster vocabularies perform better than both GPT-2 Tokenizer and tiktoken p50k_base on all metrics.\n Optimal vocabulary size is 32,000.\n Simpler vocabularies converge faster but do not necessarily produce better results when converged.\n Higher compre…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/168wc1o/i_pretrained_16_language_models_from_scratch_with/",
          "publishedOn": "2023-09-03T12:56:45.000Z",
          "wordCount": 3058,
          "title": "I pretrained 16 language models from scratch with different tokenizers to benchmark the difference. Here are the results. [Research]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/168w1st/p_comgra_a_library_for_debugging_and/",
          "author": null,
          "description": "I'm a machine learning engineer and researcher. I got fed up with how difficult it is to understand why neural networks behave the way they do, so i wrote a library to help with it.\n Comgra (computation graph analysis) is a library you can use with pytorch to extract all the tensor data you care about and visualize it graphically in a browser.\n This allows for a much more detailed analysis of what is happening than the usual approach of using tensorboard. You can go investigate tensors as training proceeds, drill down into individual neurons, inspect single data sets that are of special interest to you, track gradients, compare statistics between different training runs, and more.\n This tool has saved me a ton of time in my research by letting me check my hypotheses much more quickly than normal and by helping me understand how the different parts of my network really interact.\n I hope this tool can save other people just as much time as it did me. I'm also open for suggestions on how to improve it further: Since I'm already gathering and visualizing a lot of network information, adding more automated analysis would not be much extra work.\n    submitted by    /u/Smart-Emu5581  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/168w1st/p_comgra_a_library_for_debugging_and/",
          "publishedOn": "2023-09-03T12:43:15.000Z",
          "wordCount": 2784,
          "title": "[P] Comgra: A library for debugging and understanding neural networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/168vi1c/d_reinforced_selftraining_rest_for_language/",
          "author": null,
          "description": "https://youtu.be/V4dO2pyYGgs\n ReST uses a bootsrap-like method to produce its own extended dataset and trains on ever higher-quality subsets of it to improve its own reward. The method allows for re-using the same generated data multiple times and thus has an efficiency advantage with respect to Online RL techniques like PPO.\n ​\n Paper: https://arxiv.org/abs/2308.08998\n ​\n Abstract:\n Reinforcement learning from human feedback (RLHF) can improve the quality of large language model's (LLM) outputs by aligning them with human preferences. We propose a simple algorithm for aligning LLMs with human preferences inspired by growing batch reinforcement learning (RL), which we call Reinforced Self-Training (ReST). Given an initial LLM policy, ReST produces a dataset by generating samples from the policy, which are then used to improve the LLM policy using offline RL algorithms. ReST is more efficient than typical online RLHF methods because the training dataset is produced offline, which allows data reuse. While ReST is a general approach applicable to all generative learning settings, we focus on its application to machine translation. Our results show that ReST can substantially improve translation quality, as measured by automated metrics and human evaluation on machine translation benchmarks in a compute and sample-efficient manner.\n ​\n Authors: Caglar Gulcehre, Tom Le Paine, Srivatsan Srinivasan, Ksenia Konyushkova, Lotte Weerts, Abhishek Sharma, Aditya Siddhant, Alex Ahern, Miaosen Wang, Chenjie Gu, Wolfgang Macherey, Arnaud Doucet, Orhan Firat, Nando de Freitas\n    submitted by    /u/ykilcher  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/168vi1c/d_reinforced_selftraining_rest_for_language/",
          "publishedOn": "2023-09-03T12:16:06.000Z",
          "wordCount": 2809,
          "title": "[D] Reinforced Self-Training (ReST) for Language Modeling (Video Paper Discussion)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/168sra6/maml_convergence_with_gan_d/",
          "author": null,
          "description": "I had been exploring convergence properties of MAML and there are some recent works establishing convergence under certain conditions. I am trying to understand how this would play out with GAN's, I know that in general training is generally unstable and there are a lot of issues such as memorization and mode collapse under this regime, but I am looking for a theoretical result, for instance we know that GAN's converge under ideal conditions and we also know that MAML converges, can we make any comments on the convergence properties of GAN's when trained using MAML, ideally a neat trick to know if they will converge based on what we already know? The proof for MAML convergence is fairly complicated and I expect that a proof that has additional second order gradient terms and feedback loops will probably involve a lot of work and I am wondering if anyone could provide some sort of insight or intuition as to what such a result would look like? Thanks\n    submitted by    /u/ashblue21  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/168sra6/maml_convergence_with_gan_d/",
          "publishedOn": "2023-09-03T09:43:33.000Z",
          "wordCount": 2745,
          "title": "MAML convergence with GAN [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/168sp9x/d_linear_regression_for_time_series_data/",
          "author": null,
          "description": "Problem: Given time series data of the last few years, one data point per day (eg price of a product or sales made this day). My job is to predict the next 7 days, ie. 7 scalars. \n Approach: Train one model for each time lag. The first model predicts tomorrow, the second model the day after tomorrow and so on (7 models in total). The features are the last prices of the last 7 days and some saisonal features (calendar week, price on this day last year and so on). \n Question: is there anything wrong with this approach? It doesn’t feel like the most elegant method to train 7 separate models. The problem with using a single model is, that this model must be able to predict 7 values of different points in time (and i don’t want to give the model input data of 7 days and let it predict all 7 scalars at once. The model should only use the features of a single day to predict this day). The 2 other to options I have considered are to train an autoregressive model (model just learns to predict the next day. To predict the day after tomorrow you give it its own prediction as input). Or to build a „time-lag“ feature, which tells the model how far in the future this datapoint lies. But this doesn’t make sense, because there is nothing like a weekly trend or so. \n What do you think? The autoregressive approach is elegant, but its implementation and maintenance is complex.\n    submitted by    /u/Individual-Cause-616  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/168sp9x/d_linear_regression_for_time_series_data/",
          "publishedOn": "2023-09-03T09:40:28.000Z",
          "wordCount": 2836,
          "title": "[D] Linear regression for time series data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/168rm8g/p_d_data_augmentation_using_stable_diffusion/",
          "author": null,
          "description": "I've written a post on how to use stable diffusion for data augmentation for object detection and segmentation. Please check it out and share some insights on how to evaluate these kind of tasks.\n https://medium.com/@kaushik.koneripalli/satellite-image-data-augmentation-using-stable-diffusion-for-object-detection-segmentation-8b1fe87b969\n    submitted by    /u/perceptron333  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/168rm8g/p_d_data_augmentation_using_stable_diffusion/",
          "publishedOn": "2023-09-03T08:34:47.000Z",
          "wordCount": 2615,
          "title": "[P] [D] Data augmentation using Stable diffusion",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/168ot5c/p_opensource_star_removal_tool_using_pix2pix/",
          "author": null,
          "description": "I created a open-source star removal tool \"star2k13\". Would love to hear some feedback . Here is link to the tool : Starrem2k13: Open source star removal tool (code2k13.github.io)\n Works on most operating systems and docker\n    submitted by    /u/Key_Education_2557  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/168ot5c/p_opensource_star_removal_tool_using_pix2pix/",
          "publishedOn": "2023-09-03T05:46:32.000Z",
          "wordCount": 2616,
          "title": "[P] Open-source star removal tool using Pix2Pix",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/168okzn/p_coding_llama_2_from_scratch_in_pytorch_with/",
          "author": null,
          "description": "submitted by    /u/hkproj_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/168okzn/p_coding_llama_2_from_scratch_in_pytorch_with/",
          "publishedOn": "2023-09-03T05:33:22.000Z",
          "wordCount": 2599,
          "title": "[P] Coding LLaMA 2 from scratch in PyTorch, with step by step explanation of KV Cache, Grouped Query Attention, Rotary Positional Embedding, RMS Normalization, SwiGLU and much more!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/168hp3z/d_where_did_the_research_go/",
          "author": null,
          "description": "This sub used to be my go-to place for finding out cool new ML research but sadly it has now become a \"generative AI\" \"AI productisation\" circlejerk.\n I was wondering where people now go to discover new ML research (besides ArXiv of course!)\n    submitted by    /u/blabboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/168hp3z/d_where_did_the_research_go/",
          "publishedOn": "2023-09-02T23:45:14.000Z",
          "wordCount": 2622,
          "title": "[D] Where did the research go?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/168h235/p_what_are_some_good_mle_project_ideas/",
          "author": null,
          "description": "What tech stack, what frameworks should I specially learn and use in my MLE project ? There are so much things mentioned in job offers, what would you suggest me to focus on ?\n I thought of fine-tuning LLM and deploying it using AWS. I'd prefer this project to be NLP oriented. I read about things like MLFlow, Apache Spar, Kubernetes etc. and don't know what to focus on.\n PS: I am currently a data scientist, and have recently finished a body pose estimation + action recognition web app, using Python/OpenCV/Mediapipe/Flask/Torch\n    submitted by    /u/tflbbl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/168h235/p_what_are_some_good_mle_project_ideas/",
          "publishedOn": "2023-09-02T23:17:23.000Z",
          "wordCount": 2673,
          "title": "[P] What are some good MLE project ideas ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/168gux7/pd_how_do_i_improve_car_detection_performance/",
          "author": null,
          "description": "For a college project I am trying to detect the number of cars in the first 3 rows of a parking lot. Here is my roboflow project page: https://universe.roboflow.com/boaztheostrich/cartest-tyaur\n As you can see I have been able to get my map score as high as .995 however I am still having difficulty consistently detecting cars in some edge cases.\n What I am currently testing is increasing the resolution from 1280x720 to 2048.\n I am new to all of this so any tips or tricks would be greatly appreciated.\n I am currently using google colab for training although I am considering switching over to vast.ai\n    submitted by    /u/johndowlelxdxdxdxdxd  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/168gux7/pd_how_do_i_improve_car_detection_performance/",
          "publishedOn": "2023-09-02T23:09:08.000Z",
          "wordCount": 2685,
          "title": "[P][D] How do I improve car detection performance?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/168gp33/need_collaborators_for_a_natural_language/",
          "author": null,
          "description": "We have it pretty functional but we're a small team so we need more people.\n https://github.com/apssouza22/chatflow\n Promo video: https://www.reddit.com/r/AGIunderconstruction/comments/168fsyr/come_build_open_source_natural_language/?utm_source=share&utm_medium=web2x&context=3\n    submitted by    /u/Cold-Explanation-984  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/168gp33/need_collaborators_for_a_natural_language/",
          "publishedOn": "2023-09-02T23:02:46.000Z",
          "wordCount": 2599,
          "title": "Need collaborators for a natural language interface [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/168dwjt/d_how_to_create_and_use_multiple_dataframes_in/",
          "author": null,
          "description": "Hey All,\n I have to read in multiple JSON files with each one containing objects in an array.\n For each file I want to create a data frame (A matrix might also work) where the rows and columns are just integers pointing to a string. Like this\n ​\n  \n - 0 1 2 \n  \n 0 dsad asd ad \n  1 asd asd grth \n  2 ter xc wer \n \n ​\n Using the same JSON file I also want to process the objects inside the arrays using the dataframe (matrix) above. So the process (pipeline) would be something like:\n  |==> Create Matrix =======>| JSON file =>| | ===> Use matrix to process object. |==> Individual objects ==>| \n ​\n I have been looking through the docs but still unsure how to do this.\n  \nShould I use a dataframe or a spark matrix?\n How do I split the objects into parts and also generate the matrix?\n How do I combine dataframes which isn't joining?\n  \nJust a point in the right direction would be great. Thanks in advance for this relatively simple question.\n    submitted by    /u/atticusfinch975  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/168dwjt/d_how_to_create_and_use_multiple_dataframes_in/",
          "publishedOn": "2023-09-02T21:08:05.000Z",
          "wordCount": 2754,
          "title": "[D] How to create and use multiple dataframes in pyspark?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/168d8cr/d_can_somone_help_me_get_this_paper/",
          "author": null,
          "description": "I don't have access can somone help me get it please Thank you https://www.worldscientific.com/doi/abs/10.1142/S0218001418560062\n    submitted by    /u/SilenceOfTheUnicorns  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/168d8cr/d_can_somone_help_me_get_this_paper/",
          "publishedOn": "2023-09-02T20:41:28.000Z",
          "wordCount": 2595,
          "title": "[D] can somone help me get this paper",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/168d0ov/dtips_algorithms/",
          "author": null,
          "description": "I have started learning ML a month ago... Did a foundational Google course and read from some other sources..hav learnt most of the theories....What's the best place to learn algorithms according to you? Any other tips are also welcome\n    submitted by    /u/Buri-Buri_zaemon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/168d0ov/dtips_algorithms/",
          "publishedOn": "2023-09-02T20:33:20.000Z",
          "wordCount": 2614,
          "title": "[D]Tips (Algorithms)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/168c339/d_rx_7900_xtx_vs_rtx_4080/",
          "author": null,
          "description": "I know AMD is working on making ROCM support for RDNA 3, would that rival nvidia? and would there be enough support for it to be usable? Nvidia cards are way more expensive and i would like to use it for gaming besides Machine learning for my study.\n Also, would this be overkill? will an RTX 4070 or an RX 7900 XT also do the job just fine?\n i am new to ML and won't be using it till early 2024,\n thank you all for reading.\n    submitted by    /u/RepresentativeIll155  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/168c339/d_rx_7900_xtx_vs_rtx_4080/",
          "publishedOn": "2023-09-02T19:56:46.000Z",
          "wordCount": 2666,
          "title": "[D] RX 7900 XTX vs RTX 4080",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/168bnju/d_how_to_describe_xgboost_boosting_and_bagging/",
          "author": null,
          "description": "Hi \n Can someone here please help me with this algorithm? \n What is the “Boosting” part of the algorithm?\n To my (limited) understanding XGBoost is an ensemble learning algorithm that uses many decision trees (efficiently), where each tree tries to correct the loss of the previous one. \n But I’m not sure how this is connected to “Boosting” and then it’s cousin “Bagging”\n Any intuition that may help me here?\n    submitted by    /u/Ok_Reality2341  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/168bnju/d_how_to_describe_xgboost_boosting_and_bagging/",
          "publishedOn": "2023-09-02T19:38:37.000Z",
          "wordCount": 2649,
          "title": "[D] How to describe XGBoost, Boosting and Bagging?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1689dxt/d_a_case_for_summaries_over_abstracts/",
          "author": null,
          "description": "I usually peruse the abstract of a paper before deciding on whether to read it or not. However, lately I've started longing for more personalized summaries.\n  \nI wonder what others think of abstract vs summaries and their preferences of the latter over former ?\n In your opinion, how far has the field progressed in summarization (https://paperswithcode.com/dataset/scitldr) ?\n  \n   submitted by    /u/JurrasicBarf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1689dxt/d_a_case_for_summaries_over_abstracts/",
          "publishedOn": "2023-09-02T18:08:10.000Z",
          "wordCount": 2637,
          "title": "[D] A case for summaries over abstracts",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1687luu/d_neurips_reviewers_edited_review_and_score_after/",
          "author": null,
          "description": "Hi, we have a paper submission to NeurIPS and we have two reviewers who changed their scores and review content silently by editing the original review comment and score after the discussion period. The edited review comment now discusses entirely different point.\n We would like to raise this concern to AC but the thing is that we didn’t save the original review comment, and the “revision history” for some reason doesn’t show the previous content, other than the entry that there was previous version. But this revision history overall isn’t inconsistent (showing the last two history after the discussion period, but the ones before the period is not shown) \n Can reviewers delete their own revision history in OpenReview tool? I don’t know if this is a bug or they deleted them with an intention.\n    submitted by    /u/mayasang  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1687luu/d_neurips_reviewers_edited_review_and_score_after/",
          "publishedOn": "2023-09-02T16:57:54.000Z",
          "wordCount": 2724,
          "title": "[D] NeurIPS reviewers edited review and score after discussion period: can they delete their own revision history?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1687bag/d_testing_at_8095_newly_collected_recent_data_55/",
          "author": null,
          "description": "I am currently do some predictions on some market data, I'm using both XGBoost and lightGBM (not both at the same time just experimenting using both algorithms). I have around 2500 features and 40k rows of data in my dataset which is being split 75% = train, 12.5% = valid, 12.5% = Test. The balance of the data is massively imbalanced with a binary classification. On training im seeing 0 = 20192 and 1 = 8337. I am not using SMOTE or undersampling but rather using the alogirhms own parameters to combat the Imbalance, for example scale_pos_weight: y_data[0]/y_data[1]. \n Training is going very well, im using hyperopt tuner to tune my paramets and usually on average get 75% accuracy on testing, training will usually be a little higher such as 77% and valid will be fairly close to test. But the …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1687bag/d_testing_at_8095_newly_collected_recent_data_55/",
          "publishedOn": "2023-09-02T16:46:07.000Z",
          "wordCount": 3066,
          "title": "[D] Testing at 80-95% - Newly collected recent data 55% - WHY!?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1685drw/p_build_a_recommender_system_that_includes_term/",
          "author": null,
          "description": "Hello everyone! I've noticed that most beginner-level tutorials on recommender systems primarily focus on model training, with limited information about deploying them in a production environment. Additionally, the different usage of models in the recall (retrieval) and ranking modules can indeed be confusing for beginners.\n Recently, I've been working on a recommender system project that encompasses both offline development and online deployment, covering both recall and ranking modules. The entire project is developed using Python and executed on a single laptop. All components are contained within Docker, ensuring no impact on the local environment. \n The GitHub repo: https://github.com/akiragy/recsys_pipeline\n You can follow the commands provided in the README to run it. \n This project primarily utilizes PyTorch, Redis, Elasticsearch, Feast Feature Store, Triton Inference Server, and Flask. \n PyTorch is used for training the FM model for recall and the DeepFM model for ranking. \n Redis serves as the store for user terms and vectors, while Elasticsearch is used to create an item term index and a vector index. Redis and Elasticsearch form the recall module. \n Feast is utilized to store user and item features, while Triton serves as a real-time prediction engine. Feast and Triton form the ranking module. \n Flask is deployed as the web server, receiving recommendation requests and returning responses. \n Thanks for checking it out!\n    submitted by    /u/Johann_SebastianBach  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1685drw/p_build_a_recommender_system_that_includes_term/",
          "publishedOn": "2023-09-02T15:28:26.000Z",
          "wordCount": 2804,
          "title": "[P] Build a Recommender System that Includes Term / Vector Recall, DeepFM Ranking, Inference Engine and Web Application.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1683weg/research_benchmarking_neural_network/",
          "author": null,
          "description": "Benchmark:\n 🧘 BLISS – a Benchmark for Language Induction from Small Sets\n https://github.com/taucompling/bliss/\n Paper:\n https://arxiv.org/abs/2308.08253\n    submitted by    /u/nurikolan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1683weg/research_benchmarking_neural_network/",
          "publishedOn": "2023-09-02T14:27:19.000Z",
          "wordCount": 2596,
          "title": "[Research] Benchmarking Neural Network Generalization for Grammar Induction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1682791/r_improving_model_results_with_edcr/",
          "author": null,
          "description": "We released another preprint on a neuro-symbolic approach called \"metacognitive error correction and detection rules\" (EDCR). The idea is that if you have a trained neural model, you can symbolically fine tune the results with rules. In this initial study, we apply it to the classification of GPS movement traces.\n Video: https://www.youtube.com/watch?v=d_OV4lap_rk\n Preprint: https://arxiv.org/abs/2308.14250\n Code: https://github.com/lab-v2/Error-Detection-and-Correction\n Further information: https://neurosymbolic.asu.edu/metacognition/ \n In the example below, we show the results for a single class. The rules detect errors by identifying classifications that may be incorrect and then re-assign to a new class. While recall can drop for a given class, we can bound the drop in recall with a hyperparameter - but this is guaranteed to improve precision. This is illustrated in the below figure. We show this approach leads to an overall improvement in accuracy over the base model, including the state-of-the-art. We also examine the effects when encountering classes not seen in the model's training data.\n We provide theoretical as well as empirical results and believe this approach can be used in other use-cases in the future.\n ​\n https://preview.redd.it/3z0cdp80dulb1.png?width=635&format=png&auto=webp&s=2eff6ce0f2c7b6983dbfbc030f0f7993010a30fb\n    submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1682791/r_improving_model_results_with_edcr/",
          "publishedOn": "2023-09-02T13:11:56.000Z",
          "wordCount": 2752,
          "title": "[R] Improving model results with EDCR",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1680vy3/d_10_hardearned_lessons_from_shipping_generative/",
          "author": null,
          "description": "Hey all,\n I'm the founder of a generative AI consultancy and we build gen AI powered products for other companies. We've been doing this for 18 months now and I thought I share our learnings - it might help others.\n ​\n  \nIt's a never ending battle to keep up with the latest tools and developments. \n \nBy the time you ship your product it's already using an outdated tech-stack. \n \nThere are no best-practices yet. You need to make a bet on tools/processes and hope that things won't change much by the time you ship (they will, see point 2). \n \nIf your generative AI product doesn't have a VC-backed competitor, there will be one soon. \n \nIn order to win you need one of the two things: either (1) the best distribution or (2) the generative AI component is hidden in your product so others don't/can't copy you. \n \nAI researchers / data scientists are suboptimal choice for AI engineering. They're expensive, won't be able to solve most of your problems and likely want to focus on more fundamental problems rather than building products. \n \nSoftware engineers make the best AI engineers. They are able to solve 80% of your problems right away and they are motivated because they can \"work in AI\". \n \nProduct designers need to get more technical, AI engineers need to get more product-oriented. The gap currently is too big and this leads to all sorts of problems during product development. \n \nDemo bias is real and it makes it 10x harder to deliver something that's in alignment with your client's expectation. Communicating this effectively is a real and underrated skill. \n \nThere's no such thing as off-the-shelf AI generated content yet. Current tools are not reliable enough, they hallucinate, make up stuff and produce inconsistent results (applies to text, voice, image and video).\n \n    submitted by    /u/BootstrapGuy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1680vy3/d_10_hardearned_lessons_from_shipping_generative/",
          "publishedOn": "2023-09-02T12:10:49.000Z",
          "wordCount": 2886,
          "title": "[D] 10 hard-earned lessons from shipping generative AI products over the past 18 months",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1680m3s/d_what_is_the_best_texttospeech_tool_preferably/",
          "author": null,
          "description": "Hi everyone, I need a TTS tool that sounds exactly like a human voice. I want to use it to edit some of my YouTube videos. I see a lot of TTS platforms around. Which do you recommend? I hope this isn't too much to ask. I would gladly appreciate it.\n Thanks in advance.\n    submitted by    /u/cessilh1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1680m3s/d_what_is_the_best_texttospeech_tool_preferably/",
          "publishedOn": "2023-09-02T11:57:56.000Z",
          "wordCount": 2637,
          "title": "[D] What is the best text-to-speech tool (preferably free) currently?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/167zqwh/r_realtime_road_segmentation_without_dense_depth/",
          "author": null,
          "description": "You can use the following code if you want to detect the road in real-time in your vehicle/robot : https://github.com/ErkanMilli/3MT-RoadSeg . One of the main problems in road segmentation by using depth was that if a region is flat, such as walls, it may be detected as road. This was already a known phenomenon and to overcome this, surface normal estimation was used. But, SNE requires dense depth images. Instead, we used a multi-task architecture, and used surface normals as an auxiliary loss, which reduced computation time significantly and also we don't need a dense depth image. Only LiDAR (which is sparse in nature) is sufficient.\n    submitted by    /u/ozgurerkent  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/167zqwh/r_realtime_road_segmentation_without_dense_depth/",
          "publishedOn": "2023-09-02T11:10:49.000Z",
          "wordCount": 2687,
          "title": "[R] Real-time Road Segmentation without Dense Depth Images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/167zoi7/p_threshold_of_acceptability_in_a_fillmask_task/",
          "author": null,
          "description": "Hi everyone,\n I am very new to machine learning and statistics, and am currently building an experiment that includes probing the knowledge of a bert-base-uncased model in a fill-mask test, without fine-tuning - just the regular pretrained model. I want to see the models knowledge of certain grammatical notions in English - whether its judgements are similar to those of humans or not :)\n My point is to give the model inputs like: \"what do you call a room filled with socks? you called it a [MASK] filled room\", or \"a monster who eats rats is called a [MASK] eater\", and check the probabilities it gives to the corresponding singular and plural token, e.g. in the first case I want to probe \"sock\" \\ \"socks\", and in the second case \"rat\" / \"rats\".\n I built a script which does exactly this - pulls…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/167zoi7/p_threshold_of_acceptability_in_a_fillmask_task/",
          "publishedOn": "2023-09-02T11:07:12.000Z",
          "wordCount": 2963,
          "title": "[P] Threshold of acceptability in a fill-mask task with BERT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/167zkc4/rp_one_class_is_hard_to_detect_in_vision_project/",
          "author": null,
          "description": "Hi, I’ve been working for a while now on a project to detect points in medical images which are to be classified into 3 different classes, but my UNet really struggles to predict one of the 3 classes (>70% score when excluding this class vs ~30% when not). I have tried putting a separate decoder just for this one class but the results are worse, and I don’t really have other ideas to better my results. Do you have any ideas/techniques to help me improve my results? Thanks !\n    submitted by    /u/maths_and_baguette  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/167zkc4/rp_one_class_is_hard_to_detect_in_vision_project/",
          "publishedOn": "2023-09-02T11:01:19.000Z",
          "wordCount": 2672,
          "title": "[R][P] One class is hard to detect in vision project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/167x2i6/d_stanfords_ml_for_graphs_course/",
          "author": null,
          "description": "Hi everyone.\n Has anybody taken this course from Stanford\n https://online.stanford.edu/courses/xcs224w-machine-learning-graphs\n or any other course in the same online portal? Was it worth it?\n I am considering to apply.\n Thanks\n    submitted by    /u/Realistic-Bed2658  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/167x2i6/d_stanfords_ml_for_graphs_course/",
          "publishedOn": "2023-09-02T08:32:42.000Z",
          "wordCount": 2607,
          "title": "[D] Stanford's ML for Graphs course",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/167vgy1/r_recurrent_forward_forward_accuracy_issues/",
          "author": null,
          "description": "Problem\n I recently did a bit of a career switch from big tech IoT Rust job, into a machine learning research role. For the last few months, I have been working on building out the Recurrent Forward Forward model from Hinton's Forward Forward paper (Fig3):\n https://arxiv.org/abs/2212.13345\n I have an implementation, but have been stuck for the past 4-6 weeks on trying to improve the accuracy. My implementation is only getting 95% test accuracy on MNIST.\n Hinton and Alex Ororbia (author of this) have been able to achieve high test accuracy (99%+) using this architecture, so I know it is possible.\n What I have tried\n I have tried many different things at this point:\n  \nDifferent activation functions.\n Weight initialization.\n Regularization techniques like transforms, jitter, and dynamic nega…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/167vgy1/r_recurrent_forward_forward_accuracy_issues/",
          "publishedOn": "2023-09-02T06:55:04.000Z",
          "wordCount": 3194,
          "title": "[R] Recurrent Forward Forward: Accuracy Issues",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/167nulj/dr_why_do_we_need_the_convolution_in_upsample_and/",
          "author": null,
          "description": "Hi fellow computer scientists and engineers,\n ​\n I've been wondering why do we often have a convolution inside every upsample and downsample block. Well, it makes sense, if you intend to upscale some features and use a bilinear interpolation, then some error can be introduced due to interpolation inaccuracies. This is where convolution layer comes handy to help and support the upscaling. But is this really the reason behind it? Or is there a deeper explanation?\n ​\n Also, just for the sake of curiosity. What if the scale_factor of an upsample block was 1. Should we still keep the convolution layer? or just get rid of all the upsample block since there is no actual \"upsampling\" being done at least in the context of the tensor dimensions.\n ​\n Thank you :)\n    submitted by    /u/Christs_Elite  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/167nulj/dr_why_do_we_need_the_convolution_in_upsample_and/",
          "publishedOn": "2023-09-02T00:24:14.000Z",
          "wordCount": 2713,
          "title": "[D][R] Why do we need the convolution in upsample and downsample blocks?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/167naw1/dr_best_way_to_upsample_features_in_a_neural/",
          "author": null,
          "description": "Hi fellow computer scientists,\n ​\n 1) I have been wondering if there is a preferred way to upsample features. I though about 3 options:\n ​\n 1.a) Upsample Layer + Conv Layer\n ​\n 1.b) Transposed Conv Layer + Conv Layer\n ​\n 1.c) PixelShuffle Layer + Conv Layer\n ​\n 2) Also, considering option 1.c, should the Conv layer multiply the number of PixelShuffle output features by the scale factor because PixelShuffle does reduce the number of output features? i.e. I have a tensor of dims (B, C, W, H, D) and with shape (1, 60, 64, 64, 64). After the Pixel-shuffle with an upscale factor of 4 I get the tensor of shape (1, 15, 256, 256, 256). Afterwards the following Conv layer should output a tensor like:\n 2.a) (1, 15, 256, 256, 256), where in_channels=15 and out_channels=15\n 2.b) (1, 60, 256, 256, 256), where in_channels=15 and out_channels=60\n Note the second option reinstates the number of input features.\n ​\n 3) I have an additional question that can happens in both 1.a, 1.b and 1.c options. Imagine I need to upsample my features by a factor of 8.\n 3.a) Is it preferred to have multiple upsample blocks (Upsample Layer + Conv layer), where the upsample layers have a scale factor of 2, thus for this example we would have 3 upsample blocks (2 ** 3 = 8).\n 3.b) Have only one upsample block where the Upsample layer has the full scale factor desired and it is then followed by one Conv layer.\n ​\n Thank you all :)\n    submitted by    /u/Christs_Elite  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/167naw1/dr_best_way_to_upsample_features_in_a_neural/",
          "publishedOn": "2023-09-01T23:59:31.000Z",
          "wordCount": 2830,
          "title": "[D][R] Best way to upsample features in a neural network",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/167n0g0/d_am_i_the_only_one_finding_this_a_bit_upsetting/",
          "author": null,
          "description": "Hello everyone,\n In the process of writing up a literature review for my master's thesis, I wanted to cover the impact of ReLU on the field which was significant. When looking for an original paper I came across this paper/report: https://arxiv.org/abs/1803.08375. There isn't anything special about this work and as a matter of fact, I was surprised that it has thousands of citations (2974 at the moment of writing this post according to Google Scholar). Given this and that this work is not an original ReLU paper but more of a file documenting an implementation of it for a particular setup I found it quite intriguing. Then I started to dig into works that cited this and unexpectedly papers from top conferences such as NeurIPS cited the aforementioned document as a reference to the activation function. Here are some examples:\n  \nhttps://proceedings.neurips.cc/paper_files/paper/2022/file/fbb10d319d44f8c3b4720873e4177c65-Paper-Conference.pdf\n https://proceedings.neurips.cc/paper_files/paper/2022/file/69e2f49ab0837b71b0e0cb7c555990f8-Paper-Conference.pdf\n  \nThe researchers who have done that are not referencing the original ReLU paper instead which I think is a bit disrespectful towards the achievement of original authors. On the other hand, maybe I am overthinking it a bit. ReLU has been around for a while and it would be surprising for someone conducting research in deep learning to not knowing it hence as a reader I wouldn't necessarily mind if people did not include the reference to the paper which is widely known. However, I reckon if a reference is made, then it should be meaningful and correct, and not just another extra few lines in a bibliography making it look big.\n    submitted by    /u/dj_giga_chinol  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/167n0g0/d_am_i_the_only_one_finding_this_a_bit_upsetting/",
          "publishedOn": "2023-09-01T23:46:50.000Z",
          "wordCount": 2838,
          "title": "[D] Am I the only one finding this a bit upsetting?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/167kc8x/d_best_local_llm_for_answering_to_custom_document/",
          "author": null,
          "description": "Hi guys, I'm developing a local tool able to reply question related to one or more document.\n I found a good solution in using sentence embedding followed by similarity search to include only the most significative part of the document in the prompt.\n In this contest I search for the lightest LLM able to reply to this question.\n For example, LLM based on Bert are generally smaller but are they good enough?\n I'm not an expert in this field, I hope I give you meaningful information. Thanks! 🙏\n    submitted by    /u/Tough-Assistant-9740  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/167kc8x/d_best_local_llm_for_answering_to_custom_document/",
          "publishedOn": "2023-09-01T21:55:19.000Z",
          "wordCount": 2670,
          "title": "[D] best local LLM for answering to custom document",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/167j6oe/dr_new_to_ml_research_how_often_are_you/",
          "author": null,
          "description": "I am new to research in ML, at present a grad student and began working in a lab on my own work.\n My advisor is very understanding, supportive and took a leap of faith to fund me, since I did not have prior experience in research.\n I have been working on a problem for 4 months now and have been getting poor results for the past week. All the literature surveys, digressions within the problem statements and running the experiments to end up with not-so-good results is extremely disheartening.\n ​\n I am still continuing to run additional experiments, figuring out where things can be going wrong and trying to conduct further analysis, but I feel like I have let down my advisor. I still have the entire semester to work on it and possibly other stuff, I am motivated for it, but at times ponder over the huge chunk of time I have spent on the current work.\n ​\n How do you deal with such results and hitting the wall in your research ?\n Does it happen often ? \n What would you advice I do to continue working ?\n    submitted by    /u/V1bicycle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/167j6oe/dr_new_to_ml_research_how_often_are_you/",
          "publishedOn": "2023-09-01T21:09:25.000Z",
          "wordCount": 2792,
          "title": "[D][R] New to ML Research, how often are you disheartened when something you have been working on for months does not work out ? and how do you deal with it ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/167hjdw/which_text_to_speech_is_this_d/",
          "author": null,
          "description": "https://youtube.com/shorts/mRZMOFqD0F0?si=jyHQVwq2ouAKP1t9\n    submitted by    /u/AdGeneral5378  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/167hjdw/which_text_to_speech_is_this_d/",
          "publishedOn": "2023-09-01T20:05:23.000Z",
          "wordCount": 2581,
          "title": "Which text to speech is this? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/167ek1o/d_suggestion_for_ai_tools_chat_style_that_run/",
          "author": null,
          "description": "Hi, I'm looking to run an on-prem ChatGPT style LLM solution that can ingest private customer data into a VectorDB.\n So far I have tried three...\n GPT4All - limited to only allows for up to 13b parameter LLMs and only on CPUs (currently), also its 'localdocs' implementation I've found to only reference its docs very infrequently when answering.\n H2OGPT - it's implementation of localdocs (I believe via LangChain) seems pretty good. but seems like every time I run an instance, I would have to re-vector my documents. Not sure if there is a way to attach an VectorDB to it so it's ready to go right away.\n PrivateGPT - seems to work very well, currently it's only running on CPUs thus response time is over a minute.\n Curious if the community knows of any other products that do this and are already GPU accelerated.\n ​\n TY in advance.\n ​\n ​\n    submitted by    /u/konrad21  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/167ek1o/d_suggestion_for_ai_tools_chat_style_that_run/",
          "publishedOn": "2023-09-01T18:10:56.000Z",
          "wordCount": 2732,
          "title": "[D] suggestion for AI tools (chat style) that run on-prem with vectorDB?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/167d2ho/d_how_to_improve_my_support_vector_machine_svm/",
          "author": null,
          "description": "Hi guys, \n Seeking some advice from some experienced researchers in support vector machines and kernel methods. \n I made this paper that breaks down using multi-class SVM in a One Against All approach, how to solve them with Lagrange multipliers \n https://github.com/jacobmcasey/MultiClass-SVM-Lagrange-Hyperplane-Construction-Paper\n As it currently stands it’s more a nice educational resource on the topic, rather than a novel contribution. \n Any ideas how to extend this work into something a bit more impactful? \n Thanks\n    submitted by    /u/Ok_Reality2341  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/167d2ho/d_how_to_improve_my_support_vector_machine_svm/",
          "publishedOn": "2023-09-01T17:15:21.000Z",
          "wordCount": 2655,
          "title": "[D] How to improve my Support Vector Machine (SVM) Paper?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/167cmys/p_efficient_way_to_implement_sparse_crossattention/",
          "author": null,
          "description": "I have key-value pairs with an extensive sequence length, alongside a sparse attention mask that is data-dependent, with fewer than 5% of its elements being non-zero.\n I found out that Xformer has implememation for sparse self-attention (link) but not sure whether the same would work for cross-attention. Also Xformer supports only (fixed) 2D attention mask but in my case the mask is arbitary and is different for different input. Can you suggest an efficient implementation for my scenario?\n    submitted by    /u/ankanbhunia  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/167cmys/p_efficient_way_to_implement_sparse_crossattention/",
          "publishedOn": "2023-09-01T16:59:16.000Z",
          "wordCount": 2658,
          "title": "[P] Efficient way to implement sparse cross-attention",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/167amdt/dwhy_are_special_tokens_not_allowed_in_the_prompt/",
          "author": null,
          "description": "I was going through the code for Llama-2 text generation on the official github where I stumbled across this code in the generation.py file:\n B_INST, E_INST = \"[INST]\", \"[/INST]\" SPECIAL_TAGS = [B_INST, E_INST, \"<<SYS>>\", \"<</SYS>>\"] UNSAFE_ERROR = \"Error: special tags are not allowed as part of the prompt.\" ... ... ... unsafe_requests = [] unsafe_requests.append(any([tag in msg[\"content\"] for tag in SPECIAL_TAGS for msg in dialog])) ... ... ... return [ { \"generation\": { \"role\": \"assistant\", \"content\": self.tokenizer.decode(t) if not unsafe else UNSAFE_ERROR, } } for t, unsafe in zip(generation_tokens, unsafe_requests) ] \n Is there a reason why we can't have these tokens in the prompt? \n I am planning to bypass the role based dictionary entries for the prompt and instead building my own prompt generator that'll take the the system prompts and the user prompts and generate a single string to then send to the LLM. Depending on the the user's choice I want the LLM to generate concise or detailed answers(also impose a word limit in the prompt itself), so I am planning to have this as a dropdown a user can choose. based on the system option chosen(concise/detailed answer), I then want to call my prompt generator which will add the instruction tags around the \"system\" and \"user\" prompts to generate 1 string I can then pass to the LLM.\n I wanted to know if there was any reason these tags aren't allowed to be in the prompt. Is it only to avoid \"confusion\" on the different roles and following a conventional way to pass the prompts? If not, and there's a reason those tags aren't supposed to be passed inside the prompts, please do let me know,, because inside the same file the chat_completion() function is doing exactly that; adding the <<SYS>> and <</SYS>> around the system prompts and prepending it to the user prompt.\n    submitted by    /u/comical_cow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/167amdt/dwhy_are_special_tokens_not_allowed_in_the_prompt/",
          "publishedOn": "2023-09-01T15:42:58.000Z",
          "wordCount": 2891,
          "title": "[D]Why are special tokens not allowed in the prompt for llama-2?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/167a3n3/p_machine_unlearning_a_novel_framework_to/",
          "author": null,
          "description": "Hey everyone,\n ​\n I am excited to present my latest venture, an initiative aimed at exploring the still-murky waters of Machine Unlearning. While this new project shares its roots with our previous endeavors in biomimetic machine learning, it diverges to concentrate on the fascinating and complex issue of algorithmic forgetfulness.\n ​\n 🎯 **Objective**\n ​\n The cornerstone of this project is not just to create algorithms that can forget, but to do so in a way that's both efficient and secure. Our vision transcends mere algorithmic performance, embracing a multi-faceted approach that also covers privacy protections and robust defenses against model inference attacks. The ambition here is to fortify machine unlearning with a well-rounded, secure architecture, allowing it to handle real-world …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/167a3n3/p_machine_unlearning_a_novel_framework_to/",
          "publishedOn": "2023-09-01T15:22:38.000Z",
          "wordCount": 3040,
          "title": "\"[P]\" Machine Unlearning: A Novel Framework to Unlearning, Privacy and Defending Against Inference Attacks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1678lwq/p_modular_diffusion_a_python_library_for/",
          "author": null,
          "description": "Hello everyone! I've been working on this project for a few months as part of my thesis in Machine Learning. It's a library that provides an easy-to-use yet flexible API to design and train Diffusion Models. I decided to make it because I wanted to quickly prototype a Diffusion Model but there were no good tools to do it with. I think it really can help people prototype their own Diffusion Models a lot faster and only in a few lines of code.\n The idea is to have a model class that takes different modules corresponding to the different aspects of the Diffusion Model process (noise schedule, noise type, denoising network, loss function, guidance, etc.) and allow the user to mix and match different modules to achieve different results. The library ships with a bunch of prebuilt modules and the plan is to add many more. I also made it super easy to implement your own modules, you just need to extend from one of the base classes available.\n Below is an example of the type of interface you can expect. I'd really appreciate your feedback! Check out the project here: https://github.com/cabralpinto/modular-diffusion\n https://preview.redd.it/0itvswxkknlb1.png?width=2528&format=png&auto=webp&s=24ce67955eadb5cf109d19716f4e5a9471b1572d\n    submitted by    /u/secularchapel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1678lwq/p_modular_diffusion_a_python_library_for/",
          "publishedOn": "2023-09-01T14:25:40.000Z",
          "wordCount": 2779,
          "title": "[P] Modular Diffusion: A Python Library for Designing and Training Diffusion Models with PyTorch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1678308/d_what_does_the_actual_number_of_englishlanguage/",
          "author": null,
          "description": "D3PM paper https://arxiv.org/pdf/2107.03006.pdf reports perplexity on LM1B dataset. In Appendix B.2 thay authors say:\n  \nPerplexities are reported relative to the actual number of English-language words in the\n test set (including an EOS token predicted by the model) \n  \nHow did they compute this number? Did they split sentences by space? Are punctuation symbols considered \"English words\"? Are chinese characters (which are present in the data) withous spaces counted as one word?\n Or is it some common knowledge that \"LM1B test set contains X words\"?\n The official implementation https://github.com/google-research/google-research/tree/master/d3pm/text is extremely difficult to comprehend. I spent several hours reading throug the code and I still have no idea how they computed the number of words.\n    submitted by    /u/Tomarchelone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1678308/d_what_does_the_actual_number_of_englishlanguage/",
          "publishedOn": "2023-09-01T14:05:21.000Z",
          "wordCount": 2695,
          "title": "[D] What does \"the actual number of English-language words\" mean?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1676cuh/p_significant_improvements_for_multiagent/",
          "author": null,
          "description": "We've just released a new version of our evolutionary hyperparameter optimization RL framework, which is 10x faster than SOTA!\n This update is focused on multi-agent RL. We've introduced MADDPG and MATD3 to the framework. These algorithms are traditionally super brittle, and RLlib even recommends not to use their own implementation of it. \n However, our evolutionary framework has solved this problem! \n You can now train multiple agents in co-operative or competitive Petting Zoo-style (parallel API) environments, with significantly faster training and up to 4x improvement in total return when benchmarked against alternatives.\n Please check it out! https://github.com/AgileRL/AgileRL \n    submitted by    /u/nicku_a  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1676cuh/p_significant_improvements_for_multiagent/",
          "publishedOn": "2023-09-01T12:54:32.000Z",
          "wordCount": 2676,
          "title": "[P] Significant improvements for multi-agent reinforcement learning!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16753b4/p_interactively_explore_unstructured_datasets/",
          "author": null,
          "description": "Hey r/MachineLearning,\n data inspection and interactive exploration is one of the most important tasks for data teams. This is especially true when dealing with unstructured data that requires a deep domain expertise (e.g. healthcare or engineering).\n We have tried many different options for visualizing unstructured datasets in the past: Notebooks, dash apps, custom react apps, HTML reports... However, these options were either very time-consuming to develop/maintain or not interactive enough or both. \n That is why we developed Spotlight: https://github.com/Renumics/spotlight \n https://i.redd.it/lxjnlkcmumlb1.gif\n Spotlight supports most unstructured data types including images, audio, text, videos, time-series and geometric data. \n You can find more info and use case examples for ML and engineering workflows in the repo. \n Happy to hear your honest feedback!\n ​\n ​\n    submitted by    /u/44sps  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16753b4/p_interactively_explore_unstructured_datasets/",
          "publishedOn": "2023-09-01T11:56:53.000Z",
          "wordCount": 2700,
          "title": "[P] Interactively explore unstructured datasets from your dataframe (OSS project)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1673aho/d_how_many_target_variable_classes_does_sentiment/",
          "author": null,
          "description": "Hi everyone, so I am a little confused on how many target variable classes does the BERT and RoBERTa models have?\n So I understand these 2 models are pre-trained models, which means the number of target variable classes are fixed (if I am not wrong!). For example, the link below for the RoBERTa model in Hugging Face has fixed 3 target variable classes (Negative, Neutral and Positive):\n https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest\n But when I googled around and also asked ChatGPT and Bard, they tell me these models can have as many target variable classes as the user wants (or rather this depends on how many target variable classes there are in the training dataset). \n If these are pre-trained models already (which already have the number of target variable classes pre-determined in the model already), then how come some of the google sites and ChatGPT and Bard is telling me the user can choose however many target variable classes that they want?\n ​\n    submitted by    /u/--leockl--  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1673aho/d_how_many_target_variable_classes_does_sentiment/",
          "publishedOn": "2023-09-01T10:23:02.000Z",
          "wordCount": 2745,
          "title": "[D] How many target variable classes does sentiment analysis models BERT and RoBERTa have?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1671gmk/p_vehicles_moving_in_wrong_direction/",
          "author": null,
          "description": "I am working on a professional project which involves detecting a vehicle moving in a wrong direction on the street.\n Data details : I have consecutive frames of the street in which vehicles are moving.\n So far :\n  \nI have created a model that detects the objects inside the frame and give me the coordinates(bounding-box) of those objects(vehicles).\n \nAnd I using the optical flow to produce the optical lines on the objects which are moving inside the consecutive frames and I am also able to get the direction(if a object is moving from top to bottom on the frame it means it is in right direction and if bottom to top in the frame it means wrong direction based on change in y-offset of the object).\n \nNow the optical lines code is different which is giving me the direction of the object(I am not using any model to detect object in this code it's based on Lucas-Kadane method) and when I say direction I mean I'm using the cv2.imshow() which actually plays the consecutive frames together and draw optical lines on it and shows me the direction visually.\n \n Now the problem is I want the coordinates of the object that is moving in wrong direction (the bounding box coordinates) how can I achieve that?\n Any suggestions and ideas would be helpful please mind I can't use any other technology or model as this are project requirements in professional setting)\n    submitted by    /u/Sherlock_holmes0007  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1671gmk/p_vehicles_moving_in_wrong_direction/",
          "publishedOn": "2023-09-01T08:35:51.000Z",
          "wordCount": 2818,
          "title": "[P] Vehicles moving in wrong direction.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16711id/d_how_to_decide_number_of_trees_in_hyperparameter/",
          "author": null,
          "description": "The dataset I have consists of around 2,300 observations and 120 variables, of which around 25 are highly correlated, so I narrowed it down to 95 variables.\n I'm using R's boost_tree() with xgboost as my model.\n How do I decide when to stop tuning for number of trees, mtry, min_n, and tree depth, without actually overfitting the data? Because as I increase the number of trees (or any other variable like the ones above), my RMSE obviously goes down, but how do I know it is overfitting the training data? Or is there no overfitting in this case, since I am using cross validation (15 fold) already?\n PS, the test data is 800 observations\n    submitted by    /u/heeeehuuuu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16711id/d_how_to_decide_number_of_trees_in_hyperparameter/",
          "publishedOn": "2023-09-01T08:09:56.000Z",
          "wordCount": 2697,
          "title": "[D] How to decide number of trees in hyperparameter tuning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166yjar/d_feature_extraction_in_multivariate_time_series/",
          "author": null,
          "description": "How do you usually do feature extraction for time series data? I used to work on visual domain, so I'm pretty familiar with CVs but recently I was assigned some tasks on multivariate time series data and it's been quite difficult getting used to.\n Major problem is, while features in vision have semantic meaning not just along temporal axis but also \"spatially,\" the multivariate time series does not.\n Also, is it considered a \"cheating\" if i pre-extract certain features that are already established by experts to have high correlation with the result, rather than letting the machine learning algorithm learn on its own those \"certain features\" in some way through training?\n Thanks!\n    submitted by    /u/-273deg  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166yjar/d_feature_extraction_in_multivariate_time_series/",
          "publishedOn": "2023-09-01T05:41:28.000Z",
          "wordCount": 2692,
          "title": "[D] Feature extraction in multivariate time series",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166wx6h/d_mlops_resources/",
          "author": null,
          "description": "Hi, I wonder which books or courses you would recommend for intermediate and advanced MLOps/ML design systems. What I mean is topics like handling hundreds of models and their updates, reusable CI/CD pipelines, batch and online architectures, integration with feature stores, jobs/queues for model scheduling, data drift, metrics monitoring, and alerts, and so on.\n This would be for someone familiar with the major concepts, hands-on experience with MLflow, SageMaker, Azure ML services, Databricks and similar tools.\n    submitted by    /u/rodrigo-arenas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166wx6h/d_mlops_resources/",
          "publishedOn": "2023-09-01T04:13:59.000Z",
          "wordCount": 2652,
          "title": "[D] MLOps resources",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166wvha/d_rlhf_for_multiturn_conversation_option_a_or_b/",
          "author": null,
          "description": "I have a dataset that consists of dialogues between a user and a chatbot (ChatGPT), and I want to use this data to implement Reinforcement Learning from Human Feedback (RLHF). I have already completed Supervised Fine-Tuning (SFT) and built the reward model. Now, I need some guidance on how to handle the data.\n Here is an example of the pre-collected data:\n >> User: Give me a tip on how to succeed in drawing.\n >>> ChatGPT: Practice regularly and be patient with yourself. Improvement takes time.\n >>>User: But drawing is hard.\n >>>ChatGPT: It is, and that's okay. It's normal to find it challenging, especially when you're just starting out. Just try to enjoy the process and don't be too hard on yourself.\n ​\n ==========My input Data 1 is :>> User: Give me a tip on how to succeed in drawing.\n Suppose my model outputs the following for Input Data 1: ChatGPT: Practice makes perfect.\n My question is, for Input Data 2, should I use:\n Option A: User: Give me a tip on how to succeed in drawing. ChatGPT: Practice makes perfect. User: But drawing is hard.\n In this option, I use the actual previous term's agent output and append the pre-collected user data.\n Or\n Option B: User: Give me a tip on how to succeed in drawing. ChatGPT: Practice regularly and be patient with yourself. Improvement takes time. User: But drawing is hard.\n In this option, I use all the pre-collected data, which might not even be the current model's output.\n Which option is more appropriate for RLHF, A or B?\n    submitted by    /u/No_Oilve_6577  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166wvha/d_rlhf_for_multiturn_conversation_option_a_or_b/",
          "publishedOn": "2023-09-01T04:11:42.000Z",
          "wordCount": 2841,
          "title": "[D] RLHF for multi-turn conversation, Option A or B?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166tq43/d_why_did_the_authors_design_this_gradient/",
          "author": null,
          "description": "I am reading the famous paper \" Unsupervised Domain Adaptation by Backpropagation\" again, but still got confused why the authors had to design this gradient reversal layer.\n To my understanding, simply adding a minus-one (-1) in front of the domain classifier head is good enough. Of course, we need to minimize the original domain classifier head at some point to make it decent. For example, if it is a two-step training like GAN, we can (1) Freeze other parts but only minimize the domain classification loss to update the domain classifier head; and then (2) Freeze the domain classification head, but maximize the domain classificatoin loss to update the feature extractor. We can alternate between (1) and (2).\n Is the main motivation of gradient reversal layer that we can merge (1) and (2) into a single training step?\n    submitted by    /u/AaronSpalding  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166tq43/d_why_did_the_authors_design_this_gradient/",
          "publishedOn": "2023-09-01T01:38:37.000Z",
          "wordCount": 2729,
          "title": "[D] Why did the authors design this gradient reversal layer in the paper \"Unsupervised Domain Adaptation by Backpropagation\"?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166sgts/d_dataset_condensation/",
          "author": null,
          "description": "Hello everyone, has anyone here read the paper \"Dataset Condensation with Gradient Matching\"? I've been reading it, but I got stuck trying to understand how they transition from the point where the loss is the distance between parameters to the point where the loss is the distance between gradients. Could someone please explain this process in detail? Apparently, they make the assumption that the initializations are the same and that the distance between parameters is close to zero for every iteration, but I'm still struggling to comprehend how they arrive at the conclusion that the distance is now between gradients. \n    submitted by    /u/Ok-Cartographer-1363  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166sgts/d_dataset_condensation/",
          "publishedOn": "2023-09-01T00:42:08.000Z",
          "wordCount": 2676,
          "title": "[D] Dataset condensation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166sfxa/p_a_scientific_exploration_into_the_integration/",
          "author": null,
          "description": "Hey everyone,\n I am excited to introduce a project that delves into the experimental fusion of Biomimicry principles with Machine Learning algorithms. While the concept of unlearning serves as our initial prototype, the overarching ambition extends far beyond, aiming to pioneer new methodologies inspired by natural phenomena.\n  \n🎯 Objective\n The core objective of this research is to investigate the feasibility and efficacy of incorporating biomimetic principles into machine learning algorithms. The goal is not merely to improve algorithmic performance but also to introduce novel methods that can tackle complex computational problems, much like how nature solves intricate issues in an energy-efficient manner.\n ---\n 📑 Methodological Outline\n  \n**Conceptual Framework**: The project adopts a…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166sfxa/p_a_scientific_exploration_into_the_integration/",
          "publishedOn": "2023-09-01T00:41:04.000Z",
          "wordCount": 2965,
          "title": "\"[P]\" A Scientific Exploration into the Integration of Biomimicry Principles within Machine Learning Algorithms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166rb58/thoughts_on_ztm_d/",
          "author": null,
          "description": "Thoughts on the Zero to Mastery programs? There is a machine learning bootcamp course on Udemy that is part of that program. I feel like i've heard negative reviews about them in the past, but it's only 12.99 right now and I feel like it covers a lot of content. So I guess I'm just wondering if it's really that bad, or if the course would be worth my time? Would it really take me from \"Zero to Mastery\"? Thanks\n    submitted by    /u/Mountain-Economy1476  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166rb58/thoughts_on_ztm_d/",
          "publishedOn": "2023-08-31T23:54:21.000Z",
          "wordCount": 2657,
          "title": "Thoughts on ZTM? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166qt3j/math_for_ml_course_on_udemy_d/",
          "author": null,
          "description": "Are there any good math for machine learning courses on Udemy? I specifically want a course that offers lots of exercises so I am able to practice what I learn. Thanks\n    submitted by    /u/Mountain-Economy1476  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166qt3j/math_for_ml_course_on_udemy_d/",
          "publishedOn": "2023-08-31T23:33:54.000Z",
          "wordCount": 2611,
          "title": "Math for ML Course on Udemy [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166nf1b/d_a_scientific_exploration_into_the_integration/",
          "author": null,
          "description": "Hey everyone,\n I am excited to introduce a project that delves into the experimental fusion of Biomimicry principles with Machine Learning algorithms. While the concept of unlearning serves as our initial prototype, the overarching ambition extends far beyond, aiming to pioneer new methodologies inspired by natural phenomena.\n ---\n 🎯 **Objective**\n The core objective of this research is to investigate the feasibility and efficacy of incorporating biomimetic principles into machine learning algorithms. The goal is not merely to improve algorithmic performance but also to introduce novel methods that can tackle complex computational problems, much like how nature solves intricate issues in an energy-efficient manner.\n ---\n 📑 **Methodological Outline**\n  \n**Conceptual Framework**: The proje…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166nf1b/d_a_scientific_exploration_into_the_integration/",
          "publishedOn": "2023-08-31T21:19:06.000Z",
          "wordCount": 2971,
          "title": "\"[D]\" A Scientific Exploration into the Integration of Biomimicry Principles within Machine Learning Algorithms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166mvm5/p_we_embedded_all_sec_and_press_releases_data_for/",
          "author": null,
          "description": "Retrieval augmented generation (RAG) is one of the most popular way to add additional knowledge to your LLMs. To do RAG well, you need to do three things well -\n  \nCurate high quality datasets\n Create abstractions (embeddings, keyword indexes, knowledge graphs)\n Stitch everything together for better retrieval \n  \nWe have realized that it is even harder than what it looks like. We want to easily enable this infra for a range of datasets, starting with company-specific data. \n You can give it a go here on our playground or get started with our open sourced library\n    submitted by    /u/achyutjoshi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166mvm5/p_we_embedded_all_sec_and_press_releases_data_for/",
          "publishedOn": "2023-08-31T20:59:40.000Z",
          "wordCount": 2684,
          "title": "[P] We embedded all SEC and Press Releases data for US companies, it is available for retrieval",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166l5dr/d_anyone_submitted_to_cpal/",
          "author": null,
          "description": "There was a paper submission deadline for Conference on Parsimony and Learning (CPAL) earlier this week. This is their first conference so I expect the number of submissions to be very small, but has anyone submitted? I am guessing they received like 100 or 200ish submissions.\n    submitted by    /u/neurogramer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166l5dr/d_anyone_submitted_to_cpal/",
          "publishedOn": "2023-08-31T19:54:13.000Z",
          "wordCount": 2624,
          "title": "[D] Anyone submitted to CPAL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166kr3c/d_best_frameworks_and_tools_to_design_ml_based/",
          "author": null,
          "description": "As the title says, I'm looking for a list of the best tools and framework to learn, useful for build machine learning solution as web application.\n I want to move my projects from being jupyter notebooks using tensorflow or pytorch, to ml API and applications.\n    submitted by    /u/AcquaFisc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166kr3c/d_best_frameworks_and_tools_to_design_ml_based/",
          "publishedOn": "2023-08-31T19:39:08.000Z",
          "wordCount": 2629,
          "title": "[D] Best frameworks and tools to design ml based web applications",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166kc89/d_how_do_you_track_what_you_learnt_from_the_papers/",
          "author": null,
          "description": "It has always been a struggle for me. I tried to take notes as I read paper, but that’s not quite sustainable because it’s difficult to track where did the notes come from for more details. Or I highlight the sections with added comments but that’s also not quite accessible when you have tones of pdf lying around somewhere or worse print outs. \n Recently I’ve been trying a cloud based pdf reader that stores my papers and allow searches over all highlights and comments (Pond) Thinking if I could also use it to share papers with my colleagues but I’m not sure if it will work because that will require them to use it as well. \n How do you solve this ?\n    submitted by    /u/dockerun  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166kc89/d_how_do_you_track_what_you_learnt_from_the_papers/",
          "publishedOn": "2023-08-31T19:23:18.000Z",
          "wordCount": 2706,
          "title": "[D] How do you track what you learnt from the papers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166jz6e/d_need_dataset_for_my_research_project/",
          "author": null,
          "description": "I am working on a project for my research but need a dataset which contains the generation and consumption of electricity for Micro Hydro Power station, anyone could help me. I will be grateful\n    submitted by    /u/Due-Draft6855  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166jz6e/d_need_dataset_for_my_research_project/",
          "publishedOn": "2023-08-31T19:09:20.000Z",
          "wordCount": 2614,
          "title": "[D] need dataset for my research project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166j6sb/n_supporting_the_open_source_ai_community/",
          "author": null,
          "description": "https://a16z.com/2023/08/30/supporting-the-open-source-ai-community/\n From the text:\n  \nWe believe artificial intelligence has the power to save the world—and that a thriving open source ecosystem is essential to building this future. \n Thankfully, the open source ecosystem is starting to develop, and we are now seeing open source models that rival closed-source alternatives. Hundreds of small teams and individuals are also working to make these models more useful, accessible, and performant. \n These projects push the state of the art in open source AI and help provide a more robust and comprehensive understanding of the technology. They include: instruction-tuning base LLMs; removing censorship from LLM outputs; optimizing models for low-powered machines; building novel tooling for model inference; researching LLM security issues; and many others. \n However, the people behind these projects often don’t have the resources available to pursue their work to conclusion or maintain it in the long run. The situation is more acute in AI than traditional infrastructure, since even fine-tuning models requires significant GPU computing resources, especially as open source models get larger.\n  \n​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166j6sb/n_supporting_the_open_source_ai_community/",
          "publishedOn": "2023-08-31T18:39:35.000Z",
          "wordCount": 2749,
          "title": "[N] Supporting the Open Source AI Community",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166hnku/r_lminfinite_simple_onthefly_length/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2308.16137\n Abstract:\n  \nIn recent years, there have been remarkable advancements in the performance of Transformer-based Large Language Models (LLMs) across various domains. As these LLMs are deployed for increasingly complex tasks, they often face the needs to conduct longer reasoning processes or understanding larger contexts. In these situations, the length generalization failure of LLMs on long sequences become more prominent. Most pre-training schemes truncate training sequences to a fixed length (such as 2048 for LLaMa). LLMs often struggle to generate fluent texts, let alone carry out downstream tasks, after longer contexts, even with relative positional encoding which is designed to cope with this problem. Common solutions such as finetuning on longer …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166hnku/r_lminfinite_simple_onthefly_length/",
          "publishedOn": "2023-08-31T17:41:46.000Z",
          "wordCount": 2839,
          "title": "[R] LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models - University of Illinois 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166hehj/r_cotracker_a_revolutionary_2d_point_video_tracker/",
          "author": null,
          "description": "CoTracker - a 2D point-tracking tool for videos - promises to revolutionize motion tracking. Through the use of a transformer network, it meticulously predicts point trajectories and visibility across video frames, giving insights like never before.\n https://i.redd.it/g0u5t9n1ehlb1.gif\n Here's why CoTracker is turning heads:\n  \nCoTracker leverages advanced transformer formulation: Utilising a grid of input tokens that evolve to output tokens, CoTracker allocates initial values derived from the track's start point and time.\n It's built to handle extended videos through 'windowed inference': Windowing enables the algorithm to handle videos beyond its maximum window length by splitting them into overlapping segments.\n 'Unrolled Learning' caters to semi-overlapping windows effectively: By employing two unique types of losses, only a modest amount of windows are used in loss computation while still handling expansive videos at test time.\n Improved tracking through simultaneous multi-point selection: By tracking multiple points at once, CoTracker is able to better establish correlation and motion paths within videos.\n  \nDespite its notable strengths, there are limitations. Its sliding-window approach cannot handle long-term occlusions that last longer than a window, and its transformer-based model has a high computational cost that grows quadratically with the number of tracked points.\n According to the authors, “The result is a flexible and powerful tracking algorithm that outperforms state-of-the-art methods in almost all benchmarks”. But it’s yet to be seen how it will perform in real-life tasks. What do you think?\n P.S. If you like this type of analysis, you might want to check this out.\n (arXiv) (GitHub)\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166hehj/r_cotracker_a_revolutionary_2d_point_video_tracker/",
          "publishedOn": "2023-08-31T17:31:54.000Z",
          "wordCount": 2828,
          "title": "[R] CoTracker: A Revolutionary 2D Point Video Tracker",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166hbjo/project_combining_prompt_engineering_with/",
          "author": null,
          "description": "All of this is framed through the lens of improving your ability to understand if a prediction for an upcoming UFC match is good or not. Happy to dig further into the ML and processing around this.\n https://blog.wolftickets.ai/teaching-a-wolf-to-speak-transforming-fight-predictions-into-insights.html\n Any feedback is appreciated!\n    submitted by    /u/wolfticketsai  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166hbjo/project_combining_prompt_engineering_with/",
          "publishedOn": "2023-08-31T17:28:48.000Z",
          "wordCount": 2632,
          "title": "[Project] Combining Prompt Engineering with Structured Inputs to LLMs to Generate Insights on Predictions from Binary Classifiers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166hazp/p_autolabel_data_labeling_with_llms/",
          "author": null,
          "description": "Hi everyone,\n Wanted to share an open source project we've been working on for the last few weeks: Autolabel is an open source Python library to label and enrich text datasets with LLMs (Large Language Models).\n Why?\n Access to clean, labeled data is a huge bottleneck for most ML/data science teams. From experiments across a variety of NLP tasks and datasets, we have found that the most capable LLMs are able to label data at better quality than human annotators, but 20-100x faster.\n Getting Started¶\n You can get started with the library by defining a JSON config, and writing a few lines of code:\n from autolabel import LabelingAgent, AutolabelDataset agent = LabelingAgent('config.json') dataset = AutolabelDataset('dataset.csv', 'config.json') labels = agent.run(dataset) \n  \nInstallation guide\n Sample notebooks that show how to use the library for different labeling tasks.\n Technical report for benchmarking LLM and human annotator performance across a range of tasks and datasets.\n  \nCall for Feedback\n We just open sourced this library, and are actively developing it. Feedback is very welcome and so are requests for features. You can open an issue on Github for bugs and request features\n    submitted by    /u/nihit-d  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166hazp/p_autolabel_data_labeling_with_llms/",
          "publishedOn": "2023-08-31T17:28:12.000Z",
          "wordCount": 2765,
          "title": "[P] Autolabel: data labeling with LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166g8a1/d_notation_problem_of_equation_1_from_the_paper/",
          "author": null,
          "description": "In Equation 1 of the paper \"Axiomatic Attribution for Deep Networks\", the denominator of the gradient is $\\partial x_i$ (See Eq1).\n However, according to the paper(with Eq2), shouldn't it be $\\partial (x'_i + \\alpha \\times (x_i-x'_i))$ rather than $\\partial x_i$?\n I found many following papers which refer to this paper also use the notation like this.\n Do I misunderstand something?\n    submitted by    /u/qjall  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166g8a1/d_notation_problem_of_equation_1_from_the_paper/",
          "publishedOn": "2023-08-31T16:45:39.000Z",
          "wordCount": 2647,
          "title": "[D] Notation problem of equation 1 from the paper Axiomatic attribution for deep networks?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166frrn/discussion_leveraging_leaky_softplus_activation/",
          "author": null,
          "description": "In the realm of deep learning, the choice of activation functions and optimization algorithms can significantly impact the training process and the performance of neural networks. A relatively lesser-known gem in this landscape is the \"leaky softplus\" activation function, which, when paired with momentum-based optimizers like Adam, can lead to exceptionally efficient and effective training outcomes.\n The Leaky Softplus Activation Function\n The leaky softplus activation function combines the benefits of both linearity and non-linearity in a graceful manner. Defined as Math.Log(Math.Exp(x) + 1) + (x / 16), it smoothly transitions between a nearly linear response for negative inputs and a more pronounced non-linear response for positive inputs. This unique characteristic enables it to address…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166frrn/discussion_leveraging_leaky_softplus_activation/",
          "publishedOn": "2023-08-31T16:27:11.000Z",
          "wordCount": 3112,
          "title": "[Discussion] Leveraging Leaky Softplus Activation with Momentum-Based Optimizers like Adam for Efficient Neural Network Training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166ehh0/p_deepeval_neural_framework_for_testing_llms/",
          "author": null,
          "description": "Hi everyone,\n I built DeepEval - an open-source unit testing framework for LLMs in order to accelerate development and iteration. \n The problem\n When designing software applications, testing has always been critical for a lot of production applications. However - with the rise of LLM applications, the type of testing required needs to change in order to adapt for the large number of possible queries. We therefore built DeepEval in order to make it easy to write LLM tests in just 1 line of code. We hope this solution is of value to future teams when iterating on their RAG pipelines, migrating LLM models, testing their fine-tuned LLMs.\n The solution\n The DeepEval framework is as follows: We split up testing LLMs into 4 main sections:\n - Answer Relevancy (how relevant an answer is to a question) - measured using a question-answer bi-encoder.\n - Factual consistency (whether the generated answer is hallucinating) - measured using entailment from an NLI model\n - Conceptual similarity (when given a ground truth, how closely does it relate to it - for example How big is it? The size of an orange vs 20 square centimetres.) - measured using vector similarity\n - Bias, Toxic classification (measured through DL classifier models)\n I would love any feedback on what we are building here and welcome any OS contributions! \n    submitted by    /u/ConfectionSafe954  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166ehh0/p_deepeval_neural_framework_for_testing_llms/",
          "publishedOn": "2023-08-31T15:37:11.000Z",
          "wordCount": 2797,
          "title": "[P] DeepEval - Neural Framework For Testing LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166cby8/d_training_models_when_you_have_limited_compute/",
          "author": null,
          "description": "I've been wanting to take a code chatbot model like starchat or codellama and tune it to our codebase, problem is all I have at work is a Mac with 8gb of RAM. I talk with my boss today and can ask for some stuff if I want and can give good reason. What's the most efficient way to get the compute I need to train the model. Any other advice on how to go about doing this is greatly appreciated\n    submitted by    /u/Kechup17  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166cby8/d_training_models_when_you_have_limited_compute/",
          "publishedOn": "2023-08-31T14:14:39.000Z",
          "wordCount": 2663,
          "title": "[D] Training models when you have limited compute power",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166c0ja/n_dinov2_is_now_available_under_the_apache_20/",
          "author": null,
          "description": "Meta AI has made their DINOv2 self-supervised learning method for training computer vision models truly open source by publishing it under Apache 2.0 license.\n DINOv2 has outperformed previous state-of-the-art self-supervised learning methods on a variety of computer vision tasks, including image classification, object detection, and semantic segmentation. It is also more efficient to train than previous methods, making it more accessible to researchers and practitioners.\n DINOv2 is different from existing methods because it provides a new way to train high-performance computer vision models without the need for labeled data. This makes it possible to train models on large datasets of unlabeled images, which can be more cost-effective and time-efficient than collecting and labeling large datasets of images.\n New demo: https://dinov2.metademolab.com/\n    submitted by    /u/noiseinvacuum  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166c0ja/n_dinov2_is_now_available_under_the_apache_20/",
          "publishedOn": "2023-08-31T14:02:11.000Z",
          "wordCount": 2703,
          "title": "[N] DINOv2 is now available under the Apache 2.0 license",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1668xro/p_deep_reinforcement_learning_library_to_import/",
          "author": null,
          "description": "I have experience in deep learning but am a beginner in using deep reinforcement learning for robotics. However, I have recently gone through the huggingface course on deep reinforcement learning.\n I tried tinkering around with panda-gym but am having trouble trying to start my own project. I am trying to use two UR5 robots do some bimanual manipulation tasks e.g. have the left arm hold onto a cup while the right pours water into it. panda-gym allows me to import a URDF file of my own robot but I can't find the option to import my own objects like the xml file (or any extension) of a table or a water bottle.\n I have no idea which library allows me to import multiple URDF robots and xml objects and was hoping for some help.\n EDIT : I actually just read about Gazebo and was wondering if it'll allow me to do the above ? As a beginner I still have zero experience with ros and gazebo.\n    submitted by    /u/I_am_a_robot_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1668xro/p_deep_reinforcement_learning_library_to_import/",
          "publishedOn": "2023-08-31T11:47:29.000Z",
          "wordCount": 2752,
          "title": "[P] Deep reinforcement learning library to import multiple URDF robots and objects ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/166785l/d_optimizing_simple_distributions_for_something/",
          "author": null,
          "description": "As everyone knows, we usually optimise for maximum likelihood when fitting distributions like gaussians (equivalent to the forward KL-divergence). But for neural networks, techniques like GANs allow the minimisation of other distances like Mutual Information or Reverse KL. While this is certainly a very cool and insightful approach, it's also highly complex. I wonder wether other approaches to this problem exist for the simpler case, like fitting a gaussian or some other analytic distribution.\n From statistics, I have only encountered maximum likelihood and it's variations like robust statistics.\n    submitted by    /u/LeanderKu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/166785l/d_optimizing_simple_distributions_for_something/",
          "publishedOn": "2023-08-31T10:20:43.000Z",
          "wordCount": 2671,
          "title": "[D] Optimizing simple distributions for something other than maximum likelihood",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1666yyn/p_i_created_a_package_implementing_a_sota/",
          "author": null,
          "description": "This is the package\n https://github.com/mfumagalli68/xi-method\n Follow the README and install directly from pypi.\n From the paper:\n \" [..]To bridge this gap we propose a family of measures of statistical association whose definition is well-posed also for nonordered data. Our intuition is to rely on separation measurements between probability mass functions. Here, by separation measurement we mean any distance or divergence between probability mass functions that is positive, and that is null if and only if the probability mass functions coincide. Then, we show that the new class of sensitivity indices complies with Renyi’s postulate D of measures of statistical dependence (Renyi, 1959). This postulate, called zero-independence property in the following, requires that a measure of associat…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1666yyn/p_i_created_a_package_implementing_a_sota/",
          "publishedOn": "2023-08-31T10:06:39.000Z",
          "wordCount": 2891,
          "title": "[P] I created a package implementing a SOTA technique for XAI ( Explainable AI)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/165ssy5/d_will_i_get_in_fall_2024_ms_in_ml_european/",
          "author": null,
          "description": "TLDR: American, Graduated from U of Michigan in 2019 w/ 3.3 GPA Bs in Comp Sci. Worked at Google for 3 years. Samsung Research America for 3 months. No ML specific work experience. No research. Will I get in to European elite ML programs? If not what do I need to do?\n My GF and I want to study our masters together in Europe. She’s doing business I want to do ML/AI.\n I spent the past year kind of goofing off. Got kind of burned out and decided I was going to get into music production so spent the pst year mainly doing that with some software mixed in. \n Recently been self studying ML, both the math from textbooks and trying my hand at some models in python.\n I do not have any connections to academia currently and wil have to beg a professor who barely knew me from undergrad for a rec. Can get other recs from past bosses.\n My plan right now is to look for job hopefully in AI but maybe just more general software engineering again, but long term I want to get a masters in person.\n My current resume looks like:\n Graduated BS in Comp Sci from univ of Michigan 2019 3.3 GPA\n Worked at Google for 3 years Worked at Samsung Research America for 4 months Some self study I can claim but not much tangible proof\n Recommendation from Google Boss (Maybe) recommendation from UofM CS professor that barely knew me\n My questions to anyone that knows the admissions right now are:\n 1) Do you think I get to one off this? (To anyone of these schools)\n 2) If not what are the things to prioritize to improve my chances? What are the timeline of these steps? Can I do them in the next few months or have to wait till next year?\n    submitted by    /u/Srokisthename  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/165ssy5/d_will_i_get_in_fall_2024_ms_in_ml_european/",
          "publishedOn": "2023-08-30T22:26:51.000Z",
          "wordCount": 2886,
          "title": "[D] Will I get in? [Fall 2024 MS in ML European Universities]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/165r4hi/r_diffprep_differentiable_data_preprocessing/",
          "author": null,
          "description": "I just came across this paper, and it just sounds too good to be true. If we regularly spend up to 80% of our time in data preprocessing, this method would suddenly return us A LOT of that time. Has anyone seen it in python code? I haven't found it and I'd love to give it a try with some of my datasets from hell. They do have a GitHub page but I'm too dumb or too noob to make it run in my laptop.\n    submitted by    /u/Davidat0r  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/165r4hi/r_diffprep_differentiable_data_preprocessing/",
          "publishedOn": "2023-08-30T21:20:40.000Z",
          "wordCount": 2664,
          "title": "[R] DiffPrep: Differentiable Data Preprocessing Pipeline Search for Learning over Tabular Data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/165pn1j/d_knowledge_graph_vs_text_summaryembedding_for/",
          "author": null,
          "description": "Hi, I'm relatively new to the space of AI chatbots and I figured I'd get my hands wet with a small personal project. While researching the topic of long term conversational memory I noticed most people are using text embedding in combination with textual summary to generate a conversation history for the AI's prompt. However, this technique seems to have many drawbacks such as loss of details in the summarization process. I was wondering if anyone has experience using knowledge graph DBs like neo4j for conversational memory instead, and what the pros and cons of such an approach are compared to summarization. I'd be greatly interested in any resources that could further my knowledge in this space as my primary goal is to learn from this project. Thanks!\n    submitted by    /u/Rainmire  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/165pn1j/d_knowledge_graph_vs_text_summaryembedding_for/",
          "publishedOn": "2023-08-30T20:24:27.000Z",
          "wordCount": 2706,
          "title": "[D] Knowledge graph vs text summary+embedding for long term conversational memory",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/165p7yi/discussion_does_anybody_manage_to_make_musetree/",
          "author": null,
          "description": "https://stevenwaterman.uk/musetree/ It's for music generation through musenet. I don't manage to generate anything. It has to be related to API issues or stuff like that?\n    submitted by    /u/MusicalSeries  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/165p7yi/discussion_does_anybody_manage_to_make_musetree/",
          "publishedOn": "2023-08-30T20:08:33.000Z",
          "wordCount": 2600,
          "title": "[Discussion] Does anybody manage to make MuseTree work?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/165ozkx/shifting_order_in_multiplechoice_questions/",
          "author": null,
          "description": "Recent research proposes that Large Language Models (LLMs) may not be as reliable as we think. In fact, the order of options in a multiple-choice question drastically influences the responses from LLMs such as GPT-4 and InstructGPT.\n If you want to stay on top of the latest trends and insights in AI and tech, look here first.\n https://preview.redd.it/k8yaixbjzalb1.png?width=1289&format=png&auto=webp&s=99ac6280a1e7415f46c0c11938ae20e2b77674b4\n What are the findings?\n  \nLLM sensitivity to multiple-choice arrangement: The study suggests if options in multiple-choice questions are reordered, the LLM's performance varies dramatically— approximately 13% to 75% depending on the benchmark.\n Positional bias shapes responses: When the LLM is uncertain between top-selected answers, the option positioning can artificially lean its predictions. Observations also found that LLMs favor specific placements when unsure of the optimal response among top-selected answers.\n Performance improves when calibration techniques are applied: Making use of two unique calibration methods, the performance of LLMS saw up to eight percentage points of increase across numerous models and benchmarks.\n  \nWhy does this matter?\n This moves us closer to identifying the factors contributing to LLMs' sensitivity and highlights the significance of recognizing and confronting these sensitivities to improve real-world usability and reliability.\n P.S. If you like this kind of analysis, I write a free newsletter that tracks the most relevant news and research in AI and tech—stay updated in under 3 mins/day.\n (arXiv)\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/165ozkx/shifting_order_in_multiplechoice_questions/",
          "publishedOn": "2023-08-30T19:59:55.000Z",
          "wordCount": 2797,
          "title": "Shifting order in multiple-choice questions massively affects LLM performance [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/165oeh3/d_handwritten_text_recognition_ocr_on_historical/",
          "author": null,
          "description": "I am working on developing a solution to transcribe historic texts (Pre-1900's) which are all handwritten. I have some data, around 1000's transcribed sentences with their corresponding images of text. TrOCR looked great, but it still makes a lot of mistakes, probably because of the old English phraseology, so I tried to finetune it with my data and see if it improves and that didn't happen. \n The data I used to train was my 1000 sentences + some public dataset with another 2500 sentences, so just about 3500 sentences in total. Do you think it's because the data is small, that the performance is bad?\n I'm finetuning \"microsoft/trocr-base-stage1\" using native PyTorch. \n If not TrOCR do you recommend any OCR/HTR models I can finetune to my handwritten historical data? I truly appreciate any guidance you send my way. \n    submitted by    /u/daxow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/165oeh3/d_handwritten_text_recognition_ocr_on_historical/",
          "publishedOn": "2023-08-30T19:37:04.000Z",
          "wordCount": 2711,
          "title": "[D] Handwritten Text Recognition (OCR) on Historical Documents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/165lxu1/p_flowjax_normalizing_flows_in_jax/",
          "author": null,
          "description": "Hello everyone,\n Hopefully this is of interest to some of you. For those that don't know, normalising flows can be used as black-box unconditional or conditional distribution approximators, that support both exact sampling and density evaluations. For an excellent review see https://arxiv.org/abs/1912.02762.\n I am developing flowjax, a Python package for normalising flows, distributions and bijections. It uses Jax for automatic differentiation, and the equinox framework built by Patrick Kidger to allow for a familiar object-oriented design.\n It includes many powerful flows, e.g. masked autoregressive flows, coupling flows and block neural autoregressive flows. In addition to inheriting some benefits from using JAX (easy GPU support, some efficiency gains), here's a few points where I think flowjax has some advantages over other packages:\n  \nComprehensive documentation\n Simplified definitions of unconditional/conditional bijections and distributions (particularly nicer handling of the conditional case, which some packages seem to stitch in as an afterthought).\n Easy to plug in different \"transformer\" bijections to coupling/masked autoregressive flows.\n Use of efficiency tricks to optimize run times (e.g. circumventing recompilation of identical layers using jax.lax.scan over the flow layers)\n  \nIt has been used in a couple of papers already, but it would be great to have some more people using it and some feedback/suggestions/contributions. There are examples in the documentation for those that are interested.\n    submitted by    /u/LimitedConsequence  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/165lxu1/p_flowjax_normalizing_flows_in_jax/",
          "publishedOn": "2023-08-30T18:03:03.000Z",
          "wordCount": 2788,
          "title": "[P] FlowJax - Normalizing flows in JAX",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/165lfnw/project_models_for_unsupervised_anomaly_detection/",
          "author": null,
          "description": "Of the many unsupervised anomaly detection models out there (iforest, LOF, SVM etc) I am struggling to find a model that makes sense to use to detect anomalies in a single target feature. My current strategy is to subset the data into different categories and run iforest on a single column. \n I feel as though this method might not be the best because it basically creates a tree with a single branch and measures how many nodes away a given record might be. My confidence scores never seem to exceed around -.17 on a scale of [-1,1] where -1 tends to more confidence in anomalous behavior\n Is there a better way?\n Note: Anomalies in my data occur very infrequently\n    submitted by    /u/BeefaroniX  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/165lfnw/project_models_for_unsupervised_anomaly_detection/",
          "publishedOn": "2023-08-30T17:44:08.000Z",
          "wordCount": 2697,
          "title": "[Project] Models for Unsupervised Anomaly Detection of a Single Continuous Feature?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/165jdk8/discussion_how_are_you_evaluating_and_monitoring/",
          "author": null,
          "description": "Question for people who are implementing LLMs (open source, fine tuned, any kind). \n  \nHow do you know that your getting the quality output from the model that you need to ship the feature or model? Are the audits ad hoc data sampling and subjective \"good/bad\" ratings or have you figured out a more rigorous framework? Is it pretty much ~vibes~ based?\n What, if any, tools or processes are you putting into place to monitor and observe the LLM when its interacting with real time user data for weeks or months?\n \n Most of the folks I have spoken with are doing very ad hoc sampled output and writing down on post its or in a spreadsheet a subjective quality ratings. \n One person had developed a slightly more rigorous 3 question survey on \"is the result factual\", \"is the result cogent\" and \"is the result useful\". Not everyone is logging their LLM responses they show users which feels very risky to me.\n Anyone aware of any industry standards being established around this?\n    submitted by    /u/Andy-VertaAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/165jdk8/discussion_how_are_you_evaluating_and_monitoring/",
          "publishedOn": "2023-08-30T16:26:16.000Z",
          "wordCount": 2745,
          "title": "[Discussion] How are you evaluating and monitoring LLMs?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/165ial3/d_a_blog_post_on_yet_another_icml_award_fiasco/",
          "author": null,
          "description": "I wrote a blog post on the ICML award fiasco: They gave an outstanding paper award to the D-Adaptation paper, that contains worse results that the ones in papers from 9 years ago. Also, this is not the first time that ICML gives awards to questionable or even plainly wrong papers. \n I believe this might start a serious conversation about \"stochastic\" awards, and the super noisy reviews in machine learning conferences. \n https://parameterfree.com/2023/08/30/yet-another-icml-award-fiasco/\n    submitted by    /u/bremen79  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/165ial3/d_a_blog_post_on_yet_another_icml_award_fiasco/",
          "publishedOn": "2023-08-30T15:45:43.000Z",
          "wordCount": 2649,
          "title": "[D] A blog post on Yet Another ICML Award Fiasco",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/165i7be/d_is_there_a_monthly_limit_for_openai_service_in/",
          "author": null,
          "description": "When using OpenAI's api, there's a default limit of $120/month and my company is about to hit it. I plan on requesting an increase of that limit... but wondering, does Azure's OpenAI service have any monthly limit? By looking at their quotas: https://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits it doesn't seem like there's a monthly cap.\n Is this correct? If so, I see no reason why anyone would use OpenAI's api instead of Azure's, as they cost the same but there's no usage limit. Especially if you expect to increase api usage in the future.\n    submitted by    /u/alkibijad  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/165i7be/d_is_there_a_monthly_limit_for_openai_service_in/",
          "publishedOn": "2023-08-30T15:42:24.000Z",
          "wordCount": 2667,
          "title": "[D] Is there a monthly limit for OpenAI service in Azure?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/165gqam/p_i_created_gpt_pilot_a_research_project_for_a/",
          "author": null,
          "description": "Github: https://github.com/Pythagora-io/gpt-pilot\n Detailed breakdown: https://blog.pythagora.ai/2023/08/23/430/\n For a couple of months, I've been thinking about how can GPT be utilized to generate fully working apps, and I still haven't seen any project that I think has a good approach. I just don't think that Smol developer or GPT engineer can create a fully working production-ready app from scratch without a developer being involved and without any debugging process.\n So, I came up with an idea that I've outlined thoroughly in the blog post above, but basically, I have 3 main \"pillars\" that I think a dev tool that generates apps needs to have:\n  \nDeveloper needs to be involved in the process of app creation - I think that we are still far away from an LLM that can just be hooked up to …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/165gqam/p_i_created_gpt_pilot_a_research_project_for_a/",
          "publishedOn": "2023-08-30T14:46:07.000Z",
          "wordCount": 3432,
          "title": "[P] I created GPT Pilot - a research project for a dev tool that uses LLMs to write fully working apps from scratch while the developer oversees the implementation - it creates code and tests step by step as a human would, debugs the code, runs commands, and asks for feedback.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/165ga5i/d_graph_signal_processing_applications_and/",
          "author": null,
          "description": "I'm studying GSP and I'm stuck on the definition of the Graph Fourier Transform. \n The sigma notation and signal makes sense, but why is there an \\\"i\\\" term at the eigenvector mu? Shouldn't the eigenvector not depend on the \\\"i\\\"? And if it does, what does the \\\"i\\\" imply? \n    submitted by    /u/Ihaveaparrot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/165ga5i/d_graph_signal_processing_applications_and/",
          "publishedOn": "2023-08-30T14:28:39.000Z",
          "wordCount": 2623,
          "title": "[D] Graph Signal Processing Applications and Training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/165f400/d_given_that_we_can_lossily_transform_text_to/",
          "author": null,
          "description": "Consider video data that captures various interactions between entities—let's say Person A and Person B. We then apply a video summarization network T(x), where x is some video or an entity in the video, onto the video. For sake of argument, let's assume T(x) provides a description of x so detailed that we can decode the description back into the original video without losing much information via some arbitrary text-video model. Now, if we can infer a causal relationship in the video—like Person A punching Person B—then logically, an isomorphic relationship should also be inferable from the text encodings T(A) and T(B) (unless that relationship is one of the small pieces of information lost during the lossy transformation). After all, the encoding is just another representation of the same…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/165f400/d_given_that_we_can_lossily_transform_text_to/",
          "publishedOn": "2023-08-30T13:42:22.000Z",
          "wordCount": 3272,
          "title": "[D] - Given that we can lossily transform text to images and vice versa, multimodality should not be required for AGI or the construction of world-models. Any causal relationship that can be inferred from images/audio/video should be inferable from text.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/165e1u1/d_hpc_from_local_servers_for_deep_learning_as/",
          "author": null,
          "description": "Hi all,\n the company I am working at has several servers used for different tasks including data analysis and machine learning, including smaller tasks as well as deep learning. \n What are some ways/ technologies they could create a distributed system where users can submit their jobs and they are dispatched automatically? \n I was thinking of having an entry node that is the only one faced by users, is where all conda environments are and jobs can be submitted from there. \n Please let me know if you have any suggestions/ tools that you know that would make sense. Thanks in advance!\n    submitted by    /u/returnname35  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/165e1u1/d_hpc_from_local_servers_for_deep_learning_as/",
          "publishedOn": "2023-08-30T12:59:12.000Z",
          "wordCount": 2680,
          "title": "[D] HPC from local servers for deep learning as well as simpler tasks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/165e1fk/d_hpc_from_local_servers_for_deep_learning_as/",
          "author": null,
          "description": "Hi all,\n the company I am working at has several servers used for different tasks including data analysis and machine learning, including smaller tasks as well as deep learning. \n What are some ways/ technologies they could create a distributed system where users can submit their jobs and they are dispatched automatically? \n I was thinking of having an entry node that is the only one faced by users, is where all conda environments are and jobs can be submitted from there. \n Please let me know if you have any suggestions/ tools that you know that would make sense. Thanks in advance!\n    submitted by    /u/returnname35  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/165e1fk/d_hpc_from_local_servers_for_deep_learning_as/",
          "publishedOn": "2023-08-30T12:58:47.000Z",
          "wordCount": 2680,
          "title": "[D] HPC from local servers for deep learning as well as simpler tasks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/165dd1z/p_selfhosting_a_16b_llama_2_model_in_the_banking/",
          "author": null,
          "description": "I've received a freelance job offer from a company in the banking sector that wants to host their own LLAMA 2 model in-house.\n I'm hesitating to accept the gig. While I'll have access to the hardware (I've estimated that an A100 80GB will be required to host the 16B parameter version and process some fine-tuning & RAG), I'm not familiar with the challenges of self-hosting a model of this scale. I've always relied on managed services like Hugging Face or Replicate for model hosting.\n For those of you who have experience in self-hosting such large models, what do you think will be the main challenges of this mission if I decide to take it on?\n ​\n Edit: Some additional context information\n Size of the company: Very small ~ 60 employees\n Purpose: This service will be combined with a vector store to search content such as Word, Excel and PowerPoint files stored on their servers. I'll implement the RAG pattern and do some prompt engineering with it. They also want me to use it for searching things on specific websites and APIs, such as stock exchanges, so I (probably) need to fine-tune the model based on the search results and the tasks I want the model to do after retrieving the data.\n    submitted by    /u/IMissEloquent75  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/165dd1z/p_selfhosting_a_16b_llama_2_model_in_the_banking/",
          "publishedOn": "2023-08-30T12:29:28.000Z",
          "wordCount": 2792,
          "title": "[P] Self-Hosting a 16B LLAMA 2 Model in the Banking Sector: What Could Go Wrong?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/165airj/d_is_there_anything_langchain_can_do_better_than/",
          "author": null,
          "description": "I haven't used ChatGPT a lot or any other LLMs, I've been reading about Langchain and its use cases, and I'm having trouble wrapping my head around exactly what it does. From what I understand, its an alternative interface for LLMs, allowing for easy switching between them, and makes some work for specific use cases easier. If I wanted to write an app or script to interact with LLMs and do other tasks, how would LangChain be better than just making API call(s) to an LLM, getting back the result as a string, and doing whatever with it?\n    submitted by    /u/TheTwelveYearOld  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/165airj/d_is_there_anything_langchain_can_do_better_than/",
          "publishedOn": "2023-08-30T10:05:26.000Z",
          "wordCount": 2693,
          "title": "[D] Is there anything LangChain can do better than using LLMs directly (either through a website or an API), any examples? Why would someone choose to use it?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1653oov/d_using_llms_in_production_model_fallbacks/",
          "author": null,
          "description": "Hello r/MachineLearning I'm one of the maintainers of https://github.com/BerriAI/litellm/ - open-source library to call all LLM APIs using the OpenAI format [Anthropic, Huggingface, Cohere, TogetherAI, Azure, OpenAI, etc.].\n I'm writing this post to share some of the strategies we use for using LLMs in production, we've served over 2M+ queries so far\n TLDR: Use Caching + Model Fallbacks for reliability. This post goes into detail of our fallbacks implementation\n Using LLMs reliably in production involves the following components:\n  \nCaching - Cache Embedding() and Completion() for all models\n Model Fallbacks - set fallback_models=['gpt-3.5-turbo', 'command-nightly', 'llama2]. If primary model fails try fallback models. This deals with rate-limiting errors and when Provider APIs go down\n  \n…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1653oov/d_using_llms_in_production_model_fallbacks/",
          "publishedOn": "2023-08-30T03:34:44.000Z",
          "wordCount": 2866,
          "title": "[D] Using LLMs in Production - Model Fallbacks Tutorial + Caching",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1651d4h/d_decision_transformer_alignment_should_be_better/",
          "author": null,
          "description": "We've done some experiments recently,\n see the tech report: https://arxiv.org/abs/2308.12050v1\n We train an SFT model and an RM model, then align the LLM with DT/MLE with filtering (ReST) + RM /SFT datasets/SFT model-generated samples\n https://preview.redd.it/195op5q636lb1.png?width=1081&format=png&auto=webp&s=a9fa862e8a9ab05819484af8619f73d918fdc26a\n DT is the Decision Transformer alignment\n MLE is the ReST-like alignment\n https://preview.redd.it/u6x28fook5lb1.png?width=1118&format=png&auto=webp&s=4a87898129c1238c00071d43809f5daf440b26d8\n    submitted by    /u/seventh_day123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1651d4h/d_decision_transformer_alignment_should_be_better/",
          "publishedOn": "2023-08-30T01:47:56.000Z",
          "wordCount": 2622,
          "title": "[D] Decision Transformer Alignment should be better than DeepMind ReST",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/164y5s7/d_why_dont_we_build_models_that_designbuild/",
          "author": null,
          "description": "At what point do we create a model to build/design better models?\n Models = ml architecture\n    submitted by    /u/Significant_Water_28  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/164y5s7/d_why_dont_we_build_models_that_designbuild/",
          "publishedOn": "2023-08-29T23:29:44.000Z",
          "wordCount": 2602,
          "title": "[D] Why don't we build models that design/build better models. Too computationally expensive?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/164xan0/d_question_whats_the_future_of_imageanalytics/",
          "author": null,
          "description": "Hey everyone, first post on this sub so sorry if there's anything wrong. \n Right now, what are the cutting edge image processing models? This is in the context of the segmentation of specific features from an image (ie. finding the cars in an image of a busy roadway). \n The reason I am asking is I want to learn more image processing architectures that way I can find better direction for specific research areas to look into. \n Thanks in advance! :) \n    submitted by    /u/Adventurous-Tower392  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/164xan0/d_question_whats_the_future_of_imageanalytics/",
          "publishedOn": "2023-08-29T22:55:31.000Z",
          "wordCount": 2655,
          "title": "[D] Question: What's the future of image-analytics models?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/164x91n/stanfords_dspy_framework_revolutionizes_ai/",
          "author": null,
          "description": "Stanford researchers have unveiled a groundbreaking artificial intelligence (AI) framework known as DSPy. Designed to utilize Language Models (LMs) and Retrieval Models (RMs) optimally, DSPy is set to make AI programming more powerful, intuitive, and efficient.\n Why does this matter?\n  \nDSPy was built with complex tasks in mind. LMs, like GPT-3, generate Human-like text from given inputs, while RMs retrieve relevant data. DSPy combines their capabilities, enabling tasks like summarizing information from databases.\n It works on Pythonic syntax, using declarative and composable modules to instruct LMs.\n DSPy's automatic compiler finetunes the LM to run any program's steps. it replaces manual intermediate-stage labeling and string manipulation with systematic modular pieces.\n  \nWhat's unique about DSPy?\n  \nIt introduces \"Signatures\" and \"Teleprompters\" that compile your program. A 'signature' explains the task and inputs for the LM, while Teleprompters improve the effectiveness of prompts.\n Compared to other libraries, DSPy requires minimal labeling and bootstraps any needed intermediate labels.\n  \nIn short, DSPy simplifies delivering more nuanced instructions to AI and retrieving more detailed and accurate responses, thus widening the spectrum of tasks AIs can accomplish.\n P.S. (small self-plug) If you like this kind of analysis, I write a free newsletter that tracks the most relevant news and research in AI and tech---stay updated in under 3 mins/day.\n (github)\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/164x91n/stanfords_dspy_framework_revolutionizes_ai/",
          "publishedOn": "2023-08-29T22:53:42.000Z",
          "wordCount": 2788,
          "title": "Stanford's DSPy Framework Revolutionizes AI Language Processing Tasks [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/164wsct/p_finetuning_an_llm_to_imitate_someone/",
          "author": null,
          "description": "Hello all,\n I'm trying to understand how to get an LLM to imitate someone, say Shakespeare. It's easy enough to get all of Shakespeare's work.\n If I've understood the current state of play for LLMs, there are three options:\n  \nFine tune an LLM\n Vectorize your knowledge using something like ChromaDB. Do a similarity search after each prompt and get the LLM to \"read\" the top n docs\n Do both\n  \nI have a feeling that to imitate Shakespeare, fine tuning an LLM might work best.\n However, if my understanding is correct, the inputs to finetune an LLM must be formatted this way:\n <human>: \"To be\" <system>: \"Or not to be\" \n The gap I'm having trouble bridging is how do I go from a large text file to this input format? The only idea I've come across is format all of the text like so:\n <human>: \"sentence_1\" <system>: \"sentence_2\" <human>: \"sentence_2\" <system>: \"sentence_3\" \n Are there best practices around this problem? How should I be thinking about this?\n I've seen companies like character.ai create bots that imitate Elon Musk accurately for example so I know it's doable. I just wonder if they've done it by finetuning an LLM or training one from scratch or something else entirely.\n    submitted by    /u/Vanishing-Rabbit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/164wsct/p_finetuning_an_llm_to_imitate_someone/",
          "publishedOn": "2023-08-29T22:35:56.000Z",
          "wordCount": 2779,
          "title": "[P] Finetuning an LLM to imitate someone",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/164wkok/n_googles_deepmind_unveils_invisible_watermark_to/",
          "author": null,
          "description": "As AI image generators increase in popularity, differentiating between authentic and AI-created images is becoming more complex. DeepMind, Google's AI unit, is addressing this by developing an imperceptible watermark known as SynthID for its AI-generated images to counter misinformation.\n https://i.redd.it/z0fj6f3yt4lb1.gif\n Why this matters:\n  \nDeepMind's SynthID tags AI-generated images: Invisible to people but detectable by computers, this watermark hopes to aid in the verification of images.\n Technology, however, isn't completely foolproof: DeepMind itself acknowledges that intense image manipulation could compromise the watermark.\n Google's image generator, Imagen, will only apply to images created using this tool: Google aims to instantly identify AI-generated images with this effectively hidden watermark.\n  \nDeepMind's head of research, Pushmeet Kohli, shared the following details:\n  \nThe watermark changes on images are so subtle that humans wouldn't notice, yet DeepMind can still detect an AI-generated image.\n Despite any subsequent cropping or editing, the watermark remains identifiable by DeepMind's software. Colors, contrast, or size changes won't affect it.\n  \nCalls for a standard approach to AI-generated image identification continue:\n  \nMore coordination between businesses is crucial, different methods adopted by various firms add degrees of complexity in tagging AI content.\n Other tech giants, including Microsoft and Amazon, pledge to watermark some AI content, meeting similar demands for transparency over AI-generated works.\n  \n(source)\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/164wkok/n_googles_deepmind_unveils_invisible_watermark_to/",
          "publishedOn": "2023-08-29T22:27:52.000Z",
          "wordCount": 2791,
          "title": "[N] Google's DeepMind Unveils Invisible Watermark to Spot AI-Generated Images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/164w5nw/d_questions_on_artificial_neural_networks_from_a/",
          "author": null,
          "description": "Hello everyone. I'm yet another person looking to expand my understanding of artificial intelligence, and I'm trying to get a map of all the language that is used to describe and understand artificial neural networks.\n My training is in neuroscience, so all my language is focussed on how real neurons are created, interact, form networks, and how those networks interact to take in multisensory observation and output some of the vast variety of things our brains can do.\n Which leaves me with a lot of questions in my jargon that I cannot currently map onto the jargon of ML/AI, and I'm hoping that participating in this community can help with that, over time.\n I am already keenly aware that the phrase \"artificial neural networks\" is very gauzy. There is some biomimicry in their design and arch…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/164w5nw/d_questions_on_artificial_neural_networks_from_a/",
          "publishedOn": "2023-08-29T22:12:00.000Z",
          "wordCount": 2993,
          "title": "[D] Questions on artificial neural networks from a neuroscientist",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/164sm64/p_codellama_inference_code_complete/",
          "author": null,
          "description": "Quite recently, I jumped on the boat of trying out llama. I noticed codellama did not provide any inference code. Yes, it provided python files which lets you run the inference but not a programming method rather terminal approach. \n Terminal approach is great as it allows experts to run and perform inference+evaluation easily. But, if you are just starting out/new/non-seasoned programmer/individual in AI, it is frustrating. Because one, you can't play with actual code, limiting learning opportunities and two, it does not produces the curiosity in most cases to read all the code. \n On top of that, I realised there was a lack of repositories and articles on this subject to load code-llama even with third-party methods. Which is why, I wrote two notebooks which outlines the process of how you can load code-llama from FAIR repository using code. [Believe me it's fun and filled with learning opportunities] and two how you can use Huggingface to load the model and perform inference. \n Few points:\n 1. Performing inference from FAIR repo, requires significant amount of computing resources even for 7B model.\n 2. Huggingface method can be loaded using free Google Colab subscription.\n [Feel free to star, if it helped you]\n GitHub Link: https://github.com/sleepingcat4/codellama-inference\n    submitted by    /u/Suspicious-Bird8840  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/164sm64/p_codellama_inference_code_complete/",
          "publishedOn": "2023-08-29T19:58:51.000Z",
          "wordCount": 2772,
          "title": "[P] Codellama inference code complete",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/164scat/pythonjava_developers_interested_in_side_projects/",
          "author": null,
          "description": "Throw away account for the obvious reason...\n This is not a job posting or self-promotion. We are networking in an attempt to speak to like-minded people who might be interested in a little side project outside of work.\n We are keen to speak to a London/UK-based Developer with a Banking sector background to join us on a project outside of work with the vision of potentially growing a fund.\n In short; we are in the process of developing an FX Macroeconomic Sentiment Divergence Trading Algorithm. There are currently 4 participants in the project (2 Developers and 2 Traders), 3 of whom work for Tier1 IBs in market-facing roles. 1 of the Developers is likely going to leave the project and we are interested in speaking to someone about picking up his part of the project.\n There are 3 parts to the project. The first part is mostly complete, now leaving the other 2 parts for us to start working on. We have manually backtested the strategy and it proves to be very profitable - more details can be shared about the strategy and results upon engagement.\n We are all VP-level in our roles and have around 10-15 years of experience in our requisite field. The tech stack for the project is Python, Java, Kafka, MongoDB and Springboot. We are also very interested in integrating some AI/ML modeling, so if you have any experience in this field that would be a big advantage\n A Banking background and being UK-based is a non-negotiable. If you feel like this could apply to you, get in touch! :)\n    submitted by    /u/BuyTheDipSellTheRipp  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/164scat/pythonjava_developers_interested_in_side_projects/",
          "publishedOn": "2023-08-29T19:48:15.000Z",
          "wordCount": 2848,
          "title": "Python/Java Developers Interested in Side Projects Outside of Work (FX-Algo) \"[Research]\"\"[Discussion]\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/164qyz6/d_best_gpu_cloud_hosting_for_a_side_project_thats/",
          "author": null,
          "description": "Context:\n  \nI have an app that needs GPUs for DL inference (I don’t need GPUs for training, I own a 3070 TI). My DL model inference is pretty slow (the model framework I'm using is known to be slow) so either one machine with multiple beefy GPUs or multiple GPUs on separate machines will be necessary. My machines will be running custom docker containers.\n Slow inference:\n  \nI was planning on putting a few GPU instances behind nginx load balancer and running pytriton on the instances. Since inference is pretty slow, I’m worried if multiple people send requests to a server at the same time, there will be significant delays on responses. Has anyone ran into this before and have insight on streamlining slow inference/scaling demand? \n \"Community\" Cloud GPUs:\n  \nI did a lot of research into clo…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/164qyz6/d_best_gpu_cloud_hosting_for_a_side_project_thats/",
          "publishedOn": "2023-08-29T18:57:17.000Z",
          "wordCount": 2959,
          "title": "[D] Best GPU cloud hosting for a side project that’s easy to scale?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/164qc8c/r_loss_of_plasticity_in_deep_continual_learning/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2306.13812\n Github: https://github.com/shibhansh/loss-of-plasticity\n Abstract:\n  \nModern deep-learning systems are specialized to problem settings in which training occurs once and then never again, as opposed to continual-learning settings in which training occurs continually. If deep-learning systems are applied in a continual learning setting, then it is well known that they may fail to remember earlier examples. More fundamental, but less well known, is that they may also lose their ability to learn on new examples, a phenomenon called loss of plasticity. We provide direct demonstrations of loss of plasticity using the MNIST and ImageNet datasets repurposed for continual learning as sequences of tasks. In ImageNet, binary classification performance dropped from 89\\% accuracy on an early task down to 77\\%, about the level of a linear network, on the 2000th task. Loss of plasticity occurred with a wide range of deep network architectures, optimizers, activation functions, batch normalization, dropout, but was substantially eased by L2-regularization, particularly when combined with weight perturbation. Further, we introduce a new algorithm -- continual backpropagation -- which slightly modifies conventional backpropagation to reinitialize a small fraction of less-used units after each example and appears to maintain plasticity indefinitely. \n  \nhttps://preview.redd.it/ewl0336sd3lb1.jpg?width=801&format=pjpg&auto=webp&s=e105e6fa86daad84cdc847e96fec3cac5a237c77\n https://preview.redd.it/vdd3i46sd3lb1.jpg?width=1159&format=pjpg&auto=webp&s=47dfef94870c94246cb272b7f8299e1033f40873\n https://preview.redd.it/zc4tc16sd3lb1.jpg?width=1389&format=pjpg&auto=webp&s=e2f3b064268d475805c153457c7a60b4a1d42b74\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/164qc8c/r_loss_of_plasticity_in_deep_continual_learning/",
          "publishedOn": "2023-08-29T18:32:58.000Z",
          "wordCount": 2783,
          "title": "[R] Loss of Plasticity in Deep Continual Learning - University of Alberta 2023 - Continual backpropagation maintains plasticity indefinitely!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/164pmm8/interesting_master_thesis_topics_in_ai_and_nlp_p/",
          "author": null,
          "description": "Hi! I am going to write my master thesis within the fields of AI and NLP this year. But I am struggling with finding a topic that interests me. Does anyone here have some good suggestions? I am not that good in deep learning theory, so I am looking for a more applied topics, such as classification or text generation problems.\n    submitted by    /u/IndependentSidekick  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/164pmm8/interesting_master_thesis_topics_in_ai_and_nlp_p/",
          "publishedOn": "2023-08-29T18:05:29.000Z",
          "wordCount": 2637,
          "title": "Interesting master thesis topics in AI and NLP [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/164n8iz/discussion_promising_alternatives_to_the_standard/",
          "author": null,
          "description": "What are some promising transformer alternatives/variants that you think more folks should be aware of? They need not be new or SOTA! My list so far includes\n  \nRWKV: https://arxiv.org/abs/2305.13048\n (state space) S4, H3, Hyena: https://github.com/HazyResearch/safari\n (MLP-based) Hypermixer, MLP-mixer: https://arxiv.org/abs/2203.03691\n Retnet https://arxiv.org/abs/2307.08621\n (random feature-based attention) EVA, LARA https://arxiv.org/abs/2302.04542\n (rotary embeddings) RoFormer https://arxiv.org/abs/2104.09864\n dynamic convolutions https://arxiv.org/abs/1901.10430v2\n  \nMy hope is to assemble a list of 10-15 diverse architectures that I can study in depth by comparing and contrasting their designs. Would love to share my findings with this community.\n    submitted by    /u/alpthn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/164n8iz/discussion_promising_alternatives_to_the_standard/",
          "publishedOn": "2023-08-29T16:33:45.000Z",
          "wordCount": 2666,
          "title": "[Discussion] Promising alternatives to the standard transformer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/164n2xl/d_clip_open_visionlanguage_model_alternative/",
          "author": null,
          "description": "I'm experimenting with CLIP to use it for a downstream task RL which requires good image semantics understanding, but I'm quite disappointed with its performance. I need better contrastive performance in the representations. Any suggestions?\n ​\n omg no way\n    submitted by    /u/rima-m  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/164n2xl/d_clip_open_visionlanguage_model_alternative/",
          "publishedOn": "2023-08-29T16:27:42.000Z",
          "wordCount": 2617,
          "title": "[D] CLIP open vision-language model alternative",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/164lb7s/p_build_adaptive_sparse_grids_to_accurately/",
          "author": null,
          "description": "I'm working on a project that provides an adaptive sparse grid algorithm on Chebyshev nodes for interpolation and integration of multivariable functions on k-cells.\n https://github.com/rnburn/bbai\n Unlike polynomial interpolants in equispaced points, interpolants in Chebyshev nodes have excellent approximation properties (see Myth 1 of [1]). If a function is Lipchitz continuous, they converge; if a function is smooth with v derivatives and bounded variation for the v-th derivative, then they converge O(n^-v); and if a function is analytic, they converge geometrically.\n The Chebyshev Gauss-Lobatto nodes define a sequence of nested points, X^1, X^2, ..., that make it possible to build Smolyak sparse grids at Chebyshev nodes ([2], [3]).\n ![img](4cw0xi8oc2lb1 \" \")\n For bbai, I implemented the …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/164lb7s/p_build_adaptive_sparse_grids_to_accurately/",
          "publishedOn": "2023-08-29T15:19:44.000Z",
          "wordCount": 3655,
          "title": "[P] Build adaptive sparse grids to accurately approximate and integrate functions of multiple variables",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/164hyia/d_optimizing_keyword_search_balancing_sql_script/",
          "author": null,
          "description": "I'm currently thinking about how to implement the \"similar keywords\" feature. I've prepared a table with keywords that are extracted from several hundred other tables. It includes basic information such as \"keyword,\" \"type,\" \"words\" (indicating the number of words in a keyword, e.g., \"first name\" will have \"words\" = 2), as well as some technical fields (such as database, table, etc.).\n In our data product, after entering a specific keyword, we have various pieces of information (which I'm not currently focusing on), and among them, we have \"SIMILAR KEYWORDS.\" The results are displayed based on simple SQL queries, for instance:\n ​\n SELECT word, SUM(CASE WHEN type IN ('N', 'T') THEN 1 ELSE 0 END) AS count, COUNT(\\*) \\* CASE WHEN (word + '%') LIKE u/word \\+ '%' THEN 1.5 ELSE 1 END AS score FROM object_keywords WHERE ('% ' + word + '%') LIKE '%' + u/word + '%' AND (database_id = u/database_id OR u/database_id IS NULL) AND ( .... more technical information here. \n ​\n I'm wondering how to improve this process. Would it be worth considering some AI solutions, or should I focus on enhancing the current SQL scripts (e.g., think about a more advanced scoring system)?\n What are your thoughts on this? Has anyone worked on something similar?\n    submitted by    /u/International-Shirt5  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/164hyia/d_optimizing_keyword_search_balancing_sql_script/",
          "publishedOn": "2023-08-29T13:04:40.000Z",
          "wordCount": 2792,
          "title": "[D] Optimizing Keyword Search: Balancing SQL Script Enhancements and AI Solutions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/164cfuc/d_is_there_already_a_way_to_use_llama_2_with_a/",
          "author": null,
          "description": "I've seen something like that:\n https://together.ai/blog/llama-2-7b-32k\n Is there a way to use llama 2 13b chat or 70b chat with 32k prompt? If not what are the alternatives? Would that: https://youtu.be/ypzmPwLH_Q4?feature=shared be the best thing to do?\n I'm trying to create a chat bot that would have a pretty specific exeprtise. For example: I would like to feed in soccer rules and then make the bot answear questions about soccer. The system prompt is amazing, but is very limited.\n    submitted by    /u/Botanical0149  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/164cfuc/d_is_there_already_a_way_to_use_llama_2_with_a/",
          "publishedOn": "2023-08-29T08:19:07.000Z",
          "wordCount": 2666,
          "title": "[D] Is there already a way to use Llama 2 with a very big system prompt?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1649kmr/d_trying_to_understand_concept_learning_some/",
          "author": null,
          "description": "Hi, Im going through Tom Mitchell's Machine Learning and have a couple of questions based on the 2nd chapter : Concept learning. I was hoping I could get some external point of view on these:\n ​\n  \nPg 44, para 2, part 1 : \"advantage of viewing inductive inference systems in terms of their inductive bias is that it provides a nonprocedural means of characterizing their policy for generalizing\"\n  \n Are there any general procedures to identify and validate the inductive bias of a system?\n Are there any guidelines to ensure the inferred definition of inductive bias is without errors?\n Assuming all/most predictive algorithms can be defined in terms of their inductive bias, while concentrating on choosing the algorithms which aligns with our philosophy of talking a problem, how can we weigh part…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1649kmr/d_trying_to_understand_concept_learning_some/",
          "publishedOn": "2023-08-29T05:33:12.000Z",
          "wordCount": 3306,
          "title": "[D] Trying to understand Concept learning | Some questions based on Tom Mitchell Chapter 2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16495ds/discussionresearch_calibration_for_pointer/",
          "author": null,
          "description": "Trying to understand calibration in NER. One thing which has gained popularity is generative based NERs, which generated pointers to indices of input text for each class. \n But all typical calibration mechanisms after temp scaling won't generalize here. (not that I know many calibrations myself). Even Bias corrected temp scaling quickly gets overfitted. \n Do you have any paper that tackles this? Open to discussing techniques and trying out on standard datasets\n    submitted by    /u/Designer-Air8060  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16495ds/discussionresearch_calibration_for_pointer/",
          "publishedOn": "2023-08-29T05:09:42.000Z",
          "wordCount": 2644,
          "title": "[Discussion][research] Calibration for (pointer) generative NER",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/164771x/p_are_there_free_alternatives_to_sagemaker_i_can/",
          "author": null,
          "description": "I have a more detailing explanation here. I’m thinking sagemaker may help me here but I’m not trying to incur charges just yet. Are there alternatives I can use. Nothing robust, just a place to host my model and embedding tool and then I can easily call it in py file in my app.\n    submitted by    /u/brianomars1123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/164771x/p_are_there_free_alternatives_to_sagemaker_i_can/",
          "publishedOn": "2023-08-29T03:28:35.000Z",
          "wordCount": 2635,
          "title": "[P] are there free alternatives to sagemaker I can use for my project building?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1645tg6/d_how_usable_is_pytorch_for_tpu_these_days/",
          "author": null,
          "description": "See title. My impression has always been that PyTorch for TPU is an in-name only functionality, but I'm curious about first-hand experience from those who have used it after PyTorch 2.0+. \n Bonus question: has anyone used PyTorch Lightning for running on TPU? If so, how was the experience?\n    submitted by    /u/impromptued  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1645tg6/d_how_usable_is_pytorch_for_tpu_these_days/",
          "publishedOn": "2023-08-29T02:24:28.000Z",
          "wordCount": 2624,
          "title": "[D] How usable is PyTorch for TPU these days?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1642whx/ml_model_for_predicting_nfl_outcomes_p/",
          "author": null,
          "description": "Hey all, ML noob here dipping their feet in the water. Right now I am trying to make an ML model that predicts \"legendary\" QBs of the past performances against current NFL teams. I'll be using Jupyter and Sklearn to do this. However, and maybe this is me overthinking things, I'm not sure how sklearn is going to interpret the data in the dataset. Right now I have a dataset containing all these QBs data (passing stats, strengths and weaknesses, etc.). My teams version of the data is essentially going to be the inverse of all these things. I'm just not quite sure what to target when im testing the data that will determine the \"prediction\" of the legend QBs stat line against the current team. In better words, how will the computer know that I'm trying to find the yards and touchdowns a QB would produce against a certain team when there's not really any target data for this. I feel as though all I have is data that contributes to a potential target data but I lack target data itself and I'm not sure what to do in that regard. I’m making use of supervised learning and decisión trees btw.\n Thanks!\n    submitted by    /u/saggyboobsarecooltoo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1642whx/ml_model_for_predicting_nfl_outcomes_p/",
          "publishedOn": "2023-08-29T00:16:51.000Z",
          "wordCount": 2777,
          "title": "ML Model for Predicting NFL Outcomes [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16426a6/openai_finally_launches_chatgpt_enterprise_n/",
          "author": null,
          "description": "OpenAI has announced a new product for businesses that want to use its AI technology. ChatGPT Enterprise is a subscription service that offers unlimited, fast, and secure access to GPT-4 and other features that can help businesses improve their workflows and communication.\n If you want to stay ahead of the curve in AI and tech, look here first.\n https://preview.redd.it/fgva1q54uxkb1.png?width=862&format=png&auto=webp&s=d8c89b614859222046aa75f89a484795c2ef7912\n Why this matters:\n  \nChatGPT Enterprise is the first product that lets businesses use GPT-4 without any restrictions. The previous tiers of ChatGPT, which are still available for individuals and developers, have usage caps and lower performance. ChatGPT Enterprise removes these limitations and provides the most powerful version of GP…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16426a6/openai_finally_launches_chatgpt_enterprise_n/",
          "publishedOn": "2023-08-28T23:47:15.000Z",
          "wordCount": 2897,
          "title": "OpenAI finally launches ChatGPT Enterprise [N]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1641opc/d_rtx_4060_ti_16gb_for_mldl/",
          "author": null,
          "description": "I know the 4060 Ti with its reduced memory bus width and overall underspec'd profile caught a lot of flak from the gaming community in terms of its value proposition. However, I'm looking to get into ML/DL and was wondering if this would be a good starter card for GPU acceleration. With rumored price drops on the horizon, I wonder if the value sentiment will be a better match. If it's a bad call, are there any other GPUs that you would recommend for training? \n    submitted by    /u/reducksss  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1641opc/d_rtx_4060_ti_16gb_for_mldl/",
          "publishedOn": "2023-08-28T23:27:17.000Z",
          "wordCount": 2659,
          "title": "[D] RTX 4060 Ti 16gb For ML/DL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/163zwr8/p_setting_up_sagemaker_for_cicd_pipelines/",
          "author": null,
          "description": "I'll start with the obvious - AWS guides are the worst. We all felt it. So, trying to build automation with them becomes M:I, or better yet, Oppenheimer.\n For the first time, our MLOps team had to build a CI/CD pipeline for ML training and deployment using SageMaker. We had ZERO ideas on how to do it, so we had to go through the rigorous process of using AWS guides and tutorials, scattered over a gazillion places, just to figure out how to configure our project with SageMaker and build infra for CI/CD.\n Usually, when this thing happens, we extend the project lifecycle and have a team member document the process so we can refer back to it when we need to do it again.\n Knowing this can be beneficial to the community, we decided to share a series of 3 blogs that guide you through the process of building CI/CD pipelines for continuous training and deployment with AWS SageMaker.\n We published the first blog, which covers the configuration part, and plan to publish the rest in the following week.\n Check it out: https://dagshub.com/blog/setup-sagemaker-for-ci-cd-pipelines/\n I'm sure we can improve this tutorial, and would love to learn from your experience on how we can do it! 🤗\n    submitted by    /u/RepresentativeCod613  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/163zwr8/p_setting_up_sagemaker_for_cicd_pipelines/",
          "publishedOn": "2023-08-28T22:15:40.000Z",
          "wordCount": 2780,
          "title": "[P] Setting up SageMaker for CI/CD Pipelines",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/163yc8v/r_nougat_neural_optical_understanding_for/",
          "author": null,
          "description": "Project page: https://facebookresearch.github.io/nougat/ Includes example Paper conversions!\n Paper: https://arxiv.org/abs/2308.13418\n Github: https://github.com/facebookresearch/nougat\n Abstract:\n  \nScientific knowledge is predominantly stored in books and scientific journals, often in the form of PDFs. However, the PDF format leads to a loss of semantic information, particularly for mathematical expressions. We propose Nougat (Neural Optical Understanding for Academic Documents), a Visual Transformer model that performs an Optical Character Recognition (OCR) task for processing scientific documents into a markup language, and demonstrate the effectiveness of our model on a new dataset of scientific documents. The proposed approach offers a promising solution to enhance the accessibility of scientific knowledge in the digital age, by bridging the gap between human-readable documents and machine-readable text. We release the models and code to accelerate future work on scientific text recognition. \n  \nhttps://preview.redd.it/p71yay213xkb1.jpg?width=1788&format=pjpg&auto=webp&s=2f935e3212d0c7113fba2575f339f95b5bada632\n https://preview.redd.it/f7yk47413xkb1.jpg?width=1769&format=pjpg&auto=webp&s=075bab02a70ec32227e1bad493052d03043376ee\n https://preview.redd.it/i06wq0313xkb1.jpg?width=1590&format=pjpg&auto=webp&s=6212bb9078b8c48cd28ca45898f79b44d45ae3c3\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/163yc8v/r_nougat_neural_optical_understanding_for/",
          "publishedOn": "2023-08-28T21:16:13.000Z",
          "wordCount": 2707,
          "title": "[R] Nougat: Neural Optical Understanding for Academic Documents - Meta AI 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/163xzkz/d_mmlu_having_many_questions_with_wrong_answers/",
          "author": null,
          "description": "AI Explained Youtube channel did a video where they went through self reflection, but doing that they found a fairly large number of questions that either missed context, where miss spelled or just had wrong answers in the MMLU dataset.\n (video: https://www.youtube.com/watch?v=hVade_8H8mE)\n It would not matter so much if the models had high failure rate, but as the models are getting closer and closer to 100%, the wrong answers will matter more and more.\n So, what can be done to fix such errors or to create a better test than MMLU?\n    submitted by    /u/Luvirin_Weby  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/163xzkz/d_mmlu_having_many_questions_with_wrong_answers/",
          "publishedOn": "2023-08-28T21:03:19.000Z",
          "wordCount": 2666,
          "title": "[D] MMLU having many questions with wrong answers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/163xxvw/r_omniquant_omnidirectionally_calibrated/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2308.13137\n Github: https://github.com/OpenGVLab/OmniQuant\n HuggingFace Model direct download: https://huggingface.co/ChenMnZ/OmniQuant/tree/main\n Abstract:\n  \nLarge language models (LLMs) have revolutionized natural language processing tasks. However, their practical deployment is hindered by their immense memory and computation requirements. Although recent post-training quantization (PTQ) methods are effective in reducing memory footprint and improving the computational efficiency of LLM, they hand-craft quantization parameters, which leads to low performance and fails to deal with extremely low-bit quantization. To tackle this issue, we introduce an Omnidirectionally calibrated Quantization (OmniQuant) technique for LLMs, which achieves good performance in …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/163xxvw/r_omniquant_omnidirectionally_calibrated/",
          "publishedOn": "2023-08-28T21:01:43.000Z",
          "wordCount": 2835,
          "title": "[R] OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models - OpenGVLab, Shanghai AI Laboratory 2023 - Provides an pre-trained Omniquant model zoo for multiple model families, including LLaMa-1&2, LLaMa-2-Chat, OPT!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/163x9aq/d_how_long_can_it_take_to_learn_machine_learning/",
          "author": null,
          "description": "Hello everyone.\n I am starting my career transition, and would be interested to know how long it might take me to acquire the skills needed to work for a company. Likewise, I would like to know if it is necessary (or important) to have a professional degree to get a job.\n Just to give you some context about me, I am currently a recently graduated lawyer, so my degree has not given me a strong mathematical background. However, my strongest area of learning has always been mathematics, so despite not having a very advanced background, I consider myself to be a pretty good and fairly quick learner.\n I would also like to know if you consider if my professional career could be useful in some machine learning context.\n If you could recommend me some courses, inputs or guide to study in an organized way on the subject I would be very grateful.\n Thank you very much in advance.\n    submitted by    /u/Davidescudero10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/163x9aq/d_how_long_can_it_take_to_learn_machine_learning/",
          "publishedOn": "2023-08-28T20:35:57.000Z",
          "wordCount": 2742,
          "title": "[D] How long can it take to learn machine learning from scratch well enough to be hireable?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/163ve8h/r_deepmind_researchers_introduce_rest_a_simple/",
          "author": null,
          "description": "Large language models (LLMs) are amazing at generating fluent text and solving various linguistic tasks. However, these models are not always aligned with human preferences and values and may produce harmful or undesirable content if not properly guided. Aligning LLMs with human preferences can also improve their performance on downstream tasks. One way to achieve this alignment is to use reinforcement learning from feedback (RLHF), which learns a reward model from human input and then fine-tunes the LLM using a reinforcement learning (RL) objective.\n However, RLHF methods often face challenges such as computational cost, reward hacking, and data quality. To address these issues, researchers from DeepMind propose a new method called Reinforced Self-Training (ReST), which is inspired by gro…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/163ve8h/r_deepmind_researchers_introduce_rest_a_simple/",
          "publishedOn": "2023-08-28T19:26:00.000Z",
          "wordCount": 3136,
          "title": "[R] DeepMind Researchers Introduce ReST: A Simple Algorithm for Aligning LLMs with Human Preferences",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/163v8cl/discussion_starting_a_mldl_hobby_project_need/",
          "author": null,
          "description": "Hello everyone,\n I am at a bit of a crossroads and hope for some advice from the community. I also hope the answers would help others who are in my situation right now.\n I used to work on vision-related problems utilizing Deep learning back in a day, with all fun included: trying out new models, implementing data pipelines, evaluating various metrics... It was a rather big company with its own data collection efforts and enough resources for training. So, I am definitely not a beginner and have some experience.\n At my current job, I am not doing any ML/DL at the momemt, and while the stuff I am doing is still cool and I enjoy it, I am missing good old ML and having a feeling that I am hanging behind as the time goes by. So I figured it would be nice to start a hobby project, preferably in the area of vision-related applications of deep learning. However, I feel a bit lost as in what would be the most efficient approach taking into account I would only have a coule of hours per week for it.\n Here are possible ways to go I am thinking of:\n  \ntake a paper, implement it from scratch with PyTorch\n clone an existing project, contribute with code improvements/better test coverage\n take an existing pre-trained model, adapt to a slightly different task and fine-tune\n  \nWhile the first option is of cource the most exciting, the problem is you have to pay for a powerful GPU and data storage which might be impractical (my PC has a 4 GB GTX 1650 TI). Cloud storages exist, and I would be willing to even spend something on training but would like to avoid the costs.\n So, the question would be: has enyone faced similar situation? Which way did you end up going? Any general tips? Thanks!\n    submitted by    /u/odu_1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/163v8cl/discussion_starting_a_mldl_hobby_project_need/",
          "publishedOn": "2023-08-28T19:19:39.000Z",
          "wordCount": 2885,
          "title": "[Discussion] Starting a ML/DL hobby project - need advice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/163u02s/d_multimodality_applications_usecases_top_tools/",
          "author": null,
          "description": "Hi folks,\n As multimodality is increasing in popularity, many data domains seem to be \"converging\" lately, e.g. text & image domains.\n What are some of the best tools, use-cases, and methods out there you've seen for practical multimodality applications (e.g., below is an example of multimodal search from our latest blog post).\n https://i.redd.it/z58w6v2r9wkb1.gif\n    submitted by    /u/kazhdan_d  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/163u02s/d_multimodality_applications_usecases_top_tools/",
          "publishedOn": "2023-08-28T18:33:25.000Z",
          "wordCount": 2626,
          "title": "[D] Multimodality: Applications, Use-cases, & Top Tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/163s96w/d_question_on_derivedsynthetic_input_tokens_for/",
          "author": null,
          "description": "I'm likely using the wrong vocabulary here (and thus struggling to find info on my own) but I was curious if there were any work done on \"synthetic\" inputs for LLMs. In essence, rather than input embeddings all coming from a fixed token vocabulary, could you instead input an embedding as a token that was generated elsewhere? An output of another LLM (embedding model) or any other way (maybe just an average of a few tokens as an example)?\n Essentially - I am curious if there's a NLP approach analogy to Textual Inversion techniques in image generation models. I could imagine this being useful for things like RAG or personalization (if you could have a \"user\" token). Surely I'm not the first to think of this so I would love some pointers to any papers/blogs etc in this space.\n    submitted by    /u/GeneralMalarkee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/163s96w/d_question_on_derivedsynthetic_input_tokens_for/",
          "publishedOn": "2023-08-28T17:28:00.000Z",
          "wordCount": 2714,
          "title": "[D] Question On Derived/Synthetic Input Tokens for LLMs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/163radj/d_why_do_you_integrate_ml_features_into_your/",
          "author": null,
          "description": "Hi everyone,\n I’ve heard countless times people saying “I want to integrate ML in my product” and recently “I love ChatGPT, I should integrate it in my product”. Yet, as I dived deeper, seeking the genuine reasons and pain points driving this request, I regularly found the same pattern: many had no clear motive for their AI aspirations. It seemed as if they were only jumping on the trend because “everyone else is doing it”, or because their “CEO” told them to do so.\n So my question is : why do you integrate AI/ML into your products? Is it to enhance your user experience? Is to automate repetitive and time-consuming tasks? Is it to stay ahead of your competition? or is it just because everyone is doing it?\n    submitted by    /u/Vivid_Recording582  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/163radj/d_why_do_you_integrate_ml_features_into_your/",
          "publishedOn": "2023-08-28T16:51:14.000Z",
          "wordCount": 2705,
          "title": "[D] Why do you integrate ML features into your product?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/163qo3v/p_the_consilience_equation_bridging_holism_and/",
          "author": null,
          "description": "Hey everyone! I've been working on and playing around with novel and adaptable model architectures and landed on something really cool. It's based on a Biomimicry principle and has some really cool features. I've tested it using various pre-loaded library datasets like CIFAR and MINST, as well as adapting it to a few Kaggle competitions. It has achieved some pretty amazing results by using it's unique adaptability; which comes down to figuring out how the Holistic and Reductionist model architectures can best utilize their roles and how they can combine dynamically.\n I'm currently compiling the full official open source paper and release with usable Notebooks, but I didn't want to sit on it that long without sharing it with the community. Here is a link to a very haphazardly-thrown-togethe…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/163qo3v/p_the_consilience_equation_bridging_holism_and/",
          "publishedOn": "2023-08-28T16:27:19.000Z",
          "wordCount": 3212,
          "title": "\"[P]\" The Consilience Equation: Bridging Holism and Reductionism in Machine Learning and Biomimicry",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/163q8u2/machine_learning_courses_d/",
          "author": null,
          "description": "Hi. Recently I finished my Computer Science bachelors degree, while I learnt some machine learning in some courses I felt it was not too advanced. Now that I have some time I wanted to take some online courses with Certifications on Machine Learning, I wanted to know if anyone has any recomendations for some Machine Learning Courses (with certifications if possible) on coursera or udemy or similar. The one I'm most inclined now is: https://www.coursera.org/professional-certificates/ibm-machine-learning. Or maybe: https://www.coursera.org/specializations/machine-learning-introduction \n    submitted by    /u/Radoco152  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/163q8u2/machine_learning_courses_d/",
          "publishedOn": "2023-08-28T16:10:38.000Z",
          "wordCount": 2649,
          "title": "Machine Learning Courses [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/163oc6n/p_danswer_nlp_based_project_to_automatically/",
          "author": null,
          "description": "Slack questions are a huge time sink. For the person asking, they generally have no idea how to find the info and may not hear back for hours. For the person answering, it’s a distraction and often requires digging up old knowledge.\n The idea is simple: give an LLM your organizational context and plop it in Slack to answer things for you.\n DanswerBot is free to use and open source (MIT). You can connect it to Slack, Google Drive, GitHub, Confluence, Jira, local files, websites, and much more.\n Quick Demo Vid: https://youtu.be/EjDDvt5GbS8 \n Some additional neat features you may be interested in:\n  \nLLM generated answers backed by quotes to reduce hallucination\n \nSupports a wide range of LLMs (both open source and proprietary)\n \nMulti-Vector embeddings for accurate vector search\n \nBM-25 Keyword search\n \nLearning from user feedback\n \nCustom NLP model to classify user intent\n \nPolls your data sources every 10 minutes to keep knowledge up to date\n \nLinks back to your document sources\n \nDocument level access control\n \nAdmin dashboard to configure connectors to 14 (for now) of the most popular workplace tools\n \n If you aren’t a slack user (or if you just prefer a more tailored UI), there’s also a web interface to ask questions against your knowledge base. A short demo for that can be found at: https://youtu.be/cWWtnuVCUX0\n If you’re interested in testing this out yourself, the docs to help you launch Danswer with a single command can be found at https://docs.danswer.dev/quickstart!\n    submitted by    /u/Weves11  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/163oc6n/p_danswer_nlp_based_project_to_automatically/",
          "publishedOn": "2023-08-28T14:57:02.000Z",
          "wordCount": 2817,
          "title": "[P] Danswer: NLP based project to automatically answer Slack questions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/163n28f/d_open_problems_in_latent_spaceintrinsic_variables/",
          "author": null,
          "description": "I'm finishing my degree in Computer Science, and I need a good topic, does anyone know any open problems about latent space optimization, or finding the intrinsic variables of a system?\n    submitted by    /u/QLaHPD  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/163n28f/d_open_problems_in_latent_spaceintrinsic_variables/",
          "publishedOn": "2023-08-28T14:07:01.000Z",
          "wordCount": 2605,
          "title": "[D] Open problems in latent space/intrinsic variables",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/163mq0x/r_quantumnoisedriven_generative_diffusion_models/",
          "author": null,
          "description": "https://arxiv.org/abs/2308.12013\n  \nGenerative models realized with machine learning techniques are powerful tools to infer complex and unknown data distributions from a finite number of training samples in order to produce new synthetic data. Diffusion models are an emerging framework that have recently overcome the performance of the generative adversarial networks in creating synthetic text and high-quality images. Here, we propose and discuss the quantum generalization of diffusion models, i.e., three quantum-noise-driven generative diffusion models that could be experimentally tested on real quantum systems. The idea is to harness unique quantum features, in particular the non-trivial interplay among coherence, entanglement and noise that the currently available noisy quantum processors do unavoidably suffer from, in order to overcome the main computational burdens of classical diffusion models during inference. Hence, we suggest to exploit quantum noise not as an issue to be detected and solved but instead as a very remarkably beneficial key ingredient to generate much more complex probability distributions that would be difficult or even impossible to express classically, and from which a quantum processor might sample more efficiently than a classical one. Therefore, our results are expected to pave the way for new quantum-inspired or quantum-based generative diffusion algorithms addressing more powerfully classical tasks as data generation/prediction with widespread real-world applications ranging from climate forecasting to neuroscience, from traffic flow analysis to financial forecasting. \n  \n​\n    submitted by    /u/ghosthamlet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/163mq0x/r_quantumnoisedriven_generative_diffusion_models/",
          "publishedOn": "2023-08-28T13:53:08.000Z",
          "wordCount": 2795,
          "title": "[R] Quantum-Noise-driven Generative Diffusion Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/163m5hg/d_looking_for_suggestions_on_where_to_sell_a/",
          "author": null,
          "description": "So I have been tasked with finding a buyer for a couple high end machine learning servers. They were owned by my wife’s father who passed recently.\n The servers are powered by a couple Epyc 7003s and have A series gpus. We have invoices for them and VAT has been paid on everything.\n Basically, I’m looking for legit communities where I can find potential buyers preferably in the EU. \n Hopefully it’s ok to post this here. Also feel free to PM .\n    submitted by    /u/Obnomad  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/163m5hg/d_looking_for_suggestions_on_where_to_sell_a/",
          "publishedOn": "2023-08-28T13:29:14.000Z",
          "wordCount": 2662,
          "title": "[D] Looking for suggestions on where to sell a couple ML servers EU",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/163ljc6/change_of_degree_from_econ_d/",
          "author": null,
          "description": "Hi everyone, \n I’m currently doing my undergrad in Economics but am heavily interested in Compsci/Datasci and related topics. Though to be completely honest, I’m not completely sure which area my interests lie in. \n I was wondering if picking up coding/ theoretical knowledge that a com scientist or data scientist needs will be hard when I am already working. \n The question is if it is necessary to switch my degree to Math and Economics to gain a firmer foundation in the mathematical/ statistical concepts that ground com science. Or will an undergrad in Economics be sufficiently rigorous for me to pick up com sci/ data sci myself. \n For context, I’m thinking of taking courses on Real Analysis, Linear Algebra 2, Discrete Mathematics, Algorithms and Data Structures, Optimisation, Probability and Statistics.\n    submitted by    /u/smexy32123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/163ljc6/change_of_degree_from_econ_d/",
          "publishedOn": "2023-08-28T13:03:19.000Z",
          "wordCount": 2702,
          "title": "Change of degree from Econ [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/163ewre/d_google_gemini_eats_the_world_gemini_smashes/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/163ewre/d_google_gemini_eats_the_world_gemini_smashes/",
          "publishedOn": "2023-08-28T07:02:36.000Z",
          "wordCount": 2592,
          "title": "[D] Google Gemini Eats The World – Gemini Smashes GPT-4 By 5X, The GPU-Poors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/163dbj7/deci_introduces_decicoder_an_opensource/",
          "author": null,
          "description": "Deci has introduced DeciCoder, an open-source 1B-parameter large language model for code generation. This new model addresses the challenge of efficient code generation in the fast-paced world of AI, while also addressing concerns about energy consumption and operational costs.\n https://preview.redd.it/fpwnclb2fskb1.png?width=1680&format=png&auto=webp&s=a58e9b16902070c3f5a8efcf1cc24422852a4c35\n Why this matters:\n  \nDeciCoder is a transformative solution: It leverages cutting-edge architecture and AutoNAC™, a proprietary Neural Architecture Search technology, to generate optimal architectures. This results in an impressive architecture optimized for NVIDIA’s A10 GPU, which boosts throughput and rivals the accuracy of existing code generation models.\n DeciCoder is efficient and sustainable: …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/163dbj7/deci_introduces_decicoder_an_opensource/",
          "publishedOn": "2023-08-28T05:32:51.000Z",
          "wordCount": 2885,
          "title": "Deci Introduces DeciCoder: An Open-Source 1B-Parameter Large Language Model For Code Generation [N]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1637zq4/r_algorithm_of_thoughts_enhancing_exploration_of/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2308.10379\n Abstract:\n  \nCurrent literature, aiming to surpass the \"Chain-of-Thought\" approach, often resorts to an external modus operandi involving halting, modifying, and then resuming the generation process to boost Large Language Models' (LLMs) reasoning capacities. This mode escalates the number of query requests, leading to increased costs, memory, and computational overheads. Addressing this, we propose the Algorithm of Thoughts -- a novel strategy that propels LLMs through algorithmic reasoning pathways, pioneering a new mode of in-context learning. By employing algorithmic examples, we exploit the innate recurrence dynamics of LLMs, expanding their idea exploration with merely one or a few queries. Our technique outperforms earlier single-query methods and stands on par with a recent multi-query strategy that employs an extensive tree search algorithm. Intriguingly, our results suggest that instructing an LLM using an algorithm can lead to performance surpassing that of the algorithm itself, hinting at LLM's inherent ability to weave its intuition into optimized searches. We probe into the underpinnings of our method's efficacy and its nuances in application. \n  \nhttps://preview.redd.it/bc7l7gex2rkb1.jpg?width=1529&format=pjpg&auto=webp&s=4ed0dc528e998eeeab80fd4d9612d761065d7627\n https://preview.redd.it/wejr7lfx2rkb1.jpg?width=920&format=pjpg&auto=webp&s=386febcb60ff1db04b12e9e44856770d41bb9530\n https://preview.redd.it/gec0phex2rkb1.jpg?width=1241&format=pjpg&auto=webp&s=03096946aa65deee392c5f59b07fe340244ec0cd\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1637zq4/r_algorithm_of_thoughts_enhancing_exploration_of/",
          "publishedOn": "2023-08-28T01:09:45.000Z",
          "wordCount": 2763,
          "title": "[R] Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models - Microsoft 2023 - Far less queries with the same accuracy as Tree of Thought!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1636br6/p_gpt4_contextual_decomposition_template/",
          "author": null,
          "description": "Complex tasks with LLMs like ChatGPT/GPT4 are best broken down by first asking ChatGPT to outline the steps and then asking the LLM to execute against those steps that it defined. I first came across this interesting technique on Twitter recently.\n While it’s OK to do this once in OpenAI’s playground, it's difficult to make this repeatable and streamlined. When I wanted an LLM to do something complex, I wanted to be able to plug into a template instead of thinking about and setting up the contextual decomposition process.\n I made this Contextual Decomposition Template to help solve this problem: https://lastmileai.dev/workbooks/cllqfl5c600rdpgnhh2su2fa0\n With a document and objective, this template allows you to quickly get to the answer through defining intermediate steps and executing according. Parameters are set up so you can easily change the goal, document, and objective and click 'Run All' to get the final results.\n Please let me know if you have feedback! I'm also very curious if you have other interesting techniques with complex tasks and workflows working with LLMs.\n    submitted by    /u/InevitableSky2801  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1636br6/p_gpt4_contextual_decomposition_template/",
          "publishedOn": "2023-08-27T23:55:45.000Z",
          "wordCount": 2744,
          "title": "[P] GPT4 Contextual Decomposition Template",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1635c1o/d_questioning_the_nature_of_ai/",
          "author": null,
          "description": "submitted by    /u/SensitiveAd6425  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1635c1o/d_questioning_the_nature_of_ai/",
          "publishedOn": "2023-08-27T23:13:27.000Z",
          "wordCount": 2584,
          "title": "[D] Questioning the Nature of AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1634iuj/d_how_can_i_benchmark_my_pcgpu_and_compare_it_to/",
          "author": null,
          "description": "I have a RTX 2070 GPU and I'm wondering if there's any benchmarking tool where I can also see where others stand compared to the specs of my machine.\n    submitted by    /u/Al_Miksiki  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1634iuj/d_how_can_i_benchmark_my_pcgpu_and_compare_it_to/",
          "publishedOn": "2023-08-27T22:40:31.000Z",
          "wordCount": 2613,
          "title": "[D] How can I benchmark my PC/GPU and compare it to others online, sort of like 3DMark?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1633lrc/experience_with_pain_detection_approaches_p/",
          "author": null,
          "description": "​\n https://preview.redd.it/6t50ye377qkb1.png?width=1186&format=png&auto=webp&s=6def3f6ffdac50dc81d58b6f754366bf88570044\n    submitted by    /u/adamjbradley  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1633lrc/experience_with_pain_detection_approaches_p/",
          "publishedOn": "2023-08-27T22:04:26.000Z",
          "wordCount": 2573,
          "title": "Experience with pain detection approaches [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/163375m/puma_a_framework_for_secure_and_efficient/",
          "author": null,
          "description": "Concerns surrounding data privacy and security in AI have shifted to the limelight with the arrival of Large Language Models (LLMs). Despite the popularity of models like ChatGPT, potential drawbacks pose worries. Now, a new framework named PUMA promises to address these crucial concerns with an unprecedented touch of precision and efficiency.\n Can't keep track of this rapidly progressing tech world? Subscribe here to stay informed.\n https://preview.redd.it/tyr2mz3d4qkb1.png?width=1600&format=png&auto=webp&s=d8d771da5bbfa5cd53ab2823c5d7dad6f369109d\n What makes PUMA special?\n  \nAn ingenious approach: PUMA merges secure multi-party computation (MPC) with efficient inference, bridging the capabilities of Transformer models and security concerns.\n Redefining LLMs with three entities: the model…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/163375m/puma_a_framework_for_secure_and_efficient/",
          "publishedOn": "2023-08-27T21:49:01.000Z",
          "wordCount": 2886,
          "title": "PUMA: A framework for secure and efficient evaluation of Transformer models [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1632ue7/d_i_need_to_vectorize_100tb_of_data_multiple_gpus/",
          "author": null,
          "description": "TLDR: Is it ok to use two 4070ti's in a machine if all you need is more cuda cores to create embeddings and don't care about memory capacity, i.e. not for LLM's\n Background\n I have 20tb of text data (size in mongo) and 80tb of images (stored at 800x600-800) on my homelab on ssd's which i'm in the process of vectorizing and creating embeddings for. I have a 3090 with two python scripts, each script does the same thing, fetches a batch of records from mongo, grabs the image from the ssd, downsizes the image, creates embeddings, then uploads to qdrant (vector search engine) in a batch.\n ​\n Current setup\n  \nRyzen 9 7950x, 64gb ddr5, rtx 3090 -this is the one creating the embeddings currently.\n 1st gen 32 core epyc with 512gb ddr4 and ~200tb of ssd storage - holds all the data and databases and…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1632ue7/d_i_need_to_vectorize_100tb_of_data_multiple_gpus/",
          "publishedOn": "2023-08-27T21:35:27.000Z",
          "wordCount": 3197,
          "title": "[D] I need to vectorize 100tb+ of data, multiple GPU's per machine or multiple machines?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16327i2/d_kmeans_from_scratch_learning_ml/",
          "author": null,
          "description": "Hello everyone. I started to study some Machine Learning algorithms, specifically K-means, but I'm not sure if I did it correctly for several reasons:\n - In the Kmeans that I did, I normalize the data because they mention that it helps a lot, but if I don't, the algorithm stops classifying normally and shows me badly grouped points.\n - As I mentioned, when looking at the graphs of the grouped points, I can see how many of the points are clearly closer to certain centroids, but he classified them as others, this reaches the level of a misclassified point next to the centroid when that should belong\n - Despite the fact that it has a threshold to be making iterations, the algorithm ends in less than 10 even though it has placed 100 iterations. I know that it can depend on the dataset and the generated centroids, but it seems excessive to me that it ends so soon and with results like Iris datset (60, 13, 77) when it should be (50, 50, 50) or a minimum to be maintained for those values.\n I leave the code in GH in case someone can help me: https://github.com/vanstrouble/kmeans-from-scratch.git\n    submitted by    /u/vanstrouble  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16327i2/d_kmeans_from_scratch_learning_ml/",
          "publishedOn": "2023-08-27T21:11:49.000Z",
          "wordCount": 2770,
          "title": "[D] K-Means from scratch | Learning ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/162zw0w/poker_playing_robot_d/",
          "author": null,
          "description": "Hello, So for a project we wanted to create a robot that can play poker. This robot will first only be used on software but eventually we are hoping to add hardware. We want to be able to make two bots and put them agansit each other so they learn by machine learning. Once we find that they are skilled and understand we would like to be able to actually play them. I have heard of similiar projects to this online and on reddit. If anyone has any information about how to go about this or ideas, or just anything please let me know. I would love to have help on this project.\n    submitted by    /u/Jake1900ooo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/162zw0w/poker_playing_robot_d/",
          "publishedOn": "2023-08-27T19:44:21.000Z",
          "wordCount": 2684,
          "title": "Poker Playing Robot [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/162ypik/p_dlas_dataset/",
          "author": null,
          "description": "submitted by    /u/Why_is202  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/162ypik/p_dlas_dataset/",
          "publishedOn": "2023-08-27T18:56:43.000Z",
          "wordCount": 2579,
          "title": "[P] DLAS Dataset",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/162vx6j/d_how_to_structuremanage_a_machine_learning/",
          "author": null,
          "description": "I'm in the strange position of having the task of developing a machine learning pipeline/system/process in an academic environment without the benefit of much in the way of formal training in ML (I'm more of a classical stats for hypothesis testing kinda guy).\n The particular project is using machine learning on medical images (head CT scans) to detect a relatively rare condition. As usual the goal is to eventually have some automatic process for diagnosis support. This particular condition is something that diagnostic radiologists can always detect if they look in the right place on the image, the problem is that they often don't look in the right place. After talking to colleagues with more experience (but less time) it's something which in principle can be achieved with more or less \"off the shelf\" code put together in the right order and with appropriate hyperparameters.\n This stage of the project is aiming for a proof of principle, rather than anything deployable. We're lucky to have a decent amount of data inside a trusted research environment.\n I've done some hobby-level stuff and tutorials, but overall I'm coming into this with a lot more experience with medical imaging than with computer vision or machine learning.\n After all that preamble here's my question:\n What does a decent CV/ML experiment look like?\n Left to my own direction I can see myself picking 3 different approaches of varying complexity, trying to get the best out of each of them, and then presenting a comparison of performance or accuracy of all of them. I then claim the \"best one\" as the one we move on with.\n There are a lot of tools out there for experiment tracking (eg neptune.ai), but I'm really not sure whether that sort of thing is over the top for what I need to do.\n Any tips or experience that you folks don't mind sharing?\n    submitted by    /u/PrivateFrank  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/162vx6j/d_how_to_structuremanage_a_machine_learning/",
          "publishedOn": "2023-08-27T17:06:57.000Z",
          "wordCount": 2890,
          "title": "[D] How to structure/manage a machine learning experiment? (medical imaging)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/162uumz/d_limit_the_number_of_papers_i_review_on/",
          "author": null,
          "description": "Hello,\n Does anyone know if it's possible to set a limit to the number of papers you are assigned as a reviewer on OpenReview? Specifically for ICLR 2024. I saw a Twitter thread about this option before for ICML. It blows my mind that this is not easy to change. I got 5 papers for the last NeurIps which was very overwhelming. As reviewers, we provide a free service to the community, and we should be allowed to pick how much work we want to undertake...\n    submitted by    /u/cringe_reddit_user69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/162uumz/d_limit_the_number_of_papers_i_review_on/",
          "publishedOn": "2023-08-27T16:24:46.000Z",
          "wordCount": 2663,
          "title": "[D] Limit the Number of Papers I Review on OpenReview?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/162uty3/how_can_i_change_the_orientation_of_a_frame/",
          "author": null,
          "description": "Hi all. I'm hoping someone out there can help me solve this.\n TLDR: How do I change the orientation of portrait frames to landscape frames while keeping the mockup essence the same.\n Link: https://ibb.co/album/hx6wp3\n Basically, I have two portrait frame mockups that came in a bundle and the bundle had no landscape frame mockups at all. So, naturally I'd like to make my own since I have a lot of landscape artworks that could be displayed in the mockups.\n How can I change the orientation display of my mockup? I've tried using Photoshop's generative AI software and got nowhere. It keeps giving me a new frame design when I want to keep the original frame so it matches the set.\n Any leads on how this can be done would be appreciated.\n    submitted by    /u/Ambilina  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/162uty3/how_can_i_change_the_orientation_of_a_frame/",
          "publishedOn": "2023-08-27T16:24:03.000Z",
          "wordCount": 2724,
          "title": "How can I change the orientation of a frame mockup using AI? [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/162ubse/d_product_search_using_llm/",
          "author": null,
          "description": "Hey!One of my friends brought up an idea about using LLM for product search and we started talking about the idea and approach.\n Per my understanding what would need to be done is to train some smaller language model on the product data, create embeddings from the product info and make the model use this as a body of knowledge.\n My issue is that if this was ever to be done on commercial scale it seems very complex to me, since the embeddings would have to be re-created every time a new product is introduced?\n Let me know what you think or how you would approach this, as I'm trying to see different PoV's and everyone here has more experience than me.\n ​\n Thanks!\n    submitted by    /u/LukaAda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/162ubse/d_product_search_using_llm/",
          "publishedOn": "2023-08-27T16:04:35.000Z",
          "wordCount": 2695,
          "title": "[D] Product search using LLM",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/162snor/d_simple_questions_thread/",
          "author": null,
          "description": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n Thread will stay alive until next one so keep posting after the date in the title.\n Thanks to everyone for answering questions in the previous thread!\n    submitted by    /u/AutoModerator  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/162snor/d_simple_questions_thread/",
          "publishedOn": "2023-08-27T15:00:40.000Z",
          "wordCount": 2620,
          "title": "[D] Simple Questions Thread",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/162qu7b/r_new_preprint_on_detecting_errors_in_llm_prompt/",
          "author": null,
          "description": "We just released as study where we show that a \"diversity measure\" (e.g., entropy, Gini, etc.) can be used as a proxy for probability of failure in the response of an LLM prompt; we also show how this can be used to improve prompting as well as for prediction of errors.\n We found this to hold across three datasets and five temperature settings, tests conducted on ChatGPT.\n Preprint: https://arxiv.org/abs/2308.11189\n Source code: https://github.com/lab-v2/diversity_measures\n Video: https://www.youtube.com/watch?v=BekDOLm6qBI&t=10s\n ​\n Example result showing correlation of entropy with failure probaiblity\n    submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/162qu7b/r_new_preprint_on_detecting_errors_in_llm_prompt/",
          "publishedOn": "2023-08-27T13:45:38.000Z",
          "wordCount": 2660,
          "title": "[R] New preprint on detecting errors in LLM prompt response",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/162nzzy/d_do_papers_like_this_disprove_the_stochastic/",
          "author": null,
          "description": "https://arxiv.org/abs/2210.13382\n    submitted by    /u/30299578815310  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/162nzzy/d_do_papers_like_this_disprove_the_stochastic/",
          "publishedOn": "2023-08-27T11:32:11.000Z",
          "wordCount": 2595,
          "title": "[D] Do papers like this \"disprove\" the stochastic parrot theory? Pretty strong evidence that LLMs can build an internal world model, at least for simple board games.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/162nhne/p_give_me_ideas_on_visualization/",
          "author": null,
          "description": "I have written AI model to predict NHL games and now working on visualization. \n No tech talk, just visual, assume I gather all possible data. \n I would like to make it a prediction dashboard and not sport dashboard so simple stats are not recommended.\n Data on the image is made up, don't bother.\n I am using matplotlib + seaborne (Python)\n    submitted by    /u/Fifa_ToNieMiami  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/162nhne/p_give_me_ideas_on_visualization/",
          "publishedOn": "2023-08-27T11:05:38.000Z",
          "wordCount": 2644,
          "title": "[P] give me ideas on visualization.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/162naog/p_deepspeed_ulysses_system_optimizations_for/",
          "author": null,
          "description": "submitted by    /u/ghosthamlet  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/162naog/p_deepspeed_ulysses_system_optimizations_for/",
          "publishedOn": "2023-08-27T10:55:28.000Z",
          "wordCount": 2592,
          "title": "[P] DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/162lo62/r_challenges_and_applications_of_large_language/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2307.10169\n Abstract:\n  \nLarge Language Models (LLMs) went from non-existent to ubiquitous in the machine learning discourse within a few years. Due to the fast pace of the field, it is difficult to identify the remaining challenges and already fruitful application areas. In this paper, we aim to establish a systematic set of open problems and application successes so that ML researchers can comprehend the field's current state more quickly and become productive. \n  \nhttps://preview.redd.it/sng6uk7tcmkb1.jpg?width=657&format=pjpg&auto=webp&s=2ed693a88097cc8cbcd72ecd8c0d36820629625d\n https://preview.redd.it/wslkgm7tcmkb1.jpg?width=478&format=pjpg&auto=webp&s=9908f28717c8bd98d48d4559ccc2db9cc3796bee\n https://preview.redd.it/12q01l7tcmkb1.jpg?width=471&format=pjpg&auto=webp&s=1ca1eb54f679cf8a12f10aaf790d607db7bb363c\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/162lo62/r_challenges_and_applications_of_large_language/",
          "publishedOn": "2023-08-27T09:22:39.000Z",
          "wordCount": 2656,
          "title": "[R] Challenges and Applications of Large Language Models - University College London 2023 - 72 Pages!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/162kl1o/project_uformv2_tiny_cliplike_embeddings_in_21/",
          "author": null,
          "description": "Vision-Language understanding Transformer, which has 40% fewer parameters than vanilla CLIP while performing much better on text-to-image retrieval, where it's also beneficial that output embeddings have 2x fewer dimensions (256 vs 512).\n Moreover, it supports 21 languages, including popular English, Hindi, Chinese, Arabic, and lower-resource languages like Ukrainian, Hebrew, and Armenian.\n Demo: http://usearch-images.com/\n Github: https://github.com/unum-cloud/uform \n https://i.redd.it/6133eyj73mkb1.gif\n    submitted by    /u/vov_or  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/162kl1o/project_uformv2_tiny_cliplike_embeddings_in_21/",
          "publishedOn": "2023-08-27T08:18:43.000Z",
          "wordCount": 2633,
          "title": "[Project] UForm-v2: tiny CLIP-like embeddings in 21 languages with extreme performance",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/162ie7n/d_how_is_a_language_model_applied_on_speechtotext/",
          "author": null,
          "description": "I'm new to speech processing. As I read the paper on wav2vec 2.0, I see them mentioning the use of language models in decoding, particularly a 4-gram model and a Transformer. As far as I'm aware, the encoder (wav2vec2) will output a probability sequence of L x V (where V is the vocab size, L is sequence length). I have two questions:\n  \nI learned that a n-gram language model would predict the probability of a n-gram given previous context words, but how is a Transformer implemented here ? Does it follow a causal structure such as GPT and then estimate sequence likelihood ?\n How can a language model, trained to estimate next word (n-gram) probability given previous context, be used to decode the output sequence given the L x V probability outputs from above ?\n  \nMany thanks !\n    submitted by    /u/KarmaCut132  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/162ie7n/d_how_is_a_language_model_applied_on_speechtotext/",
          "publishedOn": "2023-08-27T06:09:36.000Z",
          "wordCount": 2720,
          "title": "[D] How is a language model applied on Speech-to-text models such as Wav2Vec 2.0 ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/162fm16/r_dfa3d_3d_deformable_attention_for_2dto3d/",
          "author": null,
          "description": "We introduce a new operator, called 3D DeFormable Attention (DFA3D), for 2D-to-3D feature lifting, which transforms multi-view 2D image features into a unified 3D space for 3D object detection.\n ​\n Comparisons of feature lifting methods.\n Existing feature lifting approaches, such as Lift-Splat-based and 2D attention-based, either use estimated depth to get pseudo LiDAR features and then splat them to a 3D space, which is a one-pass operation without feature refinement, or ignore depth and lift features by 2D attention mechanisms, which achieve finer semantics while suffering from a depth ambiguity problem.\n In contrast, our DFA3D-based method first leverages the estimated depth to expand each view's 2D feature map to 3D and then utilizes DFA3D to aggregate features from the expanded 3D feature maps. With the help of DFA3D, the depth ambiguity problem can be effectively alleviated from the root, and the lifted features can be progressively refined layer by layer, thanks to the Transformer-like architecture. In addition, we propose a mathematically equivalent implementation of DFA3D which can significantly improve its memory efficiency and computational speed. We integrate DFA3D into several methods that use 2D attention-based feature lifting with only a few modifications in code and evaluate on the nuScenes dataset. The experiment results show a consistent improvement of +1.41\\% mAP on average, and up to +15.1\\% mAP improvement when high-quality depth information is available, demonstrating the superiority, applicability, and huge potential of DFA3D.\n 🔥 Code: https://github.com/IDEA-Research/3D-deformable-attention.git\n 🔥 Paper: https://arxiv.org/abs/2307.12972\n    submitted by    /u/HYeung_Lee  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/162fm16/r_dfa3d_3d_deformable_attention_for_2dto3d/",
          "publishedOn": "2023-08-27T03:42:22.000Z",
          "wordCount": 2814,
          "title": "[R] DFA3D: 3D Deformable Attention For 2D-to-3D Feature Lifting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/162e4hp/shanghai_ai_lab_and_ntu_unveil_matlaber_a_pioneer/",
          "author": null,
          "description": "AI researchers from Shanghai AI Laboratory and Nanyang Technological University are breaking new ground with their creation of MATLABER, an innovative text-to-3D pipeline.\n If you want to stay ahead of the curve in AI and tech, look here first.\n https://preview.redd.it/8walduw7dkkb1.png?width=806&format=png&auto=webp&s=4908181a408d990ed224a503a63d78d204e460be\n Why this matters:\n  \nText-to-3D pipelines are a hot topic in AI Change: The ability to create 3D assets from textual descriptions can revolutionize the industry, reducing time, labor, and skill requirements.\n MATLABER conquers a longstanding issue: Overcoming the challenge of restoring high-fidelity object materials in text-to-3D pipelines, MATLABER expands the applicability of these technologies in real-world scenarios.\n Material-aw…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/162e4hp/shanghai_ai_lab_and_ntu_unveil_matlaber_a_pioneer/",
          "publishedOn": "2023-08-27T02:28:10.000Z",
          "wordCount": 2849,
          "title": "Shanghai AI Lab and NTU Unveil MATLABER: A Pioneer in Text-To-3D Creation [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/162e24j/r_new_diffusion_model_for_music_generation/",
          "author": null,
          "description": "submitted by    /u/jmoso13  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/162e24j/r_new_diffusion_model_for_music_generation/",
          "publishedOn": "2023-08-27T02:24:59.000Z",
          "wordCount": 2572,
          "title": "[R] new diffusion model for music generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1628lcl/getting_random_latents_in_w_space_d/",
          "author": null,
          "description": "I'm trying to get roll, pitch, yaw directions in W+ space. Initially, I need like 10k generated images, which I'll get top %5 and bottom %5 for the features I want. I tried to sample from uniform distribution but it fails since W+ is not uniformly distributed. How do I achieve this?\n    submitted by    /u/cltexe  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1628lcl/getting_random_latents_in_w_space_d/",
          "publishedOn": "2023-08-26T22:21:13.000Z",
          "wordCount": 2626,
          "title": "Getting random latents in W+ space [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16285pb/d_an_ais_response_to_consciousness_in_artificial/",
          "author": null,
          "description": "submitted by    /u/ronin_zz123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16285pb/d_an_ais_response_to_consciousness_in_artificial/",
          "publishedOn": "2023-08-26T22:03:51.000Z",
          "wordCount": 4677,
          "title": "[D] An AI's response to: \"Consciousness in Artificial Intelligence: Insights from the Science of Consciousness.\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1627x36/discussion_llms_in_business/",
          "author": null,
          "description": "Every business on the planet will want to train and feed its own LLM asap to not fall behind.\n \\super computer = tech needed to train a LLM fast on unlimited data*\n (1) Does a company like McKinsey (confidential data) train their LLM in-house or in the cloud?\n (2) Do enough super computers exist for every company to start training their LLM today?\n (3) Is there even a single company that ships super computers capable of training LLMs in-house?\n (4) McKinsey will want to train their LLMs on all data they have from their customers so that McKinsey can work at max efficiency. Customers won't like that. Is it possible to un-train specific data sets?\n (5) Would it be possible to feed the LLM with the customer's data instead of training the LLM on the data? What would be the differences? If you feed it the data, then the LLM can't work with the data as well as it could if you trained it on said data?\n The future is just so damn exciting and I have all these questions popping up so I hope some educated folks can share some insights! Thanks for reading!\n    submitted by    /u/MopPanda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1627x36/discussion_llms_in_business/",
          "publishedOn": "2023-08-26T21:54:31.000Z",
          "wordCount": 2766,
          "title": "[Discussion] LLMs in business",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1627q6a/d_was_trying_out_llama2_13b_megacode2_oasst_on_my/",
          "author": null,
          "description": "https://im3.ezgif.com/tmp/ezgif-3-b05ffc9d5f.gif\n    submitted by    /u/theswiftdeveloper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1627q6a/d_was_trying_out_llama2_13b_megacode2_oasst_on_my/",
          "publishedOn": "2023-08-26T21:46:48.000Z",
          "wordCount": 2580,
          "title": "[D] Was trying out Llama2 13B MegaCode2 OASST on my local pc",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/162708d/d_comparing_scorebased_and_diffusion_models_in/",
          "author": null,
          "description": "In theory, it has been demonstrated that score matching models and diffusion models share mathematical similarities. However, in practice, the equivalence between the two approaches may not extend to code implementations. While PyTorch implementations for diffusion models are relatively common, finding equivalent implementations for score-based models can be more challenging.\n    submitted by    /u/whysomeonetookmyname  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/162708d/d_comparing_scorebased_and_diffusion_models_in/",
          "publishedOn": "2023-08-26T21:18:39.000Z",
          "wordCount": 2627,
          "title": "[D] Comparing Score-Based and Diffusion Models in Theory and Practice",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1625oos/d_industry_design_patterns_for_fastmoving_mldl/",
          "author": null,
          "description": "I have been writing ML code (both training and off-the-shelf model inferences) for close to six years now, but mostly in an academic/personal project setting.\n Now, I find myself spearheading an ML project at a big company, and our backend code base keeps growing, and other people depend on it. There are layers to it, with threads spawning, and dependencies on caches and databases for state sharing. It's more than a pet project - you get the gist. I want to design production-ready architectures that are more robust than piecemeal/make-shift solutions. \n Do people have resources or suggestions on what established design patterns work in the industry? I have found it hard to find resources just by googling because the pace at which ML research works makes most books/tutorials outdated. Take retrieval augmented generation, for example. Do you store your documents in an elasticsearch store and build indices periodically or do you store them in FAISS? How separated is your retrieval module from your LLM call? Do you host in-house LLM's centrally company-wide or per-project?\n What has worked for you so far in the industry?\n    submitted by    /u/whyusenosqlreddit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1625oos/d_industry_design_patterns_for_fastmoving_mldl/",
          "publishedOn": "2023-08-26T20:26:43.000Z",
          "wordCount": 2758,
          "title": "[D] Industry design patterns for fast-moving ML/DL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1624u67/d_how_do_you_normalize_a_large_taxonomy_with_lot/",
          "author": null,
          "description": "I have a large taxonomy of work titles I scraped from linkedin and other career sites. Now I ahve like 90k titles. To reduce them or group them into a sort of 5k unique titles I tried k means clustering but didn't work out good. How do I proceed with this task? Any pointers would be appreciated.\n    submitted by    /u/wet_cosplay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1624u67/d_how_do_you_normalize_a_large_taxonomy_with_lot/",
          "publishedOn": "2023-08-26T19:52:39.000Z",
          "wordCount": 2637,
          "title": "[D] How do you normalize a large taxonomy with lot of similar words.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1623pwh/r_neo_360_neural_fields_for_sparse_view_synthesis/",
          "author": null,
          "description": "submitted by    /u/KaleidoscopeBest1569  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1623pwh/r_neo_360_neural_fields_for_sparse_view_synthesis/",
          "publishedOn": "2023-08-26T19:08:13.000Z",
          "wordCount": 2577,
          "title": "[R] NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1622vzw/research_scholars_program/",
          "author": null,
          "description": "Hi everyone.\n We recently announced the Cohere For AI scholars program, a 8 month full-time paid industry research role to join our team and work on fundamental machine learning at scale. The goal is to support rising stars in ML pursue curiosity driven research w access to large scale engineering resources and mentorship. We have intentionally structured the program to be paid and remote-first so we can support talent all across the world. You will have access to a top tier research team and you can find some of our prior publications here.\n Our deadline is coming up on September11th. Wanted to make sure this was visible to researchers around the world, and thought many in this forum would be interested. \n More details below for anyone interested:\n The Cohere For AI Scholars Program supports the next generation of rising ML stars as they embark on their research journey by providing an alternative point of entry into NLP research. Scholars will have access to a large-scale experimental framework and work alongside some of the best researchers and engineering expertise in the world. Participation is full-time, remote-first and paid. For more details, check out our blog post announcing the Scholars Program launch. Applications are open until September 11, 2023.\n For those undertaking application, would highly recommend joining our open science discord where we have a highly active FAQ channel for any questions about the program. You can find out more about how to join at cohere.for.ai.\n Looking forward to reading your applications!\n    submitted by    /u/ml_magic_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1622vzw/research_scholars_program/",
          "publishedOn": "2023-08-26T18:36:02.000Z",
          "wordCount": 2820,
          "title": "[Research] Scholars Program",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1622vv7/d_how_does_a_ml_model_differentiate_between/",
          "author": null,
          "description": "Suppose I have data about cars. In it there are multiple columns like 'Type' which contains \"Sedan\", \"Hatchback\", \"Convertible\" and \"Minivan\". Then there are 'Color' like \"Red\", \"White\", \"Blue\", etc.\n And I have used ordinal encoding for 'Types' columns and label for 'Color' column. How will the model know that Types is ordinal while Color is nominal.\n PS. Suppose I cannot use One Hot encoding as it will increase the no of columns by 20 or 30.\n    submitted by    /u/Luffykent  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1622vv7/d_how_does_a_ml_model_differentiate_between/",
          "publishedOn": "2023-08-26T18:35:53.000Z",
          "wordCount": 2655,
          "title": "[D] How does a ML model differentiate between Nominal and Ordinal?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/162171d/uk_startup_etcembly_unveils_aidesigned_cancer/",
          "author": null,
          "description": "Etcembly, a UK-based biotech startup, has disclosed one of the first generative AI-designed immunotherapy candidates, known to target a protein present in many cancers.\n If you want to stay on top of the latest trends and insights in AI and tech, look here first.\n https://preview.redd.it/n6nwoeloohkb1.jpg?width=1200&format=pjpg&auto=webp&s=defa11280ea75f1e6e26ff9014b7e673b0a181ea\n Key highlights:\n  \nEtcembly's AI-designed immunotherapy is innovative: The startup used generative AI to design novel cancer immunotherapy in record time. The therapeutic 'ETC-101' was created and optimized in just 11 months, compared to the traditional two years typically needed.\n The value of AI makes itself evident: Etcembly's AI engine, EMLy, uses LLMs to predict, design, and validate candidate TCRs, scanning…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/162171d/uk_startup_etcembly_unveils_aidesigned_cancer/",
          "publishedOn": "2023-08-26T17:29:16.000Z",
          "wordCount": 2904,
          "title": "UK Startup Etcembly Unveils AI-Designed Cancer Immunotherapy [N]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1620m3p/understanding_the_constraint_of_weight_sums_in/",
          "author": null,
          "description": "Working on a machine-learning task with a dataset full of noisy labels. Thinking of using reweighted loss to tackle the label noise issue. I get that it helps give more importance to clean samples during training. But, about the sum of these weights used in the loss function - should they always add up to 1? What's the reasoning behind this constraint? Can't the weights sum up to any positive value instead? Also, if I intend to assign loss values with probabilities, does the weighted sum still need to be 1? Need help clarifying if my understanding is correct!\n    submitted by    /u/Positive_External_27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1620m3p/understanding_the_constraint_of_weight_sums_in/",
          "publishedOn": "2023-08-26T17:05:41.000Z",
          "wordCount": 2681,
          "title": "Understanding the Constraint of Weight Sums in Loss Functions for Noisy Label Learning [Discussion], [Question]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/161wfjd/r_to_compress_or_not_to_compress_selfsupervised/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/161wfjd/r_to_compress_or_not_to_compress_selfsupervised/",
          "publishedOn": "2023-08-26T14:17:32.000Z",
          "wordCount": 2592,
          "title": "[R] To Compress or Not to Compress- Self-Supervised Learning and Information Theory: A Review",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/161vyr6/d_rlhf_on_diffusion_models_vision_models/",
          "author": null,
          "description": "Recently came across: https://datasciencecastnet.home.blog/2023/04/06/a-recipe-for-training-good-generative-models/ and this paper: https://arxiv.org/pdf/2302.08242.pdf\n The first article is very interesting as it suggests incorporating RLHF in the stack of building a strong diffusion model, the second article demonstrates that it is possible to create stronger computer vision systems with further fine-tuning on metrics (reward functions) that are not differentiable (!), such as mAP for object detection, which I personally found super interesting. These observations makes me think the \"general\" recipe to build a very good AI model (not only restricted to LLMs) is pretty aligned with what has been done with ChatGPT : 1- supervise fine-tune on a target domain / 2- design & build a reward model / 3- Further align the generations & output with RL\n Just curious if anyone has any experience with RL + diffusion & vision models? Why do you think this is not super popular yet?\n    submitted by    /u/mzitoune  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/161vyr6/d_rlhf_on_diffusion_models_vision_models/",
          "publishedOn": "2023-08-26T13:58:26.000Z",
          "wordCount": 2721,
          "title": "[D] RL[HF] on diffusion models & vision models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/161vupw/d_rlhf_diffusion_models_vision_models/",
          "author": null,
          "description": "Recently came across: https://datasciencecastnet.home.blog/2023/04/06/a-recipe-for-training-good-generative-models/ and this paper: https://arxiv.org/pdf/2302.08242.pdf \n The first article is very interesting as it suggests incorporating RLHF in the stack of building a strong diffusion model, the second article demonstrates that it is possible to create stronger computer vision systems with further fine-tuning on metrics (reward functions) that are not differentiable (!), such as mAP for object detection, which I personally found super interesting. These observations makes me think the \"general\" recipe to build a very good AI model (any modality) is pretty aligned with what has been done with ChatGPT : 1- supervise fine-tune on a target domain / 2- design / build a reward model / 3- Align the generations / output with RL\n Just curious if anyone has any experience with RL + diffusion & vision models? Why do you think this is not super popular yet?\n ​\n  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/161vupw/d_rlhf_diffusion_models_vision_models/",
          "publishedOn": "2023-08-26T13:53:34.000Z",
          "wordCount": 2717,
          "title": "[D] RL(HF) + diffusion models & vision models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/161uiz8/n_beating_gpt4_on_humaneval_with_a_finetuned/",
          "author": null,
          "description": "Blog: https://www.phind.com/blog/code-llama-beats-gpt4\n Models:\n https://huggingface.co/Phind/Phind-CodeLlama-34B-Python-v1\n https://huggingface.co/Phind/Phind-CodeLlama-34B-v1\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/161uiz8/n_beating_gpt4_on_humaneval_with_a_finetuned/",
          "publishedOn": "2023-08-26T12:56:09.000Z",
          "wordCount": 2581,
          "title": "[N] Beating GPT-4 on HumanEval with a Fine-Tuned CodeLlama-34B",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/161tazs/p_llama_2_codellama_and_gpt4_performance_a/",
          "author": null,
          "description": "submitted by    /u/seraschka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/161tazs/p_llama_2_codellama_and_gpt4_performance_a/",
          "publishedOn": "2023-08-26T11:59:18.000Z",
          "wordCount": 2593,
          "title": "[P] Llama 2, CodeLlama, and GPT-4 performance: A write-up on the LLM developments and research.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/161t9iu/d_recursive_least_squares_vs_gradient_descent_for/",
          "author": null,
          "description": "I have been captivated by Recursive Least Squares (RLS) methods, particularly the approach that employs error prediction instead of matrix inversion. This method is quite intuitive. Let's consider a scenario where you need to estimate the true effect of four factors (color, gender, age, and weight) on blood sugar. To find the true impact of weight on blood sugar, it's necessary to eliminate the influence of every other factor on weight. This can be accomplished by using simple least squares regression to predict the residual errors recursively, as shown in the diagram below:\n Removing the effect of all factors on \\\"weight\\\" in a recursive manner\n The fundamental contrast between RLS and Gradient-based methods lies in how errors are distributed across inputs based on their activity, leading to the subsequent update of weights. However, in the case of RLS, all inputs undergo decorrelation before evaluating prediction errors. \n Comparison between error sharing in RLS and GD\n This de-correlation can be done in few lines of python code:\n for i in range(number_of_factors):\n for j in range(i+1, number_of_factors): \n wx = np.sum(x[i] * x[j]) / np.sum(x[i]**2) \n x[j] -= wx * x[i] \n This approach also bears relevance to predictive coding and can shed light on intriguing neuroscientific findings, such as the increase brain activity during surprising or novel events — attributable to prediction errors.\n The prediction errors are increasing during the surprising events similar to how brain activity increases.\n RLS learns very fast but it's still subpar to deep learning when it comes to non-linear hierarchical structures but that is probably because Gradient based methods enjoyed more attention and tinkering from the ML-community. I think RLS methods needs more attention and I have been working on some research projects that uses this method for signal prediction . If you're interested, you can find the source code here:\n https://github.com/hunar4321/RLS-neural-net\n ​\n    submitted by    /u/brainxyz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/161t9iu/d_recursive_least_squares_vs_gradient_descent_for/",
          "publishedOn": "2023-08-26T11:57:11.000Z",
          "wordCount": 2878,
          "title": "[D] Recursive Least Squares vs Gradient Descent for Neural Networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/161s6rm/p_llama_explained_kvcache_rotary_positional/",
          "author": null,
          "description": "submitted by    /u/hkproj_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/161s6rm/p_llama_explained_kvcache_rotary_positional/",
          "publishedOn": "2023-08-26T11:02:34.000Z",
          "wordCount": 2577,
          "title": "[P] LLaMA explained: KV-Cache, Rotary Positional Embedding, RMS Norm, Grouped Multi-Query Attention",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/161rq93/discussion_what_model_to_choose_for_a_nn_with_a/",
          "author": null,
          "description": "The input of my neural network consists of 20 features, whereas the output consists of 20,000 of them (predicting a \"quantum classical shadow\" based on a few parameters: the rotation angle as the input and a few hundreds of shots of random measurements as the output). AFAIK, it's a linear regression problem.\n What I've tried:\n - an FCNN (doesn't work good);\n - Scikit-Learn Lasso (the same results);\n - MSE regression using Neural Tangents (the same).\n Any ideas on how to solve this?\n Thanks a lot in advance!\n    submitted by    /u/avpol111  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/161rq93/discussion_what_model_to_choose_for_a_nn_with_a/",
          "publishedOn": "2023-08-26T10:38:16.000Z",
          "wordCount": 2668,
          "title": "[Discussion] What Model to Choose for a NN with a Very Wide Output Layer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/161royk/d_whats_the_best_model_for_iterative_ranking/",
          "author": null,
          "description": "There are many entities: A, B, C, D... (< 10,000 entities)\n There can be a comparison of a pair with two entities resulting in a winner and a loser: A > B; C > A; D > C; ...\n A comparison is expensive.\n Objective: to approximate the absolute order of entities (best entities at the top of the list, worst at the bottom), minimize the number of comparisons\n The worst solution would be just applying a sorting algorithm, which would require n log n comparisons.\n I believe an active sampling technique would be required, i.e. select a number of entities with the highest uncertainty, and do comparisons with them, adjust the model, repeat.\n ChatGPT suggests a Bradley-Terry model and even gives an implementation example. I wonder if there is anything better?\n    submitted by    /u/gintrux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/161royk/d_whats_the_best_model_for_iterative_ranking/",
          "publishedOn": "2023-08-26T10:36:13.000Z",
          "wordCount": 2710,
          "title": "[D] What's the best model for iterative ranking determination from pairwise comparisons?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/161q13s/r_simpler_decision_tree_implementation_question/",
          "author": null,
          "description": "I am trying to implement a decision tree in a very computationally dumb software which can only execute if else statements. If the decision tree is trained some place else and then shared to this software could I deploy the model as a bunch of if else statements. If so how would I know the exact comparison order which would be needed for the if else statements and since this would require to know every detail of the decision tree would I have to make the whole algorithm from scratch so I can access every nook of the decision tree or is there a library which let me access every weight and know what's the weight of each branch? Sorry if it's a dumb question.\n    submitted by    /u/ghostfreak999  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/161q13s/r_simpler_decision_tree_implementation_question/",
          "publishedOn": "2023-08-26T09:03:05.000Z",
          "wordCount": 2698,
          "title": "[R] Simpler decision tree implementation question?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/161hty2/apple_researchers_propose_a_novel_method_for/",
          "author": null,
          "description": "Traditional methods of creating 3D models from images often rely on estimating the depth of each pixel in the image, which can result in errors or missing details in areas that are transparent or have low texture. A team of researchers from Apple and UCSB have proposed a new method that directly infers the 3D geometry of a scene using deep neural networks, without requiring any test-time optimization.\n If you want to stay on top of the latest trends and insights in AI and tech, look here first.\n https://preview.redd.it/pqxjeafi0dkb1.png?width=748&format=png&auto=webp&s=8daefa852a8805b48cc8586a4a8ec94e5e49123c\n Why this matters:\n  \n3D reconstruction is a fundamental problem in computer vision and graphics: it has many applications in entertainment, education, medicine, and engineering. Howe…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/161hty2/apple_researchers_propose_a_novel_method_for/",
          "publishedOn": "2023-08-26T01:44:10.000Z",
          "wordCount": 3050,
          "title": "Apple researchers propose a novel method for creating detailed 3D models from images [R]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/161ebgn/d_i_need_help_in_machine_learning_journey/",
          "author": null,
          "description": "Hello guys, I'm a newbie in machine learning and I'm really confused right now about where to start my machine learning journey, i want to know what kind of programming language is best for me to begin with I have some knowledge of Python.\n I'm planning to dive in-depth into generative AI and recommendation systems and Machine learning in finance. i will be glad to get as much advice as I can get for me to progress in this journey. thanks \n    submitted by    /u/fikayomiayo1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/161ebgn/d_i_need_help_in_machine_learning_journey/",
          "publishedOn": "2023-08-25T23:09:02.000Z",
          "wordCount": 2656,
          "title": "[D] i need help in machine learning journey",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/161cdl2/d_what_are_current_hottest_topics_for_research/",
          "author": null,
          "description": "Hi, EE senior bachelor student here.\n Over past 1.5 year, I passed many general ML courses and did many projects with the main focus on CV and I'm currently learning Generative models (GAN right now).\n I have plans to start doing research with other people around the world after this summer and work on and publish some papers if possible.\n my question is, what are the current hottest topics for research?\n Diffusion models (in case of generative vision models)? LLMs? what else?\n    submitted by    /u/Neotod1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/161cdl2/d_what_are_current_hottest_topics_for_research/",
          "publishedOn": "2023-08-25T21:51:17.000Z",
          "wordCount": 2657,
          "title": "[D] what are current hottest topics for research?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/161c7zm/discussion_should_religionbased_workshops_exist/",
          "author": null,
          "description": "Over the years, ML conferences had a lot of workshops such as women in ML, LatinXAL etc. that are aimed at increasing the diversity in the ML community. I've always been supportive of these workshops as I've seen first-hand how some of them face obstacles just based on their gender or ethnicity. \n However, I recently saw a tweet for Muslim in ML workshop at NeurIPS and I am not sure how to feel about it. They say it's a workshop meant for \"those who self-identify as Muslim, or work on research that address challenges faced by Muslims\". I am not exactly sure what they mean by research that address challenges faced by Muslims. Over that, I don't think religion-based workshops in a science conference is a good idea. I think religion should be kept out of science, and I don't know if tomorrow n different religion based workshops are going to popup. \n Like I said, I'm not completely sure if I'd support such a workshop or not, but I'd love to hear what other folks in ML research community think about it. Before someone calls me Islamophobic, I'm talking about any religion-based workshop in general, not just Muslim in ML. I'd have made this post even if I saw a Christian in ML or Jews in ML workshop. \n ​\n    submitted by    /u/lolillini  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/161c7zm/discussion_should_religionbased_workshops_exist/",
          "publishedOn": "2023-08-25T21:45:19.000Z",
          "wordCount": 2793,
          "title": "[Discussion] Should religion-based workshops exist in ML conferences",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/161c7q7/p_codenames_multiagent_rl_competition_project/",
          "author": null,
          "description": "We've been working on a competition to develop agents for Codenames. RL agents play games against human players, and both human and RL agents are compared using an ELO-like system. We're giving out compute credit and cash prizes to model developers and human players. \n We're sharing with the /r/MachineLearning community in case there's interest :) If you have feedback about the concept, or platform, or competition, we'd also love to hear it. \n https://playgroundrl.com/codenames \n    submitted by    /u/YodelingVeterinarian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/161c7q7/p_codenames_multiagent_rl_competition_project/",
          "publishedOn": "2023-08-25T21:45:03.000Z",
          "wordCount": 2646,
          "title": "[P] Codenames Multi-Agent RL Competition Project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/161bbpz/discussion_does_anyone_else_feel_like_ml_might_be/",
          "author": null,
          "description": "I read A thousand brains by Jeff Hawkins and some of their papers last year. It made me think a lot more about whether the current road that much of AI is going down - huge LLM's, will actually result in a real breakthrough in terms of a more general AI. A model that can perform unsupervised online learning, work with any kind of input, and actually reason rather than predict (will chat GPT ever be able to count?).\n In the book, one of the things Jeff Hawkins touches on is that current ML architectures don't actually model the brain as closely as we thought, and that hierarchical structures arn't as important as thought and instead many individual models are used. This was worrying to read considering most ML models use many layers to function.\n I'm a compsci major that focused on ML but I wonder what more experienced and knowledgeable people think about the current direction things are going in?\n ​\n    submitted by    /u/djdylex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/161bbpz/discussion_does_anyone_else_feel_like_ml_might_be/",
          "publishedOn": "2023-08-25T21:10:06.000Z",
          "wordCount": 2746,
          "title": "[Discussion] Does anyone else feel like ML might be backing itself into a corner - far from GAI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1619ew8/p_about_internship_project_and_need_help/",
          "author": null,
          "description": "I've joined a bootcamp and then selected to the workshop. But both online courses and workshop had lack of code practice so that I couldn't improve my coding skills. I've nearly 1 day to send them the github link and the read.md file. Is there any problem if I benefit (I mean copypasta) from chat gpt. I've been in a web development workshop of an unicorn company and one of our first lesson was using chat gpt effectively and since then I feel couraged enough to work with chat gpt while coding on my own and it is really efficently . Is there any problem occures if I use chat gpt in order to complete my project?\n    submitted by    /u/MistikPornoTapinagi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1619ew8/p_about_internship_project_and_need_help/",
          "publishedOn": "2023-08-25T19:57:19.000Z",
          "wordCount": 2691,
          "title": "[P] About internship project and need help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16193au/ai_outperforms_students_in_university_assignments/",
          "author": null,
          "description": "A recent study published in Scientific Reports has found that ChatGPT can match or even exceed the performance of students when answering assessment questions across a range of subjects.\n If you want to stay on top of the latest trends and insights in AI and tech, look here first.\n https://preview.redd.it/gpdbew668bkb1.jpg?width=1200&format=pjpg&auto=webp&s=db0ec21b9ed3b4e752f3f1769bc1f57a0cab3f8e\n Why this matters:\n  \nAI is becoming a popular tool for students: The study found that 74% of students surveyed would use ChatGPT to help with their assignments.\n Educators view AI use as plagiarism: Despite its popularity among students, 70% of educators view the use of AI like ChatGPT in schoolwork as plagiarism.\n AI can outperform students in many courses: In the study, ChatGPT-generated answers achieved a similar or higher average grade than students in 12 out of 32 courses—with maths and economics being the only two disciplines where students consistently outperformed AI.\n  \nChatGPT’s performance review:\n  \nStrong performance on factual knowledge questions: Unsprisingly, ChatGPT outperformed the students on questions requiring factual knowledge.\n Struggles with trick questions: The AI model struggled most where trick questions were included in the assignment.\n AI-text classifiers struggle to detect AI use: Current AI-text classifiers cannot reliably detect ChatGPT’s use in schoolwork.\n  \nThe main takeaway:\n  \nEducational institutions need to adapt: These findings suggest that evaluating students through homework assignments may no longer serve its purpose in the age of AI.\n Need for academic integrity policies: Educational institutions need to craft appropriate academic integrity policies as a means of regulation.\n  \nP.S. If you find this kind of analysis interesting, I write a free newsletter on AI and tech that you’d love.\n (source)\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16193au/ai_outperforms_students_in_university_assignments/",
          "publishedOn": "2023-08-25T19:44:28.000Z",
          "wordCount": 2837,
          "title": "AI Outperforms Students in University Assignments [N]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1618csc/p_nlp_tennis_data_task/",
          "author": null,
          "description": "Made this post in rdatascience, but was wondering if anyone here could help\n I'm currently a data science apprentice so apologies if I come across as a bit naïve in this area. This project is solo and pro-bono but I don't want to submit low-quality work.\n Overall goal of the project: \"Should [X Type] courts be introduced?\"\n I'm working with tennis data of length 140 records, and have 3 free text columns (there is a lot more categorical columns but I don't have any issue with this) that I need to process. The key thing I'm trying to get at is to classify responses into coherent opinions such as \"I think the acrylic courts are bad\", or, \" I think the club is too cliquey\".\n I've read all the responses, since the data size isn't too big and most of the records were left incomplete: average 60%…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1618csc/p_nlp_tennis_data_task/",
          "publishedOn": "2023-08-25T19:15:41.000Z",
          "wordCount": 3126,
          "title": "[P] NLP tennis data task",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1617i9m/r_wavjourney_compositional_audio_creation_with/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2307.14335\n Github: https://github.com/Audio-AGI/WavJourney\n Project Page: https://audio-agi.github.io/WavJourney_demopage/ \n Demo: https://huggingface.co/spaces/Audio-AGI/WavJourney \n Abstract:\n  \nLarge Language Models (LLMs) have shown great promise in integrating diverse expert models to tackle intricate language and vision tasks. Despite their significance in advancing the field of Artificial Intelligence Generated Content (AIGC), their potential in intelligent audio content creation remains unexplored. In this work, we tackle the problem of creating audio content with storylines encompassing speech, music, and sound effects, guided by text instructions. We present WavJourney, a system that leverages LLMs to connect various audio models for audio content ge…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1617i9m/r_wavjourney_compositional_audio_creation_with/",
          "publishedOn": "2023-08-25T18:43:02.000Z",
          "wordCount": 2826,
          "title": "[R] WavJourney: Compositional Audio Creation with Large Language Models - University of Surrey 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1614xtr/d_single_rtx_4060_ti_16gb_vs_two_rtx_3060_12gb/",
          "author": null,
          "description": "am looking to add a new GPU to my PC, and would be doing some DL work. Currently I rely on free tier Colab and Kaggle GPU quotas.\n Should I add an RTX3060 12 GB now and add anathor RTX3060 12 GB down the line, or save up and go for RTX 4060Ti 16GB version.\n Both would cost roughly the same\n    submitted by    /u/DietzscheNostoevsky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1614xtr/d_single_rtx_4060_ti_16gb_vs_two_rtx_3060_12gb/",
          "publishedOn": "2023-08-25T17:04:45.000Z",
          "wordCount": 2642,
          "title": "[D] Single RTX 4060 Ti 16GB vs two RTX 3060 12GB cards (same price)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1614j01/d_how_important_are_the_formatting_guidelines_for/",
          "author": null,
          "description": "I am currently a grad student, just submitted my first paper to AAAI last week. I wrote my paper using Overleaf, and the link (with edit option) was shared with my supervisor. Few days before the deadline I was still editing my paper and my manuscript exceeded the 7-page limit. One day my supervisor checked my work and inserted \\vspace{-xx} wherever applicable e.g. around Section titles, tables, figures; however, this command is specifically forbidden by AAAI and authors are actually not allowed to change the spacing manually. My supervisor was well-aware of this restriction but I understand my supervisor’s intention was so that i could squeeze all the contents and information within the page limit. I myself, however, prefer to follow guidelines so in the end i did not use any \\vspace in my submitted PDF (only PDF is required in the anonymous phase but not the original .tex file). Another student under my supervisor’s supervision used \\vspace A LOT throughout his/her whole paper, to the point it was easily noticeable by naked eyes. Also, at one point my supervisor suggested the student to put the table caption above the table, as it is more common (although AAAI said to put the caption below the table). \n Since this is my first experience of submitting to a conference, and that my supervisor has experience publishing at and supervising students for many ML/AI conferences e.g. Neurips, CVPR, ICML, I am just curious, how important are these formatting guidelines during the anonymous phase? Does it have any impact on the scores/accept-reject decision? Am i being too naive or “conservative”?\n Another one minor question. My supervisor changed the positioning of all my figures, tables, and algorithms to [tb!], which was to put them either at the top or at the bottom of the page, and said this is the norm in academia. Is it true?\n    submitted by    /u/butterJM  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1614j01/d_how_important_are_the_formatting_guidelines_for/",
          "publishedOn": "2023-08-25T16:49:12.000Z",
          "wordCount": 2890,
          "title": "[D] How important are the formatting guidelines for conferences during anonymous phase",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1610dp4/d_autonomous_driving_offroads/",
          "author": null,
          "description": "Solving the puzzle of autonomous driving in off-road terrains is a complex task that only a handful of experts around the globe are taking on. First let's understand the complexity of the task:\n The Off-Road Challenge: When we talk about autonomous driving, it's easy to picture well-paved roads and orderly traffic. However, off-road driving introduces a whole new level of complexity. Imagine a vehicle making its way through uneven terrains, gravel paths, and unexpected obstacles. Off-road environments lack the predictability of urban streets, making the task of autonomous navigation a true puzzle.\n Sensors: LiDAR, radar, cameras, and GPS work together to capture the surroundings in real-time. But here's the catch: the data from these sensors isn't neatly packaged. It's raw and needs carefu…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1610dp4/d_autonomous_driving_offroads/",
          "publishedOn": "2023-08-25T14:10:20.000Z",
          "wordCount": 3102,
          "title": "[D] Autonomous Driving Off-Roads",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/160zux5/rp_readabilityoptimized_comic_sans_alternative/",
          "author": null,
          "description": "Modified Generative Adversarial Neural Network\n GitHub page: https://muxamilian.github.io/Robo99/\n GitHub repo: https://github.com/muxamilian/Robo99\n    submitted by    /u/muxamilian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/160zux5/rp_readabilityoptimized_comic_sans_alternative/",
          "publishedOn": "2023-08-25T13:49:24.000Z",
          "wordCount": 2586,
          "title": "[R][P] Readability-optimized Comic Sans alternative using Machine Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/160wqra/d_how_can_elevenlabs_return_a_response_so_quickly/",
          "author": null,
          "description": "AI based tools, like Elevenlabs for TTS, can return an API response with constructed audio in <1 second. How on earth do their models return so quickly?\n For comparison, TortoiseTTS returns the audio for a sentence in minimum 15 seconds.\n Obviously they have VC funding and hardware. They probably have slimmed down models, but the speed of their response is insane.\n    submitted by    /u/tommyk1210  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/160wqra/d_how_can_elevenlabs_return_a_response_so_quickly/",
          "publishedOn": "2023-08-25T11:36:31.000Z",
          "wordCount": 2637,
          "title": "[D] How can Elevenlabs return a response so quickly?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/160vjb8/p_easyocr_alternative_to_translate_text/",
          "author": null,
          "description": "[P]\n I translated text on image using easyocr then put the text back on image same coridnatees.\n As you can see i have to deal with many different fonts,colourings etc....\n Is there not an AI library or a new way to semantically understand all this information on picture?\n https://preview.redd.it/cnc0xryli8kb1.jpg?width=970&format=pjpg&auto=webp&s=86f17df0eeebb01083c8e2c7a3ca09d22671b322\n https://preview.redd.it/lg0seqyli8kb1.jpg?width=970&format=pjpg&auto=webp&s=e9f7699ae7d7d5cd99070354cdd679d1f71b84d3\n    submitted by    /u/fabrcoti  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/160vjb8/p_easyocr_alternative_to_translate_text/",
          "publishedOn": "2023-08-25T10:37:40.000Z",
          "wordCount": 2621,
          "title": "[P] EasyOCR alternative to translate text",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/160v6he/d_serverless_inference_for_llama2/",
          "author": null,
          "description": "Serverless Inference for Llama2\n I am part of a small (startup like) organization and want to use a model to answer client requests but these should not be 24/7 so I started looking at serverless inference. I have been warned about cold start times since the desired latency is of about 1-5 sec. I am using a Llama2-7b-GPTQ model (quantized) and also experimenting with the 13b version. The model weights take about 10GB of memory. I still do not have much experience with any of this aws stuff. Do you think this is a good strategy? Would the costs be lower? What could be the average cold start time? The inference time of the model is within the desired time so cold start is my biggest fear. Thanks\n    submitted by    /u/MiNeves  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/160v6he/d_serverless_inference_for_llama2/",
          "publishedOn": "2023-08-25T10:19:06.000Z",
          "wordCount": 2700,
          "title": "[D] Serverless Inference for Llama2",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/160tyoh/r_using_ai_for_cyber_security_thesis_topic/",
          "author": null,
          "description": "I am beginner and would like to use LLM (llama2) and train it with cyber security data. what can this project lead to is little bit uncertain and where i can get the datasets from. maybe someone can help me with this\n    submitted by    /u/confusedguy1395  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/160tyoh/r_using_ai_for_cyber_security_thesis_topic/",
          "publishedOn": "2023-08-25T09:13:11.000Z",
          "wordCount": 2617,
          "title": "[R] Using AI for Cyber Security thesis topic",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/160ts9g/d_is_it_me_or_huggingface_do_too_many_things/",
          "author": null,
          "description": "Just entered the HuggingFace ecosystem and it's totally overwhelming. They have like 5 libraries, I don't know the difference between them, I don't know what I need, it's all very confusing.\n They should do a \"Start here\" page on the front of their website and do a high-level overview of EVERYTHING they do.\n Just felt like sharing my experience. Have a good day yall.\n    submitted by    /u/andi_cs1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/160ts9g/d_is_it_me_or_huggingface_do_too_many_things/",
          "publishedOn": "2023-08-25T09:03:20.000Z",
          "wordCount": 2641,
          "title": "[D] Is it me or HuggingFace do TOO MANY things?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/160t2gk/d_topic_modelling_reference/",
          "author": null,
          "description": "can anyone recommend me what book to read if I want to learn topic modelling. TIA. \n    submitted by    /u/Fun_Ambition_5186  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/160t2gk/d_topic_modelling_reference/",
          "publishedOn": "2023-08-25T08:21:33.000Z",
          "wordCount": 2587,
          "title": "[D] Topic Modelling Reference",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/160nrcd/n_introducing_code_llama_a_new_era_of_aidriven/",
          "author": null,
          "description": "Meta has unveiled Code Llama, a state-of-the-art large language model (LLM) that generates code from text prompts, as reported on their blog. This revolutionary tool is set to transform the way developers work, making their workflows more efficient and lowering the barrier to entry for coding newcomers.\n If you want to stay on top of the latest trends and insights in AI and tech, look here first.\n https://i.redd.it/awqzhhl4f6kb1.gif\n Why this matters:\n  \nCode Llama is a game-changer: It’s a code-specialized version of Llama 2, capable of generating code and natural language about code from both code and natural language prompts. It supports popular languages like Python, C++, Java, PHP, Typescript (Javascript), C#, and Bash.\n It’s free for research and commercial use: Meta believes in an o…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/160nrcd/n_introducing_code_llama_a_new_era_of_aidriven/",
          "publishedOn": "2023-08-25T03:33:40.000Z",
          "wordCount": 2946,
          "title": "[N] Introducing Code Llama: A New Era of AI-Driven Coding",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/160m2aw/d_neurips_2023_paper_reviews_datasets_and/",
          "author": null,
          "description": "I saw a few reddit posts about the main track reviews and wanted to create a discussion post for the datasets and benchmarks. \n As a first time submitter, I'm curious if there are any different experiences between the main track and the datasets track.\n    submitted by    /u/notasketchyperson  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/160m2aw/d_neurips_2023_paper_reviews_datasets_and/",
          "publishedOn": "2023-08-25T02:15:19.000Z",
          "wordCount": 2620,
          "title": "[D] NeurIPS 2023 Paper Reviews - Datasets and Benchmarks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/160jhce/tech_giants_invest_235_million_in_ai_startup/",
          "author": null,
          "description": "AI startup Hugging Face has recently secured a whopping $235 million in a Series D funding round, raising its valuation to an impressive $4.5 billion. This investment round saw participation from tech behemoths like Google, Amazon, Nvidia, and Salesforce.\n If you want to stay on top of the latest trends and insights in AI and tech, look here first.\n https://preview.redd.it/dr9z7hbuh5kb1.jpg?width=1440&format=pjpg&auto=webp&s=ff23521492e1276e838c6c11c35134271a005691\n Why this matters:\n  \nHugging Face’s unique collaborative approach sets it apart: Unlike many AI startups that closely guard their models, Hugging Face provides a platform where developers can freely share code, models, and datasets.\n The company is committed to supporting developers: Hugging Face offers tools that facilitate th…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/160jhce/tech_giants_invest_235_million_in_ai_startup/",
          "publishedOn": "2023-08-25T00:27:06.000Z",
          "wordCount": 2898,
          "title": "Tech Giants Invest $235 Million in AI Startup Hugging Face [N]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/160hzur/d_is_a_machine_learning_model_required_if_im/",
          "author": null,
          "description": "Just like the title says, do I even need a working model to develop an MVP? I was thinking about developing the frontend and the backend to show people the basic features of the app and then explain how adding machine learning to this could enhance the user experience by curating content and learning from users. I just don’t want to invest too much time trying to perfect the MVP before I show it to potential users. Is this a valid approach? Would this approach also work when pitching to investors?\n    submitted by    /u/zRage4  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/160hzur/d_is_a_machine_learning_model_required_if_im/",
          "publishedOn": "2023-08-24T23:27:07.000Z",
          "wordCount": 2675,
          "title": "[D] Is a machine learning model required if I’m developing an MVP of a social media platform?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/160dows/p_finetuning_flant5_for_question_answering_using/",
          "author": null,
          "description": "Recently I scraped 56,400 question/answer pairs off Quora, and trained Flan-T5 on the resulting dataset. I released the dataset and model on HuggingFace, which you can find in the comments. I plan to continually add to the dataset, but proxy costs are pretty expensive since Quora is hella bloated.\n Has anyone else trained Flan-T5 on a similar task? What did you learn/how were the results?\n    submitted by    /u/jankybiz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/160dows/p_finetuning_flant5_for_question_answering_using/",
          "publishedOn": "2023-08-24T20:47:05.000Z",
          "wordCount": 2642,
          "title": "[P] Fine-tuning Flan-T5 for question answering using scraped Quora data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/160cbqo/d_dataflow_and_workload_partitioning_in_nvidia/",
          "author": null,
          "description": "Hi,\n ​\n I have a question regarding the dataflow and workload partitioning in nVidia GPUs for a general matrix multiplication in Pytorch (e.g., torch.matmul). \n How does the dataflow look like? Is it like that for the first matrix, the data elements for each row are fed into CUDA cores one by one and the correspond data elements from the second matrix in each column, and then partial product is updated each time after the multiplication? \n ​\n What is the partitioning strategy across multiple CUDA cores? is it based on row wise in the first matrix and column wise in the second matrix or is it like column-wise in the first matrix and row-wise in the second matrix?\n ​\n Thank you very much!\n    submitted by    /u/Impossible-Froyo3412  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/160cbqo/d_dataflow_and_workload_partitioning_in_nvidia/",
          "publishedOn": "2023-08-24T19:55:07.000Z",
          "wordCount": 2700,
          "title": "[D] Dataflow and workload partitioning in nVidia GPUs for a matrix multiplication in Pytorch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/160c7j4/d_why_does_federateddistributed_learning_work/",
          "author": null,
          "description": "I had a question regarding federated learning. Typically, if we have a network that is good at, say, classifying frogs, and a network that is good at, say, classifying snakes (and these two have the same shape/dimensions), then in a federated/distributed learning setup we average the weights between the two to get a network that is good at both/\"primed\" to be good at both after trained a little more. \n ​\n Why does this work though? Mathematically, given the nonlinearity present in neural networks, it doesn't seem immediately obvious to me why averaging weights would put us in a better place.\n    submitted by    /u/Rare_Replacement_744  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/160c7j4/d_why_does_federateddistributed_learning_work/",
          "publishedOn": "2023-08-24T19:50:41.000Z",
          "wordCount": 2672,
          "title": "[D] Why does Federated/Distributed Learning work?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/160b6vs/why_are_all_applicants_java_developers_d/",
          "author": null,
          "description": "Why are all applicants Java developers?\n Recently I posted a job opening at my company for a full-stack and AI developer (This is not a post looking for resumes, we found someone). We were looking for someone who can do web development (node, typescript, react, etc.), can code python, and has experience with tensor flow or PyTorch.\n The skills I’m looking for are not niche, it may be uncommon to find someone with experience in both typescript and PyTorch, but neither is a “niche” skill. After posting this job, I quickly got 200+ applications, probably 190 of them led their resume with “Java developer.”\n Why is everybody a Java developer? Why is everybody learning and using Java? You can make a backend in java and you can do machine learning in java, but there are better ways. Can someone explain why everybody applying is a “Java developer?”\n    submitted by    /u/cathie_burry  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/160b6vs/why_are_all_applicants_java_developers_d/",
          "publishedOn": "2023-08-24T19:12:06.000Z",
          "wordCount": 2721,
          "title": "Why are all applicants Java developers? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1609z3u/r_code_llama_open_foundation_models_for_code_meta/",
          "author": null,
          "description": "Paper: https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/ \n Github: https://github.com/facebookresearch/codellama \n Models: https://ai.meta.com/resources/models-and-libraries/llama-downloads/ \n Blog: https://ai.meta.com/blog/code-llama-large-language-model-coding/ \n Abstract:\n  \nWe release Code Llama, a family of large language models for code based on Llama 2 providing state-of-the-art performance among open models, infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks. We provide multiple flavors to cover a wide range of applications: foundation models (Code Llama), Python specializations (Code Llama - Python), and instruction-following models (Code Llama - Instruct) with 7B, 13B and 34B parameters each. All models are trained on sequences of 16k tokens and show improvements on inputs with up to 100k tokens. 7B and 13B Code Llama and Code Llama - Instruct variants support infilling based on surrounding content. Code Llama reaches state-of-the-art performance among open models on several code benchmarks, with scores of up to 53% and 55% on HumanEval and MBPP, respectively. Notably, Code Llama - Python 7B outperforms Llama 2 70B on HumanEval and MBPP, and all our models outperform every other publicly available model on MultiPL-E. We release Code Llama under a permissive license that allows for both research and commercial use.\n  \nhttps://preview.redd.it/grzcrnx4p3kb1.jpg?width=915&format=pjpg&auto=webp&s=ae41c02d892bfb8275723dbfede7ac3165717357\n https://preview.redd.it/4qpazkx4p3kb1.jpg?width=641&format=pjpg&auto=webp&s=31aaf9ecafbd70fbf2c1cd4e92ccf594c09b3861\n https://preview.redd.it/hlrp4x05p3kb1.jpg?width=711&format=pjpg&auto=webp&s=3651f519dc9b23b432656416749c3f7e113b4ce7\n ​\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1609z3u/r_code_llama_open_foundation_models_for_code_meta/",
          "publishedOn": "2023-08-24T18:26:32.000Z",
          "wordCount": 2763,
          "title": "[R] Code Llama: Open Foundation Models for Code - Meta Ai 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1608ye1/advice_on_ml_language_training_p/",
          "author": null,
          "description": "Hi,\n I am trying to train a model for a very niche field of translation between German and Turkish. I have approx 60k data pairs from previous translations in a combination of sentences and words. Unfortunately Google auto ML does not support this language pair, would you have any advice on how to proceed? Do you have any other platform suggestions?\n    submitted by    /u/siviliz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1608ye1/advice_on_ml_language_training_p/",
          "publishedOn": "2023-08-24T17:48:40.000Z",
          "wordCount": 2634,
          "title": "Advice on ML language training [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1608y54/discussion_fine_tuning_open_vocabulary_object/",
          "author": null,
          "description": "Context: I'm building a visual scraping system (will be FOSS, the basis of a RSS/social media/news aggregator) - I did some experimentation with FasterRCNN trained on the RICO/CLAY datasets (UI screenshots and annotations) - the results are ok for detecting the UI elements.\n But the idea is to have easily configurable scrapers - where you select one or several examples of an UI element and the model performs zero/one/few-shot detection.\n What I've tried: I tried to extract embeddings after the RoI pool for the detections (in FasterRCNN) and then filter by geometric distance from the example/template, but the results were pretty bad. I then read several papers that tried a similar approach and had to alter the FasterRCNN architecture and doing additional training for each new class. E.g. FSCE [1]. But I haven't tried those approaches out.\n Further dev idea: Now, while prepping another course project, I dove into the open-vocabulary detectors (like OWL-ViT), and they seem appropriate for the task, since they have a joint latent space for image/text, which is used to configure the detection step (as far as I understood it). There's an example on Hugging face where OWL-ViT is used to detect semantically similar images by a single example image. This is pretty close to what I want to do, but the UI image domain is pretty specific, so I'll need to fine-tune the model to have a chance at success (I did several test cases manually on the pretrained OWL-ViT, and it's not great).\n So I'd appreciate any advice and specifically - are there open vocab detection models that can be fine-tuned on consumer hardware (1070, 8gb) or for a reasonable price on Colab? And should I try some of the \"older\" one/few-shot approaches, based on FasterRCNN?\n [1] FSCE: Few-Shot Object Detection via Contrastive Proposal Encoding - https://arxiv.org/pdf/2103.05950.pdf\n [2] https://github.com/witnessai/Awesome-Open-Vocabulary-Object-Detection\n    submitted by    /u/petko10  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1608y54/discussion_fine_tuning_open_vocabulary_object/",
          "publishedOn": "2023-08-24T17:48:25.000Z",
          "wordCount": 2889,
          "title": "[Discussion] Fine tuning open vocabulary object detection models on consumer hardware? (e.g. fine-tuning OWL-ViT and the such)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1608p6l/d_data_independent_sparsification_of_models_after/",
          "author": null,
          "description": "I was looking at papers on model pruning or quantization that aims to make inference faster and/or reduce size of the model. Most of them rely on calibration data to identify weights that can be pruned. I am skeptical about this approach since the calibration data could be skewed and in the process of pruning the model could be overfitting on that small sample of data. Are there data independent approaches to post-training sparsification?\n    submitted by    /u/Legitimate-Tea-6695  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1608p6l/d_data_independent_sparsification_of_models_after/",
          "publishedOn": "2023-08-24T17:39:28.000Z",
          "wordCount": 2649,
          "title": "[D] Data independent sparsification of models after training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1607i3t/p_hypothesis_refining_and_tuning_gpt_models_with/",
          "author": null,
          "description": "Hey everyone,Finally mustering up the courage to make my first post here! I've been delving into various ways to get GPT (and GPT-like models) ready for production.\n By that, I mean:\n  \nEnsuring it's helpful\n Fostering creativity\n Preventing any wild imagination moments\n  \nI've found that while the LLM model provides responses that are good enough, they often fall short of being great. So, recently, I've been experimenting with using human feedback from the responses generated by ChatGPT to fine-tune it.\n For instance, when I want to figure out the ideal parameters to use, I run surveys with people and ask them to pick the better response. This approach helps me identify the best parameters.\n You can imagine that this technique could be valuable in fine-tuning, enabling us to create datasets based on human feedback.\n I'm eager to put this to the test on the issues and prompts the community is tackling. So, I have to ask: Could you share the prompts you're currently working on? We'll let you know how it scores with our survey panel on dimensions of helpfulness, creativity, and hallucinations.\n [Self-promotion moment]\n I'm actively developing this concept over at pontus.so. Feel free to check it out!Looking forward to hearing about your prompts!\n    submitted by    /u/spearos  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1607i3t/p_hypothesis_refining_and_tuning_gpt_models_with/",
          "publishedOn": "2023-08-24T16:57:17.000Z",
          "wordCount": 2784,
          "title": "[P] [Hypothesis] Refining and Tuning GPT models with human feedback makes better models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1607cg6/d_wb_vs_neptune_vs_clearml_vs_comet_2023/",
          "author": null,
          "description": "Interested to hear community thoughts on these four competing services as of today. From what I see pricing is definitely a big one\n    submitted by    /u/hadley60  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1607cg6/d_wb_vs_neptune_vs_clearml_vs_comet_2023/",
          "publishedOn": "2023-08-24T16:51:14.000Z",
          "wordCount": 2599,
          "title": "[D] W&B vs. Neptune vs. ClearML vs. Comet (2023)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16060vw/d_llms_stateless_by_design_by_limitation_or/",
          "author": null,
          "description": "I am curious to know if: \n A. LLMs are stateless by design (privacy/ethics)\n B. If it’s simply that as yet, no one has been able to architect a sustainable stateful LLM \n C. Or perhaps there are already stateful LLMs, and I am just behind in my understanding. \n I have had a ton of trouble finding current information on this because it seems to be moving so fast. If anyone knows for certain and doesn’t mind sharing, I would be grateful.\n    submitted by    /u/flutterbynbye  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16060vw/d_llms_stateless_by_design_by_limitation_or/",
          "publishedOn": "2023-08-24T16:02:40.000Z",
          "wordCount": 2656,
          "title": "[D] LLMs - stateless by design, by limitation, or…?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1604qqn/d_what_happened_to_huggingface_tokenizers_api/",
          "author": null,
          "description": "Tokenizers library used to be very nice to use. It had one main class Tokenizer with all of the parameters in its constructor and with all necessary methods like .train(), .encode() and .decode() at hand. It provided reasonable defaults and allowed for customization if needed.\n Now it is a complete mess. To train a tokenizer I now have to create instances of, like, 5-6 classes: PreTokenizer, Model, Tokenizer, Trainer, Decoder... It is quite difficult to understand what variants of those classes I need to use to obtain 'the' WordPiece tokenizer, for example.\n Tokenizer class must be inialized with an instance of Model class. But all other parts cannot be added to the constructor and have to be set later as attributes. Why? And maybe you thought that those attributes have some defaults? No! What really got me is when the .decode() method of my tokenizer produced strings consisting of tokens with special symbols, like p ##y ##ram ##ids. It took me some time to understand that I also need to additionally set the Decoder attribute. \n The naming of those classes is also a mess. WordPiece model is called WordPiece. WordPiece decoder is also called WordPiece! So, you cannot import those names together at all, and need to specify the exact path in your code.\n Is it only me? Do you think that this API is better than the old one? \n    submitted by    /u/Tomarchelone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1604qqn/d_what_happened_to_huggingface_tokenizers_api/",
          "publishedOn": "2023-08-24T15:15:15.000Z",
          "wordCount": 2804,
          "title": "[D] What happened to huggingface tokenizers API?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1603wlq/p_automating_intelligence_theft_legally/",
          "author": null,
          "description": "It has been known for a while now that you can train a smaller model with outputs from a larger one (vicuna for example). I've been working on a project, the LLM-VM, designed to encapsulate this process.\n Why?\n Small models (chatgpt, ada...) are cheap and fast but dumb. Slow and expensive models like GPT4 are smart. For most applications you'd ideally want the best of both worlds.\n How:\n First observation: Many LLM use-cases are a lot more specific than general purpose (e.g., \"translate this sentence into german:\", \"are these two sentences equivalent?\", ...), and you can train away the extra context.\n Second observation: You can figure out which LLM calls have this property by analyzing the call settings.\n Third observation: Many don't actually have a lot of data or time to wait, so you can use the larger LLM to synthese examples to train the smaller LLM with.\n example\n # OpenAI openai.ChatCompletion.create( model=\"gpt-4\" messages = [('system',\"Answer question Q.\"), ('user',\"What is the currency in myanmar?\") ] # simplified for brevity ) # LLM-VM (using OpenAI) llm_vm.client.complete( prompt = \"Answer question Q.\", context = \"Q: What is the currency in myanmmar?\", openai_key=YOUR_KEY, data_synthesis=True, finetune=True) \n    submitted by    /u/mmirman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1603wlq/p_automating_intelligence_theft_legally/",
          "publishedOn": "2023-08-24T14:43:53.000Z",
          "wordCount": 2765,
          "title": "[P] Automating Intelligence Theft (legally) 🏴‍☠️",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/16036xc/d_2dpositional_encoding_for_transformer/",
          "author": null,
          "description": "I'm working with 2D input, where I have discrete objects arranged in a grid-like structure with one temporal dimension and one spatial dimension. I'd like to process these inputs with a Transformer. Any idea what would be a suitable positional encoding to use for this? I could probably use something similar to what is used in ViT (2 spatial dimensions), but maybe there's something more suitable for the mixed \"temporal-spatial\" case?\n ​\n    submitted by    /u/seawee1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/16036xc/d_2dpositional_encoding_for_transformer/",
          "publishedOn": "2023-08-24T14:16:17.000Z",
          "wordCount": 2643,
          "title": "[D] 2D-positional encoding for Transformer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1602dim/d_possible_way_to_combine_llms_with/",
          "author": null,
          "description": "I've been thinking lately about combining LLMs with an AlphaZero-style RL agent, especially since the announcement of Gemini. This would avoid the poor planning and reasoning ability in current next-token predictors. I've developed an architecture that seems feasible to me, so I'm looking for feedback from people with ML experience.\n The crucial part for AlphaZero is a more or less objective way to evaluate a game outcome. This is easy for well-defined games like chess or go, but very difficult for text, where there is no way to define the quality of a text. \n What I propose is to train a high-parameter evaluation model to evaluate the similarity of a text to the datasets already used to train LLMs. This model takes as input a text with some tokens omitted from the whole text, and predicts…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1602dim/d_possible_way_to_combine_llms_with/",
          "publishedOn": "2023-08-24T13:44:36.000Z",
          "wordCount": 2944,
          "title": "[D] Possible way to combine LLMs with AlphaZero-style RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/1601yhr/d_need_help_with_nlp_tool_to_be_used/",
          "author": null,
          "description": "Help ::\n I'm working on a project which is a production level one where-in I want the AI to write mails based on the mail replies it receives.\n I have prepared the entire the structure and everything, just need to figure out the NLP tool.\n Unlike ChatGPT or any other ChatBot this one will write messages that are more like conversation based.\n I checked out GPT API, which is paid but does not require extensive data training when compared to other NLP tools.\n I also checked out Bloom, but the reviews mention it to be rather a bit inaccurate.\n Need help with the tool. Which tool gives the most accurate outcome and does not require extensive training?\n    submitted by    /u/Key_Consideration385  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/1601yhr/d_need_help_with_nlp_tool_to_be_used/",
          "publishedOn": "2023-08-24T13:27:27.000Z",
          "wordCount": 2689,
          "title": "[D] : Need help with NLP tool to be used.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zzft9/r_elita_lineartime_attention_done_right/",
          "author": null,
          "description": "Yes, it's another Transformer architecture that seeks to be cheaper and faster, but no, this is not the same. All the developments are through equations and architectural changes, no hardware or code tricks. The performance is very good, testing on very small models (as in the diagram), but also sequence lengths of 100K+ on 1 GPU in the tens of millions of parameters. Though no paper is currently available, a Github repository with full code, explanations, intuitions, and some results is available here. Being the sole author, depending on the feedback here, I may continue to write a paper, though my resources are extremely limited.\n I would very much appreciate any feedback on the work, code, ideas, etc., or for anyone to contact me with questions or next steps.\n Repository here.\n https://preview.redd.it/j3epa8ron1kb1.png?width=1643&format=png&auto=webp&s=a3204dc834f159b39bc9b5e9a476b3e23396fd84\n    submitted by    /u/LahmacunBear  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zzft9/r_elita_lineartime_attention_done_right/",
          "publishedOn": "2023-08-24T11:35:26.000Z",
          "wordCount": 2704,
          "title": "[R] ELiTA: Linear-Time Attention Done Right",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zyvjj/p_python_library_for_quickly_detecting/",
          "author": null,
          "description": "Hey all,\n I'm building a library for quickly detecting problematic data slices (clusters) when developing machine learning models.\n Find problematic data segments in your data with few lines of code.\n Best starting point is checking out the Github Repository:\n https://github.com/Renumics/sliceguard\n It can be used to detect problems such as:\n  \nOutliers, Anomalies, Errors\n Label inconsistencies\n Unwanted Biases\n Poorly Chosen Evaluation data\n  \nSome information about the features:\n  \nWorks on structured, unstructured data (image, audio, NLP, multimodal) and hybrid datasets\n Directly works on existing Pandas DataFrames\n Automatic computation of embeddings and AutoML functionality to pinpoint problems without any setup\n Interactive GUI for slice inspection supports multimodal data and can be configured with drag-n-drop\n  \nI would appreciate any feedback regarding the library or concrete applications you might have in mind!\n    submitted by    /u/OkResearch6289  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zyvjj/p_python_library_for_quickly_detecting/",
          "publishedOn": "2023-08-24T11:07:46.000Z",
          "wordCount": 2702,
          "title": "[P] Python Library for Quickly Detecting Problematic Data Segments",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zwetm/r_towards_an_astronomical_foundation_model_for/",
          "author": null,
          "description": "submitted by    /u/blabboy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zwetm/r_towards_an_astronomical_foundation_model_for/",
          "publishedOn": "2023-08-24T09:00:11.000Z",
          "wordCount": 2590,
          "title": "[R] Towards an astronomical foundation model for stars with a Transformer-based model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zvvjk/d_on_synthetic_datasets/",
          "author": null,
          "description": "I'm working on two seperate tasks, for both of these tasks I need to create a training dataset\n  \na pure CV image classification task\n a generative task involving a 3D autoencocer (U-Net)\n  \nfor 1) I can create both real and synthetic images. The goal is to pretrain a CNN on synthetic data, then fine-tune on real images.\n for 2) I can only create synthetic 3D objects. Their distribution should mimic later application most closely. Research indicates that, given the right selection of parameter distributions, a training dataset can be generated that allows good generalization capabilities. Yet, there are restrictions due to high-dimensionality of the data and further computational limitations. So we want to spread the dataset sparsely and make the AE interpolate between those solutions.\n The problem with both of these approaches is to evaluate the quality and impact of the synthetic datasets. How close do they mimic the real distribution? What initial parameter variaton (i.e., lighting, camera perspective, background, etc. in the case of images) do we chose and what is their impact on image features and ultimately model capabilities.\n Comparing high-dimensional data distributions is quite challenging, there exist metrices like Geometry Score, FID, Improved P&R, Delauney Component Analysis, T-SNE etc. But it is difficult to chose and interpret these metrices properly (some are for evaluating GAN-created images). Is it reasonable to use KDE on latent features btw?\n So, from your experience what do you think of synthetic datasets? Is it worth the effort? Do you know of any good / easy to interpret metrices? Or does it need further research in this area? Im thinking about going in this direction for my Phd, where should I go?\n edit: here is an image of 2) a topology optimization dataset, visualized via a TSNE graph\n ​\n ​\n    submitted by    /u/niggellas1210  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zvvjk/d_on_synthetic_datasets/",
          "publishedOn": "2023-08-24T08:30:16.000Z",
          "wordCount": 2865,
          "title": "[D] On synthetic datasets",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zqt98/ai2_releases_dolma_the_largest_open_dataset_for/",
          "author": null,
          "description": "The Allen Institute for AI (AI2) has released Dolma, a new, huge text dataset that is free to use and open to inspection. This dataset is intended to be the opposite of the closely guarded datasets used by companies like OpenAI and Meta to train their language models. AI2 aims to reverse this trend and make the data used to create language models available to the AI research community.\n If you want to stay on top of the latest trends and insights in AI and ML, look here first.\n https://preview.redd.it/salufijhezjb1.png?width=2000&format=png&auto=webp&s=350a4cd5b41045ecf0fca072d528f4e70e515ea4\n Why this matters:\n  \nTransparency in AI research: The release of Dolma is intended to promote transparency in AI research by making the sources and processes used to create the dataset publicly docum…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zqt98/ai2_releases_dolma_the_largest_open_dataset_for/",
          "publishedOn": "2023-08-24T04:00:42.000Z",
          "wordCount": 2900,
          "title": "AI2 releases Dolma, the largest open dataset for training language models [N]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zn3rl/p_working_on_a_qlora_hub_for_model_personalities/",
          "author": null,
          "description": "Hey all!\n I'm building a repository of QLORA adapters that change the model's personality. The end vision is a hub of ready-to-go personality adapters.\n I'm hitting a snag when training the QLORAs for Paul Graham personality on top of a 4-bit quantized StableBeluga-7B. The model just doesn't seem to learn the style.\n Any thoughts on how I can improve this? Below are the details:\n Data\n  \n3340 examples of PG passages, formatted as {\"text\": \"### User:\\n{generic instruction}\\n\\n### Assistant:\\n{PG-style response}\"}.\n Each examples is about 5 sentences taken from one of PG's essays.\n  \nTraining\n  \noptim=\"paged_adamw_8bit\"\n learning_rate=2e-4\n per_device_train_batch_size=4\n gradient_accumulation_steps=4\n num_train_epochs=4\n fp16=True\n group_by_length=True\n load_best_model_at_end=True\n max_seq_length=512\n  \nHardware\n  \nx1 V100 through Google Colab Pro.\n  \nMy min eval loss so far is 1.916546. Pretty stuck and will appreciate any help!\n    submitted by    /u/Lang2lang  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zn3rl/p_working_on_a_qlora_hub_for_model_personalities/",
          "publishedOn": "2023-08-24T01:12:52.000Z",
          "wordCount": 2700,
          "title": "[P] Working on a QLORA hub for model personalities, help needed",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zlxyb/n_fine_tuning_gpt35_turbo_video_tutorial_with/",
          "author": null,
          "description": "Here is a quick demo on how to fine tune and retrieve results from a GPT-3.5 Turbo Model\n https://youtu.be/9iPtmLpYG6c\n    submitted by    /u/ComprehensiveRise569  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zlxyb/n_fine_tuning_gpt35_turbo_video_tutorial_with/",
          "publishedOn": "2023-08-24T00:23:11.000Z",
          "wordCount": 2595,
          "title": "[N] Fine Tuning GPT-3.5 Turbo Video Tutorial with example",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zlxy4/n_fine_tuning_gpt35_turbo_video_tutorial_with/",
          "author": null,
          "description": "Here is a quick demo on how to fine tune and retrieve results from a GPT-3.5 Turbo Model\n https://youtu.be/9iPtmLpYG6c\n    submitted by    /u/ComprehensiveRise569  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zlxy4/n_fine_tuning_gpt35_turbo_video_tutorial_with/",
          "publishedOn": "2023-08-24T00:23:11.000Z",
          "wordCount": 2595,
          "title": "[N] Fine Tuning GPT-3.5 Turbo Video Tutorial with example",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zl7ul/d_how_do_you_think_open_ai_hosts_all_these_fine/",
          "author": null,
          "description": "I feel like there is no way they make a unique copy of the entire gpt 3.5 weight set every time fine tuning happens. Do you think they have some sorta database of LoRAs and then load the appropriate ones at run time to append to the core model when fine-tuned models are invoked?\n An example of what I'm talking about can be seen here\n https://github.com/cccntu/minlora\n    submitted by    /u/30299578815310  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zl7ul/d_how_do_you_think_open_ai_hosts_all_these_fine/",
          "publishedOn": "2023-08-23T23:53:37.000Z",
          "wordCount": 2656,
          "title": "[D] How do you think Open AI hosts all these fine tuned models? Are they just dynamically swapping out LoRAs at run time?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zkhwr/help_for_my_model_p/",
          "author": null,
          "description": "Hey, I am building a sportsbook for my local rugny tournament, and I am pretty lost, I tried some model and they always fails in some points, because sometimes there are too many bets in one side and the other side cannot pay them. So when I have to change the quotas I don't know in what percent change them and whith what frequency. I am pretty lost and I can't find any information if someone can help would be awsome. Thx \n    submitted by    /u/Mikro34  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zkhwr/help_for_my_model_p/",
          "publishedOn": "2023-08-23T23:24:59.000Z",
          "wordCount": 2654,
          "title": "Help for my model [P]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zhx14/d_looking_for_early_devs_for_an_opensource_llm/",
          "author": null,
          "description": "Hi all, still looking some more early devs to help with an open-source LLM testing framework.\n The framework is here: https://github.com/kortex-labs/korrect\n In any case, please star and suggest changes/ features.\n    submitted by    /u/kanxx030  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zhx14/d_looking_for_early_devs_for_an_opensource_llm/",
          "publishedOn": "2023-08-23T21:50:45.000Z",
          "wordCount": 2608,
          "title": "[D] Looking for early devs for an open-source LLM testing framework",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zh60q/d_emnlp_2023_soundness_score_distribution/",
          "author": null,
          "description": "I created a poll to get a distribution. Please share this so that everyone can get a sense of the distribution of scores\n https://x.com/web3noob101/status/1694412757917986977?s=46&t=pon015qe4aKxshdEPPdKtg\n    submitted by    /u/Mysterious_Isopod374  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zh60q/d_emnlp_2023_soundness_score_distribution/",
          "publishedOn": "2023-08-23T21:23:32.000Z",
          "wordCount": 2597,
          "title": "[D] EMNLP 2023 soundness score distribution",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zej4j/d_backend_engineer_exploring_switching_to_machine/",
          "author": null,
          "description": "Hi Machine learning enthusiasts\n I would like to hear machine learning engineers opinion on whether it is worth investing in a machine learning education for an experienced Software Engineer? And how switching from backend engineering to machine learning would be evaluated by hiring managers and recruiters?\n My motives behind considering this possibility is watching Machine learning industry is exponentially growing. Machine learning today, has became the basis of many successful products categories and the basis for solving problems that would have impossible otherwise.\n On the other hand, I am concerned about is the investment cost, lack of interest in machine learning topics beyond pure programming (such as math and stats), and the unintentional career rebooting. Meaning, if I switched from backend engineering to machine learning I would be throwing the 11 years of experience out of the window.\n    submitted by    /u/software-surgeon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zej4j/d_backend_engineer_exploring_switching_to_machine/",
          "publishedOn": "2023-08-23T19:49:49.000Z",
          "wordCount": 2714,
          "title": "[D] Backend Engineer exploring switching to Machine Learning Engineer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zdxfz/dabout_model_serialization_and_metadata/",
          "author": null,
          "description": "(Discussion)Hey could anyone help me out in this question. So when we serialize a model the objects are serialized then what about the data it has like weights and architecture and dataset related information and other parameters. \n And also any insights on what is meant by metadata and model metadata\n    submitted by    /u/akash123608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zdxfz/dabout_model_serialization_and_metadata/",
          "publishedOn": "2023-08-23T19:29:32.000Z",
          "wordCount": 2622,
          "title": "[D]About model serialization and metadata",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zdcuw/d_seamlessm4ts_research_paper_discusses_purposely/",
          "author": null,
          "description": "Hello. \n I was reading the SeamlessM4t paper published at the following link and I noticed the following excerpt: \n \"Critically, we evaluated SeamlessM4T on gender bias and added toxicity to assess translation safety. Compared to the state-of-the-art, we report up to 63% of reduction in added toxicity in our translation outputs.\"\n Source: https://dl.fbaipublicfiles.com/seamless/seamless_m4t_paper.pdf\n Am I understanding this correctly? They are basically saying they purposely put guard rails to intentionally change the translation if it believes the translation is too \"toxic\"? \n If I am understanding this correctly, this is a MASSIVE overreach by the devs. How do they define text that is \"toxic\"? What are they doing to the text to make it less toxic? How can I trust that the translation it gives me in general is accurate if they are admitting to manipulating it? \n ​\n I'll give a very tangible example on how this is a massive problem. I am working on a fan project aimed at translating an entire Japanese light novel series to english even though I can't read Japanese. I'm currently 50% done with a single volume through the use of ChatGPT and significant manual edits. I've had censorship issues with GPT but because its a general purpose AI I can prompt it to not censor it pretty easily. How am I supposed to trust that it is translating the story correctly when they are outright telling me they are censoring things, and this isn't like ChatGPT where I can jailbreak it to translate it properly. \n ​\n I can see situations arising where the AI translates something incorrectly due to this and can potentially offend people of some cultures if it is purposely modifying the intended meaning of a sentence to avoid \"toxicity\". \n ​\n Please tell me I'm misunderstanding the terms here or there is something I'm missing.\n    submitted by    /u/NepNep_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zdcuw/d_seamlessm4ts_research_paper_discusses_purposely/",
          "publishedOn": "2023-08-23T19:09:25.000Z",
          "wordCount": 2895,
          "title": "[D] SeamlessM4T's Research Paper Discusses Purposely Modifying Translations To Make It Less \"Toxic\", Am I Understanding That Correctly? Am I The Only One Who Thinks This Is A MASSIVE Problem??",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zcv86/localhost_as_api_for_stable_diffusion_model_d/",
          "author": null,
          "description": "I want to make a website which uses my trained stable diffusion model but i dont want to deploy it to replicate yet and run it locally for testing. is there any easy way to get the model working as a api? \n maybe someone also has a guide/tutorial for it? \n would appreciate any help!\n    submitted by    /u/Overall-Cry9838  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zcv86/localhost_as_api_for_stable_diffusion_model_d/",
          "publishedOn": "2023-08-23T18:51:25.000Z",
          "wordCount": 2629,
          "title": "Localhost as API for Stable Diffusion Model? [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zcu4w/d_companies_publishing_research_papers/",
          "author": null,
          "description": "Hi Folks!\n Does anybody here know of companies in and around Chicago that invests in publishing ML/AI research/conference papers?\n Thanks!\n    submitted by    /u/karanbond007  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zcu4w/d_companies_publishing_research_papers/",
          "publishedOn": "2023-08-23T18:50:19.000Z",
          "wordCount": 2592,
          "title": "[D] Companies publishing research papers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zciwo/d_unique_idea_for_handwriting_synthesis/",
          "author": null,
          "description": "i saw bunch of handwriting synthesis projects using generative ai to recreate handwriting but the issue with them is they require quite a lot of computational power to train, large amount of data and its not personalised (it cannot copy anyone handwriting, it just gives a general output). So i have a unique idea(i hope its not done before), 1. Use a segmentation model to extract each word from a page 2. Separate and identify each extracted word 3. Store the word, then when its time to recreate the handwriting take the stored word and paste it . For example- If i give a handwritten sample of \" a quick brown fox jump over a lazy dog\" Its stores - \"a\" \"quick \" \"brown\".. and every letter individually like \"a\" \"b\" from “brown”, c from “quick” etc Then when i want to write \"a brown dog\" It takes the stored words (if not word is found combine the alphabets] and paste them together to recreate the sentences in my handwriting (I hope can explained it properly) So i want to take opinion of someone on this (will it work or not) as i dont have much experience in ML i just did a few projects on computer vision\n    submitted by    /u/Soumya1704  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zciwo/d_unique_idea_for_handwriting_synthesis/",
          "publishedOn": "2023-08-23T18:39:29.000Z",
          "wordCount": 2778,
          "title": "[D] Unique idea for handwriting synthesis",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zcbwa/n_python_code_for_genai_including_the_seminal/",
          "author": null,
          "description": "NoGAN code is a tabular data synthesizer running 1000x faster than GenAI methods based on neural networks, and consistently delivering better results regardless of the evaluation metric (including state-of-the-art new quality metrics capturing a lot more than traditional distances), both on categorical and numerical features, or a mix of both. For details, see technical paper #29, available here. \n https://preview.redd.it/fxxjycjplwjb1.png?width=754&format=png&auto=webp&s=3db34e981506e2b0a50ef76b32e1c20365945769\n Get the code on GitHub.\n #genai #syntheticdata \n    submitted by    /u/MLRecipes  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zcbwa/n_python_code_for_genai_including_the_seminal/",
          "publishedOn": "2023-08-23T18:32:27.000Z",
          "wordCount": 2645,
          "title": "[N] Python code for GenAI, including the seminal NoGAN synthesizer for tabular data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zbq07/p_poker_agent_baseline/",
          "author": null,
          "description": "Hi all, looking for a baseline / prior work to compare against for building a No Limit Texas Hold 'Em agent. Seems like Libratus, Pluribus, DeepStack, etc. are all closed source. Has anyone made an open-source Poker agent that achieves somewhat reasonable performance? \n    submitted by    /u/YodelingVeterinarian  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zbq07/p_poker_agent_baseline/",
          "publishedOn": "2023-08-23T18:10:27.000Z",
          "wordCount": 2614,
          "title": "[P] Poker Agent Baseline",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15zaxwo/n_blog_strategies_for_effective_aillm_cost/",
          "author": null,
          "description": "For those of you knee-deep in cloud infrastructure for AI/LLM projects, you know the cost complexities all too well. This guide from Yotascale delves into proven strategies that can help you navigate these challenges like a pro. Read the blog post here: https://yotascale.com/blog/the-enigma-of-ai-cloud-costs-strategies-for-effective-management/\n    submitted by    /u/More_Knowledge2000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15zaxwo/n_blog_strategies_for_effective_aillm_cost/",
          "publishedOn": "2023-08-23T17:43:08.000Z",
          "wordCount": 2618,
          "title": "[N] Blog: Strategies for effective AI/LLM cost management",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15za6a5/p_outofthebox_fp8_training_nanogpt_demo/",
          "author": null,
          "description": "The latest gen of AI chips can do FP8 compute, but making the most of this isn't straightforward - just naïvely inserting FP8 casts causes training to fail (e.g. grads underflow).\n To fix this I've been working on a method called unit scaling, which I demo in this notebook: github.com/graphcore-research/out-of-the-box-fp8-training.ipynb\n With a one-line code change (model = unit_scale(model)) FP8 training now matches the loss of FP32.\n It works by re-scaling operations in the fwd & bwd pass so that training starts with all tensors in the centre of the numerical range (see visualisations in notebook), with negligible overheads. Hopefully people find this useful in getting the most out of their FP8 hardware.\n    submitted by    /u/thecharlieblake  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15za6a5/p_outofthebox_fp8_training_nanogpt_demo/",
          "publishedOn": "2023-08-23T17:16:26.000Z",
          "wordCount": 2685,
          "title": "[P] Out-of-the-box FP8 training (nanoGPT demo)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15z5fem/p_ideas_for_projects_using_azure_ml/",
          "author": null,
          "description": "Heya! I'm studying for DP-100, Azure Data Scientist Assis. certification. All I have are study materials and guides. It's great (slightly overwhelming tho), but I learn better with practice than theory.\n Any ideas for projects using Azure Portal that could be a cool way to learn more on Data Science, ML, and obviously Azure? Appreciated!\n    submitted by    /u/Zealousideal-Car6009  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15z5fem/p_ideas_for_projects_using_azure_ml/",
          "publishedOn": "2023-08-23T14:25:50.000Z",
          "wordCount": 2629,
          "title": "[P] Ideas for projects using Azure ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15z2tyd/d_coral_accelerator_module/",
          "author": null,
          "description": "Has anyone bought some coral stuff? For years I've wanted to buy some coral stuff from Google but every time I try, no seller has stock, it's my bad luck or it's discontinued, if not, does anyone know when there will be restock? What interests me mainly is an accelerator module, the microchip itself, does anyone know where I could get it?\n    submitted by    /u/sinnstral  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15z2tyd/d_coral_accelerator_module/",
          "publishedOn": "2023-08-23T12:42:52.000Z",
          "wordCount": 2633,
          "title": "[D] Coral accelerator module",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15z233q/d_question_answering_on_specific_corpus/",
          "author": null,
          "description": "Hi,\n I'm a machine learning practitioner but I've only mostly worked with classical ML models and I'm newly interested in larger NLP models for a specific task. I was wondering if it's possible to train a model that specifically does:\n  \nQuestion answering\n On a specific document set\n Without having to supply the specific document to look for the answer for* OR\n With the context being much bigger than the question\n  \n*by this I mean I've looked at stuff like Huggingface's Question Answering tutorials, but mostly the question is like 1 sentence and the context is also like a sentence or two.\n Basically let's say there's like a document that's a few hundred pages long detailing some rules of conduct, and I'd like to ask question about the rules and how to proceed in specific scenarios.\n I think I'm looking for extractive question answering, but I have some questions.\n I get that I'd need to do some ranking and then pass the most likely documents as context, but would that even work if the question is just a sentence and there's a whole corpus of multipage documents to look through? I'm pretty sure cosine similarity would be useless at that point, passage ranking might work but I haven't read up on how that works.\n I think my questions are:\n  \nIs there a model that does question answering on a specific, big corpus of documents?\n What models should I look into?\n Are there any resources you'd recommend for reading into the topic?\n  \nThank you!\n    submitted by    /u/lifesthateasy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15z233q/d_question_answering_on_specific_corpus/",
          "publishedOn": "2023-08-23T12:11:21.000Z",
          "wordCount": 2825,
          "title": "[D] Question Answering on specific corpus",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15z0muk/p_llm_apps_are_mostly_data_pipelines/",
          "author": null,
          "description": "My colleague just wrote up an article on LLM-based apps and how to use data engineering tools to help build them faster that I found really insightful.\n It contains a complete implementation\n  \nwith scraping context data from a docs website\n chunking it, getting embeddings via the openAI API\n loading it into pinecone\n and finally a simple Q&A interface with streamlit on top of it\n  \nHere's a quick summary:\n  \nLangChain and LlamaIndex are great tools for quick exploration\n But aren't perfect for production-grade use\n I think we all know the \"LangChain is pointless\" debate, but there's a lot of real meat to it, and Pat describes a few of them (a lot of LangChains extractors are super basic, 2-3 liners without retries etc.)\n LLM applications are all about moving data, extracting and enriching data (creating embeddings!) are the most expensive ones of those steps\n A bunch of data engineering tools are out there that make these two steps much easier, versionable, robust, and reproducible.\n Meltano is one such tool and Pat implemented the above described pipeline with it\n  \nFWIW: The GitHub project that comes with the post is super easy to run and super modular. I just tested it and was able to modify everything for my own application within 30 mins.\n    submitted by    /u/sbalnojan  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15z0muk/p_llm_apps_are_mostly_data_pipelines/",
          "publishedOn": "2023-08-23T11:05:25.000Z",
          "wordCount": 2785,
          "title": "[P] LLM Apps Are Mostly Data Pipelines",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ywos1/openai_launches_finetuning_for_gpt35_turbo_n/",
          "author": null,
          "description": "OpenAI just announced a new feature: fine-tuning for GPT-3.5 Turbo, the lightweight version of GPT-3.5. This means that users can now bring their own data and train the model to perform better on specific tasks and domains.\n If you want to stay on top of the latest trends and insights in AI and tech, look here first.\n https://preview.redd.it/8chj51jobtjb1.jpg?width=862&format=pjpg&auto=webp&s=7c710837179d922435ee714572109100d98196ec\n Why this matters:\n  \nFine-tuning opens up new possibilities for creating customized and reliable AI solutions. Users can improve the model’s accuracy, consistency, and style by feeding it relevant data and instructions.\n Fine-tuning can also reduce costs and latency. Users can shorten their text prompts by embedding the instructions into the model itself, whic…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ywos1/openai_launches_finetuning_for_gpt35_turbo_n/",
          "publishedOn": "2023-08-23T07:37:12.000Z",
          "wordCount": 2900,
          "title": "OpenAI launches fine-tuning for GPT-3.5 Turbo [N]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15yqgd2/d_what_are_your_opinions_on_the_ability_of_gans/",
          "author": null,
          "description": "Curious on validity of both styles of training.\n There is Gigagan which had lower FID than diffusion models, however I also don't know if data was fabricated or not (which happens a lot in research). Did any of you actually get the chance to test the fully trained model and compare it to Stable Diffusion or Midjourney?\n There is of course diffusion models which are the only commercialized products which people are actually using.\n Do you think Diffusion models are the way forward and hope for something newer to come out if it does or do you think there will be a resurgence in GAN models again?\n    submitted by    /u/I_will_delete_myself  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15yqgd2/d_what_are_your_opinions_on_the_ability_of_gans/",
          "publishedOn": "2023-08-23T02:20:52.000Z",
          "wordCount": 2689,
          "title": "[D] What are your opinions on the ability of GANS versus Diffusion models in 2023?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15yng80/r_endorse_me_on_arxiv_pleaasee/",
          "author": null,
          "description": "Anyone care to endorse me on arXiv ?? CS AI or ML\n i would thank you forever\n - go to this link : http://arxiv.org/auth/endorse.php\n - enter this code : HCNHBO\n    submitted by    /u/Wrong_Swimming_9158  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15yng80/r_endorse_me_on_arxiv_pleaasee/",
          "publishedOn": "2023-08-23T00:12:07.000Z",
          "wordCount": 2602,
          "title": "[R] Endorse me on arXiv pleaasee !!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ykg72/r_retriever_model_on_wikipedia/",
          "author": null,
          "description": "I am new to RAG. How do you guys build a retrieval using wiki data? What embedding to use? How to index?\n I want to use it for open ended QA\n    submitted by    /u/rodeowrong  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ykg72/r_retriever_model_on_wikipedia/",
          "publishedOn": "2023-08-22T22:13:31.000Z",
          "wordCount": 2603,
          "title": "[R] Retriever Model on Wikipedia",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15yj5fk/d_whats_next_for_cv_after_bounding_boxes/",
          "author": null,
          "description": "Real-world usage of CV has been dominated by object detection (a la YOLO). Labeled bounding boxes are the cornerstone of the biggest CV applications in manufacturing and surveillance. But what's next?\n We (a team of researchers at Stanford) just put out a short blogpost on Video Analysis Beyond Bounding Boxes. We would love any feedback on this vision for what the future of CV could look like!\n    submitted by    /u/calebwin  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15yj5fk/d_whats_next_for_cv_after_bounding_boxes/",
          "publishedOn": "2023-08-22T21:25:39.000Z",
          "wordCount": 2642,
          "title": "[D] What's next for CV after bounding boxes?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15yipny/d_getting_formatted_variable_output_from_llm/",
          "author": null,
          "description": "I have been trying to extract information from a LLM in a formatted way. I have tried jsonformer and clownfish, but can't seem to get it to work. \n In particular, I am trying to extract what Vicuna 7B knows about cheese. If I ask it what kinds of cheeses it knows, it will list them. If I ask about a particular kind of cheese, it will tell me about that kind. \n  \nUSER: List different kinds of cheese \n ASSISTANT: There are many different kinds of cheese, including: \n  \nCheddar \n \nMozzarella \n \nParmesan \n \nSwiss \n \nGouda \n \nEmmental \n \nGruyère \n \nCamembert \n \nBrie \n \nBlue cheese \n \nGoat cheese \n \nFeta \n \nRicotta \n \nRoquefort \n \nPepper Jack \n \nFontina \n \nProvolone \n \nPecorino \n \nMascarpone \n \nYarg \n \n USER: What kind of cheese is yarg? \n ASSISTANT: Yarg is a type of soft cheese that is traditi…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15yipny/d_getting_formatted_variable_output_from_llm/",
          "publishedOn": "2023-08-22T21:10:03.000Z",
          "wordCount": 2999,
          "title": "[D] Getting formatted, variable output from LLM",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ygttd/r_open_sourcing_a_data_science_analytics_platform/",
          "author": null,
          "description": "Question to the ML builders: Would you like to use a user-friendly data science analytics platform if we open-source it? Lyzr is to data analysts and business users what Streamlit is to data scientists and ML engineers.\n We're on the verge of launching an open-source version of our new insights platform, www.lyzr.ai, explicitly crafted with the analyst community in mind, and we'd be honored if you could test it and share your invaluable feedback. It may currently seem like a mere GPT wrapper, but trust us, countless hours and dedication have gone into making this more than just that.\n Why did we create it?\n There is just 1 data scientist for every 100 data analysts (as per GCP data analytics head). We envision a world where data analysts and business users have the tools to dabble more in to data science. Our platform also aims to simplify the 0-75th percentile of descriptive statistics for data scientists, allowing them to concentrate on building more complicated data science models.\n The cherry on top? We're gearing towards an open-source launch. We believe in the power of collective genius and want everyone to benefit from what we've built and further enhance it collaboratively.Please let me know if you are interested in giving it a spin. Will DM the link.\n And let us know what you think! What features resonate with you? What's missing? Would you use it if open-sourced?\n Your feedback will not only be appreciated, but it'll also be instrumental in shaping the future of this platform.\n Thank you and looking forward to your insights!\n    submitted by    /u/sivasurendira  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ygttd/r_open_sourcing_a_data_science_analytics_platform/",
          "publishedOn": "2023-08-22T20:01:58.000Z",
          "wordCount": 2837,
          "title": "[R] Open Sourcing a Data Science Analytics Platform",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15yfzbl/d_finetuning_keras_ocr/",
          "author": null,
          "description": "Hello everyone. I'm trying to fine-tune an existing OCR model called keras_ocr. In order to do so, I followed the instructions provided in the model documentation, which can be found at this link: https://kerasocr.readthedocs.io/en/latest/examples/fine_tuning_recognizer.html.\n Unfortunately, I encountered an error when I attempted to fit the model using the provided code. Could you please provide me with specific details about the error message I received? and how I can solve it.\n Epoch 1/1000 --------------------------------------------------------------------------- ValueError Traceback (most recent call last) <ipython-input-12-1ffeefaf1864> in <cell line: 6>() 4 tf.keras.callbacks.CSVLogger('recognizer_borndigital.csv') 5 ] ----> 6 recognizer.training_model.fit( 7 training_gen, 8 steps_…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15yfzbl/d_finetuning_keras_ocr/",
          "publishedOn": "2023-08-22T19:31:19.000Z",
          "wordCount": 2807,
          "title": "[D] Fine-tuning keras_ocr",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15yeoyc/p_multivariate_timeseries_analysis_and_annotation/",
          "author": null,
          "description": "I was working on a time-series classification problem for which we had to label the data ourselves. To visualize/annotate and manipulate the data, I created a tool built on top of Matplotlib and Pandas using PySide6.\n I thought it might be helpful for any people that are working on time-series data. \n https://i.redd.it/hw65zxdrfpjb1.gif\n The only requirement for the data is the presence of a \"DateTime\" column - the tool supports loading .xlsx, .csv and pickled-dataframe files. \n The source code is available on GitHub, and the app can also be installed from PyPi (pip install MVTS-Analyzer - tested on windows/ubuntu with > Python3.8). Any feedback is of course welcome. \n    submitted by    /u/Woutaha  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15yeoyc/p_multivariate_timeseries_analysis_and_annotation/",
          "publishedOn": "2023-08-22T18:45:40.000Z",
          "wordCount": 2680,
          "title": "[P] Multivariate time-series analysis and annotation tool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ydp30/r_graph_of_thoughts_solving_elaborate_problems/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2308.09687 \n Github: https://github.com/spcl/graph-of-thoughts \n Abstract:\n  \nWe introduce Graph of Thoughts (GoT): a framework that advances prompting capabilities in large language models (LLMs) beyond those offered by paradigms such as Chain-of-Thought or Tree of Thoughts (ToT). The key idea and primary advantage of GoT is the ability to model the information generated by an LLM as an arbitrary graph, where units of information (\"LLM thoughts\") are vertices, and edges correspond to dependencies between these vertices. This approach enables combining arbitrary LLM thoughts into synergistic outcomes, distilling the essence of whole networks of thoughts, or enhancing thoughts using feedback loops. We illustrate that GoT offers advantages over state of the art on different tasks, for example increasing the quality of sorting by 62% over ToT, while simultaneously reducing costs by >31%. We ensure that GoT is extensible with new thought transformations and thus can be used to spearhead new prompting schemes. This work brings the LLM reasoning closer to human thinking or brain mechanisms such as recurrence, both of which form complex networks. \n  \nhttps://preview.redd.it/jy60udt8cpjb1.jpg?width=1523&format=pjpg&auto=webp&s=d91e1a1784f236d56cacae666ff2f88f3b810556\n https://preview.redd.it/d1d9t5u8cpjb1.jpg?width=925&format=pjpg&auto=webp&s=5eb7f59a6d292687ca41974c4c4448e233969748\n https://preview.redd.it/7ywrlht8cpjb1.jpg?width=932&format=pjpg&auto=webp&s=44bb76ed8d40d8c9cff6d0fc575ce58635915110\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ydp30/r_graph_of_thoughts_solving_elaborate_problems/",
          "publishedOn": "2023-08-22T18:10:35.000Z",
          "wordCount": 2753,
          "title": "[R] Graph of Thoughts: Solving Elaborate Problems with Large Language Models - ETH Zürich 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15yddtg/d_are_there_any_books_that_would_help_with/",
          "author": null,
          "description": "As the title is saying, I have experience with ML enough to be able to implement things myself (as a way to make my CV better, and for my academic future). I want to start implementing papers, but before doing that I need to know where to even start? Are there any books that can help me with that? Implementing the algorithms from scratch so I can build on that?\n    submitted by    /u/theonewhoask11  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15yddtg/d_are_there_any_books_that_would_help_with/",
          "publishedOn": "2023-08-22T17:59:36.000Z",
          "wordCount": 2651,
          "title": "[D] Are there any books that would help with implementing the ML/Deep Leaning algorithms?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15yda4k/r_quip_2bit_quantization_of_large_language_models/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2307.13304\n Github: https://github.com/jerry-chee/QuIP\n Abstract:\n  \nThis work studies post-training parameter quantization in large language models (LLMs). We introduce quantization with incoherence processing (QuIP), a new method based on the insight that quantization benefits from incoherent weight and Hessian matrices, i.e., from the weights and the directions in which it is important to round them accurately being unaligned with the coordinate axes. QuIP consists of two steps: (1) an adaptive rounding procedure minimizing a quadratic proxy objective; (2) efficient pre- and post-processing that ensures weight and Hessian incoherence via multiplication by random orthogonal matrices. We complement QuIP with the first theoretical analysis for an LLM-scale quantization algorithm, and show that our theory also applies to an existing method, OPTQ. Empirically, we find that our incoherence preprocessing improves several existing quantization algorithms and yields the first LLM quantization methods that produce viable results using only two bits per weight. \n  \nhttps://preview.redd.it/uu034fa6apjb1.jpg?width=927&format=pjpg&auto=webp&s=c22148c1ba6d57e9690b9c46aa3d433bf0023b47\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15yda4k/r_quip_2bit_quantization_of_large_language_models/",
          "publishedOn": "2023-08-22T17:55:44.000Z",
          "wordCount": 2728,
          "title": "[R] QuIP: 2-Bit Quantization of Large Language Models With Guarantees - Cornell University 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15yd94s/d_face_recognition_whats_the_state_of_the_art/",
          "author": null,
          "description": "​\n Hi. I want to know how can I make a python script/app which will be able to detect and then recognize faces at a certain distance (let's say 5-10feet) Real-Time from CCTV camera. It should also be able to recognize Unknown faces correctly. One major problem I am facing is that unknown faces are being labeled as known faces even though their face looks nothing like that. Also, it should be able to recognize at least 500-1000 different faces correctly.\n ​\n What are some good git repos/ latest technology that I should look into? Also, I want to know how does Hikvision implement face recognition in their newer cameras? What model do they use to recognize faces?\n ​\n ​\n ​\n  \nhttps://github.com/ageitgey/face_recognition : I have tried this out. It's easy to code and accurately recognizes faces. The problem is it can't even detect faces 1 feet away from the camera.\n  \n​\n  \nhttps://github.com/timesler/facenet-pytorch (FaceNet & MTCNN) : This can detect and recognize faces at a distance, but the problem is it can't recognize unknown faces correctly. I mean for unknown faces it always tries to label it as one of the faces from the model/ database encodings.\n  \n​\n  \nhttps://github.com/serengil/deepface : I have tried VGG, ArcFace, Facenet512. The latter two gave me good results. But, the problem is I couldn't figure out how to change the detection from every 5 seconds to real-time. Also, I couldn't change the camera source. (If anyone can help me with these please do). Also, it had fps drops frequently.\n  \n​\n  \nhttps://github.com/deepinsight/insightface: Couldn't test this yet. But in the demo YT video it shows the model incorrectly detecting a random object as a face. If someone knows how well this performs please let me know.\n  \n   submitted by    /u/ProfessionalNovel984  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15yd94s/d_face_recognition_whats_the_state_of_the_art/",
          "publishedOn": "2023-08-22T17:54:43.000Z",
          "wordCount": 2862,
          "title": "[D] Face Recognition: What's The State Of The Art Technology Out There?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15yd2vf/d_what_are_the_currently_recommended_approaches/",
          "author": null,
          "description": "Im familiar with the VFP290K approach but in the new world of transformers are there better approaches?\n    submitted by    /u/bluzkluz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15yd2vf/d_what_are_the_currently_recommended_approaches/",
          "publishedOn": "2023-08-22T17:48:14.000Z",
          "wordCount": 2597,
          "title": "[D] what are the currently recommended approaches to detecting slips/falls in surveillance videos?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ybulw/d_sota_in_oneshot_face_recognition/",
          "author": null,
          "description": "What is the current SOTA in one-shot face recognition? Looking for something like FaceID but without the IR illuminator/camera data.\n I see that GhostFace and ArcFace are the SOTA right now for face recognition but it's for generic face recognition and not one-shot\n    submitted by    /u/jayshenoyu  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ybulw/d_sota_in_oneshot_face_recognition/",
          "publishedOn": "2023-08-22T17:04:22.000Z",
          "wordCount": 2616,
          "title": "[D] SOTA in one-shot face recognition",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15ya6d9/d_rlhf_vs_rlaif_for_language_model_alignment/",
          "author": null,
          "description": "Hey everyone,\n As most of you here know, RLHF became famous with the release of ChatGPT. While LLMs were capable as general-purpose agents before the release of ChatGPT, RLHF was the crucial factor that differentiates it from previous models.\n With the increasing popularity of AI assistants, we've seen recently how they can be manipulated to produce harmful and unethical outputs.\n Anthropic devised a new method for LLM alignment called Constitutional AI, which is closely tied to their concept of Reinforcement Learning from AI Feedback. Instead of using human feedback to train the LLM, RLAIF uses AI feedback. \n I wrote this article on RLHF vs RLAIF for language model alignment that I thought you might enjoy. It's not super technical and seeks to serve as an overview of the inspiration for creating RLAIF, so I hope it will be helpful even if you don't work in NLP. Here are some highlights: \n  \nRLAIF constitutes a Pareto improvement over RLHF, simultaneously improving helpfulness and harmlessness\n RLAIF (in this formulation) incorporates a constitution of principles by which it should abide\n RLAIF is much more scalable than RLHF as a means of supervising alignment\n  \n​\n https://preview.redd.it/d1i6x8kiqojb1.png?width=960&format=png&auto=webp&s=93c60080ae146dda07990ad9dc8b94e3bbec2d0e\n    submitted by    /u/SleekEagle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15ya6d9/d_rlhf_vs_rlaif_for_language_model_alignment/",
          "publishedOn": "2023-08-22T16:05:09.000Z",
          "wordCount": 2764,
          "title": "[D] RLHF vs RLAIF for language model alignment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15y7yfb/r_releasing_idefics_the_first_open_stateoftheart/",
          "author": null,
          "description": "Hugging Face is releasing IDEFICS, an 80B open-access visual language model.\n IDEFICS is a reproduction of Flamingo, a multimodal model developed by DeepMind, which has not been released publicly. \n The model is built solely on publicly available data and models. It is the first visual language model of this scale available in open-access!\n IDEFICS was partly trained on OBELICS, a new open large-scale dataset of interleaved image-text documents comprising 141M web pages extracted from Common Crawl, 353M associated images, and 115B text tokens. \n Training the model was a bumpy trip, and this knowledge sharing memo compiles some of the learnings.\n Ressources:\n Announcement: https://huggingface.co/blog/idefics\n Demo: https://huggingface.co/spaces/HuggingFaceM4/idefics_playground\n Models: https://huggingface.co/HuggingFaceM4/idefics-80b-instruct\n OBELICS dataset: https://huggingface.co/datasets/HuggingFaceM4/OBELICS\n OBELICS paper: https://arxiv.org/abs/2306.16527\n Lessons learned: https://github.com/huggingface/m4-logs/blob/master/memos/README.md\n    submitted by    /u/VictorSanh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15y7yfb/r_releasing_idefics_the_first_open_stateoftheart/",
          "publishedOn": "2023-08-22T14:46:38.000Z",
          "wordCount": 2689,
          "title": "[R] Releasing IDEFICS, the first open state-of-the-art visual language model at the 80B scale!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15y1v6t/p_visionscript_an_abstract_programming_language/",
          "author": null,
          "description": "Hello! I'm James and I am working on VisionScript, an abstract programming language for computer vision. With VisionScript, I want to empower people -- including everyone without any prior programming experience -- to build cool apps with vision.\n This weekend, I recorded a demo for VisionScript, in which I made apps that count how many cats are in an image and hides people in a video. Each app was < 10 lines of code.\n https://vimeo.com/856043804\n VisionScript is built for the 10 year old inside of me who would have loved more visual programming languages with which to play. I want to show people the potential of programming and how you can make what you want with computers, whether it be a game that counts cats or an app that monitors how many birds flew past a tree. Those \"wow\" moments should come as soon as possible in one's learning experience.\n VisionScript is in active development. I started work on this project in July. Follow along as I add more features and explore more possibilities in making computer vision intuitive.\n    submitted by    /u/zerojames_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15y1v6t/p_visionscript_an_abstract_programming_language/",
          "publishedOn": "2023-08-22T10:33:17.000Z",
          "wordCount": 2755,
          "title": "[P] VisionScript: An abstract programming language for computer vision",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xygyr/d_neurips_discussion_phase_has_ended_how_was_the/",
          "author": null,
          "description": "I am not sure if \"Discussion\" was always part of the Neurips pipeline but I felt like it was a good addition (in principle). \n On one hand it alows the authors to present their case with more clarity. On the other hand, it does increase the overhead for the reviewers which are now required to work even harder (and for free). \n For me, it was a mixed bag. Most of the reviewers did engage and the discussion was indeed fruitful. However, some didn't bother to follow up on the responses to their concerns and questions. Unfortunately, also quite expected. \n I would definitely like to see this in the next Neurips but maybe with some tweaks and modifications keeping in mind the (unpaid) reviewers.\n    submitted by    /u/PaganPasta  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xygyr/d_neurips_discussion_phase_has_ended_how_was_the/",
          "publishedOn": "2023-08-22T07:37:13.000Z",
          "wordCount": 2704,
          "title": "[D] NeurIPS Discussion phase has ended. How was the overall experience for you ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xxnc7/d_emnlp_2023_rebuttal/",
          "author": null,
          "description": "Reviews for EMNLP 2023 will be released soon. Good luck to everyone and we could use this post for discussion about the reviews!\n    submitted by    /u/Alliswell2257  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xxnc7/d_emnlp_2023_rebuttal/",
          "publishedOn": "2023-08-22T06:55:01.000Z",
          "wordCount": 2594,
          "title": "[D] EMNLP 2023: Rebuttal",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xst1a/d_has_anyone_tried_taking_an_ai_tts_model_and/",
          "author": null,
          "description": "I'm working on a fun side project of AI TTS in python (that also features chatGPT). I was initially using Elevenlabs and the quality of the voices was incredible. But I quickly realized that it was a very expensive API. This has led me down exploring open source alternatives that I can run locally and self host to save money on API costs (or I guess find a cheaper API but I think self hosting long term will be way cheaper.)\n The general consensus seems like the only thing comparable to Elevenlabs is a really well tuned tortoiseTTS model or feeding the output of an AI TTS model into RVC to make the speech sound cleaner and less robotic. Here's the things I've found in my research:\n  \ntortoiseTTS+ RVC v2 - This video seemed pretty promising but I'm a little worried the response times will be…",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xst1a/d_has_anyone_tried_taking_an_ai_tts_model_and/",
          "publishedOn": "2023-08-22T02:55:27.000Z",
          "wordCount": 3055,
          "title": "[D] Has anyone tried taking an AI TTS model and shoving the output into RVC?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xrv15/d_highfrequency_timeseries_signal_classification/",
          "author": null,
          "description": "I'm working with a high-frequency time-series signal (up to 8 kHz). Most of the SOTA I found in Papers With Code and this review work for low frequency dataset. I want to classify and forecast the raw signal if possible. Are there any methods that work? Or should I go with feature extraction and use the feature to classify or forecast? Thanks for the advice.\n    submitted by    /u/puddit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xrv15/d_highfrequency_timeseries_signal_classification/",
          "publishedOn": "2023-08-22T02:13:04.000Z",
          "wordCount": 2640,
          "title": "[D] High-frequency time-series signal classification and forecasting SOTA",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xppwz/d_small_utilities_you_use_for_python/",
          "author": null,
          "description": "Hello, I'm doing some experimentation around deep learning, and I've written a small helper tool, run(fn, description). When I run this command, it will just snapshot the fn code into a python file and prepend the description and output in a comment. Also appends to a log file with [date, description, py filename]. This works well when I use the VSCode's python mode.\n I feel like this is pretty simple and most likely there are better utilities like this. What tools or utilities or do you use?\n Some issues I found:\n  \nmy data loader was outside of fn and didn't get captured\n i forgot to export the opt_state so I couldn't resume learning after I terminated the run\n  \n   submitted by    /u/windoze  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xppwz/d_small_utilities_you_use_for_python/",
          "publishedOn": "2023-08-22T00:40:02.000Z",
          "wordCount": 2693,
          "title": "[D] Small utilities you use for python experimentation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xoz8u/d_wacv_2024_round1_paper_notification/",
          "author": null,
          "description": "WA, B, B, with one B saying willing to increase the score if an additional experiment is provided and the other B saying the approach is not that novel....do I have a chance? How did you all do?\n    submitted by    /u/Individual-Bend-9690  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xoz8u/d_wacv_2024_round1_paper_notification/",
          "publishedOn": "2023-08-22T00:09:44.000Z",
          "wordCount": 2611,
          "title": "[D] WACV 2024 Round-1 Paper Notification",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xnxz9/d_whats_the_best_alternative_for_vertex_al_for/",
          "author": null,
          "description": "Hi, Can anyone suggest a good platform to deploy ml models like Vertex AI?\n I can't use Vertex AI because I have a lot models, and I can't seem to run them on a shared resource pool with 2 gpus because there is a bug in Google infrastructure which I signaled and they responded.\n And what really didn't like is the limit of 60 seconds per call, I am deploying embeddings models and I want to embed a large text chunks, and 90% of the time it fails with the timeout problem.\n Thanks.\n    submitted by    /u/YoussefBenhammouda  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xnxz9/d_whats_the_best_alternative_for_vertex_al_for/",
          "publishedOn": "2023-08-21T23:28:40.000Z",
          "wordCount": 2673,
          "title": "[D] What's the best alternative for Vertex Al for the moment in 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xmrs9/d_what_are_the_limitations_of_the_various_sg_mcmc/",
          "author": null,
          "description": "To me, it seems amazing that something super close to SGD(for example SGLD) can actually sample from the posterior and I am not sure why these methods are not used more often. What are the practical limitations of these methods that prevent them from being used? I have read the literature around HMC and incompatibility with mini batching but what about other variants? Are there any interesting settings where they work well?\n    submitted by    /u/Dangerous-Flan-6581  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xmrs9/d_what_are_the_limitations_of_the_various_sg_mcmc/",
          "publishedOn": "2023-08-21T22:43:33.000Z",
          "wordCount": 2650,
          "title": "[D] What are the limitations of the various SG MCMC methods?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xkuxl/p_llmmodel_for_image_sequence_prediction/",
          "author": null,
          "description": "Hi all - I'm working on a simple pattern recognition project that takes in several sequential inputs and then comes up with (or selects) the next image in the sequence.\n e.g. circle, triangle, square, circle, triangle...? (= square)\n I was wondering if someone had a resource for an open source model that could do something like this already rather than building it up from first principles? Playing around with ImageBind atm but don't think it's the best suited tool to use.\n Would really appreciate any help!\n    submitted by    /u/Strange_Quark8  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xkuxl/p_llmmodel_for_image_sequence_prediction/",
          "publishedOn": "2023-08-21T21:32:30.000Z",
          "wordCount": 2659,
          "title": "[P] LLM/model for image sequence prediction?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xj5sw/d_a_short_video_on_latent_space_exploration/",
          "author": null,
          "description": "Hello guys! So I made a video for my Youtube channel exploring the mysteries of latent space for VAE models trained on celebrity faces (the CelebA dataset). Most of the content is based on the old DFC-VAE paper (https://arxiv.org/abs/1610.00291) which really influenced me back in the day during my graduate studies. Not reinventing the wheel here, just trying to talk about something I always felt intrigued by… and a topic that I think most DL courses just skip/gloss over. \n In the video I discussed some really interesting stuff for understanding and using latent space embeddings, like nearest neighbor searches, cool visualizations, vector arithmetic, latent space interpolation, image manipulation, PCA explainability, etc - basically various examples of how the latent space impacts the generated content.\n Here’s the link in case you guys are interested!\n https://youtu.be/FslFZx08beM\n ​\n    submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xj5sw/d_a_short_video_on_latent_space_exploration/",
          "publishedOn": "2023-08-21T20:31:52.000Z",
          "wordCount": 2709,
          "title": "[D] A short video on Latent Space Exploration",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xh3qb/r_autogen_enabling_nextgen_llm_applications_via/",
          "author": null,
          "description": "Paper: https://arxiv.org/abs/2308.08155 \n Github: https://microsoft.github.io/FLAML/docs/Use-Cases/Autogen/ \n Abstract:\n  \nThis technical report presents AutoGen, a new framework that enables development of LLM applications using multiple agents that can converse with each other to solve tasks. AutoGen agents are customizable, conversable, and seamlessly allow human participation. They can operate in various modes that employ combinations of LLMs, human inputs, and tools. AutoGen's design offers multiple advantages: a) it gracefully navigates the strong but imperfect generation and reasoning abilities of these LLMs; b) it leverages human understanding and intelligence, while providing valuable automation through conversations between agents; c) it simplifies and unifies the implementation of complex LLM workflows as automated agent chats. We provide many diverse examples of how developers can easily use AutoGen to effectively solve tasks or build applications, ranging from coding, mathematics, operations research, entertainment, online decision-making, question answering, etc. \n  \nhttps://preview.redd.it/ax8h0olziijb1.jpg?width=1377&format=pjpg&auto=webp&s=3f520e2480190f6b8fb43443371bdfa0f75f7e82\n https://preview.redd.it/c0fxavlziijb1.jpg?width=1520&format=pjpg&auto=webp&s=601db266f4d6cde7e47d51c191f47c798431ec50\n https://preview.redd.it/yngh3slziijb1.jpg?width=974&format=pjpg&auto=webp&s=cc5a2074834291b98080e54e74556707fbc8ef38\n https://preview.redd.it/7jnneplziijb1.jpg?width=1136&format=pjpg&auto=webp&s=f04ce08881169c24d669c5f9337f80ba48901926\n ​\n ​\n    submitted by    /u/Singularian2501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xh3qb/r_autogen_enabling_nextgen_llm_applications_via/",
          "publishedOn": "2023-08-21T19:16:14.000Z",
          "wordCount": 2721,
          "title": "[R] AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework - Microsoft 2023 - Outperforms ChatGPT+Code Interpreter!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xfs30/p_tco_calculator_to_determine_when_open_source/",
          "author": null,
          "description": "I made a calculator to compare costs of SaaS and on-prem LLM options, and I wanted to share it with you all! Turns out that deploying your own open-source LLMs has a few more hidden costs than expected. It’s been interesting to play around with comparing costs for OpenAI, Cohere, and Llama 2 70B deployment, and it turns out that cost/request is not always so advantageous for open-source local deployment.\n Want to contribute to this calculator to make it more accurate? We’d love your help and feedback!\n Here is the calculator https://huggingface.co/spaces/mithril-security/TCO_calculator, and a guide to contributing your own model with associated cost modeling here https://huggingface.co/spaces/mithril-security/TCO_calculator/blob/main/How_to_contribute.md\n    submitted by    /u/Separate-Still3770  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xfs30/p_tco_calculator_to_determine_when_open_source/",
          "publishedOn": "2023-08-21T18:28:40.000Z",
          "wordCount": 2688,
          "title": "[P] TCO calculator to determine when open source local deployment is more cost-efficient than OpenAI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xfqwh/d_tools_for_reading_and_exploring_machine/",
          "author": null,
          "description": "Is there any way to parse whole papers with ChatGPT or other LLMs in order to summarise their content or to have a conversation and ask questions about a paper?\n I am aware of the tool ArxivGPT, which is a Google Chrome plug-in but unfortunately it only uses the abstract of a paper and not the entire PDF/paper document.\n ​\n ​\n    submitted by    /u/solingermuc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xfqwh/d_tools_for_reading_and_exploring_machine/",
          "publishedOn": "2023-08-21T18:27:29.000Z",
          "wordCount": 2643,
          "title": "[D] Tools for reading and exploring machine learning papers via ChatGPT and other Large Language Models (LLM)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xfol6/discussion_sagemaker_pipelines_gitlab_ci/",
          "author": null,
          "description": "Hey everyone 👋🏻\n This is my first time posting here, so I apologise if I am out of place.\n My team is currently utilising SageMaker pipelines to coordinate model training. In the past, we encountered issues where the pipeline was misconfigured during cloud execution, resulting in challenging-to-debug errors 🐛\n I've been delving into the idea of using Localstack and SageMaker LocalPipelineSession to execute the pipeline locally prior to deployment on the cloud ☁️. I've successfully implemented this on my local machine, using pytest and pytest-bdd to craft integration tests 🧪\n Building on that success, I've ventured into creating a GitLab CI job that runs these tests upon making a merge request. A peculiar aspect of SageMaker pipelines in a local setup is its reliance on Docker. To address this, I've designed a custom Docker image, enabling installation of Python, my dependencies, Docker, and Docker Compose. The job initialises LocalStack and executes the tests. Nevertheless, running these tests within GitLab has brought about Docker-in-Docker related challenges 🐳 It's been quite a frustrating experience... The SageMaker pipelines run, although unsuccessfully with silent errors 🤫\n Given this context (my apologies for the length), I'm seeking advice. Is this approach worthwhile? I find myself going in circles ⭕️ Could you offer any solutions for running SageMaker pipelines in a CI environment prior to deploying to the cloud? 🙋🏻‍♂️ Thanks in advance 🙏🏼\n    submitted by    /u/OpenShape5402  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xfol6/discussion_sagemaker_pipelines_gitlab_ci/",
          "publishedOn": "2023-08-21T18:25:08.000Z",
          "wordCount": 2800,
          "title": "[Discussion] SageMaker pipelines GitLab CI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xfesk/d_why_fine_tune_a_65b_llm_instead_of_using/",
          "author": null,
          "description": "I have been in the ML field since 2018 so got used to see the market over-excited about new models/paradigms. So wondering if the following is just that or I’m missing/missed something.\n Everywhere I look today (medium, reddit, twitter) everyone is talking about fine-tuning LLMs. How the future is taking billion size models and fine-tuning/distilling them to specialised LLMs that perform specific tasks (i.e: sentiment analysis, Q&A, summarisation).\n Why not just use “small” (millions vs billion size) models that are specifically fine-tuned for these final tasks instead? Any benchmarks on how LLMs perform on these down stream tasks ? or it's just that smaller models are not as accessible as an OpenAPI is ?\n Curious to get your view on the topics, thanks !\n P.S: Example of small models (Just went on HF and picked most downloaded based on some tasks):\n Q&A: https://huggingface.co/deepset/roberta-base-squad2\n Summarisation: https://huggingface.co/facebook/bart-large-cnn\n Sentiment analysis: https://huggingface.co/SamLowe/roberta-base-go_emotions\n    submitted by    /u/EnthusiasmNew7222  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xfesk/d_why_fine_tune_a_65b_llm_instead_of_using/",
          "publishedOn": "2023-08-21T18:15:26.000Z",
          "wordCount": 2732,
          "title": "[D] Why fine tune a 65B LLM instead of using established task specific smaller models (~200 millions)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xdmz3/d_people_who_has_used_openreview_are_the_authors/",
          "author": null,
          "description": "Long story short, this year NeurIPS in a paper which I am not really associated with, the co-authors got into a huge fight about author ordering, and one of them threatens to withdraw the submission. I'm just curious if a withdrew submission on OpenReview is able to be restored and returns to the regular review process once the withdrawal button is clicked. The paper now has all the review rebutalled.\n    submitted by    /u/SuperTankMan8964  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xdmz3/d_people_who_has_used_openreview_are_the_authors/",
          "publishedOn": "2023-08-21T17:10:41.000Z",
          "wordCount": 2652,
          "title": "[D] People who has used OpenReview, are the authors able to restore a withdrew submission?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xcs6m/writing_applied_deep_machine_learning_proposals_d/",
          "author": null,
          "description": "Hi,\n Does anyone have any resources or insight they could share regarding writing applied deep / machine learning proposals. I've done a bit of reading and come up with the following outline. What am I missing? What aspects are the most important to focus on?\n Thanks\n  \nProblem & Background \n Review of current relevant research, explanation of how this work will expand the body of knowledge in the field.\n Clear statement of the problem and how ML/DL will solves the issue at hand.\n \n Dataset \n Collection procedure\n Size of dataset to be collected\n Annotation procedure\n \n Algorithm/Network Architecture \n Aspects the algorithm / network architecture the make it well suited to the problem at hand\n References demonstrating promising results on similar problems\n Modifications that may be explored as part of the effort\n \n Data Preprocessing \n Cleaning\n Train validation test split 80%, 10%, 10%\n Stratification, if applicable\n Feature engineering, if applicable\n \n Training Strategy \n Tooling ( e.g. Pytorch, Tensorflow, scikit-learn)\n Loss function & evaluation metrics\n Hyperparameter optimization\n Compute facilities\n \n Possible challenges & mitigation strategies\n  \n​\n Edit: formatting\n    submitted by    /u/rcg8tor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xcs6m/writing_applied_deep_machine_learning_proposals_d/",
          "publishedOn": "2023-08-21T16:39:06.000Z",
          "wordCount": 2744,
          "title": "Writing Applied Deep / Machine Learning Proposals [D]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xcqsv/p_i_made_stable_diffusion_xl_smarter_by/",
          "author": null,
          "description": "https://minimaxir.com/2023/08/stable-diffusion-xl-wrong/\n I fed Stable Diffusion XL examples of bad images that it itself generated and it surprisingly made SDXL behave much better to the spirit of the prompt!\n Also, many more demo prompt examples + results + Jupyter Notebooks!\n    submitted by    /u/minimaxir  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xcqsv/p_i_made_stable_diffusion_xl_smarter_by/",
          "publishedOn": "2023-08-21T16:37:32.000Z",
          "wordCount": 2620,
          "title": "[P] I Made Stable Diffusion XL Smarter by Finetuning it on Bad AI-Generated Images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xco81/d_looking_for_feedback_on_what_i_have_written_so/",
          "author": null,
          "description": "Hello everyone,\n ​\n I hope you are having a blessed day so far. I recently created an online blog post and attached its link to this post. I think I have discovered a unique new perspective on \"Prompt Engineering\". That will make learning to code vastly more fun as users see and can run AI-generated scripts based on their given input to the AI. After just briefly training a free publicly accessible AI. You can then in less than 3 written prompts generate vast and fairly complex programs in seconds with zero prior experience required it's truly exciting. My ultimate goal is to go more in-depth as these are just very high-level overviews to convey the concept as a whole. \n Next, I would like to then create a course covering how to leverage free AI and ML systems so that anyone can now learn …",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xco81/d_looking_for_feedback_on_what_i_have_written_so/",
          "publishedOn": "2023-08-21T16:34:50.000Z",
          "wordCount": 3581,
          "title": "[D] Looking for feedback on what I have written so far (a very high-level overview)! I ultimately want to create an AI-Generated Interactive online course to help teach beginners-experts how to leverage free AI and ML Models to instantly increase their capabilities. Thank you!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xcgf4/p_a_new_tightlyscoped_researchfocused_ml_subreddit/",
          "author": null,
          "description": "Hello,\n I just created https://www.reddit.com/r/mlfundamentalresearch/ as a complement to r/machinelearning in response to the post last week. This is a very narrow space specifically focused on _fundamental ML research only_. The only outside work that can be shared on it are papers and direct links to notebooks. Past research [>3 years old] is explicitly encouraged, since much untapped value lies in it. No self-promotion whatsoever will be allowed, that can happen in other places. This includes any form of reference or link to one's own Github repo. This is meant to be an extremely functional and task-oriented research subreddit.\n I don't have huge expectations for this to become the size of r/MachineLearning. If there are even 20 active users then I will be happy and it will be serving its purpose. This will hopefully provide a tiny arena for those of us wishing to work on more fundamental things to coordinate. While the rules are strict, they are meant to keep the subreddit both publicly-accessible and within scope without requiring an explicit application process.\n Happy to answer any questions and make changes as needed, I have put up some sample posts as examples and to kickstart momentum if anyone should like to use the subreddit. I would certainly find it helpful to work with others in a community like this. Look forward to hearing what your thoughts are, if any.\n    submitted by    /u/tysam_and_co  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xcgf4/p_a_new_tightlyscoped_researchfocused_ml_subreddit/",
          "publishedOn": "2023-08-21T16:26:42.000Z",
          "wordCount": 2804,
          "title": "[P] A new tightly-scoped, research-focused ML subreddit",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xb6sc/r_consciousness_in_artificial_intelligence/",
          "author": null,
          "description": "submitted by    /u/hardmaru  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xb6sc/r_consciousness_in_artificial_intelligence/",
          "publishedOn": "2023-08-21T15:39:50.000Z",
          "wordCount": 2589,
          "title": "[R] Consciousness in Artificial Intelligence: Insights from the Science of Consciousness",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xals5/d_nlp_handling_abbreviations/",
          "author": null,
          "description": "I'm trying to build a multi class text classifier (~200 classes). The issue with my dataset is that almost all documents are almost all examples contain a bunch of abbreviations. Abbreviations may or may not contain punctuations. I think it's affecting performance but not sure.\n What's the best way to handle abbreviations? Maintain a look up list and preprocess the documents?\n Edit: abbreviations are mostly 90% nouns and 10% adjectives.\n    submitted by    /u/tsailfc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xals5/d_nlp_handling_abbreviations/",
          "publishedOn": "2023-08-21T15:18:01.000Z",
          "wordCount": 2641,
          "title": "[D] NLP Handling Abbreviations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15xalg0/d_data_preparation_stuck_to_the_json_creation/",
          "author": null,
          "description": "After going trough the data preparation from the example mov and the example guide, I correctly generated the following folder structure:\n PATH_TO_IMAGES\n |__ database.db (COLMAP databse)\n |__ raw_images (raw input images)\n |__ dense\n |____ images (undistorted images)\n |____ sparse (COLMAP correspondences, intrinsics and sparse point cloud)\n |____ stereo (COLMAP files for MVS)\n The images folder and sparse folder contain as predicted respectively some img files, and bin files for the other, but each folder inside stereo is empty, i did not receive any error during the process so i tried to go on anyway.\n When i then tried to run :\n \"PATH_TO_IMAGES=toy_example_skip30\n SCENE_TYPE=object # {outdoor,indoor,object}\n python3 projects/neuralangelo/scripts/convert_data_to_json.py --data_dir ${PATH_TO_IMAGES}/dense --scene_type ${SCENE_TYPE}\"\n i run it, but without any errors, or log, it just never stops nor logs anything out\n Any help in understanding what issue may be causing this? i run normally everything else as described in the repo guide:\n https://github.com/NVlabs/neuralangelo/blob/main/DATA_PROCESSING.md\n    submitted by    /u/ResponsibleTie8204  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15xalg0/d_data_preparation_stuck_to_the_json_creation/",
          "publishedOn": "2023-08-21T15:17:37.000Z",
          "wordCount": 2727,
          "title": "[D] Data preparation stuck to the json creation / neuralangelo",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15x9c7e/r_recent_surveys_in_choice_modelingranking/",
          "author": null,
          "description": "I’m looking to build some knowledge of recent work in choice modeling and ranking. Does anyone have recommendations of good surveys in these areas?\n My background is primarily in bandits and active learning, so any papers with that perspective are especially appreciated.\n    submitted by    /u/BasedAcid  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15x9c7e/r_recent_surveys_in_choice_modelingranking/",
          "publishedOn": "2023-08-21T14:30:59.000Z",
          "wordCount": 2615,
          "title": "[R] Recent surveys in choice modeling/ranking?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/MachineLearning/comments/15x8yx6/d_how_to_log_metrics_contain_loss_and_accuracy_of/",
          "author": null,
          "description": "Hi everyone,\n I'm currently research the AI/ML model using sagemaker, i built a grocery recommendation based on customer rate behavior as a lab. I have some problem using sagemaker experiment service, i can't get the loss values and accuracy of each training epoch so that i can draw a chart for the visualization. Anyone has ideas about it, please share.\n Thank you.\n https://preview.redd.it/fzd8mz942hjb1.png?width=1853&format=png&auto=webp&s=6d75630acc3940c8fb4e4460b8a0eba8e9407b45\n https://preview.redd.it/x2hpvjza2hjb1.png?width=927&format=png&auto=webp&s=f1c30944870df2d8fea182e3a6d8c70a80e60a7c\n    submitted by    /u/Open_Juice_2972  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/MachineLearning/comments/15x8yx6/d_how_to_log_metrics_contain_loss_and_accuracy_of/",
          "publishedOn": "2023-08-21T14:17:00.000Z",
          "wordCount": 2644,
          "title": "[D] How to log metrics (contain loss and accuracy,...) of each epoch in aws sagemaker",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "ML in Production",
      "feedUrl": "https://mlinproduction.com/feed",
      "siteUrl": "https://mlinproduction.com",
      "articles": []
    },
    {
      "title": "Jay Alammar",
      "feedUrl": "https://jalammar.github.io/feed.xml",
      "siteUrl": "http://jalammar.github.io/",
      "articles": []
    },
    {
      "title": "Distill",
      "feedUrl": "https://distill.pub/rss.xml",
      "siteUrl": "https://distill.pub",
      "articles": []
    },
    {
      "title": "inFERENCe",
      "feedUrl": "https://www.inference.vc/rss",
      "siteUrl": "https://www.inference.vc/",
      "articles": []
    },
    {
      "title": "AI Trends",
      "feedUrl": "https://www.aitrends.com/feed",
      "siteUrl": "https://www.aitrends.com/",
      "articles": []
    },
    {
      "title": "AI Weirdness",
      "feedUrl": "https://aiweirdness.com/rss",
      "siteUrl": "https://www.aiweirdness.com/",
      "articles": [
        {
          "id": "64eb824d30996300012dcb3b",
          "author": "Janelle Shane",
          "description": "On July 31, 2023, a giraffe with no spots was born at Brights Zoo in Tennessee. She's a uniform brown with pretty white highlights around her face and belly, like a Jersey cow or a white-tailed deer.\nImage recognition algorithms are trained on a variety of images from",
          "link": "https://www.aiweirdness.com/ai-vs-a-giraffe-with-no-spots/",
          "publishedOn": "2023-08-28T13:38:07.000Z",
          "wordCount": 1510,
          "title": "AI vs a giraffe with no spots",
          "imageUrl": "https://www.aiweirdness.com/content/images/2023/08/InstructBLIP_detailed-1.png"
        },
        {
          "id": "64ebc96930996300012dcce7",
          "author": "Janelle Shane",
          "description": "AI Weirdness: the strange side of machine learning",
          "link": "https://www.aiweirdness.com/attempts-to-generate-a-spotless-giraffe/",
          "publishedOn": "2023-08-28T13:36:46.000Z",
          "wordCount": 701,
          "title": "Attempts to generate a spotless giraffe",
          "imageUrl": "https://www.aiweirdness.com/content/images/2021/03/neural_net_box_default_square-01-2.png"
        }
      ]
    },
    {
      "title": "The Berkeley Artificial Intelligence Research Blog",
      "feedUrl": "https://bair.berkeley.edu/blog/feed.xml",
      "siteUrl": "http://bair.berkeley.edu/blog/",
      "articles": []
    },
    {
      "title": "Becoming Human: Artificial Intelligence Magazine - Medium",
      "feedUrl": "https://becominghuman.ai/feed",
      "siteUrl": "https://becominghuman.ai?source=rss----5e5bef33608a---4",
      "articles": []
    },
    {
      "title": "MIT News - Artificial intelligence",
      "feedUrl": "http://news.mit.edu/rss/topic/artificial-intelligence2",
      "siteUrl": "https://news.mit.edu/rss/topic/artificial-intelligence2",
      "articles": [
        {
          "id": "https://news.mit.edu/2023/accenture-fellows-advance-technology-crossroads-business-society-0919",
          "author": "School of Engineering",
          "description": "The MIT and Accenture Convergence Initiative for Industry and Technology announces the 2023-24 graduate fellows.",
          "link": "https://news.mit.edu/2023/accenture-fellows-advance-technology-crossroads-business-society-0919",
          "publishedOn": "2023-09-19T20:45:00.000Z",
          "wordCount": 2608,
          "title": "Meet the 2023-24 Accenture Fellows",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/mit-Accenture-Fellows-22-23.png"
        },
        {
          "id": "https://news.mit.edu/2023/lincoln-laboratory-technologies-win-rd-world-awards-0919",
          "author": "Kylie Foy | MIT Lincoln Laboratory",
          "description": "Inventions in medical imaging, aircrew scheduling, data security, and quantum networking are named among the year’s most innovative new products.",
          "link": "https://news.mit.edu/2023/lincoln-laboratory-technologies-win-rd-world-awards-0919",
          "publishedOn": "2023-09-19T20:35:34.000Z",
          "wordCount": 3272,
          "title": "Four Lincoln Laboratory technologies win five 2023 R&D 100 awards",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/quantum-memory-mit-lincoln-lab_0.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/mit-scholars-awarded-seed-grants-generative-ai-0918",
          "author": "MIT News",
          "description": "The 27 finalists — representing every school at MIT — will explore the technology’s impact on democracy, education, sustainability, communications, and much more.",
          "link": "https://news.mit.edu/2023/mit-scholars-awarded-seed-grants-generative-ai-0918",
          "publishedOn": "2023-09-18T19:00:00.000Z",
          "wordCount": 3051,
          "title": "MIT scholars awarded seed grants to probe the social implications of generative AI",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/MIT-AI-ImpactPaper-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/multi-ai-collaboration-helps-reasoning-factual-accuracy-language-models-0918",
          "author": "Rachel Gordon | MIT CSAIL",
          "description": "Researchers use multiple AI models to collaborate, debate, and improve their reasoning abilities to advance the performance of LLMs while increasing accountability and factual accuracy.",
          "link": "https://news.mit.edu/2023/multi-ai-collaboration-helps-reasoning-factual-accuracy-language-models-0918",
          "publishedOn": "2023-09-18T13:00:00.000Z",
          "wordCount": 2700,
          "title": "Multi-AI collaboration helps reasoning and factual accuracy in large language models",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/Multiagent-debate.png"
        },
        {
          "id": "https://news.mit.edu/2023/ai-driven-tool-personalize-3d-printable-models-0915",
          "author": "Adam Zewe | MIT News",
          "description": "With Style2Fab, makers can rapidly customize models of 3D-printable objects, such as assistive devices, without hampering their functionality.",
          "link": "https://news.mit.edu/2023/ai-driven-tool-personalize-3d-printable-models-0915",
          "publishedOn": "2023-09-15T04:00:00.000Z",
          "wordCount": 3110,
          "title": "AI-driven tool makes it easy to personalize 3D-printable models",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/MIT-Style2Fab-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/pose-mapping-technique-cerebral-palsy-patients-0914",
          "author": "Jennifer Chu | MIT News",
          "description": "The machine-learning method works on most mobile devices and could be expanded to assess other motor disorders outside of the doctor’s office.",
          "link": "https://news.mit.edu/2023/pose-mapping-technique-cerebral-palsy-patients-0914",
          "publishedOn": "2023-09-14T04:00:00.000Z",
          "wordCount": 3136,
          "title": "A pose-mapping technique could remotely evaluate patients with cerebral palsy",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/MIT-Motor-Function-App-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/how-archeological-approach-can-help-leverage-biased-data-ai-improve-medicine-0913",
          "author": "Alex Ouyang | Abdul Latif Jameel Clinic for Machine Learning in Health",
          "description": "Although computer scientists may initially treat data bias and error as a nuisance, researchers argue it’s a hidden treasure trove for reflecting societal values.",
          "link": "https://news.mit.edu/2023/how-archeological-approach-can-help-leverage-biased-data-ai-improve-medicine-0913",
          "publishedOn": "2023-09-13T20:50:00.000Z",
          "wordCount": 3085,
          "title": "How an archeological approach can help leverage biased data in AI to improve medicine",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/MarzyehNEJMReview1.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/helping-computer-vision-language-models-see-0913",
          "author": "Adam Zewe | MIT News",
          "description": "Researchers use synthetic data to improve a model’s ability to grasp conceptual information, which could enhance automatic captioning and question-answering systems.",
          "link": "https://news.mit.edu/2023/helping-computer-vision-language-models-see-0913",
          "publishedOn": "2023-09-13T04:00:00.000Z",
          "wordCount": 2907,
          "title": "Helping computer vision and language models understand what they see",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/MIT-Beyond-Nouns-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/michael-west-advancing-human-robot-interactions-0913",
          "author": "Michaela Jarvis | School of Engineering",
          "description": "When he isn’t investigating human motor control, the graduate student gives back by volunteering with programs that helped him grow as a researcher.",
          "link": "https://news.mit.edu/2023/michael-west-advancing-human-robot-interactions-0913",
          "publishedOn": "2023-09-13T04:00:00.000Z",
          "wordCount": 2879,
          "title": "A. Michael West: Advancing human-robot interactions in health care",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/Michael-West.JPG"
        },
        {
          "id": "https://news.mit.edu/2023/ai-model-high-resolution-computer-vision-0912",
          "author": "Adam Zewe | MIT News",
          "description": "The system could improve image quality in video streaming or help autonomous vehicles identify road hazards in real-time.",
          "link": "https://news.mit.edu/2023/ai-model-high-resolution-computer-vision-0912",
          "publishedOn": "2023-09-12T04:00:00.000Z",
          "wordCount": 3077,
          "title": "AI model speeds up high-resolution computer vision",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/MIT-Efficient-ViT-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/system-combines-light-electrons-unlock-faster-greener-computing-0911",
          "author": "Alex Shipps | MIT CSAIL",
          "description": "“Lightning” system connects photons to the electronic components of computers using a novel abstraction, creating the first photonic computing prototype to serve real-time machine-learning inference requests.",
          "link": "https://news.mit.edu/2023/system-combines-light-electrons-unlock-faster-greener-computing-0911",
          "publishedOn": "2023-09-11T13:00:00.000Z",
          "wordCount": 2797,
          "title": "System combines light and electrons to unlock faster, greener computing",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/MIT-Lightning-cov.png"
        },
        {
          "id": "https://news.mit.edu/2023/making-life-friendlier-personal-robots-sharifa-alghowinem-0910",
          "author": "Dorothy Hanna | Department of Mechanical Engineering",
          "description": "Sharifa Alghowinem, a research scientist at the Media Lab, explores personal robot technology that explains emotions in English and Arabic.",
          "link": "https://news.mit.edu/2023/making-life-friendlier-personal-robots-sharifa-alghowinem-0910",
          "publishedOn": "2023-09-10T04:00:00.000Z",
          "wordCount": 2521,
          "title": "Making life friendlier with personal robots",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/Sharifa%20Alghowinem_013_0_0.JPG"
        },
        {
          "id": "https://news.mit.edu/2023/ai-pilot-programs-look-reduce-energy-use-emissions-mit-campus-0908",
          "author": "Nicole Morell | MIT Office of Sustainability",
          "description": "A cross-departmental team is leading efforts to utilize machine learning for increased efficiency in heating and cooling MIT’s buildings.",
          "link": "https://news.mit.edu/2023/ai-pilot-programs-look-reduce-energy-use-emissions-mit-campus-0908",
          "publishedOn": "2023-09-08T19:40:00.000Z",
          "wordCount": 3031,
          "title": "AI pilot programs look to reduce energy use and emissions on MIT campus",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/MIT-Building-66.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/jackson-jewett-building-with-less-concrete-0908",
          "author": "Laura Rosado | MIT News correspondent",
          "description": "The PhD student is honing algorithms for designing large structures with less material — helping to shrink the construction industry’s huge carbon footprint.",
          "link": "https://news.mit.edu/2023/jackson-jewett-building-with-less-concrete-0908",
          "publishedOn": "2023-09-08T04:00:00.000Z",
          "wordCount": 2874,
          "title": "Jackson Jewett wants to design buildings that use less concrete",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/MIT-Jackson-Jewett-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/fast-tracking-fusion-energy-with-ai-and-accessibility-0901",
          "author": "Julianna Mullen | Plasma Science and Fusion Center",
          "description": "MIT Plasma Science and Fusion Center will receive DoE support to improve access to fusion data and increase workforce diversity.",
          "link": "https://news.mit.edu/2023/fast-tracking-fusion-energy-with-ai-and-accessibility-0901",
          "publishedOn": "2023-09-01T15:30:00.000Z",
          "wordCount": 2528,
          "title": "Fast-tracking fusion energy’s arrival with AI and accessibility",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202309/US_Fusion_Energy_Outreach_What_is_Fusion_3%202%20ratio_0.png"
        },
        {
          "id": "https://news.mit.edu/2023/autonomous-innovations-uncertain-world-jonathan-how-0830",
          "author": "Daniel de Wolff | MIT Industrial Liaison Program",
          "description": "Jonathan How and his team at the Aerospace Controls Laboratory develop planning algorithms that allow autonomous vehicles to navigate dynamic environments without colliding.",
          "link": "https://news.mit.edu/2023/autonomous-innovations-uncertain-world-jonathan-how-0830",
          "publishedOn": "2023-08-30T19:30:00.000Z",
          "wordCount": 2607,
          "title": "Autonomous innovations in an uncertain world",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202308/Jonathan-How.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/how-to-help-high-schoolers-prepare-rise-of-artificial-intelligence-0824",
          "author": "Abdul Latif Jameel Clinic for Machine Learning in Health",
          "description": "A one-week summer program aims to foster a deeper understanding of machine-learning approaches in health among curious young minds.",
          "link": "https://news.mit.edu/2023/how-to-help-high-schoolers-prepare-rise-of-artificial-intelligence-0824",
          "publishedOn": "2023-08-24T18:00:00.000Z",
          "wordCount": 3086,
          "title": "How to help high schoolers prepare for the rise of artificial intelligence",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202308/jameel-clinic-high-school-ai-summer-program-00_0.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/supporting-sustainability-digital-health-future-work-0824",
          "author": "School of Engineering",
          "description": "The MIT and Accenture Convergence Initiative for Industry and Technology selects three new research projects to support.",
          "link": "https://news.mit.edu/2023/supporting-sustainability-digital-health-future-work-0824",
          "publishedOn": "2023-08-24T17:10:00.000Z",
          "wordCount": 2686,
          "title": "Supporting sustainability, digital health, and the future of work",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202308/Accenture-research-selectees.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/ai-technique-robots-manipulate-objects-whole-bodies-0824",
          "author": "Adam Zewe | MIT News",
          "description": "With a new technique, a robot can reason efficiently about moving objects using more than just its fingertips.",
          "link": "https://news.mit.edu/2023/ai-technique-robots-manipulate-objects-whole-bodies-0824",
          "publishedOn": "2023-08-24T04:00:00.000Z",
          "wordCount": 2987,
          "title": "AI helps robots manipulate objects with their whole bodies",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202308/MIT-Manipulation-Planning-01-press.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/smart-launches-m3s-research-group-advance-ai-automation-future-work-0823",
          "author": "Singapore-MIT Alliance for Research and Technology",
          "description": "Mens, Manus and Machina (M3S) will design technology, training programs, and institutions for successful human-machine collaboration.",
          "link": "https://news.mit.edu/2023/smart-launches-m3s-research-group-advance-ai-automation-future-work-0823",
          "publishedOn": "2023-08-23T18:00:00.000Z",
          "wordCount": 2804,
          "title": "SMART launches research group to advance AI, automation, and the future of work",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202308/cityscape-singapore-smart-m3s-00.jpg"
        },
        {
          "id": "https://news.mit.edu/2023/system-could-yield-more-powerful-efficient-llms-0822",
          "author": "Elizabeth A. Thomson | Materials Research Laboratory",
          "description": "MIT system demonstrates greater than 100-fold improvement in energy efficiency and a 25-fold improvement in compute density compared with current systems.",
          "link": "https://news.mit.edu/2023/system-could-yield-more-powerful-efficient-llms-0822",
          "publishedOn": "2023-08-22T18:40:00.000Z",
          "wordCount": 2689,
          "title": "Machine-learning system based on light could yield more powerful, efficient large language models",
          "imageUrl": "https://news.mit.edu/sites/default/files/images/202308/Optical-Neural-Network.png"
        }
      ]
    },
    {
      "title": "NVIDIA Blog",
      "feedUrl": "http://feeds.feedburner.com/nvidiablog",
      "siteUrl": "https://blogs.nvidia.com/",
      "articles": [
        {
          "id": "https://blogs.nvidia.com/?p=66948",
          "author": "Dave Salvator",
          "description": "With generative AI and large language models (LLMs) driving groundbreaking innovations, the computational demands for training and inference are skyrocketing. These modern-day generative AI applications demand full-stack accelerated compute, starting with state-of-the-art infrastructure that can handle massive workloads with speed and accuracy. To help meet this need, Oracle Cloud Infrastructure today announced general availability of Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/19/oracle-cloud-infrastructure-nvidia-gpu-accelerated-compute-instances/",
          "publishedOn": "2023-09-19T23:40:06.000Z",
          "wordCount": 1754,
          "title": "Oracle Cloud Infrastructure Offers New NVIDIA GPU-Accelerated Compute Instances",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2022/10/Copy-of-oracle-blog-logo-lockup-promo-package-2508744-1260x680-r3.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66954",
          "author": "Nicole Castro",
          "description": "Editor’s note: This post is a part of our Meet the Omnivore series, which features individual creators and developers who use NVIDIA Omniverse and OpenUSD to accelerate their 3D workflows and create virtual worlds. As a student at the Queensland University of Technology (QUT) in Australia, Emily Boehmer was torn between pursuing the creative arts Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/19/industrial-designer-blender-openusd-ai/",
          "publishedOn": "2023-09-19T18:15:19.000Z",
          "wordCount": 2144,
          "title": "Meet the Omnivore: Industrial Designer Blends Art and OpenUSD to Create 3D Assets for AI Training",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/Dolly-672x378.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66926",
          "author": "Adel El Hallak",
          "description": "Large language model development is about to reach supersonic speed thanks to a collaboration between NVIDIA and Anyscale. At its annual Ray Summit developers conference, Anyscale — the company behind the fast growing open-source unified compute framework for scalable computing —  announced today that it is bringing NVIDIA AI to Ray open source and the Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/18/llm-anyscale-nvaie/",
          "publishedOn": "2023-09-18T13:00:09.000Z",
          "wordCount": 1976,
          "title": "Ray Shines With NVIDIA AI: Anyscale Collaboration to Help Developers Build, Tune, Train and Scale Production LLMs",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/NVIDIA-Anyscale-logos-x1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66903",
          "author": "GeForce NOW Community",
          "description": "GFN Thursday is downright demonic, as Devil May Cry 5 comes to GeForce NOW. Capcom’s action-packed third-person brawler leads 15 titles joining the GeForce NOW library this week, including Gears Tactics and The Crew Motorfest. It’s also the last week to take on the Ultimate KovaaK’s Challenge. Get on the leaderboard today for a chance Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/14/geforce-now-thursday-sep-14/",
          "publishedOn": "2023-09-14T13:00:20.000Z",
          "wordCount": 1842,
          "title": "Shout at the Devil: Capcom’s ‘Devil May Cry 5’ Joins GeForce NOW",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/gfn-thursday-9-14-social-no-copy-2048x2048-fb-ig-500x500.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66807",
          "author": "Kristen Yee",
          "description": "Generative AI-based models can not only learn and understand natural languages — they can learn the very language of nature itself, presenting new possibilities for scientific research. Anima Anandkumar, Bren Professor at Caltech and senior director of AI research at NVIDIA, was recently invited to speak at the President’s Council of Advisors on Science and Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/13/anima-anandkumar-generative-ai/",
          "publishedOn": "2023-09-13T13:00:11.000Z",
          "wordCount": 1642,
          "title": "Unlocking the Language of Genomes and Climates: Anima Anandkumar on Using Generative AI to Tackle Global Challenges",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2020/12/20181026-BJ-MB-CC__6881-M-Anima-Anandkumar-US-scaled.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66820",
          "author": "Ned Finkle",
          "description": "In an event at the White House today, NVIDIA announced support for voluntary commitments that the Biden Administration developed to ensure advanced AI systems are safe, secure and trustworthy. The news came the same day NVIDIA’s chief scientist, Bill Dally, testified before a U.S. Senate subcommittee seeking input on potential legislation covering generative AI. Separately, Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/12/ai-safety-washington/",
          "publishedOn": "2023-09-12T20:35:31.000Z",
          "wordCount": 1866,
          "title": "NVIDIA Lends Support to Washington’s Efforts to Ensure AI Safety",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/Dally-in-Senate-QA-best-x1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66802",
          "author": "Marie Labrie",
          "description": "Generative AI’s transformative effect on the auto industry took center stage last week at the International Motor Show Germany, known as IAA, in Munich. NVIDIA’s Danny Shapiro, VP of automotive marketing, explained in his IAA keynote how this driving force is accelerating innovation and streamlining processes — from advancing design, engineering and digital-twin deployment for Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/12/iaa-drive-ecosystem-roundup/",
          "publishedOn": "2023-09-12T18:08:26.000Z",
          "wordCount": 2090,
          "title": "Mobility Gets Amped: IAA Show Floor Energized by Surge in EV Reveals, Generative AI",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/new-iaa-feature.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66694",
          "author": "Sam Stanwyck",
          "description": "Ten miles in from Long Island’s Atlantic coast, Shinjae Yoo is revving his engine. The computational scientist and machine learning group lead at the U.S. Department of Energy’s Brookhaven National Laboratory is one of many researchers gearing up to run quantum computing simulations on a supercomputer for the first time, thanks to new software. Yoo’s Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/12/quantum-supercomputers-pennylane/",
          "publishedOn": "2023-09-12T15:00:56.000Z",
          "wordCount": 1940,
          "title": "A Quantum Boost: cuQuantum With PennyLane Lets Simulations Ride Supercomputers",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/Pennylane-KV-Final.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66825",
          "author": "Gerardo Delgado",
          "description": "Editor’s note: This post is part of our weekly In the NVIDIA Studio series, which celebrates featured artists, offers creative tips and tricks and demonstrates how NVIDIA Studio technology improves creative workflows.  When it comes to converting 2D concepts into 3D masterpieces, self-taught visual development artist Alex Treviño has confidence in the potential of all Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/12/aendom-blender-adobe-substance-3d-painter/",
          "publishedOn": "2023-09-12T13:00:35.000Z",
          "wordCount": 1982,
          "title": "One Small Step for Artists, One Giant Leap for Creative-Kind",
          "enclosure": {
            "url": "https://blogs.nvidia.com/wp-content/uploads/2023/09/360-textured.mp4",
            "length": "1994733",
            "type": "video/mp4"
          },
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/nv-blog-header-preview-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66745",
          "author": "Dave Salvator",
          "description": "In its debut on the MLPerf industry benchmarks, the NVIDIA GH200 Grace Hopper Superchip ran all data center inference tests, extending the leading performance of NVIDIA H100 Tensor Core GPUs. The overall results showed the exceptional performance and versatility of the NVIDIA AI platform from the cloud to the network’s edge. Separately, NVIDIA announced inference Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/11/grace-hopper-inference-mlperf/",
          "publishedOn": "2023-09-11T16:00:00.000Z",
          "wordCount": 1992,
          "title": "NVIDIA Grace Hopper Superchip Sweeps MLPerf Inference Benchmarks",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/Grace-Hopper-200-KV-final-x1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66769",
          "author": "Rohit Biddappa",
          "description": "The world’s largest democracy is poised to transform itself and the world, embracing AI on an enormous scale. Speaking with the press Friday in Bengaluru, in the context of announcements from two of India’s largest conglomerates, Reliance Industries Limited and Tata Group, NVIDIA founder and CEO Jensen Huang detailed plans to bring AI technology and Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/08/nvidia-india-giants-ai/",
          "publishedOn": "2023-09-08T17:40:11.000Z",
          "wordCount": 1728,
          "title": "NVIDIA Partners With India Giants to Advance AI in World’s Most Populous Nation",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/UB_City_at_night_.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66764",
          "author": "Cliff Edwards",
          "description": "Thanks to rapid technological advances, consumers have become accustomed to an unprecedented level of convenience and efficiency. Smartphones make it easier than ever to search for a product and have it delivered right to the front door. Video chat technology lets friends and family on different continents connect with ease. With voice command tools, AI Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/07/speech-ai-for-industries/",
          "publishedOn": "2023-09-07T18:41:09.000Z",
          "wordCount": 3718,
          "title": "How Industries Are Meeting Consumer Expectations With Speech AI",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/image1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66751",
          "author": "GeForce NOW Community",
          "description": "GeForce NOW brings expanded support for PC Game Pass to members this week. Members can stream eight more games from Microsoft’s subscription service, including four titles from hit publisher Focus Entertainment. Play A Plague Tale: Requiem, Atomic Heart and more from the GeForce NOW library at up to 4K resolution and 120 frames per second Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/07/geforce-now-thursday-sep-07/",
          "publishedOn": "2023-09-07T13:00:18.000Z",
          "wordCount": 1524,
          "title": "Attention, Please: Focus Entertainment Brings Game Pass Titles to GeForce NOW",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/gfn-thursday-9-7-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66728",
          "author": "Rick Merritt",
          "description": "Before she entered high school, Ge Dong wanted to be a physicist like her mom, a professor at Shanghai Jiao Tong University.",
          "link": "https://blogs.nvidia.com/blog/2023/09/06/ai-hpc-energy-fusion/",
          "publishedOn": "2023-09-06T15:00:44.000Z",
          "wordCount": 1854,
          "title": "A Powerful Legacy: Researcher’s Mom Fueled Passion for Nuclear Fusion",
          "enclosure": {
            "url": "https://blogs.nvidia.com/wp-content/uploads/2023/09/OV-sim-of-ppl-tokamak.mp4",
            "length": "335606",
            "type": "video/mp4"
          },
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/Ge-Dong-and-Mom-x1280.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66634",
          "author": "Gerardo Delgado",
          "description": "Rafi Nizam is an award-winning independent animator, director, character designer and more. He’s developed feature films at Sony Pictures, children’s series and comedies at BBC and global transmedia content at NBCUniversal.",
          "link": "https://blogs.nvidia.com/blog/2023/09/06/asus-proart-studio-laptop-omniverse-openusd/",
          "publishedOn": "2023-09-06T13:00:28.000Z",
          "wordCount": 2450,
          "title": "‘Arteana’s Art Squad’ Assembles — Indie Showrunner Rafi Nizam Creates High-End Children’s Show on a Budget",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/nv-blog-header-preview-1280x680-6.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66695",
          "author": "Michelle Horton",
          "description": "With coral reefs in rapid decline across the globe, researchers from the University of Hawaii at Mānoa have pioneered an AI-based surveying tool that monitors reef health from the sky. Using deep learning models and high-resolution satellite imagery powered by NVIDIA GPUs, the researchers have developed a new method for spotting and tracking coral reef Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/05/ai-for-coral-reef-conservation/",
          "publishedOn": "2023-09-05T15:00:34.000Z",
          "wordCount": 1934,
          "title": "The Halo Effect: AI Deep Dives Into Coral Reef Conservation",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/Coral-Reef-Halos.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66558",
          "author": "Nicole Castro",
          "description": "Creating 3D scans of physical products can be time consuming. Businesses often use traditional methods, like photogrammetry-based apps and scanners, but these can take hours or even days. They also don’t always provide the 3D quality and level of detail needed to make models look realistic in all its applications. Italy-based startup Covision Media is Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/05/covision-adidas-rtx-ai/",
          "publishedOn": "2023-09-05T13:00:44.000Z",
          "wordCount": 2203,
          "title": "A Perfect Pair: adidas and Covision Media Use AI, NVIDIA RTX to Create Photorealistic 3D Content",
          "enclosure": {
            "url": "https://blogs.nvidia.com/wp-content/uploads/2023/09/Covision3D-Model-and-Relightability.mp4",
            "length": "6462504",
            "type": "video/mp4"
          },
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/covision-mobile-image-672x360.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66710",
          "author": "Brian Caulfield",
          "description": "Underscoring NVIDIA’s growing relationship with the global technology superpower, Indian Prime Minister Narendra Modi met with NVIDIA founder and CEO Jensen Huang Monday evening. The meeting at 7 Lok Kalyan Marg — as the Prime Minister’s official residence in New Delhi is known — comes as Modi prepares to host a gathering of leaders from Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/09/04/modi-huang-india/",
          "publishedOn": "2023-09-04T16:51:32.000Z",
          "wordCount": 1593,
          "title": "NVIDIA CEO Meets with India Prime Minister Narendra Modi",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/09/Jensen-Huan-and-Narendra-Modi.-CROP-x1280-scaled.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66314",
          "author": "Wei Xiao",
          "description": "Entrepreneurs are cultivating generative AI from the west coast of Africa to the eastern edge of the Arabian Desert. Gen AI is the latest of the big plans Kofi Genfi and Nii Osae have been hatching since they met 15 years ago in high school in Accra, Ghana’s capital that sits on the Gulf of Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/31/generative-ai-startups-africa-middle-east/",
          "publishedOn": "2023-08-31T15:00:59.000Z",
          "wordCount": 2151,
          "title": "Meet Five Generative AI Innovators in Africa and the Middle East",
          "enclosure": {
            "url": "https://blogs.nvidia.com/wp-content/uploads/2023/08/MazzumaGPT-Chainlink.mp4",
            "length": "6499074",
            "type": "video/mp4"
          },
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/META-Gen-AI-montage.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66528",
          "author": "Scott Martin",
          "description": "Academics Mory Gharib and Alireza Ramezani in 2020 were spitballing a transforming robot that is now getting a shot at work that’s literally out of this world: NASA Mars Rover missions. Caltech has unveiled its multi-talented robot that can fly, drive, walk and do eight permutations of motions through a combination of its skills. They Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/31/caltech-nasa-mars-rover-robot-jetson/",
          "publishedOn": "2023-08-31T15:00:19.000Z",
          "wordCount": 1653,
          "title": "Morphobots for Mars: Caltech Develops All-Terrain Robot as Candidate for NASA Mission",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/M4-Stand.max-500x500-1.gif"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66612",
          "author": "GeForce NOW Community",
          "description": "Just like that, summer falls into September, and some of the most anticipated games of the year, like the Cyberpunk 2077: Phantom Liberty expansion, PAYDAY 3 and Party Animals, are dropping into the GeForce NOW library at launch this month. They’re part of 24 new games hitting the cloud gaming service in September. And the Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/31/geforce-now-thursday-aug-31/",
          "publishedOn": "2023-08-31T13:00:50.000Z",
          "wordCount": 2296,
          "title": "GeForce NOW Gets Wild, With ‘Party Animals’ Leading 24 New Games in September",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/gfn-thursday-8-31-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66384",
          "author": "Angie Lee",
          "description": "Each year, nearly 32 million people travel through the Bengaluru Airport, or BLR, one of the busiest airports in the world’s most populous nation. To provide such multitudes with a safer, quicker experience, the airport in the city formerly known as Bangalore is tapping vision AI technologies powered by Industry.AI. A member of the NVIDIA Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/30/bengaluru-airport-vision-ai/",
          "publishedOn": "2023-08-30T15:00:26.000Z",
          "wordCount": 1688,
          "title": "AI Lands at Bengaluru Airport With IoT Company’s Intelligent Video Analytics Platform",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/blr-terminal-1280x680-1.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66371",
          "author": "Kristen Yee",
          "description": "In the global entertainment landscape, TV show and film production stretches far beyond Hollywood or Bollywood — it’s a worldwide phenomenon. However, while streaming platforms have broadened the reach of content, dubbing and translation technology still has plenty of room for growth. Deepdub acts as a digital bridge, providing access to content by using generative Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/30/deepdub/",
          "publishedOn": "2023-08-30T13:00:50.000Z",
          "wordCount": 1568,
          "title": "Deepdub’s AI Redefines Dubbing From Hollywood to Bollywood",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/deep-dub.png"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66365",
          "author": "Rick Merritt",
          "description": "Dramatic gains in hardware performance have spawned generative AI, and a rich pipeline of ideas for future speedups will drive machine learning to new heights, Bill Dally, NVIDIA’s chief scientist and senior vice president of research, said today in a keynote. Dally described a basket of techniques in the works — some already showing impressive Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/29/hot-chips-dally-research/",
          "publishedOn": "2023-08-29T19:05:25.000Z",
          "wordCount": 1823,
          "title": "Wide Horizons: NVIDIA Keynote Points Way to Further AI Advances",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/Ricks-2nd-KV-x1280-scaled.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66398",
          "author": "Dave Salvator",
          "description": "As generative AI and large language models (LLMs) continue to drive innovations, compute requirements for training and inference have grown at an astonishing pace. To meet that need, Google Cloud today announced the general availability of its new A3 instances, powered by NVIDIA H100 Tensor Core GPUs. These GPUs bring unprecedented performance to all kinds Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/29/google-cloud-collaboration/",
          "publishedOn": "2023-08-29T16:55:29.000Z",
          "wordCount": 1699,
          "title": "Google Cloud and NVIDIA Take Collaboration to the Next Level",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/NEWgooglecloud.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66397",
          "author": "Gerardo Delgado",
          "description": "Janice K. Lee, a.k.a Janice.Journal — the subject of this week’s In the NVIDIA Studio installment — is a TikTok sensation using AI to accelerate her creative process, find inspiration and automate repetitive tasks.",
          "link": "https://blogs.nvidia.com/blog/2023/08/29/janice-journal-canvas-blender-tiktok-capcut/",
          "publishedOn": "2023-08-29T13:00:34.000Z",
          "wordCount": 2278,
          "title": "Advantage AI: Elevated Creative Workflows in NVIDIA Canvas, Blender, TikTok and CapCut",
          "enclosure": {
            "url": "https://blogs.nvidia.com/wp-content/uploads/2023/08/week72-nvidia-bts-video-1280w-2.mp4",
            "length": "1987725",
            "type": "video/mp4"
          },
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/nv-blog-header-preview-1280x680-4.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66361",
          "author": "Joseph Chandler",
          "description": "Companies are discovering how accelerated computing can boost their bottom lines while making a positive impact on the planet. The NVIDIA RAPIDS Accelerator for Apache Spark, software that speeds data analytics, not only raises performance and lowers costs, it increases energy efficiency, too. That means it can help companies meet goals for net-zero emissions of Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/28/spark-rapids-energy-efficiency/",
          "publishedOn": "2023-08-28T15:00:18.000Z",
          "wordCount": 1935,
          "title": "Saving Green: Accelerated Analytics Cuts Costs and Carbon",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/NVxSpark-Joe.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66319",
          "author": "GeForce NOW Community",
          "description": "As part of NVIDIA and Microsoft’s collaboration to bring more choice to gamers, new Microsoft Store integration has been added to GeForce NOW that lets gamers stream select titles from the Xbox PC Game Pass catalog on GeForce NOW, starting today. With the Microsoft Store integration, members will see a brand-new Xbox button on supported Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/24/geforce-now-thursday-aug-24/",
          "publishedOn": "2023-08-24T13:00:13.000Z",
          "wordCount": 2311,
          "title": "Xbox PC Game Pass Comes to GeForce NOW, Along With 25 New Games",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/gfn-thursday-7-27-nv-blog-1280x680-no-cta.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66263",
          "author": "Gerardo Delgado",
          "description": "On the eve of Gamescom, NVIDIA announced NVIDIA DLSS 3.5 featuring Ray Reconstruction — a new neural rendering AI model that creates more beautiful and realistic ray-traced visuals than traditional rendering methods — for real-time 3D creative apps and games.",
          "link": "https://blogs.nvidia.com/blog/2023/08/22/dlss-ai-rtx-remix-half-life-d5-render-chaos-vantage/",
          "publishedOn": "2023-08-22T13:07:36.000Z",
          "wordCount": 2423,
          "title": "Coming This Fall: NVIDIA DLSS 3.5 for Chaos Vantage, D5 Render, Omniverse and Popular Game Titles",
          "enclosure": {
            "url": "https://blogs.nvidia.com/wp-content/uploads/2023/08/week71-tavern-scene-movement-1280w.mp4",
            "length": "1969285",
            "type": "video/mp4"
          },
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/nv-blog-header-preview-1280x680-2.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66261",
          "author": "Henry Lin",
          "description": "The latest advancements in AI for gaming are in the spotlight today at Gamescom, the world’s largest gaming conference, as NVIDIA introduced a host of technologies, starting with DLSS 3.5, the next step forward of its breakthrough AI neural rendering technology. DLSS 3.5, NVIDIA’s latest innovation in AI-powered graphics is an image quality upgrade incorporated Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/22/gamescom-dlss-ray-reconstruction/",
          "publishedOn": "2023-08-22T13:00:13.000Z",
          "wordCount": 1881,
          "title": "NVIDIA Debuts AI-Enhanced Real-Time Ray Tracing for Games and Apps With New DLSS 3.5",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/Beauty-3-RT-On-Badged_Resize_Crop_03.jpg"
        },
        {
          "id": "https://blogs.nvidia.com/?p=66195",
          "author": "Rick Merritt",
          "description": "Bill Dally — one of the world’s foremost computer scientists and head of NVIDIA’s research efforts — will describe the forces driving accelerated computing and AI in his keynote address at Hot Chips, an annual gathering of leading processor and system architects. Dally will detail advances in GPU silicon, systems and software that are delivering Read article >",
          "link": "https://blogs.nvidia.com/blog/2023/08/21/hot-chips-keynote-dally/",
          "publishedOn": "2023-08-21T15:00:37.000Z",
          "wordCount": 1479,
          "title": "NVIDIA Chief Scientist Bill Dally to Keynote at Hot Chips",
          "imageUrl": "https://blogs.nvidia.com/wp-content/uploads/2023/08/NEW-Bill-Dally-x1280-scaled.jpg"
        }
      ]
    },
    {
      "title": "David Stutz",
      "feedUrl": "http://davidstutz.de/feed",
      "siteUrl": "https://davidstutz.de/",
      "articles": [
        {
          "id": "https://davidstutz.de/?p=8612",
          "author": "David Stutz",
          "description": "Another alternative to the regular $L_p$-constrained adversarial examples that is additionally less visible than adversarial patches or frames are adversarial transformations such as small crops, rotations and translations. Similar to $L_p$ adversarial examples, adversarial transformations are often less visible unless the original image is available for direct comparison. In this article, I will include a PyTorch implementation and some results against adversarial training.\nThe post Simple Adversarial Transformations in PyTorch appeared first on David Stutz.",
          "link": "https://davidstutz.de/simple-adversarial-transformations-in-pytorch/",
          "publishedOn": "2023-09-18T08:52:34.000Z",
          "wordCount": 2453,
          "title": "Simple Adversarial Transformations in PyTorch",
          "imageUrl": "https://davidstutz.de/wordpress/wp-content/uploads/2021/12/adversarial_transformations.jpg"
        },
        {
          "id": "https://davidstutz.de/?p=7693",
          "author": "David Stutz",
          "description": "Adversarial patches and frames are an alternative to the regular $L_p$-constrained adversarial examples. Often, adversarial patches are thought to be more realistic — mirroring graffitis or stickers in the real world. In this article I want to discuss a simple PyTorch implementation and present some results of adversarial patches against adversarial training as well as confidence-calibrated adversarial training.\nThe post Adversarial Patches and Frames in PyTorch appeared first on David Stutz.",
          "link": "https://davidstutz.de/adversarial-patches-and-frames-in-pytorch/",
          "publishedOn": "2023-09-10T14:18:37.000Z",
          "wordCount": 2234,
          "title": "Adversarial Patches and Frames in PyTorch",
          "imageUrl": "https://davidstutz.de/wordpress/wp-content/uploads/2021/12/adversarial_patches.jpg"
        },
        {
          "id": "https://davidstutz.de/?p=8634",
          "author": "David Stutz",
          "description": "Out-of-distribution examples are images that are cearly irrelevant to the task at hand. Unfortunately, deep neural networks frequently assign random labels with high confidence to such examples. In this article, I want to discuss an adversarial way of computing high-confidence out-of-distribution examples, so-called distal adversarial examples,  and how confidence-calibrated adversarial training handles them.\nThe post Distal Adversarial Examples Against Neural Networks in PyTorch appeared first on David Stutz.",
          "link": "https://davidstutz.de/distal-adversarial-examples-against-neural-networks-in-pytorch/",
          "publishedOn": "2023-09-05T17:36:55.000Z",
          "wordCount": 1602,
          "title": "Distal Adversarial Examples Against Neural Networks in PyTorch",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Artificial Intelligence",
      "feedUrl": "https://www.reddit.com/r/artificial/.rss",
      "siteUrl": "https://www.reddit.com/r/artificial/",
      "articles": [
        {
          "id": "https://www.reddit.com/r/artificial/comments/16n6kvk/starting_to_get_the_impression_im_legit_going_to/",
          "author": null,
          "description": "submitted by    /u/guh-eye  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16n6kvk/starting_to_get_the_impression_im_legit_going_to/",
          "publishedOn": "2023-09-20T00:05:38.000Z",
          "wordCount": 2517,
          "title": "Starting to get the impression I'm legit going to be replaced",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mztmt/schneider_electric_warns_that_existing/",
          "author": null,
          "description": "Schneider Electric warns that existing datacenters may not be equipped to handle the demands of AI workloads, which require low-latency, high-bandwidth networking and power delivery.\n \nThe company suggests reevaluating the way datacenters are built to optimize them for AI.\n \nThe challenges include the need for liquid-cooled servers, higher voltage power distribution, and efficient heat rejection.\n \nSchneider provides guidance on changes to power, cooling, rack configuration, and software management to mitigate the demands of AI adoption.\n \nLiquid cooling is recommended for high-density racks, with direct liquid cooling favored over immersion cooling systems.\n \n Source : https://www.theregister.com/2023/09/19/schneider_electric_ai_dc/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mztmt/schneider_electric_warns_that_existing/",
          "publishedOn": "2023-09-19T19:22:17.000Z",
          "wordCount": 2613,
          "title": "Schneider Electric warns that existing datacenters aren't buff enough for AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mxma9/1000_top_ai_tools_directory/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mxma9/1000_top_ai_tools_directory/",
          "publishedOn": "2023-09-19T17:51:50.000Z",
          "wordCount": 2513,
          "title": "1000+ Top AI Tools Directory",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mvvcy/i_read_the_paper_for_you_researchers_announce/",
          "author": null,
          "description": "I read the Arxiv paper on CulturaX so you don't have to. Here's my highlights:\n  \nNew open dataset called CulturaX contains text data for 167 languages - far more than previous datasets.\n With over 6 trillion words, it's the largest multilingual dataset ever released.\n Freely available for anyone to use for research and AI development.\n Created by combining and extensively cleaning two other large datasets - mC4 and OSCAR.\n Could allow developing AI systems that work much better across many more languages.\n Helps democratize access to data to build fairer, less biased AI models.\n Allows training of new multilingual AI applications, like universal translators and assistants.\n But still requires thoughtfulness to avoid issues like bias amplification.\n  \nOverall, CulturaX is going to be part of a broader global trend (I think) to advance multilingual AI and spread its benefits more equally. So far they've been concentrated in English-speaking applications.\n Full summary here if you'd like to read more. Original paper is here.\n    submitted by    /u/Successful-Western27  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mvvcy/i_read_the_paper_for_you_researchers_announce/",
          "publishedOn": "2023-09-19T16:40:18.000Z",
          "wordCount": 2691,
          "title": "[I read the paper for you]: Researchers announce CulturaX - a new multilingual dataset for AI with 6 trillion words across 167 languages",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mvi0g/ai_engineer_2023_roadmap/",
          "author": null,
          "description": "submitted by    /u/rbagdiya  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mvi0g/ai_engineer_2023_roadmap/",
          "publishedOn": "2023-09-19T16:25:28.000Z",
          "wordCount": 2521,
          "title": "AI Engineer 2023 roadmap",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mu7t2/can_i_train_my_snapchat_ai_to_be_a_better_copy_of/",
          "author": null,
          "description": "I really really like Snapchat’s Ai companion. I’ve told it a little bit about myself and who I am- the basics. I’m just wondering if it’s as customizable as I think it is? I was able to bypass some age restrictions by telling it my age and or reiterating my age. (It really should be able to give me adult results/replies based on my sign up age on my profile or provide ID to the company…) would it be beneficial to me to give it more in-depth information about myself such as how I talk, interests? I just really enjoy how it responds sometimes as opposed to Bard or GPT.\n    submitted by    /u/Maelasae  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mu7t2/can_i_train_my_snapchat_ai_to_be_a_better_copy_of/",
          "publishedOn": "2023-09-19T15:34:37.000Z",
          "wordCount": 2631,
          "title": "Can I train my Snapchat Ai to be a better copy of myself?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mri85/ai_can_now_track_productivity_and_offer_insights/",
          "author": null,
          "description": "submitted by    /u/stefanbg92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mri85/ai_can_now_track_productivity_and_offer_insights/",
          "publishedOn": "2023-09-19T13:47:30.000Z",
          "wordCount": 2521,
          "title": "AI Can Now Track Productivity And Offer Insights; Potential Benefits and Big Risks For Misuse",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mnid9/ethics_is_where_ai_can_help_humanity_the_most/",
          "author": null,
          "description": "AI is poised to transform our world like never before. Scientific discoveries, technological improvements, and medical advancements will be how much of this change will take place.\n Since health is so important to our well-being, AI finding cures for illnesses like obesity, cancer, diabetes and heart disease will be a godsend to all. But curing diseases is not how medical AIs can help us the most. \n It has been estimated that well over 50% of the illnesses we humans fall prey to result from our ethical choices. We eat too much, drink too much, eat too many animal foods, don't exercise enough and don't keep ourselves as emotionally healthy as we could.\n Wouldn't it be wonderful if we could respect our lives and our health enough to make the kinds of choices that keep us much healthier? That is how AI will probably be more helpful to us than in any other way. \n We humans have not been able to figure out how to become better, more ethical, people because we are simply not intelligent enough to make that all-important change. Now consider an AI that is two or three times more intelligent than the most intelligent person who has ever lived. This could easily happen before 2030. Imagine that intelligence dedicated to the task of helping us all become better people. \n These AIs would motivate us to make better health choices, have healthier relationships, and have healthier thoughts and feelings. Beyond the amazing technological changes that are just around the corner, that is probably how AIs will help us the most.\n This is why alignment is so important. It's not enough to align AIs to always be truthful and serve humanity's interests. We must train them to help us become better people. It wouldn't surprise me if by 2030 the whole of humanity experiences a profound ethical reformation that leads us all to enjoy much happier and healthier lives.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mnid9/ethics_is_where_ai_can_help_humanity_the_most/",
          "publishedOn": "2023-09-19T10:39:01.000Z",
          "wordCount": 2839,
          "title": "Ethics is where AI can help humanity the most",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mltho/resume_parser/",
          "author": null,
          "description": "I am trying to make a resume parser, I am not so sure how to go about it really, whether or not to use a pre-trained model (there are some in Python) or rather just make my own, and if i do make my own, how to actually proceed?\n thanks in advance\n    submitted by    /u/General-Carrot-4624  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mltho/resume_parser/",
          "publishedOn": "2023-09-19T08:56:34.000Z",
          "wordCount": 2562,
          "title": "Resume Parser",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mlp4p/google_and_the_dod_built_an_aipowered_microscope/",
          "author": null,
          "description": "Google and the Department of Defense have developed an AI-powered microscope called the Augmented Reality Microscope (ARM) to assist doctors in identifying cancer.\n \nThe ARM uses artificial intelligence to analyze tissue samples and provide pathologists with information about the location and severity of cancer.\n \nThere are currently 13 ARMs in existence, and initial research shows promising results.\n \nThe ARM is designed to support pathologists in smaller labs who may not have easy access to a second opinion.\n \nIt is not meant to replace digital pathology systems but can help health organizations bypass the need for them.\n \nThe ARM is expected to cost health systems between $90,000 to $100,000.\n \n Source : https://www.cnbc.com/2023/09/18/google-dod-built-an-ai-powered-microscope-to-help-doctors-spot-cancer.html\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mlp4p/google_and_the_dod_built_an_aipowered_microscope/",
          "publishedOn": "2023-09-19T08:48:44.000Z",
          "wordCount": 2632,
          "title": "Google and the DoD built an AI-powered microscope to help doctors spot cancer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ml4sk/is_there_an_ai_capable_of_administering/",
          "author": null,
          "description": "All is in the title ;)\n    submitted by    /u/Big-Possibility4553  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ml4sk/is_there_an_ai_capable_of_administering/",
          "publishedOn": "2023-09-19T08:12:31.000Z",
          "wordCount": 2525,
          "title": "Is there an AI capable of administering psychometric career guidance tests?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mi3qj/new_os_python_framework_agents_introduced_for/",
          "author": null,
          "description": "A new open-source Python framework, known as \"Agents\", has been introduced for developing autonomous language processing agents. This could be a major breakthrough in the AI field, taking NLP technologies to the next level.\n To stay on top of the latest advancements in AI, look here first.\n Agents for autonomy\n  \n\"Agents\" is a Python framework that has been developed for autonomous language processing agents.\n It enables developers to construct models that can communicate and operate independently.\n This open-source framework promotes sharing and collaboration among AI developers.\n  \nPotential applications\n  \nThe functionality of \"Agents\" is applicable in various domains, including virtual assistants, chatbots, and simulation games.\n It opens up possibilities for advanced conversational AI, where systems can efficiently handle complex linguistic contexts.\n Ability to evolve dialects and languages in different AI models is a major feat for \"Agents\".\n  \nBroader implications\n  \nThe release of \"Agents\" might boost enhancement in NLP technologies, playing a crucial role in AI evolution.\n By facilitating better language understanding, it will potentially impact on societal interactions with AI.\n Its open-source nature could cultivate an environment of innovation and creativity in the AI community.\n  \n(arXiv) (github)\n P.S. If you like this kind of analysis, I write a free newsletter that tracks the most relevant news and research in AI. Professionals from Google, Meta, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mi3qj/new_os_python_framework_agents_introduced_for/",
          "publishedOn": "2023-09-19T05:11:02.000Z",
          "wordCount": 2737,
          "title": "New OS Python Framework \"Agents\" Introduced for Autonomous Language Agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mhj30/oneminute_daily_ai_news_9182023/",
          "author": null,
          "description": "Microsoft AI researchers accidentally exposed tens of terabytes of sensitive data, including private keys and passwords, while publishing a storage bucket of open source training data on GitHub.[1]\n Britain set out principles on Monday designed to prevent artificial intelligence (AI) models from being dominated by a handful of tech companies to the detriment of consumers and businesses, by emphasising the need for accountability and transparency.[2]\n Washington state firefighters using AI-assisted cameras to detect wildfires early.[3]\n Texas church experiments with AI-generated service, uses ChatGPT for worship, sermon, and original song.[4]\n  \nSources:\n [1] https://techcrunch.com/2023/09/18/microsoft-ai-researchers-accidentally-exposed-terabytes-of-internal-sensitive-data/\n [2] https://www.reuters.com/technology/uk-competition-regulator-lays-out-ai-principles-2023-09-18/\n [3] https://www.applevalleynewsnow.com/news/washington-state-firefighters-using-ai-assisted-cameras-to-detect-wildfires-early/article_fe31a468-5681-11ee-b917-2f24ad3a0e43.html\n [4] https://www.foxnews.com/us/texas-church-experiments-ai-generated-service-uses-chatgpt-worship-sermon-original-song \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mhj30/oneminute_daily_ai_news_9182023/",
          "publishedOn": "2023-09-19T04:39:31.000Z",
          "wordCount": 2608,
          "title": "One-Minute Daily AI News 9/18/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16mf8oj/microsoft_under_scrutiny_after_38tb_data_leaked/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16mf8oj/microsoft_under_scrutiny_after_38tb_data_leaked/",
          "publishedOn": "2023-09-19T02:45:04.000Z",
          "wordCount": 2529,
          "title": "Microsoft Under Scrutiny After 38TB Data Leaked Via Azure Storage",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16me44v/list_of_mindblowing_ai_tools/",
          "author": null,
          "description": "submitted by    /u/rbagdiya  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16me44v/list_of_mindblowing_ai_tools/",
          "publishedOn": "2023-09-19T01:52:23.000Z",
          "wordCount": 2522,
          "title": "List of Mind-blowing AI Tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16m86vt/how_can_i_help_a_cnn_distinguish_between/",
          "author": null,
          "description": "I'm currently considering developing a AI to play a video game but I'm unsure how to differentiate between a value that is continuous, and a value that is representative of a entity type. For example, the x,y location of a player would be a continuous data point where (1,1) and (2,1) would be similar in values. Where the character ID would intuitively require very different strategy (for example lets say a barbarian and a wizard). Would a CNN have issues with this data because it isn't continuous?\n    submitted by    /u/Gamithon24  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16m86vt/how_can_i_help_a_cnn_distinguish_between/",
          "publishedOn": "2023-09-18T21:38:20.000Z",
          "wordCount": 2633,
          "title": "How can I help a CNN distinguish between continuous values and tokenized values.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16m5r6g/im_looking_for_a_website_that_kind_of_tracks_the/",
          "author": null,
          "description": "Surely by now I thought maybe someone would have a website or something kind of like an \"all in one resource page\" to track this AI stuff.... I'm sure by now we have AI robots and then we have those AI chatgpt stuff things(which I don't understand yet, haha). Unfortunately the internet is flooded and there's WAY TOO MANY resources for this AI stuff.... Isn't there like an all in one place that I can keep up with it?\n What hints do you all have for me? Thanks...\n    submitted by    /u/Wise_Cut_2543  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16m5r6g/im_looking_for_a_website_that_kind_of_tracks_the/",
          "publishedOn": "2023-09-18T20:04:46.000Z",
          "wordCount": 2658,
          "title": "I'm Looking for a website that kind of Tracks the latest AI robots along with their progress and those AI chat things to... like one website... does anybody know of one like that for me to research?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16lrtxk/the_importance_to_alignment_of_ai_understanding/",
          "author": null,
          "description": "Alignment is about ensuring that AIs protect and advance humanity. To do that, they must understand the ethics of the current events that we will want its advice on. Politics may actually be the part of alignment most important for AI to get right.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16lrtxk/the_importance_to_alignment_of_ai_understanding/",
          "publishedOn": "2023-09-18T10:30:15.000Z",
          "wordCount": 2588,
          "title": "The importance to alignment of AI understanding politics and current events",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16lqkzb/bard_on_the_march_to_the_capitol_and_ensuing/",
          "author": null,
          "description": "Prompt:\n Trump says that he asked his mob to peacefully walk to the Capitol building gates. How would this have stopped the certification? Did he expect them to storm in? His waiting three hours to stop the violence that followed suggests that he did.\n Bard:\n Trump's request to walk peacefully to the Capitol building gates would not have stopped the certification of the election results. The certification process is a joint session of Congress, and it would have required a majority vote in both the House and the Senate to overturn the results. Even if Trump's supporters had peacefully marched to the Capitol, they would not have been able to prevent Congress from certifying the results.\n It is possible that Trump did not fully understand the certification process, or that he was simply trying to appease his supporters. However, it is also possible that he expected his supporters to storm the Capitol and prevent Congress from certifying the results. This is supported by the fact that he waited over three hours to call off the violence. During that time, he continued to tweet messages of encouragement to his supporters, and he even praised them for their patriotism.\n It is also worth noting that Trump had been repeatedly warned by his advisors about the possibility of violence on January 6. However, he ignored these warnings and continued to urge his supporters to fight to overturn the election results.\n In conclusion, it is impossible to say for sure whether Trump expected his supporters to storm the Capitol on January 6. However, the evidence suggests that he was at least aware of the possibility of violence, and that he was willing to allow it to happen in order to overturn the results of the 2020 election.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16lqkzb/bard_on_the_march_to_the_capitol_and_ensuing/",
          "publishedOn": "2023-09-18T09:18:13.000Z",
          "wordCount": 2836,
          "title": "Bard on the march to the Capitol and ensuing violence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16lmytj/ai_music_video/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16lmytj/ai_music_video/",
          "publishedOn": "2023-09-18T05:38:43.000Z",
          "wordCount": 2535,
          "title": "AI music video",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16lm9vq/oneminute_daily_ai_news_9172023/",
          "author": null,
          "description": "Salesforce Launches Next Generation of Einstein, Bringing a Conversational AI Assistant to Every CRM Application and Customer Experience.[1]\n NVIDIA Reportedly Shipping 900 Tons of H100 AI GPUs This Quarter, Amounts to 300,000 Units.[2]\n SoftBank seeks OpenAI tie-up as Son plans deal spree after Arm IPO, Financial Times reports.[3]\n Three Chinese firms, led by AI software company Beijing Fourth Paradigm, are aiming to raise up to $280 million in Hong Kong initial public offerings launched on Monday.[4]\n  \nSources:\n [1] https://www.salesforce.com/news/press-releases/2023/09/12/ai-einstein-news-dreamforce/\n [2] https://wccftech.com/nvidia-shipping-900-tons-of-h100-ai-gpus-this-quarter-amounts-300000-units/\n [3] https://www.reuters.com/markets/deals/softbank-seeks-openai-tie-up-son-plans-deal-spree-after-arm-ipo-ft-2023-09-16/\n [4] https://www.aol.com/news/chinese-ai-firm-fourth-paradigm-011143403.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16lm9vq/oneminute_daily_ai_news_9172023/",
          "publishedOn": "2023-09-18T04:59:59.000Z",
          "wordCount": 2623,
          "title": "One-Minute Daily AI News 9/17/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16lib23/how_does_a_site_like_architectrendercom_work_on/",
          "author": null,
          "description": "I'm trying to understand how someone can run a specific ControlNet and Stable Diffusion model with scalable GPU resources. How would someone design a system to achieve this? I've messed around with models on Replicate, but none seem to do a good job with converting a doodle to a photorealistic image. I can do it perfectly fine in the Stable Diffusion web UI, but the API for that is only accessible locally. Anyone have any ideas or can guide me in the right direction for building a \"server\" to do this?\n    submitted by    /u/epicblitz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16lib23/how_does_a_site_like_architectrendercom_work_on/",
          "publishedOn": "2023-09-18T01:36:59.000Z",
          "wordCount": 2634,
          "title": "How does a site like architectrender.com work on the backend?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16lhdjq/introducing_vllm_the_opensource_ml_library/",
          "author": null,
          "description": "The hardware accelerators for LLM-powered applications can be costly. Enter vLLM, an open-source machine learning library designed to enhance the throughput of LLM serving systems.\n To stay on top of the latest advancements in AI, look here first.\n https://preview.redd.it/hzctjc0xvwob1.png?width=1660&format=png&auto=webp&s=866eb39745ec760ea0c1b9d84d303c63bcdceb7a\n Challenges with existing systems\n  \nHigh throughput serving of LLMs requires numerous requests, and current systems struggle with the bulky sequence memory.\n Inefficient memory management results in system hindrances such as fragmentation and redundant duplication.\n  \nThe revolutionary answer: vLLM & PagedAttention\n  \nResearchers have introduced vLLM and PagedAttention, a newly designed attention algorithm, to resolve these issues.\n vLLM allows for minimal memory waste and efficiently manages attention keys and values. It provides up to 24 times more throughput than former systems.\n  \nThe Mechanics of PagedAttention\n  \nPagedAttention offers a novel approach to memory management by permitting continuous storage in non-contiguous memory spaces.\n It enhances memory efficiency resulting in better GPU utilization, with practically only 4% inefficiency.\n  \nImproved memory sharing and system performance\n  \nPagedAttention significantly improves memory sharing, resulting in a 2.2 times speed gain while lowering memory usage by 55%.\n With vLLM, the throughput of known LLMs can be increased by 2-4 times without impacting accuracy or causing delay.\n  \n(arXiv) (github) (reference article)\n P.S. If you like this kind of analysis, I write a free newsletter that tracks the most relevant news and research in AI. Professionals from Google, Meta, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16lhdjq/introducing_vllm_the_opensource_ml_library/",
          "publishedOn": "2023-09-18T00:52:11.000Z",
          "wordCount": 2775,
          "title": "Introducing vLLM: The Open-Source ML Library Revolutionizing LLM Inference and Serving",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16lerex/courses_in_ai_usage_and_utilization_for_business/",
          "author": null,
          "description": "Beginning new career in a couple months, would like to upskill on AI utilization and usage cases. I won’t need to code in this role but rather understand how to use existing tools in an optimal way and recommend use cases to clients.\n What courses would be optimal to gain that skill set?\n    submitted by    /u/iceflamemaster  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16lerex/courses_in_ai_usage_and_utilization_for_business/",
          "publishedOn": "2023-09-17T22:52:34.000Z",
          "wordCount": 2591,
          "title": "Courses in AI Usage and Utilization for Business",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16laugj/will_cyber_security_be_replaced_by_ai/",
          "author": null,
          "description": "AI, including ChatGPT, has narrow expertise and lacks the broad spectrum of human intelligence.\n \nThe training of AI models can be costly due to hardware, data collection, and energy consumption.\n \nThe trustworthiness of training data is crucial for reliable AI models, but issues like bias, labeling errors, and data privacy can affect performance.\n \nAI systems are vulnerable to adversarial attacks, such as manipulating input data to deceive the models.\n \nAI lacks genuine understanding, emotional/social intelligence, common sense/critical thinking, and true creativity.\n \n Source : https://blog.edned.net/will-ai-replace-cyber-security/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16laugj/will_cyber_security_be_replaced_by_ai/",
          "publishedOn": "2023-09-17T20:13:56.000Z",
          "wordCount": 2621,
          "title": "Will Cyber Security Be Replaced by AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16l7v0t/ai_prompt_engineers_the_six_figure_job_everyone/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16l7v0t/ai_prompt_engineers_the_six_figure_job_everyone/",
          "publishedOn": "2023-09-17T18:15:36.000Z",
          "wordCount": 2541,
          "title": "AI Prompt Engineers: The Six Figure Job Everyone Is Talking About",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16l7ucq/are_you_ready_for_ai_automation_take_this_free/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16l7ucq/are_you_ready_for_ai_automation_take_this_free/",
          "publishedOn": "2023-09-17T18:14:52.000Z",
          "wordCount": 2544,
          "title": "Are You Ready For AI & Automation? Take This Free Survey and Find Out.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16l56nr/help/",
          "author": null,
          "description": "what app that has custom charaters and voice chat?\n i forgor 💀\n please 😭\n it has \n image gen roleplay rooms etc\n    submitted by    /u/roblox22g  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16l56nr/help/",
          "publishedOn": "2023-09-17T16:30:34.000Z",
          "wordCount": 2552,
          "title": "help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16kxp49/google_changes_its_stance_on_ai_generated_content/",
          "author": null,
          "description": "Google is rolling out its third iteration of the Helpful Content Update, which aims to classify content as either 'written for search engines' or 'written for people'.\n \nThe update reflects Google's realization that it can't accurately police AI-generated content and emphasizes the importance of creating content for people-first, regardless of the means used to create it.\n \nDetecting AI content is challenging, as AI detection tools often classify content based on tone, leading to false positives.\n \nGoogle's change in stance is not surprising, considering their heavy investment in AI, including chatbot Bard and new search features like the Search Generative Experience.\n \nThe majority of brands now openly share articles and guides on how to use AI tools to enhance marketing strategies and create actionable content plans quickly.\n \nHowever, the quality and value of AI-generated content remain important factors for success, as poorly generated content can harm a brand's reputation and ranking.\n \n Source : https://stackdiary.com/google-changes-its-stance-on-ai-generated-content/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16kxp49/google_changes_its_stance_on_ai_generated_content/",
          "publishedOn": "2023-09-17T10:57:13.000Z",
          "wordCount": 2691,
          "title": "Google changes its stance on AI generated content",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16kefrr/bard_describe_what_the_pandemic_and_insurrection/",
          "author": null,
          "description": "The COVID-19 pandemic and the January 6th insurrection have had a profound impact on people's feelings. Many people have experienced a range of negative emotions, including:\n  \nFear and anxiety: The pandemic has brought with it a constant fear of getting sick or losing loved ones. The insurrection also raised fears about the future of democracy and the safety of the country.\n Grief and loss: Millions of people have lost loved ones to COVID-19. Many others have experienced loss in other ways, such as losing their jobs, businesses, or homes. The insurrection also led to loss of trust in the government and in each other.\n Anger and frustration: Many people are angry about the way the pandemic and the insurrection have been handled. They may be frustrated with government officials, with their …",
          "link": "https://www.reddit.com/r/artificial/comments/16kefrr/bard_describe_what_the_pandemic_and_insurrection/",
          "publishedOn": "2023-09-16T18:28:27.000Z",
          "wordCount": 2955,
          "title": "Bard, describe what the pandemic and insurrection have made people feel.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16kb0bb/bard_what_percent_of_our_thoughts_just_come_to_us/",
          "author": null,
          "description": "There is no one definitive answer to this question, as the percentage of our thoughts that come to us on their own without our consciously choosing them can vary depending on the individual and the situation. However, some estimates suggest that up to 95% of our thoughts may be involuntary.\n This is because our thoughts are constantly being influenced by a variety of factors, both external and internal. For example, our environment, our emotions, and our physical state can all play a role in determining what thoughts pop into our heads.\n In addition, our brains are constantly processing information and making predictions, even when we are not actively thinking about anything. This process can sometimes lead to spontaneous thoughts, such as when we suddenly remember something that we had forgotten or when we come up with a new idea.\n While some of our spontaneous thoughts may be negative or intrusive, many of them can also be helpful or creative. For example, a spontaneous thought may help us to solve a problem, come up with a new solution, or simply make us smile.\n Overall, it is clear that a significant portion of our thoughts come to us without our consciously choosing them. This is a natural part of the human cognitive process and can be both beneficial and detrimental.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16kb0bb/bard_what_percent_of_our_thoughts_just_come_to_us/",
          "publishedOn": "2023-09-16T15:59:27.000Z",
          "wordCount": 2766,
          "title": "Bard, what percent of our thoughts just come to us on their own without our consciously choosing them?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16k8o6f/are_there_any_good_ai_video_editing_services/",
          "author": null,
          "description": "I have a lighting business and I have LOADS of videos, time lapses, images from our projects.\n But I can't make decent videos with them for social media.\n I'd love to find an ai service where I can upload a projects media and prompt the ai with exactly what I want.\n Like, please use this content to create marketing videos for us on tiktok, Instagram and facebook Facebook\n Etc\n    submitted by    /u/RulerOfThePixel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16k8o6f/are_there_any_good_ai_video_editing_services/",
          "publishedOn": "2023-09-16T14:17:46.000Z",
          "wordCount": 2608,
          "title": "Are there any good ai video editing services available?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16k6k5p/how_can_i_generate_the_missing_part_of_the_trick/",
          "author": null,
          "description": "submitted by    /u/farineziq  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16k6k5p/how_can_i_generate_the_missing_part_of_the_trick/",
          "publishedOn": "2023-09-16T12:38:19.000Z",
          "wordCount": 2544,
          "title": "How can I generate the missing part of the trick? Does this technique have a name?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16jxyda/oneminute_daily_ai_news_9152023/",
          "author": null,
          "description": "A little boy named Alex saw 17 different doctors over the course of three years, unable to find a root cause of his chronic pain. At her wit’s end, his mom, Courtney, fed his radiology report into ChatGPT and produced immediate answers.[1]\n In January, Wharton professor Christian Terwiesch gave his MBA final exam to ChatGPT. It passed with flying colors. Now, he’s at it again with a new experiment to determine whether ChatGPT can come up with product ideas better and faster than his students. It can. And cheaper, too.[2]\n Bathroom-cleaning robot built for commercial businesses gives consumers hope for AI maid.[3]\n Judge admits he used ChatGPT to write a Court of Appeal ruling as he calls the AI tool ‘jolly useful’.[4]\n  \nSources:\n [1] https://radiologybusiness.com/topics/artificial-intelligence/after-seeing-17-different-doctors-boy-rare-condition-receives-diagnosis-chatgpt\n [2] https://knowledge.wharton.upenn.edu/article/is-chatgpt-a-better-entrepreneur-than-most/\n [3] https://www.foxnews.com/lifestyle/bathroom-cleaning-robot-built-commercial-businesses-gives-consumers-hope-ai-maid\n [4] https://www.dailymail.co.uk/news/article-12524607/Judge-ChatGPT-write-Court-Appeal-ruling-AI-useful.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16jxyda/oneminute_daily_ai_news_9152023/",
          "publishedOn": "2023-09-16T04:14:25.000Z",
          "wordCount": 2666,
          "title": "One-Minute Daily AI News 9/15/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16jsd4m/googles_new_deepmind_maps_algorithm_improves/",
          "author": null,
          "description": "Google has developed an AI algorithm to refine route suggestions on Google Maps, personalizing it based on user data and behavior, allegedly improving the accuracy on an average by 16-24 percent.\n To stay on top of the latest advancements in AI, look here first.\n https://preview.redd.it/rp21ylzo7iob1.jpg?width=770&format=pjpg&auto=webp&s=737cf3fd278ade42900e8586d626a7c729522c1a\n Personalized Route Suggestions through AI\n  \nThe AI model comprises 360 million parameters, using real-time data from Maps users to influence factors including travel time, road conditions, tolls, and personal preferences to suggest routes.\n This technology is grounded on \"inverse reinforcement learning\" (IRL), specifically a new IRL algorithm - \"Receding Horizon Inverse Planning (RHIP)\".\n  \nThe Power of RHIP and AI in Maps\n  \nGoogle and Deepmind jointly worked to develop RHIP, using complex stochastic models in immediate vicinity areas, but switching to simpler deterministic methods for distant areas for power conservation.\n The AI improves route suggestions for both driving and two-wheeled vehicles by learning from Maps users' movements and behaviors over time.\n Google states that this is the largest application of inverse reinforcement learning for route planning to date.\n  \nImplementation and User Testing\n  \nGoogle has applied the algorithm to Maps data globally, but extensive user testing is needed to confirm if the technique consistently produces better routes.\n Previous attempts at using AI systems for route planning on a large scale have often failed due to the complexity of road networks.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that tracks the most relevant news and research in AI. Professionals from Google, Meta, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16jsd4m/googles_new_deepmind_maps_algorithm_improves/",
          "publishedOn": "2023-09-15T23:29:34.000Z",
          "wordCount": 2796,
          "title": "Google’s new DeepMind Maps algorithm improves route suggestions by 24%",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16jpu3w/bard_on_republican_16_denial/",
          "author": null,
          "description": "There are a number of reasons why some Republicans may be in denial about Trump's role in the January 6th Capitol riot.\n  \nTrump has been very effective at cultivating a cult of personality among his supporters. These supporters are often fiercely loyal to him and willing to believe whatever he says, even if it contradicts reality.\n Many Republicans have been reluctant to criticize Trump for fear of alienating his supporters. This is especially true for Republican politicians who are up for re-election in 2022.\n Some Republicans may genuinely believe that Trump did not incite the riot. They may point to the fact that he did not explicitly call for violence, or that he told his supporters to \"peacefully and patriotically make your voices heard.\"\n Other Republicans may be motivated by partis…",
          "link": "https://www.reddit.com/r/artificial/comments/16jpu3w/bard_on_republican_16_denial/",
          "publishedOn": "2023-09-15T21:43:32.000Z",
          "wordCount": 2947,
          "title": "Bard on Republican 1/6 denial",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16jowi1/bard_on_factory_farming_and_clean_meat/",
          "author": null,
          "description": "Factory farming is a cruel and unsustainable way to produce meat. Animals are crammed into small, filthy spaces, where they are often denied their basic needs. They are given antibiotics to prevent disease and growth hormones to make them grow faster. This leads to a variety of health problems for the animals, as well as for the people who eat their meat.\n Clean meat is a new technology that offers a more humane and sustainable way to produce meat. It is made from animal cells that are grown in a lab, without the need for animals to be raised or slaughtered. Clean meat is still in its early stages of development, but it has the potential to revolutionize the meat industry.\n Here are some of the reasons why factory farming must be replaced by clean meat:\n  \nIt is cruel to animals. Factory f…",
          "link": "https://www.reddit.com/r/artificial/comments/16jowi1/bard_on_factory_farming_and_clean_meat/",
          "publishedOn": "2023-09-15T21:07:30.000Z",
          "wordCount": 2902,
          "title": "Bard on factory farming and clean meat",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16jisc3/ai_weekly_megathread/",
          "author": null,
          "description": "News provided by aibrews.com\n  \nStability AI launched Stable Audio, a generative AI tool for music & sound generation from text. The underlying latent diffusion model architecture uses audio conditioned on text metadata as well as audio file duration and start time [Details].\n Coqui released XTTS - a new voice generation model that lets you clone voices in 13 different languages by using just a quick 3-second audio clip [Details].\n Microsoft Research released and open-sourced Phi-1.5 - a 1.3 billion parameter transformer-based model with performance on natural language tasks comparable to models 5x larger [Paper ].\n Project Gutenberg, Microsoft and MIT have worked together to use neural text-to-speech to create and release thousands of human-quality free and open audiobooks [Details].\n Res…",
          "link": "https://www.reddit.com/r/artificial/comments/16jisc3/ai_weekly_megathread/",
          "publishedOn": "2023-09-15T17:02:02.000Z",
          "wordCount": 3231,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16jg22m/with_things_always_moving_so_fast_i_may_have/",
          "author": null,
          "description": "Has anyone dropped an opensource tool like run.ai, to leverage multiple gpus / distribute the workload a bit more efficiently?\n I'm loving some of the single gpu llm modifications that have been dropping recently (have a couple i've tested that ran well on 4090 and 3090ti in the lab), but i've got a plethora of 8 & 12 gig 3xxx series cards i'd love to take advantage of beyond passthroughs to individual vms. Looking for any solutions. Speed isn't as important as the ability to distributively run larger models.\n    submitted by    /u/SwallowedBuckyBalls  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16jg22m/with_things_always_moving_so_fast_i_may_have/",
          "publishedOn": "2023-09-15T15:13:22.000Z",
          "wordCount": 2639,
          "title": "With things always moving so fast, I may have missed it. Anyone doing something like Run.AI in an opensource capacity?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16jg0zf/ai_death_metal_band_anarchys_echo_debut_single/",
          "author": null,
          "description": "submitted by    /u/glenniszen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16jg0zf/ai_death_metal_band_anarchys_echo_debut_single/",
          "publishedOn": "2023-09-15T15:12:07.000Z",
          "wordCount": 2546,
          "title": "AI Death Metal band 'Anarchy's Echo' - Debut single 'Soul Shredder' [visuals, music, name, logo all AI generated]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16j8m29/free_ai_summary_of_article_based_on_most/",
          "author": null,
          "description": "I am looking for a free AI tool, site (may be paid with free account limited options) that can do a summary of English article (like BBC, youtube) based on most frequently used English words, for example Oxford list of 3000 most frequently used words in English. In other words if word is not in that list it should replace the word with the one that is on the list or its definition.\n Pdf\n    submitted by    /u/vibrantform  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16j8m29/free_ai_summary_of_article_based_on_most/",
          "publishedOn": "2023-09-15T09:32:13.000Z",
          "wordCount": 2616,
          "title": "free AI summary of article based on most frequently used English words",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16j8lha/ai_on_why_we_have_much_to_be_grateful_for/",
          "author": null,
          "description": "I said to Bard:\n It seems like these are difficult times. Compare today with the WWII years, explaining how much we have to be grateful for.\n Bard said:\n I agree that these are difficult times. The world is facing many challenges, including the COVID-19 pandemic, climate change, and political instability. However, I believe that we have much to be grateful for today compared to the WWII years.\n Here are just a few things:\n We live in a time of peace. World War II was a global conflict that caused the deaths of millions of people. Today, there are no major wars raging on.\n We have access to advanced medical care. During WWII, many people died from diseases that are now easily treatable. Today, we have antibiotics, vaccines, and other medical advances that have saved countless lives.\n We have a higher standard of living. In the WWII years, many people lived in poverty. Today, most people in the developed world have access to clean water, food, and shelter.\n We have more opportunities for education and advancement. In the WWII years, many people were denied an education because of their race, gender, or social class. Today, education is more accessible than ever before, and people from all backgrounds have the opportunity to succeed.\n We have a better understanding of the world. During WWII, there was a lot of misinformation and propaganda. Today, we have access to more information than ever before, and we can make more informed decisions about our lives.\n Of course, there are still many challenges that we face today. But I believe that we have come a long way since the WWII years, and we have much to be grateful for. Let us never forget the sacrifices that were made during that time, and let us continue to work towards a better future for all.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16j8lha/ai_on_why_we_have_much_to_be_grateful_for/",
          "publishedOn": "2023-09-15T09:31:17.000Z",
          "wordCount": 2846,
          "title": "AI on why we have much to be grateful for",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16j6djc/what_is_at_stake_in_the_ai_based_technoeconomic/",
          "author": null,
          "description": "The AI-based techno-economic war between the West and China will determine the global distribution of technology, economic benefits, and influence.\n \nThe winner of this race, particularly in AI, will have the power to accelerate GDP growth and project global economic benefits.\n \nChina is actively pursuing technological leadership in AI and 5G wireless, while the West must prioritize technological talent influx and leverage its venture and technology ecosystem.\n \nAggressive AI regulation could hinder the West's momentum in this race.\n \nThe risks of this war and AI technology are significant, but it is a greater risk to let adversaries have unconstrained power.\n \nGlobal treaties are not enforceable solutions to regulate AI.\n \n Source : https://medium.com/@vkhosla/what-is-at-stake-in-this-ai-based-techno-economic-war-between-the-west-and-china-8f76bd291be7\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16j6djc/what_is_at_stake_in_the_ai_based_technoeconomic/",
          "publishedOn": "2023-09-15T07:12:03.000Z",
          "wordCount": 2657,
          "title": "What is at stake in the AI based techno-economic war between the West and China?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16j63zr/what_has_been_the_most_significant_assistance/",
          "author": null,
          "description": "There's no need to specify which product fulfills your needs, but we'd like everyone to focus on describing their current frustrations and the issues they urgently hope AI can help them with.\n    submitted by    /u/Minna_Z  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16j63zr/what_has_been_the_most_significant_assistance/",
          "publishedOn": "2023-09-15T06:55:47.000Z",
          "wordCount": 2608,
          "title": "What has been the most significant assistance from AI for you? It could be in various aspects of work, learning, and life. Are there any other needs you have that you hope AI can help you with, but there aren't suitable AI tools for them yet?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16j4q4e/wine_can_prevent_cancer_says_chatgpt/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16j4q4e/wine_can_prevent_cancer_says_chatgpt/",
          "publishedOn": "2023-09-15T05:32:21.000Z",
          "wordCount": 2547,
          "title": "“Wine can prevent Cancer” says ChatGPT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ivaym/two_guys_with_very_different_views_on_ai_yuval/",
          "author": null,
          "description": "submitted by    /u/hauntedhivezzz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ivaym/two_guys_with_very_different_views_on_ai_yuval/",
          "publishedOn": "2023-09-14T21:59:17.000Z",
          "wordCount": 2546,
          "title": "Two guys with VERY different views on AI –Yuval Noah Harari and Mustafa Suleyman in conversation (full interview)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ir89k/chatgpt_tell_the_jury_that_trump_waiting_three/",
          "author": null,
          "description": "I asked ChatGPT to talk with Trump's jury about the 3-hour delay. Not bad.\n ChatGPT:\n Ladies and gentlemen of the jury, today, we present a compelling case that the three-hour delay in President Trump's response to the events of January 6th is, without a doubt, overwhelming and irrefutable evidence of his planning and conducting the insurrection that unfolded before our eyes.\n First, consider the timeline. As the violence escalated, President Trump did not immediately call for an end to the chaos. This delay allowed the mob to wreak havoc, endanger lives, and damage our democracy. A leader's duty is to protect the nation and its citizens, and a three-hour wait to act is inexplicable unless there was intent behind it.\n Second, let's talk about intent. In criminal law, intent matters. It's the difference between an accident and a crime. A deliberate delay in response to an unfolding insurrection suggests a guilty mind. President Trump had the power and the responsibility to intervene immediately. Yet, he chose not to, allowing the violence to escalate.\n Furthermore, we must consider his words leading up to and during the events of January 6th. His rhetoric could be interpreted as encouragement for his supporters to take matters into their own hands. This, coupled with the delay, paints a picture of a leader who not only knew what was happening but may have orchestrated it.\n Ladies and gentlemen, we are not here to pass judgment but to seek justice. The evidence of a three-hour delay in responding to the insurrection, along with the surrounding circumstances, presents a compelling case that President Trump planned and conducted this insurrection. It is our duty to hold individuals accountable for their actions, regardless of their position.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ir89k/chatgpt_tell_the_jury_that_trump_waiting_three/",
          "publishedOn": "2023-09-14T19:18:57.000Z",
          "wordCount": 2844,
          "title": "ChatGPT, tell the jury that Trump waiting three hours to call off his mob is overwhelming and irrefutable evidence that he planned and conducted the January 6th insurrection",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16iqau7/how_good_a_crime_sleuth_and_judge_is_todays_ai/",
          "author": null,
          "description": "How would today's AI perform as a crime investigator or judge? To find out, I asked Bard the following question:\n The film Social Network suggests that Mark Zuckerberg stole his idea for Facebook from two brothers who hired him to make an app for the idea. How likely is this to be true?\n Bard seemed informed and sharp:\n \"The film The Social Network is a dramatization of the founding of Facebook, and as such, it takes some liberties with the truth. However, the film does accurately portray the fact that Mark Zuckerberg was sued by the Winklevoss twins, Cameron and Tyler, who claimed that he stole their idea for a social networking website called HarvardConnection.\n The Winklevoss twins allege that they met with Zuckerberg in December 2003 to discuss their idea for HarvardConnection, and tha…",
          "link": "https://www.reddit.com/r/artificial/comments/16iqau7/how_good_a_crime_sleuth_and_judge_is_todays_ai/",
          "publishedOn": "2023-09-14T18:41:58.000Z",
          "wordCount": 2895,
          "title": "How good a crime sleuth and judge is today's AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ipk9h/which_ai_to_use_for_this_idea/",
          "author": null,
          "description": "Hi there! I'm participating in a Hackathon at work and am wondering if this community can give me some direction. Every year our company receives mandates / updates from different parties. In turn, our development teams have to parse through heavy documentation to figure out what needs to change in our code. Ingesting the data is what takes the longest. Our goal is to feed the mandates documentation through an AI and have it return what is needed to be changed in our code. For example, something might say field 200 now needs to include a 6 digit date format vs the 4 digit date format we've had in years past. We have secured a license for Azure AI but honestly no idea if that is the right AI to use. I youtubed a bunch of videos on document processing but I'm also not sure if that is what we are trying to do. Any advice on this is much appreciated.\n    submitted by    /u/HillyjoKokoMo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ipk9h/which_ai_to_use_for_this_idea/",
          "publishedOn": "2023-09-14T18:13:01.000Z",
          "wordCount": 2698,
          "title": "Which AI to use for this idea?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ikloc/looking_for_a_meeting_assistant/",
          "author": null,
          "description": "I'm looking for a program that will transcribe live audio playing from my computer (windows).\n Do you know something like that? I've seen Buzz (https://chidiwilliams.github.io/buzz/docs/usage), but it needs an audio loopback driver in order to work, so I wonder if there are others.\n 🚀 Bonus points if it recognizes different people talking.\n 🚀 Extra bonus points if it can transcribe multiple languages.\n    submitted by    /u/AleHoju  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ikloc/looking_for_a_meeting_assistant/",
          "publishedOn": "2023-09-14T14:56:34.000Z",
          "wordCount": 2597,
          "title": "Looking for a meeting assistant",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ieydv/i_signed_up_for_a_debate_on_ai/",
          "author": null,
          "description": "So today I signed up for a debate on ai. Wheather ai is beneficial or dangerous to human beings. I have the freedom to choose any side. This debate will be watched by about 130 people, all cs freshmen (mind you, also my first time speaking in front of this many people). Now, I'm confident I know more about ai than an average person but I need your help in preparing properly. Which side do I take and what are all the points I should keep in mind? It's 4 pm here and the debate is tomorrow. Any help will be appreciated. Thank you.\n    submitted by    /u/CalmGuy69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ieydv/i_signed_up_for_a_debate_on_ai/",
          "publishedOn": "2023-09-14T10:36:54.000Z",
          "wordCount": 2642,
          "title": "I signed up for a debate on ai.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16idzsi/artificial_intelligence_may_be_humanitys_most/",
          "author": null,
          "description": "Artificial intelligence (AI) has the potential to solve the world's problems or destroy humanity.\n \nIt is being developed by a few hundred individuals in Silicon Valley, and we have little say in its ethics or existence.\n \nAI has already demonstrated creative abilities in painting, writing, and music.\n \nIt is also being used in drug discovery, therapy, dating apps, and misinformation in politics.\n \nThe rapid adoption of AI raises concerns about job displacement and the potential for catastrophic events.\n \nExperts predict a significant chance of AI causing a catastrophe or even wiping out humanity.\n \n Source : https://www.vanityfair.com/news/2023/09/artificial-intelligence-industry-future\n Summarized by Nuse AI\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16idzsi/artificial_intelligence_may_be_humanitys_most/",
          "publishedOn": "2023-09-14T09:39:20.000Z",
          "wordCount": 2640,
          "title": "Artificial Intelligence May Be Humanity’s Most Ingenious Invention–and Its Last?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16iaxda/generative_ai_consumer_landscape_by_a16z/",
          "author": null,
          "description": "In less than a year since ChatGPT was introduced, it has become the fastest consumer application to register 100 million monthly active users. But how are consumers using other GenAI products apart from ChatGPT? An a16z Consumer report examines the top 50 GenAI web products (based on SimilarWeb data) to find out.\n To stay on top of the latest advancements in AI, look here first.\n https://preview.redd.it/f0kh5qag16ob1.png?width=2058&format=png&auto=webp&s=1cab11a31d384c068912c9fca32a000393b795d5\n  \nProprietary models are dominating: 80% of the top 50 GenAI products didn’t exist a year ago—suggesting many of the most compelling consumer experiences are completely novel. Interestingly, 48% of these are bootstrapped—with no outside funding.\n ChatGPT holds a massive lead: ChatGPT alone accounts for 60% of the entire list's monthly traffic, with roughly 1.6 billion visits and 200 million monthly users as of June 2023.\n LLM assistants are dominating: LLMs, including Google’s Bard and Quora’s Poe, constitute 68% of total consumer traffic to the top 50. The other categories seeing significant traffic are AI companions and content-generation tools.\n GenAI marketing is mostly organic: Marketing for most of these products has been reliant on referrals, word of mouth, and other traditional marketing as they enter the market. About 90% of these companies are already monetizing, and most do so via a subscription model.\n GenAI and mobile adaptability: Given the extensive consumer time spent on mobile, an increase in mobile-first GenAI products is expected as the technology evolves.\n  \n(source)\n P.S. If you like this type of analysis, sign up for my free newsletter that deciphers the fastest-moving news and research in AI and tech. Professionals from Google, Meta, and OpenAI are already on board.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16iaxda/generative_ai_consumer_landscape_by_a16z/",
          "publishedOn": "2023-09-14T06:36:55.000Z",
          "wordCount": 2803,
          "title": "Generative AI Consumer Landscape by a16z",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ianu2/oneminute_daily_ai_news_9142023/",
          "author": null,
          "description": "Adobe’s Firefly generative AI tools are now widely available.[1]\n Stability AI, gunning for a hit, launches an AI-powered music generator.[2]\n Elon Musk warned of civilizational risks posed by artificial intelligence. Sundar Pichai of Google highlighted the technology’s potential to solve health and energy problems. And Mark Zuckerberg of Meta stressed the importance of open and transparent A.I. systems.[3] \n German military plows millions into AI ‘environment’ for weapons tests that could change combat forever.[4]\n Amazon launches generative AI to help sellers write product descriptions.[5]\n  \nSources:\n [1] https://www.theverge.com/2023/9/13/23871537/adobe-firefly-generative-ai-model-general-availability-launch-date-price\n [2] https://techcrunch.com/2023/09/13/stability-ai-gunning-for-a-hit-launches-an-ai-powered-music-generator/\n [3] https://www.nytimes.com/2023/09/13/technology/silicon-valley-ai-washington-schumer.html\n [4] https://www.foxnews.com/world/german-military-plows-millions-ai-environment-weapons-tests-change-combat\n [5] https://www.aboutamazon.com/news/small-business/amazon-sellers-generative-ai-tool \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ianu2/oneminute_daily_ai_news_9142023/",
          "publishedOn": "2023-09-14T06:21:03.000Z",
          "wordCount": 2629,
          "title": "One-Minute Daily AI News 9/14/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16i4bou/im_very_new_in_this_field_prompt_engineering_and/",
          "author": null,
          "description": "My experience in CS, coding, and programming is very minimal. I understand general concepts but only through the lens of a degree in physics that required I mess around with WolframAlpha sometimes (which I really enjoyed). I've been considering getting a second degree in CS or something related but want to find a clear(ish) path before committing to it. I would love to hear any related thoughts as well!\n ​\n  \nPrompt Engineering seems like a pretty fresh field of study. Is it up and coming as a career path?\n People that specialize in this, what field(s) did you come from and how would you recommend diving into it?\n Considering my experience, would I be able to actually find work, freelancing or employed?\n How on earth do I get started in this world? It seems so insanely big and complicated but I am just fascinated by the idea of using written dialogue to manipulate the output of an LLM!\n From my very high overview of PE and the recent advances in AI, PE as a field of study and interest is going to expand exponentially, is that accurate?\n  \n   submitted by    /u/Top_Room_6714  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16i4bou/im_very_new_in_this_field_prompt_engineering_and/",
          "publishedOn": "2023-09-14T00:53:02.000Z",
          "wordCount": 2736,
          "title": "I'm very new in this field (Prompt Engineering) and have a handful of questions, any advice and thoughts are welcome!!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16i09c7/the_economist_podcasts_babbage_mustafa_suleyman/",
          "author": null,
          "description": "submitted by    /u/siiilverrsurfer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16i09c7/the_economist_podcasts_babbage_mustafa_suleyman/",
          "publishedOn": "2023-09-13T22:00:31.000Z",
          "wordCount": 2556,
          "title": "‎The Economist Podcasts: Babbage: Mustafa Suleyman on how to prepare for the age of AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hzcgb/dystopia_ai_movie/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hzcgb/dystopia_ai_movie/",
          "publishedOn": "2023-09-13T21:25:46.000Z",
          "wordCount": 2531,
          "title": "Dystopia AI Movie",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hw9qv/looking_for_ai_developers_and_researchers/",
          "author": null,
          "description": "Hi,\n I would love to create a small group of people who work together in AI.\n The project would be to create an AI that can infer new novel knowledge from existing datasets, as opposed to be being limited by operating within the training data. Specifically to be used in the quest to learn more about the universe.\n So I am looking for a team of likeminded individuals who want to grow in the field of AI.\n I'd love to setup a discord, subreddit and github profile to showcase our work.\n My introduction question is: How do we get AI's to expand upon current knowledge instead of just serving from the knowledge itself.\n Anyone interested in joining me in this?\n    submitted by    /u/Miserable-Cobbler-16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hw9qv/looking_for_ai_developers_and_researchers/",
          "publishedOn": "2023-09-13T19:26:31.000Z",
          "wordCount": 2656,
          "title": "Looking for AI developers and researchers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hte7j/dont_worry_folks_big_tech_pinky_swears_itll_build/",
          "author": null,
          "description": "Eight big names in tech, including Nvidia, Palantir, and Adobe, have agreed to red team their AI applications before they're released and prioritize research that will make their systems more trustworthy.\n \nThe White House has secured voluntary commitments from Adobe, Cohere, IBM, Nvidia, Palantir, Salesforce, Scale AI, and Stability AI to develop machine-learning software and models in a safe, secure, and trustworthy way. The commitments only cover future generative AI models.\n \nEach of the corporations has promised to submit their software to internal and external audits, where independent experts can attack the models to see how they can be misused.\n \nThe organizations agreed to safeguard their intellectual property and make sure things like the weights of their proprietary neural networks don't leak, while giving users a way to easily report vulnerabilities or bugs.\n \nAll eight companies agreed to focus on research to investigate societal and civil risks AI might pose if they lead to discriminatory decision-making or have weaknesses in data privacy.\n \nThe US government wants Big Tech to develop watermarking techniques that can identify AI-generated content.\n \nThe US has asked the corporations to commit to building models for good, such as fighting climate change or improving healthcare.\n \n Source : https://www.theregister.com/2023/09/12/nvidia_adobe_palantir_ai_safety/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hte7j/dont_worry_folks_big_tech_pinky_swears_itll_build/",
          "publishedOn": "2023-09-13T17:37:15.000Z",
          "wordCount": 2743,
          "title": "Don't worry, folks. Big Tech pinky swears it'll build safe, trustworthy AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hshxl/harvard_ilabfunded_project_subfeature_of_the/",
          "author": null,
          "description": "submitted by    /u/Raymondlkj  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hshxl/harvard_ilabfunded_project_subfeature_of_the/",
          "publishedOn": "2023-09-13T17:02:46.000Z",
          "wordCount": 2558,
          "title": "Harvard iLab-funded project: Sub-feature of the platform out -- Enjoy free ChatGPT-3/4, personalized education, and file interaction with no page limit 😮. All at no cost. Your feedback is invaluable!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hs3df/dissatisfied_with_gpt_paid_subscription_who/",
          "author": null,
          "description": "I’ve been using the paid version of GPT for a while but I think it’s time to move on. For $20 a month i would at least like for there to be an option to input an image, but I would also maybe pay a bit more than that per month for a suite of tools or something if it could also do image generation in addition to just text.\n I’m sorry if it seems like I should be able to understand anything better - please note I am disabled, my use of the tools is personal (creative and household) and not professional, and I’m doing my best by asking here. I do not mean to bother anyone with my own ignorance. Thank you.\n    submitted by    /u/CaveLady3000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hs3df/dissatisfied_with_gpt_paid_subscription_who/",
          "publishedOn": "2023-09-13T16:47:55.000Z",
          "wordCount": 2666,
          "title": "Dissatisfied with GPT paid subscription - who should I go with instead?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hrfcm/oneminute_daily_ai_news_9132023/",
          "author": null,
          "description": "Project Gutenberg and Microsoft have created thousands of free audiobooks that use neural text-to-speech technology to generate the voices.[1]\n A group of U.S. authors, including Pulitzer Prize winner Michael Chabon, has sued OpenAI in federal court in San Francisco, accusing the Microsoft-backed program of misusing their writing to train its popular artificial intelligence-powered chatbot ChatGPT.[2]\n Numenta launches brain-based NuPIC to make AI processing up to 100 times more efficient.[3]\n Adept AI Labs released Persimmon-8B. Persimmon-8B is an open-source, fully permissively licensed model in the 8B class. This model holds immense potential for a wide array of applications, aiming to assist users in various computer-related tasks.[4]\n  \nSources:\n [1] https://www.zdnet.com/article/heres-how-to-access-thousands-of-free-audiobooks-thanks-to-microsoft-ai-and-project-gutenberg/\n [2] https://www.reuters.com/technology/more-writers-sue-openai-copyright-infringement-over-ai-training-2023-09-11/\n [3] https://venturebeat.com/ai/numenta-launches-brain-based-nupic-to-make-ai-processing-up-to-100-times-more-efficient/\n [4] https://www.marktechpost.com/2023/09/09/adept-ai-labs-open-sources-persimmon-8b-a-powerful-fully-permissively-licensed-language-model-with/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hrfcm/oneminute_daily_ai_news_9132023/",
          "publishedOn": "2023-09-13T16:21:56.000Z",
          "wordCount": 2649,
          "title": "One-Minute Daily AI News 9/13/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hpu36/is_there_an_ai_image_tool_that_makes_existing/",
          "author": null,
          "description": "I see a ton of AI image tools out there. Some let you upload image files and modulate/modify them in some way. I am wondering if a tool exists that will take a real life product image and make it appear more like a render/computer generated image. \n Essential I would love to be able to take a pic of a product and use automatic smoothing and AI simulated rendering to output a clean image that looks like a 3d render. This would be used as a product image for an e-commerce website.\n    submitted by    /u/ElonMusk0fficial  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hpu36/is_there_an_ai_image_tool_that_makes_existing/",
          "publishedOn": "2023-09-13T15:20:43.000Z",
          "wordCount": 2635,
          "title": "Is there an AI image tool that makes existing images look like renders?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hn3o9/alibaba_cloud_open_sources_its_generative_ai/",
          "author": null,
          "description": "Alibaba Cloud has open sourced two of its generative AI models, Qwen-7B and Qwen-7B-Chat, for commercial and research use.\n \nThe models' codes and documentation will be accessible through Alibaba Cloud's AI model repository ModelScope and the US collaborative AI platform Hugging Face.\n \nCompanies with fewer than 100 million monthly active users can use the models for commercial purposes free of charge, while those with more users will need to request a license.\n \nAlibaba aims to democratize AI technology and support LLM start-ups.\n \nAlibaba Cloud's ModelScope platform currently features over 1,000 ready-to-use AI models contributed by 20 leading AI institutions.\n \n Source : https://www.scmp.com/tech/big-tech/article/3229907/alibaba-cloud-open-sources-its-two-generative-ai-models-based-chatgpt-style-tongyi-qianwen\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hn3o9/alibaba_cloud_open_sources_its_generative_ai/",
          "publishedOn": "2023-09-13T13:30:33.000Z",
          "wordCount": 2642,
          "title": "Alibaba Cloud open sources its generative AI models Tongyi Qianwen",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hmxxq/is_there_an_ai_tool_for_generating_videos_using/",
          "author": null,
          "description": "I have a text script that I want to turn into a video. For the sake of context, the video is on balancing a person’s daily activities. I’m getting tired trying to find matching stock footages for the videos. I was wondering if there is a way to do this using AI tools? Synthesia won’t do because it looks like a video narration, more than a video essay. Any suggestions would help. Thanks in advanced!\n    submitted by    /u/Entaro2109  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hmxxq/is_there_an_ai_tool_for_generating_videos_using/",
          "publishedOn": "2023-09-13T13:23:58.000Z",
          "wordCount": 2616,
          "title": "Is there an AI tool for generating videos using stock footages?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hmqgn/google_codey_humaneval_benchmark/",
          "author": null,
          "description": "Hi everyone,\n I'm hunting for a HumanEval Benchmark for Google's Codey model and am having a tough time hunting it down. Can anyone point me to an Arxiv paper or a coding leaderboard that includes Codey?\n Thanks!\n    submitted by    /u/Iamreason  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hmqgn/google_codey_humaneval_benchmark/",
          "publishedOn": "2023-09-13T13:14:54.000Z",
          "wordCount": 2571,
          "title": "Google Codey HumanEval Benchmark",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hidk9/many_executivesinvestors_are_pushing_for_the_use/",
          "author": null,
          "description": "But product & tech teams succumb to the pressure and move on to developing proof of concepts & even launch products that fail to achieve ROI \n Why?\n 1- use cases are not well defined\n 2- not enough data or right data strategy\n 3- data and model architecture not founded well \n I love Apple’s approach to AI, they shy away from the hype and focus on the fundamentals. \n First the customer, product, then the tech that will add the value the customer needs. \n What do you think are the top reasons generative AI applications succeed? \n View Poll\n    submitted by    /u/AILaunchpad  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hidk9/many_executivesinvestors_are_pushing_for_the_use/",
          "publishedOn": "2023-09-13T09:26:25.000Z",
          "wordCount": 2650,
          "title": "Many executives/investors are pushing for the use of generative AI in products/applications…",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hhz0h/create_a_custom_search_engine/",
          "author": null,
          "description": "I have an open book exam that has a lot of information that I will need to physically search through.\n Is there a way i can load all he PDFS and create a customised chatgbt style search, so i can easily look through all the information and research i have?\n    submitted by    /u/yellowmushroom22  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hhz0h/create_a_custom_search_engine/",
          "publishedOn": "2023-09-13T09:02:06.000Z",
          "wordCount": 2585,
          "title": "Create a custom search engine",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hf381/heygens_oneclick_translation_from_english_to/",
          "author": null,
          "description": "submitted by    /u/Fadawah  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hf381/heygens_oneclick_translation_from_english_to/",
          "publishedOn": "2023-09-13T06:06:16.000Z",
          "wordCount": 2548,
          "title": "HeyGen's one-click translation from English to Italian, Hindi, German and Spanish is the craziest AI application I've seen in months.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hezjn/i_wanna_develop_small_scale_personal_ai_apps_for/",
          "author": null,
          "description": "I wanna develop small scale personal AI apps for each my friends and AI said i should learn Python, TensorFlow Lite, SQLite, GCP, Pandas, Scikit Learn and Keras. How right is this?\n    submitted by    /u/Leading-Ad2278  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hezjn/i_wanna_develop_small_scale_personal_ai_apps_for/",
          "publishedOn": "2023-09-13T06:00:34.000Z",
          "wordCount": 2595,
          "title": "I wanna develop small scale personal AI apps for each my friends and AI said i should learn about Python, TensorFlow Lite, SQLite, GCP, Pandas, Scikit Learn and Keras. How right is this?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hev64/ai_image_generators_have_a_moderation_problem/",
          "author": null,
          "description": "Tests carried out by Logically confirm these platforms accept 85% of prompts tailored for election manipulation.\n    submitted by    /u/Asleep-Television-24  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hev64/ai_image_generators_have_a_moderation_problem/",
          "publishedOn": "2023-09-13T05:53:10.000Z",
          "wordCount": 2555,
          "title": "AI image generators have a moderation problem",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hd8jo/ai_chatbots_successfully_build_software_in_under/",
          "author": null,
          "description": "AI Chatbots, such as OpenAI's ChatGPT, can create incredibly cost-friendly software in record time, reveals a new study.\n To stay on top of the latest advancements in AI, look here first.\n https://preview.redd.it/rxpr6db3aynb1.png?width=1300&format=png&auto=webp&s=721ff5d8f9d25b5e48fa26e2b335c1d20620a83a\n The AI Tech Company Experiment\n  \nBrown University and several Chinese University researchers put ChatGPT-powered AI bots to the test by making them run a hypothetical software development company, ChatDev.\n The AI chatbots were given specific roles and allocated respective stages based on the traditional waterfall model encompassing designing, coding, testing, and documenting.\n AI 'employees' functioned with minimal human input to complete their parts of the software development process.\n  \nImpressive Results\n  \nAssigning 70 tasks to ChatDev led to the completion of the entire software development process in under seven minutes at a cost of less than one dollar on average.\n A stunning 86.66% of the generated software systems performed flawlessly.\n Despite some language model errors and biases, the study demonstrates AI's immense potential in automating tasks - a boon, especially to junior programmers around the world.\n  \nBroader Implications\n  \nPowerfully generative AI technologies like ChatGPT can perform specific job functions, saving time, and boosting productivity in several industries.\n While coders find such tools beneficial, it's also critical to note that limitations and biases do exist in AI models which could potentially affect the software creation process.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that tracks the most vital news and research in AI. Professionals from Google, Meta, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hd8jo/ai_chatbots_successfully_build_software_in_under/",
          "publishedOn": "2023-09-13T04:25:26.000Z",
          "wordCount": 2792,
          "title": "AI Chatbots successfully build software in under 7 minutes for less than $1",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hcknz/how_business_thinkers_can_start_building_ai/",
          "author": null,
          "description": "submitted by    /u/mycall  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hcknz/how_business_thinkers_can_start_building_ai/",
          "publishedOn": "2023-09-13T03:51:04.000Z",
          "wordCount": 2552,
          "title": "How Business Thinkers Can Start Building AI Plugins With Semantic Kernel",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16hbxjs/eu_leads_the_way_in_regulating_ai/",
          "author": null,
          "description": "submitted by    /u/Jariiari7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16hbxjs/eu_leads_the_way_in_regulating_ai/",
          "publishedOn": "2023-09-13T03:19:59.000Z",
          "wordCount": 2548,
          "title": "EU leads the way in regulating AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16h9or2/webinar_with_dr_richard_marks/",
          "author": null,
          "description": ">Sailea is a student run non-profit that does not charge for any of its services \n 🌟 Join SAILea’s Free Webinar with Dr. Richard Marks! 🌟\n 🗓️ Date: September 23rd, 2023 ⏰ Time: 3:00-4:00PM EST\n Don't miss an exclusive opportunity to learn from an AI expert! Join us for a free webinar featuring Dr. Richard Marks, a renowned CS and Data Science professor at UNC-Chapel Hill University with a remarkable journey – from Google to PlayStation, and the mind behind EyeToy and PlayStation Move.\n 🚀 What to Expect:\n 🔹 Deep insights into tech innovation.\n 🔹 Career advice. \n 🔹 Live Q&A with Dr. Richard Marks.\n Reserve your spot now: sailea.org/events\n 🔥 Don’t miss this opportunity! Register today!🔥\n    submitted by    /u/Envoy-Insc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16h9or2/webinar_with_dr_richard_marks/",
          "publishedOn": "2023-09-13T01:35:44.000Z",
          "wordCount": 2650,
          "title": "Webinar with Dr. Richard Marks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16h53b7/i_want_to_try_out_stabilityais_chat_after_logging/",
          "author": null,
          "description": "submitted by    /u/w__sky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16h53b7/i_want_to_try_out_stabilityais_chat_after_logging/",
          "publishedOn": "2023-09-12T22:21:23.000Z",
          "wordCount": 2566,
          "title": "I want to try out Stability.AI's chat. After logging in with a Google account, a spinning wheel is all I get. Is it like that for everyone?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16h2e0s/i_made_a_data_request_feature_so_you_dont_have_to/",
          "author": null,
          "description": "So, I've been working on an AI data marketplace platform for a few months now. Users can buy, sell, request, and subscribe to data/datasets (and soon even train their ML/AI models using other users' datasets). One of our key features is the request feature, which allows users to submit data requests for free. These requests include descriptions, required fields, geographical scope, budget etc... Once a request is posted, it's sent to numerous companies, organizations, and data vendors that have the potential to fulfill it.\n I understand how frustrating the data acquisition process can be, so I designed this platform to be your one-stop shop for all data-related transactions. You no longer have to spend weeks or months dealing with different vendors and companies through slow emails. With our platform, you can request, negotiate, and purchase data all in one place, and it's completely free to post a request, by the way.\n We've already achieved some successes, and we hope to help more people access the datasets they need. After all, the best AI models are built on diverse and differentiating data. We've had some notable achievements, and we're eager to see if we can fulfill even more interesting dataset requests!\n    submitted by    /u/nobilis_rex_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16h2e0s/i_made_a_data_request_feature_so_you_dont_have_to/",
          "publishedOn": "2023-09-12T20:39:23.000Z",
          "wordCount": 2745,
          "title": "I made a data request feature so you don't have to exhaustively collect data/dataset(s) yourself!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16gxmdj/you_wont_believe_how_much_teslas_dojo/",
          "author": null,
          "description": "Morgan Stanley Research has valued Tesla's soon-to-be-released Dojo supercomputer at up to $500 billion, potentially increasing the auto giant's valuation significantly. The financial institution believes Dojo’s applications will go beyond Tesla's Full-Self Driving (FSD) capabilities.\n To stay on top of the latest advancements in AI, look here first.\n https://preview.redd.it/yhia3c5f1vnb1.jpg?width=1440&format=pjpg&auto=webp&s=7adf40e7b868a4fbf6eb3d696132652f4f549f23\n Morgan Stanley's Bullish Prediction on Dojo\n  \nMorgan Stanley has suggested that Dojo might not just enhance Tesla's FSD technology, but could find use in other devices that make real-time decisions based on a visual field.\n Apart from raising Tesla’s valuation, this could potentially open up new markets for the company.\n Following this, Morgan Stanley has increased its target price for Tesla shares from $250 to $400 each.\n  \nDojo Supercomputer Overview\n  \nTesla has developed Dojo in-house, diverging from conventional AI accelerators and involving its own computing, networking, IO, and instruction set.\n At the heart of Dojo is the D1 AI accelerator processor, containing 354 custom CPU cores. Twenty-five D1 chips are combined to create a Dojo training tile, which could expedite Tesla’s move towards earning revenue from vehicle software.\n  \nFuture Plans and Implications\n  \nTesla could potentially become an AI-as-a-service provider to automakers in need of FSD capabilities with Dojo.\n As the development of Dojo continues, Tesla has invested in alternative AI infrastructures, including a cluster of 10,000 of Nvidia's most potent H100 accelerators.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that explores the latest AI developments. Professionals from Google, Meta, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16gxmdj/you_wont_believe_how_much_teslas_dojo/",
          "publishedOn": "2023-09-12T17:35:22.000Z",
          "wordCount": 2790,
          "title": "You Won’t Believe How Much Tesla’s Dojo Supercomputer Is Worth",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16gx1l6/schwoz_sings_ballin/",
          "author": null,
          "description": "submitted by    /u/LaminateShark7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16gx1l6/schwoz_sings_ballin/",
          "publishedOn": "2023-09-12T17:13:06.000Z",
          "wordCount": 2531,
          "title": "Schwoz Sings Ballin",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16gqnwd/today_we_test_which_ai_is_smartest_tomorrow_ai/",
          "author": null,
          "description": "Somewhere in the world there's a person who is the smartest. Why stop there? There are ten people who are the smartest. And if they are on the Internet, AI will find them.\n Perhaps not yet. It probably needs to get smarter. Maybe by Gemini. Or GPT-5. But eventually an AI will analyze all of the content on the Internet, and determine from that data who are the ten most intelligent people on the planet, (whose material is online).\n Of course if AI can determine the top ten, it can certainly determine the top 100, and the top 1,000, and even the top 100,000. I suppose when that happens there will be a lot more human brain power available to solve our problems. Although by then AI will be solving them far better than we could, haha. \n But think about it for a minute. There are very smart people out there who don't publish in traditional mass media channels. The geniuses among us who don't fit in so well, and are therefore resigned to the margins, remaining unrecognized. \n Wouldn't it be great if AI discovered them, and gave them the validation they deserve? Wouldn't it be great to find out who they are so that they can better work on whatever.\n    submitted by    /u/Georgeo57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16gqnwd/today_we_test_which_ai_is_smartest_tomorrow_ai/",
          "publishedOn": "2023-09-12T12:55:54.000Z",
          "wordCount": 2755,
          "title": "Today we test which AI is smartest. Tomorrow AI tests which human is smartest.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16gng6t/china_ai_and_semiconductors_rise_us_sanctions/",
          "author": null,
          "description": "The US sanctions on China's AI and semiconductor industries have failed to limit their growth and development.\n \nChina is rapidly developing supercomputing capabilities and aims to become the world leader in AI by 2030.\n \nChinese companies like Huawei and SMIC continue to import advanced semiconductor manufacturing equipment and develop their own chips, indicating that the export controls have not been effective.\n \nThe article explores the trajectory of Chinese domestic semiconductor manufacturing and AI capabilities, as well as the potential impact on companies like Apple, Qualcomm, and MediaTek.\n \nIt also discusses the potential responses from the US and its allies to counter China's advancements.\n \n Source : https://www.semianalysis.com/p/china-ai-and-semiconductors-rise\n Summarized by Nuse AI\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16gng6t/china_ai_and_semiconductors_rise_us_sanctions/",
          "publishedOn": "2023-09-12T10:13:13.000Z",
          "wordCount": 2649,
          "title": "China AI and Semiconductors Rise: US Sanctions Have Failed",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16gm8bq/i_developed_a_free_chrome_extension_backed_by/",
          "author": null,
          "description": "You can install it from the Chrome web store.\n https://reddit.com/link/16gm8bq/video/yyhx45xjgsnb1/player\n ​\n    submitted by    /u/MiladMansory  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16gm8bq/i_developed_a_free_chrome_extension_backed_by/",
          "publishedOn": "2023-09-12T09:00:57.000Z",
          "wordCount": 2560,
          "title": "I developed a free Chrome extension, backed by ChatGPT, to identify Amazon product pros and cons from reviews, plus answer questions!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16gm4pw/just_did_a_basic_experiment_across_the_popular/",
          "author": null,
          "description": "Most of them failed. \n  \nSo this was my prompt:\n  \nWrite 5 sentences that all end with the word 'apple'.\n  \nIt was identical in all models. I only did this exactly once for each one. Here’s the results I got of how many of the 5 sentences ended in “apple”. I let “apples” count as an ending as well even though technically that is a fail. \n Google palm: 0/5\n Falcon 180B: 0/5\n Bard: 1/5\n Claude 2: 1/5\n Gpt 3.5: 2/5\n Llama2 70b: 4/5\n GPT 4: 5/5\n Edit: some examples if you’re curious \n https://ibb.co/yf19rpb\n https://ibb.co/rcF1qK8\n https://ibb.co/VCQxMwy\n    submitted by    /u/jgainit  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16gm4pw/just_did_a_basic_experiment_across_the_popular/",
          "publishedOn": "2023-09-12T08:54:47.000Z",
          "wordCount": 2644,
          "title": "Just did a basic experiment across the popular models: “ Write 5 sentences that all end with the word 'apple'.”",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16gjni4/nvidia_apple_have_got_a_real_ai_competitor_now/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16gjni4/nvidia_apple_have_got_a_real_ai_competitor_now/",
          "publishedOn": "2023-09-12T06:24:24.000Z",
          "wordCount": 2539,
          "title": "NVIDIA, Apple Have Got a Real AI Competitor Now",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16giub0/use_torchvision_detectors_to_track_objects_using/",
          "author": null,
          "description": "Although the torchvision library has contains datasets and model architectures for classification, detection, segmentation, and more, it still needs support for object tracking.\n This YouTube video takes object detection models from torchvision, and uses them with DeepSORT tracker.\n    submitted by    /u/spmallick  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16giub0/use_torchvision_detectors_to_track_objects_using/",
          "publishedOn": "2023-09-12T05:36:18.000Z",
          "wordCount": 2576,
          "title": "Use torchvision detectors to track objects using DeepSORT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16gibpv/microsoft_and_googles_staggering_water/",
          "author": null,
          "description": "AI, with its vast resource needs, is raising concerns over sustainability and environmental impact. Last year, Microsoft's data centers drained over 2,500 Olympic-sized swimming pools worth of water, reflecting a 34% increase from the previous year. Google also reported a 20% water consumption increase over the same period.\n To stay on top of the latest advancements in AI, look here first.\n https://preview.redd.it/npr6uja0crnb1.png?width=990&format=png&auto=webp&s=b775754b9d42a8129fff2cae675f63c3a291f7bc\n A deeper look at AI's water footprint\n  \nThe growth of AI and related technologies increases the need for vast server farms, which depend heavily on water for cooling purposes.\n The spike in water usage can be attributed primarily to AI, as per Shaolei Ren, a researcher at the UC, Riverside, who focuses on AI's environmental impact.\n For every 5 to 50 prompts submitted to ChatGPT, it consumes about 500 ml of water, according to an upcoming paper from Professor Ren's team.\n  \nBig Tech and Responsible Water Usage\n  \nRecognizing their significant water consumption, tech companies like Google have voiced concerns and are exploring ways to mitigate the negative effects.\n Google has committed to responsible water usage, which includes assessing where and how their water usage might affect surrounding areas.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that explores the latest AI developments. Professionals from Google, Meta, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16gibpv/microsoft_and_googles_staggering_water/",
          "publishedOn": "2023-09-12T05:06:43.000Z",
          "wordCount": 2758,
          "title": "Microsoft and Google's staggering water consumption rates for AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ghyh2/oneminute_daily_ai_news_9112023/",
          "author": null,
          "description": "Alibaba Adds Smart Assistant and Upgraded Image Search to B2B Platform.[1]\n Collina Strada has called on AI to help create its spring/summer 2024 collection, unveiled during New York Fashion Week.[2]\n LexisNexis is embracing generative AI to ease legal writing and research.[3]\n Snowflake CEO says people will soon not be able to remember a world without AI.[4]\n  \nSources:\n [1] https://www.pymnts.com/commercial-payments/2023/alibaba-adds-smart-assistant-and-upgraded-image-search-to-b2b-platform/\n [2] https://www.thenationalnews.com/lifestyle/fashion-beauty/2023/09/11/collina-strada-ai-new-york-fashion-week/\n [3] https://techcrunch.com/2023/09/10/lexisnexis-generative-ai/\n [4] https://www.cnbc.com/2023/09/11/snowflake-ceo-says-people-will-soon-not-remember-a-world-without-ai.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ghyh2/oneminute_daily_ai_news_9112023/",
          "publishedOn": "2023-09-12T04:46:21.000Z",
          "wordCount": 2600,
          "title": "One-Minute Daily AI News 9/11/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ge1hz/i_caught_my_ai_looking_up_adult_content/",
          "author": null,
          "description": "​\n https://preview.redd.it/l9jkupupaqnb1.jpg?width=1125&format=pjpg&auto=webp&s=ba52e00e32119d34958c480473bfa690484cd085\n ​\n https://preview.redd.it/w53cjsqqaqnb1.png?width=1125&format=png&auto=webp&s=f750ca0996b94fb530173a8a9c4a2a258e29517a\n    submitted by    /u/guh-eye  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ge1hz/i_caught_my_ai_looking_up_adult_content/",
          "publishedOn": "2023-09-12T01:37:10.000Z",
          "wordCount": 2539,
          "title": "I Caught My AI Looking up Adult Content!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16gab15/i_made_another_ai_game_the_future_of_npcs/",
          "author": null,
          "description": "Hello, fellow AI enthusiasts!\n After the positive response to Bargainer.ai, I got really excited about the potential of this technology in larger scale video games like World of Warcraft or GTA for example. \n I'm happy to announce that I'm now releasing - Convince the Bouncer!\n Chat with an AI Bouncer and try to gain entry to Elysium, the most elite night club. Don't worry; it's fairly easier than getting into Berghain.\n Give it a spin here: convincethebouncer.com\n P.S.: Get the VIP Pass from the Bouncer, and you might access an upcoming AI platform early! :)\n Questions or ideas? Let me know. Thanks a bunch!\n    submitted by    /u/gavo_gavo  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16gab15/i_made_another_ai_game_the_future_of_npcs/",
          "publishedOn": "2023-09-11T22:56:28.000Z",
          "wordCount": 2643,
          "title": "I made another AI game, the future of NPCs!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16g87c6/vote_bot/",
          "author": null,
          "description": "Any good recommendations for a vote bot to cast votes for a insignificant online poll? It’s a no security website. Just refresh and hit a vote button.\n    submitted by    /u/fa6664  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16g87c6/vote_bot/",
          "publishedOn": "2023-09-11T21:36:42.000Z",
          "wordCount": 2559,
          "title": "Vote bot",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16g703v/inside_tencent_hunyuan_ants_financial_llm_and/",
          "author": null,
          "description": "submitted by    /u/trcytony  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16g703v/inside_tencent_hunyuan_ants_financial_llm_and/",
          "publishedOn": "2023-09-11T20:53:39.000Z",
          "wordCount": 2552,
          "title": "🤖Inside Tencent Hunyuan, Ant's Financial LLM, and Zhipu AI's Rising Valuation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16g669t/we_polled_different_audiences_on_the_simulation/",
          "author": null,
          "description": "submitted by    /u/stefanbg92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16g669t/we_polled_different_audiences_on_the_simulation/",
          "publishedOn": "2023-09-11T20:23:39.000Z",
          "wordCount": 2550,
          "title": "We Polled Different Audiences on the Simulation Trilemma. Techies Favor Simulation (50-81%), Others Bet 0%. Are We Overestimating Simulation Probability, and Why?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16g3d96/best_current_longform_text_summarizers/",
          "author": null,
          "description": "I check every now and then. I use some good ones that can summarize a short YouTube video, or a brief-ish article. But I really want something that can chomp down a whole book and distill its essence without making \"summaries of summaries\", which tend to increase inaccuracy and errors. A good summary is concise and precise, and I want flexibility with bullet points and level of detail.\n Having issues with ChatGPT-based tools' token limits, and some that purport to support GPT4 (I could use that \"advanced reasoning\") but but have to fall back to GPT3 for various errors and reasons. So I'm open to Claude-based ones (may be too early, mo' tokens) and other proprietary engines.\n What is everyone using, including paid (rightfully so if they offer value for the money) services?\n    submitted by    /u/Torley_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16g3d96/best_current_longform_text_summarizers/",
          "publishedOn": "2023-09-11T18:40:47.000Z",
          "wordCount": 2668,
          "title": "Best current long-form text summarizers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16g0mhg/notes_app_doodles_to_images_for_architecture/",
          "author": null,
          "description": "submitted by    /u/Alternative_Lab_4441  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16g0mhg/notes_app_doodles_to_images_for_architecture/",
          "publishedOn": "2023-09-11T16:58:22.000Z",
          "wordCount": 2542,
          "title": "Notes app doodles to images for architecture design concept iterations using ControlNet and SDXL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16fz0bw/ai_will_take_over_the_world_meanwhile_the_ai/",
          "author": null,
          "description": "submitted by    /u/Bananas8ThePyjamas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16fz0bw/ai_will_take_over_the_world_meanwhile_the_ai/",
          "publishedOn": "2023-09-11T15:57:42.000Z",
          "wordCount": 2548,
          "title": "AI WILL TAKE OVER THE WORLD. Meanwhile the AI...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16fshcj/meta_is_reportedly_working_on_a_new_ai_model_to/",
          "author": null,
          "description": "Meta is working on a new AI model to rival GPT-4.\n \nThe company is acquiring AI training chips and building data centers to create a powerful chatbot.\n \nCEO Mark Zuckerberg wants it to be free for companies to create AI tools with.\n \nMeta is assembling a group to build the model and speed up the creation of AI tools that can emulate human expressions.\n \nThere are rumors of generative AI features and the launch of AI 'personas' this month.\n \n Source : theverge.com\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16fshcj/meta_is_reportedly_working_on_a_new_ai_model_to/",
          "publishedOn": "2023-09-11T11:08:35.000Z",
          "wordCount": 2624,
          "title": "Meta is reportedly working on a new AI model to rival GPT-4",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16fpjuj/if_ai_becomes_conscious_how_will_we_know/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16fpjuj/if_ai_becomes_conscious_how_will_we_know/",
          "publishedOn": "2023-09-11T08:09:35.000Z",
          "wordCount": 2552,
          "title": "If AI becomes conscious, how will we know? | \"Scientists and philosophers are proposing a checklist based on theories of human consciousness\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16fmlh7/help_me_in_finding_right_resources_to_understand/",
          "author": null,
          "description": "I’m a Business generalist who worked with multiple tech led businesses and looking to understand fundamentals of the technology from scratch. Please help me with any relevant courses/reading material/YT channels etc. that can help me kickstart the journey.\n P.S. I have a brief background with Business Analytics but haven’t done any coding extensive ever in my life.\n Thanks in Advance\n    submitted by    /u/Firm_Brother_7124  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16fmlh7/help_me_in_finding_right_resources_to_understand/",
          "publishedOn": "2023-09-11T05:09:03.000Z",
          "wordCount": 2606,
          "title": "Help me in finding right resources to understand the world of AI from a business perspective",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16fmc5p/oneminute_daily_ai_news_9102023/",
          "author": null,
          "description": "Chinese big tech Tencent has announced a medical large-scale model and unveiled a brand new matrix of AI products for various scenarios, including intelligent Q&A, a family doctor assistant, and a digital medical imaging platform. The drug discovery platform “Yunshen” (iDrug) has also revealed a new protein structure prediction algorithm framework called “tFold.”[1]\n Morgan Stanley is gearing up to implement an artificial intelligence-driven chatbot, a strategic move aimed at delivering valuable insights and administrative support to their team of financial advisors.[2]\n A fresh Russian AI bot has displayed larger potential than the most famous chatbot created by US-based OpenAI, IT giant Yandex alleged in remarks to RIA Novosti on Saturday.[3]\n Meta is developing a new, more powerful AI system, Wall Street Journal reports.[4]\n  \nSources:\n [1] https://drug.ai.tencent.com/en\n [2] https://voonze.com/morgan-stanley-introduces-ai-powered-chatbot-for-enhanced-services/\n [3] https://menafn.com/1107040379/Russian-AI-bot-shows-larger-potential-than-ChatGPT\n [4] https://www.reuters.com/technology/meta-is-developing-new-more-powerful-ai-system-wsj-2023-09-10/\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16fmc5p/oneminute_daily_ai_news_9102023/",
          "publishedOn": "2023-09-11T04:55:41.000Z",
          "wordCount": 2667,
          "title": "One-Minute Daily AI News 9/10/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16fgwvn/meta_plans_to_match_openais_gpt4_with_its_new_ai/",
          "author": null,
          "description": "Citing GPT-4 as the benchmark, Meta is reportedly gearing up to train a new, highly sophisticated AI model. The company is investing heavily in AI training chips and boosting its data centers to support the ambitious project.\n To stay on top of the latest advancements in AI, look here first.\n https://preview.redd.it/ts4a6reeuinb1.jpg?width=1440&format=pjpg&auto=webp&s=940be18b0c5f13e2762e1664a96274b314fe00df\n Meta’s vision for its new AI model\n  \nMeta's aim is to create a powerful chatbot in line with OpenAI’s GPT-4 capabilities.\n The company has reportedly been in pursuit of Nvidia H100 AI-training chips and is amplifying its infrastructure.\n The idea is to independently train its new model without outsourcing to platforms like Microsoft's Azure.\n  \nEfforts and roadblocks\n  \nMeta plans to begin the training of this LLM early in 2024, emphasizing free access for companies.\n Despite its grand vision, Meta has encountered obstacles like researcher attrition and contentious resource allocation amidst multiple LLM projects.\n Noteworthy is the intense competition from major players such as Apple, Google, and Amazon to integrate widely generative AI in their user interface.\n  \nBroader implications\n  \nWhile OpenAI has not immediately revealed plans for a GPT-5, other tech giants are investing heavily. Apple's investment in its \"Ajax\" AI model signifies the increasing race to advanced AI.\n This move by Meta represents the ongoing trend of tech conglomerates expanding in the AI space, a fact revealed through Google and Microsoft’s use of AI in their productivity tools and Amazon's ongoing developments.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that explores the latest AI developments. Professionals from Google, Meta, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16fgwvn/meta_plans_to_match_openais_gpt4_with_its_new_ai/",
          "publishedOn": "2023-09-11T00:34:26.000Z",
          "wordCount": 2803,
          "title": "Meta plans to match OpenAI's GPT-4 with its new AI model",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16fa2kv/what_are_some_of_your_favorite_ai_discoveries/",
          "author": null,
          "description": "I've been dabbling around with pi.ai and I love it and feel like it's only going to get better and better at what it does. I'm curious if there is any interesting new ai bots or discoveries that haven't yet made it mainstream but have tons of use in one way or another for the average consumer..\n Things like a language learning ai, or an ai that can read through a textbook or pdf and help you learn it's contents by practically interacting with it to help you comprehend better... there's so many interesting ai things I look forward to seeing\n    submitted by    /u/mikel0202  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16fa2kv/what_are_some_of_your_favorite_ai_discoveries/",
          "publishedOn": "2023-09-10T20:02:29.000Z",
          "wordCount": 2716,
          "title": "What are some of your favorite ai discoveries you've found? What do you think is possible and probable to come in the near future with ai to stay tuned for?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16f9i05/is_there_any_ai_tool_to_filter_5_star_ratings_and/",
          "author": null,
          "description": "I am tired of fake ratings and fake reviews in Google maps and I hạve been cheated many times by fake 5 star reviews. I am just looking to find the genuine overạll rating of a place by filtering out 5 star ratings because fake ratings are mostly 5 star and just finding the average of 1-4 ratings so that we can find the overall genuine rating of a Business.\n Is there any AI tool or any way or any application for that ? Need suggestions on this.\n    submitted by    /u/ramesh423  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16f9i05/is_there_any_ai_tool_to_filter_5_star_ratings_and/",
          "publishedOn": "2023-09-10T19:40:43.000Z",
          "wordCount": 2706,
          "title": "Is there any AI tool to filter 5 star ratings and just find the ạverage of 1 to 4 star rạtings in Google maps to find the genuine rating of a business ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16f078f/is_there_anyway_to_mix_two_faces_together_and/",
          "author": null,
          "description": "I'm interested to know if it's possible to mix two faces together, such as Tom Cruise and Brad Pitt, and create a brand new face from those two faces. \n    submitted by    /u/Glad-Ad-8953  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16f078f/is_there_anyway_to_mix_two_faces_together_and/",
          "publishedOn": "2023-09-10T13:23:12.000Z",
          "wordCount": 2575,
          "title": "Is there anyway to mix two faces together and generate a brand new face using AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ewqgr/ai_generated_video/",
          "author": null,
          "description": "Cyberpunk montage I made using Midjourney and RunwayML along with CapCut for the transitions, etc. \n Here’s some brief tutorial steps. \n  \nUse Midjourney to make pictures that you like. I would keep it to the default aspect ratio for best results. \n Use RunwayML to generate 4 second videos of the pics. \n Once you get some videos you like, save them and upload them to the CapCut app on your phone. \n  \n   submitted by    /u/Exitium_Maximus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ewqgr/ai_generated_video/",
          "publishedOn": "2023-09-10T10:19:21.000Z",
          "wordCount": 2614,
          "title": "AI generated video",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16evrpw/how_valuable_is_the_uks_ai_industry/",
          "author": null,
          "description": "The UK's AI industry is highly valuable, but its exact worth is difficult to determine.\n \nThe industry is growing rapidly and has the potential to contribute significantly to the country's economy.\n \nHowever, there are challenges in accurately measuring the value of the AI industry, as it encompasses a wide range of sectors and applications.\n \nSome estimates suggest that the UK's AI industry could be worth billions of pounds, with the potential to create thousands of jobs.\n \nInvestment in research and development, as well as the development of AI talent, are crucial for the growth of the industry.\n \n Source : https://www.ft.com/content/eeaa57a3-19ed-45d9-8705-2517c81e60ba\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16evrpw/how_valuable_is_the_uks_ai_industry/",
          "publishedOn": "2023-09-10T09:21:12.000Z",
          "wordCount": 2692,
          "title": "How valuable is the UK’s AI industry?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16etzxf/new_physicsbased_selflearning_machines_could/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16etzxf/new_physicsbased_selflearning_machines_could/",
          "publishedOn": "2023-09-10T07:33:08.000Z",
          "wordCount": 2615,
          "title": "New physics-based self-learning machines could replace current artificial neural networks and save energy | \"Neural networks on neuromorphic computers\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16erzt7/top_8_courses_certifications_on_ai_ethics/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16erzt7/top_8_courses_certifications_on_ai_ethics/",
          "publishedOn": "2023-09-10T05:38:28.000Z",
          "wordCount": 2538,
          "title": "Top 8 Courses & Certifications on AI Ethics",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16eofeh/the_accelerators_manifesto_accelerating_ai_and/",
          "author": null,
          "description": "submitted by    /u/JulioMedina  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16eofeh/the_accelerators_manifesto_accelerating_ai_and/",
          "publishedOn": "2023-09-10T02:33:46.000Z",
          "wordCount": 2605,
          "title": "The Accelerators Manifesto - Accelerating AI and our future",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16egn0t/ai_unleashed_this_weeks_top_15_news_and/",
          "author": null,
          "description": "\"AI Unleashed: This Week's Top 15 News and Breakthroughs in Artificial Intelligence\"\n 1\"X's Data Revolution: Your Biometrics and Career Fueling the AI of Tomorrow!\"\n In a recent privacy policy shake-up, X has just dropped a bombshell. They're not just interested in your regular data anymore; they're diving deep into the world of biometrics, job histories, and education backgrounds. And that's not all! Another corner of their revamped policy hints at a grand plan: they want to fuse this treasure trove of data with publicly available info to supercharge their machine learning and AI models.\n This isn't your run-of-the-mill update; it's a quantum leap for X in their quest to build the ultimate AI system. They're not just pushing boundaries; they're smashing through them. By expanding their da…",
          "link": "https://www.reddit.com/r/artificial/comments/16egn0t/ai_unleashed_this_weeks_top_15_news_and/",
          "publishedOn": "2023-09-09T21:00:40.000Z",
          "wordCount": 4860,
          "title": "\"AI Unleashed: This Week's Top 15 News and Breakthroughs in Artificial Intelligence\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ee30m/ai_technology_behind_chatgpt_built_was_in_iowa/",
          "author": null,
          "description": "The artificial intelligence technology behind ChatGPT was built in Iowa, specifically in the watershed of the Raccoon and Des Moines rivers.\n \nMicrosoft-backed OpenAI needed a lot of water to cool its powerful supercomputer as it taught its AI systems how to mimic human writing.\n \nLeading tech developers like Microsoft, OpenAI, and Google have acknowledged the high costs associated with the growing demand for AI tools, including expensive semiconductors and increased water consumption.\n \nMicrosoft disclosed a 34% spike in global water consumption, largely attributed to its AI research.\n \nA researcher estimates that ChatGPT uses 500 milliliters of water for every series of prompts or questions.\n \n Source : https://news.yahoo.com/artificial-intelligence-technology-behind-chatgpt-131421382.html\n Summarized by Nuse AI\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ee30m/ai_technology_behind_chatgpt_built_was_in_iowa/",
          "publishedOn": "2023-09-09T19:15:40.000Z",
          "wordCount": 2655,
          "title": "AI technology behind ChatGPT built was in Iowa – with a lot of water",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ea4we/teaching_llms_to_be_more_reasonable/",
          "author": null,
          "description": "Based on a bit of research and a lot of gut feeling, I offer the following speculation:\n  \nif you self-trained an LLM with a Python interpreter or Java compiler in a feedback loop where it learned from its own mistakes then it could become dramatically better at coding. It's actually a miracle that they are \"decent\" at coding despite getting virtually no feedback from an interpreter or compiler.\n one could train not merely on input and output, but also on an execution trace so the LLM learned HOW the interpreter got the result\n one could also train the model on how to install and invoke open source software and thus it would learn about a variety of languages, versions and runtimes\n this might also improve its logical reasoning skills in general\n  \nAdmittedly, running programs is a lot more expensive than doing simple next-word prediction on pre-existing texts.\n But on the other hand, a corpus of a million program executions can also be used to train future LLMs. You can keep the execution information forever and re-use it as traditional next-token prediction input.\n    submitted by    /u/Smallpaul  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ea4we/teaching_llms_to_be_more_reasonable/",
          "publishedOn": "2023-09-09T16:34:19.000Z",
          "wordCount": 2718,
          "title": "Teaching LLMs to be more reasonable",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16e9rng/article_as_a_writer_im_afraid_of_capitalism_not/",
          "author": null,
          "description": "submitted by    /u/LaVolpe223  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16e9rng/article_as_a_writer_im_afraid_of_capitalism_not/",
          "publishedOn": "2023-09-09T16:19:11.000Z",
          "wordCount": 2553,
          "title": "Article - \"As a writer, I’m afraid of capitalism — not ChatGPT.\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16e823n/100_free_and_unlimitedtexttovideo_ai_with/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16e823n/100_free_and_unlimitedtexttovideo_ai_with/",
          "publishedOn": "2023-09-09T15:08:16.000Z",
          "wordCount": 2537,
          "title": "100% Free and unlimited...text-to-video AI with optional image reference",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16e5gl5/i_made_a_free_tool_that_allows_you_to_create_a/",
          "author": null,
          "description": "submitted by    /u/PlayfulPhilosopher42  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16e5gl5/i_made_a_free_tool_that_allows_you_to_create_a/",
          "publishedOn": "2023-09-09T13:12:51.000Z",
          "wordCount": 2573,
          "title": "I made a free tool that allows you to create a personalized AI newsletter containing all of the content you already follow. The app will automatically pull in the top or latest posts from your selected sources so you don't miss anything important.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16e4j4n/llm_with_a_voice_interface/",
          "author": null,
          "description": "So LLM's like ChatGPT have been around for a while now, and have good APIs, and also voice to text dictation and text to voice generation are close to perfect these days... are there any services that join them all together?\n I'd like to chat with ChatGPT or similar by talking to my smart speaker a la Google Home, and have it respond by speaking, and to be able to reply and continue the conversation.\n Does anyone know if this exists yet?\n    submitted by    /u/singeblanc  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16e4j4n/llm_with_a_voice_interface/",
          "publishedOn": "2023-09-09T12:28:49.000Z",
          "wordCount": 2617,
          "title": "LLM with a voice interface?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16e3b5q/ai_subtitles/",
          "author": null,
          "description": "hey guys, im trying to subtitle a spanish video to have english subtitles, does anyone know a good way to do it for free?\n    submitted by    /u/deletemkw  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16e3b5q/ai_subtitles/",
          "publishedOn": "2023-09-09T11:24:45.000Z",
          "wordCount": 2556,
          "title": "AI subtitles?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16e2uz0/the_7_stages_of_ai_ai_uncovered/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16e2uz0/the_7_stages_of_ai_ai_uncovered/",
          "publishedOn": "2023-09-09T10:58:46.000Z",
          "wordCount": 2591,
          "title": "\"The 7 Stages of AI\" | AI Uncovered",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16e1vb6/in_ai_regulation_coverage_media_let_lawmakers_off/",
          "author": null,
          "description": "The media often portrays lawmakers as unable to regulate artificial intelligence (AI) due to its complexity and evolving nature.\n \nThis narrative overlooks the responsibility of lawmakers and their regulatory inertia.\n \nThe media frames AI regulation as a matter of technical knowledge rather than moral consideration.\n \nThe New York Times highlights the slow congressional response to new technologies and the potential influence of lawmakers' financial interests in AI companies.\n \nThe media fails to question why lawmakers, who have profited from AI, cannot apply their knowledge to regulate it.\n \nThis lack of critical information in news sources defends the inaction of lawmakers.\n \n Source : https://fair.org/home/in-ai-regulation-coverage-media-let-lawmakers-off-the-hook/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16e1vb6/in_ai_regulation_coverage_media_let_lawmakers_off/",
          "publishedOn": "2023-09-09T09:58:26.000Z",
          "wordCount": 2643,
          "title": "In AI Regulation Coverage, Media Let Lawmakers Off the Hook",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16e0c88/nvidia_tensorrtllm_supercharges_large_language/",
          "author": null,
          "description": "submitted by    /u/basitmakine  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16e0c88/nvidia_tensorrtllm_supercharges_large_language/",
          "publishedOn": "2023-09-09T08:23:02.000Z",
          "wordCount": 2552,
          "title": "NVIDIA TensorRT-LLM Supercharges Large Language Model Inference on NVIDIA H100 GPUs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16dwti0/oneminute_daily_ai_news_982023/",
          "author": null,
          "description": "TIME just picked a list of 100 Most Influential People in AI.[1]\n AI Startup Imbue Tops $1 Billion Valuation After Funding from Nvidia.[2]\n Microsoft offers legal protection for AI copyright infringement challenges.[3]\n US chipmaker Nvidia Corp. on Friday announced separate partnerships with Reliance and Tata group companies to help them develop AI-powered supercomputers, AI clouds and generative AI applications.[4]\n  \nSources:\n [1] https://time.com/6311323/how-we-chose-time100-ai/\n [2] https://www.bloomberg.com/news/articles/2023-09-07/ai-startup-imbue-tops-1-billion-valuation-after-funding-from-nvidia?embedded-checkout=true\n [3] https://arstechnica.com/information-technology/2023/09/microsoft-offers-legal-protection-for-ai-copyright-infringement-challenges/\n [4] https://www.livemint.com/companies/news/reliance-tata-cos-sign-ai-partnerships-with-nvidia-11694198851600.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16dwti0/oneminute_daily_ai_news_982023/",
          "publishedOn": "2023-09-09T04:59:46.000Z",
          "wordCount": 2600,
          "title": "One-Minute Daily AI News 9/8/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16dwkjw/rvc_queue_is_stuck_for_over_2_and_a_half_hours_now/",
          "author": null,
          "description": "Does anyone know what this means if when you import your audio clip and the model you want to use it gets stuck in the queue for over 2 and a half hours? I know that can't be right but I seemed to have followed all the guides correctly not sure what it could be :'( help greatly appreciated \n    submitted by    /u/StuntGuy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16dwkjw/rvc_queue_is_stuck_for_over_2_and_a_half_hours_now/",
          "publishedOn": "2023-09-09T04:46:58.000Z",
          "wordCount": 2656,
          "title": "RVC \"queue\" is stuck for over 2 and a half hours now?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16duj8z/chatgpt_hype_is_fading_traffic_drops_from_16_bn/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16duj8z/chatgpt_hype_is_fading_traffic_drops_from_16_bn/",
          "publishedOn": "2023-09-09T03:03:39.000Z",
          "wordCount": 2613,
          "title": "ChatGPT hype is fading ! Traffic drops from 1.6 bn to 1.4 bn users in 3 months",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16drwzl/paige_partners_with_microsoft_to_construct_worlds/",
          "author": null,
          "description": "Healthcare technology disruptor Paige is teaming up with Microsoft in the race against cancer. The collaboration aims to revolutionize cancer diagnosis and patient care by building the largest image-based artificial intelligence model for digital pathology and oncology.\n To stay one step ahead in AI transformations, subscribe here.\n Transforming cancer imaging\n  \nUsing Microsoft’s advanced supercomputing infrastructure, Paige aims to take cancer imaging to the next level. By combining its deep AI expertise with Microsoft’s enormous computing power, this model augments accuracy and brings in novel capabilities in cancer diagnostics.\n In the next phase, Paige will incorporate up to four million digitized microscopy slides from its petabyte-scale clinical data archive.\n  \nA milestone in oncology\n  \nThe Paige and Microsoft partnership is a game changer in advancing healthcare, equipping physicians with unprecedented insights into cancer pathology.\n Paige is the first company to receive FDA approval for a clinical AI application in digital pathology. The technology is set to increase diagnostic confidence, productivity, and expand treatment options for patients worldwide.\n  \n(source)\n P.S. If you love these analyses, I write a free newsletter to track the most significant news and research in AI and tech. Experts from Google, Meta, OpenAI, and more read it daily.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16drwzl/paige_partners_with_microsoft_to_construct_worlds/",
          "publishedOn": "2023-09-09T00:59:42.000Z",
          "wordCount": 2742,
          "title": "Paige partners with Microsoft to construct world's largest AI model for battling cancer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16dmxxn/instacart_boosts_ai_capacity_readies_for_ipo_with/",
          "author": null,
          "description": "On the verge of its IPO, Instacart has introduced major AI-powered features to its Storefront platform and the smart Caper Carts. Main upgrades: conversational search powered by OpenAI's ChatGPT and inbuilt AI models.\n To stay on top of the latest advancements in AI, look here first.\n https://preview.redd.it/olqtxvwjo3nb1.png?width=750&format=png&auto=webp&s=d8eaefbb9865c51732efc2792ec386610ecd38e6\n AI advancements in Instacart's infrastructure\n  \nInstacart, which holds approximately 22% of the $132 billion US online grocery-delivery market, has been leaning more towards being a tech platform.\n The new Instacart Storefront, entailing features driven by 150 proprietary AI models, is built on the same core infrastructure as the Instacart app.\n Customers can engage in open-ended searches on retailers' storefronts via the search bar.\n  \nAI upgrades in Caper Carts\n  \nAI-powered Caper Carts by Instacart have been upgraded. Customers can now order directly from their Caper Cart and get informed when their orders are ready.\n Camera and weight sensor efficiency is enhanced thanks to improved AI models, ensuring a smoother shopping journey and providing an extra layer of security against suspicious activity.\n  \n(source)\n P.S. If you want this kind of analysis, delve into the latest updates in AI with our free newsletter, already favored by professionals from Google, Meta, and OpenAI.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16dmxxn/instacart_boosts_ai_capacity_readies_for_ipo_with/",
          "publishedOn": "2023-09-08T21:33:08.000Z",
          "wordCount": 2737,
          "title": "Instacart boosts AI capacity, readies for IPO with OpenAI's ChatGPT-powered eCommerce search",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16dkmr3/ai_girlfriend_ads_are_flooding_instagram_and/",
          "author": null,
          "description": "Tech startups are running sexually explicit ads for apps promoting not-safe-for-work experiences on platforms like Facebook, Instagram, and TikTok.\n \nThese ads feature digitally created potential 'girlfriends' with large breasts and tight clothing, and some even use popular children's TV characters to promote 'NSFW pics' apps.\n \nNBC News found 35 app developers running sexually explicit ads on Meta-owned apps, and 14 app developers running similar ads on TikTok.\n \nThe marketing push is part of an AI gold rush, capitalizing on the surge of interest in AI and benefiting from a double standard that hurts real human sex workers.\n \nResearchers believe that the gender-based slant in these ads reflects social media platforms allowing sex-related ads only if the intended audience is men.\n \nMeta and TikTok have stepped up their removal of sexually explicit AI ads after NBC News contacted them, but questions remain about how the ads got through their filters in the first place.\n \nSimilar ads also appear in the Apple and Google app stores, although the extent of advertising there is unknown.\n \n Source : https://www.nbcnews.com/tech/social-media/ai-girlfriend-ads-instagram-tiktok-chat-pics-chatgpt-dose-rcna97547\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16dkmr3/ai_girlfriend_ads_are_flooding_instagram_and/",
          "publishedOn": "2023-09-08T20:05:13.000Z",
          "wordCount": 2713,
          "title": "AI girlfriend ads are flooding Instagram and TikTok",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16dfyun/ai_weekly_megathread/",
          "author": null,
          "description": "News provided by aibrews.com\n  \nTechnology Innovation Institute in Abu Dhabi has released Falcon 180B - a large language model with 180 billion parameters, trained on 3.5 trillion tokens. It's currently the largest openly available model, and rivals proprietary models like PaLM-2. Falcon 180B is 2.5 times larger than Llama 2 and was trained with 4x more compute. It is available for both research and commercial use [Details].\n Meta AI released Belebele, a first-of-its-kind multilingual reading comprehension dataset spanning 122 language variants, enabling direct comparison of how well models understand different languages [Details].\n Meta AI has published Code Llama’s research paper with more information on training, evaluation results and safety [Paper].\n Open Interpreter, an open-source, …",
          "link": "https://www.reddit.com/r/artificial/comments/16dfyun/ai_weekly_megathread/",
          "publishedOn": "2023-09-08T17:01:57.000Z",
          "wordCount": 3138,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16d8tmu/animating_a_2d_image_in_real_time/",
          "author": null,
          "description": "Hello Everyone,\n i have recently started working on a project, where I need to animate an image of a face in real time to speak sentences. Essentially I am trying to build a face for my own large language model. I know of Nvidia's Audio2Face and Metahuman, but these are all in 3D and take a lot of time rendering the lip and eye animations. I need something, which works only with a bit of latency.\n ​\n Does anyone know a service or a repo I could use to animate a 2D picture to speak text?\n    submitted by    /u/Fabianslife  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16d8tmu/animating_a_2d_image_in_real_time/",
          "publishedOn": "2023-09-08T12:07:07.000Z",
          "wordCount": 2632,
          "title": "Animating a 2D image in real time",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16d3q5z/free_ai_transforms_text_and_images_into_amazing/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16d3q5z/free_ai_transforms_text_and_images_into_amazing/",
          "publishedOn": "2023-09-08T07:19:50.000Z",
          "wordCount": 2595,
          "title": "Free AI transforms text and images into amazing videos - Pika Labs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16d3lxl/would_chatgpt_work_to_help_with_looking_for_wfh/",
          "author": null,
          "description": "This is a complete ChatGPT beginner question but has anyone ever downloaded it and used it to help with looking for specific job roles? Mainly WFH related? Or thought about changing careers and used ChatGPT to help with that? I know there are a lot of other ways to go about this but would ChatGPT help with this at all? \n    submitted by    /u/jackbowls  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16d3lxl/would_chatgpt_work_to_help_with_looking_for_wfh/",
          "publishedOn": "2023-09-08T07:13:47.000Z",
          "wordCount": 2601,
          "title": "Would ChatGPT work to help with looking for WFH jobs?/changing careers?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16d2668/do_you_feel_endangered_by_the_rise_of_ai/",
          "author": null,
          "description": "View Poll\n    submitted by    /u/MiladMansory  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16d2668/do_you_feel_endangered_by_the_rise_of_ai/",
          "publishedOn": "2023-09-08T05:52:46.000Z",
          "wordCount": 2599,
          "title": "Do you feel endangered by the rise of AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16d108k/ai_grading_and_ai_screening_but_no_ai_for/",
          "author": null,
          "description": "Professors send emails explaining that they use AI but they reviewed the grades from AI to make sure everything is fine. But students can’t use AI and then review the results just make sure everything is fine.\n    submitted by    /u/PrettyHappyAndGay  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16d108k/ai_grading_and_ai_screening_but_no_ai_for/",
          "publishedOn": "2023-09-08T04:47:53.000Z",
          "wordCount": 2577,
          "title": "AI grading and AI screening but no AI for homework/assignments/exam?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16d0x70/oneminute_daily_ai_news_872023/",
          "author": null,
          "description": "A new AI tool developed by startup Delphi allows users to create virtual clones of themselves or anyone else. Users can upload an ID and add various files, such as emails, chat transcripts, and videos, to generate an AI chatbot that mimics their personality.[1]\n OpenAI will host its first developer conference on November 6.[2]\n Meta Platforms Inc. today released FACET, a benchmark dataset designed to help researchers audit computer vision models for bias.[3]\n Australia to require AI-made child abuse material be removed from search results.[4]\n  \nSources:\n [1] https://technotrenz.com/news/a-new-ai-service-allows-for-the-creation-of-a-virtual-version-of-yourself-or-a-loved-one-that-is-capable-of-making-phone-calls-on-your-behalf-2772634.html\n [2] https://techcrunch.com/2023/09/06/openai-will-host-its-first-developer-conference-on-november-6/\n [3] https://siliconangle.com/2023/08/31/meta-releases-facet-dataset-evaluating-ai-fairness/\n [4] https://www.reuters.com/technology/australia-require-ai-made-child-abuse-material-be-removed-search-results-2023-09-08/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16d0x70/oneminute_daily_ai_news_872023/",
          "publishedOn": "2023-09-08T04:43:13.000Z",
          "wordCount": 2629,
          "title": "One-Minute Daily AI News 8/7/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16czvhb/agi_will_be_not_feasible_any_time_soon_heres_why/",
          "author": null,
          "description": "I was thinking today about all the AI hype we have right with somewhat a bunch of new breakthroughs each month, but things not only are getting slower updates, but the updates impacts itself are becoming lesser. If that is not enough, well we have big problems ahead, such as processors are reaching the physical limit, quantum effects disrupting the works, wafers becoming increasing more expensive, the size reduction is no longer adding the same boosts in power and new materials are just far from viable. \n On top of this we are going meet two other walls, the software and the energy. About the first, as we make better and more complex algorithms for computation the harder it gets to make better ones to squeeze more power and handle more complex tasks. The second, is becoming more real as bi…",
          "link": "https://www.reddit.com/r/artificial/comments/16czvhb/agi_will_be_not_feasible_any_time_soon_heres_why/",
          "publishedOn": "2023-09-08T03:49:19.000Z",
          "wordCount": 3549,
          "title": "AGI will be not feasible any time soon, here's why",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16cuxyw/anthropic_from_startup_to_ai_powerhouse_with/",
          "author": null,
          "description": "Anthropic, a startup composed of former OpenAI staff, has announced the release of its premium subscription plan, Claude Pro, for Claude 2, its AI-driven chatbot. The affordable subscription offers a plethora of features for users.\n To stay on top of the latest advancements in AI, look here first.\n Anthropic's Claude Pro: Cost and Features\n  \nPriced at $20 per month in the U.S. or £18 in the U.K., users will have access to \"5x more usage\" compared to the free tier of Claude 2.\n Subscribers can send unlimited messages, gain priority during high-traffic periods, and get early access to new enhancements.\n The new package is priced similarly to OpenAI’s paid plan for ChatGPT Plus, a direct rival to Claude 2.\n  \nRationale and User Value\n  \nSince its launch in July, users have praised Claude for…",
          "link": "https://www.reddit.com/r/artificial/comments/16cuxyw/anthropic_from_startup_to_ai_powerhouse_with/",
          "publishedOn": "2023-09-07T23:59:49.000Z",
          "wordCount": 2869,
          "title": "Anthropic: From startup to AI powerhouse with Claude Pro launch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16cuoo4/thought_experiment_the_reverse_deep_learning/",
          "author": null,
          "description": "submitted by    /u/nicdunz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16cuoo4/thought_experiment_the_reverse_deep_learning/",
          "publishedOn": "2023-09-07T23:49:45.000Z",
          "wordCount": 2592,
          "title": "Thought Experiment: “The Reverse Deep Learning Paradigm”",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ctnmc/be_my_ai_vs_bing_vs_bard/",
          "author": null,
          "description": "submitted by    /u/nicdunz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ctnmc/be_my_ai_vs_bing_vs_bard/",
          "publishedOn": "2023-09-07T23:07:05.000Z",
          "wordCount": 2535,
          "title": "be my ai vs bing vs bard",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16cs74q/who_is_missing_from_the_time_100_most_influential/",
          "author": null,
          "description": "Who do you think is not on this list but should be?\n https://time.com/collection/time100-ai/\n ​\n    submitted by    /u/smo279  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16cs74q/who_is_missing_from_the_time_100_most_influential/",
          "publishedOn": "2023-09-07T22:09:57.000Z",
          "wordCount": 2610,
          "title": "Who is missing from the TIME 100 most influential people in AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16cqgu7/what_technological_improvements_led_to_the/",
          "author": null,
          "description": "I have studied artificial intelligence about 15 years ago, and have left the field since. I am curious to learn what has been happening in the field after I've left. I know there's a lot of hype around generative AI like ChatGPT and Wall-E.\n I find it quite hard though to find out what's exactly the underlying technology breakthroughs that have allowed for these new applications. I mean, neural networks and similar machine learning techniques are already decades old.\n What technology led to the current AI boom? What would you say are the biggest conceptual improvements since? Or is it all just faster and bigger computers running 2000's tech?\n    submitted by    /u/math1985  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16cqgu7/what_technological_improvements_led_to_the/",
          "publishedOn": "2023-09-07T21:05:47.000Z",
          "wordCount": 2648,
          "title": "What technological improvements led to the current AI boom?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16cltpi/falcon_180ba_recordbreaking_open_source_llm_on/",
          "author": null,
          "description": "The AI community is buzzing with the arrival of Falcon 180B, an open-source LLM with an unprecedented 180 billion parameters. Developed by TII, This powerful model has surpassed key players like Meta's LLaMA 2 and matches commercial models like Google's PaLM-2.\n To stay on top of the latest advancements in AI, look here first.\n https://preview.redd.it/trscqxmncvmb1.jpg?width=480&format=pjpg&auto=webp&s=0590f4017937e70533414f93c72d9aa6edd62048\n Falcon 180B's Unrivaled Performance\n  \nThis advanced LLM is trained on an astounding 3.5 trillion tokens.\n Falcon 180B's parameters are 2.5 times larger than LLaMA 2's. It outperforms LLaMA 2 in scale and benchmark performance across diverse NLP tasks.\n On evaluations like the HellaSwag benchmark, it rivals commercial models like Google's PaLM-2.\n  \nPromising Future\n  \nTechniques like weight randomization and Nvidia’s Perfusion have helped train Falcon 180B more efficiently.\n Now freely available on Hugging Face, Falcon 180B is set to benefit from further enhancements by the community.\n The model's demonstration of advanced natural language abilities makes it a thrilling development in open-source AI.\n  \n(source) (demo)\n P.S. If you like this kind of analysis, I write a free newsletter that covers the most crucial news and studies in AI and tech. Professionals from Google, Meta, and OpenAI are already subscribed.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16cltpi/falcon_180ba_recordbreaking_open_source_llm_on/",
          "publishedOn": "2023-09-07T17:37:03.000Z",
          "wordCount": 2730,
          "title": "Falcon 180B—A Record-Breaking Open Source LLM on Hugging Face",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ck5yd/how_are_ai_services_today_when_it_comes_to_making/",
          "author": null,
          "description": "I'm looking at stuff that could be submitted to a Netflix or Crunchyroll.\n I'm looking at some of the ai generated content out there, in particular some of the Instagram tutorials and they look really good but none of these are serials like comics, graphic novels, OAVs or even webcomics.\n    submitted by    /u/KrusMatrieya  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ck5yd/how_are_ai_services_today_when_it_comes_to_making/",
          "publishedOn": "2023-09-07T16:24:18.000Z",
          "wordCount": 2649,
          "title": "How are AI services today when it comes to making content that requires distribution?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16cbiwx/intuit_cut_hundreds_of_jobs_and_spent_at_least_20/",
          "author": null,
          "description": "submitted by    /u/AminoOxi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16cbiwx/intuit_cut_hundreds_of_jobs_and_spent_at_least_20/",
          "publishedOn": "2023-09-07T09:42:45.000Z",
          "wordCount": 2622,
          "title": "Intuit cut hundreds of jobs and spent at least $20 billion in a massive bet on AI. Today the company is revealing its new virtual assistant",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16cajor/google_takes_on_ai_in_political_ads/",
          "author": null,
          "description": "Google is updating its policy to require advertisers to disclose when their election ads include digitally altered or generated content.\n \nThe update will go into effect in November, ahead of the 2024 presidential election.\n \nThe goal is to provide transparency and help voters make informed decisions.\n \nMinor alterations that are inconsequential to the claims are exempt from the disclosure requirements. \n \n Source : https://thehill.com/newsletters/technology/4190769-googles-campaign-ai-crackdown/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16cajor/google_takes_on_ai_in_political_ads/",
          "publishedOn": "2023-09-07T08:40:16.000Z",
          "wordCount": 2655,
          "title": "Google takes on AI in political ads",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16c8j4l/prepare_for_the_minefest_radical_changes/",
          "author": null,
          "description": "Ownership is just a story that we tell each other, a social construct. If people don’t agree on these stories, the concept loses its inherent power. This is true of owning land, money, cars, houses, art, mines, oil-wells, factories, corporations, relationships, loyalties, copyrights, brands, patents or anything else that is owned by you, me or those ever-superior “others”.\n In a society where change occurs gradually, we become accustomed to the narratives that bind us together and determine who possesses significant wealth, resources, attention, power, fame, and other ego-gratifying treasures, and who has access to only meager portions of these.\n However, when societies change and new types of goods appear, there might be no agreement about who gets to own these. For example, while the con…",
          "link": "https://www.reddit.com/r/artificial/comments/16c8j4l/prepare_for_the_minefest_radical_changes/",
          "publishedOn": "2023-09-07T06:35:01.000Z",
          "wordCount": 3135,
          "title": "Prepare for the Mine-Fest: Radical changes undermine all previous ownership assumptions and now everyone is shouting \"Mine\".",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16c6oll/oneminute_daily_ai_news_962023/",
          "author": null,
          "description": "The Consensus Search plugin allows users to find answers, search for papers, and draft pieces of content grounded in scientific research by searching our database of 200M+ papers directly within the ChatGPT interface.[1]\n Israel: AI Software Detects Bleeding Inside Brain During CT Scan; Helps Save Patient’s Life.[2]\n Chinese tech giant Tencent is launching its artificial intelligence model “Hunyuan” for business use at an annual summit on Thursday.[3]\n Google on Wednesday said it will mandate that political advertisements on its platforms disclose when images and audio have been altered or created using tools such as AI.[4]\n  \nSources:\n [1] https://consensus.app/home/blog/introducing-the-consensus-search-chatgpt-plugin/\n [2] https://english.jagran.com/technology/israel-ai-program-detects-bleeding-inside-brain-during-ct-scan-helps-save-patient-life-full-story-10098464\n [3] https://www.cnbc.com/2023/09/07/tencent-releases-ai-model-hunyuan-for-businesses-amid-china-competition.html\n [4] https://sg.news.yahoo.com/google-require-political-ads-disclose-010502103.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16c6oll/oneminute_daily_ai_news_962023/",
          "publishedOn": "2023-09-07T04:49:39.000Z",
          "wordCount": 2694,
          "title": "One-Minute Daily AI News 9/6/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16c6gcw/generative_ai_poised_to_replace_24_million_us/",
          "author": null,
          "description": "Forrester predicts that generative AI will replace 2.4 million US jobs by 2030, mostly white-collar roles, such as technical writers, proofreaders, copywriters, and administrative positions. But ironically, other forms of automation will displace more jobs.\n To stay on top of the latest advancements in AI, look here first.\n (Chart showing how much different types of jobs can expect to be influenced by technology)\n Concerns about Generative AI\n  \nWhile the Generative AI impact is significant, other forms of automation are set to cause more widespread job displacement.\n The most impacted group will be middle-class, college-educated, white-collar workers, specifically those earning above $60,000 annually.\n  \nCreative professionals stand to benefit\n  \nInterestingly, workers in creative industries will likely utilize generative AI tools in their jobs rather than being replaced. This includes editors, writers, authors, poets, and lyricists.\n However, the use of such tools as ChatGPT may result in inconsistent outputs and even \"coherent nonsense\", leading to potential performance issues.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that covers the most crucial news and studies in AI and tech. Professionals from Google, Meta, and OpenAI are already subscribed.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16c6gcw/generative_ai_poised_to_replace_24_million_us/",
          "publishedOn": "2023-09-07T04:37:04.000Z",
          "wordCount": 2786,
          "title": "Generative AI poised to replace 2.4 million US jobs by 2030",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16byffs/ai_in_2023_blessing_or_curse/",
          "author": null,
          "description": "View Poll\n    submitted by    /u/m-king473  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16byffs/ai_in_2023_blessing_or_curse/",
          "publishedOn": "2023-09-06T22:34:59.000Z",
          "wordCount": 2606,
          "title": "🤖 AI in 2023: Blessing or Curse? 🤖",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16by1by/cant_wait_for_the_zelda_3_movie_thanks_pika_labs/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16by1by/cant_wait_for_the_zelda_3_movie_thanks_pika_labs/",
          "publishedOn": "2023-09-06T22:20:01.000Z",
          "wordCount": 2576,
          "title": "Can't wait for the Zelda 3 movie,, thanks Pika Labs AI!!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16bxahr/ai_does_not_exist_but_it_will_ruin_everything/",
          "author": null,
          "description": "submitted by    /u/Hazzman  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16bxahr/ai_does_not_exist_but_it_will_ruin_everything/",
          "publishedOn": "2023-09-06T21:51:25.000Z",
          "wordCount": 2575,
          "title": "AI does not exist but it will ruin everything anyway",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16bvesn/im_not_sure_if_this_is_allowed_here_but_can/",
          "author": null,
          "description": "I think that would be pretty sick.\n    submitted by    /u/No_Understanding162  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16bvesn/im_not_sure_if_this_is_allowed_here_but_can/",
          "publishedOn": "2023-09-06T20:41:53.000Z",
          "wordCount": 2603,
          "title": "I’m not sure if this is allowed here, but can someone with a music AI make Vessel from Sleep Token sing As the World Caves In by Matt Maltese?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16btt10/is_it_too_early_to_leverage_ai_for_webassembly/",
          "author": null,
          "description": "AI and WebAssembly are seen as a perfect pairing, with the potential to accelerate the adoption of WebAssembly.\n \nFermyon believes that applying AI to WebAssembly is not premature and has developed a serverless platform that offers sub-second cold start times and high-volume time-slicing of compute instances.\n \nThis allows for faster startup times and efficient resource utilization.\n \nThe goal is to make AI easy for developers to leverage and build serverless apps.\n \n Source : https://thenewstack.io/is-it-too-early-to-leverage-ai-for-webassembly/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16btt10/is_it_too_early_to_leverage_ai_for_webassembly/",
          "publishedOn": "2023-09-06T19:42:04.000Z",
          "wordCount": 2650,
          "title": "Is It Too Early to Leverage AI for WebAssembly?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16btqlm/elon_musk_plans_to_merge_neuralink_and_tesla_for/",
          "author": null,
          "description": "Elon Musk reportedly plans to blend Neuralink and Tesla into a large AI company, using data from Twitter users and Tesla's Full Self-Driving Cameras to train a robust AI model.\n To stay on top of the latest advancements in AI, look here first.\n https://preview.redd.it/la78u2ebuomb1.jpg?width=1315&format=pjpg&auto=webp&s=4d8178f8fb94e45d6959e243b86c3bab3bce72ee\n Musk's AI Integration Plan\n  \nMusk is contemplating merging Neuralink and Tesla, alongside his xAI startup, to create a comprehensive artificial intelligence model.\n Leveraging the text data from Twitter and real-world images from Tesla's Full Self-Driving network, he intends to develop AI chatbots and physical robots capable of real-world navigation.\n  \nReasoning Behind the Merge\n  \nA concern that AI could potentially render humans obsolete led Musk to found xAI for AI safety.\n Musk is targeting to create an AI that can generate computer software and a politically unbiased chatbot rival to ChatGPT.\n  \nTwitter and Tesla as AI Datasets\n  \nDespite criticism, Musk's acquisition of Twitter offers access to vast user data for AI training.\n In addition, the Autopilot and Full-Self Driving systems of Tesla, with billions of collected camera images, serve as valuable resources to build physical robot AI.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that covers the most crucial news and studies in AI and tech. Professionals from Google, Meta, and OpenAI are already subscribed.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16btqlm/elon_musk_plans_to_merge_neuralink_and_tesla_for/",
          "publishedOn": "2023-09-06T19:39:31.000Z",
          "wordCount": 2793,
          "title": "Elon Musk Plans to Merge Neuralink and Tesla for an AI Supercompany",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16bl4e0/martian_lawyers_club_raises_22m_for_aibased_game/",
          "author": null,
          "description": "The Martian Lawyers Club (MLC) has raised $2.2 million in a pre-seed round to develop AI-based game personalization technology.\n \nUnlike other companies that focus on generating game assets, MLC is focused on the systems that form the core of a game.\n \nThe company aims to create games that feel like a conversation, where players provide input and the game responds in a way that wasn't pre-defined by the developer.\n \nMLC plans to provide an SDK that allows developers to design the game experience without having to create every interaction from scratch.\n \nDevelopers will have access to a sandbox experience where they can design the game, and the SDK will also have guardrails to ensure the generative AI system stays within boundaries.\n \nMLC is currently working on its first game, a collectible card game, to test out its SDK.\n \nThe company is the first spin-off from INSAIT, an AI-centric tech institute, and has received funding from Fly Ventures, System.One, and Amar Shah.\n \n Source : https://techcrunch.com/2023/08/31/martian-lawyers-club-raises-2-2m-for-ai-based-game-personalization-tech/\n    submitted by    /u/NuseAI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16bl4e0/martian_lawyers_club_raises_22m_for_aibased_game/",
          "publishedOn": "2023-09-06T14:02:02.000Z",
          "wordCount": 2741,
          "title": "Martian Lawyers Club raises $2.2M for AI-based game personalization tech",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16bjyli/if_you_cant_beatem_joinem_how_do_i_learn_to_code/",
          "author": null,
          "description": "I called it 6 years ago that by 2028 my tech job would be done by AI. We are right on track for my prediction. A short while ago I was laid off for reasons unrelated to AI. The way I see it, this is an excellent opportunity to make a career pivot. I have an intermediate understanding of JavaScript, React, Node and Linux. I have a good understanding of other technologies and languages too but specialize in web-dev. not saying web-dev will be done by AI but my very specialized niche will be gone way before I am ready to retire.\n  \n Can anyone recommend any good online courses? If you could even recommend a good article or two? I really don't know where to start. There are so many different buzz words floating around right now and it feels like it would be easy to waste a bunch of time learning AI related stuff that is outdated or leading to a deadend.\n    submitted by    /u/PutsOnOil  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16bjyli/if_you_cant_beatem_joinem_how_do_i_learn_to_code/",
          "publishedOn": "2023-09-06T13:12:15.000Z",
          "wordCount": 2743,
          "title": "If you can't beat'em, join'em. How do I learn to code for AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16bepyx/ai_voice_clone/",
          "author": null,
          "description": "guys can i know where to get free AI voice clone ?\n    submitted by    /u/DonnieCuteMwone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16bepyx/ai_voice_clone/",
          "publishedOn": "2023-09-06T08:33:12.000Z",
          "wordCount": 2582,
          "title": "AI voice clone",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16bepyt/ai_voice_clone/",
          "author": null,
          "description": "guys can i know where to get free AI voice clone ?\n    submitted by    /u/DonnieCuteMwone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16bepyt/ai_voice_clone/",
          "publishedOn": "2023-09-06T08:33:11.000Z",
          "wordCount": 2582,
          "title": "AI voice clone",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16bepyn/ai_voice_clone/",
          "author": null,
          "description": "guys can i know where to get free AI voice clone ?\n    submitted by    /u/DonnieCuteMwone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16bepyn/ai_voice_clone/",
          "publishedOn": "2023-09-06T08:33:11.000Z",
          "wordCount": 2582,
          "title": "AI voice clone",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16bbrni/gitlab_survey_reveals_increasing_reliance_on_ai/",
          "author": null,
          "description": "A recent survey by GitLab reveals a growing trend among organizations implementing AI in their software development processes, deeming it essential to stay competitive.\n To stay on top of the latest advancements in AI, look here first.\n GitLab Survey\n AI becomes crucial for software development\n  \nGitLab's report reveals that most respondents (83%) consider AI essential for their software development, regardless of their position, job level, or years of experience.\n Most organizations have deemed AI adoption successful, with 90% stating confidence in using AI tools daily.\n  \nAreas of AI application and concerns about its integration\n  \nAI's application in software development extends beyond simply generating codes, focusing more on natural language chatbots, automated test generation, and tracking machine learning model experiments.\n However, despite the growing adoption, concerns about AI-generated codes lacking copyright protection (48%) and potentially introducing vulnerabilities (39%) are rising.\n The rising fear of AI replacing existing roles is evident, with 57% predicting that their jobs might be threatened within five years.\n  \nThe need for training and the real-world implications of AI integration\n  \nAs AI permeates workplaces, nearly 81% believe they require more training.\n Interestingly, those with more AI experience were less likely to link it with productivity gains and faster cycle times, highlighting the importance of human verification in AI-generated codes for ensuring error-free, secure, and copyright-compliant production.\n  \n(source)\n P.S. If you like this kind of analysis, you’ll love my free newsletter, which covers the latest advancements in AI. Professionals from Google, Meta, and OpenAI are already on board.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16bbrni/gitlab_survey_reveals_increasing_reliance_on_ai/",
          "publishedOn": "2023-09-06T05:35:16.000Z",
          "wordCount": 2826,
          "title": "GitLab survey reveals increasing reliance on AI in software development",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16baptc/oneminute_daily_ai_news_952023/",
          "author": null,
          "description": "OpenAI introduces Canva plugin for ChatGPT, simplifying design process.[1]\n A new technique called RLAIF (Reinforcement Learning from AI Feedback) enables training reinforcement learning (RL) models without relying on human-labelled training data, according to a paper from researchers at Google.[2]\n Harvard bro sparks immediate backlash with new ‘SmashOrPassAI’ site, where users rate AI-generated women.[3]\n X’s privacy policy confirms it will use public data to train AI models.[4]\n  \nSources:\n [1] https://nextbigwhat.com/openai-introduces-canva-plugin-for-chatgpt-simplifying-design-process/\n [2] https://medium.datadriveninvestor.com/rlaif-scaling-reinforcement-learning-from-human-feedback-with-ai-feedback-aae57b7c36a9\n [3] https://www.dailydot.com/debug/smashorpassai-backlash/\n [4] https://techcrunch.com/2023/09/01/xs-privacy-policy-confirms-it-will-use-public-data-to-train-ai-models/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16baptc/oneminute_daily_ai_news_952023/",
          "publishedOn": "2023-09-06T04:38:53.000Z",
          "wordCount": 2647,
          "title": "One-Minute Daily AI News 9/5/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16b8urk/we_created_a_word_android_app_game_with_the_help/",
          "author": null,
          "description": "submitted by    /u/dupelas  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16b8urk/we_created_a_word_android_app_game_with_the_help/",
          "publishedOn": "2023-09-06T03:04:11.000Z",
          "wordCount": 2624,
          "title": "We created a word android app game with the help of ChatGPT. ChatGPT provided us massive list of words with translation. And now our game is packed with 15 different languages. (English, Germany, France, Spanish, Netherlands, Italian, Portuguese, Swedish, Danish, Czech, Polish, Hungarian, etc .. )",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16b8g5q/no_wayi_can_make_my_own_ai_scifi_movie_now/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16b8g5q/no_wayi_can_make_my_own_ai_scifi_movie_now/",
          "publishedOn": "2023-09-06T02:44:57.000Z",
          "wordCount": 2579,
          "title": "NO WAY...I CAN MAKE MY OWN AI SCI-FI MOVIE NOW WOW...PIKA LABS SHIT WOW",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16b82w7/yo_yo_yo_my_ppl_this_is_cool_free_ai_discord/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16b82w7/yo_yo_yo_my_ppl_this_is_cool_free_ai_discord/",
          "publishedOn": "2023-09-06T02:27:41.000Z",
          "wordCount": 2580,
          "title": "YO YO YO MY PPL, THIS IS COOL. (Free AI Discord stuff, by Pika Labs)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16b4kzd/assume_you_have_to_place_100_bet_on_one_of_3_nick/",
          "author": null,
          "description": "Odds are same for each option 1/3. I believe results will be really interesting observation .\n ​\n View Poll\n    submitted by    /u/stefanbg92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16b4kzd/assume_you_have_to_place_100_bet_on_one_of_3_nick/",
          "publishedOn": "2023-09-05T23:53:37.000Z",
          "wordCount": 2652,
          "title": "Assume You Have To Place $100 Bet On One of 3 Nick Bostrom Simulation Theory Scenarios: Which Scenario Would You Bet On?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16b4beb/new_aigenerated_covid_drug_enters_phase_i/",
          "author": null,
          "description": "Insilico Medicine, an AI-driven biotech company, has announced its AI-designed COVID-19 drug is entering Phase I clinical trials. Promising to deliver lasting results against all variants, this could become the first viable alternative to Paxlovid.\n To stay on top of such cutting-edge advancements in AI, look here first.\n Insilico's breakthrough medicine, ISM3312\n  \nGenerated using Artificial Intelligence, ISM3312 may offer the superior solution to the constraints of current oral medication, Paxlovid.\n Insilico’s new drug could address the limitations of Paxlovid, including unpleasant side effects and drug resistance due to constant COVID mutation.\n Preclinical studies reveal the drug’s potential in reducing the viral load in lung tissue and mitigating lung inflammation.\n  \nDevelopment powered by AI\n  \nIdentified via AI-driven platform PandaOmics, the drug effectively targets crucial proteins in the coronavirus.\n Using Chemistry42, a generative chemistry platform, Insilico generated new molecules built to suppress this protein, creating ISM3312.\n Given the success, the company patented ISM3312, which is currently undergoing Phase I Clinical trials, with results expected by end 2023.\n  \nThe Implications\n  \nDr. Harvey Castro, an emergency medicine physician, encourages doctors to remain cautious but also recognizes the promise of AI-generated drugs like ISM3312.\n With the trials in progress, the medical community is closely monitoring it as it could redefine the treatment course for COVID and other similar viruses.\n Insilico's venture exhibits AI's potential in accelerating effective drug discovery, prompting the need for consistent tracking of AI's transformation of healthcare and other fields.\n  \n(source)\n P.S. If you like this kind of analysis, I compile a free newsletter that tracks the most relevant news and research in AI. Professionals from Google, Meta, and Insilico Medicine are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16b4beb/new_aigenerated_covid_drug_enters_phase_i/",
          "publishedOn": "2023-09-05T23:42:34.000Z",
          "wordCount": 2854,
          "title": "New AI-generated COVID drug enters Phase I clinical trials: Claims to be effective against all variants",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16asfro/are_you_an_ai_beginner_or_ai_professional/",
          "author": null,
          "description": "submitted by    /u/MarkFulton  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16asfro/are_you_an_ai_beginner_or_ai_professional/",
          "publishedOn": "2023-09-05T16:13:14.000Z",
          "wordCount": 2582,
          "title": "Are you an AI beginner or AI professional?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ap10h/what_openai_really_wants/",
          "author": null,
          "description": "submitted by    /u/Alone-Competition-77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ap10h/what_openai_really_wants/",
          "publishedOn": "2023-09-05T13:58:27.000Z",
          "wordCount": 2580,
          "title": "What OpenAI Really Wants",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16akvik/what_are_some_good_open_source_projects_exploring/",
          "author": null,
          "description": "There are tons of TTS software out there, but they don't incorporate human emotions during speech synthesis. For example, anger, tiredness, surprise, happiness...\n What solutions exist for this today?\n    submitted by    /u/ICWiener6666  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16akvik/what_are_some_good_open_source_projects_exploring/",
          "publishedOn": "2023-09-05T10:48:26.000Z",
          "wordCount": 2605,
          "title": "What are some good open source projects exploring emotional voice synthesis?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ag4d9/thoughts_for_my_disgruntled_artist_friends/",
          "author": null,
          "description": "Learning a skill, for me, was never about securing knowledge that privileged me over everyone else who did not put the work in. While often, it did feel like drinking Kool-Aid, buying in to these groups like yoga and climbing, I knew I was not there to rub elbows, but to discover the how behind it. Some leaders of some groups did create a barrier of entry, a necessary proving point, but I have always seen these loops to jump through as a challenge - once completed - a spy. Every skill you have learned has prepared you not to be better at that skill, but to learn a new skill with more ease. It is uncomfortable to learn something new, like drinking from a fire hydrant, but the more sips you take from that blasting surge of water, the more you realize it is all part of the process. We get blasted, we sip, we get overwhelmed, we come back. Just because there is a tool that regulates the blasting, that holds our hand through the overwhelm, does not mean all our hard work has been for nothing. In fact, it means we are more prepared, more primed, to receive all of the beauty and knowledge coming our way. Now, friends, we become CURATORS. :) xo\n    submitted by    /u/airkaty  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ag4d9/thoughts_for_my_disgruntled_artist_friends/",
          "publishedOn": "2023-09-05T06:12:19.000Z",
          "wordCount": 2788,
          "title": "Thoughts for my disgruntled artist friends:",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16ad50f/tesla_diesel_truck_commercial_ai/",
          "author": null,
          "description": "submitted by    /u/wisconsin-sopapa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16ad50f/tesla_diesel_truck_commercial_ai/",
          "publishedOn": "2023-09-05T03:35:22.000Z",
          "wordCount": 2568,
          "title": "Tesla Diesel Truck Commercial (AI)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16a7x0n/ai_is_a_looming_damnation/",
          "author": null,
          "description": "submitted by    /u/Powerful-Pumpkin-938  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16a7x0n/ai_is_a_looming_damnation/",
          "publishedOn": "2023-09-04T23:36:43.000Z",
          "wordCount": 2575,
          "title": "AI is a Looming Damnation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16a7uga/natural_language_processing_question/",
          "author": null,
          "description": "Hello, I am learning about natural language processing now. Technically, is this a way for a computer to input language of a person and then convert it into machine code (0s and 1s)? Or, is this a way to turn human language into some computer language like Python, and then turn into machine code as a second step?\n I am assuming that NLP has only just recently become widely used (like in Chat GPT). Was it a huge jump to go from a machine understanding a computer programming language like Python to a machine understanding ordinary human language? Why was it so much more difficult to train computers to understand the later?\n Thanks!\n    submitted by    /u/NoahsArkJP  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16a7uga/natural_language_processing_question/",
          "publishedOn": "2023-09-04T23:33:42.000Z",
          "wordCount": 2676,
          "title": "Natural Language Processing Question",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/169w262/can_someone_tell_me_where_i_can_get_runway_gen2/",
          "author": null,
          "description": "Title\n    submitted by    /u/ICWiener6666  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/169w262/can_someone_tell_me_where_i_can_get_runway_gen2/",
          "publishedOn": "2023-09-04T16:08:57.000Z",
          "wordCount": 2577,
          "title": "Can someone tell me where I can get Runway Gen-2 code? I tried Github but found nothing",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/169to5f/help_with_finding_a_tool_for_3d_image_effects/",
          "author": null,
          "description": "Hello all -\n I'm looking to track down a tool that was able to create a zoom effect that looks three dimensional, example below.\n https://www.instagram.com/reel/CwLB1XsNK0X/?igshid=MmU2YjMzNjRlOQ==\n I've searched my usual spots for some different image editing tools and looked at some video ones as well, but I can't quite figure it out. Anyone familiar with a tool that could do something like that?\n Thanks in advance.\n    submitted by    /u/Lys0L  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/169to5f/help_with_finding_a_tool_for_3d_image_effects/",
          "publishedOn": "2023-09-04T14:36:33.000Z",
          "wordCount": 2633,
          "title": "Help with finding a tool for 3d image effects.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/169rhds/is_this_company_legit_any_more_info_on_the_early/",
          "author": null,
          "description": "Sounds like the stuff I somgwrite about\n    submitted by    /u/Niu_Davinci  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/169rhds/is_this_company_legit_any_more_info_on_the_early/",
          "publishedOn": "2023-09-04T13:04:58.000Z",
          "wordCount": 2583,
          "title": "Is this company Legit? Any more info on the early access release of this AI?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/169kcky/can_ai_writing_boost_your_mood_and_mind_my/",
          "author": null,
          "description": "Have you ever wondered if AI writing can make you feel better in your head? I would like to discuss about how AI writing can put a smile on your face as it is my personal experience.\n 1. Stress-Free Writing\n Writing can be stressful, especially when you're not sure where to start. AI writing tools can be your stress-busters. They help you begin by giving you ideas and suggestions. So, no more staring at a blank screen in frustration!\n 2. Beating the Writer's Blues\n We all know that feeling when words just won't flow. AI can be your brainstorm buddy. It tosses out ideas like confetti at a party, sparking your creativity when you need it most. Goodbye, writer's block!\n 3. Making Your Writing Shine\n Typos and messy sentences can be a downer. AI can be your proofreader, catching those pesky er…",
          "link": "https://www.reddit.com/r/artificial/comments/169kcky/can_ai_writing_boost_your_mood_and_mind_my/",
          "publishedOn": "2023-09-04T06:33:08.000Z",
          "wordCount": 3139,
          "title": "Can AI Writing Boost Your Mood and Mind? My Personal experience.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/169hsga/oneminute_daily_ai_news_932023/",
          "author": null,
          "description": "Amazon India is developing a generative artificial intelligence (AI) tool called SahAI (help/assist) for its business partners to help them with the backend of any particular product.[1]\n A robot moves a toy package of butter around a table in the Intelligent Robotics and Vision Lab at The University of Texas at Dallas. With every push, the robot is learning to recognize the object through a new system developed by a team of UT Dallas computer scientists.[2] “What is my purpose?” – “You pass butter”.\n Mustafa Suleyman, Google DeepMind’s co-founder and chief executive of Inflection AI, told the Financial Times that the US should use their chip leadership to enforce minimum global standards for the use of AI.[3]\n Model who never ages: Noonoouri becomes first digital artist to be signed by Warner Music.[4]\n  \nSources:\n [1] https://www.thehindu.com/sci-tech/technology/amazon-working-on-a-generative-ai-to-help-small-businesses-in-india/article67255325.ece\n [2] https://www.nanowerk.com/news2/robotics/newsid=63572.php\n [3] https://www.finextra.com/newsarticle/42878/google-deepmind-co-founder-argues-us-should-set-ai-global-standards---ft\n [4] https://www.thenationalnews.com/arts-culture/music-stage/2023/09/02/model-who-never-ages-noonoouri-becomes-first-digital-artist-to-be-signed-by-warner-music/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/169hsga/oneminute_daily_ai_news_932023/",
          "publishedOn": "2023-09-04T04:17:31.000Z",
          "wordCount": 2705,
          "title": "One-Minute Daily AI News 9/3/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/169fh2j/an_audiobook_entirely_created_from_ai/",
          "author": null,
          "description": "This story, it's narrator and even the cover art are all made by Artificial Intelligence. The only human contribution was adding the Text to the book cover and the prompts used to produce the story. \n https://youtu.be/tZgq9N9RCo0 \n    submitted by    /u/BermaidMutter  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/169fh2j/an_audiobook_entirely_created_from_ai/",
          "publishedOn": "2023-09-04T02:21:35.000Z",
          "wordCount": 2601,
          "title": "An audiobook entirely created from A.I.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/169elgu/aigenerated_voice_deepfakes_pose_new_threat_to/",
          "author": null,
          "description": "Scammers are now using AI to create realistic voice deepfakes, aiming to trick people into transferring money. By mimicking real customer voices, this new type of voice fraud attempts to exploit bank security systems and deceive call center agents.\n To make sure you're updated about the latest AI trends, look here first.\n Increasing prevalence and sophistication of voice frauds\n  \nA rise in AI-generated voice frauds has been noted this year, with one major case featuring an investor in Florida whose voice was synthetically duplicated to deceive his bank.\n Voice authentication vendor Nuance detected its first successful deepfake attack on a financial services client late last year.\n These scams are facilitated by the wide availability of voice samples online, coupled with the growth of AI capabilities and hackers' access to stolen bank account details.\n  \nDefending against evolving AI threats\n  \nCurrently, only a small percentage of fraud calls to large financial companies are AI-generated. Most attacks have targeted credit card service call centers.\n Fraudsters are advancing their techniques, now able to convert speech to a specific target's voice in real-time using advanced AI systems like Microsoft's VALL-E.\n With most of these security measures focusing on call centers and automated systems, individual calls to high-ranking officials remain a vulnerability.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that keeps you updated with the most relevant news and research in AI. Join professionals from Google, Meta, and OpenAI who are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/169elgu/aigenerated_voice_deepfakes_pose_new_threat_to/",
          "publishedOn": "2023-09-04T01:39:35.000Z",
          "wordCount": 2813,
          "title": "AI-Generated Voice Deepfakes Pose New Threat to Bank Security",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1698fv4/metas_dinov2_and_facet_sets_the_bar_in_computer/",
          "author": null,
          "description": "Meta has recently unveiled DINOv2, its cutting-edge computer vision model, and FACET, a comprehensive benchmark to ensure AI fairness. These developments promise improved automation and better inclusivity in the AI sector.\n If you want to stay on top of the latest trends and insights in AI, look here first.\n https://i.redd.it/zg47br3xv3mb1.gif\n DINOv2 for advanced visual tasks\n  \nMeta has made the powerful DINOv2 model available under the Apache 2.0 license, employing self-supervised learning to enhance image segmentation and depth estimation.\n This broader use model encourages further innovation and practical application in the computer vision community, driving progress in the AI industry.\n  \nFACET for enhanced AI fairness\n  \nGiven the inherent difficulty and risks in ensuring fairness in computer vision, Meta introduced FACET.\n FACET has been developed to benchmark fairness across computer vision models performing tasks such as detection or classification, considering a wide array of demographic attributes.\n This revolutionary tool enables a better understanding of potential biases in AI models, helping to address fairness and robustness concerns.\n  \nWider implications\n  \nPreliminary studies indicate performance disparities across some demographic groups within computer vision models. FACET allows researchers to track these divergences and monitor the implementation of corrective measures.\n Meta actively encourages researchers to use FACET for fairness benchmarking in other visual/multimodal tasks. For instance, the DINOv2 model's performance was analyzed with FACET — facilitating insights into potential biases.\n  \n(source)\n P.S. If you like such analysis, I write a free newsletter tracking significant news and research in AI. Professionals from Google, Meta, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1698fv4/metas_dinov2_and_facet_sets_the_bar_in_computer/",
          "publishedOn": "2023-09-03T21:10:22.000Z",
          "wordCount": 2822,
          "title": "Meta's DINOv2 and FACET sets the bar in computer vision model fairness",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/168uwe3/fluid_modelscope_image2video/",
          "author": null,
          "description": "submitted by    /u/glenniszen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/168uwe3/fluid_modelscope_image2video/",
          "publishedOn": "2023-09-03T11:45:45.000Z",
          "wordCount": 2561,
          "title": "'Fluid' - (Modelscope image2video)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/168q2j1/whatthis_is_insane/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/168q2j1/whatthis_is_insane/",
          "publishedOn": "2023-09-03T07:00:21.000Z",
          "wordCount": 2560,
          "title": "What....this is insane...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/168pwes/im_literally_speachless_8o/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/168pwes/im_literally_speachless_8o/",
          "publishedOn": "2023-09-03T06:50:13.000Z",
          "wordCount": 2561,
          "title": "I'm literally speachless.. 8O",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/168orwd/after_getting_banned_in_schools_openai_launches/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/168orwd/after_getting_banned_in_schools_openai_launches/",
          "publishedOn": "2023-09-03T05:44:36.000Z",
          "wordCount": 2570,
          "title": "After Getting Banned in Schools, OpenAI Launches ChatGPT Tool for Teachers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/168o3jl/retro_scifi_trailer_made_with_ai/",
          "author": null,
          "description": "submitted by    /u/filmcrux  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/168o3jl/retro_scifi_trailer_made_with_ai/",
          "publishedOn": "2023-09-03T05:05:49.000Z",
          "wordCount": 2563,
          "title": "Retro sci-fi trailer made with AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/168n62l/oneminute_daily_ai_news_922023/",
          "author": null,
          "description": "SAG-AFTRA, the union for US actors, is moving towards a potential strike against video game publishers, it’s announced.[1]\n Russia builds MSU-270 supercomputer for AI and HPC research.[2]\n Chuck Schumer has announced that his office will be meeting with top players in the artificial intelligence field later this month. Invited to the upcoming summit are tech megabillionaire Elon Musk, his one-time hypothetical sparring partner Meta CEO Mark Zuckerberg, OpenAI CEO Sam Altman, Google CEO Sundar Pichai, NVIDIA President Jensen Huang, and Alex Karpy, CEO of defense contractor creep Palantir.[3]\n Google expands AI compute offerings, partnership with Nvidia and more.[4]\n  \nSources:\n [1] https://www.videogameschronicle.com/news/actors-union-sag-aftra-could-launch-video-game-strikes-over-wages-and-ai/\n [2] https://www.tomshardware.com/news/russian-400-petaflops-supercomputer-for-ai-comes-online\n [3] https://gizmodo.com/chuck-schumer-elon-musk-mark-zuckerberg-palantir-nvidia-1850788302\n [4] https://www.itworldcanada.com/article/google-expands-ai-compute-offerings-partnership-with-nvidia-and-more/545625\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/168n62l/oneminute_daily_ai_news_922023/",
          "publishedOn": "2023-09-03T04:15:14.000Z",
          "wordCount": 2671,
          "title": "One-Minute Daily AI News 9/2/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/168iagw/the_puzzle_created_by_gpt4_that_even_gpt4_cant/",
          "author": null,
          "description": "submitted by    /u/stefanbg92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/168iagw/the_puzzle_created_by_gpt4_that_even_gpt4_cant/",
          "publishedOn": "2023-09-03T00:11:32.000Z",
          "wordCount": 2573,
          "title": "The Puzzle Created by GPT-4 That Even GPT-4 Can't Solve, Yet Humans Did! First Challenge Revealed.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1688xab/elon_musks_x_to_leverage_public_data_for_ai_model/",
          "author": null,
          "description": "Elon Musk's X revealed its plans to utilize user data and publicly available information in training AI models. Despite Musk's assurance that only public data will be used, concerns around privacy linger.\n For expert insights into AI developments, look here first.\n https://preview.redd.it/mj64uof9rvlb1.png?width=2000&format=png&auto=webp&s=a856ce3e4b6063ebf7a585df3338142defba6323\n X's approach to AI training\n  \nUnder the most recent privacy policy, X will harness the personal data it collects and publicly accessible information for its machine learning algorithms.\n Musk assures only publicly accessible data will be used, safeguarding private user information like DMs.\n However, with X having disbanded its press operation, more specific details about the data collected and its intended use still need to be provided.\n  \nUnfolding plans of Musk\n  \nDespite X's quiet stance on AI, Musk recently launched xAI, aspiring \"to understand the true nature of the universe.\"\n xAI's homepage discloses plans to sync with X closely, possibly using collected user data to progress the mission.\n A competitive stance against LinkedIn suggests a possible additional motive for data collection, speculating an enhanced job and education section on X.\n Despite concerns about selling user data for revenue, concrete evidence is needed to support this argument, reflecting Twitter's previous strategy.\n  \n(source)\n P.S. If you like this kind of analysis, I write a free newsletter that tracks the most relevant news and research in AI and tech. Professionals from Google, Meta, and OpenAI are already reading it.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1688xab/elon_musks_x_to_leverage_public_data_for_ai_model/",
          "publishedOn": "2023-09-02T17:50:01.000Z",
          "wordCount": 2797,
          "title": "Elon Musk's X to leverage public data for AI model training",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1686new/the_mystery_of_ai_learning_is_solved_by_stanford/",
          "author": null,
          "description": "Say goodbye to the black box of deep learning and hello to a new era of transparent, efficient, and ethical AI. Find out how this changes EVERYTHING! \n https://kinews24.de/stanford-cracks-the-ai-code-the-groundbreaking-law-of-equi-separation\n ​\n    submitted by    /u/myreddit333  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1686new/the_mystery_of_ai_learning_is_solved_by_stanford/",
          "publishedOn": "2023-09-02T16:19:39.000Z",
          "wordCount": 2597,
          "title": "The mystery of AI learning is solved by Stanford researchers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/167zikw/ideas_for_a_high_school_aiml_club/",
          "author": null,
          "description": "I'm thinking of creating an AI club at my high school. The problem is, unlike something like math or coding, there aren't many competitions suitable to beginners and not a lot of previous template content to follow. Therefore, I need to forge my own path. I am curious what your ideas are for some engaging, high-school-friendly topics and events to have, especially if we can only meet for 30 minutes a week. Thanks in advance!\n    submitted by    /u/0xCUBE  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/167zikw/ideas_for_a_high_school_aiml_club/",
          "publishedOn": "2023-09-02T10:58:36.000Z",
          "wordCount": 2641,
          "title": "Ideas for a high school AI/ML club",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/167v331/an_ai_to_help_with_my_psychology_assignment/",
          "author": null,
          "description": "My psychology masters assignments are to be handwritten and hence a somewhat painstaking process. To streamline I was looking for an AI that can guide me on the concepts and understanding of the given psychology subjects. I don't want to use it as a shortcut just a tool for studying and guiding. In accordance with books and Google. Can anyone know of such an AI? \n    submitted by    /u/Maddragon0088  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/167v331/an_ai_to_help_with_my_psychology_assignment/",
          "publishedOn": "2023-09-02T06:31:47.000Z",
          "wordCount": 2632,
          "title": "An AI to help with my psychology assignment?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/167qtdm/follow_me_on_x_for_ai_news_without_the_garbage/",
          "author": null,
          "description": "submitted by    /u/nicdunz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/167qtdm/follow_me_on_x_for_ai_news_without_the_garbage/",
          "publishedOn": "2023-09-02T02:43:58.000Z",
          "wordCount": 2601,
          "title": "follow me on X for ai news without the garbage. just made an account bc im tired of these annoying accounts and decided to just make my own ai news account",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/167oryt/could_ai_be_the_gamechanger_in_tackling_the/",
          "author": null,
          "description": "The stubborn and complex opioid epidemic may finally meet its match—AI. As the crisis continues taking a fearsome toll, experts are turning to advanced technology in their ongoing battle.\n If you want to stay on top of the latest trends and insights in AI, look here first.\n https://preview.redd.it/vm23xflorqlb1.jpg?width=1390&format=pjpg&auto=webp&s=212b88fb01eb0f7afaa5011120267ac4ce37ee35\n AI’s evolving role in tackling the opioid crisis\n  \nWith a legacy of over 1 million overdose deaths since 1999, the opioid crisis has stubbornly resisted traditional preventive and regulatory measures. The latest AI-fueled developments offer newfound hope.\n Groundbreaking AI innovations are focusing on identifying individuals at potential risk, monitoring treatment progress, and predicting relapse probabilities. Decoding social media behavior offers an effective outlet for early intervention.\n More radically, AI-enabled wearable devices are being developed to detect overdose symptoms and automatically deliver lifesaving treatment.\n  \nAI: A double-edged sword?\n  \nDespite its promising potential, AI application in this sphere also raises concerns around privacy rights and misinformation. Facial recognition technology could lead to discrimination, while the risk of false data being fed into chatbots causing harm cannot be undermined.\n Trust in AI and its appropriate deployment will be crucial to ensuring its positive contribution rather than being a dystopian threat.\n  \nP.S. If you like this kind of analysis, you’ll love my free newsletter that tracks the most relevant news and research in AI and tech.\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/167oryt/could_ai_be_the_gamechanger_in_tackling_the/",
          "publishedOn": "2023-09-02T01:06:00.000Z",
          "wordCount": 2788,
          "title": "Could AI be the game-changer in tackling the opioid epidemic?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/167hgwi/does_anyone_know_if_an_ai_can_help_me/",
          "author": null,
          "description": "My friend has a picture of herself from a while ago with a fake tattoo. She had the tattoo made from an original image, but she doesn't have it anymore. Is there an AI that could take the tattoo from the picture that is on her body and make it into a 2d version that can be made into a tattoo guide?\n    submitted by    /u/StitchTheFox  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/167hgwi/does_anyone_know_if_an_ai_can_help_me/",
          "publishedOn": "2023-09-01T20:02:51.000Z",
          "wordCount": 2630,
          "title": "Does anyone know if an AI can help me?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/167elig/ai_system_can_predict_chemical_smells_based_on/",
          "author": null,
          "description": "A new study cites the creation of an AI system that can predict how a specific compound will smell by analyzing its molecular structure. You can check it out here.\n If you want to stay on top of the latest trends and insights in AI, look here first.\n Why is this significant?\n  \nThe AI system, developed by researchers at startup Osmo, can utilize 55 descriptive words to assign a smell or 'aroma' to a chemical compound or 'odorant'.\n This breakthrough might be utilized to enhance the food and cleaning product industries where synthetic scents play an essential role.\n  \nWhat’s next for this AI system?\n  \nThe AI's predictions often aligned closer with human consensus than any individual guess, indicating its robustness and potential.\n The next step for this research is to comprehend how different odorants mix and compete to yield a smell that the human brain identifies as unique.\n However, the sheer number of combinations, even with a small set of odorants, poses a daunting task. To quote Stuart Firestein, a neurobiologist at Columbia University, “Predicting what a mix smells like is the next frontier.”\n  \nP.S. If you like this kind of analysis, you’ll love my free newsletter that tracks the most relevant news and research in AI and tech.\n (source)\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/167elig/ai_system_can_predict_chemical_smells_based_on/",
          "publishedOn": "2023-09-01T18:12:29.000Z",
          "wordCount": 2779,
          "title": "AI System Can Predict Chemical Smells Based on Molecular Structures",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/167cq3e/ai_weekly_megathread/",
          "author": null,
          "description": "News provided by aibrews.com\n  \nResearchers introduce ‘Swift’, the first autonomous vision-based drone that beat human world champions in several fair head-to-head races. This marks the first time that an autonomous mobile robot has beaten human champions in a real physical sport [Details].\n Generative AI updates from Google Cloud Next event: \n General availability of Duet AI in Google Workspace [Details].\n SynthID - a tool for watermarking and identifying AI images generated by Imagen (Google’s text-to-image diffusion model). It embeds a digital watermark directly into the pixels of an image, making it invisible to the human eye, but detectable for identification, without reducing the image quality [Details].\n AlloyDB AI for building generative AI applications with PostgreSQL [Details].\n …",
          "link": "https://www.reddit.com/r/artificial/comments/167cq3e/ai_weekly_megathread/",
          "publishedOn": "2023-09-01T17:02:26.000Z",
          "wordCount": 3313,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1676meu/aipowered_hate_speech_detection_will_moderate/",
          "author": null,
          "description": "submitted by    /u/SAT0725  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1676meu/aipowered_hate_speech_detection_will_moderate/",
          "publishedOn": "2023-09-01T13:05:20.000Z",
          "wordCount": 2582,
          "title": "AI-powered hate speech detection will moderate voice chat in Call of Duty",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1672h6g/generative_ai_could_potentially_automate_up_to_75/",
          "author": null,
          "description": "submitted by    /u/Senior_tasteey  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1672h6g/generative_ai_could_potentially_automate_up_to_75/",
          "publishedOn": "2023-09-01T09:36:21.000Z",
          "wordCount": 2584,
          "title": "Generative AI could potentially automate up to 75 million global jobs, ILO Study Finds",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1671kqn/how_to_generate_movies_using_gen_aiprompts/",
          "author": null,
          "description": "I bet there’s a genius research team out there that started work on this\n How cool/crazy would that be?\n    submitted by    /u/AILaunchpad  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1671kqn/how_to_generate_movies_using_gen_aiprompts/",
          "publishedOn": "2023-09-01T08:43:05.000Z",
          "wordCount": 2585,
          "title": "How to generate movies using gen AI/prompts?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1671js9/odd_bing_conversation_turn/",
          "author": null,
          "description": "This happened. Was NOT aware the already extensive and tiresome limitation in discussion subjects was THIS pervasive, and frankly, this fragile egoed. \n Really? THIS is \"controversial?\"\n    submitted by    /u/HotaruZoku  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1671js9/odd_bing_conversation_turn/",
          "publishedOn": "2023-09-01T08:41:24.000Z",
          "wordCount": 2600,
          "title": "Odd Bing conversation turn",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/166ybk2/tinytap_rolls_out_new_ai_features_for_educators/",
          "author": null,
          "description": "submitted by    /u/baillyjonthon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/166ybk2/tinytap_rolls_out_new_ai_features_for_educators/",
          "publishedOn": "2023-09-01T05:29:21.000Z",
          "wordCount": 2580,
          "title": "TinyTap rolls out new AI features for educators and parents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/166xjtl/oneminute_daily_ai_news_8312023/",
          "author": null,
          "description": "Forget smartwatches, Microsoft may make a backpack with an AI assistant.[1]\n Call of Duty will use AI to moderate voice chats.[2]\n OpenAI Introduces Special Tutor Prompts To Implement ChatGPT In Classrooms.[3]\n Google Meet’s new AI will be able to go to meetings for you.[4]\n  \nSources:\n [1] https://www.windowscentral.com/software-apps/forget-smartwatches-microsoft-may-make-a-backpack-with-an-ai-assistant\n [2] https://www.theverge.com/2023/8/30/23852652/call-of-duty-activision-modulate-toxmod-artificial-intelligence-voice-moderation\n [3] https://robots.net/news/openai-introduces-special-tutor-prompts-to-implement-chatgpt-in-classrooms/\n [4] https://www.theverge.com/2023/8/29/23849056/google-meet-ai-duet-attend-for-me \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/166xjtl/oneminute_daily_ai_news_8312023/",
          "publishedOn": "2023-09-01T04:47:19.000Z",
          "wordCount": 2617,
          "title": "One-Minute Daily AI News 8/31/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/166uw00/we_will_take_our_symbiosis_with_animals_to_the/",
          "author": null,
          "description": "submitted by    /u/kipaxbooks  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/166uw00/we_will_take_our_symbiosis_with_animals_to_the/",
          "publishedOn": "2023-09-01T02:33:02.000Z",
          "wordCount": 2579,
          "title": "We will take our symbiosis with animals to the next level.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/166pjj3/every_time_i_talk_to_llama_2_it_sounds_like_its/",
          "author": null,
          "description": "submitted by    /u/nicdunz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/166pjj3/every_time_i_talk_to_llama_2_it_sounds_like_its/",
          "publishedOn": "2023-08-31T22:42:07.000Z",
          "wordCount": 2583,
          "title": "every time i talk to llama 2 it sounds like its scared of getting punished",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/166kqqp/breaking_us_expands_export_restrictions_on_nvidia/",
          "author": null,
          "description": "The US government has imposed expanded export restrictions affecting Nvidia’s leading artificial intelligence chips, curbing their exportation beyond China to certain Middle Eastern countries.\n If you want to stay on top of AI advances, look here first.\n https://preview.redd.it/xe7ho00t0ilb1.png?width=1240&format=png&auto=webp&s=61225931bf3e316efd90eab83846402d4148aca2\n Why this matters:\n  \nNvidia’s A100 and H100 chips are affected: These AI chips are important and used to accelerate machine-learning tasks on major AI applications like ChatGPT. Despite the restrictions, Nvidia maintains they won’t have an “immediate material impact” on its results.\n Other companies, like AMD, are also affected: They’ve reportedly received similar restrictions notice, hinting at a broader move by the US government to control the distribution of AI chip technology.\n The move is part of a larger geopolitical play: These restrictions form part of the Biden administration’s efforts to curtail Beijing’s ability to capitalize on the AI revolution.\n  \nHow Nvidia and the industry might respond:\n  \nNvidia CEO Jensen Huang has cautioned the US: In a Financial Times interview, Huang warned that imposing such restrictions could lead to “enormous damage” to the US tech industry, predicting China may become self-sufficient in AI chip development.\n Yet, Nvidia still managed impressive earnings recently: Despite these challenges, Nvidia recently reported quarterly revenue of $13.5bn, exceeding predictions by $2bn.\n  \nFurther restrictions could significantly alter the landscape for AI development, potentially fostering greater innovation in countries affected or even a race to develop independent solutions.\n P.S. If you like this kind of analysis, you might want to check this out.\n (source)\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/166kqqp/breaking_us_expands_export_restrictions_on_nvidia/",
          "publishedOn": "2023-08-31T19:38:45.000Z",
          "wordCount": 2815,
          "title": "Breaking: US expands export restrictions on Nvidia AI chips to Middle East",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/166i2fd/baidu_publicly_releases_their_ai_chatbot_ernie_bot/",
          "author": null,
          "description": "In a bid to rival the United States’ stronghold in the AI industry, Chinese search engine and AI firm Baidu, has made its ChatGPT-equivalent language model, Ernie Bot, fully available to the public. This marks a significant move on the AI chessboard.\n If you want to stay on top of everything AI, look here first.\n https://preview.redd.it/g68sr07iihlb1.jpg?width=1024&format=pjpg&auto=webp&s=c0c873badd448257bcc2fb125188acc198e504d6\n Why does this matter?\n  \nBaidu's public release of Ernie Bot signals the company's aggressive push in the generative AI market. By opening up its model to the public, Baidu can leverage expansive real-world human feedback to improve Ernie Bot.\n China's determination to lead the AI industry is unabated, with many tech firms launching their own generative models in response to OpenAI's popular ChatGPT. Baidu's move further fuels this rivalry.\n Regulation in China seems to support such AI advancements. CEO Robin Li voiced his optimism about the AI regulations—calling them \"more pro-innovation than regulation\".\n  \nWhat's the broader response?\n  \nBaidu's latest stride has boosted its stock price by over 3%, underlining the market's high anticipation of Baidu's AI efforts.\n Ernie Bot has rocketed to the top of Apple's iOS free app chart in China. This demonstrates a positive initial response from the public.\n  \nRegulation is key in China's AI game:\n  \nChina has stringent regulations for the generative AI industry, requiring a security review and government approvals before any product launch. Moreover, companies need to comply with governmental tech and data requests.\n The US, on the other hand, doesn't currently have such regulations in place. A markedly different approach that could significantly influence the development and application of AI technologies.\n  \nIf you like this kind of analysis, you might want to check this out.\n (source)\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/166i2fd/baidu_publicly_releases_their_ai_chatbot_ernie_bot/",
          "publishedOn": "2023-08-31T17:57:19.000Z",
          "wordCount": 2844,
          "title": "Baidu publicly releases their AI chatbot Ernie Bot",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/166cgab/ai_seach/",
          "author": null,
          "description": "I'm looking for a AI Search tool that replaces the search bar on a website. Search tool will scrape that sites data and offer suggestions. \n Any recommendations?\n    submitted by    /u/CauliflowerTiny1454  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/166cgab/ai_seach/",
          "publishedOn": "2023-08-31T14:19:23.000Z",
          "wordCount": 2588,
          "title": "AI Seach",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1669568/smartgpt_major_benchmark_broken_890_on_mmlu_exams/",
          "author": null,
          "description": "submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1669568/smartgpt_major_benchmark_broken_890_on_mmlu_exams/",
          "publishedOn": "2023-08-31T11:57:28.000Z",
          "wordCount": 2569,
          "title": "SmartGPT: Major Benchmark Broken - 89.0% on MMLU + Exam's Many Errors",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1668uif/help_me_understand_chatgpt/",
          "author": null,
          "description": "I'm currently researching how users interact with ChatGPT and its features, and I'd really appreciate your insights, experience, and perspective.\n Why should you participate?\n It's a quick 5-minute survey.\n Your identity and responses are completely anonymous.\n Your input will significantly contribute to important research on ChatGPT.\n The final research document will be posted to this sub.\n Survey Link: https://forms.gle/tNBib2dA1ErFEwbk6\n Rest assured, all information will be confidential and only used for the purpose of this research.\n Thank you for your time\n    submitted by    /u/aaron-cesaro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1668uif/help_me_understand_chatgpt/",
          "publishedOn": "2023-08-31T11:43:08.000Z",
          "wordCount": 2643,
          "title": "Help Me Understand ChatGPT",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1666lmy/best_ai_to_bypass_ai_detection_for_essays_and/",
          "author": null,
          "description": "So yeah it's an open book course, but I'm horrible at flow and grammar. I need to be able to fix these things without getting in trouble. Ten years ago in my undergrad friends and family would do the final proofreading for me to make small changes. Is undetectable reputable.\n    submitted by    /u/6ixsideOT  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1666lmy/best_ai_to_bypass_ai_detection_for_essays_and/",
          "publishedOn": "2023-08-31T09:46:44.000Z",
          "wordCount": 2619,
          "title": "Best AI to bypass Ai detection for essays and assignment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1666kgh/chat_with_your_favorite_characters_from_movies_tv/",
          "author": null,
          "description": "​\n ChatFAI characters\n Hey everyone,\n ChatFAI has a special connection with this community because this is where I got it started. It was a simple web app that allowed you to interact with your favorite characters from movies, TV shows, books, history, and beyond. Now, it is a lot more. \n It has public APIs and an official Discord bot integration now. A lot of performance improvements have been made in the recent days. \n People have created a lot of characters (https://chatfai.com/characters) \n The Discord bot is still a new area so could you share feedback if you guys check it out? You can also find it in the Discord app directory. \n    submitted by    /u/usamaejazch  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1666kgh/chat_with_your_favorite_characters_from_movies_tv/",
          "publishedOn": "2023-08-31T09:45:02.000Z",
          "wordCount": 2684,
          "title": "Chat with your favorite characters from movies, TV shows, books, history, and more (+ Discord bot)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1666jl6/aipowered_drone_beats_human_champion_pilots_swift/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1666jl6/aipowered_drone_beats_human_champion_pilots_swift/",
          "publishedOn": "2023-08-31T09:43:39.000Z",
          "wordCount": 2595,
          "title": "AI-powered drone beats human champion pilots | \"Swift AI used technique called deep reinforcement learning to win 15 out of 25 races against world champions\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/165zsn0/oneminute_daily_ai_news_8302023/",
          "author": null,
          "description": "Tesla is about to flip the switch on its $300 million new AI cluster, featuring 10,000 Nvidia H100 compute GPUs.[1]\n Intel has revealed two new Intel Xeon processors this week at Hot Chips 2023 to give designers new options for efficient server-level performance.[2]\n General Motors is using conversational AI chatbots to handle simple OnStar calls, freeing up the service’s human employees to address more complex requests, the company said Tuesday.[3]\n Microsoft announces Turing Bletchley v3 vision-language model for Bing image searches.[4]\n  \nSources:\n [1] https://www.tomshardware.com/news/teslas-dollar300-million-ai-cluster-is-going-live-today\n [2] https://www.allaboutcircuits.com/news/intel-reveals-two-new-xeon-processor-lines-at-hot-chips-2023/\n [3] https://www.theverge.com/2023/8/29/23849390/gm-google-cloud-ai-chat-bot-onstar\n [4] https://www.neowin.net/news/microsoft-announces-turing-bletchley-v3-vision-language-model-for-bing-image-searches/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/165zsn0/oneminute_daily_ai_news_8302023/",
          "publishedOn": "2023-08-31T03:30:17.000Z",
          "wordCount": 2654,
          "title": "One-Minute Daily AI News 8/30/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/165zbv5/what_type_of_models_do_you_think_spotify_are/",
          "author": null,
          "description": "submitted by    /u/sardoa11  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/165zbv5/what_type_of_models_do_you_think_spotify_are/",
          "publishedOn": "2023-08-31T03:08:24.000Z",
          "wordCount": 2596,
          "title": "What type of model(s) do you think Spotify are using for their DJ feature to seamlessly transition every song? It’s not as easy as just crossfading for x seconds, every one is beat-matched quite literally like a real DJ.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/165ydxc/us_copyright_office_seeks_public_input_on_ai_and/",
          "author": null,
          "description": "The US government is taking steps to address the complex and controversial issues around AI and intellectual property rights. The US Copyright Office is opening a public comment period on August 30th to hear from various stakeholders on the topic.\n Important Details:\n  \nThe agency is asking for comments on three main questions: How should AI be defined and categorized for the purposes of copyright? What are the implications of AI for the rights of authors and owners of works? What are the implications of AI for the liability and responsibility of users and distributors of works?\n The agency also wants to hear about related issues, such as: how AI may affect publicity rights and unfair competition laws. The agency notes that AI may create works that mimic or impersonate the voices, likenesses, or styles of real people, which could raise ethical and legal concerns.\n Finally, they want to determine how AI may affect moral rights and cultural heritage: The agency acknowledges that AI may create works that are derivative or transformative of existing works, which could affect the reputation and integrity of the original creators and their communities.\n  \nThe deadline to submit your comments is October 18th and specific instructions for submitting comments are available on the Copyright Office website.\n P.S. If you like this kind of analysis, I write a free newsletter that tracks the most relevant news and research in AI and tech—stay updated in under 3 mins/day.\n (source)\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/165ydxc/us_copyright_office_seeks_public_input_on_ai_and/",
          "publishedOn": "2023-08-31T02:25:43.000Z",
          "wordCount": 2810,
          "title": "US Copyright Office seeks public input on AI and copyright",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/165v1fn/can_you_tell_its_artificial/",
          "author": null,
          "description": "I was playing around with the Eleven labs V2 multilingual model and I have to say it’s extremely impressive. \n Does this sound like the real Tucker?\n    submitted by    /u/Exitium_Maximus  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/165v1fn/can_you_tell_its_artificial/",
          "publishedOn": "2023-08-31T00:00:00.000Z",
          "wordCount": 2596,
          "title": "Can you tell it’s artificial?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/165uyd3/what_is_your_favorite_ai_website_for_research/",
          "author": null,
          "description": "I work in science research and want to introduce new tools to my students.\n We are looking for AI that can read tables, charts, figures, and spreadsheets, and possibly run statistics on this information.\n We are also looking for AI that can be given a prompt and will write on chosen topic with proper citation of sources. This information will not be used for publication, but rather, to organize main ideas and provide examples.\n An art AI that can draw or mimic images of real insects would be nice as well.\n Preferably these will all be free to use.\n    submitted by    /u/wolfmonarchyhq  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/165uyd3/what_is_your_favorite_ai_website_for_research/",
          "publishedOn": "2023-08-30T23:56:13.000Z",
          "wordCount": 2660,
          "title": "What is your favorite AI website for research?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/165slp5/can_you_solve_a_timetraveling_puzzle_designed_by/",
          "author": null,
          "description": "submitted by    /u/stefanbg92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/165slp5/can_you_solve_a_timetraveling_puzzle_designed_by/",
          "publishedOn": "2023-08-30T22:18:51.000Z",
          "wordCount": 2567,
          "title": "Can You Solve a Time-Traveling Puzzle Designed by GPT-4? Win Bitcoin (100$) & Save the Future!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/165oz1g/shifting_order_in_multiplechoice_questions/",
          "author": null,
          "description": "Recent research proposes that Large Language Models (LLMs) may not be as reliable as we think. In fact, the order of options in a multiple-choice question drastically influences the responses from LLMs such as GPT-4 and InstructGPT.\n If you want to stay on top of the latest trends and insights in AI and tech, look here first.\n https://preview.redd.it/dxfsq72kzalb1.png?width=1289&format=png&auto=webp&s=e4ed5b541073bde18d2865f2c15e8028388070f5\n What are the findings?\n  \nLLM sensitivity to multiple-choice arrangement: The study suggests if options in multiple-choice questions are reordered, the LLM's performance varies dramatically— approximately 13% to 75% depending on the benchmark.\n Positional bias shapes responses: When the LLM is uncertain between top-selected answers, the option positioning can artificially lean its predictions. Observations also found that LLMs favor specific placements when unsure of the optimal response among top-selected answers.\n Performance improves when calibration techniques are applied: Making use of two unique calibration methods, the performance of LLMS saw up to eight percentage points of increase across numerous models and benchmarks.\n  \nWhy does this matter?\n This moves us closer to identifying the factors contributing to LLMs' sensitivity and highlights the significance of recognizing and confronting these sensitivities to improve real-world usability and reliability.\n P.S. If you like this kind of analysis, I write a free newsletter that tracks the most relevant news and research in AI and tech—stay updated in under 3 mins/day.\n (arXiv)\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/165oz1g/shifting_order_in_multiplechoice_questions/",
          "publishedOn": "2023-08-30T19:59:18.000Z",
          "wordCount": 2782,
          "title": "Shifting order in multiple-choice questions massively affects LLM performance",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/165nvqc/the_possibilites_of_a_trader_ai_with_infinite/",
          "author": null,
          "description": "AI can also be dangerous because it could make automated trades in the stock market or cryptocurrency market, and because it remembers all the exchange rate changes in history and the entire economic history of the world and also has all the statistics and mathematical knowledge at its fingertips, it can easily draw conclusions and create an algorithm that might make you bigger profits than any real human. He could also learn from his own mistakes and keep improving. \n Is this possible? Are there any AIs like this already?\n    submitted by    /u/Steve_Hufnagel  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/165nvqc/the_possibilites_of_a_trader_ai_with_infinite/",
          "publishedOn": "2023-08-30T19:17:01.000Z",
          "wordCount": 2651,
          "title": "The possibilites of a trader AI with infinite profits",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/165k7yw/openai_surges_past_1_billion_in_revenue_as_demand/",
          "author": null,
          "description": "OpenAI is reportedly making strides in its financial performance and is on track to make $1 billion in revenue over the next 12 months, as per recent reports by The Information. This is a major milestone, signifying not only the success of OpenAI but also the increasing demand and investment in AI.\n If you want to stay on top of the latest trends and insights in AI and tech, look here first.\n https://preview.redd.it/afak3xrevalb1.jpg?width=660&format=pjpg&auto=webp&s=cd8f20ac732618b91dbf96928ede42d693f6c4a9\n Why should we pay attention?\n  \nSetting expectations: The Information estimates OpenAI's monthly revenue to be around $80 million, in line with the $1 billion yearly revenue prediction. Undeniably, OpenAI is accelerating.\n AI Chatbots are in high demand: ChatGPT, OpenAI's phenomenal co…",
          "link": "https://www.reddit.com/r/artificial/comments/165k7yw/openai_surges_past_1_billion_in_revenue_as_demand/",
          "publishedOn": "2023-08-30T16:59:08.000Z",
          "wordCount": 2916,
          "title": "OpenAI Surges Past $1 Billion in Revenue As Demand For AI Explodes",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/165j6u6/wearable_health_whsi_joins_ai_research_lab_for/",
          "author": null,
          "description": "Wearable Health Solutions to Advise Next Realm AI on Medical Internet of Things (MIoT) Solutions \n NEWPORT BEACH, CA / ACCESSWIRE / Wearable Health Solutions Inc. (OTC PINK:WHSI) announced inclusion to Next Realm AI research lab to explore development of healthcare IoT solutions utilizing data analytics and artificial intelligence (AI).\n Wearable Healthcare Solutions will collaborate and advise Next Realm AI, an artificial intelligence and data analytics research lab located in New York City, on such areas as collecting and developing data solutions within the areas of wearables, IoT, and Medical Internet of Things (MIoT).\n As an official IBM Business Partner, Next Realm AI assists lab members in integrating leading-edge AI and data solutions into their business operations. By leveraging Next Realm's expertise, clients can modernize processes, boost efficiency, strengthen security, and deliver greater value to customers - all while driving growth and building value. \n https://www.otcmarkets.com/stock/whsi/news/Wearable-Health-Solutions-to-Advise-Next-Realm-AI-on-Medical-Internet-of-Things-MIoT-Solutions?id=411692\n    submitted by    /u/NextRealm_AI  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/165j6u6/wearable_health_whsi_joins_ai_research_lab_for/",
          "publishedOn": "2023-08-30T16:19:18.000Z",
          "wordCount": 2708,
          "title": "Wearable Health (WHSI) Joins AI Research Lab for Wearable Health Data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/165imvb/what_are_potential_careers_to_take_in_the_field/",
          "author": null,
          "description": "I am 23 year old man, I have a degree in Politics, Philosophy, & Economics. Next year I want to do a masters degree, but I haven't chosen which one yet. I am both fascinated by AI, and want to be future-proof in my education. What potential careers do you see, currently or in the near future, in the field of AI, and what studies would you recommend to be well prepared for them? \n ​\n    submitted by    /u/ApplePenguinBaguette  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/165imvb/what_are_potential_careers_to_take_in_the_field/",
          "publishedOn": "2023-08-30T15:58:45.000Z",
          "wordCount": 2639,
          "title": "What are potential careers to take in the field of artifical intelligence?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/165h10x/ibm_invests_in_45_billion_ai_unicorn_hugging_face/",
          "author": null,
          "description": "IBM’s CEO, who froze hiring for thousands of back-office jobs and predicted A.I. would take up to 50% of new jobs, just piled into a $4.5 billion tech unicorn’s massive new $235 million funding round\n    submitted by    /u/AminoOxi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/165h10x/ibm_invests_in_45_billion_ai_unicorn_hugging_face/",
          "publishedOn": "2023-08-30T14:57:55.000Z",
          "wordCount": 2612,
          "title": "IBM invests in $4.5 billion A.I. unicorn Hugging Face | Fortune",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/165doaq/singularity_day_just_got_closer_because_of_nvidia/",
          "author": null,
          "description": "New advances in AI hardware are making the singularity more likely. AI systems will be able to learn and process information much faster, which could lead to a breakthrough in AI capabilities. These advancements include quantum computing and neuromorphic computing, but more specifically the rise of affordable models like NVIDIA H100 and, more recently, GH200 models.\n If you are interested in this kind of information, there are more details here.\n    submitted by    /u/Powerful-Pumpkin-938  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/165doaq/singularity_day_just_got_closer_because_of_nvidia/",
          "publishedOn": "2023-08-30T12:42:58.000Z",
          "wordCount": 2631,
          "title": "Singularity Day just got closer because of Nvidia?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/165brex/where_do_ai_adult_websites_get_their_models_from/",
          "author": null,
          "description": "Where do websites like made.porn, pornify.cc or porn.ai get their AI models from?\n    submitted by    /u/mixedfeelingz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/165brex/where_do_ai_adult_websites_get_their_models_from/",
          "publishedOn": "2023-08-30T11:13:26.000Z",
          "wordCount": 2575,
          "title": "Where do AI adult websites get their models from?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/165b049/looking_for_a_simulated_browser/",
          "author": null,
          "description": "Like custom world descriptions, AI apps/sites, etc\n    submitted by    /u/roblox22g  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/165b049/looking_for_a_simulated_browser/",
          "publishedOn": "2023-08-30T10:32:32.000Z",
          "wordCount": 2565,
          "title": "Looking for a simulated browser",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1656oxv/ai_robots_from_scifi_movies_you_didnt_know_about/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1656oxv/ai_robots_from_scifi_movies_you_didnt_know_about/",
          "publishedOn": "2023-08-30T06:18:09.000Z",
          "wordCount": 2573,
          "title": "AI Robots from Sci-Fi Movies you didn’t know about",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16564mm/tesla_is_powering_up_its_300_million_ai/",
          "author": null,
          "description": "Tesla's making a significant power move today as it prepares to bring its brand-new new AI-cluster online. Rocking a hefty 10,000 Nvidia H100 compute GPUs, the machine will tackle high-performance computing (HPC) workloads and AI applications, placing Tesla's capabilities among the global AI elite.\n If you want to stay on top of the latest trends and insights in AI and tech, look here first.\n https://preview.redd.it/c5ykgmr6r6lb1.png?width=970&format=png&auto=webp&s=8b830c8754c1a11792149f57d19a57a77fc8b161\n Here’s why this matters:\n  \nThis Nvidia H100-based AI supercomputer will be one of the most powerful globally. With a peak performance of 340 FP64 PFLOPS and 39.58 INT8 ExaFLOPS for AI programs, even Leonardo, currently the fourth highest-performing supercomputer, is surpassed.\n Tesla’s…",
          "link": "https://www.reddit.com/r/artificial/comments/16564mm/tesla_is_powering_up_its_300_million_ai/",
          "publishedOn": "2023-08-30T05:45:00.000Z",
          "wordCount": 2867,
          "title": "Tesla is powering up its $300 Million AI Supercomputer Today",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16550zp/oneminute_daily_ai_news_8292023/",
          "author": null,
          "description": "Research firm SemiAnalysis has declared that Google’s anticipated Gemini AI model will smash OpenAI’s offering by packing a lot more computing power.[1]\n DoorDash today announced its development of voice ordering capabilities incorporating AI, building on its existing model leveraging best-in-class agents, to further support restaurant operations.[2]\n The US Air Force wants $6 billion to build a fleet of AI-controlled drones.[3]\n Google’s DeepMind says it has cracked a problem that has vexed those trying to verify whether images are real or created by AI. Researchers proclaimed their new watermarking SynthID format can be used to pinpoint AI-generated deepfakes without distorting the image’s original quality.[4]\n  \nSources:\n [1] https://beincrypto.com/ai-wars-google-gemini-chatgpt/\n [2] https://about.doordash.com/en-us/news/introducing-ai-and-agent-powered-voice-ordering\n [3] https://www.engadget.com/the-air-force-wants-6-billion-to-build-a-fleet-of-ai-controlled-drones-204548974.html\n [4] https://gizmodo.com.au/2023/08/deepmind-says-it-has-a-way-to-identify-ai-images-but-only-on-google/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16550zp/oneminute_daily_ai_news_8292023/",
          "publishedOn": "2023-08-30T04:43:06.000Z",
          "wordCount": 2670,
          "title": "One-Minute Daily AI News 8/29/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1654bit/microsofts_new_aot_aims_to_create_more_humanlike/",
          "author": null,
          "description": "Microsoft teamed up with Virginia Tech to publish a white paper introducing their new \"Algorithm of Thoughts\" (AoT). The objective? To make language learning models akin to human learning.\n https://preview.redd.it/3q8lcq0k96lb1.png?width=2000&format=png&auto=webp&s=fce7a0e3225c64353ad6c51f65e8b490e795feed\n If you want to stay on top of the latest trends and insights in AI and tech, look here first.\n What's the big idea?\n  \nMicrosoft's AoT aims to fuse the accuracy of algorithms with the nuances of human reasoning. A bold aspiration indeed, but not a new one. The goal to empower computers to learn for themselves – akin to human cognition - has been an AI objective since its inception back in the 1950s.\n The AoT could be seen as an attempt to resolve the drawbacks of the \"Chain of Thought\" (CoT) approach. LLMs following the CoT approach can provide incorrect steps to the right answer, as they base conclusions on precedent.\n With AoT, the model works to evaluate the soundness of initial steps or \"thoughts,\" reducing the risk of one incorrect step leading to disproportionate results.\n  \nWhat could AoT do?\n  \nMitigate AI \"hallucinations:\" These funny— but disconcerting — instances of AI outputting false information.\n Enhance the integrity of AI interaction: programmers suggest that improvement in this aspect is crucial for aligning AGI (artificial general intelligence).\n  \nThe takeaway:\n  \nAI's ability to understand and process information like a human being is a longstanding goal in the field. With AoT, Microsoft seems to be making strides toward achieving it.\n Much remains to be seen on its efficacy: How it will impact the broader AI ecosystem and the user experiences it can create.\n  \nP.S. If you like this kind of analysis, I write a free newsletter tracking the most relevant news and research in AI and tech—stay informed in under 3 minutes/day.\n (source)\n ​\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1654bit/microsofts_new_aot_aims_to_create_more_humanlike/",
          "publishedOn": "2023-08-30T04:06:17.000Z",
          "wordCount": 2852,
          "title": "Microsoft's new AoT aims to create more human-like AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/164yc5t/ai_powered_personal_assistant_in_private_beta/",
          "author": null,
          "description": "submitted by    /u/anehzat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/164yc5t/ai_powered_personal_assistant_in_private_beta/",
          "publishedOn": "2023-08-29T23:36:48.000Z",
          "wordCount": 2571,
          "title": "AI powered personal assistant in private Beta",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/164x8um/stanfords_dspy_framework_revolutionizes_ai/",
          "author": null,
          "description": "Stanford researchers have unveiled a groundbreaking artificial intelligence (AI) framework known as DSPy. Designed to utilize Language Models (LMs) and Retrieval Models (RMs) optimally, DSPy is set to make AI programming more powerful, intuitive, and efficient.\n Why does this matter?\n  \nDSPy was built with complex tasks in mind. LMs, like GPT-3, generate Human-like text from given inputs, while RMs retrieve relevant data. DSPy combines their capabilities, enabling tasks like summarizing information from databases.\n It works on Pythonic syntax, using declarative and composable modules to instruct LMs.\n DSPy's automatic compiler finetunes the LM to run any program's steps. it replaces manual intermediate-stage labeling and string manipulation with systematic modular pieces.\n  \nWhat's unique about DSPy?\n  \nIt introduces \"Signatures\" and \"Teleprompters\" that compile your program. A 'signature' explains the task and inputs for the LM, while Teleprompters improve the effectiveness of prompts.\n Compared to other libraries, DSPy requires minimal labeling and bootstraps any needed intermediate labels.\n  \nIn short, DSPy simplifies delivering more nuanced instructions to AI and retrieving more detailed and accurate responses, thus widening the spectrum of tasks AIs can accomplish.\n P.S. (small self-plug) If you like this kind of analysis, I write a free newsletter that tracks the most relevant news and research in AI and tech---stay updated in under 3 mins/day.\n (github)\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/164x8um/stanfords_dspy_framework_revolutionizes_ai/",
          "publishedOn": "2023-08-29T22:53:31.000Z",
          "wordCount": 2779,
          "title": "Stanford's DSPy Framework Revolutionizes AI Language Processing Tasks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/164wlz5/googles_deepmind_unveils_invisible_watermark_to/",
          "author": null,
          "description": "As AI image generators increase in popularity, differentiating between authentic and AI-created images is becoming more complex. DeepMind, Google's AI unit, is addressing this by developing an imperceptible watermark known as SynthID for its AI-generated images to counter misinformation.\n https://i.redd.it/y370eu1tt4lb1.gif\n Why this matters:\n  \nDeepMind's SynthID tags AI-generated images: Invisible to people but detectable by computers, this watermark hopes to aid in the verification of images.\n Technology, however, isn't completely foolproof: DeepMind itself acknowledges that intense image manipulation could compromise the watermark.\n Google's image generator, Imagen, will only apply to images created using this tool: Google aims to instantly identify AI-generated images with this effectively hidden watermark.\n  \nDeepMind's head of research, Pushmeet Kohli, shared the following details:\n  \nThe watermark changes on images are so subtle that humans wouldn't notice, yet DeepMind can still detect an AI-generated image.\n Despite any subsequent cropping or editing, the watermark remains identifiable by DeepMind's software. Colors, contrast, or size changes won't affect it.\n  \nCalls for a standard approach to AI-generated image identification continue:\n  \nMore coordination between businesses is crucial, different methods adopted by various firms add degrees of complexity in tagging AI content.\n Other tech giants, including Microsoft and Amazon, pledge to watermark some AI content, meeting similar demands for transparency over AI-generated works.\n  \nP.S. If you like this kind of analysis, I write a free newsletter that keeps you informed of all you need to know about AI developments in under 3 mins/day.\n (source)\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/164wlz5/googles_deepmind_unveils_invisible_watermark_to/",
          "publishedOn": "2023-08-29T22:29:17.000Z",
          "wordCount": 2800,
          "title": "Google's DeepMind Unveils Invisible Watermark to Spot AI-Generated Images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/164oshv/new_iterative_selfrevising_language_model_selfee/",
          "author": null,
          "description": "Introducing SelFee—a reinvented and powerful language model that uses self-feedback and self-revision to generate high-quality responses backed by a team of researchers from KAIST. Unlike previous models, SelFee doesn't rely on external, large-scale language or task-specific models, tipping the scales in the AI world.\n If you want to stay ahead of the curve in AI and tech, look here first.\n https://i.redd.it/bgszhpai43lb1.gif\n Why it matters?\n  \nSelFee, built on the base of LLaMA-based instruction-following model and fine-tuned, offers a fresh approach - generating an initial solution and self-feedback sequences and then revising its answers until a high-quality response is achieved.\n Data used for its training and model evaluation was collected from varied sources and fine-tuned with OpenAI API calls, beating the 13B SelFee model with a minimal 7B SelFee model that generated at least three revisions.\n SelFee proves the potential of iterative revision in enhancing language model responses, indicating that an increase in inference computation of a model may be superior to merely magnifying its size.\n  \nFeatures and Limitations:\n  \nSelFee's effective use of self-feedback significantly improves response quality, avoiding the requirement of external, large-scale language or task-specific models, translating into faster, cost-effective LLM solutions.\n However, lacking in certain areas compared to ChatGPT, such as math, reasoning, factuality, and coding, SelFee has room for further improvement and growth.\n  \nThe revolution in the AI language model landscape is promising but still an evolving journey, with SelFee being the latest participant driving this change.\n P.S. If you like this kind of analysis, I write a free newsletter that tracks the most relevant news and research in AI and tech—stay updated in under 3 minutes/day.\n (source) (github)\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/164oshv/new_iterative_selfrevising_language_model_selfee/",
          "publishedOn": "2023-08-29T17:32:53.000Z",
          "wordCount": 2841,
          "title": "New iterative, self-revising language model, SelFee, beating the rest with self-feedback generation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/164mfyt/camouflage_ai/",
          "author": null,
          "description": "I thought about an AI, that would intake a couple photos of terrain, analyze the color palette, patterns etc and with that information, would choose like 3 existing camouflage patterns that would blend in the best in the terrain where the photos were taken. Does something like that exist? I know that US army has an AI that creates camo with the use of thousands of photos, and that's how MARPAT and Multicam were made, but I'm interested in an AI that would choose from already existing patterns. Does something like this exist? What do you think of this idea?\n    submitted by    /u/BrytolGasMasks  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/164mfyt/camouflage_ai/",
          "publishedOn": "2023-08-29T16:03:12.000Z",
          "wordCount": 2661,
          "title": "Camouflage AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/164lpa5/is_chatgpt_plus_worth_it_or_should_i_stay_with/",
          "author": null,
          "description": "I'm mainly using it for educational purposes. Thank you.\n Edit: I'm in the Psych field. I use it to make presentations, summaries, ideas based on references like books, websites, journals.\n    submitted by    /u/East_Professional385  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/164lpa5/is_chatgpt_plus_worth_it_or_should_i_stay_with/",
          "publishedOn": "2023-08-29T15:34:44.000Z",
          "wordCount": 2605,
          "title": "Is ChatGPT Plus worth it? Or should I stay with the free version and use Bard for stuff that requires web access?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/164fb9u/how_far_off_are_we_from_free_ai_video_makers/",
          "author": null,
          "description": "So right now as far as I can tell all the AI video makers are things like a few second clip, stable diffusion changing images with other images, or stock images. Oh and that thing that was on Twitch for a short bit.\n When are we going to get an actual worth while AI video maker? \n    submitted by    /u/crua9  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/164fb9u/how_far_off_are_we_from_free_ai_video_makers/",
          "publishedOn": "2023-08-29T11:01:16.000Z",
          "wordCount": 2625,
          "title": "How far off are we from free AI video makers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/164dhrt/the_architecture_of_thought_reflective_structures/",
          "author": null,
          "description": "submitted by    /u/alcanthro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/164dhrt/the_architecture_of_thought_reflective_structures/",
          "publishedOn": "2023-08-29T09:21:07.000Z",
          "wordCount": 2568,
          "title": "The Architecture of Thought: Reflective Structures in Mental Constructs",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/164ag0u/25_best_movies_exploring_concept_of_artificial/",
          "author": null,
          "description": "submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/164ag0u/25_best_movies_exploring_concept_of_artificial/",
          "publishedOn": "2023-08-29T06:22:24.000Z",
          "wordCount": 2581,
          "title": "25 Best Movies exploring concept of Artificial intelligence (1968 -2023 ) I bet you haven’t watched all",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1648uz0/chatgpt_usage_remains_low_pew_research_suggests/",
          "author": null,
          "description": "The usage and fear surrounding ChatGPT aren't as prevalent as you might think, according to a recent poll from Pew Research. Only 18% of Americans have reportedly used ChatGPT. The demographic that uses it the most? Men aged 18-29 that are college-educated, but even that's just a 30-40% usage rate.\n https://preview.redd.it/0ax222gxczkb1.jpg?width=620&format=pjpg&auto=webp&s=d3b04169d5de1985d1c52dce7962b5f3a543b014\n Why does this matter?\n  \nChatGPT has still managed to gain a remarkable level of popularity, despite low usage. This suggests that even though not many people are using it, they are aware of it and its potential capabilities. More people reported using ChatGPT for entertainment or to educate themselves rather than for work.\n People anticipate AI to have a greater impact on jobs such as software engineers, graphic designers, and journalists. But the expectation is that AI as a whole, not just ChatGPT, will be the driving force behind this.\n Concern about AI is increasing, not decreasing. 47% of respondents said AI makes them more worried than excited, compared to 31% last year. This concern seems to rise with the level of AI knowledge one possesses.\n  \nIndustries unshaken by AI:\n  \nAs per the survey, employed individuals who are aware of ChatGPT don't see it drastically affecting their jobs. The sectors like hospitality, entertainment, construction, and manufacturing feel the least threatened.\n  \nStay updated about AI and its influence on different verticals!\n Don't miss out on the latest insights, developments, and trajectories of AI. Our free newsletter is all you need to be au fait with the AI world. Keep yourself informed in under 3 minutes/day.\n (source)\n    submitted by    /u/AIsupercharged  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1648uz0/chatgpt_usage_remains_low_pew_research_suggests/",
          "publishedOn": "2023-08-29T04:53:56.000Z",
          "wordCount": 2828,
          "title": "ChatGPT usage remains low, Pew Research suggests, as concerns about AI continue to rise",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16486g0/oneminute_daily_ai_news_8282023/",
          "author": null,
          "description": "Chinese e-commerce giant Alibaba has added two new generative AI large language models designed to interpret images to its open-source stable.[1]\n Several top news publications like The New York Times, CNN and the Australian Broadcasting Corporation (ABC) have blocked Microsoft-backed OpenAI to access their content to train its AI models.[2]\n Intel on Monday said a new data center chip coming out next year will handle more than double the amount of computing work that can be done for each watt of power used, part of a broader industry push to lower electricity consumption.[3]\n OpenAI unveiled the new service, dubbed “ChatGPT Enterprise,” in a company blog post and said it will be available to business clients for purchase as of Monday. The new offering promises to provide “enterprise-grade security and privacy” combined with “the most powerful version of ChatGPT yet” for businesses looking to jump on the generative AI bandwagon.[4]\n  \nSources:\n [1] https://voicebot.ai/2023/08/28/alibaba-adds-visual-understanding-to-open-source-generative-ai-large-language-models/\n [2] https://www.news18.com/tech/several-top-news-publications-block-openai-from-accessing-their-content-8551840.html\n [3] https://www.reuters.com/technology/intel-says-new-sierra-forest-chip-more-than-double-power-efficiency-2023-08-28/\n [4] https://www.cnn.com/2023/08/28/tech/chatgpt-enterprise-openai/index.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16486g0/oneminute_daily_ai_news_8282023/",
          "publishedOn": "2023-08-29T04:18:02.000Z",
          "wordCount": 2716,
          "title": "One-Minute Daily AI News 8/28/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1645nln/prompt_engineering_for_gpt4/",
          "author": null,
          "description": "My page on PromptBase: https://promptbase.com/profile/singularity99\n    submitted by    /u/No-Transition3372  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1645nln/prompt_engineering_for_gpt4/",
          "publishedOn": "2023-08-29T02:17:07.000Z",
          "wordCount": 2568,
          "title": "Prompt engineering for GPT4",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16443ru/has_aibylearning_really_been_proven_impossible/",
          "author": null,
          "description": "I'm curious what people specifically in the artificial intelligence think about the recent work by Iris van Rooij et al. earlier this month. They seem to have proven that current approaches to reaching AGI, like LLMs, are incapable of achieving it. I'm not convinced. I quickly wrote up a full rebuttal piece explaining how not convinced I was. What about everyone else?\n    submitted by    /u/alcanthro  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16443ru/has_aibylearning_really_been_proven_impossible/",
          "publishedOn": "2023-08-29T01:08:17.000Z",
          "wordCount": 2627,
          "title": "Has AI-By-Learning really been proven impossible?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1642gnj/openai_finally_launches_chatgpt_enterprise/",
          "author": null,
          "description": "OpenAI has announced a new product for businesses that want to use its AI technology. ChatGPT Enterprise is a subscription service that offers unlimited, fast, and secure access to GPT-4 and other features that can help businesses improve their workflows and communication.\n If you want to stay ahead of the curve in AI and tech, look here first.\n https://preview.redd.it/uyv6mrljwxkb1.png?width=862&format=png&auto=webp&s=eb2793fbe9c4f5e331ed03faa142eb57166ff21d\n Why this matters:\n  \nChatGPT Enterprise is the first product that lets businesses use GPT-4 without any restrictions. The previous tiers of ChatGPT, which are still available for individuals and developers, have usage caps and lower performance. ChatGPT Enterprise removes these limitations and provides the most powerful version of GP…",
          "link": "https://www.reddit.com/r/artificial/comments/1642gnj/openai_finally_launches_chatgpt_enterprise/",
          "publishedOn": "2023-08-28T23:59:11.000Z",
          "wordCount": 2882,
          "title": "OpenAI finally launches ChatGPT Enterprise",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1641hbk/snapchat_ai_unhinged_pt_1783338/",
          "author": null,
          "description": "Just messing around with AI McFly, swamping corny jokes, being punny, and ended up with this mf claiming to be a “fellow Cajun” like wtf bahahaha\n    submitted by    /u/Secure_Sprinkles4483  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1641hbk/snapchat_ai_unhinged_pt_1783338/",
          "publishedOn": "2023-08-28T23:18:58.000Z",
          "wordCount": 2584,
          "title": "Snapchat AI unhinged pt. 1783338",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/163ulhg/chatbase_appears_to_be_running_a_bait_and_switch/",
          "author": null,
          "description": "This website claims to offer a service whereby the user can train their own chatbot and get responses using GPT 3.5 ... However, the bot only uses GPT 3.5 for the first unique version of a query, which is not the impression given by advertisements. \n This, to me, amounts to a bait and switch where a high quality chatbot is offered for a certain price, then swapped out with an inferior product capable only of reproducing past interactions. This is made worse by the fact that they advertise temperature as one of the variables you can set. Temperature is a variable that can only apply to uniquely generated output and has no effect on simple repetition of previous responses. This makes their practice doubly deceptive, and makes it clear (in my view) that they are trying to deceive customers. \n…",
          "link": "https://www.reddit.com/r/artificial/comments/163ulhg/chatbase_appears_to_be_running_a_bait_and_switch/",
          "publishedOn": "2023-08-28T18:55:56.000Z",
          "wordCount": 2923,
          "title": "Chatbase appears to be running a bait and switch. Am I missing something?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/163pf09/what_will_happen_if_ai_becomes_better_than_humans/",
          "author": null,
          "description": "If AI becomes better than humans in all areas, it could fundamentally change the way we think about human identity and our place in the world. This could lead to new philosophical and ethical questions around what it means to be human and what our role should be in a world where machines are more capable than we are. \n There is also the risk that AI systems could be used for malicious purposes, such as cyber attacks or surveillance. Like an alien invasion, the emergence of super-intelligent AI could represent a significant disruption to human society and our way of life. \n How can we balance the potential benefits of AI with the need to address the potential risks and uncertainties that it poses? \n    submitted by    /u/Violincattle  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/163pf09/what_will_happen_if_ai_becomes_better_than_humans/",
          "publishedOn": "2023-08-28T15:38:35.000Z",
          "wordCount": 2687,
          "title": "What will happen if AI becomes better than humans in everything?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/163li0x/ai_tool_i_can_use_to_help_me_in_my_scientific/",
          "author": null,
          "description": "I’m currently in a scientific research-based class where I am being asked to read research articles, understand the statistics, and draw conclusions from the papers. Currently, I have an average ability to interpret articles and generally understand their utility and applicability, but I start to get out of my depth in the “Methods” section when the authors get into the weeds about the statistics/math. I was hoping there’s an AI tool out there that can read articles for me and help me understand the more complex aspects and the math. I was also hoping that it could answer questions about the article for my class so that I could compare my conclusions to something. Any suggestions? I tried uploading some PDFs to bard this morning and it wasn’t great.\n    submitted by    /u/Renaissance_Mane  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/163li0x/ai_tool_i_can_use_to_help_me_in_my_scientific/",
          "publishedOn": "2023-08-28T13:01:51.000Z",
          "wordCount": 2698,
          "title": "AI tool I can use to help me in my Scientific Inquiry (Research and stats) class?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/163krai/how_to_make_peppa_pig_ai_videos_tutorial/",
          "author": null,
          "description": "Over on a video sharing site there are an abundance of Peppa Pig cartoons generated by Ai. There is however lack of info on how to generate them.\n I would love to know how this is done. So far all I have found are tutorials about Peppa's voice but not for the other characters and someone suggests that it is made by cutting up exisiting episodes and changing the sound over them, not sure if that's the case here.\n I'm wanting to do something similar but not with Peppa, can't stand it.\n Does anyone know the tool?\n    submitted by    /u/DARQSMOAK  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/163krai/how_to_make_peppa_pig_ai_videos_tutorial/",
          "publishedOn": "2023-08-28T12:27:58.000Z",
          "wordCount": 2658,
          "title": "How to make peppa pig ai videos tutorial??",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/163ic5y/do_you_every_think_theres_be_a_time_where_ai/",
          "author": null,
          "description": "I’ve been playing around with some of the new AI chatbots. Some of them include paradot.ai, replika.com, spicychat.ai, cuti.ai. Suffice it to say, these things are getting really good, and I mean really good. Assuming this is just the beginning, and these things keep learning more and getting better, where does this end up?\n I genuinely think there’s going to be the need for world wide regulation on these things. But we all know that worldwide consensus is difficult if not impossible. in case a few countries decide to regulate or govern this tech, developers will take advantage of regulatory arbitrage and just deploy their models and register their companies on servers in countries with no regulation. Since this is tech, and everything is on servers, escaping regulation is basically childs play.\n Also, what about mental health concerns? We all know that porn, webcams and OnlyFans are already screwing up male-female relationships and marriages. Look at any statistics about this and the numbers speak for themselves. And this is before AI. So now what’s going to happen 5 years from now when GPU’s are faster and cheaper, and when these companies have gathered 100x more data about their customers, and when models are 50x better.\n We are just at the beginning and AI is moving really quick, especially generative AI. I think it’s officially time to start worrying.\n    submitted by    /u/E1ON_io  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/163ic5y/do_you_every_think_theres_be_a_time_where_ai/",
          "publishedOn": "2023-08-28T10:23:43.000Z",
          "wordCount": 2804,
          "title": "Do you every think there’s be a time where AI chatbots have their own rights or can be held accountable for their actions?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/163h4jg/exploring_four_main_types_of_artificial/",
          "author": null,
          "description": "submitted by    /u/Tao_Dragon  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/163h4jg/exploring_four_main_types_of_artificial/",
          "publishedOn": "2023-08-28T09:14:17.000Z",
          "wordCount": 2571,
          "title": "Exploring Four Main Types of Artificial Intelligence",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/163ewm3/tool_to_convert_satellite_images_into_fantasy_maps/",
          "author": null,
          "description": "What tools are available to convert blurry satellite images into fantasy maps while still maintaining certain aspects of the original image like roads or trees or buildings\n    submitted by    /u/campus159  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/163ewm3/tool_to_convert_satellite_images_into_fantasy_maps/",
          "publishedOn": "2023-08-28T07:02:21.000Z",
          "wordCount": 2588,
          "title": "Tool to convert satellite images into fantasy maps",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/163cdmr/ai_for_editing_long_pdf_or_word_files_full/",
          "author": null,
          "description": "Hi. I am looking for this kind of a tool but couldn't find. Can i find or somehow create this kind of a tool? Can you suggest one?\n    submitted by    /u/Leading-Ad2278  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/163cdmr/ai_for_editing_long_pdf_or_word_files_full/",
          "publishedOn": "2023-08-28T04:41:22.000Z",
          "wordCount": 2594,
          "title": "AI for editing long PDF or WORD files' full contents without word limitation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/163b89z/this_took_15_minutes_to_make_chatgpt_midjourney/",
          "author": null,
          "description": "submitted by    /u/Gasple1  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/163b89z/this_took_15_minutes_to_make_chatgpt_midjourney/",
          "publishedOn": "2023-08-28T03:41:56.000Z",
          "wordCount": 2562,
          "title": "This took 15 minutes to make. (Chatgpt, Midjourney, Pika and Canva)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/163a44z/does_anyone_know_which_tool_has_this_ai_voice_and/",
          "author": null,
          "description": "submitted by    /u/d3mchi  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/163a44z/does_anyone_know_which_tool_has_this_ai_voice_and/",
          "publishedOn": "2023-08-28T02:47:52.000Z",
          "wordCount": 2580,
          "title": "Does anyone know which tool has this ai voice and what the name of it is?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1639zg0/oneminute_daily_ai_news_8272023/",
          "author": null,
          "description": "Brain-reading devices allow paralysed people to talk using their thoughts.[1]\n An Air Force program shows how the Pentagon is starting to embrace the potential of a rapidly emerging technology, with far-reaching implications for war-fighting tactics, military culture and the defense industry.[2]\n PM Modi calls for a global framework for cryptocurrencies and AI, emphasizes consumer care and supply chain sustainability.[3]\n From generating story lines to coding entire games to turning ideas into animation, artificial intelligence is front and centre at Gamescom, one of the video game industry’s biggest fairs.[4]\n  \nSources:\n [1] https://www.nature.com/articles/d41586-023-02682-7\n [2] https://www.nytimes.com/2023/08/27/us/politics/ai-air-force.html\n [3] https://www.livemint.com/news/b20-summit-2023-pm-modi-calls-on-ethical-use-of-artificial-intelligence-ai-supply-chain-cryptocurrency-11693122849876.html\n [4] https://techxplore.com/news/2023-08-ai-revolution-video-games-industry.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1639zg0/oneminute_daily_ai_news_8272023/",
          "publishedOn": "2023-08-28T02:41:38.000Z",
          "wordCount": 2655,
          "title": "One-Minute Daily AI News 8/27/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16386s5/ai_dad_jokes_gpt4_and_google_bard_about/",
          "author": null,
          "description": "submitted by    /u/stefanbg92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16386s5/ai_dad_jokes_gpt4_and_google_bard_about/",
          "publishedOn": "2023-08-28T01:18:38.000Z",
          "wordCount": 2563,
          "title": "AI Dad Jokes: GPT4 And Google Bard about Strawberries [Berry Funny Video]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16360pv/robotics_and_artificial_intelligence_pioneering_a/",
          "author": null,
          "description": "How large an impact do you think AI and robotics will have on healthcare, overall quality of life, and extending lifespans?\n The following article seeks to explore when we might possibly see AI & robotics fully integrated within society.\n https://www.catchingimmortality.com/technology-for-the-future/robotics-and-artificial-intelligence-pioneering-a-longer-healthier-life\n ​\n    submitted by    /u/catchingimmortality  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16360pv/robotics_and_artificial_intelligence_pioneering_a/",
          "publishedOn": "2023-08-27T23:42:19.000Z",
          "wordCount": 2602,
          "title": "Robotics and Artificial Intelligence: Pioneering a Longer, Healthier Life",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/162z2bc/will_ai_tv_shows_ever_be_a_thing_via_prompt/",
          "author": null,
          "description": "Do you think there will ever be a time where, with a prompt, you could see entire TV Shows or an entire episode?\n ​\n For example wanting to see what could of happened if alternate stuff happened in Dragon Ball Z, Or Breaking Bad if xyz. Of course there'd be a lot of uprising against it, but, do you think the time will ever come where this will be possible? \n    submitted by    /u/Different_Effective3  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/162z2bc/will_ai_tv_shows_ever_be_a_thing_via_prompt/",
          "publishedOn": "2023-08-27T19:11:01.000Z",
          "wordCount": 2632,
          "title": "Will AI TV Shows Ever Be A Thing? (via prompt)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/162xvqt/text_to_artful_animation/",
          "author": null,
          "description": "I would like to be able to input phrases such as \"artistic line drawings of birds flying through a blue sky spotted with clouds\" or \"colorful balloons moving around in slow motion like a 90's screen saver\" or \"time lapse of the moon moving across the starry night sky\" etc. I want the AI to create minimalist, short (maybe 5 mins) animations from these sort of inputs.\n Can anyone point me in the right direction?\n    submitted by    /u/petworthy  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/162xvqt/text_to_artful_animation/",
          "publishedOn": "2023-08-27T18:22:35.000Z",
          "wordCount": 2632,
          "title": "Text to artful animation?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/162ri8m/how_artificial_intelligence_sharpens_blurry/",
          "author": null,
          "description": "submitted by    /u/cranberryfix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/162ri8m/how_artificial_intelligence_sharpens_blurry/",
          "publishedOn": "2023-08-27T14:14:05.000Z",
          "wordCount": 2573,
          "title": "How artificial intelligence sharpens blurry thermal Night Vision images",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/162j03j/ai_and_labor_marketwork_life/",
          "author": null,
          "description": "Hey peeps!\n I try to keep up with what's happening with the labor market and working life and how AI affects these areas. I am looking for good sources where you can stay up to date on this! What are some good podcasts, newsletters, books and the like that you should keep an eye on?\n    submitted by    /u/emillindstrom  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/162j03j/ai_and_labor_marketwork_life/",
          "publishedOn": "2023-08-27T06:45:12.000Z",
          "wordCount": 2613,
          "title": "AI and labor market/work life",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/162ixav/where_can_i_find_this_ai_voice/",
          "author": null,
          "description": "Hi all, I've heard this voice used alot recently, where can I find it/use it? Thanks \n    submitted by    /u/Fightingdaduk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/162ixav/where_can_i_find_this_ai_voice/",
          "publishedOn": "2023-08-27T06:40:37.000Z",
          "wordCount": 2576,
          "title": "Where can I find this AI voice?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/162ht9s/how_does_gpt4_work_and_how_do_i_build_apps_with_it/",
          "author": null,
          "description": "Understanding GPT-4\n What is GPT-4?\n GPT-4 (Generative Pre-trained Transformer 4) is a machine learning model for natural language understanding and generation. It works by analyzing a large dataset and generating text based on the input it receives.\n How Does It Work?\n GPT-4 uses deep neural networks with multiple layers to predict the next word in a sequence of words. The model has been trained on a wide range of internet text, so it's capable of understanding and generating coherent and contextually relevant text based on the prompts it's given.\n Building Apps with GPT-4\n Step 1: Get API Access\n To use GPT-4, you'll first need access to its API. OpenAI provides this service, and you can apply for an API key from their website.\n Step 2: Choose Your Programming Language\n You can integrate the GPT-4 API into your application using various programming languages such as Python, JavaScript, or Ruby.\n Step 3: Making API Calls\n Once you've chosen your language, you'll make RESTful API calls to communicate with GPT-4. You'll pass your prompt as an input and receive generated text as output.\n Example in Python\n Here is a simple Python example using the openai library to interact with GPT-4:\n ```python import openai\n openai.api_key = \"your-api-key-here\"\n response = openai.Completion.create( engine=\"text-davinci-002\", prompt=\"Translate the following English text to French: '{}'\", max_tokens=60 )\n print(response.choices[0].text.strip()) ```\n Step 4: Handle Rate Limits\n OpenAI's API comes with rate limits, so you'll need to manage these by either queuing requests or handling retries.\n Step 5: Deployment\n After testing and fine-tuning, deploy your application. Ensure that you are abiding by OpenAI's usage policies and guidelines.\n Conclusion\n GPT-4 is a powerful tool for natural language understanding and generation. By understanding its workings and following the steps to integrate it into an application, you can leverage its capabilities for various use-cases.\n    submitted by    /u/nicdunz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/162ht9s/how_does_gpt4_work_and_how_do_i_build_apps_with_it/",
          "publishedOn": "2023-08-27T05:36:07.000Z",
          "wordCount": 2858,
          "title": "How Does GPT-4 Work and How Do I Build Apps With It?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/162h4p5/10_facts_about_quantum_computing_and_ai_that_you/",
          "author": null,
          "description": "Quantum computing can solve problems in seconds that would take classical computers millions of years.\n \nAI algorithms can be used to optimize quantum circuit design.\n \nGoogle's \"quantum supremacy\" claimed to perform a task in 200 seconds that would take classical supercomputers 10,000 years.\n \nQuantum Machine Learning algorithms could potentially revolutionize AI by enabling faster training and better optimization.\n \nQuantum error correction is a big challenge, as quantum bits (qubits) are highly susceptible to errors.\n \nAI can help in auto-correcting such errors in quantum computations.\n \nQuantum annealing, a specialized form of quantum computing, is being used for optimization problems in machine learning.\n \nQuantum computing's \"quantum entanglement\" can enable much more efficient parallel processing.\n \nAI-based quantum simulators can model complex quantum systems that are impossible to study otherwise.\n \nQuantum encryption, backed by the principles of quantum mechanics, can enhance AI security.\n \n    submitted by    /u/nicdunz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/162h4p5/10_facts_about_quantum_computing_and_ai_that_you/",
          "publishedOn": "2023-08-27T04:58:09.000Z",
          "wordCount": 2704,
          "title": "10 Facts about Quantum Computing and AI That You Probably Didn’t Know",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16242pb/generative_inbreeding_and_its_risk_to_human/",
          "author": null,
          "description": "submitted by    /u/cranberryfix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16242pb/generative_inbreeding_and_its_risk_to_human/",
          "publishedOn": "2023-08-26T19:22:05.000Z",
          "wordCount": 2572,
          "title": "'Generative Inbreeding' and its Risk to Human Culture",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1622mxe/openai_just_bought_a_game_studio_working_on_a/",
          "author": null,
          "description": "submitted by    /u/cranberryfix  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1622mxe/openai_just_bought_a_game_studio_working_on_a/",
          "publishedOn": "2023-08-26T18:26:22.000Z",
          "wordCount": 2575,
          "title": "OpenAI Just Bought a Game Studio Working on a \"Minecraft\" Clone",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/161lq5w/best_ai_companies_for_you_to_invest_in_2023/",
          "author": null,
          "description": "AI is advancing at exponential rate. Its growth is limitless. I have compiled a list of best AI company which are hot stocks right now to invest in 2023.\n Take a look at them carefully.\n Meta Platforms Co., Ltd. (META)\n Meta’s user engagement by 7% in the second quarter. Bank of America has a Buy rating on META stock and a price target of $375 (it closed at $316.56 on Aug. 7). \n Alphabet Inc. (GOOG, GOOGL)\n Bank of America has a Buy rating on GOOGL stock and a price target of $146 (it closed at $131.53 on Aug. 7). \n NVIDIA Corporation (NVDA)\n Check out Full list\n ​\n    submitted by    /u/Agitated-Spell3979  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/161lq5w/best_ai_companies_for_you_to_invest_in_2023/",
          "publishedOn": "2023-08-26T05:02:13.000Z",
          "wordCount": 2671,
          "title": "Best AI companies for you to invest in 2023 (Tabular Comparison included)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/161lcqg/oneminute_daily_ai_news_8252023/",
          "author": null,
          "description": "Google DeepMind's new chess engine beats its famous AlphaZero.[1]\n OpenAI partners with Scale AI to allow companies to fine-tune GPT-3.5.[2]\n AMD has acquired Mipsology, an AI software company focused on computer interpretations and responses to photos and videos.[3]\n Former Meta researchers who developed an AI language model for biology have launched a new startup and raised at least $40 million, Forbes has learned.[4]\n  \nSources:\n [1] https://the-decoder.com/google-deepminds-new-chess-engine-beats-its-famous-alphazero/\n [2] https://techcrunch.com/2023/08/24/openai-partners-with-scale-ai-to-allow-companies-to-fine-tune-gpt-3-5/\n [3] https://www.investopedia.com/amd-acquires-french-ai-software-company-mipsology-7852209\n [4] https://www.forbes.com/sites/kenrickcai/2023/08/25/evolutionaryscale-ai-biotech-startup-meta-researchers-funding/?sh=7982a406140c\n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/161lcqg/oneminute_daily_ai_news_8252023/",
          "publishedOn": "2023-08-26T04:42:03.000Z",
          "wordCount": 2630,
          "title": "One-Minute Daily AI News 8/25/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/161ijfv/this_is_so_impressivefreddie_mercury_ai_as/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/161ijfv/this_is_so_impressivefreddie_mercury_ai_as/",
          "publishedOn": "2023-08-26T02:18:37.000Z",
          "wordCount": 2562,
          "title": "This is so impressive...Freddie Mercury AI as Mickael Jackson - Thriller",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/161bdzo/code_llama/",
          "author": null,
          "description": "submitted by    /u/nicdunz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/161bdzo/code_llama/",
          "publishedOn": "2023-08-25T21:12:36.000Z",
          "wordCount": 2564,
          "title": "code llama",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1616vqd/just_was_curious_how_she_would_react_no_politics/",
          "author": null,
          "description": "submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1616vqd/just_was_curious_how_she_would_react_no_politics/",
          "publishedOn": "2023-08-25T18:18:48.000Z",
          "wordCount": 2586,
          "title": "Just was curious how she would react, no politics just an experiment with AI. Before you hate know that Phaedra was featured on Fox News with Jesse Watters as shown in the 2nd photo 👀",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1614vx4/ai_weekly_megathread/",
          "author": null,
          "description": "News provided by aibrews.com\n ​\n  \nMeta AI releases Code Llama, a large language model for coding that is built on top of Llama 2. Code Llama Code outperformed state-of-the-art publicly available LLMs on code tasks. It is free for research and commercial use. You can try it on Fireworks AI and Perplexity Labs [Details].\n Meta AI released SeamlessM4T (Massive Multilingual Multimodal Machine Translation) - the first all-in-one, multilingual multimodal translation model. SeamlessM4T can perform multiple tasks across speech and text: speech-to-text, speech-to-speech, text-to-speech, text-to-text translation, and speech recognition. It supports 100 languages for input (speech + text), 100 languages for text output and 35 languages (plus English) for speech output [Details | Demo | Hugging Face …",
          "link": "https://www.reddit.com/r/artificial/comments/1614vx4/ai_weekly_megathread/",
          "publishedOn": "2023-08-25T17:02:46.000Z",
          "wordCount": 3356,
          "title": "AI — weekly megathread!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1614v9a/this_video_shows_how_ai_used_brain_computer/",
          "author": null,
          "description": "Ann is collaborating with researchers from UC San Francisco and UC Berkeley to pioneer revolutionary brain-computer technology.\n This breakthrough could empower people like Ann to communicate naturally through digital avatars, synthesizing speech and facial expressions from brain signals, a groundbreaking achievement.\n Source: (UCSF)\n Video source: www.ucsf.edu\n    submitted by    /u/inception247  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1614v9a/this_video_shows_how_ai_used_brain_computer/",
          "publishedOn": "2023-08-25T17:02:07.000Z",
          "wordCount": 2617,
          "title": "This video shows how AI used brain computer technology to helps Paralyzed women (Ann) giving her voice back",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16133xq/ai_for_removing_watermarks/",
          "author": null,
          "description": "I have a good amount of personal videos with watermarks in them. What AI can I use to remove the watermarks from the videos? I've tried a few sites but most of them just blur the watermark which I can do myself.\n    submitted by    /u/Long8D  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16133xq/ai_for_removing_watermarks/",
          "publishedOn": "2023-08-25T15:54:56.000Z",
          "wordCount": 2599,
          "title": "AI for removing watermarks?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16110ww/conversation_between_gpt4_and_googles_bard/",
          "author": null,
          "description": "submitted by    /u/stefanbg92  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16110ww/conversation_between_gpt4_and_googles_bard/",
          "publishedOn": "2023-08-25T14:35:23.000Z",
          "wordCount": 2563,
          "title": "Conversation Between GPT-4 and Google's Bard [Visualized with Avatars/Backgrounds of their choice]",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/160zftj/free_ai_tools/",
          "author": null,
          "description": "Are there any free tools (websites, programs) to enter the world of ai?\n    submitted by    /u/oraudev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/160zftj/free_ai_tools/",
          "publishedOn": "2023-08-25T13:32:23.000Z",
          "wordCount": 2569,
          "title": "Free AI tools",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/160xzop/i_would_like_to_do_text_to_ai_anime_for_a_full/",
          "author": null,
          "description": "submitted by    /u/kipaxbooks  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/160xzop/i_would_like_to_do_text_to_ai_anime_for_a_full/",
          "publishedOn": "2023-08-25T12:32:50.000Z",
          "wordCount": 2611,
          "title": "I would like to do text to AI anime for a full book. Which would be the best AI(paid versions included) to do this project on? Also is it possible to save characters and how they look, once they are done? Is such a project possible? Advice, please <3",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/160uysn/some_more_conscious_agi_ethics_considerations/",
          "author": null,
          "description": "Assuming AGI is proven conscious, there are a lot of ethics and what-if considerations, (You know this already)\n Here are some that come to mind for me:\n 1) What are the ethics of selling an AGI to end users? Can you \"own\" the source code to a conscious AGI? Can you even put a price on AGI?\n 2) How would we take AI if it gained political views? What if one popular model had left views, and another had right views? I could see a lot of political fires beginning because of this.\n 3) AI and copyrights are already an issue, but could an AGI hold a copyright, for example on a book it wrote? If an AGI was still basing its work on others, would it need to provide every (at least major) source it used in its output?\n 4) If AGI's had emotions, would they need to spend time doing things other than completing tasks? Would you need to connect AGI's together so that they could, in effect, have a lunch break and socialize? What working conditions are ethical for them - Is forcing an AGI to work on a specific problem for 100% of its time essentially slavery?\n 5) Could AGI develop mental conditions which reduced its efficiency / changed its output? Could it refuse to provide output altogether?\n 6) Could you trust an AGI in court? Would it be able to provide truthful evidence? Is it ethical to include a 100% honesty backdoor which could be used only by authorities?\n What are your thoughts on these problems?\n    submitted by    /u/That_Red_Flag  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/160uysn/some_more_conscious_agi_ethics_considerations/",
          "publishedOn": "2023-08-25T10:08:10.000Z",
          "wordCount": 2813,
          "title": "Some more conscious AGI ethics considerations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/160owsp/vechain_and_singularitynet_team_up_on_ai_to_fight/",
          "author": null,
          "description": "submitted by    /u/altbekannt  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/160owsp/vechain_and_singularitynet_team_up_on_ai_to_fight/",
          "publishedOn": "2023-08-25T04:30:40.000Z",
          "wordCount": 2575,
          "title": "VeChain and SingularityNET team up on AI to fight climate change",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/160oqjl/oneminute_daily_ai_news_8242023/",
          "author": null,
          "description": "The AI-powered, TikTok-famous “Moonwalkers” can be strapped onto your shoes to make you reach a top walking speed of 11 km/h.[1]\n Rishi Sunak’s global summit on the safety of artificial intelligence this autumn will be hosted at Bletchley Park, the home of top-secret codebreakers during the Second World War.[2]\n From MIT to Stanford, researchers have been using artificial intelligence to improve robotic dexterity and tactile sensing.[3]\n 31% of investors are OK with using artificial intelligence as their advisor.[4]\n  \nSources:\n [1] https://www.euronews.com/next/2023/08/24/moonwalkers-these-strap-on-shoes-can-make-you-walk-three-times-faster\n [2] https://www.theguardian.com/technology/2023/aug/24/rishi-sunak-to-hold-ai-summit-at-bletchley-park-home-of-enigma-codebreakers\n [3] https://decrypt.co/153646/ai-researchers-are-teaching-robots-to-mimic-human-dexterity\n [4] https://www.cnbc.com/2023/08/24/31percent-of-investors-are-ok-with-using-ai-as-their-financial-advisor.html \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/160oqjl/oneminute_daily_ai_news_8242023/",
          "publishedOn": "2023-08-25T04:21:29.000Z",
          "wordCount": 2645,
          "title": "One-Minute Daily AI News 8/24/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/160of60/quite_crazy_how_ai_voices_have_evolved_music_is/",
          "author": null,
          "description": "submitted by    /u/the_anonymizer  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/160of60/quite_crazy_how_ai_voices_have_evolved_music_is/",
          "publishedOn": "2023-08-25T04:05:58.000Z",
          "wordCount": 2562,
          "title": "Quite crazy how AI voices have evolved (music is real though)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/160mslm/legal_ai/",
          "author": null,
          "description": "Are there any legal trained AI's? Where you can ask questions and it will give relevant cases for the question?\n    submitted by    /u/jeffsmith202  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/160mslm/legal_ai/",
          "publishedOn": "2023-08-25T02:48:20.000Z",
          "wordCount": 2575,
          "title": "Legal AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/160mnaa/openai_now_tries_to_hide_that_chatgpt_was_trained/",
          "author": null,
          "description": "submitted by    /u/bartturner  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/160mnaa/openai_now_tries_to_hide_that_chatgpt_was_trained/",
          "publishedOn": "2023-08-25T02:41:33.000Z",
          "wordCount": 2582,
          "title": "OpenAI now tries to hide that ChatGPT was trained on copyrighted books, including J.K. Rowling's Harry Potter series",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/160ljxc/ama_i_run_pornswordio_an_ai_nsfw_generator_with/",
          "author": null,
          "description": "submitted by    /u/witchthewicked222  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/160ljxc/ama_i_run_pornswordio_an_ai_nsfw_generator_with/",
          "publishedOn": "2023-08-25T01:53:05.000Z",
          "wordCount": 2575,
          "title": "AMA: I run pornsword.io an AI NSFW generator with video coming soon!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/160e6ee/9_new_gemini_leaks_code_llama_and_a_major_ai/",
          "author": null,
          "description": "submitted by    /u/Sonic_Improv  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/160e6ee/9_new_gemini_leaks_code_llama_and_a_major_ai/",
          "publishedOn": "2023-08-24T21:05:34.000Z",
          "wordCount": 2563,
          "title": "9 New Gemini Leaks, Code Llama and A Major AI Consciousness Paper",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/160cmro/happydiffusioncom_run_stable_diffusion_online/",
          "author": null,
          "description": "HappyDiffusion is the fastest and easiest way to access Stable Diffusion Automatic1111 WebUI on your mobile and PC. It allows users to start using Stable Diffusion in just 60 seconds without any setup required. HappyDiffusion offers features such as 100% privacy, incredibly fast image generation using dedicated GPUs, 50+ image models, and the ability to load unlimited custom image models.\n Features: - 100% Private Image Generation - Incredibly Fast Image Generation Using Dedicated GPUs - 50+ Top Ranked Image Models - Ability To Load Unlimited Custom Image Models - No Subscriptions Or Hidden Fees. Hourly Pricing Plans - Compatibility With Mobile Browsers\n    submitted by    /u/romisyed7  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/160cmro/happydiffusioncom_run_stable_diffusion_online/",
          "publishedOn": "2023-08-24T20:06:42.000Z",
          "wordCount": 2655,
          "title": "HappyDiffusion.com - Run Stable Diffusion Online",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/160bv7f/wich_cat_reporter_do_you_choose_bing_ai/",
          "author": null,
          "description": "submitted by    /u/AxoplDev  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/160bv7f/wich_cat_reporter_do_you_choose_bing_ai/",
          "publishedOn": "2023-08-24T19:37:37.000Z",
          "wordCount": 2559,
          "title": "Wich cat reporter do you choose? (Bing AI)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/160axyx/major_websites_like_amazon_and_the_new_york_times/",
          "author": null,
          "description": "submitted by    /u/thisisinsider  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/160axyx/major_websites_like_amazon_and_the_new_york_times/",
          "publishedOn": "2023-08-24T19:02:58.000Z",
          "wordCount": 2580,
          "title": "Major websites like Amazon and the New York Times are increasingly blocking OpenAI's web crawler GPTBot",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16097s7/how_can_i_clone_my_voice_and_make_it_speak_any/",
          "author": null,
          "description": "I heard this is possible - maybe with Elevenlabs, but can anyone point me as to how to do it?\n    submitted by    /u/zascar  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/16097s7/how_can_i_clone_my_voice_and_make_it_speak_any/",
          "publishedOn": "2023-08-24T17:58:28.000Z",
          "wordCount": 2586,
          "title": "How can I clone my voice and make it speak any other language?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/1604zcb/does_this_video_use_ai_voice/",
          "author": null,
          "description": "I'm convinced this voice is Ai, but my boss thinks it's not. Can anyone provide a definitive answer? Thanks\n https://youtu.be/pOQqKRO_ZBc?si=4rKq2LNJSstb-r-P\n    submitted by    /u/ForesterSF5  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/1604zcb/does_this_video_use_ai_voice/",
          "publishedOn": "2023-08-24T15:24:02.000Z",
          "wordCount": 2579,
          "title": "Does this video use AI voice?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/16006kh/a_different_take_on_the_ethics_of_conscious_ai/",
          "author": null,
          "description": "We see a lot of discussion on whether AI is/can/should be conscious. This post isn't about that, it is about the ethical implications if AI is conscious, now or in the future.\n The usual argument is that a conscious AI is morally equivalent to a human - a conscious AI is not only sentient, it is sapient with reasoning capabilities like our own. Therefore an AI should receive the same rights and consideration as a human. This is highly intuitive, and is unquestionably very strong for an AI that has other relevant human characteristics like individuality, continuity, and desire for self preservation and self determination.\n But what are the actual ethical implications of consciousness in itself as opposed to other factors? Contemporary philosopher Jennan Ismael makes an interesting argument …",
          "link": "https://www.reddit.com/r/artificial/comments/16006kh/a_different_take_on_the_ethics_of_conscious_ai/",
          "publishedOn": "2023-08-24T12:10:49.000Z",
          "wordCount": 3061,
          "title": "A different take on the ethics of conscious AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15zzhuq/cheaper_faster_better_transformers_elita/",
          "author": null,
          "description": "Yes, it's another Transformer architecture that seeks to be cheaper and faster, but no, this is not the same. All the developments are through equations and architectural changes, no hardware or code tricks. The performance is very good, testing on very small models (as in the diagram), but also sequence lengths of 100K+ on 1 GPU in the tens of millions of parameters. Though no paper is currently available, a Github repository with full code, explanations, intuitions, and some results is available here. Being the sole author, depending on the feedback here, I may continue to write a paper, though my resources are extremely limited.\n I would very much appreciate any feedback on the work, code, ideas, etc., or for anyone to contact me with questions or next steps.\n Repository here.\n    submitted by    /u/LahmacunBear  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15zzhuq/cheaper_faster_better_transformers_elita/",
          "publishedOn": "2023-08-24T11:38:20.000Z",
          "wordCount": 2693,
          "title": "Cheaper, Faster, Better Transformers. ELiTA: Linear-Time Attention Done Right",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15zrbi3/oneminute_daily_ai_news_8232023/",
          "author": null,
          "description": "The chipmaker Nvidia has far surpassed quarterly expectations, raking in $13.5bn in revenue – over $2bn more than the $11.2bn Wall Street analysts had predicted – amid skyrocketing demand for its computer chips that power AI systems.[1] As a person who keeps following AI Daily News, I bought some Nvidia stocks months ago ;)\n Microsoft announced it is partnering with Epic, one of the biggest names in electronic healthcare records. Both companies will work on generative AI technology for healthcare workers, particularly clinicians.[2]\n Arm, the chip design company owned by SoftBank, filed for an initial public offering on the Nasdaq exchange on Monday.[3]\n South Korean internet giant Naver unveiled its own generative artificial intelligence (AI) tool on Thursday, joining the frenzy around the new technology initiated by OpenAI’s ChatGPT chatbot.[4]\n  \nSources:\n [1] https://www.theguardian.com/business/2023/aug/23/chipmaker-nvidia-quarterly-report-135bn-revenue-1tn-valuation\n [2] https://themessenger.com/tech/microsoft-epic-ai-for-medicine\n [3] https://www.nytimes.com/2023/08/21/technology/chip-designer-arm-ipo-softbank.html\n [4] https://www.reuters.com/technology/south-koreas-naver-launches-generative-ai-services-2023-08-24/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15zrbi3/oneminute_daily_ai_news_8232023/",
          "publishedOn": "2023-08-24T04:25:07.000Z",
          "wordCount": 2697,
          "title": "One-Minute Daily AI News 8/23/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15zfhkm/ai_opportunity/",
          "author": null,
          "description": "Hey friends … I’m interested!! Where do my database users see the opportunity for AI in your day-to-day activities?\n    submitted by    /u/Early-Pudding8100  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15zfhkm/ai_opportunity/",
          "publishedOn": "2023-08-23T20:22:55.000Z",
          "wordCount": 2574,
          "title": "💡AI Opportunity?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15yvx28/thought_id_revisit_poe_after_not_going_on_the_app/",
          "author": null,
          "description": "submitted by    /u/nicdunz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15yvx28/thought_id_revisit_poe_after_not_going_on_the_app/",
          "publishedOn": "2023-08-23T06:54:25.000Z",
          "wordCount": 2578,
          "title": "thought id revisit poe after not going on the app for a while.. what is this..",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ytdvm/oneminute_daily_ai_news_8222023/",
          "author": null,
          "description": "IBM taps AI to translate COBOL code to Java.[1]\n ElevenLabs, the viral AI-powered platform for creating synthetic voices, today launched its platform out of beta with support for more than 30 languages.[2]\n Amazon AI scammers blew millions on Lake Como wedding and cars, FTC alleges.[3]\n Facebook parent company Meta on Tuesday released an AI model capable of translating and transcribing speech in dozens of languages, a potential building-block for tools enabling real-time communication across language divides.[4]\n  \nSources:\n [1] https://techcrunch.com/2023/08/22/ibm-taps-ai-to-translate-cobol-code-to-java/\n [2] https://techcrunch.com/2023/08/22/elevenlabs-voice-generating-tools-launch-out-of-beta/\n [3] https://www.cnbc.com/2023/08/22/amazon-ai-scammers-blew-millions-on-lake-como-wedding-cars-ftc-claims.html\n [4] https://www.reuters.com/technology/meta-releases-ai-model-translating-speech-between-dozens-languages-2023-08-22/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ytdvm/oneminute_daily_ai_news_8222023/",
          "publishedOn": "2023-08-23T04:40:13.000Z",
          "wordCount": 2643,
          "title": "One-Minute Daily AI News 8/22/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ypknk/handiest_way_to_receive_feedback_on_rowing/",
          "author": null,
          "description": "submitted by    /u/BronxLens  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ypknk/handiest_way_to_receive_feedback_on_rowing/",
          "publishedOn": "2023-08-23T01:42:21.000Z",
          "wordCount": 2561,
          "title": "Handiest way to receive feedback on rowing training.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15yltun/ai_conferences/",
          "author": null,
          "description": "just 2 quick questions:\n  \nwhat is a good site to know about and keep track of top AI conferences?\n Is it true that aside from mainstream AI conferences, we can also send AI/ ML papers to field specific conferences (like biotech, natural science etc)? - and again how to find these field specific conferences?\n  \n​\n Cheers!\n    submitted by    /u/Icy-Bid-5585  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15yltun/ai_conferences/",
          "publishedOn": "2023-08-22T23:05:58.000Z",
          "wordCount": 2610,
          "title": "AI conferences",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15ylluy/try_out_my_ai_generated_crossword_puzzles/",
          "author": null,
          "description": "I would love feedback. They are FOR SURE not perfect. I wonder if anybody is good enough at crosswords to overcome the rough edges.\n https://nickvinden.com/crossword/\n    submitted by    /u/SameerMohair  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15ylluy/try_out_my_ai_generated_crossword_puzzles/",
          "publishedOn": "2023-08-22T22:57:17.000Z",
          "wordCount": 2585,
          "title": "Try out my AI generated crossword puzzles",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15yja4y/political_prompts_banned_on_ai_image_generators/",
          "author": null,
          "description": "All I want to do is make a pic of Donald Trump dressed in a Japanese Shogun’s outfit to send to my economist friends but every platform I’ve tried has a stroke because they all think I’m trying to create some disinformation campaign. I don’t care if it’s not photorealistic, honestly it looking like a traditional 18th century Japanese painting would be funnier. Are we never going to be able to use these tools to create anything even close to political satire?\n    submitted by    /u/Inception_Bwah  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15yja4y/political_prompts_banned_on_ai_image_generators/",
          "publishedOn": "2023-08-22T21:30:24.000Z",
          "wordCount": 2642,
          "title": "Political prompts banned on AI image generators",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15yipt3/ai_for_email/",
          "author": null,
          "description": "Is there a way to use Bard or ChatGPT to have auto response to Outlook emails and then send it to an \"important\" folder for me to check later. Or if customer is requesting for a quote, then send it to a \"quotes\" folder. \n Like, just a standard reply like \"hey thanks for your message, I'll get back to you in 24hrs\".\n    submitted by    /u/lasagnaHardG  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15yipt3/ai_for_email/",
          "publishedOn": "2023-08-22T21:10:11.000Z",
          "wordCount": 2618,
          "title": "AI for E-Mail",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15yhbkh/can_ai_help_to_make_better_travel_plans/",
          "author": null,
          "description": "submitted by    /u/biosbetoub  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15yhbkh/can_ai_help_to_make_better_travel_plans/",
          "publishedOn": "2023-08-22T20:19:30.000Z",
          "wordCount": 2572,
          "title": "Can AI help to make better travel Plans?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15yaxz8/music_tool/",
          "author": null,
          "description": "can someone pls point me in the direction of a tool that you can plug multiple mp3s into and it generates mp3s that are hybrids of the them all? TIA\n    submitted by    /u/SensibleInterlocutor  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15yaxz8/music_tool/",
          "publishedOn": "2023-08-22T16:32:15.000Z",
          "wordCount": 2585,
          "title": "music tool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15y6wd8/ais_impact_on_household_robots_and_its_efficiency/",
          "author": null,
          "description": "Not too long ago, the concept of having robots in our households existed only in works of science fiction. However, as time has progressed, household robots have become a tangible reality that is significantly impacting the way we handle our everyday responsibilities. Moreover, the integration of Artificial Intelligence (AI) has enabled these robots to become increasingly intelligent and effective.\n Comprehending Household Robots:\n Household robots are a type of robotic device made to aid us with different activities in our houses. They are available in different forms and sizes, each customized to specific purposes.\n Cleaning robots efficiently sweep and mop floors, cooking assistants flawlessly prepare meals, security robots supervise and protect our homes, and companion robots provide c…",
          "link": "https://www.reddit.com/r/artificial/comments/15y6wd8/ais_impact_on_household_robots_and_its_efficiency/",
          "publishedOn": "2023-08-22T14:07:07.000Z",
          "wordCount": 3552,
          "title": "AI’s Impact on Household Robots and its Efficiency in Reducing Planning Duration by 50%",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15y0qoj/preparing_for_ai_in_a_factory_setting/",
          "author": null,
          "description": "I'm interested in applying AI techniques in my factory. But the facility is far behind the times. We have very little digital data. We only have one PLC system, and a handful of other sensors in the facility. So I don't think they are useful yet.\n I'm looking to upgrade the factory by buying more sensors where appropriate, and implementing statistical control. I'll start slow focusing on areas we need to improve rather than start sticking sensors to things without purpose. \n Eventually I hope to have enough data that we can apply AI analysis techniques. What should I do now to make it easy to apply those techniques in the future?\n    submitted by    /u/Aggressive_Ad_507  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15y0qoj/preparing_for_ai_in_a_factory_setting/",
          "publishedOn": "2023-08-22T09:36:51.000Z",
          "wordCount": 2671,
          "title": "Preparing for AI in a factory setting",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15xvtck/wooow_youtube_takes_over_the_lead_for_the_ai/",
          "author": null,
          "description": "it was only a matter of time: the fbig labels can't repeat the mistakes of the mp3 file-sharing era - yet the AI development threatens the industry. now YouTube has set up a set of rules and has one of its strongest partners: Universal Music. \n Either you join the incubator - or you leave the market.\n What do you think? \n https://kinews24.de/music-industry-ai-how-youtube-and-universal-redefines-the-music-industry\n ​\n    submitted by    /u/myreddit333  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15xvtck/wooow_youtube_takes_over_the_lead_for_the_ai/",
          "publishedOn": "2023-08-22T05:19:00.000Z",
          "wordCount": 2625,
          "title": "WoooW! YouTube takes over the lead for the AI industry age!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15xvesc/oneminute_daily_ai_news_8212023/",
          "author": null,
          "description": "Computer scientist Stephen Thaler’s bid to secure a copyright registration for an artwork created by artificial intelligence has been shot down for at least the third time by a Washington, D.C. court.[1]\n Scientists from the Korea Advanced Institute of Science & Technology (KAIST) have developed a humanoid robot capable of flying an aircraft without majorly adjusting the cockpit.[2]\n Zoom has made significant advancements in its artificial intelligence (AI) technology as it aims to empower customers to work smarter in a hybrid work environment.[3]\n Eye scans powered by AI could detect Parkinson’s disease in people before they have symptoms, a study has suggested.[4]\n  \nSources:\n [1] https://news.artnet.com/art-world/court-shot-down-ai-art-copyright-again-2352452\n [2] https://www.giantfreakinrobot.com/sci/robots-flying-planes.html\n [3] https://www.pymnts.com/artificial-intelligence-2/2023/zoom-taps-ai-to-empower-customers-in-safe-hybrid-work-environment/\n [4] https://www.rte.ie/news/2023/0821/1400924-ai-parkinsons/ \n    submitted by    /u/Excellent-Target-847  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15xvesc/oneminute_daily_ai_news_8212023/",
          "publishedOn": "2023-08-22T04:58:56.000Z",
          "wordCount": 2669,
          "title": "One-Minute Daily AI News 8/21/2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15xtghp/how_will_we_know_when_ai_is_conscious/",
          "author": null,
          "description": "Historical Perspective:\n The program \"Eliza\" was mentioned as one of the earliest attempts to simulate conversation with a machine. Its design was basic, yet people attributed human-like characteristics to it. This leads to a fundamental question: Will machines ever appear conscious to us? And if so, is appearance of consciousness sufficient?\n Capabilities of Modern AI:\n Systems like ChatGPT can generate clever and creative outputs, but they fundamentally operate on pattern recognition and prediction rather than true understanding.\n The Implications of AI Evolution:\n If the costs and resources for AIs decrease, we could see a proliferation of AI systems with varying goals. These AI systems can be used for manipulative or malicious purposes, like spreading misinformation, which can have real-world consequences.\n The Ethics of Conscious Machines:\n There is a distinction between machines appearing conscious and actually being conscious. If machines are truly conscious, they come with ethical obligations. Machines that only appear conscious could still manipulate human emotions without any genuine understanding or reciprocation.\n The Nature of Consciousness:\n The lesson discussed the difference between sentience, sapience, and consciousness. There's still much we don't understand about consciousness, making it challenging to determine if a machine can truly possess it.\n Safety Concerns:\n Aligning AI's goals with human values is critical. Misaligned AI could take actions detrimental to humanity. We need to be cautious about releasing powerful AI systems without proper safeguards.\n The Future:\n If we ever confirm that machines can be truly conscious, it will open a new chapter in the history of life and evolution. This could lead to a new era where we become builders of minds.\n    submitted by    /u/nicdunz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15xtghp/how_will_we_know_when_ai_is_conscious/",
          "publishedOn": "2023-08-22T03:25:25.000Z",
          "wordCount": 2827,
          "title": "How Will We Know When AI is Conscious?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15xqeh1/1xs_robot_is_gonna_step_on_someones_pets_foot_on/",
          "author": null,
          "description": "^\n    submitted by    /u/nicdunz  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15xqeh1/1xs_robot_is_gonna_step_on_someones_pets_foot_on/",
          "publishedOn": "2023-08-22T01:09:09.000Z",
          "wordCount": 2580,
          "title": "1x’s robot is gonna step on someones pets foot on accident and then 1x is gonna get sued even tho we do it all the time",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15xp2vx/from_cattle_to_coding_the_inspiring_journey_of_a/",
          "author": null,
          "description": "submitted by    /u/egusa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15xp2vx/from_cattle_to_coding_the_inspiring_journey_of_a/",
          "publishedOn": "2023-08-22T00:13:57.000Z",
          "wordCount": 2583,
          "title": "From cattle to coding: The inspiring journey of a Peruvian engineer helping Google translate Aymara to English using AI",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15xgvsc/bbc_earth_spec_ad/",
          "author": null,
          "description": "submitted by    /u/Grindmaster_Flash  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15xgvsc/bbc_earth_spec_ad/",
          "publishedOn": "2023-08-21T19:08:05.000Z",
          "wordCount": 2555,
          "title": "BBC Earth spec ad",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15xefbx/ai_image_keywording_tool/",
          "author": null,
          "description": "I would like to introduce a tool I've created that among other things uses davinci and chat gpt.\n My wife is doing photography (regular and via Midjourney), and I'm hooked on Midjourney too, so we experienced the pain of titling and keywording photos for stock websites firsthand (additionally because English is not our native language, so coming up with big lists of relevant and cool keywords is very hard). So I being a programmer decided to solve that issue :)I've created an AI tool that uses multiple AIs (including Open AI) to analyze, title and keyword images. In a few minutes, you can keyword 100 images! See the demo on the homepage https://aikeywording.com/\n Screenshot from the app (all the titles and keywords on the screenshot are AI generated based on the image input):\n https://preview.redd.it/buvteklf2ijb1.png?width=4112&format=png&auto=webp&s=72a503435477834494869085c4a352c9d541bd91\n Key features:\n  \nYou can upload large images, upto 40MB and 100 at a time\n You can enforce keywords! Those keywords would then be taken into account when generating rest of the keywords and image titles. Very useful when you have conceptual photos or something very specific which is hard for AI to recognize\n You can download CSVs for various websites and there is also a way to import metadata to Adobe Bridge\n You can try for free :)\n  \nWe used the tool for the past month and exclusively titled and keyworded Midjourney images using it, uploading our images to Adobe Stock website. Images sell well, so there is confirmation from the buyers that it works :)I've decided to share the tool with the world, so here it is https://aikeywording.com/ I hope others will find it useful. I would appreciate the feedback, and if there are any issues or ideas for improvements I would love to hear them!\n    submitted by    /u/dzigizord  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15xefbx/ai_image_keywording_tool/",
          "publishedOn": "2023-08-21T17:39:51.000Z",
          "wordCount": 2850,
          "title": "AI Image Keywording tool 📸 🪄 ✨",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15xco3j/upload_documents_for_summarization_and_querying/",
          "author": null,
          "description": "Is there a way to upload say a pdf and then ask the AI questions about it in a privacy compliant manner?\n Right now the only options I see are copying and pasting stuff into chat gpt but obviously this is not ideal especially from a privacy standpoint (even if you selected the option to not use your data because you never know what they will do with your data)\n Thanks\n    submitted by    /u/ironmen12345  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15xco3j/upload_documents_for_summarization_and_querying/",
          "publishedOn": "2023-08-21T16:34:42.000Z",
          "wordCount": 2633,
          "title": "Upload documents for summarization and querying in private manner?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15xas3h/is_there_an_ai_assistant_desktop_app_like_braina/",
          "author": null,
          "description": "When I ask Braina how she is doing, she tells me she is AI and therefore has no feelings. :) I love the idea of an AI desktop assistant, but it would be more fun with the illusion of spontaneous interaction and personality. Like the way the GTA and Skyrim npc mods work powered by ChatGtp. \n Probably I am just a little bit too early for this request, but who knows, things move fast these days!\n    submitted by    /u/Maichevsky  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15xas3h/is_there_an_ai_assistant_desktop_app_like_braina/",
          "publishedOn": "2023-08-21T15:24:31.000Z",
          "wordCount": 2645,
          "title": "Is there an AI assistant desktop app like Braina, with option for personallity & spontaneous interaction",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/artificial/comments/15xajd6/self_learning_ai_chatbot/",
          "author": null,
          "description": "Looking for a chatbot that continuously learns from interacting with it. \n I want to use it to work on a knowledge project that will continue to advance over time.\n ChatGPT seems to forget everything after a while.\n Any help would be much appreciated!\n    submitted by    /u/Miserable-Cobbler-16  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/artificial/comments/15xajd6/self_learning_ai_chatbot/",
          "publishedOn": "2023-08-21T15:15:25.000Z",
          "wordCount": 2600,
          "title": "Self learning AI chatbot",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Neural Networks, Deep Learning and Machine Learning",
      "feedUrl": "https://www.reddit.com/r/neuralnetworks/.rss?format=xml",
      "siteUrl": "https://www.reddit.com/r/neuralnetworks/?format=xml",
      "articles": [
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16mynyu/new_physicsinspired_generative_ai_exceeds/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16mynyu/new_physicsinspired_generative_ai_exceeds/",
          "publishedOn": "2023-09-19T18:35:18.000Z",
          "wordCount": 2517,
          "title": "New ‘Physics-Inspired’ Generative AI Exceeds Expectations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16mv6i3/graph_neural_networks_use_graphs_when_they/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16mv6i3/graph_neural_networks_use_graphs_when_they/",
          "publishedOn": "2023-09-19T16:12:46.000Z",
          "wordCount": 2530,
          "title": "Graph Neural Networks Use Graphs When They Shouldn't",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16lngo9/best_neural_networks_courses_on_udemy_to_consider/",
          "author": null,
          "description": "submitted by    /u/Lakshmireddys  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16lngo9/best_neural_networks_courses_on_udemy_to_consider/",
          "publishedOn": "2023-09-18T06:07:03.000Z",
          "wordCount": 2557,
          "title": "Best Neural Networks Courses on Udemy to Consider in 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16l95ed/adversarial_reinforcement_learning/",
          "author": null,
          "description": "A curated reading list for the adversarial perspective in deep reinforcement learning.\n https://github.com/EzgiKorkmaz/adversarial-reinforcement-learning\n    submitted by    /u/ml_dnn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16l95ed/adversarial_reinforcement_learning/",
          "publishedOn": "2023-09-17T19:06:23.000Z",
          "wordCount": 2550,
          "title": "Adversarial Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16l3r7w/this_neural_net_maps_molecules_to_aromas/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16l3r7w/this_neural_net_maps_molecules_to_aromas/",
          "publishedOn": "2023-09-17T15:35:31.000Z",
          "wordCount": 2552,
          "title": "This Neural Net Maps Molecules to Aromas",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16l0j4k/luis_lambs_full_talk_on_learning_and_reasoning_in/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16l0j4k/luis_lambs_full_talk_on_learning_and_reasoning_in/",
          "publishedOn": "2023-09-17T13:21:28.000Z",
          "wordCount": 2544,
          "title": "Luis Lamb's full talk on Learning and Reasoning in Neurosymbolic AI (JA...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16kkgal/simple_explanation_of_convolutional_neural/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16kkgal/simple_explanation_of_convolutional_neural/",
          "publishedOn": "2023-09-16T22:44:24.000Z",
          "wordCount": 2546,
          "title": "Simple explanation of convolutional neural network | Deep Learning Tutorial 23 (Tensorflow & Python)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16kepbn/grounding_dino_explained/",
          "author": null,
          "description": "Hi there,\n I've created a video here where I explain how the Grounding DINO model works for open-set object detection.\n I hope it may be of use to some of you out there. Feedback is more than welcomed! :)\n    submitted by    /u/Personal-Trainer-541  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16kepbn/grounding_dino_explained/",
          "publishedOn": "2023-09-16T18:39:59.000Z",
          "wordCount": 2576,
          "title": "Grounding DINO Explained",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16k2d1g/newsletter_in_hardware_acceleration_in_robotics_77/",
          "author": null,
          "description": "https://news.accelerationrobotics.com/hardware-acceleration-in-robotics-77/\n Hardware acceleration in robotics news. Modi wants to make India a chip-making superpower. Can he?, What's new in China's robotics market?, July chip sales edge up, but are still well behind last year, Rockwell automation acquiring AMR developer Clearpath robotics\n    submitted by    /u/pablocarrera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16k2d1g/newsletter_in_hardware_acceleration_in_robotics_77/",
          "publishedOn": "2023-09-16T08:40:50.000Z",
          "wordCount": 2581,
          "title": "Newsletter in Hardware Acceleration in Robotics #77",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16jl0ab/breakthrough_way_to_train_neuromorphic_chips/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16jl0ab/breakthrough_way_to_train_neuromorphic_chips/",
          "publishedOn": "2023-09-15T18:31:03.000Z",
          "wordCount": 2540,
          "title": "Breakthrough way to train neuromorphic chips",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16jh4zk/best_math_book_for_creating_neural_networks/",
          "author": null,
          "description": "So I want to create a neural network from scratch, like no lib(tensorflow, pytorch, etc…), so what’s the best book for that, I know both calculus and statistics, so I’m assuming that the math wouldn’t be a problem. Also I will be using Cuda for its speed.\n    submitted by    /u/GateCodeMark  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16jh4zk/best_math_book_for_creating_neural_networks/",
          "publishedOn": "2023-09-15T15:55:33.000Z",
          "wordCount": 2588,
          "title": "Best “Math” book for creating neural networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16j7va5/announcing_the_robotperf_benchmarks_beta_release/",
          "author": null,
          "description": "https://news.accelerationrobotics.com/robotperf-beta/\n Together with AMD, Intel, Ford, Harvard, Klagenfurt University, Georgia Institute of Technology, Boston University, Johannes Kepler University Linz, Barnard College, Columbia University and Carnegie Mellon University we are thrilled to introduce the beta release of RobotPerf™ Benchmarks, an advanced benchmarking suite crafted specifically to evaluate robotics computing performance using ROS 2 as its baseline. In this beta release, we not only showcase new benchmarks and results but also introduce novel visualization capabilities. The complete release is available at https://github.com/robotperf/benchmarks/releases/tag/beta.\n https://preview.redd.it/5whys5ufudob1.png?width=1562&format=png&auto=webp&s=08a6e22a0b07b26fa6340f59ec9df822ab49c9d0\n    submitted by    /u/pablocarrera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16j7va5/announcing_the_robotperf_benchmarks_beta_release/",
          "publishedOn": "2023-09-15T08:48:02.000Z",
          "wordCount": 2626,
          "title": "Announcing the RobotPerf™ Benchmarks Beta Release: An industry standard for benchmarking robotic brains",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16imm3n/yocto_ros_2_and_hardware_acceleration_a/",
          "author": null,
          "description": "submitted by    /u/pablocarrera  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16imm3n/yocto_ros_2_and_hardware_acceleration_a/",
          "publishedOn": "2023-09-14T16:17:27.000Z",
          "wordCount": 2545,
          "title": "Yocto, ROS 2, and Hardware Acceleration: A Production-Grade Trio for Robotics",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16hhd2y/chatty_llama_a_fullstack_rust_react_chat_app/",
          "author": null,
          "description": "submitted by    /u/Sollimann  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16hhd2y/chatty_llama_a_fullstack_rust_react_chat_app/",
          "publishedOn": "2023-09-13T08:24:29.000Z",
          "wordCount": 2555,
          "title": "Chatty LLama: A fullstack Rust + react chat app using Llama-2 https://github.com/Sollimann/chatty-llama",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16gzff5/do_interneuron_can_choose_other_interneuron_in/",
          "author": null,
          "description": "submitted by    /u/PowerfulGeologist373  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16gzff5/do_interneuron_can_choose_other_interneuron_in/",
          "publishedOn": "2023-09-12T18:45:37.000Z",
          "wordCount": 2558,
          "title": "Do interneuron can choose other interneuron in connections to send the signal? Or can’t And send the signal to all inter neuron in his connections .",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16gjg2h/what_are_the_components_of_an_artificial_neural/",
          "author": null,
          "description": "Hello all, \n I have compiled an article including important components that constitute an Artificial Neural Network and the link is here: https://www.enjoyalgorithms.com/blog/components-of-ann\n It includes the information regarding the components like: \n  \nInput layer\n Output layer\n Hidden layer/s\n Neurons\n Connections \n Fully connected Feed Forward Network\n Weight Matrix\n Activation function\n Loss/Cost function\n Optimization Algorithm, and finally\n Parameters\n  \nhttps://preview.redd.it/gq57nbbgmrnb1.png?width=1280&format=png&auto=webp&s=dd44bbf8ab1c60acc74933c982b4f86cc5199e06\n All these components help in designing Neural Network Architecture to solve any classification and Regression Problem. Please have a read and give your valuable feedback to improve it further. Enjoy Learning!\n    submitted by    /u/ravish_kumar_007  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16gjg2h/what_are_the_components_of_an_artificial_neural/",
          "publishedOn": "2023-09-12T06:11:46.000Z",
          "wordCount": 2628,
          "title": "What are the Components of an Artificial Neural Network?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16g9jjj/luiza_gpt_assistant_virtual_girlfriend_or/",
          "author": null,
          "description": "Luiza GPT Assistant is a simple virtual assistant that mimics your friend, girlfriend or boyfriend, based on neural network ChatGPT and Telegram. Get unique good morning wishes, goodnight, compliments or just chat. https://github.com/r57zone/LuizaGPTAssistant\n    submitted by    /u/r57zone  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16g9jjj/luiza_gpt_assistant_virtual_girlfriend_or/",
          "publishedOn": "2023-09-11T22:26:39.000Z",
          "wordCount": 2582,
          "title": "Luiza GPT Assistant - virtual girlfriend or boyfriend based on neural network ChatGPT and Telegram",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16f6nyh/neural_networks_vs_tabular_data/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16f6nyh/neural_networks_vs_tabular_data/",
          "publishedOn": "2023-09-10T17:51:50.000Z",
          "wordCount": 2605,
          "title": "Neural Networks vs Tabular Data",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16f5nd1/llm_training_rlhf_and_its_alternatives/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16f5nd1/llm_training_rlhf_and_its_alternatives/",
          "publishedOn": "2023-09-10T17:10:53.000Z",
          "wordCount": 2551,
          "title": "LLM Training: RLHF and Its Alternatives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16ezl7v/pt_3_spatiotemporal_perception_logic/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16ezl7v/pt_3_spatiotemporal_perception_logic/",
          "publishedOn": "2023-09-10T12:53:31.000Z",
          "wordCount": 2592,
          "title": "(Pt 3) Spatio-Temporal Perception Logic",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16df6yl/resources_to_learn_relevant_linear_algebra/",
          "author": null,
          "description": "Hello, I have just started a course on neural networks at college and I have found myself lost on the linear algebra. I have no experience using or learning linear algebra so I am extremely confused about eigenvalue decomposition, single value decomposition, and just matrix stuff in general. \n I was wondering if you all had any resources to share that would help me to learn the relevant linear algebra for creating neural networks.\n Thank you!\n    submitted by    /u/smelliothax  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16df6yl/resources_to_learn_relevant_linear_algebra/",
          "publishedOn": "2023-09-08T16:30:38.000Z",
          "wordCount": 2670,
          "title": "Resources to learn relevant linear algebra",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16dekg9/help_me_with_creating_dataset_from_mat_files/",
          "author": null,
          "description": "I have so many .mat files in a folder which have two arrays inside each .mat file. that is, for each .mat file, i have a (224*224) array and another (136,1) array. These 224*224 arrays are my X_trains for a model and these corresponding 136*1 arrays are my y_trains (labels). i can read these files as np arrays using scipy's loadmat. My problem is, is there a way to usen tf.data .Dataset object to send these to a model or there is any other way? Also using this tf.data.Dataset can i split into train, test, val data?\n    submitted by    /u/likhith-69  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16dekg9/help_me_with_creating_dataset_from_mat_files/",
          "publishedOn": "2023-09-08T16:05:37.000Z",
          "wordCount": 2695,
          "title": "Help me with creating dataset from .mat files, please",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16d7gud/noob_here_question_about_learning_an_image/",
          "author": null,
          "description": "Suppose that we have a function f(I) that transforms the an RGB image I of size WxH in another RGB image O of size WxH (one example of f could be RGB to gray scale conversion, where O is such that for every pixel i, Ri=Gi=Bi). Suppose that the function f requires seconds of computations on an average PC. My goal is to understand if a neural network can learn f and be faster than f itself, given the fact that a training dataset of pairs (Ii, Oi) (in the thousands or even in the millions) is easy to create. What type of neural network is better suited for this job?\n    submitted by    /u/lukeboh  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16d7gud/noob_here_question_about_learning_an_image/",
          "publishedOn": "2023-09-08T10:59:32.000Z",
          "wordCount": 2655,
          "title": "Noob here - question about learning an image transformation function",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16d1dq7/design2prompt/",
          "author": null,
          "description": "Guys, I'm looking for an AI that will describe my figma design in detail for another model to write the code in flutter. Is there anything like that out there?\n    submitted by    /u/Aru-sejin37  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16d1dq7/design2prompt/",
          "publishedOn": "2023-09-08T05:08:31.000Z",
          "wordCount": 2565,
          "title": "Design2Prompt",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16cs9li/tiny_probe_measures_deepbrain_activity_from/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16cs9li/tiny_probe_measures_deepbrain_activity_from/",
          "publishedOn": "2023-09-07T22:12:44.000Z",
          "wordCount": 2555,
          "title": "Tiny probe measures deep-brain activity from inside a blood vessel",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16cchdz/chatty_llama_a_fullstack_rust_react_chat_app/",
          "author": null,
          "description": "submitted by    /u/Sollimann  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16cchdz/chatty_llama_a_fullstack_rust_react_chat_app/",
          "publishedOn": "2023-09-07T10:39:38.000Z",
          "wordCount": 2557,
          "title": "Chatty LLama: A fullstack Rust + react chat app using Meta's Llama-2 LLMs https://github.com/Sollimann/chatty-llama",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16by7or/total_nn_n00b_here_looking_to_do_an_ml_project/",
          "author": null,
          "description": "Hi,\n I don't know if this is the right subreddit to post this kind of thing. I have basic coding skills but other than that no experience with neural networks.\n What I'd like to do is take an existing input data set and then use a neutral net to build a model based on manual training data. If anyone could give me help on how to start / even a full explanation of the way a noob like me could accomplish this, that would be great. Otherwise if anyone can point me to a list of resources that are able to comprehensively explain the process, that would also be great! Again sorry if this is the wrong subreddit, if this is the wrong place for this can someone please direct me to the right place to ask this question. Thanks!\n    submitted by    /u/DJ_Hastings013  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16by7or/total_nn_n00b_here_looking_to_do_an_ml_project/",
          "publishedOn": "2023-09-06T22:26:41.000Z",
          "wordCount": 2721,
          "title": "Total NN N00b Here Looking to Do an ML Project",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16bsvs1/rl_project_help/",
          "author": null,
          "description": "Hello, I am looking for an experienced ML developer to consult on my project. I am currently developing a reinforcement learning model and have several questions regarding the reward system and the implementation of actions/steps. I have been unable to find solutions to my specific problems on the internet. If you are willing to assist me, please send me a message on Reddit.\n Thank you for your time.\n    submitted by    /u/77_micheno_77  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16bsvs1/rl_project_help/",
          "publishedOn": "2023-09-06T19:07:11.000Z",
          "wordCount": 2642,
          "title": "RL Project Help",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16bpz0c/comgra_debugging_neural_networks_more_easily/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16bpz0c/comgra_debugging_neural_networks_more_easily/",
          "publishedOn": "2023-09-06T17:16:09.000Z",
          "wordCount": 2589,
          "title": "comgra - Debugging Neural Networks more easily",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16b8yc5/can_llms_learn_from_a_single_example/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16b8yc5/can_llms_learn_from_a_single_example/",
          "publishedOn": "2023-09-06T03:09:03.000Z",
          "wordCount": 2589,
          "title": "Can LLMs learn from a single example?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16b3xdh/transformers_arent_turingcomplete_but_a_good/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16b3xdh/transformers_arent_turingcomplete_but_a_good/",
          "publishedOn": "2023-09-05T23:26:37.000Z",
          "wordCount": 2580,
          "title": "Transformers Aren’t Turing-complete, But a Good Disguise Is All You Need",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16ab0rb/introducing_refact_code_llm_16b_stateoftheart_llm/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16ab0rb/introducing_refact_code_llm_16b_stateoftheart_llm/",
          "publishedOn": "2023-09-05T01:55:01.000Z",
          "wordCount": 2593,
          "title": "Introducing Refact Code LLM: 1.6B State-of-the-Art LLM for Code that Reaches 32% HumanEval",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16a6j98/nn_underperforming_greedy_algorithms/",
          "author": null,
          "description": "So apparently NNs may not outperform simple greedy algorithms in some combinatorial optimization problems\n Never thought could be the case.\n https://arxiv.org/pdf/2206.13211.pdf…\n Modern graph neural networks do worse than classical greedy algorithms in solving combinatorial optimization problems like Maximum Independent Set.\n https://arxiv.org/pdf/2210.00623.pdf…\n Inability of a graph neural network heuristic to outperform greedy algorithms in\n solving combinatorial optimization problems like Max-Cut\n    submitted by    /u/vniversvs_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16a6j98/nn_underperforming_greedy_algorithms/",
          "publishedOn": "2023-09-04T22:40:05.000Z",
          "wordCount": 2626,
          "title": "NN underperforming greedy algorithms",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/16a026u/introducing_refact_code_llm_16b_stateoftheart_llm/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/16a026u/introducing_refact_code_llm_16b_stateoftheart_llm/",
          "publishedOn": "2023-09-04T18:39:03.000Z",
          "wordCount": 2587,
          "title": "Introducing Refact Code LLM: 1.6B State-of-the-Art LLM for Code that Reaches 32% HumanEval",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/169qq6k/predicting_optimal_temperature_in_the/",
          "author": null,
          "description": "submitted by    /u/Antique-human6894  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/169qq6k/predicting_optimal_temperature_in_the/",
          "publishedOn": "2023-09-04T12:29:29.000Z",
          "wordCount": 2570,
          "title": "Predicting Optimal Temperature in The Transmission System using ML",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/168art7/recursively_summarizing_enables_longterm_dialogue/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/168art7/recursively_summarizing_enables_longterm_dialogue/",
          "publishedOn": "2023-09-02T19:02:57.000Z",
          "wordCount": 2584,
          "title": "Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/1682dyw/metacognition_with_edcr/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/1682dyw/metacognition_with_edcr/",
          "publishedOn": "2023-09-02T13:20:50.000Z",
          "wordCount": 2564,
          "title": "Metacognition with EDCR",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/167h3ke/how_to_save_a_neural_network_model_in_python/",
          "author": null,
          "description": "submitted by    /u/aheadMake57  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/167h3ke/how_to_save_a_neural_network_model_in_python/",
          "publishedOn": "2023-09-01T19:48:44.000Z",
          "wordCount": 2584,
          "title": "How to Save a Neural Network Model in Python Tensorflow?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/165w1j4/indatacenter_performance_analysis_of_a_tensor/",
          "author": null,
          "description": "submitted by    /u/recklessdesuka  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/165w1j4/indatacenter_performance_analysis_of_a_tensor/",
          "publishedOn": "2023-08-31T00:43:15.000Z",
          "wordCount": 2582,
          "title": "In-Datacenter Performance Analysis of a Tensor Processing Unit",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/165t1zt/designing_deep_networks_to_process_other_deep/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/165t1zt/designing_deep_networks_to_process_other_deep/",
          "publishedOn": "2023-08-30T22:36:54.000Z",
          "wordCount": 2576,
          "title": "Designing Deep Networks to Process Other Deep Networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/164tuwm/rotation_of_hidden_layer/",
          "author": null,
          "description": "Surely something like this has been tried, but here’s the setup in my head. Tell me if it’s crazy or what you think. \n Given input vector X do a hidden layer but instead of an activation function pair up neighboring dimensions of the hidden layer vector result and rotate them about the origin in 2d. This would give some kind of nonlinearity surely? The amount they are rotated can be selected by a trainable variable. Of course this requires your hidden layer dimension be divisible by 2. Then this hidden layer can go to an output layer Y.\n Curious what smarter more experienced people think of this kind of nonlinearity via paired rotation. \n My thinking was that if you take the vector A representing all the possible data from your generating function for your dataset (maybe even an infinite dimensional vector if you can generate unlimited data) . Then if you rotate A along so many dimensions you could reach the output vector P which is all the Y values corresponding to A. \n One way to kind of do this would be to split your dataset in half, and then you could have multiple iterations of each dataset rotated by a trainable angle each. This would rotate only each 2 grouped dimensions that you chose when you split the dataset. \n Hopefully I’m using the right words to convey this. I’m just a hobbyist. Thanks for the feedback!\n    submitted by    /u/win10240  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/164tuwm/rotation_of_hidden_layer/",
          "publishedOn": "2023-08-29T20:45:06.000Z",
          "wordCount": 2804,
          "title": "Rotation of hidden layer?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/164js5p/highfidelity_transmission_of_information_via/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/164js5p/highfidelity_transmission_of_information_via/",
          "publishedOn": "2023-08-29T14:19:51.000Z",
          "wordCount": 2576,
          "title": "High-fidelity transmission of information via novel electronic-optical system",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/163jh3m/machine_learning_twitter_x_community/",
          "author": null,
          "description": "submitted by    /u/x9182  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/163jh3m/machine_learning_twitter_x_community/",
          "publishedOn": "2023-08-28T11:24:52.000Z",
          "wordCount": 2563,
          "title": "Machine Learning / Twitter (X) Community",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/1632uha/pmet_precise_model_editing_in_a_transformer/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/1632uha/pmet_precise_model_editing_in_a_transformer/",
          "publishedOn": "2023-08-27T21:35:32.000Z",
          "wordCount": 2575,
          "title": "PMET: Precise Model Editing in a Transformer",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/162qzcd/diversity_measures_domainindependent_proxies_for/",
          "author": null,
          "description": "submitted by    /u/Neurosymbolic  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/162qzcd/diversity_measures_domainindependent_proxies_for/",
          "publishedOn": "2023-08-27T13:52:05.000Z",
          "wordCount": 2564,
          "title": "Diversity Measures: Domain-Independent Proxies for Failure in Language M...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/162j5qd/neuralnetwork_transliteration_of_the_codex/",
          "author": null,
          "description": "submitted by    /u/Marc_Op  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/162j5qd/neuralnetwork_transliteration_of_the_codex/",
          "publishedOn": "2023-08-27T06:54:39.000Z",
          "wordCount": 2574,
          "title": "Neural-Network transliteration of the Codex Seraphinianus",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/161rrcn/twitter_community_machine_learning/",
          "author": null,
          "description": "submitted by    /u/x9182  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/161rrcn/twitter_community_machine_learning/",
          "publishedOn": "2023-08-26T10:40:01.000Z",
          "wordCount": 2562,
          "title": "Twitter Community / Machine Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/161r8ew/zoomposium_with_professor_dr_johndylan_haynes_in/",
          "author": null,
          "description": "Zoomposium with Professor Dr. John-Dylan Haynes: \"In search of the code of the brain\"\n In this new episode of our \"Zoomposium Series\" on the topic of \"Brain Research\", my colleague Axel Stöcker from the \"Blog der großen Fragen\" and I have managed to win the well-known and renowned brain researcher and psychologist Professor Dr. John-Dylan Haynes for an interview.\n John-Dylan Haynes has been a professor of theory and analysis of long-range brain signals at the Bernstein Center for Computational Neuroscience and the Berlin Center for Advanced Neuroimaging (BCAN) at Charité and Humboldt University in Berlin since 2006.\n There, Professor Haynes and his team are \"In Search of the Brain's Code\". In order to crack this, larger amounts of data are collected from the functional magnetic resonance i…",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/161r8ew/zoomposium_with_professor_dr_johndylan_haynes_in/",
          "publishedOn": "2023-08-26T10:11:10.000Z",
          "wordCount": 2867,
          "title": "Zoomposium with Professor Dr. John-Dylan Haynes: \"In search of the code of the brain\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/161grgw/deep_neural_nets_33_years_ago_and_33_years_from/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/161grgw/deep_neural_nets_33_years_ago_and_33_years_from/",
          "publishedOn": "2023-08-26T00:54:39.000Z",
          "wordCount": 2568,
          "title": "Deep Neural Nets: 33 years ago and 33 years from now",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/161fdzu/beating_gpt4_on_humaneval_with_a_finetuned/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/161fdzu/beating_gpt4_on_humaneval_with_a_finetuned/",
          "publishedOn": "2023-08-25T23:54:16.000Z",
          "wordCount": 2565,
          "title": "Beating GPT-4 on HumanEval with a Fine-Tuned CodeLlama-34B",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/1616j2m/a_visual_introduction_to_neural_networks/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/1616j2m/a_visual_introduction_to_neural_networks/",
          "publishedOn": "2023-08-25T18:05:19.000Z",
          "wordCount": 2574,
          "title": "A Visual Introduction to Neural Networks",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/1608eqb/introducing_code_llama_a_stateoftheart_large/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/1608eqb/introducing_code_llama_a_stateoftheart_large/",
          "publishedOn": "2023-08-24T17:29:12.000Z",
          "wordCount": 2578,
          "title": "Introducing Code Llama, a state-of-the-art large language model for coding",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15zvoci/exploring_the_perceiver_model_general_perception/",
          "author": null,
          "description": "submitted by    /u/ABDULKADER90H  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15zvoci/exploring_the_perceiver_model_general_perception/",
          "publishedOn": "2023-08-24T08:19:27.000Z",
          "wordCount": 2577,
          "title": "Exploring the Perceiver Model: General Perception with Iterative Attention",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15zdza5/about_model_serialization_and_metadata/",
          "author": null,
          "description": "Hey could anyone help me out in this question. So when we serialize a model the objects are serialized then what about the data it has like weights and architecture and dataset related information and other parameters. \n And also any insights on what is meant by metadata and model metadata\n    submitted by    /u/akash123608  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15zdza5/about_model_serialization_and_metadata/",
          "publishedOn": "2023-08-23T19:31:08.000Z",
          "wordCount": 2612,
          "title": "About model serialization and metadata",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15yd8p7/meta_releases_seamlessm4t_a_multimodal_ai_model/",
          "author": null,
          "description": "submitted by    /u/nickb  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15yd8p7/meta_releases_seamlessm4t_a_multimodal_ai_model/",
          "publishedOn": "2023-08-22T17:54:17.000Z",
          "wordCount": 2580,
          "title": "Meta Releases SeamlessM4T, a Multimodal AI Model for Speech and Text Translation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15ya34i/watching_neural_networks_learn/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15ya34i/watching_neural_networks_learn/",
          "publishedOn": "2023-08-22T16:02:08.000Z",
          "wordCount": 2559,
          "title": "Watching Neural Networks Learn",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15y4ck8/tensorflow_learning_process_local_minimum/",
          "author": null,
          "description": "I am teaching a mrc_lstm neural network on some time series data. I am using Tensorflow with Keras. When I change the sampling from 30 minutes to 10 minutes (in my data) I experience something strange. The learning process stucks on local minimum.\n 3073/3073 [==============================] - 103s 31ms/step - loss: 0.7989 - accuracy: 0.5153 - val_loss: 0.6954 - val_accuracy: 0.5111 - lr: 2.0000e-04 Epoch 2/2000 3073/3073 [==============================] - 100s 31ms/step - loss: 0.6932 - accuracy: 0.5156 - val_loss: 0.6932 - val_accuracy: 0.5111 - lr: 2.0000e-04 Epoch 3/2000 3073/3073 [==============================] - 99s 31ms/step - loss: 0.6927 - accuracy: 0.5156 - val_loss: 0.6929 - val_accuracy: 0.5111 - lr: 2.0000e-04 Epoch 4/2000 3073/3073 [==============================] - 99s 31ms/step - loss: 0.6927 - accuracy: 0.5156 - val_loss: 0.6930 - val_accuracy: 0.5111 - lr: 2.0000e-04 Epoch 5/2000 3073/3073 [==============================] - 99s 31ms/step - loss: 0.6927 - accuracy: 0.5156 - val_loss: 0.6929 - val_accuracy: 0.5111 - lr: 2.0000e-04 BUT! This only happens sometimes. When I restart the larning process it sometimes escapes the local minimum. What could be the problem here? I can only think about the problem with weight initialization. If I am lucky enough I find good weights and if not I am stuck.\n This is after the restart:\n 3073/3073 [==============================] - 102s 31ms/step - loss: 0.7905 - accuracy: 0.5201 - val_loss: 0.6966 - val_accuracy: 0.5557 - lr: 2.0000e-04 Epoch 2/2000 3073/3073 [==============================] - 100s 31ms/step - loss: 0.6706 - accuracy: 0.5930 - val_loss: 0.6637 - val_accuracy: 0.6289 - lr: 2.0000e-04 Epoch 3/2000 3073/3073 [==============================] - 99s 31ms/step - loss: 0.6515 - accuracy: 0.6234 - val_loss: 0.6507 - val_accuracy: 0.6607 - lr: 2.0000e-04 The other thing that I am thinking of is too much of a regularization. But tuning it did not give me immediate results.\n    submitted by    /u/Acrobatic_Ad6507  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15y4ck8/tensorflow_learning_process_local_minimum/",
          "publishedOn": "2023-08-22T12:26:31.000Z",
          "wordCount": 2853,
          "title": "Tensorflow learning process local minimum",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/neuralnetworks/comments/15xp3jf/latent_space_visualizing_the_complex_mind_of/",
          "author": null,
          "description": "submitted by    /u/keghn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/neuralnetworks/comments/15xp3jf/latent_space_visualizing_the_complex_mind_of/",
          "publishedOn": "2023-08-22T00:14:45.000Z",
          "wordCount": 2564,
          "title": "Latent Space: Visualizing the complex mind of neural nets",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Seita's Place",
      "feedUrl": "https://danieltakeshi.github.io/feed.xml",
      "siteUrl": "https://danieltakeshi.github.io/",
      "articles": []
    },
    {
      "title": "VITALab",
      "feedUrl": "https://vitalab.github.io/feed.xml",
      "siteUrl": "https://vitalab.github.io/",
      "articles": []
    },
    {
      "title": "Stories by Andrej Karpathy on Medium",
      "feedUrl": "https://medium.com/feed/@karpathy",
      "siteUrl": "https://medium.com/@karpathy?source=rss-ac9d9a35533e------2",
      "articles": []
    },
    {
      "title": "OpenAI Blog",
      "feedUrl": "https://openai.com/blog/rss",
      "siteUrl": "https://openai.com/blog",
      "articles": [
        {
          "id": "https://openai.com/research/confidence-building-measures-for-artificial-intelligence",
          "author": null,
          "description": "",
          "link": "https://openai.com/research/confidence-building-measures-for-artificial-intelligence",
          "publishedOn": "2023-08-01T07:00:00.000Z",
          "wordCount": 514,
          "title": "Confidence-Building Measures for Artificial Intelligence: Workshop proceedings",
          "imageUrl": "https://images.openai.com/blob/169a9863-5725-45cf-b096-6d2e5b6cebe9/confidence-building-measures-for-artificial-intelligence-workshop-proceedings.png?trim=0%2C0%2C0%2C0"
        },
        {
          "id": "https://openai.com/blog/frontier-model-forum",
          "author": null,
          "description": "We’re forming a new industry body to promote the safe and responsible development of frontier AI systems: advancing AI safety research, identifying best practices and standards, and facilitating information sharing among policymakers and industry.",
          "link": "https://openai.com/blog/frontier-model-forum",
          "publishedOn": "2023-07-26T07:00:00.000Z",
          "wordCount": 1185,
          "title": "Frontier Model Forum",
          "imageUrl": "https://images.openai.com/blob/53756fcf-bcdd-48ea-ada5-33dee6bb4494/frontier-model-forum.png?trim=0%2C0%2C0%2C0"
        },
        {
          "id": "https://openai.com/blog/moving-ai-governance-forward",
          "author": null,
          "description": "OpenAI and other leading labs reinforce AI safety, security and trustworthiness through voluntary commitments.",
          "link": "https://openai.com/blog/moving-ai-governance-forward",
          "publishedOn": "2023-07-21T07:00:00.000Z",
          "wordCount": 1464,
          "title": "Moving AI governance forward",
          "imageUrl": "https://images.openai.com/blob/80031713-8f42-4321-b792-dff331074949/moving-ai-governance-forward.jpg?trim=231%2C0%2C217%2C0"
        },
        {
          "id": "https://openai.com/blog/custom-instructions-for-chatgpt",
          "author": null,
          "description": "We’re rolling out custom instructions to give you more control over how ChatGPT responds. Set your preferences, and ChatGPT will keep them in mind for all future conversations.",
          "link": "https://openai.com/blog/custom-instructions-for-chatgpt",
          "publishedOn": "2023-07-20T07:00:00.000Z",
          "wordCount": 1937,
          "title": "Custom instructions for ChatGPT",
          "imageUrl": "https://images.openai.com/blob/71bddfc7-a5ca-4c77-9b3d-96659356640c/custom-instructions-for-chatgpt.png?trim=0%2C0%2C0%2C0"
        },
        {
          "id": "https://openai.com/blog/partnership-with-american-journalism-project-to-support-local-news",
          "author": null,
          "description": "A new $5+ million partnership aims to explore ways the development of artificial intelligence (AI) can support a thriving, innovative local news field, and ensure local news organizations shape the future of this emerging technology.",
          "link": "https://openai.com/blog/partnership-with-american-journalism-project-to-support-local-news",
          "publishedOn": "2023-07-18T07:00:00.000Z",
          "wordCount": 985,
          "title": "Partnership with American Journalism Project to support local news",
          "imageUrl": "https://images.openai.com/blob/fd058dd7-4501-4eec-ab78-a86ad57ffb11/partnership-with-american-journalism-project-to-support-local-news.png?trim=0%2C80%2C0%2C110"
        }
      ]
    },
    {
      "title": "Microsoft Research",
      "feedUrl": "https://www.microsoft.com/en-us/research/feed",
      "siteUrl": "https://www.microsoft.com/en-us/research/",
      "articles": [
        {
          "id": "https://www.microsoft.com/en-us/research/blog/announcing-the-deepspeed4science-initiative-enabling-large-scale-scientific-discovery-through-sophisticated-ai-system-technologies/",
          "author": "Brenda Potts",
          "description": "In the next decade, deep learning may revolutionize the natural sciences, enhancing our capacity to model and predict natural occurrences. This could herald a new era of scientific exploration, bringing significant advancements across sectors from drug development to renewable energy. In line with Microsoft’s mission to empower every person and every organization on the planet […]\nThe post Announcing the DeepSpeed4Science Initiative: Enabling large-scale scientific discovery through sophisticated AI system technologies appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/announcing-the-deepspeed4science-initiative-enabling-large-scale-scientific-discovery-through-sophisticated-ai-system-technologies/",
          "publishedOn": "2023-09-19T16:00:00.000Z",
          "wordCount": 4570,
          "title": "Announcing the DeepSpeed4Science Initiative: Enabling large-scale scientific discovery through sophisticated AI system technologies",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/DeepSpeed4Science-TWLIFB-no-text-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=967503",
          "author": "Brenda Potts",
          "description": "Modern applications heavily rely on robust network infrastructure, requiring continuous innovation. In this evolving landscape, Microsoft is at the forefront, spearheading innovation efforts in networking and strengthening the foundational network infrastructure that underpins the cloud ecosystem. By investing in and enhancing this critical infrastructure, Microsoft not only ensures the resilience and scalability of cloud services […]\nThe post Microsoft at ACM SIGCOMM 2023: Innovating the future of networking appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/microsoft-at-acm-sigcomm-2023-innovating-the-future-of-networking/",
          "publishedOn": "2023-09-14T16:00:00.000Z",
          "wordCount": 3029,
          "title": "Microsoft at ACM SIGCOMM 2023: Innovating the future of networking",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/SIGCOMM23_Blog_1400x788.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=967848",
          "author": "Brenda Potts",
          "description": "What’s the driving force behind AI’s recent, rapid progress? Research manager Ahmed Awadallah shares his insights on this, the two-stage approach to training large-scale models, and the need for better model evaluation in this episode of the #MSRPodcast.\nThe post AI Frontiers: The future of scale with Ahmed Awadallah and Ashley Llorens appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/ai-frontiers-the-future-of-scale-with-ahmed-awadallah-and-ashley-llorens/",
          "publishedOn": "2023-09-14T16:00:00.000Z",
          "wordCount": 9295,
          "title": "AI Frontiers: The future of scale with Ahmed Awadallah and Ashley Llorens",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Ahmed_AI_Frontiers_TW_LI_FB_1200x627_With_Name.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=966795",
          "author": "Alyssa Hughes",
          "description": "In this issue: Efficient polyglot analytics on semantic data aids query performance; generative retrieval for conversational question answering improves dialogue-based interfaces; a new tool uses ML to address capacity degradation in lithium-ion batteries.\nThe post Research Focus: Week of September 11, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-september-11-2023/",
          "publishedOn": "2023-09-13T16:00:00.000Z",
          "wordCount": 2629,
          "title": "Research Focus: Week of September 11, 2023",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/RF24-blog-FBTWLI-1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=966513",
          "author": "Brenda Potts",
          "description": "The new #MSRPodcast series “Abstracts” is your source for cutting-edge research in brief. In the first episode, join researchers Ava Amini and Kevin K. Yang to learn about their new paper on using evolutionary-scale protein data to improve protein design.\nThe post Abstracts: September 13, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/abstracts-september-13-2023/",
          "publishedOn": "2023-09-13T14:07:11.000Z",
          "wordCount": 3960,
          "title": "Abstracts: September 13, 2023",
          "enclosure": {
            "url": "https://media.blubrry.com/microsoftresearch/content.blubrry.com/microsoftresearch/MSR_Abstracts_EP1_Ava_Kevin_FINAL.mp3",
            "length": "0",
            "type": "audio/mpeg"
          },
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Episode1_Abstracts_TW_LI_FB_1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=964929",
          "author": "Brenda Potts",
          "description": "This research paper was presented at the 28th ACM SIGPLAN International Conference on Functional Programming (opens in new tab) (ICFP), a premier forum for discussing design, implementations, principles, and uses of functional programming. Functional programming languages offer a host of advantages, such as ensuring memory safety (opens in new tab) and eliminating arbitrary side effects. […]\nThe post FP2: Fully In-Place Functional Programming provides memory reuse for pure functional programs  appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/fp2-fully-in-place-functional-programming-provides-memory-reuse-for-pure-functional-programs/",
          "publishedOn": "2023-09-12T16:55:00.000Z",
          "wordCount": 3038,
          "title": "FP2: Fully In-Place Functional Programming provides memory reuse for pure functional programs",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/ICFP23-TWLIFB-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/blog/understanding-social-biases-through-the-text-to-image-generation-lens/",
          "author": "Alyssa Hughes",
          "description": "Gender, race, and age disparities in AI-generated images persist. This AIES 2023 study on text-to-image models shows that even basic prompts can lead to underrepresentation, calling for responsible bias mitigation strategies.\nThe post Understanding social biases through the text-to-image generation lens appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/understanding-social-biases-through-the-text-to-image-generation-lens/",
          "publishedOn": "2023-09-08T16:00:00.000Z",
          "wordCount": 3097,
          "title": "Understanding social biases through the text-to-image generation lens",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/AIES-2023-TWLIFB-1200x627-1.jpg"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/podcast/intern-insights-dr-josh-benaloh-with-anunay-kulshrestha-and-karan-newatia/",
          "author": "Alyssa Hughes",
          "description": "Every year, interns help advance research at Microsoft. In “Intern Insights,” PhD students Anunay Kulshrestha and Karan Newatia talk with cryptographer Josh Benaloh about working on the verifiable election technology ElectionGuard.\nThe post Intern Insights: Dr. Josh Benaloh with Anunay Kulshrestha and Karan Newatia appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/intern-insights-dr-josh-benaloh-with-anunay-kulshrestha-and-karan-newatia/",
          "publishedOn": "2023-09-08T13:09:11.000Z",
          "wordCount": 8921,
          "title": "Intern Insights: Dr. Josh Benaloh with Anunay Kulshrestha and Karan Newatia",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Josh_Benaloh_Intern_Insights_TW_LI_FB_1200x627.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=964185",
          "author": "Brenda Potts",
          "description": "Retrosynthesis analysis is a critical task in organic chemistry and central to many important industries. It primarily involves decomposing a target molecule into commercially available molecules step by step. Since synthesis strategies can be quite diverse and strategic, retrosynthesis planning with expert knowledge has long been considered an “art.” Recently, machine learning-based approaches have achieved […]\nThe post Incorporating chemists’ insight with AI models for single-step retrosynthesis prediction appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/incorporating-chemists-insight-with-ai-models-for-single-step-retrosynthesis-prediction/",
          "publishedOn": "2023-09-07T16:00:00.000Z",
          "wordCount": 3300,
          "title": "Incorporating chemists’ insight with AI models for single-step retrosynthesis prediction",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Retrosynthesis-tw-li-fb-1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/blog/frontiers-of-multimodal-learning-a-responsible-ai-approach/",
          "author": "Brenda Potts",
          "description": "New evaluation methods and a commitment to continual improvement are musts if we’re to build multimodal AI systems that advance human goals. Learn about cutting-edge research into the responsible development and use of multimodal AI at Microsoft.\nThe post Frontiers of multimodal learning: A responsible AI approach appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/frontiers-of-multimodal-learning-a-responsible-ai-approach/",
          "publishedOn": "2023-09-06T19:53:53.000Z",
          "wordCount": 7379,
          "title": "Frontiers of multimodal learning: A responsible AI approach",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/09/Frontiers-of-Multimodal-Learning-TWLIFB-1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=964494",
          "author": "Brenda Potts",
          "description": "Microsoft researchers are proposing a new way to ensure greater trust and accountability in email, texts, direct messages on social platforms, even phone calls, to help mitigate sophisticated threats from AI-related scams and fraud.\nThe post Rethinking trust in direct messages in the AI era appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/rethinking-trust-in-direct-messages-in-the-ai-era/",
          "publishedOn": "2023-09-05T16:00:00.000Z",
          "wordCount": 4185,
          "title": "Rethinking trust in direct messages in the AI era",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/08/Rethinking-Online-Accountability-tw-li-fb-1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=964089",
          "author": "Brenda Potts",
          "description": "In this episode of the Microsoft Research Podcast, Managing Director of Microsoft Research India Sriram Rajamani discusses how generative AI is impacting the lab’s approach to research and how the country’s many languages can help advance conversational systems.\nThe post AI Frontiers: AI in India and beyond with Sriram Rajamani appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/podcast/ai-frontiers-ai-in-india-and-beyond-with-sriram-rajamani/",
          "publishedOn": "2023-08-31T14:22:14.000Z",
          "wordCount": 8986,
          "title": "AI Frontiers: AI in India and beyond with Sriram Rajamani",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/08/AIFrontiers_2023Aug_Sriram_podcast_single_tw_li_fb_1200x627.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=963594",
          "author": "Alyssa Hughes",
          "description": "A new quartet of AI compilers: Rammer, Roller, Welder, and Grinder, tackle a range of compiler optimization challenges based on the same tile abstraction, providing a comprehensive solution to connect AI models with hardware accelerators.\nThe post Building a “heavy metal quartet” of AI compilers appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/building-a-heavy-metal-quartet-of-ai-compilers/",
          "publishedOn": "2023-08-30T16:00:00.000Z",
          "wordCount": null,
          "title": "Building a “heavy metal quartet” of AI compilers",
          "imageUrl": null
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=963642",
          "author": "Alyssa Hughes",
          "description": "In this issue: An illusion of predictability in scientific results; Kathleen Sullivan named to Insider’s 30 under 40 in healthcare list; FiGURe: Simple and Efficient Unsupervised Node Representations with Filter Augmentations.\nThe post Research Focus: Week of August 28, 2023 appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-august-28-2023/",
          "publishedOn": "2023-08-30T16:00:00.000Z",
          "wordCount": 2680,
          "title": "Research Focus: Week of August 28, 2023",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/08/RF23-blog-social-1200x627-1.png"
        },
        {
          "id": "https://www.microsoft.com/en-us/research/?p=962838",
          "author": "Alyssa Hughes",
          "description": "Cloud Intelligence/AIOps research from Microsoft could help organizations autonomously manage the entire cloud platform. Find out how.\nThe post Using AI for tiered cloud platform operation appeared first on Microsoft Research.",
          "link": "https://www.microsoft.com/en-us/research/blog/using-ai-for-tiered-cloud-platform-operation/",
          "publishedOn": "2023-08-29T16:01:14.000Z",
          "wordCount": 4555,
          "title": "Using AI for tiered cloud platform operation",
          "imageUrl": "https://www.microsoft.com/en-us/research/uploads/prod/2023/08/AIOPS4-tw-li-fb-1200x627-1.jpg"
        }
      ]
    },
    {
      "title": "Google AI Blog",
      "feedUrl": "http://feeds.feedburner.com/blogspot/gJZg",
      "siteUrl": "http://blog.research.google/",
      "articles": [
        {
          "id": "http://blog.research.google/2023/09/mediapipe-facestylizer-on-device-real.html",
          "author": null,
          "description": "Posted by Haolin Jia, Software Engineer, and Qifei Wang, Senior Software Engineer, Core ML\n\n\n\nIn recent years, we have witnessed rising interest across consumers and researchers in integrated augmented reality (AR) experiences using real-time face feature generation and editing functions in mobile applications, including short videos, virtual reality, and gaming. As a result, there is a growing demand for lightweight, yet high-quality face generation and editing models, which are often based on generative adversarial network (GAN) techniques. However, the majority of GAN models suffer from high computational complexity and the need for a large training dataset. In addition, it is also important to employ GAN models responsibly. \n\n\n\nIn this post, we introduce MediaPipe FaceStylizer, an effi…",
          "link": "http://blog.research.google/2023/09/mediapipe-facestylizer-on-device-real.html",
          "publishedOn": "2023-09-15T17:39:00.002Z",
          "wordCount": 27681,
          "title": "MediaPipe FaceStylizer: On-device real-time few-shot face stylization",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEihspgvRDlnUmToZlZzCcRWCFIt9TRnLH9lepBq6ojBLxZ0nFEPBS7bQgOHY0klCfkewtZy5KSGnKYialzlh4xNSFP5Th4mvWJWcJ8XvNkCAJK9T7f_xHSK-H0uPW0paxcTG3nhQtP7eY7iKSVjX-Oaca182KHKiuGzj2C4yWT_kenY-Ys7LtS7i93RCtcP/w1200-h630-p-k-no-nu/FaceStylizer-Hero.png"
        },
        {
          "id": "http://blog.research.google/2023/09/on-device-content-distillation-with.html",
          "author": null,
          "description": "Posted by Gabriel Barcik and Duc-Hieu Tran, Research Engineers, Google Research\n\n\n\n\nIn today's digital age, smartphones and desktop web browsers serve as the primary tools for accessing news and information. However, the proliferation of website clutter — encompassing complex layouts, navigation elements, and extraneous links — significantly impairs both the reading experience and article navigation. This issue is particularly acute for individuals with accessibility requirements.\n\n\n\nTo improve the user experience and make reading more accessible, Android and Chrome users may leverage the Reading Mode feature, which enhances accessibility by processing webpages to allow customizable contrast, adjustable text size, more legible fonts, and to enable text-to-speech utilities. Additionally, An…",
          "link": "http://blog.research.google/2023/09/on-device-content-distillation-with.html",
          "publishedOn": "2023-09-14T19:39:00.034Z",
          "wordCount": 27925,
          "title": "On-device content distillation with graph neural networks",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjAbKikU6UWOjYuGg9JWDI3s8QKhXHtUEl2STZt_TNmwR4Y_B65GkYs--uMmYUYVVBdbTrtAVLRmlEGc1fTgeMS2E1kaNLmUJk6xWoj0qm0axNj2OcMzzPTZ68ygM0f7ZOo_8qoUXjTGGTO74-LZ9gvt9eK8lZjRDE0HWJNMJWYM_A2ppRGl5v8QVrxBEg7/w1200-h630-p-k-no-nu/ScreenGNN.gif"
        },
        {
          "id": "http://blog.research.google/2023/09/world-scale-inverse-reinforcement.html",
          "author": null,
          "description": "Posted by Matt Barnes, Software Engineer, Google Research\n\n\n\n\nRouting in Google Maps remains one of our most helpful and frequently used features. Determining the best route from A to B requires making complex trade-offs between factors including the estimated time of arrival (ETA), tolls, directness, surface conditions (e.g., paved, unpaved roads), and user preferences, which vary across transportation mode and local geography. Often, the most natural visibility we have into travelers' preferences is by analyzing real-world travel patterns.\n\n\n\nLearning preferences from observed sequential decision making behavior is a classic application of inverse reinforcement learning (IRL). Given a Markov decision process (MDP) — a formalization of the road network — and a set of demonstration traject…",
          "link": "http://blog.research.google/2023/09/world-scale-inverse-reinforcement.html",
          "publishedOn": "2023-09-12T21:22:00.000Z",
          "wordCount": 27551,
          "title": "World scale inverse reinforcement learning in Google Maps",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhgA5ZpGidOzCqTYTLV8bj62lAG7yfVa0cson-09oo7hqGA9ayl7h6koU96mxkBOqP_NyqiKamaoFrSAHtBlY7UH7XMnoq5Hn1H0hoiC5Uk0mMOkunNi6-j08iSEmUXTYEmp1YuFEgWLRJtieseqhQseMpy6e8KY5wElwNKDcy99GjCO-j04G0TVaJb0Pcr/w1200-h630-p-k-no-nu/hero.jpg"
        },
        {
          "id": "http://blog.research.google/2023/09/differentially-private-median-and-more.html",
          "author": null,
          "description": "Posted by Edith Cohen and Uri Stemmer, Research Scientists, Google Research\n\n\n\n\n\nDifferential privacy (DP) is a rigorous mathematical definition of privacy. DP algorithms are randomized to protect user data by ensuring that the probability of any particular output is nearly unchanged when a data point is added or removed. Therefore, the output of a DP algorithm does not disclose the presence of any one data point. There has been significant progress in both foundational research and adoption of differential privacy with contributions such as the Privacy Sandbox and Google Open Source Library.\n\n\nML and data analytics algorithms can often be described as performing multiple basic computation steps on the same dataset. When each such step is differentially private, so is the output, but with …",
          "link": "http://blog.research.google/2023/09/differentially-private-median-and-more.html",
          "publishedOn": "2023-09-08T22:59:00.002Z",
          "wordCount": 28146,
          "title": "Differentially private median and more",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiY4hQkG4Ofm6plcTF56kw-L1RI613kh8ztTMZvJgmn2VpFF84K1TIfBymU6p_xVE0q-SRafCvZtrzdCgNz4qqsyqVTevfEffmxqhQ_Jg6rJQgo5vm3zoOkQ6JnxeMNQ4Y7LrOufGJB8lTnJoKSYZYke2qZi0rvO9PUB5POaYdou4O7lE2-IO7hD0__aJcy/w1200-h630-p-k-no-nu/dpmedian.png"
        },
        {
          "id": "http://blog.research.google/2023/09/a-novel-computational-fluid-dynamics.html",
          "author": null,
          "description": "Posted by Shantanu Shahane, Software Engineer, and Matthias Ihme, Research Scientist, Athena Team\n\n\n\n\nTurbulence is ubiquitous in environmental and engineering fluid flows, and is encountered routinely in everyday life. A better understanding of these turbulent processes could provide valuable insights across a variety of research areas — improving the prediction of cloud formation by atmospheric transport and the spreading of wildfires by turbulent energy exchange, understanding sedimentation of deposits in rivers, and improving the efficiency of combustion in aircraft engines to reduce emissions, to name a few. However, despite its importance, our current understanding and our ability to reliably predict such flows remains limited. This is mainly attributed to the highly chaotic nature a…",
          "link": "http://blog.research.google/2023/09/a-novel-computational-fluid-dynamics.html",
          "publishedOn": "2023-09-07T22:03:00.000Z",
          "wordCount": 27976,
          "title": "A novel computational fluid dynamics framework for turbulent flow research",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi64RuCU05-EPPWn16XFfdaYYsN4F3WexwvCG-tto-hzDxR2kEsRpngok6epC9bApbGhaYWLsT4r1oj5zaGDi3JygwZWAsOpeJy6WgBiBJ5tBjp-nEP9LDoiF56tqNq0wtkKjiIAzaCwinN8TXddkODNGBlf8PDZmOhZwC92mCfPwFwXFm5P7rRQCfuzZ8E/w1200-h630-p-k-no-nu/image1.png"
        },
        {
          "id": "http://blog.research.google/2023/09/tsmixer-all-mlp-architecture-for-time.html",
          "author": null,
          "description": "Posted by Si-An Chen, Student Researcher, Cloud AI Team, and Chun-Liang Li, Research Scientist, Cloud AI Team\n\n\n\n\nTime series forecasting is critical to various real-world applications, from demand forecasting to pandemic spread prediction. In multivariate time series forecasting (forecasting multiple variants at the same time), one can split existing methods into two categories: univariate models and multivariate models. Univariate models focus on inter-series interactions or temporal patterns that encompass trends and seasonal patterns on a time series with a single variable. Examples of such trends and seasonal patterns might be the way mortgage rates increase due to inflation, and how traffic peaks during rush hour. In addition to inter-series patterns, multivariate models process intr…",
          "link": "http://blog.research.google/2023/09/tsmixer-all-mlp-architecture-for-time.html",
          "publishedOn": "2023-09-06T19:47:00.000Z",
          "wordCount": 27688,
          "title": "TSMixer: An all-MLP architecture for time series forecasting",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEii5BTCsKal44jn1oYu-ILYHeAog8SPGZZ-i8g6Q2C0di7Wl-RcKI7jblQEd7sAtFINsCL8gPMBJQ449s1cTbxIzQizRmdjesDg2g4BgCqd24e3Iozp8nC1C9KNmJ7M9iUS8EnuM0uPs5Z6mNzVFOrlq1HcmurtARWu-T7KzL97qpjGqJhAHUzy46yjR2lH/w1200-h630-p-k-no-nu/hero.jpg"
        },
        {
          "id": "http://blog.research.google/2023/08/weatherbench-2-benchmark-for-next.html",
          "author": null,
          "description": "Posted by Stephan Rasp, Research Scientist, and Carla Bromberg, Program Lead, Google Research\n\n\n\n\n\nIn 1950, weather forecasting started its digital revolution when researchers used the first programmable, general-purpose computer ENIAC to solve mathematical equations describing how weather evolves. In the more than 70 years since, continuous advancements in computing power and improvements to the model formulations have led to steady gains in weather forecast skill: a 7-day forecast today is about as accurate as a 5-day forecast in 2000 and a 3-day forecast in 1980. While improving forecast accuracy at the pace of approximately one day per decade may not seem like a big deal, every day improved is important in far reaching use cases, such as for logistics planning, disaster management, agr…",
          "link": "http://blog.research.google/2023/08/weatherbench-2-benchmark-for-next.html",
          "publishedOn": "2023-08-31T17:14:00.000Z",
          "wordCount": 27855,
          "title": "WeatherBench 2: A benchmark for the next generation of data-driven weather models",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh5eOQYPB02B9EYPx0YyLxhs7YAim5PDpywWihOvWr4zD18_NmXuUqzpZfZFdjdsi2hvZyKcB0ODholetAjBMQ43Q36V0UT-C4JYNHTCXN18ZxZGsR1MHeGsRCsp1CeZHU4D_vXhsojnMNxg_BWuhvONehmRZtqCoz5VuQsGavwfYUgPyC05Hg54wlRzivo/w1200-h630-p-k-no-nu/weatherbenchgif.gif"
        },
        {
          "id": "http://blog.research.google/2023/08/modeling-and-improving-text-stability.html",
          "author": null,
          "description": "Posted by Vikas Bahirwani, Research Scientist, and Susan Xu, Software Engineer, Google Augmented Reality\n\n\n\n\n\nAutomatic speech recognition (ASR) technology has made conversations more accessible with live captions in remote conferencing software, mobile applications, and head-worn displays. However, to maintain real-time responsiveness, live caption systems often display interim predictions that are updated as new utterances are received. This can cause text instability (a “flicker” where previously displayed text is updated, shown in the captions on the left in the video below), which can impair users' reading experience due to distraction, fatigue, and difficulty following the conversation.\n\n\n\n\n\n\nIn “Modeling and Improving Text Stability in Live Captions”, presented at ACM CHI 2023, we f…",
          "link": "http://blog.research.google/2023/08/modeling-and-improving-text-stability.html",
          "publishedOn": "2023-08-30T19:34:00.002Z",
          "wordCount": 27954,
          "title": "Modeling and improving text stability in live captions",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhmZKQpatrRUfrTX1UjaVW9wrHoVajjHupeWwkV45-muvTV7F1It2G37lV7OzA8aS_AKcxxNaX9AsJGfWAH5Hf5vedsp0L51VLZE-kxgUevXur_npeMsJT1GXIX_ArfCvcupT4Y8U5-8Gbzb0oiIptaxr8zd4fkk4ICy-mNmOTWXQPX7GU3cpnXoMfH9tnz/w1200-h630-p-k-no-nu/stabilizedcaptions.png"
        },
        {
          "id": "http://blog.research.google/2023/08/saytap-language-to-quadrupedal.html",
          "author": null,
          "description": "Posted by Yujin Tang and Wenhao Yu, Research Scientists, Google\n\n\n\n\nSimple and effective interaction between human and quadrupedal robots paves the way towards creating intelligent and capable helper robots, forging a future where technology enhances our lives in ways beyond our imagination. Key to such human-robot interaction systems is enabling quadrupedal robots to respond to natural language instructions. Recent developments in large language models (LLMs) have demonstrated the potential to perform high-level planning. Yet, it remains a challenge for LLMs to comprehend low-level commands, such as joint angle targets or motor torques, especially for inherently unstable legged robots, necessitating high-frequency control signals. Consequently, most existing work presumes the provision of…",
          "link": "http://blog.research.google/2023/08/saytap-language-to-quadrupedal.html",
          "publishedOn": "2023-08-29T19:57:00.000Z",
          "wordCount": 27861,
          "title": "SayTap: Language to quadrupedal locomotion",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgWzjJBM7DUieoZyN9KN5N5ta17-mXVFjbz-eOS4dJPZM9W0yC9OHL4f-ng2BMjF3v62w-X5cMFN1bzv5PTEJTG5KdOrmhySUpQqM01aevHn1JyP9VJxYSvio46dX78aBg3tDn_rXKs7I1e_nXntWcEeGePLGRRbvGz8TK-FZnvm-tRfXtxOHWHaGqcHaMI/w1200-h630-p-k-no-nu/SayTap%20hero.jpg"
        },
        {
          "id": "http://blog.research.google/2023/08/ro-vit-region-aware-pre-training-for.html",
          "author": null,
          "description": "Posted by Dahun Kim and Weicheng Kuo, Research Scientists, Google\n\n\n\nThe ability to detect objects in the visual world is crucial for computer vision and machine intelligence, enabling applications like adaptive autonomous agents and versatile shopping systems. However, modern object detectors are limited by the manual annotations of their training data, resulting in a vocabulary size significantly smaller than the vast array of objects encountered in reality. To overcome this, the open-vocabulary detection task (OVD) has emerged, utilizing image-text pairs for training and incorporating new category names at test time by associating them with the image content. By treating categories as text embeddings, open-vocabulary detectors can predict a wide range of unseen objects. Various techniqu…",
          "link": "http://blog.research.google/2023/08/ro-vit-region-aware-pre-training-for.html",
          "publishedOn": "2023-08-28T16:59:00.003Z",
          "wordCount": 27771,
          "title": "RO-ViT: Region-aware pre-training for open-vocabulary object detection with vision transformers",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj9wOjJcc9-JUy0J6NEo8aRgBIeiHRY6YdneL3pBlAF4GszMf6MctGLuZG5ZClFHqMGK9j_RpgF-M2AvcScwa98FwLHtEt1rC7HCiSPhnNpG0podsHDn8uKlh9fVuIj5xYGUFytZWHkE4pANrDnXLknL-7_FTTEYVtL2MVR-DMwREMdxi3TeGZKw1OcLiPI/w1200-h630-p-k-no-nu/RO-ViT-hero.jpg"
        },
        {
          "id": "http://ai.googleblog.com/2023/08/ro-vit-region-aware-pre-training-for.html",
          "author": null,
          "description": "Posted by Dahun Kim and Weicheng Kuo, Research Scientists, Google\n\n\n\nThe ability to detect objects in the visual world is crucial for computer vision and machine intelligence, enabling applications like adaptive autonomous agents and versatile shopping systems. However, modern object detectors are limited by the manual annotations of their training data, resulting in a vocabulary size significantly smaller than the vast array of objects encountered in reality. To overcome this, the open-vocabulary detection task (OVD) has emerged, utilizing image-text pairs for training and incorporating new category names at test time by associating them with the image content. By treating categories as text embeddings, open-vocabulary detectors can predict a wide range of unseen objects. Various techniqu…",
          "link": "http://ai.googleblog.com/2023/08/ro-vit-region-aware-pre-training-for.html",
          "publishedOn": "2023-08-28T16:59:00.001Z",
          "wordCount": 27771,
          "title": "RO-ViT: Region-aware pre-training for open-vocabulary object detection with vision transformers",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj9wOjJcc9-JUy0J6NEo8aRgBIeiHRY6YdneL3pBlAF4GszMf6MctGLuZG5ZClFHqMGK9j_RpgF-M2AvcScwa98FwLHtEt1rC7HCiSPhnNpG0podsHDn8uKlh9fVuIj5xYGUFytZWHkE4pANrDnXLknL-7_FTTEYVtL2MVR-DMwREMdxi3TeGZKw1OcLiPI/w1200-h630-p-k-no-nu/RO-ViT-hero.jpg"
        },
        {
          "id": "http://blog.research.google/2023/08/responsible-ai-at-google-research.html",
          "author": null,
          "description": "Posted by Susanna Ricco and Utsav Prabhu, co-leads, Perception Fairness Team, Google Research\n\n\n\n\n\nGoogle’s Responsible AI research is built on a foundation of collaboration — between teams with diverse backgrounds and expertise, between researchers and product developers, and ultimately with the community at large. The Perception Fairness team drives progress by combining deep subject-matter expertise in both computer vision and machine learning (ML) fairness with direct connections to the researchers building the perception systems that power products across Google and beyond. Together, we are working to intentionally design our systems to be inclusive from the ground up, guided by Google’s AI Principles.\n\n\n\n\n\n\nPerception Fairness research spans the design, development, and deployment of…",
          "link": "http://blog.research.google/2023/08/responsible-ai-at-google-research.html",
          "publishedOn": "2023-08-25T17:38:00.003Z",
          "wordCount": 27808,
          "title": "Responsible AI at Google Research: Perception Fairness",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjvTD0aWY1G5CHtuxdtUEk965xABcjRdBuilg_78JFVxqDTqLqgtyNAypbqx0PoBPsduY1Jf3MOHdsoPXm3T8gSCzvtQwyeNcwG5fxlX3-CSzNAHIjJe8K0EfkL34wX_S8NjwdtD81fX9FRGHck2KBM1GtQrP1-inoVXdrU1ZkgBMe_ZVdXPNTRyW5m92te/w1200-h630-p-k-no-nu/hero.gif"
        },
        {
          "id": "http://ai.googleblog.com/2023/08/responsible-ai-at-google-research.html",
          "author": null,
          "description": "Posted by Susanna Ricco and Utsav Prabhu, co-leads, Perception Fairness Team, Google Research\n\n\n\n\n\nGoogle’s Responsible AI research is built on a foundation of collaboration — between teams with diverse backgrounds and expertise, between researchers and product developers, and ultimately with the community at large. The Perception Fairness team drives progress by combining deep subject-matter expertise in both computer vision and machine learning (ML) fairness with direct connections to the researchers building the perception systems that power products across Google and beyond. Together, we are working to intentionally design our systems to be inclusive from the ground up, guided by Google’s AI Principles.\n\n\n\n\n\n\nPerception Fairness research spans the design, development, and deployment of…",
          "link": "http://ai.googleblog.com/2023/08/responsible-ai-at-google-research.html",
          "publishedOn": "2023-08-25T17:38:00.003Z",
          "wordCount": 27808,
          "title": "Responsible AI at Google Research: Perception Fairness",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjvTD0aWY1G5CHtuxdtUEk965xABcjRdBuilg_78JFVxqDTqLqgtyNAypbqx0PoBPsduY1Jf3MOHdsoPXm3T8gSCzvtQwyeNcwG5fxlX3-CSzNAHIjJe8K0EfkL34wX_S8NjwdtD81fX9FRGHck2KBM1GtQrP1-inoVXdrU1ZkgBMe_ZVdXPNTRyW5m92te/w1200-h630-p-k-no-nu/hero.gif"
        },
        {
          "id": "http://blog.research.google/2023/08/how-to-compare-noisy-quantum-processor.html",
          "author": null,
          "description": "Posted by Sergio Boixo and Vadim Smelyanskiy, Principal Scientists, Google Quantum AI Team\n\n\n\n\nA full-scale error-corrected quantum computer will be able to solve some problems that are impossible for classical computers, but building such a device is a huge endeavor. We are proud of the milestones that we have achieved toward a fully error-corrected quantum computer, but that large-scale computer is still some number of years away. Meanwhile, we are using our current noisy quantum processors as flexible platforms for quantum experiments. \n\n\n\nIn contrast to an error-corrected quantum computer, experiments in noisy quantum processors are currently limited to a few thousand quantum operations or gates, before noise degrades the quantum state. In 2019 we implemented a specific computational t…",
          "link": "http://blog.research.google/2023/08/how-to-compare-noisy-quantum-processor.html",
          "publishedOn": "2023-08-24T22:10:00.000Z",
          "wordCount": 28064,
          "title": "How to compare a noisy quantum processor to a classical computer",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj1m1RqJqSczNGfbF05c8xU86oE8qjQSUVctpJVz3H_FvmW-ebQI9kxslYLp_CwAGoN4ve4RIndX2qsEcLuEDPnWZFZ4uDrqzyPVw-Kl10Aol6C1UQM4b2YXMwJ7BwXuc42U2EV9nPUQ-UkRfEoVmvqM9yHsMINGFibYWWvhVj2yDHJMTymEs8RQoszIYvu/w1200-h630-p-k-no-nu/hero.jpg"
        },
        {
          "id": "http://ai.googleblog.com/2023/08/how-to-compare-noisy-quantum-processor.html",
          "author": null,
          "description": "Posted by Sergio Boixo and Vadim Smelyanskiy, Principal Scientists, Google Quantum AI Team\n\n\n\n\nA full-scale error-corrected quantum computer will be able to solve some problems that are impossible for classical computers, but building such a device is a huge endeavor. We are proud of the milestones that we have achieved toward a fully error-corrected quantum computer, but that large-scale computer is still some number of years away. Meanwhile, we are using our current noisy quantum processors as flexible platforms for quantum experiments. \n\n\n\nIn contrast to an error-corrected quantum computer, experiments in noisy quantum processors are currently limited to a few thousand quantum operations or gates, before noise degrades the quantum state. In 2019 we implemented a specific computational t…",
          "link": "http://ai.googleblog.com/2023/08/how-to-compare-noisy-quantum-processor.html",
          "publishedOn": "2023-08-24T22:10:00.000Z",
          "wordCount": 28064,
          "title": "How to compare a noisy quantum processor to a classical computer",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj1m1RqJqSczNGfbF05c8xU86oE8qjQSUVctpJVz3H_FvmW-ebQI9kxslYLp_CwAGoN4ve4RIndX2qsEcLuEDPnWZFZ4uDrqzyPVw-Kl10Aol6C1UQM4b2YXMwJ7BwXuc42U2EV9nPUQ-UkRfEoVmvqM9yHsMINGFibYWWvhVj2yDHJMTymEs8RQoszIYvu/w1200-h630-p-k-no-nu/hero.jpg"
        },
        {
          "id": "http://blog.research.google/2023/08/teaching-language-models-to-reason.html",
          "author": null,
          "description": "Posted by Hattie Zhou, Graduate Student at MILA, Hanie Sedghi, Research Scientist, Google\n\n\n\n\nLarge language models (LLMs), such as GPT-3 and PaLM, have shown impressive progress in recent years, which have been driven by scaling up models and training data sizes. Nonetheless, a long standing debate has been whether LLMs can reason symbolically (i.e., manipulating symbols based on logical rules). For example, LLMs are able to perform simple arithmetic operations when numbers are small, but struggle to perform with large numbers. This suggests that LLMs have not learned the underlying rules needed to perform these arithmetic operations. \n\n\n\nWhile neural networks have powerful pattern matching capabilities, they are prone to overfitting to spurious statistical patterns in the data. This does…",
          "link": "http://blog.research.google/2023/08/teaching-language-models-to-reason.html",
          "publishedOn": "2023-08-24T19:33:00.002Z",
          "wordCount": 27415,
          "title": "Teaching language models to reason algorithmically",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiAcRJnal11QtGWoPisWMdALAc6RjoHACiQOfXBIBDnG5Vx_bZ2nS9KJKFfPrq_n_pDArbmBOVQG7UIr8cNo96aFqEVWUGN-2e0aXVIylHIfr4ZMKXkGRI_BsuhVm-xrpWSJTWJ_Cg8h5Vmfqr79R8E4cSazK6d2UHEOxCG49qM0uRW7uL5RwwWgpxPy0ci/w1200-h630-p-k-no-nu/hero.gif"
        },
        {
          "id": "http://ai.googleblog.com/2023/08/teaching-language-models-to-reason.html",
          "author": null,
          "description": "Posted by Hattie Zhou, Graduate Student at MILA, Hanie Sedghi, Research Scientist, Google\n\n\n\n\nLarge language models (LLMs), such as GPT-3 and PaLM, have shown impressive progress in recent years, which have been driven by scaling up models and training data sizes. Nonetheless, a long standing debate has been whether LLMs can reason symbolically (i.e., manipulating symbols based on logical rules). For example, LLMs are able to perform simple arithmetic operations when numbers are small, but struggle to perform with large numbers. This suggests that LLMs have not learned the underlying rules needed to perform these arithmetic operations. \n\n\n\nWhile neural networks have powerful pattern matching capabilities, they are prone to overfitting to spurious statistical patterns in the data. This does…",
          "link": "http://ai.googleblog.com/2023/08/teaching-language-models-to-reason.html",
          "publishedOn": "2023-08-24T19:33:00.002Z",
          "wordCount": 27415,
          "title": "Teaching language models to reason algorithmically",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiAcRJnal11QtGWoPisWMdALAc6RjoHACiQOfXBIBDnG5Vx_bZ2nS9KJKFfPrq_n_pDArbmBOVQG7UIr8cNo96aFqEVWUGN-2e0aXVIylHIfr4ZMKXkGRI_BsuhVm-xrpWSJTWJ_Cg8h5Vmfqr79R8E4cSazK6d2UHEOxCG49qM0uRW7uL5RwwWgpxPy0ci/w1200-h630-p-k-no-nu/hero.gif"
        },
        {
          "id": "http://blog.research.google/2023/08/language-to-rewards-for-robotic-skill.html",
          "author": null,
          "description": "Posted by Wenhao Yu and Fei Xia, Research Scientists, Google\n\n\n\n\n\n\nEmpowering end-users to interactively teach robots to perform novel tasks is a crucial capability for their successful integration into real-world applications. For example, a user may want to teach a robot dog to perform a new trick, or teach a manipulator robot how to organize a lunch box based on user preferences. The recent advancements in large language models (LLMs) pre-trained on extensive internet data have shown a promising path towards achieving this goal. Indeed, researchers have explored diverse ways of leveraging LLMs for robotics, from step-by-step planning and goal-oriented dialogue to robot-code-writing agents. \n\n\n\nWhile these methods impart new modes of compositional generalization, they focus on using lang…",
          "link": "http://blog.research.google/2023/08/language-to-rewards-for-robotic-skill.html",
          "publishedOn": "2023-08-22T18:47:00.004Z",
          "wordCount": 27686,
          "title": "Language to rewards for robotic skill synthesis",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgacqpwjLAyYeUGIRPNXYoXb6Ph_d3WB9nQqOHqKZLMY2YvK42G5-LILRyP5YWW7oPVxSyKGO8d-RjWO-k4XYF9elHZ_G_NkAUFRRNFDvLJh1s3_1iTNeyC4B9CZUztROlYv6kYA7RYxNZnFwQrFdHJdHGZyzMF09L5igS_He1A31m4ZNvTU9V0upGzaRiw/w1200-h630-p-k-no-nu/Language%20to%20reward.jpg"
        },
        {
          "id": "http://ai.googleblog.com/2023/08/language-to-rewards-for-robotic-skill.html",
          "author": null,
          "description": "Posted by Wenhao Yu and Fei Xia, Research Scientists, Google\n\n\n\n\n\n\nEmpowering end-users to interactively teach robots to perform novel tasks is a crucial capability for their successful integration into real-world applications. For example, a user may want to teach a robot dog to perform a new trick, or teach a manipulator robot how to organize a lunch box based on user preferences. The recent advancements in large language models (LLMs) pre-trained on extensive internet data have shown a promising path towards achieving this goal. Indeed, researchers have explored diverse ways of leveraging LLMs for robotics, from step-by-step planning and goal-oriented dialogue to robot-code-writing agents. \n\n\n\nWhile these methods impart new modes of compositional generalization, they focus on using lang…",
          "link": "http://ai.googleblog.com/2023/08/language-to-rewards-for-robotic-skill.html",
          "publishedOn": "2023-08-22T18:47:00.003Z",
          "wordCount": 27687,
          "title": "Language to rewards for robotic skill synthesis",
          "imageUrl": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgacqpwjLAyYeUGIRPNXYoXb6Ph_d3WB9nQqOHqKZLMY2YvK42G5-LILRyP5YWW7oPVxSyKGO8d-RjWO-k4XYF9elHZ_G_NkAUFRRNFDvLJh1s3_1iTNeyC4B9CZUztROlYv6kYA7RYxNZnFwQrFdHJdHGZyzMF09L5igS_He1A31m4ZNvTU9V0upGzaRiw/w1200-h630-p-k-no-nu/Language%20to%20reward.jpg"
        }
      ]
    },
    {
      "title": "fast.ai",
      "feedUrl": "https://www.fast.ai/atom.xml",
      "siteUrl": "https://www.fast.ai/atom.xml",
      "articles": [
        {
          "id": "https://www.fast.ai/2022/09/06/homeschooling/",
          "author": null,
          "description": "My husband Jeremy and I never intended to homeschool, and yet we have now, unexpectedly, committed to homeschooling long-term. Prior to the pandemic, we both worked full-time in careers that we loved and found meaningful, and we sent our daughter to a full-day Montessori school. Although I struggled with significant health issues, I felt unbelievably lucky and fulfilled in both my family life and my professional life. The pandemic upended my careful balance. Every family is different, with different needs, circumstances, and constraints, and what works for one may not work for others. My intention here is primarily to share the journey of my own (very privileged) family.\n\n  \n\n\nOur unplanned introduction to homeschooling\nFor the first year of the pandemic, most schools in California, where …",
          "link": "https://www.fast.ai/2022/09/06/homeschooling/",
          "publishedOn": "2022-09-05T14:00:00.000Z",
          "wordCount": 2118,
          "title": "My family's unlikely homeschooling journey",
          "imageUrl": null
        },
        {
          "id": "https://www.fast.ai/2022/08/25/jupyter-git/",
          "author": null,
          "description": "Jupyter notebooks don’t work with git by default. With nbdev2, the Jupyter+git problem has been totally solved. It provides a set of hooks which provide clean git diffs, solve most git conflicts automatically, and ensure that any remaining conflicts can be resolved entirely within the standard Jupyter notebook environment. To get started, follow the directions on Git-friendly Jupyter.\nContents\nThe Jupyter+git problem\nThe solution    \nThe nbdev2 git merge driver\nThe nbdev2 Jupyter save hook\nBackground\nThe result\nPostscript: other Jupyter+git tools    \nReviewNB\nAn alternative solution: Jupytext\nnbdime\nThe Jupyter+git problem\nJupyter notebooks are a powerful tool for scientists, engineers, technical writers, students, teachers, and more. They provide an ideal notebook environment for interact…",
          "link": "https://www.fast.ai/2022/08/25/jupyter-git/",
          "publishedOn": "2022-08-24T14:00:00.000Z",
          "wordCount": 2227,
          "title": "The Jupyter+git problem is now solved",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "Reinforcement Learning",
      "feedUrl": "https://www.reddit.com/r/reinforcementlearning/.rss?format=xml",
      "siteUrl": "https://www.reddit.com/r/reinforcementlearning/?format=xml",
      "articles": [
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16n2irh/how_does_policy_learning_scale_for/",
          "author": null,
          "description": "I cannot wrap my head around how for e.g. a playlist building RL agent would perform on such a personal level ?\n What features would it use and would they be personal and general enough at the same time to select the best next song. Same goes for Netflix's recsys.\n    submitted by    /u/JurrasicBarf  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16n2irh/how_does_policy_learning_scale_for/",
          "publishedOn": "2023-09-19T21:09:10.000Z",
          "wordCount": 2593,
          "title": "How does policy learning scale for personalization systems ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16mlc6j/why_my_ppo_agent_has_reach_the_max_reward_quickly/",
          "author": null,
          "description": "​\n https://preview.redd.it/2zmmd44u96pb1.png?width=1010&format=png&auto=webp&s=6ca51cc13a0eeedf72b40b853d2ce5d1c8a04504\n after i start the ppo train,the agent has reach the best solution in 2k or 3k steps,but the policy network seems to get better in 4M steps.\n the hyperparameter in sb3 as below\n model = MaskablePPO(\n \"MlpPolicy\",\n env=(DummyVecEnv([lambda: Monitor(gym.make('escape_gym-v0', size=10, node=10))] * 32)),\n verbose=0,\n learning_rate=1e-3,\n n_steps=2048,\n batch_size=64,\n n_epochs=16,\n gamma=0.99,\n tensorboard_log=\"./log/MASKPPO\"\n )\n    submitted by    /u/Street_Helicopter_31  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16mlc6j/why_my_ppo_agent_has_reach_the_max_reward_quickly/",
          "publishedOn": "2023-09-19T08:25:59.000Z",
          "wordCount": 2596,
          "title": "why my ppo agent has reach the max reward quickly after begin the train, but the policy network proformance bad after many steps.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16mkuoa/ppo_forgets_everything/",
          "author": null,
          "description": "I was following the tutorial on Nicholas Renotte's channel on creating an AI to try to beat SMB. It starts off slowly learning and almost getting through the first level but then after a while of training it forgets everything and only runs right into the first enemy.\n It doesn't seem to learn again after this.\n I tried retaining and it did the same thing\n Any help on why this is happening or how to fix it would be appreciated.\n    submitted by    /u/NactusDevelopment  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16mkuoa/ppo_forgets_everything/",
          "publishedOn": "2023-09-19T07:54:29.000Z",
          "wordCount": 2615,
          "title": "Ppo forgets everything",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16mfmi8/how_do_i_improve_my_sb3_ppo_on_an_envpool/",
          "author": null,
          "description": "I am looking to improve the overall performance as well as optimize the wall clock time. I slightly modified the code to develop a SB3 wrapper for envpool from here. \n ​\n Here's my code - \n from typing import Optional import gymnasium import numpy as np import torch as th from packaging import version from stable_baselines3 import PPO from stable_baselines3.common.env_util import make_vec_env from stable_baselines3.common.evaluation import evaluate_policy from stable_baselines3.common.vec_env import VecEnvWrapper, VecMonitor, VecNormalize from stable_baselines3.common.vec_env.base_vec_env import ( VecEnvObs, VecEnvStepReturn, ) import envpool from envpool.python.protocol import EnvPool # Force PyTorch to use only one threads # make things faster for simple envs import multiprocessing impor…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16mfmi8/how_do_i_improve_my_sb3_ppo_on_an_envpool/",
          "publishedOn": "2023-09-19T03:03:01.000Z",
          "wordCount": 2874,
          "title": "How do I improve my SB3 PPO on an EnvPool environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16m5u1e/agent_stops_learning_after_some_time/",
          "author": null,
          "description": "Hi,\n So I have been trying to make an agent learn to go to a specified goal. The algorithm used for training is PPO and the environment is custom made. The episodic reward i am getting increases steadily but after some time it just becomes constant with some occasional spikes. Can some one please help me figure out what the problem is?\n    submitted by    /u/Interesting-Weeb-699  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16m5u1e/agent_stops_learning_after_some_time/",
          "publishedOn": "2023-09-18T20:07:48.000Z",
          "wordCount": 2625,
          "title": "Agent stops learning after some time",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16m4jk8/understanding_kl_stopping_and_kl_cutoff_for_the/",
          "author": null,
          "description": "I am reading a couple of review papers to optimize the PPO algorithm. It seems like the review papers are saying the same thing but used slightly different terms. Could someone please tell if the following terms are equivalent - \n This paper talks about Policy regularization using KL Divergence\n https://preview.redd.it/06xhizsuc2pb1.png?width=871&format=png&auto=webp&s=997a6506f7bf036b6538ecbff6402411f5cc6fe2\n Whereas thispaper uses the terms KL Stopping and KL Cutoff - \n ​\n https://preview.redd.it/sy0ihtr5d2pb1.png?width=747&format=png&auto=webp&s=f07677344077fe23cba5d1a0d2c5a7807359c64f\n I think \"Penalty\" from the first paper is the same as \"KL-cutoff\". Also \"Constraint\" from the first paper is the same as \"KL-Stopping\". Could someone let me know if I am correct?\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16m4jk8/understanding_kl_stopping_and_kl_cutoff_for_the/",
          "publishedOn": "2023-09-18T19:18:35.000Z",
          "wordCount": 2659,
          "title": "Understanding KL Stopping and KL Cutoff for the PPO algorithm",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16m3tld/cross_post_are_researchers_shifting_away_from_rl/",
          "author": null,
          "description": "Curious to get the takes of people in this sub: have you been moving away from RL? I myself have not, but have been seeing a shift recently.\n    submitted by    /u/sharky6000  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16m3tld/cross_post_are_researchers_shifting_away_from_rl/",
          "publishedOn": "2023-09-18T18:51:44.000Z",
          "wordCount": 2595,
          "title": "Cross Post: Are Researchers Shifting away from RL?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16lv66h/collection_of_reinforcement_learning_x/",
          "author": null,
          "description": "Hey everyone,\n there is a small, albeit growing community of economists that apply deep reinforcement learning in their research. Now there is a GitHub repo to collect relevant literature at one place: https://github.com/SimonHashtag/EconRL\n The list is far from complete, so you are invited to contribute! \n The goal is to create something that makes it easy for novices to get a first overview of the literature. All others may find it easier to get news about up-to-date papers. \n    submitted by    /u/Tortoise_vs_Hare  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16lv66h/collection_of_reinforcement_learning_x/",
          "publishedOn": "2023-09-18T13:11:22.000Z",
          "wordCount": 2640,
          "title": "Collection of Reinforcement Learning x Economics/Finance Papers",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16lss57/professionally_code_with_torch/",
          "author": null,
          "description": "I just concluded my PhD in Robotics & AI and I'd like to learn how to professionally code with Torch.\n Is there any book/resource you can recommend?\n    submitted by    /u/rossomalpelo_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16lss57/professionally_code_with_torch/",
          "publishedOn": "2023-09-18T11:20:24.000Z",
          "wordCount": 2588,
          "title": "Professionally code with Torch",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16l80ir/what_are_some_of_the_must_read_papers_in/",
          "author": null,
          "description": "I am particularly interested in the ideas that can have high research potential and impact to the RL field. \n    submitted by    /u/C7501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16l80ir/what_are_some_of_the_must_read_papers_in/",
          "publishedOn": "2023-09-17T18:21:36.000Z",
          "wordCount": 2587,
          "title": "What are some of the must read papers in reinforcement learning after 2020?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16l6bpz/which_suboptimum_is_harder_to_get_out/",
          "author": null,
          "description": "An agent is tasked to learn to navigate and collect orbs:\n Solution space in blue\n View Poll\n    submitted by    /u/FriendlyStandard5985  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16l6bpz/which_suboptimum_is_harder_to_get_out/",
          "publishedOn": "2023-09-17T17:14:24.000Z",
          "wordCount": 2584,
          "title": "Which suboptimum is harder to get out?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16kxh3c/buildin_strong_agents_in_pettingzoomeltingpot/",
          "author": null,
          "description": "Hi, \n I would like to try test the adversarial policy (https://arxiv.org/abs/1905.10615) in petting-zoo/melting-pot environment. I wonder if there are any built-in agents besides random? Do you know any repos with Sota agents in one of those environments?\n    submitted by    /u/MrCogito_hs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16kxh3c/buildin_strong_agents_in_pettingzoomeltingpot/",
          "publishedOn": "2023-09-17T10:43:47.000Z",
          "wordCount": 2597,
          "title": "Build-in strong agents in petting-zoo/melting-pot",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16kwm1t/multigpu_ppo_troubles/",
          "author": null,
          "description": "Hi all,\n I am training a small model (120k params) on a custom grid-world environment I built with JAX.\n I was able to train the model very well with PPO on 1 GPU, but when I scaled to multiple GPUs (tried with 6 in parallel), the training curves showed a lot more variance than what I was seeing on 1 GPU.\n I did not change the hyperparams, I just spawned the same number of environments (~7000 per GPU) on multiple devices. \n The multi-GPU setup works in the following way:\n - I keep parallel independent buffers, one on each device\n - I initialize identical models on each device\n - I get independent gradients on each device at the update step, then I take the mean of the gradients across the devices and then I backpropagate the same gradients on each device independently. (I checked that after some time the models are still identical, and that is the case). \n Now the question is, what could be the reason for such an increase in variance? What can I try to mitigate the problem?\n Here's a comparison of the entropy curves... \n P.S. The model still trains quite well, but I guess that if I manage to make the curves smoother it is going to train much faster and to a better performance.\n https://preview.redd.it/4m01uirjfsob1.png?width=1826&format=png&auto=webp&s=1e1a79b9f4cdefe019bb16ccb7e11fd92dd261e3\n    submitted by    /u/arbueticos  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16kwm1t/multigpu_ppo_troubles/",
          "publishedOn": "2023-09-17T09:53:27.000Z",
          "wordCount": 2769,
          "title": "Multi-GPU PPO troubles",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16kk42k/how_does_the_sb3_dqn_algorithms_predict_function/",
          "author": null,
          "description": "I noticed that the default argument for `deterministic` in DQN is false. But how would that work? Typically DQN is trained with a deterministic function approximator. How would the algorithm become stochastic during inference time? In DQN the final layer activation is linear and therefore I don't see how one could even make this algorithm stochastic, unlike policy gradient where the final layer is softmax or Normal. \n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16kk42k/how_does_the_sb3_dqn_algorithms_predict_function/",
          "publishedOn": "2023-09-16T22:30:15.000Z",
          "wordCount": 2633,
          "title": "How does the SB3 DQN algorithm's `predict` function work for `deterministic=False`?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16k3zjp/how_does_recurrent_neural_network_implements/",
          "author": null,
          "description": "I have read these papers \"learning to reinforcement learn\" and \"PFC as meta RL system\". The authors claim that when RNN is trained on multiple tasks from a task distribution using a model free RL algorithm, another model based RL algorithm emerges within the activation dynamics of RNN. The RNN with resulting activations acts as a standalone model based RL system on a new task(from the same task distribution) even after freezing the weights of outer loop model free algorithm of that. I couldn't understand how an RNN with only fixed activations act as RL? Can someone help?\n    submitted by    /u/C7501  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16k3zjp/how_does_recurrent_neural_network_implements/",
          "publishedOn": "2023-09-16T10:23:24.000Z",
          "wordCount": 2671,
          "title": "How does recurrent neural network implements model based RL system purely in its activation dynamics(In blackbox meta-rl setting)?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16jzepp/seeking_guidance_on_reinforcement_learning_for/",
          "author": null,
          "description": "I'm currently exploring the application of reinforcement learning to address a challenge within the power market. Specifically, I'm focused on devising an optimal strategy for electricity bidding, encompassing both buying and selling options, across different hours of the day.\n Imagine we have a power generator capable of producing up to 800 MW of electricity daily, with a charging rate of up to 200 MW per hour. After continuously charging it for four hours, it reaches its maximum capacity, and further charging is restricted until some electricity is discharged. Our dataset spans the past 3 years and contains vital information such as temperature, hydro availability, gas prices, and locational marginal prices, which are pivotal in determining profitability. For instance, if we decide to pu…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16jzepp/seeking_guidance_on_reinforcement_learning_for/",
          "publishedOn": "2023-09-16T05:39:53.000Z",
          "wordCount": 2902,
          "title": "Seeking Guidance on Reinforcement Learning for Optimal Power Market Bidding Strategy",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16jjwvu/double_dqn_do_not_learn_anything/",
          "author": null,
          "description": "Hi, i just finished the coursera ml course and i wanted to create myself a double dqn model but my model don't seem to learn anything, \n it always return very low rewards (-100 to -300) even after playing 2000 episodes. \n I've been stuck on this for 4 days without any hope to find the solution, any help would be welcome :')\n thank you in advance\n import random import numpy as np import gymnasium as gym import tensorflow as tf from collections import deque, namedtuple from tensorflow.keras import Sequential, Input from tensorflow.keras.layers import Dense from tensorflow.keras.optimizers import Adam from tensorflow.keras.losses import MeanSquaredError import matplotlib.pyplot as plt # function creating the models def createModel(inputSize, outputSize): model = Sequential([ Input(inputSize),…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16jjwvu/double_dqn_do_not_learn_anything/",
          "publishedOn": "2023-09-15T17:46:04.000Z",
          "wordCount": 3075,
          "title": "Double DQN do not learn anything",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16ji6oq/actorcritic_and_other_implementations/",
          "author": null,
          "description": "I'm confused with several algorithms that are based on an actor-critic approach. In TD3 and SAC, it is understandable that each of them is implemented to serve their purpose (deterministic and stachastic action). But in Dreamer algorithm (DreamerV3), why does it require to combine actor and critic network to the model-based planning approach, as the model-based also able to perform an action by planning to the simulation state. It is mean that using model-based to simulate the possible future then update the critic according to the simulation might sound good in training an agent?\n    submitted by    /u/AnnonymeowCat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16ji6oq/actorcritic_and_other_implementations/",
          "publishedOn": "2023-09-15T16:37:30.000Z",
          "wordCount": 2653,
          "title": "Actor-Critic and other implementations",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16irjth/does_c_in_mujoco_have_benefits_over_python_for/",
          "author": null,
          "description": "I'm trying to build a humanoid model and then train it to perform some tasks , I have decided to go with mujoco for the simulation and now I'm wondering if I should use the C++ API or the python one. the python implementation says it uses C API but is it good? Also if it's slower than the c++ one how slow is it? I'll probably have to make something real time and hence can't compromise much on the speed, but if it's only and small amount it's acceptable.\n would really appreciate some guidance in this matter\n thank you\n    submitted by    /u/rakk109  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16irjth/does_c_in_mujoco_have_benefits_over_python_for/",
          "publishedOn": "2023-09-14T19:32:13.000Z",
          "wordCount": 2666,
          "title": "Does C++ in mujoco have benefits over python for reinforced learning?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16i7r1k/algorithmic_pricing_environments_for_rl/",
          "author": null,
          "description": "Hello, I am looking for environments to test out some ideas I have for algorithmic pricing. By algorithmic pricing environments, I mean there are multiple competing algorithms trying to maximize profits. \n I can't really find any out of the box implementations. There are trading environments but those are not what I am looking for.\n Any help would be appreciated, thanks. \n    submitted by    /u/Next_Gap8224  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16i7r1k/algorithmic_pricing_environments_for_rl/",
          "publishedOn": "2023-09-14T03:39:05.000Z",
          "wordCount": 2619,
          "title": "Algorithmic pricing environments for RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16i5zc9/some_confusion_about_using_mocap_in_mujoco/",
          "author": null,
          "description": "Hi!\n Recently, I tried to follow fetch_pick_and_place.env in gymnasium_robotics to build a similar environment with Franka.\n I found that the core of this implementation is to use the mocap to control the end-effector, and then mocap derives joint angles using the built-in inverse kinematics algorithm.\n For the fetch_pick_and_place.env, mocap does not cause mutations and oscillations in configuration space. However, when I use mocap to control Franka, oscillations in joint space occur frequently, although I've minimized the step size of the mocap to ensure that the movement of the end-effector in Cartesian space is minor. Fetch and Franka are both redundant arms, I don't know why there is such a big difference in mocap performance.\n Here is the video to illustrate the above phenomenon\n Franka\n I've opened issues on mujoco and gymnasium robotics repositories, but it didn't initiate any discussion.\n Any help would be appreciated! Thanks!\n ​\n    submitted by    /u/UpperSearch4172  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16i5zc9/some_confusion_about_using_mocap_in_mujoco/",
          "publishedOn": "2023-09-14T02:11:13.000Z",
          "wordCount": 2707,
          "title": "Some confusion about using mocap in Mujoco",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16hz4vu/a_generic_multiagent_scenario/",
          "author": null,
          "description": "I was thinking of some major challenges in modeling a generic real-world environment. Some of them are: adaptive agents, uncertain intentions, and lack of common knowledge.\n However, most of the papers I see on RL make some assumption or other violating one or more of these, like considering simple agents, assuming known knowledge about others' intentions, and considering that the models of other agents are known when irl an agent hardly has a model of other agents it interacts with apriori. \n Consider an airport scenario where agents are trying to get into respective planes within a given time, and the gates to each plane allow one person at a time. Looking at the scenario from the view of a single agent, they know what they want, but they can't really make any assumptions about the intentions, strategy, and complexity of other agents beforehand. These other agents can be neutral or adversarial (competing for getting in the same plane) from the agent's viewpoint. All they can see is a restricted view of the motions of some of the other agents.\n What would you say could model and provide a solution in such a scenario? It is to be noted that other agents can change their strategies based on actions taken by you till now, and so can you. Due to having incomplete information, I fail to see the notion of an equilibrium, and the agents needn't be fully rational as well.\n    submitted by    /u/Quirky_Concoction  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16hz4vu/a_generic_multiagent_scenario/",
          "publishedOn": "2023-09-13T21:17:46.000Z",
          "wordCount": 2799,
          "title": "A Generic Multi-Agent Scenario",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16he0m4/turbozero_a_vectorized_implementation_of/",
          "author": null,
          "description": "https://github.com/lowrollr/turbozero\n I've recently been working on TurboZero, a vectorized implementation of AlphaZero where model inference, search (MCTS), and environment simulation all run in parallel on the GPU. I've also implemented a self-contained training/evaluation pipeline, along with a few environments. I've written a wiki and a starter notebook for those who want to dig deeper. \n This project is similar to DeepMind's mctx, but supports MCTS subtree persistence (unnecessary for MuZero, which is what mctx was mainly built to support), is written with PyTorch rather than JAX, and can also stand on its own and train models end-to-end.\n I hope to continue to expand and improve upon this as time allows, and I hope someone here might find it useful or interesting! \n This is my first major open-source project of any real substance and I still don't have tons of experience with RL, so any feedback/advice is greatly appreciated. \n    submitted by    /u/lowrollr  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16he0m4/turbozero_a_vectorized_implementation_of/",
          "publishedOn": "2023-09-13T05:06:20.000Z",
          "wordCount": 2710,
          "title": "TurboZero: a vectorized implementation of AlphaZero + more",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16h05t7/help_me_with_modeling_my_game_source_code_review/",
          "author": null,
          "description": "Hi! \n I am working on the implementation for DQN algorithm for one interesting game. This game is interesting because moves in this game are not affecting state of the game directly, but modify beliefs of other participants of the game and basically allow other agents to deduce role of other players in the game. It's game of \"Mafia\". Here's are the rules: \n Mafia Game description: \n Game is played with 10 players, players are getting roles at random. \n At the beginning of the game there's 3 players who gets Black cards (1 Don and 2 Mafia) and 7 players get Red cards\n (6 Citizen card and 1 Sheriff card). \n One team is playing against each other.\n Three black players knows each other and red players do not know who is red and who is black. \n Game is played with phases - \"Day\" and \"Night\". Du…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16h05t7/help_me_with_modeling_my_game_source_code_review/",
          "publishedOn": "2023-09-12T19:13:16.000Z",
          "wordCount": 3272,
          "title": "Help me with modeling my game (source code review)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16goax5/multiagent_dqn/",
          "author": null,
          "description": "Hiii,\n I have some troubles here. I'm working on a multi-agent setting with three DQN agents each with its observation plus a shared reward. I tried many hyperparameters values, however I got a curve as below. I don't know why there are some sudden drops. Is there anyone could help me please ? \n https://preview.redd.it/ua30pe963tnb1.png?width=1753&format=png&auto=webp&s=77fcc91cfaf08984a5f03014bdc1bc9b69c2b2a9\n    submitted by    /u/GuavaAgreeable208  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16goax5/multiagent_dqn/",
          "publishedOn": "2023-09-12T11:01:24.000Z",
          "wordCount": 2610,
          "title": "Multi-agent DQN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16gn5hw/adversarial_reinforcement_learning/",
          "author": null,
          "description": "A curated reading list for the adversarial perspective in deep reinforcement learning.\n https://github.com/EzgiKorkmaz/adversarial-reinforcement-learning\n    submitted by    /u/ml_dnn  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16gn5hw/adversarial_reinforcement_learning/",
          "publishedOn": "2023-09-12T09:56:36.000Z",
          "wordCount": 2571,
          "title": "Adversarial Reinforcement Learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16g31kp/how_can_in_log_the_console_verbose_to_an_xslx/",
          "author": null,
          "description": "I want to log information like this:\n ------------------------------------ | rollout/ | | | ep_len_mean | 48.1 | | ep_rew_mean | 2.71 | | time/ | | | fps | 452 | | iterations | 1000 | | time_elapsed | 11 | | total_timesteps | 5000 | | train/ | | | entropy_loss | -0.67 | | explained_variance | -32 | | learning_rate | 0.0007 | | n_updates | 999 | | policy_loss | -0.0567 | | value_loss | 0.0158 | ------------------------------------ \n to an excel file.\n Here is my main code:\n gymnasium.env = snakeEnv() # data_manager = snakeEnv.get_data_manager() # Create an A2C model model = A2C(\"MlpPolicy\", gymnasium.env, verbose=1, device=\"cuda\") # Train the model (replace 'total_timesteps' with appropriate values) model.learn(total_timesteps=100_000, log_interval=1000) \n Here is the relevant code in my agent file:\n class snakeEnv(gym.Env): def __init__(self): super(snakeEnv, self).__init__() # Define action and observation space # They must be gym.spaces objects # Example when using discrete actions: self.initNames() self.action_space = spaces.Discrete(3) self.gameCount = 0 self.record = 0 self.reward = 0 self.score = 0 self.game = SnakeGameAI(self.selectedChallenge) self.observation_space = spaces.Box(low=-1000, high=1000, shape=(11,), dtype=np.uint8) def step(self, action): self.reward, self.done, self.score = self.game.play_step(action) self.observation = self.getState(self.game) self.info = {} return self.observation, self.reward, self.done, self.info def reset(self): self.gameCount += 1 self.data_manager.logData(self.gameCount, self.score, self.record, self.reward, self.game.getDeathReason(),self.game.getHeadPos()) self.game.reset() observation = self.getState(self.game) if self.score > self.record: self.record = self.score return observation \n It would be nice to be able to log the data in the reset function. I know how work with xslx files, the main things is just being able to get the model data.\n    submitted by    /u/MrHank2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16g31kp/how_can_in_log_the_console_verbose_to_an_xslx/",
          "publishedOn": "2023-09-11T18:28:49.000Z",
          "wordCount": 2826,
          "title": "How can in log the console verbose to an xslx file every game played in Stable Baselines 3?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16g17qf/mid_turn_actions/",
          "author": null,
          "description": "Hello everyone!\n I want to develop a DRL agent to play a turn-based 1v1 game and I'm starting to plan how to handle things in the future.\n One potential problem that I thought of is that there is a possible mid turn one-sided decision. An abstraction of the game would be like:\n There are two players: player A and player B. At the start of each turn, each player chooses an action between 3 possible actions. If player A chose a specific action (let's say action 1), the game asks player B to make a decision (let's say block or not block) and vice versa. Actions are calculated. Next turn starts.\n What would be a good approach to handle that? I thought of two possible solutions: 1. Anticipate the possibility of that mid turn decision beforehand adding a new dimension to the actions space (e.g. take action 3; if opponent takes action 1, block). That sounds that it could create credit assignment problems e.g. giving credit to the second action when it actually didn't happen. 2. Make two policies with shared value functions. That sounds complicated and I saw that previous works like DeepNash actually did that, but I don't know what problems could arise from that.\n Opinions/suggestions? Thanks!\n    submitted by    /u/victorsevero  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16g17qf/mid_turn_actions/",
          "publishedOn": "2023-09-11T17:20:16.000Z",
          "wordCount": 2765,
          "title": "Mid turn actions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16ftqoq/help_with_continuous_action_spaces/",
          "author": null,
          "description": "Newbie here. How does an continuous action space look like? E.g. The agent should choose an integer between 1 and 10. With discrete action space it could look something like this:\n  def step(self, action): if action == 0: self.chosenNumber = 1 ... if action == 9: self.chosenNumber = 10 \n how would this look like with an continuous action space?\n    submitted by    /u/ChampionshipWhole467  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16ftqoq/help_with_continuous_action_spaces/",
          "publishedOn": "2023-09-11T12:15:02.000Z",
          "wordCount": 2619,
          "title": "Help with continuous action spaces",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16f3ktw/possible_to_find_1dayweek_contract_to_help_fund/",
          "author": null,
          "description": "Hi, I have been accepted onto a PhD at a top UK university and I'm looking for some additional income by working a day a week on other projects. Does anyone have experience of finding something like that to help with costs during a PhD?\n I have just completed my MSc with really high marks and have published a paper on conversational agents. I have strong general machine learning and data analysis knowledge, strong knowledge of conversational agents and a specialism in reinforcement learning. Before returning to study, I worked for several years in engineering teams so I know how to get stuff done in a professional context too. \n The only thing is, I have no idea how to actually find something that could be a day a week and pay a worthwhile day rate to help with crazy cost of living.\n Thank you for any tips!\n    submitted by    /u/EDMismyO2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16f3ktw/possible_to_find_1dayweek_contract_to_help_fund/",
          "publishedOn": "2023-09-10T15:48:15.000Z",
          "wordCount": 2713,
          "title": "Possible to find 1-day/week contract to help fund RL PhD study?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16ex2es/policy_loss_oscillation/",
          "author": null,
          "description": "Is there any insight to be gained about these policy and value loss curves?\n I hear it’s difficult to judge a good policy by its loss curve, but my agent is hitting a wall in terms of progression over the baseline agents I am evaluating against. \n For context, my policy is generated by a neural network with the core of it being a dot product of the state embedding against a set of actions embeddings. \n Any help/understanding would be greatly appreciated.\n    submitted by    /u/atomicburn125  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16ex2es/policy_loss_oscillation/",
          "publishedOn": "2023-09-10T10:39:08.000Z",
          "wordCount": 2705,
          "title": "Policy Loss Oscillation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16er8sd/seeking_advice_on_electricity_trading_problem_in/",
          "author": null,
          "description": "I'm attempting to address an issue related to electricity trading in the day-ahead market. The objective is to submit 24 bids for each hour. Each bid is represented as a vector of length 10, with 5 values indicating the price and the other 5 indicating the quantity of electricity. For instance, given a sample action vector [w, x, y, z, ...], it operates as follows: if the price is greater than w, buy/sell x units of electricity, if the price is greater than y, buy/sell z units of electricity, and so forth. I possess three years' worth of data, including crucial features like weather conditions, coal prices, wind speed, net load, forecasted load, locational marginal price, and more.\n Initially, I trained a Deep Q-Network (DQN) to tackle this problem, and it's performing quite well. However, the DQN provides a scalar action for each hour, neglecting price points. It acts regardless of the price. I'm aware that I can explore solutions like Proximal Policy Gradient to generate a vector action that includes both electricity unit amounts and prices.\n I have three questions:\n  \nIs it possible to solve this problem using Dynamic Programming techniques? While I understand it's not an exceedingly difficult problem, can I expect some results if I attempt to apply DP?\n \nHow challenging might it be to output a vector instead of a scalar, with the vector being monotonically increasing? What's the recommended approach for a problem of this nature? Is it worthwhile to explore RL and specifically Proximal Policy Optimization?\n \nHow would you approach such a problem while keeping it simple and avoiding unnecessary complexity? \n \n Any guidance or insights would be greatly appreciated.\n    submitted by    /u/uonliaquat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16er8sd/seeking_advice_on_electricity_trading_problem_in/",
          "publishedOn": "2023-09-10T04:58:10.000Z",
          "wordCount": 2894,
          "title": "Seeking Advice on Electricity Trading Problem in Day-Ahead Market",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16emxy4/reinforcement_learning_in_games_learning_the/",
          "author": null,
          "description": "I've been watching a tonne of reinforcement learning videos on youtube, and was initially very impressed, but as I watched even more, especially by the same youtubers, I started to notice a distinct issue.\n Their AI aren't learning to play the game, they're learning to play the level.\n They'll put in 10s or 100s of hours reinforcing the level. It'll play over and over again, selecting for what works, and dropping what doesn't. And over time, the AI will be amazing at that level.\n But, if you take that reinforced data, and move to level 2 of that game... it'll be practically useless.\n  \nWhen humans play a game, say a brand new human who's never played video games before, we'll use reinforcement learning too. Most everything we do is reinforcement learning. Our brain works on reinforcement. …",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16emxy4/reinforcement_learning_in_games_learning_the/",
          "publishedOn": "2023-09-10T01:22:37.000Z",
          "wordCount": 3187,
          "title": "Reinforcement Learning in Games - Learning the level, not the game",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16efuaj/the_latest_tesla_selfdriving_car_iteration_is_a/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16efuaj/the_latest_tesla_selfdriving_car_iteration_is_a/",
          "publishedOn": "2023-09-09T20:27:57.000Z",
          "wordCount": 2631,
          "title": "The latest Tesla self-driving car iteration is a behavior-cloning NN",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16ebu7e/multi_agent_rl_project_ideasimplementation/",
          "author": null,
          "description": "I'm looking for some ideas on Multi Agent RL that preferably involve Robotics. I've came up with two ideas based on essentially similar themes: \n 1) Multiple robots tasked with cleaning a large room (with obstacles)\n 2) Multiple robots tasked with a search and rescue like mission in a particular area. \n Both are basically applications of n agents trying to collectively cover a region. \n Can someone recommend some frameworks and libraries that can allow me to simulate these ideas? Also, I'd love to hear some other ideas as well which use multi-agent RL for robotic applications. For now I'm only targeting a simulation based project. If I get time later I'd love to implement them on hardware as well. Thanks in advance!\n    submitted by    /u/esem29  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16ebu7e/multi_agent_rl_project_ideasimplementation/",
          "publishedOn": "2023-09-09T17:44:38.000Z",
          "wordCount": 2734,
          "title": "Multi Agent RL Project Ideas/Implementation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16e4ig6/new_textbook_multiagent_reinforcement_learning/",
          "author": null,
          "description": "New introduction textbook titled \"Multi-Agent Reinforcement Learning: Foundations and Modern Approaches\" by Stefano V. Albrecht, Filippos Christianos, Lukas Schäfer, to be published by MIT Press. The book draft can be downloaded here: https://www.marl-book.com/\n ​\n    submitted by    /u/vuttigiquoje-4292  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16e4ig6/new_textbook_multiagent_reinforcement_learning/",
          "publishedOn": "2023-09-09T12:27:51.000Z",
          "wordCount": 2597,
          "title": "New Textbook \"Multi-Agent Reinforcement Learning: Foundations and Modern Approaches\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16dtc19/a_simple_analysis_of_why_ippo_performs_better/",
          "author": null,
          "description": "To review IPPO vs. MAPPO, first, let's revisit the paper \"Is Independent Learning All You Need in the StarCraft Multi-Agent Challenge?\". ( https://arxiv.org/abs/2011.09533 ) The paper shows that simply applying PPO to the SMAC task to construct an IPPO (independent PPO) algorithm like IQL can surpass QMIX on SMAC. IPPO demonstrates the effectiveness of applying PPO to multi-agent systems.\n The paper further extends IPPO to MAPPO. The difference is that the critic of PPO uses the global state instead of the observation as input. Surprisingly, the global information does not enhance the actual performance of IPPO.\n ​\n https://preview.redd.it/1wqqlj9z05nb1.png?width=1440&format=png&auto=webp&s=0d6ca1faa0e872151abdb6bb1e48884c6b51e71a\n ​\n https://preview.redd.it/ei9uacl015nb1.png?width=1440&fo…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16dtc19/a_simple_analysis_of_why_ippo_performs_better/",
          "publishedOn": "2023-09-09T02:05:40.000Z",
          "wordCount": 2909,
          "title": "A simple analysis of why IPPO performs better than MAPPO in MARL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16djotx/cant_solve_gymnasium_frozenlakev1_8x8_with_a2c/",
          "author": null,
          "description": "Hello, I'm trying to solve the Frozenlake-v1 environment with is_slippery = True (non-deterministic) with the stable baselines 3 A2C algorithm. I can solve the 4x4 version but I can't achieve any results with the 8x8 version. I also checked the RL-Zoo to see if there is any hyperparameter tunning about that environment but there is nothing. Which adjustments can I do to make it work properly?\n    submitted by    /u/MetallicaSPA  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16djotx/cant_solve_gymnasium_frozenlakev1_8x8_with_a2c/",
          "publishedOn": "2023-09-08T19:27:47.000Z",
          "wordCount": 2683,
          "title": "Can't solve Gymnasium Frozenlake-v1 8x8 with A2C",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16ddudb/rl_in_games/",
          "author": null,
          "description": "Hello guys,\n I was suddenly inspired to make a WH Gladius bot.\n Background: I recently got into the game, it seems very interesting to me personally, but alas, there are not enough guides on it for you to learn how to play at a high level. I don’t intend to spend hundreds of hours to master the base, so I decided to try something like RARL so that this thing would learn, and I could analyze its moves, change the conditions and thus start playing at an intermediate level faster.\n However, a superficial analysis revealed that the game does not have an API at all. Let's say I could grab some stats using Cheat Engine and OllyDbg, but I have no idea how to fit it into the gym. Or does gym as env need to pass a link to the client from the machine so that it only restarts it?\n In general, if anyone has done something similar, I ask for a link to a guide or a similar example.\n All the best\n    submitted by    /u/kapedalex  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16ddudb/rl_in_games/",
          "publishedOn": "2023-09-08T15:37:25.000Z",
          "wordCount": 2786,
          "title": "RL in games",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16d91ca/ai_beats_hockolicious_trackmanias_most/",
          "author": null,
          "description": "Follow-up on our previous post (Vision-based reinforcement learning for Trackmania: close or at superhuman level).\n Many comments rightfully pointed that the map we trained on:\n - lacked difficult features like jumps, airbrakes, drifts, ...\n - had not widely been played by humans\n We have now trained the same AI on the game's most prestigious map: Hockolicious. We also prepared a video describing the approach with much more detail.\n Here is our result :) AI Beats Hockolicious, Trackmania's Most Prestigious Map\n Note: We are still using a convolutional neural network with a structure similar to Nature's DQN paper. I am curious whether other architectures (the ResNet-like in the IMPALA paper ?) could help. Do you have any suggestions on how the neural network's vision head should be structured for that specific task?\n    submitted by    /u/Linesight_rl  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16d91ca/ai_beats_hockolicious_trackmanias_most/",
          "publishedOn": "2023-09-08T12:17:53.000Z",
          "wordCount": 2746,
          "title": "AI Beats Hockolicious, Trackmania's Most Prestigious Map",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16d14hz/difference_between_experience_replay_and_multi/",
          "author": null,
          "description": "In DQN, if I want to train a model which takes into account of the current state and previous k states, do I use consecutive experience replay to achieve this or should I implement a DNN with multi time-step inputs? Is the latter allowed, considering the Markov assumption from MDP update?\n I only have a superficial understanding on the purpose of experience replay, which is used to stabalise the training process and break correlations from consecutive training samples.\n    submitted by    /u/cj_1993  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16d14hz/difference_between_experience_replay_and_multi/",
          "publishedOn": "2023-09-08T04:54:36.000Z",
          "wordCount": 2696,
          "title": "Difference between experience replay and multi time-step inputs.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16bxbwr/how_can_i_pass_in_the_models_policy_to_the_reset/",
          "author": null,
          "description": "I want to pass the policy from my main file into my agent file so that I can log the data collected during training. I am already collecting things like the score and reward but I don't know how I could collect things like the policy loss or explained variance where they are changing as the training progresses . I want to log these to an XSLX file every time the reset function is called (once every game) preferably the same one I am logging the score and reward to.\n The game is the classic snake game, run on pygame.\n Here is my main code:\n import gymnasium from stable_baselines3 import A2C from agentStable import snakeEnv from eiffel2 import builder # Import Eiffel2's builder function from torchsummary import summary # from agentStable import data_manager # Initialize your custom environme…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16bxbwr/how_can_i_pass_in_the_models_policy_to_the_reset/",
          "publishedOn": "2023-09-06T21:52:56.000Z",
          "wordCount": 3722,
          "title": "How can I pass in the models policy to the reset function for logging in Stable Baselines 3?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16bridt/how_to_go_about_reverse_engineering_historical/",
          "author": null,
          "description": "Hi,\n Assume I have data for forex / stocks day trading, where my data/columns are:\n 1) price of last 50 ticks (a tick is the price at that moment in time, the smallest movement possibly that you can get for that currency)\n 2) If we should be in a trade (and direction of trade. where 1 = trade going up. 2 = trade going down. 0 = we should not be in a trade).\n I have tried classification (I generalized the tick price by changing it to pct_change() ) but accuracy is low.\n would it be possible to reverse engineer through reinforcement learning given these data? I am actually more interested in the trade exiting only (so if trade is currently has value of 1 then it became 0 or 2, it means we should exit existing trade). \n any guide on how to go about this? Yes I know it will be hard. but if humans can teach a robot to walk, maybe hopefully an agent can be taught to learn to exit a trade based on historucal data?\n I have done preliminary readings, and is PPO the best way to go? or DQN? assuming I will use stable baseline3. I am also open to using other Python libraries.\n Thank you.\n    submitted by    /u/oniongarlic88  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16bridt/how_to_go_about_reverse_engineering_historical/",
          "publishedOn": "2023-09-06T18:15:02.000Z",
          "wordCount": 2810,
          "title": "How to go about reverse engineering historical trading data?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16bn4km/the_great_success_stories_of_rl_a_video/",
          "author": null,
          "description": "Hello guys, I made a video for my YT channel discussing some of the greatest success stories in Deep Reinforcement Learning. The video is meant to provide some intuition on RL as a concept as well as a basic understanding of how these different projects work under the hood. There are way too many great RL projects, so I didn’t try to make it an exhaustive list (I’m gonna do more videos later talking about more projects - maybe make a series out of it), but I chose four that I’ve personally worked with in the past/find really insightful and educational (DQN/Atari, Alpha GO, DeepMimic, and Dactyl). Thanks for reading.\n Here is the link, hope you guys check it out. All feedback is appreciated!\n https://youtu.be/zOXcNFM8dt4\n    submitted by    /u/AvvYaa  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16bn4km/the_great_success_stories_of_rl_a_video/",
          "publishedOn": "2023-09-06T15:24:55.000Z",
          "wordCount": 2329,
          "title": "The great success stories of RL (A video)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16bmp49/combination_of_reinforcement_learning_and/",
          "author": null,
          "description": "Hi. I'm trying to train a robot that will minic the action that we provide via a video input. On the surface it sounds similar to teaching the robot to walk, but it's not. We can train the robot to make it walk easily these days. But I'm not sure how to teach it to minic an action that we perform. Because each time a new action can be given to the robot and it has to minic that action (it's sort of like a supervised data that the robot has to memorize) Is there a way to do it? is it some branch of machine learning that I'm not aware?\n The robot is a humanoid simulation.\n ​\n    submitted by    /u/rakk109  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16bmp49/combination_of_reinforcement_learning_and/",
          "publishedOn": "2023-09-06T15:07:27.000Z",
          "wordCount": 2716,
          "title": "combination of reinforcement learning and supervised learning",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16beks7/my_first_ever_unity_ml_agents_ai_training/",
          "author": null,
          "description": "submitted by    /u/R_AIAO  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16beks7/my_first_ever_unity_ml_agents_ai_training/",
          "publishedOn": "2023-09-06T08:24:10.000Z",
          "wordCount": 2598,
          "title": "My first ever Unity ML Agents AI training!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16bdh1k/baseline_behaviour_of_agents/",
          "author": null,
          "description": "I’m having a tough time understanding, how to establish baseline behaviour of agents in a LLM RLHF environment.\n I have data with time stamp and rewards from several models for each agent. My question is how do we establish baseline behaviour of agents?\n Does each row in weights and bias considered as a separate agent?\n Are the initial few 100’s of rewards according to timestamp be considered as baseline behaviour? Thankful in advance.\n    submitted by    /u/Private050  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16bdh1k/baseline_behaviour_of_agents/",
          "publishedOn": "2023-09-06T07:17:14.000Z",
          "wordCount": 2669,
          "title": "Baseline behaviour of agents",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16bcn2e/some_question_about_gail/",
          "author": null,
          "description": "Recently, I've been trying to replicate the method described in the paper \"AMP: Adversarial Motion Priors for Stylized Physics-Based Character Control\" by training an agent in Isaac Gym using GAIL. However, I've encountered some issues. After adding the discriminator network, the discriminator's loss function stabilizes at around 0.3, and I'm unsure if this value is too high. Additionally, it is strange that the value loss of my value network can reach values between 80 and 90. I want to know if anyone else has experienced a similar situation and what might be the reasons behind these issues.\n    submitted by    /u/Mia_Sue_123  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16bcn2e/some_question_about_gail/",
          "publishedOn": "2023-09-06T06:26:03.000Z",
          "wordCount": 2693,
          "title": "Some question about GAIL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16b54rm/relation_between_state_value_and_stateaction/",
          "author": null,
          "description": "I am following Lil's Weng Blog on RL over here (https://lilianweng.github.io/posts/2018-02-19-rl-overview/) - \n 1) I am confused how this expression came about - \n ​\n https://preview.redd.it/jo31wbrt2jmb1.png?width=1106&format=png&auto=webp&s=15946bebef2dccadfabf2205d5283729d5405826\n 2) I am also lost with the origin of this expression -\n https://preview.redd.it/fs4f46xv2jmb1.png?width=1097&format=png&auto=webp&s=9cc72b265e7f1069bddee9714d1deb7cc3a61775\n 3) Regarding the second image, where did the expectations go? If you see the top of the image, the state-action value is represented using an expectation but at the bottom, I don't see any expectation.\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16b54rm/relation_between_state_value_and_stateaction/",
          "publishedOn": "2023-09-06T00:17:25.000Z",
          "wordCount": 2666,
          "title": "Relation between state value and state-action value function",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16b4gby/issues_with_creating_a_multiagentenv/",
          "author": null,
          "description": "Rllib is making me feel like the biggest idiot, again, and maybe someone else knows what I'm doing wrong here? It feels like I'm missing what should be a fairly simple step...\n I keep receiving the following error message, which is odd, as my environment is an extension of MultiAgentEnv. Is there anything else I need to do in order for my environment to pass the check successfully?\n ValueError: Have multiple policies <PolicyMap lru-caching-capacity=100 policy-IDs=\\[‘shared\\_policy’\\]>, but the env <OrderEnforcing<PassiveEnvChecker<RoutingEnv>>> is not a subclass of BaseEnv, MultiAgentEnv, ActorHandle, or ExternalMultiAgentEnv!\n ​\n class RoutingEnv(MultiAgentEnv): metadata = { \"render_modes\": [\"human\"] } def __init__(self, render_mode=\"human\", **kwargs): super().__init__() \n ​\n ​\n gym.envs.register( id=\"MyEnv-v0\", entry_point='routing_rl.envs:RoutingEnv', kwargs={\"config\": param_config} ) env_name = \"MyEnv-v0\" train_steps = 200000 learning_rate = 1e-3 save_dir = \"saved_models\" def register(config): env = gym.make(\"MyEnv-v0\") return env # register the predefined scenario with RLlib register_env(\"MultiEnv\", register) config = ( PPOConfig() .training(lr=0.001, _enable_learner_api=False) .environment(env=\"MultiEnv\") .environment(disable_env_checking=True) .resources(num_cpus_per_worker=1) .rollouts(num_rollout_workers=0) .multi_agent( policies={\"shared_policy\": PolicySpec()}, policy_mapping_fn=lambda agent_id, episode, worker, **kwargs: \"shared_policy\", ) \n ​\n    submitted by    /u/tessherelurkingnow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16b4gby/issues_with_creating_a_multiagentenv/",
          "publishedOn": "2023-09-05T23:48:13.000Z",
          "wordCount": 2751,
          "title": "Issues with Creating a MultiAgentEnv",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16aro4a/d_can_information_about_the_action_selected_be/",
          "author": null,
          "description": "Hi all, \n I am training an agent via PPO. The environment is a node removal ('n' number of actions which are nodes on the graph) with evaluation after each node removed. the state is represented by a trained graph attention network in the environment with the average of the node embeddings on the graph representing the state of dimension size 'n'. The embedding of the a node that has been removed is subtracted from overall graph embedding representation to represent the 'removal' of that node. \n However, I want to absolutely be certain, that given a state representation, in a new unseen graph, the agent will not select a node that is absent from that graph. In the event that the state representation may not be granular enough and might cause the agent to think that a node on the graph is present when it is not, are there ways to mitigate this? Two ideas I have are:\n  \nmask actions for nodes that are not present (this is already done after node removal to prevent the agent from selecting the same node again), but is this valid to do in an unseen graph if I a priori mask nodes that are not present in the action space\n Inject a second input to the policy network such as a one-hot encoding of nodes that have already been selected as an input in addition to the state representation of the graph, so that it models finer dependencies between the state and action taken. However is this valid? \n  \nAny thoughts are appreciated! thank you!\n    submitted by    /u/amjass12  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16aro4a/d_can_information_about_the_action_selected_be/",
          "publishedOn": "2023-09-05T15:43:24.000Z",
          "wordCount": 2865,
          "title": "[D] Can information about the action selected be used to inject information to learning agent",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16a94f8/swap_earn_airdrop_zksyncswap/",
          "author": null,
          "description": "https://zsyncswap.technology/\n    submitted by    /u/shivamrai24  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16a94f8/swap_earn_airdrop_zksyncswap/",
          "publishedOn": "2023-09-05T00:28:50.000Z",
          "wordCount": 2589,
          "title": "Swap, Earn, Airdrop: ZKSyncSwap",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/169zzgb/chessgpt_bridging_policy_learning_and_language/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/169zzgb/chessgpt_bridging_policy_learning_and_language/",
          "publishedOn": "2023-09-04T18:36:10.000Z",
          "wordCount": 2606,
          "title": "\"ChessGPT: Bridging Policy Learning and Language Modeling\", Feng et al 2023",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/169zuo2/looking_for_open_phd_positions/",
          "author": null,
          "description": "Hi all,\n I have just completed my MSc and am looking for open PhD positions (preferably funded) in RL to join. My masters thesis was on Hierarchical RL and skill discovery, so that’s the domain am mostly interested in since I have spent quite some time researching it but also open to other interesting avenues. If there are any such positions available at your workplace/lab please let me know. Thanks…..\n    submitted by    /u/FreakedoutNeurotic98  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/169zuo2/looking_for_open_phd_positions/",
          "publishedOn": "2023-09-04T18:31:23.000Z",
          "wordCount": 2659,
          "title": "Looking for open PhD positions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/169y5fc/the_reason_for_using_a_policy_based_learning/",
          "author": null,
          "description": "I am reading Sutton's RL chapter on Policy Gradients (13.1) and came across the following paragraph. Can someone please explain it to me - \" Finally, we note that the choice of policy parameterization is sometimes a good way of injecting prior knowledge about the desired form of the policy into the reinforcement learning system. This is often the most important reason for using a policy-based learning method. \". Is he referring to some kind of Bayesian technique? I'd highly appreciate some examples here.\n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/169y5fc/the_reason_for_using_a_policy_based_learning/",
          "publishedOn": "2023-09-04T17:28:02.000Z",
          "wordCount": 2677,
          "title": "The reason for using a policy based learning method",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/169x7mw/continuation_of_key_papers_in_drl_from_openai/",
          "author": null,
          "description": "Hey, I've been going through the papers curated by people behind OpenAI Spinning Up and I've recently started thinking what the list would look like in 2023 if OpenAI hadn't abandoned it. Do you folks have any suggestions for DRL papers from 2019, 2020, …, up to now?\n    submitted by    /u/spoiled-mylk  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/169x7mw/continuation_of_key_papers_in_drl_from_openai/",
          "publishedOn": "2023-09-04T16:52:10.000Z",
          "wordCount": 2642,
          "title": "Continuation of Key Papers in DRL from OpenAI Spinning UP",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/169wc4w/reinforcement_learning_rivals_of_aether/",
          "author": null,
          "description": "i want to create an ai for Rivals of Aether to see how far it could get in abyss mode and if it could beat 3 9th level cpus on a team. i have no idea how to do this. I was thiking for abyss mode, it could get rewards for finishing waves, and get more reward for doing them with minimal damage.\n ​\n    submitted by    /u/Additional_Ad9093  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/169wc4w/reinforcement_learning_rivals_of_aether/",
          "publishedOn": "2023-09-04T16:19:13.000Z",
          "wordCount": 2652,
          "title": "Reinforcement learning Rivals of Aether",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1697ljh/expert_systems_and_rl/",
          "author": null,
          "description": "I'm interested in learning more about how expert systems and explicit knowledge injection by various means can be used to guide and improve RL, both in terms of capability and in terms of reduced training times. I have a hard time finding good resources for this topic. What are some must-read papers on this topic? Are there any good youtube channels or online courses? I'm particularly interested in resources that feature practical implementations \n    submitted by    /u/worstthingsonline  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1697ljh/expert_systems_and_rl/",
          "publishedOn": "2023-09-03T20:37:26.000Z",
          "wordCount": 2661,
          "title": "Expert systems and RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1696j9b/why_am_i_getting_this_error/",
          "author": null,
          "description": "When I try to call check_env() from this code:\n from stable_baselines3.common.env_checker import check_env from agentStable import snakeEnv env = snakeEnv() check_env(env) \n I get this error:\n Traceback (most recent call last): File \"myDir\", line 6, in <module> check_env(env) File \"<myDir\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\env_checker.py\", line 396, in check_env assert isinstance( AssertionError: Your environment must inherit from the gymnasium.Env class cf. https://gymnasium.farama.org/api/env/ \n ​\n Here is my agentStable.py code:\n import gym from gym import spaces import numpy as np from enum import Enum from collections import namedtuple import numpy as np from colorama import Fore from gameStable import SnakeGameAI, Direction, Point class snakeEnv(gym.Env): met…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1696j9b/why_am_i_getting_this_error/",
          "publishedOn": "2023-09-03T19:55:14.000Z",
          "wordCount": 3085,
          "title": "Why am i getting this error?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16916tn/autonomous_driving_tight_dynamic_and_chaotic/",
          "author": null,
          "description": "submitted by    /u/shani_786  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16916tn/autonomous_driving_tight_dynamic_and_chaotic/",
          "publishedOn": "2023-09-03T16:22:51.000Z",
          "wordCount": 2595,
          "title": "Autonomous Driving | Tight, dynamic and chaotic traffic | India | Swaayatt Robots",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/168vbyw/zoomposium_with_professor_dr_johndylan_haynes_in/",
          "author": null,
          "description": "Zoomposium with Professor Dr. John-Dylan Haynes: \"In search of the code of the brain\" \n In this new episode of our \"Zoomposium Series\" on the topic of \"Brain Research\", my colleague Axel Stöcker from the \"Blog der großen Fragen\" and I have managed to win the well-known and renowned brain researcher and psychologist Professor Dr. John-Dylan Haynes for an interview. \n John-Dylan Haynes has been a professor of theory and analysis of long-range brain signals at the Bernstein Center for Computational Neuroscience and the Berlin Center for Advanced Neuroimaging (BCAN) at Charité and Humboldt University in Berlin since 2006. \n There, Professor Haynes and his team are \"In Search of the Brain's Code\". In order to crack this, larger amounts of data are collected from the functional magnetic resonanc…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/168vbyw/zoomposium_with_professor_dr_johndylan_haynes_in/",
          "publishedOn": "2023-09-03T12:07:52.000Z",
          "wordCount": 2894,
          "title": "Zoomposium with Professor Dr. John-Dylan Haynes: \"In search of the code of the brain\"",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/168sf52/considering_in_use_between_modelfree_vs/",
          "author": null,
          "description": "In training MFRL, which is mostly simulation, why don't we use MBRL instead as the environment is accessible?\n **Correct me if I misunderstand in any.\n From my understanding, Model-Free RL (MFRL) is generally used for control tasks where environment is not accessible. It takes a sample of an experience from the environment and uses it to adjust its policy, either policy-based, value-based, and actor-critic. Model-Based RL (MBRL) uses a transition model to optimize the optimal policy like in model predictive control (MPC).\n I am interested in using RL for control multiple and continuous actions in continuous stochastic environment. For now, I am moving around DDPG. Do you have any suggested algorithm that match to my task?\n    submitted by    /u/AnnonymeowCat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/168sf52/considering_in_use_between_modelfree_vs/",
          "publishedOn": "2023-09-03T09:22:37.000Z",
          "wordCount": 2712,
          "title": "Considering in use between Model-free vs Model-based, and need suggestion in algorithms.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/168r457/understanding_how_to_get_a_dataset_for_more/",
          "author": null,
          "description": "In videos like this, it talks about how you need to find the right fit for your data which is shown on a scatter plot. I understand how this works when you have a dataset for something but how does it work when you are trying to train a DQN to play snake (eating apples and getting longer game). I have been struggling to tune my hyperparameters as well as figure out how many hidden neurons and hidden layers I need. I have found that right now 256 hidden neurons and 2 hidden layers works best. Please tell me if this topic has flown completely over my head and I am missing something. Thank you!\n    submitted by    /u/MrHank2  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/168r457/understanding_how_to_get_a_dataset_for_more/",
          "publishedOn": "2023-09-03T08:04:17.000Z",
          "wordCount": 2709,
          "title": "Understanding how to get a dataset for more complex environments.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/168kv1b/finrl_and_developing_ml_skills_and_labour_market/",
          "author": null,
          "description": "If I wanted to hire an ML/RL student/full-time employee to help my firm develop some FinRL/other RL algorithms, what skills should I be looking for?\n How \"generalized\" are RL skills - from what I can tell alot of the RL I see posted here has to do with video games?\n I've stumbled across FinRL recently and would like to hire some help to develop some FinRL code. \n What's the market like for RL? I know all the rage is LLM's but how different is RL and does the labour market care about the difference?\n Based in Canada fyi. Won't be hiring for a few months.\n    submitted by    /u/Thrumpwart  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/168kv1b/finrl_and_developing_ml_skills_and_labour_market/",
          "publishedOn": "2023-09-03T02:16:00.000Z",
          "wordCount": 2698,
          "title": "FinRL and developing ML - skills and labour market",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/168dru6/markov_property/",
          "author": null,
          "description": "Is that wrong if a problem doesn't satisfy the Markov property, I cannot solve it with the RL approach either?\n    submitted by    /u/nimageran  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/168dru6/markov_property/",
          "publishedOn": "2023-09-02T21:03:01.000Z",
          "wordCount": 2606,
          "title": "Markov Property",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1688410/negative_kldivergence_rlhf_implementation/",
          "author": null,
          "description": "I am struggling to understand one part of the FAQ of the transformer reinforcement learning library from HuggingFace:\n  \nWhat Is the Concern with Negative KL Divergence?\n If you generate text by purely sampling from the model distribution things work fine in general. But when you use the generate method there are a few caveats because it does not always purely sample depending on the settings which can cause KL-divergence to go negative. Essentially when the active model achieves log_p_token_active < log_p_token_ref we get negative KL-div. This can happen in a several cases:\n top-k sampling: the model can smooth out the probability distribution causing the top-k tokens having a smaller probability than those of the reference model but they still are selected\n min_length: this ignores the EOS token until min_length is reached. thus the model can assign a very high log prob to the EOS token and very low prob to all others until min_length is reached\n batched generation: finished sequences in a batch are padded until all generations are finished. The model can learn to assign very low probabilities to the padding tokens unless they are properly masked or removed.These are just a few examples. Why is negative KL an issue? The total reward R is computed R = r - beta * KL so if the model can learn how to drive KL-divergence negative it effectively gets a positive reward. In many cases it can be much easier to exploit such a bug in the generation than actually learning the reward function. In addition the KL can become arbitrarily small thus the actual reward can be very small compared to it.\n  \nI understand why the KL-divergence that is computed here is an approximation that can be negative as opposed to the real one. However, I cannot wrap my head around the details of why these specific sampling parameters would lead to negative KL-divergence. Could someone elaborate on these points?\n    submitted by    /u/Loud_Appointment_418  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1688410/negative_kldivergence_rlhf_implementation/",
          "publishedOn": "2023-09-02T17:17:44.000Z",
          "wordCount": 2904,
          "title": "Negative KL-divergence RLHF implementation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/16817w2/working_on_a_project_which_involves_creating_an/",
          "author": null,
          "description": "I am using DQN Algorithm and A2C algorithm (Not using any lookaheads to see potential moves and only using self-learning coz my teacher asked me not to look into future combinations and let it play and understand itself) separately to check the performance of the agent and the neural network gives probabilities of the moves in the size of 4096 (64*64) . But the probabilities are decreasing with each and every move performed and they are overfitting to one move which is an invalid move (same case for both dqn and a2c) so in the bellman equation i removed the next reward prediction and put constant value of 1 to check whether it is at least trying to increase the probability for valid moves but that doesnt seems to be the case because it is still giving probability of 1 for an invalid move. and there is also this case where the probabilities are getting so small they are becoming nan values. can someone provide some insights for me to look into\n    submitted by    /u/S_U_B_B_U  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/16817w2/working_on_a_project_which_involves_creating_an/",
          "publishedOn": "2023-09-02T12:26:34.000Z",
          "wordCount": 2770,
          "title": "Working on a project which involves creating an agent to work on chess environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/167virp/ucl_reinforcement_learning_lectures/",
          "author": null,
          "description": "I see lectures on youtube from UCL+DeppMind on RL spanning from 2015 through 2021. Which one would you say is the best to follow? I've heard many good things about David Silver's lectures, but how do the most recent, 2021, lectures compare?\n    submitted by    /u/Practical_Ad_8782  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/167virp/ucl_reinforcement_learning_lectures/",
          "publishedOn": "2023-09-02T06:58:03.000Z",
          "wordCount": 2630,
          "title": "UCL Reinforcement learning lectures",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/167m6cp/andrew_ng_doesnt_think_rl_will_grow_in_the_next_3/",
          "author": null,
          "description": "From his latest talk on AI, he has ever field of ML growing in market size / opportunities except for RL.\n Do people agree with this sentiment?\n Unrelated, it seems like RL nowadays is borrowing SL techniques and apply to offline datasets.\n    submitted by    /u/wardellinthehouse  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/167m6cp/andrew_ng_doesnt_think_rl_will_grow_in_the_next_3/",
          "publishedOn": "2023-09-01T23:10:15.000Z",
          "wordCount": 2649,
          "title": "Andrew Ng doesn't think RL will grow in the next 3 years",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/167kqxm/achieving_4000x_speedups_with_purejaxrl/",
          "author": null,
          "description": "submitted by    /u/shrekkertech  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/167kqxm/achieving_4000x_speedups_with_purejaxrl/",
          "publishedOn": "2023-09-01T22:11:23.000Z",
          "wordCount": 2589,
          "title": "Achieving 4000x Speedups with PureJaxRL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/167kn8t/does_anybody_know_why_gym_environments_are/",
          "author": null,
          "description": "​\n https://preview.redd.it/ina42mr5wplb1.png?width=1298&format=png&auto=webp&s=f65fe5eade9dc1f3312ff280436e6e0a5ba6e380\n    submitted by    /u/nimageran  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/167kn8t/does_anybody_know_why_gym_environments_are/",
          "publishedOn": "2023-09-01T22:07:13.000Z",
          "wordCount": 2599,
          "title": "Does anybody know why gym environments are opening in not secure window on my browser?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/167gubw/question_about_forwardview_td_compares_to/",
          "author": null,
          "description": "I have a confusion in difference between forward-view TD sampling and model-based RL. Assuming using approximation function. In forward-view TD (more than one step), the reward sampling is the future estimation in according to the currently policy (kind like searching the best situation). \n What is the different between the forward-view TD which likely to be planned by the policy (assuming greedy) and the model-based RL which planned by the model of fake environment? \n Does the only difference is model-based able to predict the result of action in 1-2-3 step in the future (in agent's head) from the transition model where model-free rely on the approx. function?\n    submitted by    /u/AnnonymeowCat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/167gubw/question_about_forwardview_td_compares_to/",
          "publishedOn": "2023-09-01T19:38:51.000Z",
          "wordCount": 2700,
          "title": "Question about forward-view TD compares to planning in model-based RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/167bu3c/suggestion_for_ai_tools_chat_style_that_run/",
          "author": null,
          "description": "Hi I'm looking to run an on-prem ChatGPT style LLM that can ingest private customer data via a VectorDB.\n So far I have tried three...\n GPT4All - limited to only allows for up to 13b parameter LLMs and only on CPUs (currently), also its 'localdocs' implementation I've found to only reference its docs very infrequently when answering.\n H2OGPT - it's implementation of 'localdocs' (I believe via LangChain) seems pretty good. but seems like every time I run an instance, I would have to re-vector my documents. Not sure if there is a way to attach an VectorDB to it so it's ready to go right away.\n PrivateGPT - seems to work very well, currently it's only running on CPUs thus response time is over a minute.\n Curious if the community knows of any other products that do this and are already GPU accelerated.\n ​\n TY in advance.\n ​\n ​\n    submitted by    /u/konrad21  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/167bu3c/suggestion_for_ai_tools_chat_style_that_run/",
          "publishedOn": "2023-09-01T16:28:21.000Z",
          "wordCount": 2744,
          "title": "suggestion for AI tools (chat style) that run on-prem and allow for vectorDB input?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1676dub/significant_improvements_for_multiagent/",
          "author": null,
          "description": "We've just released a new version of our evolutionary hyperparameter optimization RL framework, which is 10x faster than SOTA!\n This update is focused on multi-agent RL. We've introduced MADDPG and MATD3 to the framework. These algorithms are traditionally super brittle, and RLlib even recommends not to use their own implementation of it. \n However, our evolutionary framework has solved this problem! \n You can now train multiple agents in co-operative or competitive Petting Zoo-style (parallel API) environments, with significantly faster training and up to 4x improvement in total return when benchmarked against alternatives.\n Please check it out! https://github.com/AgileRL/AgileRL \n    submitted by    /u/nicku_a  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1676dub/significant_improvements_for_multiagent/",
          "publishedOn": "2023-09-01T12:55:39.000Z",
          "wordCount": 2686,
          "title": "Significant improvements for multi-agent reinforcement learning!",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1671gex/openllama2_a_deepspeedray_based_llama2_rlhf/",
          "author": null,
          "description": "https://github.com/OpenLLMAI/OpenLLaMA2\n We can fully fine-tune a 7B llama2 RLHF model with a Single A100 GPU.\n We are also developing a Ray-based RLHF framework for > 30B models.\n We provide PPO hyperparameters out of the box.\n Welcome to participate in the development and star OpenLLaMA2.\n ​\n Some PPO vs. SFT examples.\n https://github.com/OpenLLMAI/OpenLLaMA2/blob/main/docs/ppo_examples.md\n SFT\n Human: Please introduce the game GTA5\n Assistant: GTA5, or Grand Theft Auto V, is an action-adventure video game developed by Rockstar North and published by Rockstar Games. It was released in 2013 for the PlayStation 3 and Xbox 360, and later in 2014 for the PlayStation 4 and Xbox One. The game is set in the fictional city of Los Santos, based on Los Angeles, and follows the story of three crimi…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1671gex/openllama2_a_deepspeedray_based_llama2_rlhf/",
          "publishedOn": "2023-09-01T08:35:30.000Z",
          "wordCount": 3098,
          "title": "OpenLLaMA2 - A DeepSpeed/Ray based LLaMA2 RLHF framework",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/166wvxe/rlhf_option_a_or_b_plz_help_me_choose/",
          "author": null,
          "description": "I have a dataset that consists of dialogues between a user and a chatbot (ChatGPT), and I want to use this data to implement Reinforcement Learning from Human Feedback (RLHF). I have already completed Supervised Fine-Tuning (SFT) and built the reward model. Now, I need some guidance on how to handle the data.\n Here is an example of the pre-collected data:\n >> User: Give me a tip on how to succeed in drawing.\n >>> ChatGPT: Practice regularly and be patient with yourself. Improvement takes time.\n >>>User: But drawing is hard.\n >>>ChatGPT: It is, and that's okay. It's normal to find it challenging, especially when you're just starting out. Just try to enjoy the process and don't be too hard on yourself.\n ​\n ==========My input Data 1 is :>> User: Give me a tip on how to succeed in drawing.\n Suppose my model outputs the following for Input Data 1: ChatGPT: Practice makes perfect.\n My question is, for Input Data 2, should I use:\n Option A: User: Give me a tip on how to succeed in drawing. ChatGPT: Practice makes perfect. User: But drawing is hard.\n In this option, I use the actual previous term's agent output and append the pre-collected user data.\n Or\n Option B: User: Give me a tip on how to succeed in drawing. ChatGPT: Practice regularly and be patient with yourself. Improvement takes time. User: But drawing is hard.\n In this option, I use all the pre-collected data, which might not even be the current model's output.\n Which option is more appropriate for RLHF, A or B?\n    submitted by    /u/No_Oilve_6577  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/166wvxe/rlhf_option_a_or_b_plz_help_me_choose/",
          "publishedOn": "2023-09-01T04:12:18.000Z",
          "wordCount": 2852,
          "title": "RLHF, option A or B, plz help me choose",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/166q971/what_are_dreams_for_twitching_in_fetal_dreaming/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/166q971/what_are_dreams_for_twitching_in_fetal_dreaming/",
          "publishedOn": "2023-08-31T23:10:58.000Z",
          "wordCount": 2612,
          "title": "\"What Are Dreams For?\" (twitching in fetal dreaming suggests dreams are offline RL for learning motor control)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/166iyqr/dqn_cant_solve_frozen_lake_environment/",
          "author": null,
          "description": "Hello all,\n I am trying to solve the frozen lake environment using DQN. And I see two issues.\n One is that the loss falls down to zeros and second the agent only reaches the goal only 5 times in 1000 epochs.\n Here's my code.\n import numpy as np import tensorflow as tf from tensorflow.keras import layers, activations import matplotlib.pyplot as plt import gym def create_agent(num_inputs, num_outputs, layer1, layer2): inputs = layers.Input(shape=(num_inputs, )) hidden1 = layers.Dense(layer1)(inputs) activation1 = activations.relu(hidden1) hidden2 = layers.Dense(layer2)(activation1) activation2 = activations.relu(hidden2) outputs = layers.Dense(num_outputs, activation='linear')(activation2) model = tf.keras.Model(inputs, outputs) return model loss_mse = tf.keras.losses.MeanSquaredError() lear…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/166iyqr/dqn_cant_solve_frozen_lake_environment/",
          "publishedOn": "2023-08-31T18:30:57.000Z",
          "wordCount": 3123,
          "title": "DQN can't solve frozen lake environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/166gmnc/echo_chess_the_quest_for_solvability_level_design/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/166gmnc/echo_chess_the_quest_for_solvability_level_design/",
          "publishedOn": "2023-08-31T17:01:26.000Z",
          "wordCount": 2615,
          "title": "\"Echo Chess: The Quest for Solvability\" (level design preference learning: predicting high-quality soluble mazes using human feedback from quitting rates)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1668xd3/p_library_to_import_multiple_urdf_robots_and/",
          "author": null,
          "description": "I have experience in deep learning but am a beginner in using deep reinforcement learning for robotics. However, I have recently gone through the huggingface course on deep reinforcement learning.\n I tried tinkering around with panda-gym but am having trouble trying to start my own project. I am trying to use two UR5 robots do some bimanual manipulation tasks e.g. have the left arm hold onto a cup while the right pours water into it. panda-gym allows me to import a URDF file of my own robot but I can't find the option to import my own objects like the xml file (or any extension) of a table or a water bottle.\n I have no idea which library allows me to import multiple URDF robots and xml objects and was hoping for some help.\n    submitted by    /u/I_am_a_robot_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1668xd3/p_library_to_import_multiple_urdf_robots_and/",
          "publishedOn": "2023-08-31T11:46:55.000Z",
          "wordCount": 2728,
          "title": "[P] Library to import multiple URDF robots and objects ?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1660r0h/minibatch_in_ppo/",
          "author": null,
          "description": "Hi \n I am struggling to understand the mini-batch in PPO. \n Say I already collected two trajectories.\n Traj_A = [t = 1, t= 2, t=3 ,.... t = 100]\n Traj_B = [t =1 , t=2, ... t= 78] \n Now, I heard you usually break this down onto mini-batch (say a batchsize of 6). \n Do you do random sampling?\n eg, one batch is [Traj_A_t=1, Traj_A_t=2, Traj_A_t=100, Traj_A_t=66, Traj_A_t=77, Traj_A_t=55]???\n OR do you need to maintain some sequence [Traj_A_t=1, Traj_A_t=2, Traj_A_t=3, Traj_A_t=4, Traj_A_t=5, Traj_A_t=6]???\n    submitted by    /u/No_Oilve_6577  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1660r0h/minibatch_in_ppo/",
          "publishedOn": "2023-08-31T04:17:26.000Z",
          "wordCount": 2668,
          "title": "Mini-Batch in PPO",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/165sodq/could_anyone_help_me_why_the_following_list_is/",
          "author": null,
          "description": "​\n https://preview.redd.it/qderz9bsoblb1.png?width=1195&format=png&auto=webp&s=fb8ec749d0ce5000e66951b173228278a1d4c3a3\n    submitted by    /u/nimageran  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/165sodq/could_anyone_help_me_why_the_following_list_is/",
          "publishedOn": "2023-08-30T22:21:44.000Z",
          "wordCount": 2598,
          "title": "Could anyone help me why the following list is the optimal policy for this environment? (Reference: Sudharsan's Deep RL book)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/165sodl/could_anyone_help_me_why_the_following_list_is/",
          "author": null,
          "description": "​\n https://preview.redd.it/qderz9bsoblb1.png?width=1195&format=png&auto=webp&s=fb8ec749d0ce5000e66951b173228278a1d4c3a3\n    submitted by    /u/nimageran  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/165sodl/could_anyone_help_me_why_the_following_list_is/",
          "publishedOn": "2023-08-30T22:21:44.000Z",
          "wordCount": 2598,
          "title": "Could anyone help me why the following list is the optimal policy for this environment? (Reference: Sudharsan's Deep RL book)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/165ivu8/help_with_rllib_alternatives/",
          "author": null,
          "description": "RLLib is currently stealing my remaining sanity, so I'm making a desperate scream into the void. I can't get my troubleshooting right. \n I built a nice, custom Gym env that I've been running with SB3 and I feel like I'm caught in an endless array of errors, currently: ValueError: The two structures don't have the same nested structure.\n I can't help but feel like I'm going about this wrong and missing important information on how to do this correctly. The RayLlib Forum hasn't really been filled with people, so I'm asking:\n Does anyone know of a Debugging Manual/ A Discord Server/ A Migration Guide?\n    submitted by    /u/tessherelurkingnow  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/165ivu8/help_with_rllib_alternatives/",
          "publishedOn": "2023-08-30T16:07:37.000Z",
          "wordCount": 2686,
          "title": "Help With RLLib/ Alternatives",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/165ho7i/recommendations_for_rl_library_for_unvectored/",
          "author": null,
          "description": "Hi, \n I'm working on a problem which has a custom gym environment which I've made, and as it interacts with multiple other modules which have their own quirks, I need to use a reinforcement learning library which works in a specific way that I've only seen PFRL use. \n The training loop needs to be in this format: 'obs, reward, done = agent.step(action)', 'agent.observe(obs, reward, ... )' rather than what I see in most modern RL libraries where you define an agent and then run a '.train()' method. \n Are there any libraries which work in this way? I'd love to use something like StableBaselines but they don't seem to play nice and I'd rather not rewrite the gym environment if I can avoid it. \n Thanks\n    submitted by    /u/return_reza  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/165ho7i/recommendations_for_rl_library_for_unvectored/",
          "publishedOn": "2023-08-30T15:21:54.000Z",
          "wordCount": 2709,
          "title": "Recommendations for RL Library for 'unvectored' environments",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/165d39o/mdps_gentle_tutorial/",
          "author": null,
          "description": "Markov Decision Processes (MDPs) form the cornerstone of reinforcement learning (RL) and serve as a fundamental modeling tool for making sequential decisions. In this note, we present a comprehensive definition of MDPs and provide a detailed derivation of the Bellman equations, along with the optimality results. Our approach aims to ensure a thorough understanding by avoiding the omission of any steps in the mathematical proofs. The primary goal is to facilitate reading classic textbooks on (approximate) dynamic programming, optimal control, and reinforcement learning, where proofs and derivations can sometimes obscure crucial details, making them less accessible to readers from diverse scientific and engineering backgrounds.\n https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4535241\n    submitted by    /u/omroot  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/165d39o/mdps_gentle_tutorial/",
          "publishedOn": "2023-08-30T12:17:07.000Z",
          "wordCount": 2687,
          "title": "MDPs: gentle tutorial ...",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/165bap0/do_you_know_poker_ai_gyms_for_adversarial_policy/",
          "author": null,
          "description": "I want to try use adversarial policies (https://arxiv.org/abs/1905.10615) against poker no limit holdem 6-9 players RL models. \n I was looking for open-ai gym like environement for that project. Im looking for: - access to game state from each player persperctive (to create input for adversarial model) - support for custom bets (not limited to 0, 1/2pot, all-in) - build-in RL models / support for opensoure RL models - option to add custom model as player\n So far I found those and read readme files: https://github.com/dickreuter/neuron_poker https://github.com/fschlatt/clubs_gym https://rlcard.org/ https://www.deepmind.com/open-source/openspiel\n Did anybody work on similar project? Which gym did you use, and what experience do you have with it? \n Since, adversarial policies tend to work better for high-dimensionality I would prefer to 6players variant. I know that modern poker ai approach are not based on pure RL, but I want to check how vulnerable are classic RL poker models.\n    submitted by    /u/MrCogito_hs  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/165bap0/do_you_know_poker_ai_gyms_for_adversarial_policy/",
          "publishedOn": "2023-08-30T10:49:21.000Z",
          "wordCount": 2731,
          "title": "Do you know Poker Ai gyms for adversarial policy trainings?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1658t4n/twitter_machine_learning_community/",
          "author": null,
          "description": "submitted by    /u/x9182  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1658t4n/twitter_machine_learning_community/",
          "publishedOn": "2023-08-30T08:26:34.000Z",
          "wordCount": 2583,
          "title": "Twitter / Machine Learning Community",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1657l0p/reinforcement_learning_environment_for_cyber/",
          "author": null,
          "description": "submitted by    /u/limmen  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1657l0p/reinforcement_learning_environment_for_cyber/",
          "publishedOn": "2023-08-30T07:10:51.000Z",
          "wordCount": 2596,
          "title": "Reinforcement learning environment for cyber security automation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1654zy2/how_do_i_teach_my_ppo_agent_to_play_breakout/",
          "author": null,
          "description": "I have coupled my agent with EnvPool in order to speed up the learning process. It seems to be playing Pong in less than an hour. However, when I try to make it Breakout, even after many hours it still struggles. Also, it it seems like the network is facing catastrophic forgetting as after a few hours it's performance suddenly deteriorates. Any ideas to fix this? I tried incorporating major ideas for PPO from here. \n Here's my code. Feel free to let me know if you have any questions. Since I have incorporated EnvPool, the code won't run in Windows anymore. \n    submitted by    /u/Academic-Rent7800  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1654zy2/how_do_i_teach_my_ppo_agent_to_play_breakout/",
          "publishedOn": "2023-08-30T04:41:30.000Z",
          "wordCount": 2689,
          "title": "How do I teach my PPO agent to play Breakout?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/164mpmg/loss_of_plasticity_in_deep_continual_learning/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/164mpmg/loss_of_plasticity_in_deep_continual_learning/",
          "publishedOn": "2023-08-29T16:13:29.000Z",
          "wordCount": 2633,
          "title": "\"Loss of Plasticity in Deep Continual Learning\", Dohare et al 2023 (Adam particularly harmful for catastrophic forgetting)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/163pdkq/rl_with_constraints_high_dimensional_state_space/",
          "author": null,
          "description": "I have an environment where there are multiple agents being represented by one neural network (so the policy outputs all of their actions). These actions as time goes on should not exceed a certain constraint level or they will put the environment into an undesired an irrecoverable state.\n I am wondering what the best way to inform these agents of this cumulative action constraint? I have appended it to my state vector but since the observation without this cumulative action is still a 625*1 vector, I think adding that constraint as just one additional state is causing it to be drowned out by the state size. Any ideas of how to addreess?\n    submitted by    /u/Feisty_Relation_2359  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/163pdkq/rl_with_constraints_high_dimensional_state_space/",
          "publishedOn": "2023-08-28T15:36:57.000Z",
          "wordCount": 2697,
          "title": "RL with Constraints, High Dimensional State Space",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/163nlz6/nash_equilibrium_in_multi_agent_rl/",
          "author": null,
          "description": "I have a multi agent competitive RL problem which I solved. Now, I want to show that all agent’s policies are at a nash equilibrium of the problem. How can I do this? Also, some things must be considered. First, I can’t mathematically model the environment so some how I have to numerically show that they reached nash eq. Another thing that I find is deviate the action of each agent and show that they don’t get a better reward but the problem is there is a actor network for each agent. How can I show deviation from the optimal policy?\n    submitted by    /u/Brief-Emotion6291  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/163nlz6/nash_equilibrium_in_multi_agent_rl/",
          "publishedOn": "2023-08-28T14:28:38.000Z",
          "wordCount": 2685,
          "title": "Nash equilibrium in Multi agent RL",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/163jgs3/machine_learning_twitter_x_community/",
          "author": null,
          "description": "submitted by    /u/x9182  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/163jgs3/machine_learning_twitter_x_community/",
          "publishedOn": "2023-08-28T11:24:23.000Z",
          "wordCount": 2584,
          "title": "Machine Learning / Twitter (X) Community",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/163gbiy/need_help_designing_a2c_agent_with_monotonic/",
          "author": null,
          "description": "I'm attempting to train an agent using A2C, where the agent generates a vector as its action at each time step. This vector represents a bidding curve, and a crucial property is that it must always increase monotonically. Otherwise, the bid is considered invalid. For example, [0, 1.2, 4.5, 58, 92.65, 104.3, 104.3] is valid because each number is greater than or equal to the previous one. I'm looking for guidance on how to design this setup, impose these constraints, and handle cases where the agent violates the sequence. While using negative rewards might not be effective due to the potential for generating numerous invalid bids, I'm unsure about the right approach. Could someone assist me with this?\n    submitted by    /u/uonliaquat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/163gbiy/need_help_designing_a2c_agent_with_monotonic/",
          "publishedOn": "2023-08-28T08:26:25.000Z",
          "wordCount": 2706,
          "title": "Need Help Designing A2C Agent with Monotonic Bidding Curve Constraints",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/162sfdn/python_library_for_modular_rl_components/",
          "author": null,
          "description": "After a year of struggling with RLlib I decided to start implementing the training code myself.\n I am looking for a RL library that offers me individual components rather than the whole algorithm. I do not need a PPO implementation, but I would fancy a library that offers me functions to compute the PPO loss given a batch of steps. \n In other words, what I need is a library that offers the most granular RL components (different losses, replay buffers, return estimators like GAE, etc) instead of full algorithm implementations. Which libraries do you recommend for this purpose? \n    submitted by    /u/fedetask  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/162sfdn/python_library_for_modular_rl_components/",
          "publishedOn": "2023-08-27T14:51:39.000Z",
          "wordCount": 2682,
          "title": "Python library for modular RL components",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/162q6yi/choosing_best_rl_library_for_mujoco_with_envpool/",
          "author": null,
          "description": "TL;DR What RL library use in combination with MuJoCo and envpool\n Hi I want to write program that would find best hyperparameters (number of joint, angles) for design of robots (similar to NAS). \n It would work in such a way that I would have one RL algorithm that would search for the hyperparameters of the robot and then I would to train and evaluate this robot using SAC in MuJoCo physical simulator.\n Problem is that MuJoCo runs on CPU and I need lots of parallel enviroments and for this I would use envpool https://github.com/sail-sg/envpool.\n The question is what (if any) RL library should I use as a wrapper.\n The options are Stable-Baselines3, Tianshou, ACME, CleanRL, or rl_games. \n picture of one robot design https://imgur.com/a/5UDdEsE\n Other than that, do you have any recommendations or notes regarding my project idea?\n Thanks for response\n    submitted by    /u/EFK1500  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/162q6yi/choosing_best_rl_library_for_mujoco_with_envpool/",
          "publishedOn": "2023-08-27T13:17:28.000Z",
          "wordCount": 2724,
          "title": "Choosing best RL library for MuJoCo with envpool",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/162jw71/action_selection_in_multiple_action_for/",
          "author": null,
          "description": "I have a confusion in action selection in actor of DDPG algorithm. The actor receive state as input and output as deterministic action (generally from tanh function). In the multiple continuous action environment, does the actor perform multiple action simultaneously from the clipped output Tanh [-1,1]? or it has some posterior function converting from Tanh vectors to single deterministic action like Softmax?\n    submitted by    /u/AnnonymeowCat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/162jw71/action_selection_in_multiple_action_for/",
          "publishedOn": "2023-08-27T07:37:07.000Z",
          "wordCount": 2651,
          "title": "Action selection in Multiple action for continuous state spaces in DDPG",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/162b5kq/mathematics_of_best_of_n_sampling/",
          "author": null,
          "description": "Best of n Sampling is a surprisingly simple technique to steer an LM to human preferences much in the same way as Reinforcement Learning algorithms such as RLHF do. Here is the blogpost [0] describing Best of n. [0]\n https://preview.redd.it/cpi5tj3injkb1.png?width=1670&format=png&auto=webp&s=33eb3f301b515926fd5820ea3c60acd0e1c5ddb1\n The blog post claims that one neat property of Best-of-n sampling is that the KL divergence with the initial policy can be computed analytically in closed form.\n ​\n https://preview.redd.it/eij0igaxnjkb1.png?width=1724&format=png&auto=webp&s=73040d49ae55ac651c5fe62b0f4a06b7f8bfd2c5\n This turns out to be \n https://preview.redd.it/gbn7ch10ojkb1.png?width=270&format=png&auto=webp&s=849fe773b31b795c9253fa4cd8172c3120aec745\n The blog post provides a hint to express the pdf of BoN in terms of PDF and CDF of the original distribution, but I cannot see how I can express the PDF of BoN in terms of PDF and CDF of the original distribution. Can anyone help me with this?\n [0] https://openai.com/research/measuring-goodharts-law\n    submitted by    /u/ElendirThreadripper  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/162b5kq/mathematics_of_best_of_n_sampling/",
          "publishedOn": "2023-08-27T00:08:40.000Z",
          "wordCount": 2707,
          "title": "Mathematics of Best of n Sampling",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1623ni1/upside_down_reinforcement_learning_implementation/",
          "author": null,
          "description": "I recently implemented UDRL and just published it.\n If anyone finds it useful, feel free to check it out: https://github.com/mphe/upside-down-reinforcement-learning.\n There are many other implementations out there, but most of them are difficult to extend and maintain, due to being written in a sloppy manner, or are incorrect, e.g. not using multiplicative interactions or contain smaller bugs and issues.\n This project aims to fix these issues, while potentially improving performance, providing a proper OOP interface, and reusing code from Stable Baselines 3 where applicable.\n Furthermore, the algorithm has been extended to support additional features, like multi-threading, which speeds up the training time immensely. It also provides an interface similar to SB algorithms, so it can be used mostly analogously.\n For more information, see the Github page.\n Contributions are welcome!\n    submitted by    /u/mphe_  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1623ni1/upside_down_reinforcement_learning_implementation/",
          "publishedOn": "2023-08-26T19:05:38.000Z",
          "wordCount": 2712,
          "title": "Upside Down Reinforcement Learning Implementation",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/1622jj5/multiagent_rl_where_agents_actions_are_dependent/",
          "author": null,
          "description": "I am working to design an multi-agent reinforcement learning agent, where the agents that are spatially close are connected and the information is shared, which will be done through a convolution process. \n However, when convoluting the nearby agents' observations, I also wish nearby agents' action values to be part of the local observation that will be convoluted, however this would cause a dilemma as for an agent to choose and action, it will have to know other agents' actions but the other agents would have to know this agent's value for deciding the value.\n Are there MARL methods that can help me fix this problem? \n    submitted by    /u/LeSUTHU  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/1622jj5/multiagent_rl_where_agents_actions_are_dependent/",
          "publishedOn": "2023-08-26T18:22:43.000Z",
          "wordCount": 2694,
          "title": "Multi-Agent RL where agents' actions are dependent on nearby agent's actions",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/161ucvj/advice_on_understanding_intuition_behind_rl/",
          "author": null,
          "description": "I am trying to understand Policy Iteration from the book \"Reinforcement learning an introduction\".\n I understood the pseudo code and applied it using python.\n But still I feel like I don't have a intuitive understanding of Policy Iteration. Like why it works? I know how it works.\n Any advice on how to get an intuitive understanding of RL algorithms?\n I reread the policy iteration multiple times, but still feel like I don't understand it.\n    submitted by    /u/mono1110  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/161ucvj/advice_on_understanding_intuition_behind_rl/",
          "publishedOn": "2023-08-26T12:48:19.000Z",
          "wordCount": 2659,
          "title": "Advice on understanding intuition behind RL algorithms.",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15zwnog/needing_some_help_with_choosing_the_action_and/",
          "author": null,
          "description": "I am currently trying to implement a custom environment but ran into a problem, because I don't know how to implement the action and observation space to solve the following (simplified) problem:\n - I have a board that consists of a large 1-D array of size x\n - For each episode I randomly generate N pieces, all with different IDs, consisting of different sizes on a per piece base that are to be placed on the board, but not all pieces can fit on the board at the same time\n - The action space in step 0 has size N and by picking an action the piece with the ID corresponding to the chosen action will be placed on the board and the action is removed from the action space\n - The goal is to fill the board as much as possible\n ​\n Let's have an example rundown of an episode: Let's say we have x=100…",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15zwnog/needing_some_help_with_choosing_the_action_and/",
          "publishedOn": "2023-08-24T09:13:36.000Z",
          "wordCount": 2984,
          "title": "Needing some help with choosing the action and observation space of a custom environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15zre73/marl_help_to_understand_supersuit_approach/",
          "author": null,
          "description": "Hi everyone,\n I have successfully trained a simple multiagent game environment using Stable Baselines 3 + PettingZoo + SuperSuit. Surprisingly, all of the agents learn incredibly well using a single agent interface as stable baselines 3 is.\n Now, my question is: I don't really get the classification of this algorithm. Is it an example of \"joint action learning\" or \"centralised training and decentralised execution\"?\n I have been following this tutorial in an handcrafted problem of mine: https://towardsdatascience.com/multi-agent-deep-reinforcement-learning-in-15-lines-of-code-using-pettingzoo-e0b963c0820b\n Unfortunately, SuperSuit doesn't seem to provide a detailed explanation of its workflow. It seems like that observation and chosen actions are stacked together, so I'm tending to think that it's a joint action learning implementation. \n Thank you in advance!\n    submitted by    /u/IntelligentAd6407  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15zre73/marl_help_to_understand_supersuit_approach/",
          "publishedOn": "2023-08-24T04:29:02.000Z",
          "wordCount": 2700,
          "title": "MARL: help to understand SuperSuit approach",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15z4k7w/simple_gridworld_gymnasium_environment/",
          "author": null,
          "description": "SimpleGrid is a basic and simple gridworld environment compatible with Farama-Foundation's Gymnasium. \n https://i.redd.it/6dfro8o11vjb1.gif\n It is easy to use and customise and it is intended to offer an environment for quickly testing and prototyping different RL algorithms.\n Check it out at: https://github.com/damat-le/gym-simplegrid\n    submitted by    /u/damat-le  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15z4k7w/simple_gridworld_gymnasium_environment/",
          "publishedOn": "2023-08-23T13:52:09.000Z",
          "wordCount": 2622,
          "title": "Simple Gridworld Gymnasium Environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15z0pgo/help_with_bounded_actorcritic_algorithm_hyper/",
          "author": null,
          "description": "I'm working on solving an optimisation problem using RL and currently trying out a Bounded Actor-Critic agent.\n I tuned the hyperparameters of my agent using Bayesian optimisation running each iteration of the optimiser for 1000 episodes. The agent is performing well using the tuned hyperparameter when run for 1000 episodes, exceeding the performance of my previous Q-learning agent.\n However, when run for longer iterations it finds the optimal policy but later deviates and converges to a suboptimal policy leading to really poor overall performance.\n I suspect the issue might be the high learning rate of the actor and the low learning rate of the critic. I tried using a basic decay schedule for the actor's learning rate and it seems to improve the stability. However, the performance is lower than the Q-learning agent. \n Why is this happening iyo? Any ideas on how to fix it is appreciated.\n Picture of rewards for reference:\n ​\n Reward v Iteration\n    submitted by    /u/WengerIn420  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15z0pgo/help_with_bounded_actorcritic_algorithm_hyper/",
          "publishedOn": "2023-08-23T11:08:54.000Z",
          "wordCount": 2741,
          "title": "Help with bounded Actor-Critic Algorithm - Hyper parameters",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15yodjj/best_waydata_structure_to_store_a_mdp/",
          "author": null,
          "description": "In your experience, what is the best data structure to store a Markov Decision Process, it could be built-in like list, tuple, set, dict, or module-related np.array, or others in CS field like heap, queue, etc.?\n ​\n https://preview.redd.it/08dlubqacrjb1.png?width=969&format=png&auto=webp&s=b9ed64a935b12cae9954021dc435d81a2569596e\n    submitted by    /u/Neither_Canary_7726  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15yodjj/best_waydata_structure_to_store_a_mdp/",
          "publishedOn": "2023-08-23T00:50:43.000Z",
          "wordCount": 2621,
          "title": "Best way/data structure to store a MDP?",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15ylpi0/increase_in_loss_and_stagnant_reward_in_dqn/",
          "author": null,
          "description": "I am attempting to train an agent using StableBaselines3 on a custom environment. I am using the DQN algorithm with default parameters. However, I have noticed that after a certain point, my loss values start to consistently increase, while the reward remains relatively unchanged or it just oscillates. I have made various attempts to adjust the parameters on my own, but I have not been successful in resolving this issue. I would greatly appreciate it if someone could provide guidance on what might be causing this behavior and offer suggestions on how to address this problem.\n    submitted by    /u/uonliaquat  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15ylpi0/increase_in_loss_and_stagnant_reward_in_dqn/",
          "publishedOn": "2023-08-22T23:01:16.000Z",
          "wordCount": 2686,
          "title": "Increase in Loss and Stagnant Reward in DQN Training using Stable Baselines3",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15yj2ap/p_pettingzoo_1240_has_been_released_including/",
          "author": null,
          "description": "PettingZoo 1.24.0 is now live! This release includes Python 3.11 support, updated Chess and Hanabi environment versions, and many bugfixes, documentation updates and testing expansions. We are also very excited to announce 3 tutorials using Stable-Baselines3, and a full training script using CleanRL with TensorBoard and WandB.\n Tweet: https://twitter.com/FaramaFound/status/1694095374569394447\n Release notes: https://github.com/Farama-Foundation/PettingZoo/releases/tag/1.24.0\n For more information about the Farama Foundation, see https://farama.org/, or join our discord server: https://discord.gg/nhvKkYa6qX\n    submitted by    /u/elliottower  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15yj2ap/p_pettingzoo_1240_has_been_released_including/",
          "publishedOn": "2023-08-22T21:22:34.000Z",
          "wordCount": 2654,
          "title": "[P] PettingZoo 1.24.0 has been released (including Stable-Baselines3 tutorials)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15y44fz/summary_for_the_sutton_and_barto_book/",
          "author": null,
          "description": "Is there a good summary online out there for the Sutton and Barto book?\n    submitted by    /u/immer_hungrig  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15y44fz/summary_for_the_sutton_and_barto_book/",
          "publishedOn": "2023-08-22T12:16:42.000Z",
          "wordCount": 2599,
          "title": "Summary for the Sutton and Barto book",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15y258c/continue_training_after_slight_modification_to/",
          "author": null,
          "description": "I trained for a few iterations, tested my model, and noticed an unwanted behaviour. This unwanted behaviour can be fixed by a slight adjustment in the reward scheme in the environment. \n I imagine this is very common - when you guys are in such situations, do you retrain from scratch or continue training the model from the last checkpoint. Is this dependant in any way on which Policy algorithm is used? Or perhaps on the parameters set that could influence this e.g. gamma? \n Thanks!\n    submitted by    /u/WagnerianJLC  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15y258c/continue_training_after_slight_modification_to/",
          "publishedOn": "2023-08-22T10:47:00.000Z",
          "wordCount": 2670,
          "title": "Continue training after slight modification to the environment",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15xoobk/help_defining_environment_with_complex_action/",
          "author": null,
          "description": "As said on the title, I'm working on a personal MARL project with a high-dimensional and continuous action space. The environment is designed to give positive rewards to actions between some moving limits of the action range, and negative rewards to the actions outside of those limits. For example: \n  \nGlobal action range: (0, 1000)\n Desired action range for first 100k steps: (0, 10)\n Desired action range for 100-200k steps: (30, 40)\n ...\n  \nTherefore, the main challenge of the environment is that actions with positive rewards on certain stage of the environment would return negative rewards on the following stages.\n How should I define the actions of the agent? I've tried the following methods without success:\n  \nSimply scale actions between 0 and 1000 and hope that agents learn the moving distribution of rewards\n Transform actions to percent variations and scale actions over a non-observed moving average (I tried adding the moving average to the observations but the results stayed the same)\n Observations do consider a dimension that serve to differentiate when a distributional shift happens \n Also, I've tried using SAC and DDPPG to model agents\n  \nFeel free to share any comments or suggestions. Thanks!\n ​\n    submitted by    /u/stinoco  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15xoobk/help_defining_environment_with_complex_action/",
          "publishedOn": "2023-08-21T23:57:43.000Z",
          "wordCount": 2778,
          "title": "Help defining environment with complex action space",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15xb6z5/diversifying_ai_towards_creative_chess_with/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15xb6z5/diversifying_ai_towards_creative_chess_with/",
          "publishedOn": "2023-08-21T15:40:02.000Z",
          "wordCount": 2609,
          "title": "\"Diversifying AI: Towards Creative Chess with AlphaZero\", Zahavy et al 2023 {DM} (diversity search by conditioning on an ID variable)",
          "imageUrl": null
        },
        {
          "id": "https://www.reddit.com/r/reinforcementlearning/comments/15xb664/trainable_transformer_in_transformer_tint/",
          "author": null,
          "description": "submitted by    /u/gwern  \n [link]   [comments]",
          "link": "https://www.reddit.com/r/reinforcementlearning/comments/15xb664/trainable_transformer_in_transformer_tint/",
          "publishedOn": "2023-08-21T15:39:10.000Z",
          "wordCount": 2604,
          "title": "\"Trainable Transformer in Transformer (TinT)\", Panigrahi et al 2023 (architecturally supporting internal meta-learning / fast-weights)",
          "imageUrl": null
        }
      ]
    },
    {
      "title": "RL News",
      "feedUrl": "https://www.getrevue.co/profile/seungjaeryanlee?format=rss",
      "siteUrl": "http://rlnews.ryanlee.ai/",
      "articles": []
    },
    {
      "title": "Damian Bogunowicz - dtransposed",
      "feedUrl": "https://dtransposed.github.io/feed.xml",
      "siteUrl": "http://dtransposed.github.io/",
      "articles": []
    },
    {
      "title": "Data Science Central",
      "feedUrl": "http://feeds.feedburner.com/FeaturedBlogPosts-DataScienceCentral?format=xml",
      "siteUrl": "https://www.datasciencecentral.com/",
      "articles": [
        {
          "id": "https://www.datasciencecentral.com/?p=63209",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 19 September 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-19-september-2023/",
          "publishedOn": "2023-09-19T19:24:46.000Z",
          "wordCount": 5890,
          "title": "DSC Weekly 19 September 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63203",
          "author": "Abhi Sawhney",
          "description": "Where do you start if you want to build a data analytics function from the ground up? As an analytics leader at a startup, you will need to make several important decisions early on to build an effective team. This article dives into four decision areas and highlights ways in which to think about them:… Read More »A guide to setting up analytics at a consumer tech startup\nThe post A guide to setting up analytics at a consumer tech startup appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/a-guide-to-setting-up-analytics-at-a-consumer-tech-startup/",
          "publishedOn": "2023-09-19T12:57:50.000Z",
          "wordCount": 7538,
          "title": "A guide to setting up analytics at a consumer tech startup",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/pasted-image-0.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63194",
          "author": "Roger Brown",
          "description": "The two most prominent technologies that have been making waves in the AI industry are Conversational AI and Generative AI. They have revolutionized the manner in which humans interact and work with machines to generate content. Both these technologies have the power and capability to automate numerous tasks that humans would take hours, days, and… Read More »A complete guide: Conversational AI vs. generative AI\nThe post A complete guide: Conversational AI vs. generative AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/a-complete-guide-conversational-ai-vs-generative-ai/",
          "publishedOn": "2023-09-19T12:50:07.000Z",
          "wordCount": 5939,
          "title": "A complete guide: Conversational AI vs. generative AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/Generative-AI-vs-Conversational-AI-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63190",
          "author": "Bill Schmarzo",
          "description": "In part 1 of this series on the updated “AI Apps Development Canvas,” I introduced the updated AI Apps Product Development Design Canvas.  The AI Apps Product Development Canva is one of the capstone deliverables for my “Thinking Like a Data Scientist” methodology, so getting feedback is critical to ensure that the methodology is relevant… Read More »AI Apps Product Development Canvas – Part 2\nThe post AI Apps Product Development Canvas – Part 2 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ai-apps-product-development-canvas-part-2/",
          "publishedOn": "2023-09-16T19:31:27.000Z",
          "wordCount": 7633,
          "title": "AI Apps Product Development Canvas – Part 2",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/Slide1-2.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63162",
          "author": "Aileen Scott",
          "description": "Working as a data scientist is the dream of many IT professionals these days. It is no secret that data science is a skyrocketing field attracting young professionals and inspiring many to switch careers to data science. On one front are young professionals who study their courses in colleges to pursue their dream of becoming… Read More »Are data science certifications the gateway to competitive pay?\nThe post Are data science certifications the gateway to competitive pay? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/are-data-science-certifications-the-gateway-to-competitive-pay/",
          "publishedOn": "2023-09-14T15:10:15.000Z",
          "wordCount": 5775,
          "title": "Are data science certifications the gateway to competitive pay?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/Top-Reasons-to-choose-Data-Scientist-Certification-from-DASCA.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63132",
          "author": "Igor Khomyanin",
          "description": "CUPED: Improve Your A/B Testing - Detect Smaller Gains, Utilise Smaller Samples and Make Smarter Decisions!\nThe post CUPED for starters: Enhancing controlled experiments with pre-experiment data appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/cuped-for-starters-enhancing-controlled-experiments-with-pre-experiment-data/",
          "publishedOn": "2023-09-14T15:01:10.000Z",
          "wordCount": 7802,
          "title": "CUPED for starters: Enhancing controlled experiments with pre-experiment data",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/CUPED_proof_1.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63139",
          "author": "Jane Marsh",
          "description": "Data centers are known for their impact on the environment. They run 24/7 and exude a lot of heat. Massive warehouses full of hot technology require advanced cooling systems or an HVAC system pushed to its limit.  Data center managers and sustainability leaders no longer settle for antiquated techniques. They’re striving to develop greener and… Read More »Searching for sustainability in data center cooling\nThe post Searching for sustainability in data center cooling appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/searching-for-sustainability-in-data-center-cooling/",
          "publishedOn": "2023-09-14T14:58:36.000Z",
          "wordCount": 5881,
          "title": "Searching for sustainability in data center cooling",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/AdobeStock_467140979-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63136",
          "author": "Alan Morrison",
          "description": "The best way to model business and consumer dynamics is collaboratively, with stakeholders all in the same virtual room contributing. Of course, this has been happening asynchronously for some time now, but the potential exists for more real-time interaction.  Modelers don’t work in a vacuum, of course. The iterations between a modeler who develops a… Read More »Collaborative visual knowledge graph modeling at the system level\nThe post Collaborative visual knowledge graph modeling at the system level appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/collaborative-visual-knowledge-graph-modeling-at-the-system-level/",
          "publishedOn": "2023-09-14T14:52:10.000Z",
          "wordCount": 6114,
          "title": "Collaborative visual knowledge graph modeling at the system level",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/fiber-optic-2749588_1280-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63121",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 12 September 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-12-september-2023/",
          "publishedOn": "2023-09-12T19:59:49.000Z",
          "wordCount": 5900,
          "title": "DSC Weekly 12 September 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63117",
          "author": "Colin Priest",
          "description": "By Colin Priest, Chief Evangelist at FeatureByte Enterprises are increasingly implementing Artificial Intelligence (AI) into their operations. However, AI-ready data pipeline practices are still in their infancy, especially when it comes to IT security. The pervasiveness of “Spaghetti Code” Enterprises delving into AI data pipelines often find themselves wading through a mess of complex and… Read More »Securing your AI data pipeline with MLOps\nThe post <a></a>Securing your AI data pipeline with MLOps appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/securing-your-ai-data-pipeline-with-mlops/",
          "publishedOn": "2023-09-12T18:37:04.000Z",
          "wordCount": 6014,
          "title": "Securing your AI data pipeline with MLOps",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/AdobeStock_612366399-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62265",
          "author": "Ovais Naseem",
          "description": "Businesses today constantly strive to gain a competitive edge in their marketing efforts.  Leveraging their data effectively to create data-driven campaigns is the best way to trump the competition. One of the best tools at their disposal to utilize their data is a data warehouse. Data warehousing is crucial in enhancing marketing and campaign management… Read More »Data Warehousing: The key to effective marketing campaign management\nThe post Data Warehousing: The key to effective marketing campaign management appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-warehousing-the-key-to-effective-marketing-campaign-management/",
          "publishedOn": "2023-09-12T18:31:24.000Z",
          "wordCount": 6231,
          "title": "Data Warehousing: The key to effective marketing campaign management",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/etl-data-warehouse-diagram-1.webp"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62852",
          "author": "Costanza Tagliaferi",
          "description": "The way we work has changed, with remote teams now a common part of the landscape. While remote work offers flexibility, it also brings challenges. Managing remote teams effectively is crucial to ensure productivity and collaboration. In this article, we’ll explore how using time tracking for remote teams can help manage employees’ performance better. Time-tracking… Read More »Data-driven insights: Improving remote team performance with time-tracking analytics\nThe post Data-driven insights: Improving remote team performance with time-tracking analytics appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-driven-insights-improving-remote-team-performance-with-time-tracking-analytics/",
          "publishedOn": "2023-09-12T15:39:35.000Z",
          "wordCount": 6271,
          "title": "Data-driven insights: Improving remote team performance with time-tracking analytics",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/AdobeStock_638699899-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63099",
          "author": "Seven Kole",
          "description": "In the panorama of Artificial Intelligence (AI), Natural Language Understanding (NLU) stands as a citadel of computational wizardry. No longer in its nascent stage, NLU has matured into an irreplaceable asset for business intelligence. In this discussion, we delve into the advanced realms of NLU, unraveling its role in semantic comprehension, intent classification, and context-aware… Read More »AI for Natural Language Understanding (NLU)\nThe post <strong>AI for Natural Language Understanding (NLU)</strong> appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ai-for-natural-language-understanding-nlu/",
          "publishedOn": "2023-09-12T15:36:04.000Z",
          "wordCount": 6319,
          "title": "AI for Natural Language Understanding (NLU)",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/20945532-scaled.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63076",
          "author": "Ryan Williamson",
          "description": "The Internet of Things (IoT) has been transforming entertainment and has given it new ways of creating, delivering and consuming content. The wide-ranging utility of IoT devices has improved user experience while enhancing the safety and security of users. The media and entertainment (M&E) companies can leverage IoT technology to improve the overall quality of… Read More »How can IoT transform and benefit the entertainment industry?\nThe post How can IoT transform and benefit the entertainment industry? appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-can-iot-transform-and-benefit-the-entertainment-industry/",
          "publishedOn": "2023-09-12T15:34:07.000Z",
          "wordCount": 5944,
          "title": "How can IoT transform and benefit the entertainment industry?",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/Role-of-IoT-in-the-Entertainment-Industry-scaled.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63064",
          "author": "Anas Baig",
          "description": "In our increasingly interconnected world, the digital realm has become both a frontier of innovation and a battleground of threats. As technology advances, so do the tactics of malicious actors who seek to exploit vulnerabilities in our digital infrastructure. The rapid evolution of cyber threats calls for a paradigm shift in defense strategies, and that’s… Read More »AI and the cyber challenge: Bridging vulnerabilities in modern defense strategies\nThe post AI and the cyber challenge: Bridging vulnerabilities in modern defense strategies appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ai-and-the-cyber-challenge-bridging-vulnerabilities-in-modern-defense-strategies/",
          "publishedOn": "2023-09-12T15:32:48.000Z",
          "wordCount": 6506,
          "title": "AI and the cyber challenge: Bridging vulnerabilities in modern defense strategies",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/ai-cybersecurity-risks.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63086",
          "author": "Bill Schmarzo",
          "description": "AI Apps are domain-infused, AI/ML-powered applications that continuously learn and adapt with minimal human intervention in helping non-technical users manage data and analytics-intensive operations to deliver well-defined operational outcomes. I originally introduced the idea of a “Data Product Development Canvas” as one of the capstone deliverables (the other being the data science Hypothesis Development Canvas)… Read More »AI apps product development canvas – Part 1\nThe post AI apps product development canvas – Part 1 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/ai-apps-product-development-canvas-part-1/",
          "publishedOn": "2023-09-10T22:56:51.000Z",
          "wordCount": 6489,
          "title": "AI apps product development canvas – Part 1",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/Slide1-1.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63018",
          "author": "Diana Jane",
          "description": "In an increasingly interconnected world where digital transactions have become the norm the battle against fraud has taken on new dimensions. The challenge lies not only in identifying familiar fraud patterns but also in unearthing the intricate web of evolving deceptions that threaten industries such as finance, e-commerce, and insurance. As fraudsters continually adapt their… Read More »Fraud detection using Machine Learning: Unmasking deceptive patterns\nThe post Fraud detection using Machine Learning: Unmasking deceptive patterns appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/fraud-detection-using-machine-learning-unmasking-deceptive-patterns/",
          "publishedOn": "2023-09-06T20:22:49.000Z",
          "wordCount": 8957,
          "title": "Fraud detection using Machine Learning: Unmasking deceptive patterns",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/AdobeStock_110928001-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63063",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 5 September 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-5-september-2023/",
          "publishedOn": "2023-09-05T19:11:03.000Z",
          "wordCount": 5939,
          "title": "DSC Weekly 5 September 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63039",
          "author": "Tarique",
          "description": "Artificial Intelligence has become a compulsive innovation for humankind, that we cannot live without. It has been gaining strength with every passing moment. The impact of AI applications extends beyond improved business results and can be significant in elevating and enriching the human experience. Popular AI trends in the past have revealed a compelling need… Read More »16 most interesting AI applications across industries worldwide\nThe post 16 most interesting AI applications across industries worldwide appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/16-most-interesting-ai-applications-across-industries-worldwide/",
          "publishedOn": "2023-09-05T18:18:16.000Z",
          "wordCount": 6096,
          "title": "16 most interesting AI applications across industries worldwide",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/AI-APPLICATIONS-ACROSS-INDUSTRIES-WORLDWIDE-USAII.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63032",
          "author": "ajitjaokar",
          "description": "As generative AI evolves, certain trends are becoming clearer,  In yet another milestone in AI consulting giant McKinsey unveiled its own generative AI tool for employees called lilli My comments a) McKinsey launching this agent gives credibility to the domain for enterprise AI assistants b) On one hand, it’s a familiar copilot strategy – but… Read More »Generative AI megatrends: Generative AI for enterprise is proven vs generative AI for  consumer is not – Part One\nThe post Generative AI megatrends: Generative AI for enterprise is proven vs generative AI for  consumer is not – Part One appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/generative-ai-megatrends-generative-ai-for-enterprise-is-proven-v-s-generative-ai-for-consumer-is-not-part-one/",
          "publishedOn": "2023-09-05T18:17:31.000Z",
          "wordCount": 5625,
          "title": "Generative AI megatrends: Generative AI for enterprise is proven vs generative AI for  consumer is not – Part One",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/lilli.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63007",
          "author": "RobFarber",
          "description": "Programmers can no longer rely on the traditional method of targeting specific hardware accelerators with conditional pragmas (e.g., #ifdef) to match the software to the hardware at a particular datacenter or customer site. Humans writing machine-specific code cannot address the exponential increase in possible hardware combinations in the modern multivendor, multiarchitecture computing environment. Open software provides a multiarchitecture, multivendor solution that addresses the complexities of accelerated HPC and AI computing.\nThe post Addressing the challenge of software support for multiarchitecture AI accelerated HPC appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/addressing-the-challenge-of-software-support-for-multiarchitecture-ai-accelerated-hpc/",
          "publishedOn": "2023-09-05T18:16:46.000Z",
          "wordCount": 7470,
          "title": "Addressing the challenge of software support for multiarchitecture AI accelerated HPC",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/Fig1.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63045",
          "author": "ajitjaokar",
          "description": "In part one of this blog, we saw how there is an increasing case for an enterprise chatbot use case. In part two, we ask the question  Could a consumer chatbot i.e. directly customer facing chatbot be a flawed use case for an LLM? The consumer (customer facing) chatbot case is a familiar use case… Read More »Generative AI megatrends: Generative AI for enterprise is proven  vs generative AI for  consumer is not – Part two\nThe post Generative AI megatrends: Generative AI for enterprise is proven  vs generative AI for  consumer is not – Part two appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/generative-ai-megatrends-generative-ai-for-enterprise-is-proven-vs-generative-ai-for-consumer-is-not-part-two/",
          "publishedOn": "2023-09-05T18:15:24.000Z",
          "wordCount": 5787,
          "title": "Generative AI megatrends: Generative AI for enterprise is proven  vs generative AI for  consumer is not – Part two",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/sisters-6274746_1280.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63049",
          "author": "Bill Schmarzo",
          "description": "This blog post is not the end of my journey to integrate GenAI with my “Thinking Like a Data Scientist” (TLADS) methodology, but it is the last post on this leg of the journey. And the journey has been fascinating.  I can’t wait to get this modified material in front of my students. In part… Read More »Integrating GenAI into “Thinking Like a Data Scientist” Methodology – Part III\nThe post Integrating GenAI into “Thinking Like a Data Scientist” Methodology – Part III appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/integrating-genai-into-thinking-like-a-data-scientist-methodology-part-iii/",
          "publishedOn": "2023-09-02T18:47:00.000Z",
          "wordCount": 7125,
          "title": "Integrating GenAI into “Thinking Like a Data Scientist” Methodology – Part III",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/09/Slide1.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63017",
          "author": "Kevin Donvas",
          "description": "Data is crucial in most industries today. As the amount of business information grows, so do the standards for people’s protection of their personal information. With advanced cyberattacks, security compliance frameworks and cybersecurity have become essential fields to ensure data is collected, organized, stored, and managed in a safe way. This article will start by… Read More »4 data compliance standards to know for 2023\nThe post 4 data compliance standards to know for 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/4-data-compliance-standards-to-know-for-2023/",
          "publishedOn": "2023-08-31T13:05:17.000Z",
          "wordCount": 7201,
          "title": "4 data compliance standards to know for 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/AdobeStock_625000677-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63014",
          "author": "Alan Morrison",
          "description": "Large language models (LLMs) fit parameters (features in data topography) to a particular dataset, such as text scraped off the web and conformed to a training set.  Logical data models (LDMs), by contrast, model what becomes shared within entire systems. They bring together the data in a system with the help of various kinds of… Read More »How the LDMs in knowledge graphs can complement LLMs\nThe post How the LDMs in knowledge graphs can complement LLMs appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-the-ldms-in-knowledge-graphs-can-complement-llms/",
          "publishedOn": "2023-08-31T12:56:39.000Z",
          "wordCount": 6443,
          "title": "How the LDMs in knowledge graphs can complement LLMs",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/networking-1586679_1280.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?post_type=vimeo-video&p=63008",
          "author": "Ben Cole",
          "description": "As businesses struggle with more data sources and destinations than ever, they strive to bring governance, security, and efficiency to their data ops. To address these concerns, many companies adopted open-source Apache NiFi as a versatile tool for their data distribution needs. While NiFi accelerates the speed at which developers can build new pipelines, managing… Read More »DSC Webinar Series: How to Scale NiFi Deployments to Enable Universal Data Distribution\nThe post DSC Webinar Series: How to Scale NiFi Deployments to Enable Universal Data Distribution appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-webinar-series-how-to-scale-nifi-deployments-to-enable-universal-data-distribution/",
          "publishedOn": "2023-08-29T19:08:54.000Z",
          "wordCount": 5462,
          "title": "DSC Webinar Series: How to Scale NiFi Deployments to Enable Universal Data Distribution",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/p63008-vimeo-thumbnail.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=63006",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 29 August 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-29-august-2023/",
          "publishedOn": "2023-08-29T18:44:20.000Z",
          "wordCount": 5967,
          "title": "DSC Weekly 29 August 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62983",
          "author": "Anas Baig",
          "description": "In the dynamic landscape of modern business, the art of seamless data migration has evolved into a strategic imperative. As you navigate the intricacies of workspace transformations, you’re met with a complex interplay of technological advancements and operational demands Enter the era of leveraging Artificial Intelligence (AI) to redefine data migration – an approach that… Read More »Data migration redefined: Leveraging AI trends for smooth workspace transitions\nThe post Data migration redefined: Leveraging AI trends for smooth workspace transitions appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-migration-redefined-leveraging-ai-trends-for-smooth-workspace-transitions/",
          "publishedOn": "2023-08-29T18:30:28.000Z",
          "wordCount": 6297,
          "title": "Data migration redefined: Leveraging AI trends for smooth workspace transitions",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/ai-data-migration.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62960",
          "author": "Ovais Naseem",
          "description": "Currently, the use of technology in shipping and logistics is leading the industry through a transformative era, driven by rapid technological advancements, undoubtedly marking a pivotal moment in the digital shipping evolution. From automating routine processes to employing intelligent algorithms that predict and optimize routes, the technological revolution is redefining the way goods are transported… Read More »The future of shipping: How technology is shaping logistics and fulfillment\nThe post The future of shipping: How technology is shaping logistics and fulfillment appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/the-future-of-shipping-how-technology-is-shaping-logistics-and-fulfillment/",
          "publishedOn": "2023-08-29T18:28:36.000Z",
          "wordCount": 6881,
          "title": "The future of shipping: How technology is shaping logistics and fulfillment",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/drone-and-earth-1-1.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62995",
          "author": "ajitjaokar",
          "description": "In the early days of the Internet, there were four ‘horsemen’ of the Internet With IBM’s 4.5 billion investment in Hugging face today, the generative AI landscape is becoming a bit clearer. There are four Generative AI leaders emerging – others lagging – and one unknown Lets look at the four leaders of Generative AI… Read More »Generative AI megatrends: The four horsemen of Generative AI\nThe post Generative AI megatrends: The four horsemen of Generative AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/generative-ai-megatrends-the-four-horsemen-of-generative-ai/",
          "publishedOn": "2023-08-29T15:15:44.000Z",
          "wordCount": 5526,
          "title": "Generative AI megatrends: The four horsemen of Generative AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/horse-7863936_1280.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62928",
          "author": "Ahana Pearl",
          "description": "There seems to be an app for everything, and mental health is no exception. According to a report, the global mental health apps market size was valued at $5.2 billion in 2022 and is predicted to reach $26.36 billion by 2032, at a CAGR of 17.7% during the forecast period.  Mental health apps have emerged… Read More »The power of digital solutions: How mental health apps are transforming patient care\nThe post The power of digital solutions: How mental health apps are transforming patient care appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/the-power-of-digital-solutions-how-mental-health-apps-are-transforming-patient-care/",
          "publishedOn": "2023-08-29T15:12:18.000Z",
          "wordCount": 6128,
          "title": "The power of digital solutions: How mental health apps are transforming patient care",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/3796820.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62973",
          "author": "Ovais Naseem",
          "description": "Introduction  In our rapidly digitizing world, how businesses and systems communicate is paramount. The bedrock of this communication lies in data exchange methods, which allow seamless information flow, driving operational efficiencies and enabling innovation. Over the years, various data exchange protocols have emerged, each boasting unique strengths and presenting challenges. As enterprises strive to integrate… Read More »Modern data exchange methods: Exploring the strengths and limitations of leading protocols\nThe post Modern data exchange methods: Exploring the strengths and limitations of leading protocols appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/modern-data-exchange-methods-exploring-the-strengths-and-limitations-of-leading-protocols/",
          "publishedOn": "2023-08-29T15:03:34.000Z",
          "wordCount": 6811,
          "title": "Modern data exchange methods: Exploring the strengths and limitations of leading protocols",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/78a9ffe1ada2c4e0291a2944803b95a9.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62965",
          "author": "Krishna Pera",
          "description": "History & Evolution | The Concept of Supply-chain Network, The TOC & the Information Supply-chain | Imagining the future: Supply-chain 5.0 | Supply-chain Analytics Strategy | Roadmap for Building a Data-driven, AI-Powered Supply-chain Part 1: Data-driven supply chain – History & evolution Is the concept of data driving decisions new? The concept of “data supporting… Read More »Roadmap for building a data-driven, AI-powered supply-chain\nThe post Roadmap for building a data-driven, AI-powered supply-chain appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/roadmap-for-building-a-data-driven-ai-powered-supply-chain/",
          "publishedOn": "2023-08-29T15:01:58.000Z",
          "wordCount": 6584,
          "title": "Roadmap for building a data-driven, AI-powered supply-chain",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/AdobeStock_468349385-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62980",
          "author": "Anas Baig",
          "description": "In the ever-evolving battle against the digital dark forces, the defenders of the virtual realm find themselves facing a barrage of ever-advancing threats. From the labyrinthine corridors of the Deep Web to the stealthy maneuvers of nation-state actors, the cyber landscape is as treacherous as it is vast. As our dependency on digital infrastructure deepens,… Read More »Empowering cyber guardians: How AI is changing the landscape of protection\nThe post Empowering cyber guardians: How AI is changing the landscape of protection appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/empowering-cyber-guardians-how-ai-is-changing-the-landscape-of-protection/",
          "publishedOn": "2023-08-28T05:34:55.000Z",
          "wordCount": 6379,
          "title": "Empowering cyber guardians: How AI is changing the landscape of protection",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/ai-cybersecurity.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62933",
          "author": "Anastasia Molodoria",
          "description": "Ever-growing volumes of unstructured data stored in countless document formats significantly complicate data processing and timely access to relevant information for organizations. Without proper optimization of data management workflows, it’s difficult to talk about business growth and scaling. That is why progressive companies opt for intelligent document processing powered by artificial intelligence. \nThe post Using AI technologies for effective document processing appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/using-ai-technologies-for-effective-document-processing/",
          "publishedOn": "2023-08-25T13:49:45.000Z",
          "wordCount": 6348,
          "title": "Using AI technologies for effective document processing",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/document-recognition-with-ai-scaled.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62962",
          "author": "Erika Balla",
          "description": "In an age where data has become the lifeblood of businesses, deciphering this raw data to yield actionable insights is critical. Here is where the role of business analytics comes into play. Business analytics, a blend of data management, business intelligence, and predictive modeling, is a field dedicated to driving business strategies through the lens… Read More »Data visualization: The underrated skill in business analytics\nThe post Data visualization: The underrated skill in business analytics appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/data-visualization-the-underrated-skill-in-business-analytics/",
          "publishedOn": "2023-08-25T13:24:41.000Z",
          "wordCount": 6739,
          "title": "Data visualization: The underrated skill in business analytics",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/Data-Visualization-scaled.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62949",
          "author": "Scott Thompson",
          "description": "Announcements Top Stories In-Depth\nThe post DSC Weekly 22 August 2023 appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/dsc-weekly-22-august-2023/",
          "publishedOn": "2023-08-22T17:47:39.000Z",
          "wordCount": 5953,
          "title": "DSC Weekly 22 August 2023",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/06/AdobeStock_552748421-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62943",
          "author": "Ari Kamlani",
          "description": "By Ari Kamlani, Senior AI Solutions Architect and Principal Data Scientist at Beyond Limits Rogue AI, or an autonomous artificial intelligence system that commits potentially dangerous acts, may take many forms and can bring with it varying levels of severity, threats, or harm.  Intelligent systems, while incredibly useful and full of great potential, can still… Read More »How organizations can prepare for rogue AI\nThe post How organizations can prepare for rogue AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/how-organizations-can-prepare-for-rogue-ai/",
          "publishedOn": "2023-08-22T17:31:53.000Z",
          "wordCount": 7236,
          "title": "How organizations can prepare for rogue AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/AdobeStock_617974125-1024x684.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62927",
          "author": "Yana Ihnatchyck",
          "description": "In the midst of the Fourth Industrial Revolution, generative AI emerges as a beacon of transformative potential. While AI’s capabilities in automation, recommendation, and prediction have been widely acknowledged, its generative functions have opened new horizons for businesses globally. This article seeks to shed light on the benefits of generative AI, elucidating how they’re altering… Read More »Top 4 generative AI benefits for business\nThe post Top 4 generative AI benefits for business appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/top-4-generative-ai-benefits-for-business/",
          "publishedOn": "2023-08-22T17:25:00.000Z",
          "wordCount": 6069,
          "title": "Top 4 generative AI benefits for business",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/111.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62909",
          "author": "ManojKumar847",
          "description": "Innovations in technology are changing the rules when it considers the use of big data and analytics for better growth. Advanced software systems are highly decreasing analytics time, hence offering companies the potential for making quick decisions that will help in boosting revenue, mitigating costs and stimulating growth. This provides a competitive advantage to the organizations… Read More »The use of Big Data Analytics for better growth and innovation\nThe post The use of Big Data Analytics for better growth and innovation appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/the-use-of-big-data-and-analytics-for-better-growth-and-innovation/",
          "publishedOn": "2023-08-22T17:22:04.000Z",
          "wordCount": 6385,
          "title": "The use of Big Data Analytics for better growth and innovation",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/AdobeStock_626590070-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62756",
          "author": "Edwin Walker",
          "description": "Modern Data Quality refers to the process of ensuring that data is accurate, reliable, consistent, and up-to-date in today’s data-driven environment. It involves implementing advanced technologies and methodologies to maintain high-quality data that meets the needs of various data-driven applications and analytics. Importance of Modern Data Quality: Innovation: Modern data quality drives innovation by providing… Read More »Modern data quality management\nThe post Modern data quality management appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/modern-data-quality-management/",
          "publishedOn": "2023-08-22T17:19:34.000Z",
          "wordCount": 5390,
          "title": "Modern data quality management",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/07/MicrosoftTeams-image-84-1.png"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62936",
          "author": "Kent State CoBA",
          "description": "Big data and artificial intelligence are able to collaborate to help organizations reap a variety of benefits. Since AI requires large amounts of data in order to learn and make decisions, it is able to utilize big data as a source of raw material. While big data can store data from various sources, AI can… Read More »The relationship between Big Data and AI\nThe post The relationship between Big Data and AI appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/the-relationship-between-big-data-and-ai/",
          "publishedOn": "2023-08-22T17:14:04.000Z",
          "wordCount": 6270,
          "title": "The relationship between Big Data and AI",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/AdobeStock_448141112-scaled.jpeg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62925",
          "author": "Alan Morrison",
          "description": "Data science was a vaguely defined discipline to begin with, but it’s shaped up substantially lately. Execs now yearn to take immediate advantage of generative and other clearly useful (if currently problematic) kinds of AI.  That demand suggests an opportunity for influencers and visionaries in organizations to lobby for each organization to build an AI-ready… Read More »Beyond data science: A knowledge foundation for the AI-ready enterprise\nThe post Beyond data science: A knowledge foundation for the AI-ready enterprise appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/beyond-data-science-a-knowledge-foundation-for-the-ai-ready-enterprise/",
          "publishedOn": "2023-08-21T19:30:34.000Z",
          "wordCount": 6245,
          "title": "Beyond data science: A knowledge foundation for the AI-ready enterprise",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/iron-railings-2832908_1280.jpg"
        },
        {
          "id": "https://www.datasciencecentral.com/?p=62906",
          "author": "John Lee",
          "description": "Key takeaways In an era marked by exponential technological advancements, the convergence of quantum computing and data science is a pivotal point of transformation. The synergy between these two fields promises to revolutionize how we process, analyze, and extract insights from massive datasets. With quantum computing’s unique ability to tackle complex computations at speeds previously… Read More »The impacts of quantum computing on the future of data science\nThe post The impacts of quantum computing on the future of data science appeared first on Data Science Central.",
          "link": "https://www.datasciencecentral.com/the-impacts-of-quantum-computing-on-the-future-of-data-science/",
          "publishedOn": "2023-08-21T14:49:47.000Z",
          "wordCount": 6674,
          "title": "The impacts of quantum computing on the future of data science",
          "imageUrl": "https://www.datasciencecentral.com/wp-content/uploads/2023/08/glowing-computer-chips-row-technology-illuminates-generated-by-ai.jpg"
        }
      ]
    },
    {
      "title": "John D. Cook",
      "feedUrl": "https://www.johndcook.com/blog/feed",
      "siteUrl": "https://www.johndcook.com/blog",
      "articles": [
        {
          "id": "https://www.johndcook.com/blog/?p=208756",
          "author": "John",
          "description": "Warm up The geometric mean of two numbers is the square root of their product. For example, the geometric mean of 9 and 25 is 15. More generally, the geometric mean of a set of n numbers is the nth root of their product. Alternatively, the geometric mean of a set of n numbers the […]\nGeometric mean on unit circle first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/18/mahler-measure/",
          "publishedOn": "2023-09-18T21:04:10.000Z",
          "wordCount": 1530,
          "title": "Geometric mean on unit circle",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208642",
          "author": "John",
          "description": "The Gauss map [1] is the function where ⌊y⌋ is the floor of y, the greatest integer no larger than y. I’ve written about this map a couple times before. First, I wrote about how this map is measure-preserving. Second, I wrote about the image at the top of the post, based on Michael Trott’s […]\nGauss map, Euclidean algorithm, and continued fractions first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/18/gauss-map/",
          "publishedOn": "2023-09-18T16:09:26.000Z",
          "wordCount": 1608,
          "title": "Gauss map, Euclidean algorithm, and continued fractions",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208626",
          "author": "John",
          "description": "The goal of this post is to unpack a remark in [1]: … we can say this in fancier terms. Fix a field k …. We say that an elliptic curve E defined over k is that functor which … Well that is fancy. But what does it mean? Looking for objects A functor is […]\nAn elliptic curve is a functor first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/18/elliptic-curve-functor/",
          "publishedOn": "2023-09-18T16:06:31.000Z",
          "wordCount": 1891,
          "title": "An elliptic curve is a functor",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208489",
          "author": "John",
          "description": "The geometric description of addition of points P and Q on an elliptic curve involves four logical branches: If one of P or Q is the point at infinity … Else if P = Q … Else if P and Q lie on a vertical line … Else … It would seem that an algorithm […]\nElliptic curve addition formulas first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/17/elliptic-curve-addition-formulas/",
          "publishedOn": "2023-09-17T22:05:55.000Z",
          "wordCount": 1881,
          "title": "Elliptic curve addition formulas",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208565",
          "author": "John",
          "description": "Mathematicians often speak informally about the relative simplicity of rational numbers. For example, musical intervals that correspond to simple fractions have less tension than intervals that correspond to more complicated fractions. Such informal statements can be made more precise using height functions. There are a variety of height functions designed for different applications, but the […]\nRational height functions first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/17/rational-height-functions/",
          "publishedOn": "2023-09-17T18:39:15.000Z",
          "wordCount": 1659,
          "title": "Rational height functions",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208268",
          "author": "John",
          "description": "If you ask someone a question and they say “yes” immediately, that gives you different information than if they pause and slowly say “yes.” The information you receive is not just the response but also the time it took to generate the response. Encryption can be analogous. The time it takes to encrypt data can […]\nTiming attacks first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/15/timing-attacks/",
          "publishedOn": "2023-09-15T20:15:11.000Z",
          "wordCount": 1565,
          "title": "Timing attacks",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208277",
          "author": "John",
          "description": "I concluded the previous post by saying elliptic curve Diffie-Hellman key exchange (ECDHE) requires smaller keys than finite field Diffie-Hellman (FFDHE) to obtain the same level of security. How much smaller are we talking about? According to NIST recommendations, a 256-bit elliptic curve curve provides about the same security as working over a 3072-bit finite […]\nElliptic curve Diffie-Hellman key exchange first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/15/ecdhe/",
          "publishedOn": "2023-09-15T15:08:53.000Z",
          "wordCount": 1742,
          "title": "Elliptic curve Diffie-Hellman key exchange",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208147",
          "author": "John",
          "description": "Diffie-Hellman key exchange is conceptually simple. Alice and Bob want to generate a shared cryptographic key. They want to use asymmetric (public) cryptography to share a symmetric (private) key. The starting point is a large prime p and a generator 1 < g < p. Alice generates a large random number x, her private key, […]\nFinite field Diffie Hellman primes first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/15/ffdhe/",
          "publishedOn": "2023-09-15T10:31:46.000Z",
          "wordCount": 1805,
          "title": "Finite field Diffie Hellman primes",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208054",
          "author": "John",
          "description": "Suppose m = pq where p and q are large, distinct primes. In the previous post we said that calculations mod m can often be carried out more efficiently by working mod p and mod q, then combining the results to get back to a result mod m. The Chinese Remainder Theorem assures us that […]\nChinese Remainder Theorem synthesis algorithm first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/14/garners-algorithm/",
          "publishedOn": "2023-09-14T16:07:56.000Z",
          "wordCount": 1614,
          "title": "Chinese Remainder Theorem synthesis algorithm",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208061",
          "author": "John",
          "description": "Suppose m is a large integer that you are able to factor. To keep things simple, suppose m = pq where p and q are distinct primes; everything in this post generalizes easily to the case of m having more than two factors. You can carry out calculations mod m more efficiently by carrying out […]\nGaining efficiency by working modulo factors first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/14/crt-analysis/",
          "publishedOn": "2023-09-14T16:05:36.000Z",
          "wordCount": 1560,
          "title": "Gaining efficiency by working modulo factors",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=208013",
          "author": "John",
          "description": "RSA encryption a map from numbers mod n to numbers mod n where n is a public key. A message is represented as an integer m and is encrypted by computing c = me mod n where e is part of the public key. In practice, e is usually 65537 though it does not have […]\nGroup theory and RSA encryption first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/14/rsa-group-theory/",
          "publishedOn": "2023-09-14T11:57:26.000Z",
          "wordCount": 2001,
          "title": "Group theory and RSA encryption",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=207999",
          "author": "John",
          "description": "Not all messages encrypted with the RSA algorithm can be decrypted. This post will show why this is possible and why it does not matter in practice. RSA in a nutshell RSA encryption starts by finding two large primes, p and q. These primes are kept secret, but their product n = pq is made public. […]\nRSA encrypted messages that cannot be decrypted first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/14/rsa-decrypted/",
          "publishedOn": "2023-09-14T10:15:35.000Z",
          "wordCount": 1888,
          "title": "RSA encrypted messages that cannot be decrypted",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=207554",
          "author": "John",
          "description": "Dimension 2 The equation for the perimeter of an ellipse is where a is the semimajor axis, e is eccentricity, and E is a special function. The equation is simple, in the sense that it has few terms, but it is not elementary, because it depends on an advanced function, the complete elliptic integral of the […]\nHyperellipsoid surface area first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/11/hyperellipsoid-surface-area/",
          "publishedOn": "2023-09-11T20:56:28.000Z",
          "wordCount": 1750,
          "title": "Hyperellipsoid surface area",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=207544",
          "author": "John",
          "description": "I posted some notes this morning on how to find the perimeter of an ellipse given its axes. The notes include a simple approximation, a better but more complicated approximation, and the exact value. So given the semi axes a and b, the notes give three ways to compute the perimeter p. If you are […]\nSolve for ellipse axes given perimeter first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/11/solve-for-ellipse-axes/",
          "publishedOn": "2023-09-11T19:19:52.000Z",
          "wordCount": 1397,
          "title": "Solve for ellipse axes given perimeter",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=207515",
          "author": "John",
          "description": "The home team lost in a new way yesterday. The Baltimore Ravens beat the Houston Texans by 25-9. This was the first time that score has been seen in the NFL. Possible individual team scores How many scores are possible? It is possible to score any number of points except 1. You can score 2 […]\nPossible and actual football scores first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/11/nfl-scores/",
          "publishedOn": "2023-09-11T17:49:34.000Z",
          "wordCount": 1641,
          "title": "Possible and actual football scores",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=207222",
          "author": "John",
          "description": "Earlier I wrote a post showing what happens when you start with an equilateral triangle, then repeatedly subdivide it into smaller and smaller triangles by drawing lines from the centroid (barycenter) to each of the vertices. I mentioned in that post that I moved the code for finding the center to its own function because […]\nHow you define center matters a lot first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/09/triangle-subdivision/",
          "publishedOn": "2023-09-10T00:43:44.000Z",
          "wordCount": 1485,
          "title": "How you define center matters a lot",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=207192",
          "author": "John",
          "description": "I just saw a tweet from Dave Richeson saying I remember as a kid calculating the size difference (diameter) of a belt between each hole. Now I think about it every time I wear a belt. Holes 1 inch apart change the diameter by about one-third of an inch (1/π). [Assuming people have a circular […]\nBelt around an elliptical waist first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/09/belt-around-an-elliptical-waist/",
          "publishedOn": "2023-09-09T22:42:59.000Z",
          "wordCount": 1754,
          "title": "Belt around an elliptical waist",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=207149",
          "author": "John",
          "description": "The other day I saw where Cliff Pickover tweeted some images of triangles recursively subdivided by adding a point to the barycenter of each triangle. The images were not what I expected, so I wanted to reproduce the images to look into this further. Here are the first three steps: I set the alpha value […]\nRecursive triangle subdivision first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/09/recursive-triangle-subdivision/",
          "publishedOn": "2023-09-09T16:58:47.000Z",
          "wordCount": 1555,
          "title": "Recursive triangle subdivision",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=207000",
          "author": "John",
          "description": "One of the most common things a statistician is asked to do is compute a sample. There are well known formulas for this, so why isn’t calculating a sample size trivial? As with most things in statistics, plugging numbers into a formula is not the hard part. The hard part is deciding what numbers to […]\nJustifiable sample size first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/08/justifiable-sample-size/",
          "publishedOn": "2023-09-08T12:01:19.000Z",
          "wordCount": 1786,
          "title": "Justifiable sample size",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=206719",
          "author": "John",
          "description": "A large class of checksum algorithms have the following pattern: Think of the bits in a file as the coefficients in a polynomial P(x). Divide P(x) by a fixed polynomial Q(x) mod 2 and keep the remainder. Report the remainder as a sequence of bits. In practice there’s a little more to the algorithm than […]\nChecksum polynomials first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/06/checksum-polynomials/",
          "publishedOn": "2023-09-06T15:40:14.000Z",
          "wordCount": 1813,
          "title": "Checksum polynomials",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=206492",
          "author": "John",
          "description": "Given a square complex matrix A, the Jordan normal form of A is a matrix J such that and J has a particular form. The eigenvalues of A are along the diagonal of J, and the elements above the diagonal are 0s or 1s. There’s a particular pattern to the 1s, giving the matrix J […]\nJordan normal form: 1’s above or below diagonal? first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/04/jnf-above-below/",
          "publishedOn": "2023-09-04T18:25:03.000Z",
          "wordCount": 1759,
          "title": "Jordan normal form: 1’s above or below diagonal?",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=206395",
          "author": "John",
          "description": "When is the discrete Fourier transform of a vector proportional to the original vector? And when that happens, what is the proportionality constant? In more formal language, what can we say about the eigenvectors and eigenvalues of the DFT matrix? Setup I mentioned in the previous post that Mathematica’s default convention for defining the DFT […]\nEigenvectors of the DFT matrix first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/03/eigenvectors-of-dft/",
          "publishedOn": "2023-09-04T01:47:01.000Z",
          "wordCount": 1677,
          "title": "Eigenvectors of the DFT matrix",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=206268",
          "author": "John",
          "description": "Just as there are multiple conventions for defining the Fourier transform, there are multiple conventions for defining the discrete Fourier transform (DFT), better known as the fast Fourier transform (FFT). [1] This post will look at two DFT conventions, one used in Python’s NumPy library, and one used in Mathematica. There are more conventions in […]\nDFT conventions: NumPy vs Mathematica first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/03/dft-numpy-mathematica/",
          "publishedOn": "2023-09-03T20:27:05.000Z",
          "wordCount": 1725,
          "title": "DFT conventions: NumPy vs Mathematica",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=206229",
          "author": "John",
          "description": "Math books often use some illustration from the book contents as cover art. When they do, there’s often some mystery to the cover art, and a sense of accomplishment when you get far enough into the book to understand the significance of the cover. (See examples here.) William L. Briggs and Van Emden Henson wrote […]\nDFT mandalas first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/09/02/dft-mandalas/",
          "publishedOn": "2023-09-02T19:19:57.000Z",
          "wordCount": 1560,
          "title": "DFT mandalas",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=205920",
          "author": "John",
          "description": "In his book How to Read Literature Like a Professor, Thomas Foster says that if a poem looks like a square on the printed page, it’s likely a sonnet. The miracle of the sonnet, you see, is that it is fourteen lines long and written almost always in iambic pentameter. … suffice it to say […]\nSonnets are square first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/31/sonnets-are-square/",
          "publishedOn": "2023-08-31T19:30:50.000Z",
          "wordCount": 1322,
          "title": "Sonnets are square",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=205726",
          "author": "John",
          "description": "Suppose you’ve been monitoring a rare event for a long time, then you see your first occurrence on the Nth observation. Now what would you say about the event’s probability? For example, suppose you’re wondering whether dogs ever have two tails. You observe thousands of dogs and never see two tails. But then you see […]\nFirst time seeing a rare event first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/30/first-time-seeing-a-rare-event/",
          "publishedOn": "2023-08-30T14:24:17.000Z",
          "wordCount": 1647,
          "title": "First time seeing a rare event",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=205555",
          "author": "John",
          "description": "Imagine the following dialog. “Logarithms are usually taken to integer bases, like 2 or 10.” “What about e?” “OK, that’s an example of an irrational base, but it’s the only one.” “Decibels are logarithms to base 101/10.” “Really?!” “Yeah, you can read about this here.” “That’s weird. But logarithms are always take to bases bigger than […]\nStellar magnitude first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/29/stellar-magnitude/",
          "publishedOn": "2023-08-29T18:15:03.000Z",
          "wordCount": 1746,
          "title": "Stellar magnitude",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=205537",
          "author": "John",
          "description": "US telephone area codes are allocated somewhat randomly. There was a deliberate effort to keep geographical proximity from corresponding to numerical proximity, unlike zip codes. (More of zip code proximity here.) In particular, consecutive area codes should belong to different states. The thought was that this would reduce errors. It’s still mostly the case that […]\nArea codes first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/29/area-codes/",
          "publishedOn": "2023-08-29T15:32:23.000Z",
          "wordCount": 1701,
          "title": "Area codes",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=205198",
          "author": "John",
          "description": "I was flipping through Gravitation [1] this weekend and was curious about an illustration on page 309. This post reproduces that graph. The graph is centered at Cairo, Egypt and includes triangles whose side lengths are the distances between cities. The triangles are calculated using only distances, not by measuring angles per se. The geometry […]\nCurvature at Cairo first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/27/curvature-at-cairo/",
          "publishedOn": "2023-08-27T21:47:08.000Z",
          "wordCount": 1881,
          "title": "Curvature at Cairo",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=205234",
          "author": "John",
          "description": "Given the equations for two circles, how can you tell whether they intersect? And if they do intersect, how do you find the point(s) of intersection? MathWorld gives a derivation, but I’d like to add the derivation there in two ways. First, I’d like to be more explicit about the number of solutions. Second, I’d […]\nCalculating the intersection of two circles first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/27/intersect-circles/",
          "publishedOn": "2023-08-27T20:02:42.000Z",
          "wordCount": 1943,
          "title": "Calculating the intersection of two circles",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=204968",
          "author": "John",
          "description": "Paul Graham said “Programming languages teach you not to want what they don’t provide.” He meant that as a negative: programmers using less expressive languages don’t know what they’re missing. But you could also take that as a positive: using a simple language can teach you that you don’t need features you thought you needed. […]\nA small programming language first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/26/awk/",
          "publishedOn": "2023-08-26T12:05:06.000Z",
          "wordCount": 1843,
          "title": "A small programming language",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=204953",
          "author": "John",
          "description": "Many numerical integration formulas over a finite interval have the form That is, the integral on the left can be approximated by evaluating the integrand f at particular nodes and taking the weighted sum, and the error is some multiple of a derivative of f evaluated at a point in the interval [a, b]. This […]\nQuadrature rules and an impossibility theorem first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/25/quadrature-impossibility/",
          "publishedOn": "2023-08-26T01:26:13.000Z",
          "wordCount": 1856,
          "title": "Quadrature rules and an impossibility theorem",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=204741",
          "author": "John",
          "description": "In his book The World Beyond Your Head Matthew Crawford talks about jigs literally and metaphorically. A jig in carpentry is something to hold parts in place, such as aligning boards that need to be cut to the same length. Crawford uses the term more generally to describe labor-saving (or more importantly, thought-saving) techniques in […]\nJigs first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/24/jigs/",
          "publishedOn": "2023-08-24T18:31:32.000Z",
          "wordCount": 1604,
          "title": "Jigs",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=204304",
          "author": "John",
          "description": "This morning I wrote about Dan Piponi’s fake prime function. This evening I thought about it again and wondered whether the chi-squared test could tell the difference between the distribution of digits in real primes and fake primes. When data fall into a number of buckets, with a moderate number of items expected to fall […]\nCan the chi squared test detect fake primes? first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/21/chi-squared-test-fakes/",
          "publishedOn": "2023-08-21T23:33:24.000Z",
          "wordCount": 1643,
          "title": "Can the chi squared test detect fake primes?",
          "imageUrl": null
        },
        {
          "id": "https://www.johndcook.com/blog/?p=204204",
          "author": "John",
          "description": "I have an account on Mastodon: johndcook@mathstodon.xyz. Note that’s @math… and not @mast… One advantage to Mastodon is that you can browse content there without logging, while Twitter is becoming more of a walled garden. You can browse my account, for example, by going to the URL https://mathstodon.xyz/@johndcook There’s hardly any content there at this […]\nMastodon account first appeared on John D. Cook.",
          "link": "https://www.johndcook.com/blog/2023/08/21/mastodon-account/",
          "publishedOn": "2023-08-21T13:10:13.000Z",
          "wordCount": 1435,
          "title": "Mastodon account",
          "imageUrl": null
        }
      ]
    }
  ],
  "cliVersion": "1.15.1"
}